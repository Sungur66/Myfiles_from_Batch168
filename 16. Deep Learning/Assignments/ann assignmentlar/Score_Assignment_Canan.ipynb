{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {
    "executionInfo": {
     "elapsed": 1189,
     "status": "ok",
     "timestamp": 1705653817282,
     "user": {
      "displayName": "Canan Dülgeroğlu",
      "userId": "00060531196188721276"
     },
     "user_tz": -180
    },
    "id": "Ma5yf-Iop9aI"
   },
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "import pandas as pd\n",
    "import seaborn as sns\n",
    "import matplotlib.pyplot as plt\n",
    "\n",
    "%matplotlib inline\n",
    "# %matplotlib notebook\n",
    "plt.rcParams[\"figure.figsize\"] = (12, 6)\n",
    "# plt.rcParams['figure.dpi'] = 100\n",
    "sns.set_style(\"whitegrid\")\n",
    "import warnings\n",
    "\n",
    "warnings.filterwarnings(\"ignore\")\n",
    "warnings.warn(\"this will not show\")\n",
    "pd.set_option('display.float_format', lambda x: '%.3f' % x)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "executionInfo": {
     "elapsed": 12470,
     "status": "ok",
     "timestamp": 1705616259176,
     "user": {
      "displayName": "Canan Dülgeroğlu",
      "userId": "00060531196188721276"
     },
     "user_tz": -180
    },
    "id": "Im1uJYhtqAMs",
    "outputId": "3441ea36-6f5a-43a3-acdc-3173f7433ffa"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Drive already mounted at /content/drive; to attempt to forcibly remount, call drive.mount(\"/content/drive\", force_remount=True).\n"
     ]
    }
   ],
   "source": [
    "from google.colab import drive\n",
    "drive.mount('/content/drive')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "bkfodj2SZFiK"
   },
   "source": [
    "Annual_Income: The Annual Income of the person\n",
    "Monthly_Inhand_Salary: Monthly in-hand salary of the person\n",
    "Num_Bank_Accounts: The number of bank accounts of the person\n",
    "Num_Credit_Card: Number of credit cards the person is having\n",
    "Interest_Rate: The interest rate on the credit card of the person\n",
    "Num_of_Loan: The number of loans taken by the person from the bank\n",
    "Type_of_Loan: The types of loans taken by the person from the bank\n",
    "Delay_from_due_date: The average number of days delayed by the person from the date of payment\n",
    "Num_of_Delayed_Payment: Number of payments delayed by the person\n",
    "Changed_Credit_Card: The percentage change in the credit card limit of the person\n",
    "Num_Credit_Inquiries: The number of credit card inquiries by the person\n",
    "Credit_Mix: Classification of Credit Mix of the customer\n",
    "Outstanding_Debt: The outstanding balance of the person\n",
    "Credit_Utilization_Ratio: The credit utilization ratio of the credit card of the customer\n",
    "Credit_History_Age: The age of the credit history of the person\n",
    "Payment_of_Min_Amount: Yes if the person paid the minimum amount to be paid only, otherwise no.\n",
    "Total_EMI_per_month: The total EMI per month of the person\n",
    "Amount_invested_monthly: The monthly amount invested by the person\n",
    "Payment_Behaviour: The payment behaviour of the person\n",
    "Monthly_Balance: The monthly balance left in the account of the person\n",
    "Credit_Score: The credit score of the person\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 94,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>0</th>\n",
       "      <th>1</th>\n",
       "      <th>2</th>\n",
       "      <th>3</th>\n",
       "      <th>4</th>\n",
       "      <th>5</th>\n",
       "      <th>6</th>\n",
       "      <th>7</th>\n",
       "      <th>8</th>\n",
       "      <th>9</th>\n",
       "      <th>...</th>\n",
       "      <th>99950</th>\n",
       "      <th>99951</th>\n",
       "      <th>99952</th>\n",
       "      <th>99953</th>\n",
       "      <th>99954</th>\n",
       "      <th>99955</th>\n",
       "      <th>99956</th>\n",
       "      <th>99957</th>\n",
       "      <th>99958</th>\n",
       "      <th>99959</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>Delay_from_due_date</th>\n",
       "      <td>3.000</td>\n",
       "      <td>3.000</td>\n",
       "      <td>3.000</td>\n",
       "      <td>5.000</td>\n",
       "      <td>6.000</td>\n",
       "      <td>8.000</td>\n",
       "      <td>3.000</td>\n",
       "      <td>3.000</td>\n",
       "      <td>3.000</td>\n",
       "      <td>7.000</td>\n",
       "      <td>...</td>\n",
       "      <td>33.000</td>\n",
       "      <td>33.000</td>\n",
       "      <td>23.000</td>\n",
       "      <td>23.000</td>\n",
       "      <td>20.000</td>\n",
       "      <td>23.000</td>\n",
       "      <td>18.000</td>\n",
       "      <td>27.000</td>\n",
       "      <td>20.000</td>\n",
       "      <td>18.000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>Num_of_Delayed_Payment</th>\n",
       "      <td>7.000</td>\n",
       "      <td>7.000</td>\n",
       "      <td>7.000</td>\n",
       "      <td>4.000</td>\n",
       "      <td>4.000</td>\n",
       "      <td>4.000</td>\n",
       "      <td>8.000</td>\n",
       "      <td>6.000</td>\n",
       "      <td>4.000</td>\n",
       "      <td>1.000</td>\n",
       "      <td>...</td>\n",
       "      <td>26.000</td>\n",
       "      <td>25.000</td>\n",
       "      <td>6.000</td>\n",
       "      <td>6.000</td>\n",
       "      <td>6.000</td>\n",
       "      <td>7.000</td>\n",
       "      <td>7.000</td>\n",
       "      <td>6.000</td>\n",
       "      <td>6.000</td>\n",
       "      <td>6.000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>Num_Credit_Inquiries</th>\n",
       "      <td>4.000</td>\n",
       "      <td>4.000</td>\n",
       "      <td>4.000</td>\n",
       "      <td>4.000</td>\n",
       "      <td>4.000</td>\n",
       "      <td>4.000</td>\n",
       "      <td>4.000</td>\n",
       "      <td>4.000</td>\n",
       "      <td>2.000</td>\n",
       "      <td>2.000</td>\n",
       "      <td>...</td>\n",
       "      <td>9.000</td>\n",
       "      <td>9.000</td>\n",
       "      <td>3.000</td>\n",
       "      <td>3.000</td>\n",
       "      <td>3.000</td>\n",
       "      <td>3.000</td>\n",
       "      <td>3.000</td>\n",
       "      <td>3.000</td>\n",
       "      <td>3.000</td>\n",
       "      <td>3.000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>Credit_Utilization_Ratio</th>\n",
       "      <td>26.823</td>\n",
       "      <td>31.945</td>\n",
       "      <td>28.609</td>\n",
       "      <td>31.378</td>\n",
       "      <td>24.797</td>\n",
       "      <td>27.262</td>\n",
       "      <td>22.538</td>\n",
       "      <td>23.934</td>\n",
       "      <td>24.464</td>\n",
       "      <td>38.551</td>\n",
       "      <td>...</td>\n",
       "      <td>25.124</td>\n",
       "      <td>37.141</td>\n",
       "      <td>32.991</td>\n",
       "      <td>29.135</td>\n",
       "      <td>39.324</td>\n",
       "      <td>34.664</td>\n",
       "      <td>40.566</td>\n",
       "      <td>41.256</td>\n",
       "      <td>33.638</td>\n",
       "      <td>34.192</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>Credit_History_Age</th>\n",
       "      <td>265.000</td>\n",
       "      <td>265.000</td>\n",
       "      <td>267.000</td>\n",
       "      <td>268.000</td>\n",
       "      <td>269.000</td>\n",
       "      <td>270.000</td>\n",
       "      <td>271.000</td>\n",
       "      <td>271.000</td>\n",
       "      <td>319.000</td>\n",
       "      <td>320.000</td>\n",
       "      <td>...</td>\n",
       "      <td>73.000</td>\n",
       "      <td>75.000</td>\n",
       "      <td>375.000</td>\n",
       "      <td>376.000</td>\n",
       "      <td>377.000</td>\n",
       "      <td>378.000</td>\n",
       "      <td>379.000</td>\n",
       "      <td>380.000</td>\n",
       "      <td>381.000</td>\n",
       "      <td>382.000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>Payment_of_Min_Amount</th>\n",
       "      <td>No</td>\n",
       "      <td>No</td>\n",
       "      <td>No</td>\n",
       "      <td>No</td>\n",
       "      <td>No</td>\n",
       "      <td>No</td>\n",
       "      <td>No</td>\n",
       "      <td>No</td>\n",
       "      <td>No</td>\n",
       "      <td>No</td>\n",
       "      <td>...</td>\n",
       "      <td>Yes</td>\n",
       "      <td>Yes</td>\n",
       "      <td>No</td>\n",
       "      <td>No</td>\n",
       "      <td>No</td>\n",
       "      <td>No</td>\n",
       "      <td>No</td>\n",
       "      <td>No</td>\n",
       "      <td>No</td>\n",
       "      <td>No</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>Amount_invested_monthly</th>\n",
       "      <td>80.415</td>\n",
       "      <td>118.280</td>\n",
       "      <td>81.700</td>\n",
       "      <td>199.458</td>\n",
       "      <td>41.420</td>\n",
       "      <td>62.430</td>\n",
       "      <td>178.344</td>\n",
       "      <td>24.785</td>\n",
       "      <td>104.292</td>\n",
       "      <td>40.391</td>\n",
       "      <td>...</td>\n",
       "      <td>173.276</td>\n",
       "      <td>34.663</td>\n",
       "      <td>401.196</td>\n",
       "      <td>180.733</td>\n",
       "      <td>140.581</td>\n",
       "      <td>60.971</td>\n",
       "      <td>54.186</td>\n",
       "      <td>24.028</td>\n",
       "      <td>251.673</td>\n",
       "      <td>167.164</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>Monthly_Balance</th>\n",
       "      <td>312.494</td>\n",
       "      <td>284.629</td>\n",
       "      <td>331.210</td>\n",
       "      <td>223.451</td>\n",
       "      <td>341.489</td>\n",
       "      <td>340.479</td>\n",
       "      <td>244.565</td>\n",
       "      <td>358.124</td>\n",
       "      <td>470.691</td>\n",
       "      <td>484.591</td>\n",
       "      <td>...</td>\n",
       "      <td>228.750</td>\n",
       "      <td>337.363</td>\n",
       "      <td>189.641</td>\n",
       "      <td>400.104</td>\n",
       "      <td>410.256</td>\n",
       "      <td>479.866</td>\n",
       "      <td>496.652</td>\n",
       "      <td>516.809</td>\n",
       "      <td>319.165</td>\n",
       "      <td>393.674</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>Credit_Score</th>\n",
       "      <td>Good</td>\n",
       "      <td>Good</td>\n",
       "      <td>Good</td>\n",
       "      <td>Good</td>\n",
       "      <td>Good</td>\n",
       "      <td>Good</td>\n",
       "      <td>Good</td>\n",
       "      <td>Standard</td>\n",
       "      <td>Standard</td>\n",
       "      <td>Good</td>\n",
       "      <td>...</td>\n",
       "      <td>Standard</td>\n",
       "      <td>Standard</td>\n",
       "      <td>Poor</td>\n",
       "      <td>Standard</td>\n",
       "      <td>Poor</td>\n",
       "      <td>Poor</td>\n",
       "      <td>Poor</td>\n",
       "      <td>Poor</td>\n",
       "      <td>Standard</td>\n",
       "      <td>Poor</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>Credit_Mix</th>\n",
       "      <td>Good</td>\n",
       "      <td>Good</td>\n",
       "      <td>Good</td>\n",
       "      <td>Good</td>\n",
       "      <td>Good</td>\n",
       "      <td>Good</td>\n",
       "      <td>Good</td>\n",
       "      <td>Good</td>\n",
       "      <td>Good</td>\n",
       "      <td>Good</td>\n",
       "      <td>...</td>\n",
       "      <td>Bad</td>\n",
       "      <td>Bad</td>\n",
       "      <td>Good</td>\n",
       "      <td>Good</td>\n",
       "      <td>Good</td>\n",
       "      <td>Good</td>\n",
       "      <td>Good</td>\n",
       "      <td>Good</td>\n",
       "      <td>Good</td>\n",
       "      <td>Good</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>Payment_Behaviour</th>\n",
       "      <td>High_spent_Medium_value_payments</td>\n",
       "      <td>High_spent_Medium_value_payments</td>\n",
       "      <td>High_spent_Medium_value_payments</td>\n",
       "      <td>High_spent_Medium_value_payments</td>\n",
       "      <td>High_spent_Medium_value_payments</td>\n",
       "      <td>High_spent_Medium_value_payments</td>\n",
       "      <td>High_spent_Medium_value_payments</td>\n",
       "      <td>High_spent_Medium_value_payments</td>\n",
       "      <td>High_spent_Large_value_payments</td>\n",
       "      <td>High_spent_Large_value_payments</td>\n",
       "      <td>...</td>\n",
       "      <td>High_spent_Large_value_payments</td>\n",
       "      <td>High_spent_Large_value_payments</td>\n",
       "      <td>High_spent_Medium_value_payments</td>\n",
       "      <td>High_spent_Medium_value_payments</td>\n",
       "      <td>High_spent_Medium_value_payments</td>\n",
       "      <td>High_spent_Medium_value_payments</td>\n",
       "      <td>High_spent_Medium_value_payments</td>\n",
       "      <td>High_spent_Medium_value_payments</td>\n",
       "      <td>High_spent_Medium_value_payments</td>\n",
       "      <td>High_spent_Medium_value_payments</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>Age</th>\n",
       "      <td>23.000</td>\n",
       "      <td>23.000</td>\n",
       "      <td>23.000</td>\n",
       "      <td>23.000</td>\n",
       "      <td>23.000</td>\n",
       "      <td>23.000</td>\n",
       "      <td>23.000</td>\n",
       "      <td>23.000</td>\n",
       "      <td>28.000</td>\n",
       "      <td>28.000</td>\n",
       "      <td>...</td>\n",
       "      <td>28.000</td>\n",
       "      <td>28.000</td>\n",
       "      <td>25.000</td>\n",
       "      <td>25.000</td>\n",
       "      <td>25.000</td>\n",
       "      <td>25.000</td>\n",
       "      <td>25.000</td>\n",
       "      <td>25.000</td>\n",
       "      <td>25.000</td>\n",
       "      <td>25.000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>Annual_Income</th>\n",
       "      <td>19114.120</td>\n",
       "      <td>19114.120</td>\n",
       "      <td>19114.120</td>\n",
       "      <td>19114.120</td>\n",
       "      <td>19114.120</td>\n",
       "      <td>19114.120</td>\n",
       "      <td>19114.120</td>\n",
       "      <td>19114.120</td>\n",
       "      <td>34847.840</td>\n",
       "      <td>34847.840</td>\n",
       "      <td>...</td>\n",
       "      <td>20002.880</td>\n",
       "      <td>20002.880</td>\n",
       "      <td>39628.990</td>\n",
       "      <td>39628.990</td>\n",
       "      <td>39628.990</td>\n",
       "      <td>39628.990</td>\n",
       "      <td>39628.990</td>\n",
       "      <td>39628.990</td>\n",
       "      <td>39628.990</td>\n",
       "      <td>39628.990</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>Num_Bank_Accounts</th>\n",
       "      <td>3.000</td>\n",
       "      <td>3.000</td>\n",
       "      <td>3.000</td>\n",
       "      <td>3.000</td>\n",
       "      <td>3.000</td>\n",
       "      <td>3.000</td>\n",
       "      <td>3.000</td>\n",
       "      <td>3.000</td>\n",
       "      <td>2.000</td>\n",
       "      <td>2.000</td>\n",
       "      <td>...</td>\n",
       "      <td>10.000</td>\n",
       "      <td>10.000</td>\n",
       "      <td>4.000</td>\n",
       "      <td>4.000</td>\n",
       "      <td>4.000</td>\n",
       "      <td>4.000</td>\n",
       "      <td>4.000</td>\n",
       "      <td>4.000</td>\n",
       "      <td>4.000</td>\n",
       "      <td>4.000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>Num_Credit_Card</th>\n",
       "      <td>4.000</td>\n",
       "      <td>4.000</td>\n",
       "      <td>4.000</td>\n",
       "      <td>4.000</td>\n",
       "      <td>4.000</td>\n",
       "      <td>4.000</td>\n",
       "      <td>4.000</td>\n",
       "      <td>4.000</td>\n",
       "      <td>4.000</td>\n",
       "      <td>4.000</td>\n",
       "      <td>...</td>\n",
       "      <td>8.000</td>\n",
       "      <td>8.000</td>\n",
       "      <td>6.000</td>\n",
       "      <td>6.000</td>\n",
       "      <td>6.000</td>\n",
       "      <td>6.000</td>\n",
       "      <td>6.000</td>\n",
       "      <td>6.000</td>\n",
       "      <td>6.000</td>\n",
       "      <td>6.000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>Interest_Rate</th>\n",
       "      <td>3.000</td>\n",
       "      <td>3.000</td>\n",
       "      <td>3.000</td>\n",
       "      <td>3.000</td>\n",
       "      <td>3.000</td>\n",
       "      <td>3.000</td>\n",
       "      <td>3.000</td>\n",
       "      <td>3.000</td>\n",
       "      <td>6.000</td>\n",
       "      <td>6.000</td>\n",
       "      <td>...</td>\n",
       "      <td>29.000</td>\n",
       "      <td>29.000</td>\n",
       "      <td>7.000</td>\n",
       "      <td>7.000</td>\n",
       "      <td>7.000</td>\n",
       "      <td>7.000</td>\n",
       "      <td>7.000</td>\n",
       "      <td>7.000</td>\n",
       "      <td>7.000</td>\n",
       "      <td>7.000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>Num_of_Loan</th>\n",
       "      <td>4.000</td>\n",
       "      <td>4.000</td>\n",
       "      <td>4.000</td>\n",
       "      <td>4.000</td>\n",
       "      <td>4.000</td>\n",
       "      <td>4.000</td>\n",
       "      <td>4.000</td>\n",
       "      <td>4.000</td>\n",
       "      <td>1.000</td>\n",
       "      <td>1.000</td>\n",
       "      <td>...</td>\n",
       "      <td>5.000</td>\n",
       "      <td>5.000</td>\n",
       "      <td>2.000</td>\n",
       "      <td>2.000</td>\n",
       "      <td>2.000</td>\n",
       "      <td>2.000</td>\n",
       "      <td>2.000</td>\n",
       "      <td>2.000</td>\n",
       "      <td>2.000</td>\n",
       "      <td>2.000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>Monthly_Inhand_Salary</th>\n",
       "      <td>1824.843</td>\n",
       "      <td>1824.843</td>\n",
       "      <td>1824.843</td>\n",
       "      <td>1824.843</td>\n",
       "      <td>1824.843</td>\n",
       "      <td>1824.843</td>\n",
       "      <td>1824.843</td>\n",
       "      <td>1824.843</td>\n",
       "      <td>3037.987</td>\n",
       "      <td>3037.987</td>\n",
       "      <td>...</td>\n",
       "      <td>1929.907</td>\n",
       "      <td>1929.907</td>\n",
       "      <td>3359.416</td>\n",
       "      <td>3359.416</td>\n",
       "      <td>3359.416</td>\n",
       "      <td>3359.416</td>\n",
       "      <td>3359.416</td>\n",
       "      <td>3359.416</td>\n",
       "      <td>3359.416</td>\n",
       "      <td>3359.416</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>Changed_Credit_Limit</th>\n",
       "      <td>11.270</td>\n",
       "      <td>11.270</td>\n",
       "      <td>11.270</td>\n",
       "      <td>11.270</td>\n",
       "      <td>11.270</td>\n",
       "      <td>11.270</td>\n",
       "      <td>11.270</td>\n",
       "      <td>11.270</td>\n",
       "      <td>5.420</td>\n",
       "      <td>5.420</td>\n",
       "      <td>...</td>\n",
       "      <td>18.310</td>\n",
       "      <td>18.310</td>\n",
       "      <td>11.500</td>\n",
       "      <td>11.500</td>\n",
       "      <td>11.500</td>\n",
       "      <td>11.500</td>\n",
       "      <td>11.500</td>\n",
       "      <td>11.500</td>\n",
       "      <td>11.500</td>\n",
       "      <td>11.500</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>Outstanding_Debt</th>\n",
       "      <td>809.980</td>\n",
       "      <td>809.980</td>\n",
       "      <td>809.980</td>\n",
       "      <td>809.980</td>\n",
       "      <td>809.980</td>\n",
       "      <td>809.980</td>\n",
       "      <td>809.980</td>\n",
       "      <td>809.980</td>\n",
       "      <td>605.030</td>\n",
       "      <td>605.030</td>\n",
       "      <td>...</td>\n",
       "      <td>3571.700</td>\n",
       "      <td>3571.700</td>\n",
       "      <td>502.380</td>\n",
       "      <td>502.380</td>\n",
       "      <td>502.380</td>\n",
       "      <td>502.380</td>\n",
       "      <td>502.380</td>\n",
       "      <td>502.380</td>\n",
       "      <td>502.380</td>\n",
       "      <td>502.380</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>Total_EMI_per_month</th>\n",
       "      <td>49.575</td>\n",
       "      <td>49.575</td>\n",
       "      <td>49.575</td>\n",
       "      <td>49.575</td>\n",
       "      <td>49.575</td>\n",
       "      <td>49.575</td>\n",
       "      <td>49.575</td>\n",
       "      <td>49.575</td>\n",
       "      <td>18.816</td>\n",
       "      <td>18.816</td>\n",
       "      <td>...</td>\n",
       "      <td>60.965</td>\n",
       "      <td>60.965</td>\n",
       "      <td>35.104</td>\n",
       "      <td>35.104</td>\n",
       "      <td>35.104</td>\n",
       "      <td>35.104</td>\n",
       "      <td>35.104</td>\n",
       "      <td>35.104</td>\n",
       "      <td>35.104</td>\n",
       "      <td>35.104</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>21 rows × 99960 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "                                                     0      \\\n",
       "Delay_from_due_date                                  3.000   \n",
       "Num_of_Delayed_Payment                               7.000   \n",
       "Num_Credit_Inquiries                                 4.000   \n",
       "Credit_Utilization_Ratio                            26.823   \n",
       "Credit_History_Age                                 265.000   \n",
       "Payment_of_Min_Amount                                   No   \n",
       "Amount_invested_monthly                             80.415   \n",
       "Monthly_Balance                                    312.494   \n",
       "Credit_Score                                          Good   \n",
       "Credit_Mix                                            Good   \n",
       "Payment_Behaviour         High_spent_Medium_value_payments   \n",
       "Age                                                 23.000   \n",
       "Annual_Income                                    19114.120   \n",
       "Num_Bank_Accounts                                    3.000   \n",
       "Num_Credit_Card                                      4.000   \n",
       "Interest_Rate                                        3.000   \n",
       "Num_of_Loan                                          4.000   \n",
       "Monthly_Inhand_Salary                             1824.843   \n",
       "Changed_Credit_Limit                                11.270   \n",
       "Outstanding_Debt                                   809.980   \n",
       "Total_EMI_per_month                                 49.575   \n",
       "\n",
       "                                                     1      \\\n",
       "Delay_from_due_date                                  3.000   \n",
       "Num_of_Delayed_Payment                               7.000   \n",
       "Num_Credit_Inquiries                                 4.000   \n",
       "Credit_Utilization_Ratio                            31.945   \n",
       "Credit_History_Age                                 265.000   \n",
       "Payment_of_Min_Amount                                   No   \n",
       "Amount_invested_monthly                            118.280   \n",
       "Monthly_Balance                                    284.629   \n",
       "Credit_Score                                          Good   \n",
       "Credit_Mix                                            Good   \n",
       "Payment_Behaviour         High_spent_Medium_value_payments   \n",
       "Age                                                 23.000   \n",
       "Annual_Income                                    19114.120   \n",
       "Num_Bank_Accounts                                    3.000   \n",
       "Num_Credit_Card                                      4.000   \n",
       "Interest_Rate                                        3.000   \n",
       "Num_of_Loan                                          4.000   \n",
       "Monthly_Inhand_Salary                             1824.843   \n",
       "Changed_Credit_Limit                                11.270   \n",
       "Outstanding_Debt                                   809.980   \n",
       "Total_EMI_per_month                                 49.575   \n",
       "\n",
       "                                                     2      \\\n",
       "Delay_from_due_date                                  3.000   \n",
       "Num_of_Delayed_Payment                               7.000   \n",
       "Num_Credit_Inquiries                                 4.000   \n",
       "Credit_Utilization_Ratio                            28.609   \n",
       "Credit_History_Age                                 267.000   \n",
       "Payment_of_Min_Amount                                   No   \n",
       "Amount_invested_monthly                             81.700   \n",
       "Monthly_Balance                                    331.210   \n",
       "Credit_Score                                          Good   \n",
       "Credit_Mix                                            Good   \n",
       "Payment_Behaviour         High_spent_Medium_value_payments   \n",
       "Age                                                 23.000   \n",
       "Annual_Income                                    19114.120   \n",
       "Num_Bank_Accounts                                    3.000   \n",
       "Num_Credit_Card                                      4.000   \n",
       "Interest_Rate                                        3.000   \n",
       "Num_of_Loan                                          4.000   \n",
       "Monthly_Inhand_Salary                             1824.843   \n",
       "Changed_Credit_Limit                                11.270   \n",
       "Outstanding_Debt                                   809.980   \n",
       "Total_EMI_per_month                                 49.575   \n",
       "\n",
       "                                                     3      \\\n",
       "Delay_from_due_date                                  5.000   \n",
       "Num_of_Delayed_Payment                               4.000   \n",
       "Num_Credit_Inquiries                                 4.000   \n",
       "Credit_Utilization_Ratio                            31.378   \n",
       "Credit_History_Age                                 268.000   \n",
       "Payment_of_Min_Amount                                   No   \n",
       "Amount_invested_monthly                            199.458   \n",
       "Monthly_Balance                                    223.451   \n",
       "Credit_Score                                          Good   \n",
       "Credit_Mix                                            Good   \n",
       "Payment_Behaviour         High_spent_Medium_value_payments   \n",
       "Age                                                 23.000   \n",
       "Annual_Income                                    19114.120   \n",
       "Num_Bank_Accounts                                    3.000   \n",
       "Num_Credit_Card                                      4.000   \n",
       "Interest_Rate                                        3.000   \n",
       "Num_of_Loan                                          4.000   \n",
       "Monthly_Inhand_Salary                             1824.843   \n",
       "Changed_Credit_Limit                                11.270   \n",
       "Outstanding_Debt                                   809.980   \n",
       "Total_EMI_per_month                                 49.575   \n",
       "\n",
       "                                                     4      \\\n",
       "Delay_from_due_date                                  6.000   \n",
       "Num_of_Delayed_Payment                               4.000   \n",
       "Num_Credit_Inquiries                                 4.000   \n",
       "Credit_Utilization_Ratio                            24.797   \n",
       "Credit_History_Age                                 269.000   \n",
       "Payment_of_Min_Amount                                   No   \n",
       "Amount_invested_monthly                             41.420   \n",
       "Monthly_Balance                                    341.489   \n",
       "Credit_Score                                          Good   \n",
       "Credit_Mix                                            Good   \n",
       "Payment_Behaviour         High_spent_Medium_value_payments   \n",
       "Age                                                 23.000   \n",
       "Annual_Income                                    19114.120   \n",
       "Num_Bank_Accounts                                    3.000   \n",
       "Num_Credit_Card                                      4.000   \n",
       "Interest_Rate                                        3.000   \n",
       "Num_of_Loan                                          4.000   \n",
       "Monthly_Inhand_Salary                             1824.843   \n",
       "Changed_Credit_Limit                                11.270   \n",
       "Outstanding_Debt                                   809.980   \n",
       "Total_EMI_per_month                                 49.575   \n",
       "\n",
       "                                                     5      \\\n",
       "Delay_from_due_date                                  8.000   \n",
       "Num_of_Delayed_Payment                               4.000   \n",
       "Num_Credit_Inquiries                                 4.000   \n",
       "Credit_Utilization_Ratio                            27.262   \n",
       "Credit_History_Age                                 270.000   \n",
       "Payment_of_Min_Amount                                   No   \n",
       "Amount_invested_monthly                             62.430   \n",
       "Monthly_Balance                                    340.479   \n",
       "Credit_Score                                          Good   \n",
       "Credit_Mix                                            Good   \n",
       "Payment_Behaviour         High_spent_Medium_value_payments   \n",
       "Age                                                 23.000   \n",
       "Annual_Income                                    19114.120   \n",
       "Num_Bank_Accounts                                    3.000   \n",
       "Num_Credit_Card                                      4.000   \n",
       "Interest_Rate                                        3.000   \n",
       "Num_of_Loan                                          4.000   \n",
       "Monthly_Inhand_Salary                             1824.843   \n",
       "Changed_Credit_Limit                                11.270   \n",
       "Outstanding_Debt                                   809.980   \n",
       "Total_EMI_per_month                                 49.575   \n",
       "\n",
       "                                                     6      \\\n",
       "Delay_from_due_date                                  3.000   \n",
       "Num_of_Delayed_Payment                               8.000   \n",
       "Num_Credit_Inquiries                                 4.000   \n",
       "Credit_Utilization_Ratio                            22.538   \n",
       "Credit_History_Age                                 271.000   \n",
       "Payment_of_Min_Amount                                   No   \n",
       "Amount_invested_monthly                            178.344   \n",
       "Monthly_Balance                                    244.565   \n",
       "Credit_Score                                          Good   \n",
       "Credit_Mix                                            Good   \n",
       "Payment_Behaviour         High_spent_Medium_value_payments   \n",
       "Age                                                 23.000   \n",
       "Annual_Income                                    19114.120   \n",
       "Num_Bank_Accounts                                    3.000   \n",
       "Num_Credit_Card                                      4.000   \n",
       "Interest_Rate                                        3.000   \n",
       "Num_of_Loan                                          4.000   \n",
       "Monthly_Inhand_Salary                             1824.843   \n",
       "Changed_Credit_Limit                                11.270   \n",
       "Outstanding_Debt                                   809.980   \n",
       "Total_EMI_per_month                                 49.575   \n",
       "\n",
       "                                                     7      \\\n",
       "Delay_from_due_date                                  3.000   \n",
       "Num_of_Delayed_Payment                               6.000   \n",
       "Num_Credit_Inquiries                                 4.000   \n",
       "Credit_Utilization_Ratio                            23.934   \n",
       "Credit_History_Age                                 271.000   \n",
       "Payment_of_Min_Amount                                   No   \n",
       "Amount_invested_monthly                             24.785   \n",
       "Monthly_Balance                                    358.124   \n",
       "Credit_Score                                      Standard   \n",
       "Credit_Mix                                            Good   \n",
       "Payment_Behaviour         High_spent_Medium_value_payments   \n",
       "Age                                                 23.000   \n",
       "Annual_Income                                    19114.120   \n",
       "Num_Bank_Accounts                                    3.000   \n",
       "Num_Credit_Card                                      4.000   \n",
       "Interest_Rate                                        3.000   \n",
       "Num_of_Loan                                          4.000   \n",
       "Monthly_Inhand_Salary                             1824.843   \n",
       "Changed_Credit_Limit                                11.270   \n",
       "Outstanding_Debt                                   809.980   \n",
       "Total_EMI_per_month                                 49.575   \n",
       "\n",
       "                                                    8      \\\n",
       "Delay_from_due_date                                 3.000   \n",
       "Num_of_Delayed_Payment                              4.000   \n",
       "Num_Credit_Inquiries                                2.000   \n",
       "Credit_Utilization_Ratio                           24.464   \n",
       "Credit_History_Age                                319.000   \n",
       "Payment_of_Min_Amount                                  No   \n",
       "Amount_invested_monthly                           104.292   \n",
       "Monthly_Balance                                   470.691   \n",
       "Credit_Score                                     Standard   \n",
       "Credit_Mix                                           Good   \n",
       "Payment_Behaviour         High_spent_Large_value_payments   \n",
       "Age                                                28.000   \n",
       "Annual_Income                                   34847.840   \n",
       "Num_Bank_Accounts                                   2.000   \n",
       "Num_Credit_Card                                     4.000   \n",
       "Interest_Rate                                       6.000   \n",
       "Num_of_Loan                                         1.000   \n",
       "Monthly_Inhand_Salary                            3037.987   \n",
       "Changed_Credit_Limit                                5.420   \n",
       "Outstanding_Debt                                  605.030   \n",
       "Total_EMI_per_month                                18.816   \n",
       "\n",
       "                                                    9      ...  \\\n",
       "Delay_from_due_date                                 7.000  ...   \n",
       "Num_of_Delayed_Payment                              1.000  ...   \n",
       "Num_Credit_Inquiries                                2.000  ...   \n",
       "Credit_Utilization_Ratio                           38.551  ...   \n",
       "Credit_History_Age                                320.000  ...   \n",
       "Payment_of_Min_Amount                                  No  ...   \n",
       "Amount_invested_monthly                            40.391  ...   \n",
       "Monthly_Balance                                   484.591  ...   \n",
       "Credit_Score                                         Good  ...   \n",
       "Credit_Mix                                           Good  ...   \n",
       "Payment_Behaviour         High_spent_Large_value_payments  ...   \n",
       "Age                                                28.000  ...   \n",
       "Annual_Income                                   34847.840  ...   \n",
       "Num_Bank_Accounts                                   2.000  ...   \n",
       "Num_Credit_Card                                     4.000  ...   \n",
       "Interest_Rate                                       6.000  ...   \n",
       "Num_of_Loan                                         1.000  ...   \n",
       "Monthly_Inhand_Salary                            3037.987  ...   \n",
       "Changed_Credit_Limit                                5.420  ...   \n",
       "Outstanding_Debt                                  605.030  ...   \n",
       "Total_EMI_per_month                                18.816  ...   \n",
       "\n",
       "                                                    99950  \\\n",
       "Delay_from_due_date                                33.000   \n",
       "Num_of_Delayed_Payment                             26.000   \n",
       "Num_Credit_Inquiries                                9.000   \n",
       "Credit_Utilization_Ratio                           25.124   \n",
       "Credit_History_Age                                 73.000   \n",
       "Payment_of_Min_Amount                                 Yes   \n",
       "Amount_invested_monthly                           173.276   \n",
       "Monthly_Balance                                   228.750   \n",
       "Credit_Score                                     Standard   \n",
       "Credit_Mix                                            Bad   \n",
       "Payment_Behaviour         High_spent_Large_value_payments   \n",
       "Age                                                28.000   \n",
       "Annual_Income                                   20002.880   \n",
       "Num_Bank_Accounts                                  10.000   \n",
       "Num_Credit_Card                                     8.000   \n",
       "Interest_Rate                                      29.000   \n",
       "Num_of_Loan                                         5.000   \n",
       "Monthly_Inhand_Salary                            1929.907   \n",
       "Changed_Credit_Limit                               18.310   \n",
       "Outstanding_Debt                                 3571.700   \n",
       "Total_EMI_per_month                                60.965   \n",
       "\n",
       "                                                    99951  \\\n",
       "Delay_from_due_date                                33.000   \n",
       "Num_of_Delayed_Payment                             25.000   \n",
       "Num_Credit_Inquiries                                9.000   \n",
       "Credit_Utilization_Ratio                           37.141   \n",
       "Credit_History_Age                                 75.000   \n",
       "Payment_of_Min_Amount                                 Yes   \n",
       "Amount_invested_monthly                            34.663   \n",
       "Monthly_Balance                                   337.363   \n",
       "Credit_Score                                     Standard   \n",
       "Credit_Mix                                            Bad   \n",
       "Payment_Behaviour         High_spent_Large_value_payments   \n",
       "Age                                                28.000   \n",
       "Annual_Income                                   20002.880   \n",
       "Num_Bank_Accounts                                  10.000   \n",
       "Num_Credit_Card                                     8.000   \n",
       "Interest_Rate                                      29.000   \n",
       "Num_of_Loan                                         5.000   \n",
       "Monthly_Inhand_Salary                            1929.907   \n",
       "Changed_Credit_Limit                               18.310   \n",
       "Outstanding_Debt                                 3571.700   \n",
       "Total_EMI_per_month                                60.965   \n",
       "\n",
       "                                                     99952  \\\n",
       "Delay_from_due_date                                 23.000   \n",
       "Num_of_Delayed_Payment                               6.000   \n",
       "Num_Credit_Inquiries                                 3.000   \n",
       "Credit_Utilization_Ratio                            32.991   \n",
       "Credit_History_Age                                 375.000   \n",
       "Payment_of_Min_Amount                                   No   \n",
       "Amount_invested_monthly                            401.196   \n",
       "Monthly_Balance                                    189.641   \n",
       "Credit_Score                                          Poor   \n",
       "Credit_Mix                                            Good   \n",
       "Payment_Behaviour         High_spent_Medium_value_payments   \n",
       "Age                                                 25.000   \n",
       "Annual_Income                                    39628.990   \n",
       "Num_Bank_Accounts                                    4.000   \n",
       "Num_Credit_Card                                      6.000   \n",
       "Interest_Rate                                        7.000   \n",
       "Num_of_Loan                                          2.000   \n",
       "Monthly_Inhand_Salary                             3359.416   \n",
       "Changed_Credit_Limit                                11.500   \n",
       "Outstanding_Debt                                   502.380   \n",
       "Total_EMI_per_month                                 35.104   \n",
       "\n",
       "                                                     99953  \\\n",
       "Delay_from_due_date                                 23.000   \n",
       "Num_of_Delayed_Payment                               6.000   \n",
       "Num_Credit_Inquiries                                 3.000   \n",
       "Credit_Utilization_Ratio                            29.135   \n",
       "Credit_History_Age                                 376.000   \n",
       "Payment_of_Min_Amount                                   No   \n",
       "Amount_invested_monthly                            180.733   \n",
       "Monthly_Balance                                    400.104   \n",
       "Credit_Score                                      Standard   \n",
       "Credit_Mix                                            Good   \n",
       "Payment_Behaviour         High_spent_Medium_value_payments   \n",
       "Age                                                 25.000   \n",
       "Annual_Income                                    39628.990   \n",
       "Num_Bank_Accounts                                    4.000   \n",
       "Num_Credit_Card                                      6.000   \n",
       "Interest_Rate                                        7.000   \n",
       "Num_of_Loan                                          2.000   \n",
       "Monthly_Inhand_Salary                             3359.416   \n",
       "Changed_Credit_Limit                                11.500   \n",
       "Outstanding_Debt                                   502.380   \n",
       "Total_EMI_per_month                                 35.104   \n",
       "\n",
       "                                                     99954  \\\n",
       "Delay_from_due_date                                 20.000   \n",
       "Num_of_Delayed_Payment                               6.000   \n",
       "Num_Credit_Inquiries                                 3.000   \n",
       "Credit_Utilization_Ratio                            39.324   \n",
       "Credit_History_Age                                 377.000   \n",
       "Payment_of_Min_Amount                                   No   \n",
       "Amount_invested_monthly                            140.581   \n",
       "Monthly_Balance                                    410.256   \n",
       "Credit_Score                                          Poor   \n",
       "Credit_Mix                                            Good   \n",
       "Payment_Behaviour         High_spent_Medium_value_payments   \n",
       "Age                                                 25.000   \n",
       "Annual_Income                                    39628.990   \n",
       "Num_Bank_Accounts                                    4.000   \n",
       "Num_Credit_Card                                      6.000   \n",
       "Interest_Rate                                        7.000   \n",
       "Num_of_Loan                                          2.000   \n",
       "Monthly_Inhand_Salary                             3359.416   \n",
       "Changed_Credit_Limit                                11.500   \n",
       "Outstanding_Debt                                   502.380   \n",
       "Total_EMI_per_month                                 35.104   \n",
       "\n",
       "                                                     99955  \\\n",
       "Delay_from_due_date                                 23.000   \n",
       "Num_of_Delayed_Payment                               7.000   \n",
       "Num_Credit_Inquiries                                 3.000   \n",
       "Credit_Utilization_Ratio                            34.664   \n",
       "Credit_History_Age                                 378.000   \n",
       "Payment_of_Min_Amount                                   No   \n",
       "Amount_invested_monthly                             60.971   \n",
       "Monthly_Balance                                    479.866   \n",
       "Credit_Score                                          Poor   \n",
       "Credit_Mix                                            Good   \n",
       "Payment_Behaviour         High_spent_Medium_value_payments   \n",
       "Age                                                 25.000   \n",
       "Annual_Income                                    39628.990   \n",
       "Num_Bank_Accounts                                    4.000   \n",
       "Num_Credit_Card                                      6.000   \n",
       "Interest_Rate                                        7.000   \n",
       "Num_of_Loan                                          2.000   \n",
       "Monthly_Inhand_Salary                             3359.416   \n",
       "Changed_Credit_Limit                                11.500   \n",
       "Outstanding_Debt                                   502.380   \n",
       "Total_EMI_per_month                                 35.104   \n",
       "\n",
       "                                                     99956  \\\n",
       "Delay_from_due_date                                 18.000   \n",
       "Num_of_Delayed_Payment                               7.000   \n",
       "Num_Credit_Inquiries                                 3.000   \n",
       "Credit_Utilization_Ratio                            40.566   \n",
       "Credit_History_Age                                 379.000   \n",
       "Payment_of_Min_Amount                                   No   \n",
       "Amount_invested_monthly                             54.186   \n",
       "Monthly_Balance                                    496.652   \n",
       "Credit_Score                                          Poor   \n",
       "Credit_Mix                                            Good   \n",
       "Payment_Behaviour         High_spent_Medium_value_payments   \n",
       "Age                                                 25.000   \n",
       "Annual_Income                                    39628.990   \n",
       "Num_Bank_Accounts                                    4.000   \n",
       "Num_Credit_Card                                      6.000   \n",
       "Interest_Rate                                        7.000   \n",
       "Num_of_Loan                                          2.000   \n",
       "Monthly_Inhand_Salary                             3359.416   \n",
       "Changed_Credit_Limit                                11.500   \n",
       "Outstanding_Debt                                   502.380   \n",
       "Total_EMI_per_month                                 35.104   \n",
       "\n",
       "                                                     99957  \\\n",
       "Delay_from_due_date                                 27.000   \n",
       "Num_of_Delayed_Payment                               6.000   \n",
       "Num_Credit_Inquiries                                 3.000   \n",
       "Credit_Utilization_Ratio                            41.256   \n",
       "Credit_History_Age                                 380.000   \n",
       "Payment_of_Min_Amount                                   No   \n",
       "Amount_invested_monthly                             24.028   \n",
       "Monthly_Balance                                    516.809   \n",
       "Credit_Score                                          Poor   \n",
       "Credit_Mix                                            Good   \n",
       "Payment_Behaviour         High_spent_Medium_value_payments   \n",
       "Age                                                 25.000   \n",
       "Annual_Income                                    39628.990   \n",
       "Num_Bank_Accounts                                    4.000   \n",
       "Num_Credit_Card                                      6.000   \n",
       "Interest_Rate                                        7.000   \n",
       "Num_of_Loan                                          2.000   \n",
       "Monthly_Inhand_Salary                             3359.416   \n",
       "Changed_Credit_Limit                                11.500   \n",
       "Outstanding_Debt                                   502.380   \n",
       "Total_EMI_per_month                                 35.104   \n",
       "\n",
       "                                                     99958  \\\n",
       "Delay_from_due_date                                 20.000   \n",
       "Num_of_Delayed_Payment                               6.000   \n",
       "Num_Credit_Inquiries                                 3.000   \n",
       "Credit_Utilization_Ratio                            33.638   \n",
       "Credit_History_Age                                 381.000   \n",
       "Payment_of_Min_Amount                                   No   \n",
       "Amount_invested_monthly                            251.673   \n",
       "Monthly_Balance                                    319.165   \n",
       "Credit_Score                                      Standard   \n",
       "Credit_Mix                                            Good   \n",
       "Payment_Behaviour         High_spent_Medium_value_payments   \n",
       "Age                                                 25.000   \n",
       "Annual_Income                                    39628.990   \n",
       "Num_Bank_Accounts                                    4.000   \n",
       "Num_Credit_Card                                      6.000   \n",
       "Interest_Rate                                        7.000   \n",
       "Num_of_Loan                                          2.000   \n",
       "Monthly_Inhand_Salary                             3359.416   \n",
       "Changed_Credit_Limit                                11.500   \n",
       "Outstanding_Debt                                   502.380   \n",
       "Total_EMI_per_month                                 35.104   \n",
       "\n",
       "                                                     99959  \n",
       "Delay_from_due_date                                 18.000  \n",
       "Num_of_Delayed_Payment                               6.000  \n",
       "Num_Credit_Inquiries                                 3.000  \n",
       "Credit_Utilization_Ratio                            34.192  \n",
       "Credit_History_Age                                 382.000  \n",
       "Payment_of_Min_Amount                                   No  \n",
       "Amount_invested_monthly                            167.164  \n",
       "Monthly_Balance                                    393.674  \n",
       "Credit_Score                                          Poor  \n",
       "Credit_Mix                                            Good  \n",
       "Payment_Behaviour         High_spent_Medium_value_payments  \n",
       "Age                                                 25.000  \n",
       "Annual_Income                                    39628.990  \n",
       "Num_Bank_Accounts                                    4.000  \n",
       "Num_Credit_Card                                      6.000  \n",
       "Interest_Rate                                        7.000  \n",
       "Num_of_Loan                                          2.000  \n",
       "Monthly_Inhand_Salary                             3359.416  \n",
       "Changed_Credit_Limit                                11.500  \n",
       "Outstanding_Debt                                   502.380  \n",
       "Total_EMI_per_month                                 35.104  \n",
       "\n",
       "[21 rows x 99960 columns]"
      ]
     },
     "execution_count": 94,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df1 = pd.read_csv(\"Score.csv\")\n",
    "df1.T"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {
    "id": "1_6TmzLWZE0B",
    "scrolled": true
   },
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>0</th>\n",
       "      <th>1</th>\n",
       "      <th>2</th>\n",
       "      <th>3</th>\n",
       "      <th>4</th>\n",
       "      <th>5</th>\n",
       "      <th>6</th>\n",
       "      <th>7</th>\n",
       "      <th>8</th>\n",
       "      <th>9</th>\n",
       "      <th>...</th>\n",
       "      <th>99950</th>\n",
       "      <th>99951</th>\n",
       "      <th>99952</th>\n",
       "      <th>99953</th>\n",
       "      <th>99954</th>\n",
       "      <th>99955</th>\n",
       "      <th>99956</th>\n",
       "      <th>99957</th>\n",
       "      <th>99958</th>\n",
       "      <th>99959</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>Delay_from_due_date</th>\n",
       "      <td>3.000</td>\n",
       "      <td>3.000</td>\n",
       "      <td>3.000</td>\n",
       "      <td>5.000</td>\n",
       "      <td>6.000</td>\n",
       "      <td>8.000</td>\n",
       "      <td>3.000</td>\n",
       "      <td>3.000</td>\n",
       "      <td>3.000</td>\n",
       "      <td>7.000</td>\n",
       "      <td>...</td>\n",
       "      <td>33.000</td>\n",
       "      <td>33.000</td>\n",
       "      <td>23.000</td>\n",
       "      <td>23.000</td>\n",
       "      <td>20.000</td>\n",
       "      <td>23.000</td>\n",
       "      <td>18.000</td>\n",
       "      <td>27.000</td>\n",
       "      <td>20.000</td>\n",
       "      <td>18.000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>Num_of_Delayed_Payment</th>\n",
       "      <td>7.000</td>\n",
       "      <td>7.000</td>\n",
       "      <td>7.000</td>\n",
       "      <td>4.000</td>\n",
       "      <td>4.000</td>\n",
       "      <td>4.000</td>\n",
       "      <td>8.000</td>\n",
       "      <td>6.000</td>\n",
       "      <td>4.000</td>\n",
       "      <td>1.000</td>\n",
       "      <td>...</td>\n",
       "      <td>26.000</td>\n",
       "      <td>25.000</td>\n",
       "      <td>6.000</td>\n",
       "      <td>6.000</td>\n",
       "      <td>6.000</td>\n",
       "      <td>7.000</td>\n",
       "      <td>7.000</td>\n",
       "      <td>6.000</td>\n",
       "      <td>6.000</td>\n",
       "      <td>6.000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>Num_Credit_Inquiries</th>\n",
       "      <td>4.000</td>\n",
       "      <td>4.000</td>\n",
       "      <td>4.000</td>\n",
       "      <td>4.000</td>\n",
       "      <td>4.000</td>\n",
       "      <td>4.000</td>\n",
       "      <td>4.000</td>\n",
       "      <td>4.000</td>\n",
       "      <td>2.000</td>\n",
       "      <td>2.000</td>\n",
       "      <td>...</td>\n",
       "      <td>9.000</td>\n",
       "      <td>9.000</td>\n",
       "      <td>3.000</td>\n",
       "      <td>3.000</td>\n",
       "      <td>3.000</td>\n",
       "      <td>3.000</td>\n",
       "      <td>3.000</td>\n",
       "      <td>3.000</td>\n",
       "      <td>3.000</td>\n",
       "      <td>3.000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>Credit_Utilization_Ratio</th>\n",
       "      <td>26.823</td>\n",
       "      <td>31.945</td>\n",
       "      <td>28.609</td>\n",
       "      <td>31.378</td>\n",
       "      <td>24.797</td>\n",
       "      <td>27.262</td>\n",
       "      <td>22.538</td>\n",
       "      <td>23.934</td>\n",
       "      <td>24.464</td>\n",
       "      <td>38.551</td>\n",
       "      <td>...</td>\n",
       "      <td>25.124</td>\n",
       "      <td>37.141</td>\n",
       "      <td>32.991</td>\n",
       "      <td>29.135</td>\n",
       "      <td>39.324</td>\n",
       "      <td>34.664</td>\n",
       "      <td>40.566</td>\n",
       "      <td>41.256</td>\n",
       "      <td>33.638</td>\n",
       "      <td>34.192</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>Credit_History_Age</th>\n",
       "      <td>265.000</td>\n",
       "      <td>265.000</td>\n",
       "      <td>267.000</td>\n",
       "      <td>268.000</td>\n",
       "      <td>269.000</td>\n",
       "      <td>270.000</td>\n",
       "      <td>271.000</td>\n",
       "      <td>271.000</td>\n",
       "      <td>319.000</td>\n",
       "      <td>320.000</td>\n",
       "      <td>...</td>\n",
       "      <td>73.000</td>\n",
       "      <td>75.000</td>\n",
       "      <td>375.000</td>\n",
       "      <td>376.000</td>\n",
       "      <td>377.000</td>\n",
       "      <td>378.000</td>\n",
       "      <td>379.000</td>\n",
       "      <td>380.000</td>\n",
       "      <td>381.000</td>\n",
       "      <td>382.000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>Payment_of_Min_Amount</th>\n",
       "      <td>No</td>\n",
       "      <td>No</td>\n",
       "      <td>No</td>\n",
       "      <td>No</td>\n",
       "      <td>No</td>\n",
       "      <td>No</td>\n",
       "      <td>No</td>\n",
       "      <td>No</td>\n",
       "      <td>No</td>\n",
       "      <td>No</td>\n",
       "      <td>...</td>\n",
       "      <td>Yes</td>\n",
       "      <td>Yes</td>\n",
       "      <td>No</td>\n",
       "      <td>No</td>\n",
       "      <td>No</td>\n",
       "      <td>No</td>\n",
       "      <td>No</td>\n",
       "      <td>No</td>\n",
       "      <td>No</td>\n",
       "      <td>No</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>Amount_invested_monthly</th>\n",
       "      <td>80.415</td>\n",
       "      <td>118.280</td>\n",
       "      <td>81.700</td>\n",
       "      <td>199.458</td>\n",
       "      <td>41.420</td>\n",
       "      <td>62.430</td>\n",
       "      <td>178.344</td>\n",
       "      <td>24.785</td>\n",
       "      <td>104.292</td>\n",
       "      <td>40.391</td>\n",
       "      <td>...</td>\n",
       "      <td>173.276</td>\n",
       "      <td>34.663</td>\n",
       "      <td>401.196</td>\n",
       "      <td>180.733</td>\n",
       "      <td>140.581</td>\n",
       "      <td>60.971</td>\n",
       "      <td>54.186</td>\n",
       "      <td>24.028</td>\n",
       "      <td>251.673</td>\n",
       "      <td>167.164</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>Monthly_Balance</th>\n",
       "      <td>312.494</td>\n",
       "      <td>284.629</td>\n",
       "      <td>331.210</td>\n",
       "      <td>223.451</td>\n",
       "      <td>341.489</td>\n",
       "      <td>340.479</td>\n",
       "      <td>244.565</td>\n",
       "      <td>358.124</td>\n",
       "      <td>470.691</td>\n",
       "      <td>484.591</td>\n",
       "      <td>...</td>\n",
       "      <td>228.750</td>\n",
       "      <td>337.363</td>\n",
       "      <td>189.641</td>\n",
       "      <td>400.104</td>\n",
       "      <td>410.256</td>\n",
       "      <td>479.866</td>\n",
       "      <td>496.652</td>\n",
       "      <td>516.809</td>\n",
       "      <td>319.165</td>\n",
       "      <td>393.674</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>Credit_Score</th>\n",
       "      <td>Good</td>\n",
       "      <td>Good</td>\n",
       "      <td>Good</td>\n",
       "      <td>Good</td>\n",
       "      <td>Good</td>\n",
       "      <td>Good</td>\n",
       "      <td>Good</td>\n",
       "      <td>Standard</td>\n",
       "      <td>Standard</td>\n",
       "      <td>Good</td>\n",
       "      <td>...</td>\n",
       "      <td>Standard</td>\n",
       "      <td>Standard</td>\n",
       "      <td>Poor</td>\n",
       "      <td>Standard</td>\n",
       "      <td>Poor</td>\n",
       "      <td>Poor</td>\n",
       "      <td>Poor</td>\n",
       "      <td>Poor</td>\n",
       "      <td>Standard</td>\n",
       "      <td>Poor</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>Credit_Mix</th>\n",
       "      <td>Good</td>\n",
       "      <td>Good</td>\n",
       "      <td>Good</td>\n",
       "      <td>Good</td>\n",
       "      <td>Good</td>\n",
       "      <td>Good</td>\n",
       "      <td>Good</td>\n",
       "      <td>Good</td>\n",
       "      <td>Good</td>\n",
       "      <td>Good</td>\n",
       "      <td>...</td>\n",
       "      <td>Bad</td>\n",
       "      <td>Bad</td>\n",
       "      <td>Good</td>\n",
       "      <td>Good</td>\n",
       "      <td>Good</td>\n",
       "      <td>Good</td>\n",
       "      <td>Good</td>\n",
       "      <td>Good</td>\n",
       "      <td>Good</td>\n",
       "      <td>Good</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>Payment_Behaviour</th>\n",
       "      <td>High_spent_Medium_value_payments</td>\n",
       "      <td>High_spent_Medium_value_payments</td>\n",
       "      <td>High_spent_Medium_value_payments</td>\n",
       "      <td>High_spent_Medium_value_payments</td>\n",
       "      <td>High_spent_Medium_value_payments</td>\n",
       "      <td>High_spent_Medium_value_payments</td>\n",
       "      <td>High_spent_Medium_value_payments</td>\n",
       "      <td>High_spent_Medium_value_payments</td>\n",
       "      <td>High_spent_Large_value_payments</td>\n",
       "      <td>High_spent_Large_value_payments</td>\n",
       "      <td>...</td>\n",
       "      <td>High_spent_Large_value_payments</td>\n",
       "      <td>High_spent_Large_value_payments</td>\n",
       "      <td>High_spent_Medium_value_payments</td>\n",
       "      <td>High_spent_Medium_value_payments</td>\n",
       "      <td>High_spent_Medium_value_payments</td>\n",
       "      <td>High_spent_Medium_value_payments</td>\n",
       "      <td>High_spent_Medium_value_payments</td>\n",
       "      <td>High_spent_Medium_value_payments</td>\n",
       "      <td>High_spent_Medium_value_payments</td>\n",
       "      <td>High_spent_Medium_value_payments</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>Age</th>\n",
       "      <td>23.000</td>\n",
       "      <td>23.000</td>\n",
       "      <td>23.000</td>\n",
       "      <td>23.000</td>\n",
       "      <td>23.000</td>\n",
       "      <td>23.000</td>\n",
       "      <td>23.000</td>\n",
       "      <td>23.000</td>\n",
       "      <td>28.000</td>\n",
       "      <td>28.000</td>\n",
       "      <td>...</td>\n",
       "      <td>28.000</td>\n",
       "      <td>28.000</td>\n",
       "      <td>25.000</td>\n",
       "      <td>25.000</td>\n",
       "      <td>25.000</td>\n",
       "      <td>25.000</td>\n",
       "      <td>25.000</td>\n",
       "      <td>25.000</td>\n",
       "      <td>25.000</td>\n",
       "      <td>25.000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>Annual_Income</th>\n",
       "      <td>19114.120</td>\n",
       "      <td>19114.120</td>\n",
       "      <td>19114.120</td>\n",
       "      <td>19114.120</td>\n",
       "      <td>19114.120</td>\n",
       "      <td>19114.120</td>\n",
       "      <td>19114.120</td>\n",
       "      <td>19114.120</td>\n",
       "      <td>34847.840</td>\n",
       "      <td>34847.840</td>\n",
       "      <td>...</td>\n",
       "      <td>20002.880</td>\n",
       "      <td>20002.880</td>\n",
       "      <td>39628.990</td>\n",
       "      <td>39628.990</td>\n",
       "      <td>39628.990</td>\n",
       "      <td>39628.990</td>\n",
       "      <td>39628.990</td>\n",
       "      <td>39628.990</td>\n",
       "      <td>39628.990</td>\n",
       "      <td>39628.990</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>Num_Bank_Accounts</th>\n",
       "      <td>3.000</td>\n",
       "      <td>3.000</td>\n",
       "      <td>3.000</td>\n",
       "      <td>3.000</td>\n",
       "      <td>3.000</td>\n",
       "      <td>3.000</td>\n",
       "      <td>3.000</td>\n",
       "      <td>3.000</td>\n",
       "      <td>2.000</td>\n",
       "      <td>2.000</td>\n",
       "      <td>...</td>\n",
       "      <td>10.000</td>\n",
       "      <td>10.000</td>\n",
       "      <td>4.000</td>\n",
       "      <td>4.000</td>\n",
       "      <td>4.000</td>\n",
       "      <td>4.000</td>\n",
       "      <td>4.000</td>\n",
       "      <td>4.000</td>\n",
       "      <td>4.000</td>\n",
       "      <td>4.000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>Num_Credit_Card</th>\n",
       "      <td>4.000</td>\n",
       "      <td>4.000</td>\n",
       "      <td>4.000</td>\n",
       "      <td>4.000</td>\n",
       "      <td>4.000</td>\n",
       "      <td>4.000</td>\n",
       "      <td>4.000</td>\n",
       "      <td>4.000</td>\n",
       "      <td>4.000</td>\n",
       "      <td>4.000</td>\n",
       "      <td>...</td>\n",
       "      <td>8.000</td>\n",
       "      <td>8.000</td>\n",
       "      <td>6.000</td>\n",
       "      <td>6.000</td>\n",
       "      <td>6.000</td>\n",
       "      <td>6.000</td>\n",
       "      <td>6.000</td>\n",
       "      <td>6.000</td>\n",
       "      <td>6.000</td>\n",
       "      <td>6.000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>Interest_Rate</th>\n",
       "      <td>3.000</td>\n",
       "      <td>3.000</td>\n",
       "      <td>3.000</td>\n",
       "      <td>3.000</td>\n",
       "      <td>3.000</td>\n",
       "      <td>3.000</td>\n",
       "      <td>3.000</td>\n",
       "      <td>3.000</td>\n",
       "      <td>6.000</td>\n",
       "      <td>6.000</td>\n",
       "      <td>...</td>\n",
       "      <td>29.000</td>\n",
       "      <td>29.000</td>\n",
       "      <td>7.000</td>\n",
       "      <td>7.000</td>\n",
       "      <td>7.000</td>\n",
       "      <td>7.000</td>\n",
       "      <td>7.000</td>\n",
       "      <td>7.000</td>\n",
       "      <td>7.000</td>\n",
       "      <td>7.000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>Num_of_Loan</th>\n",
       "      <td>4.000</td>\n",
       "      <td>4.000</td>\n",
       "      <td>4.000</td>\n",
       "      <td>4.000</td>\n",
       "      <td>4.000</td>\n",
       "      <td>4.000</td>\n",
       "      <td>4.000</td>\n",
       "      <td>4.000</td>\n",
       "      <td>1.000</td>\n",
       "      <td>1.000</td>\n",
       "      <td>...</td>\n",
       "      <td>5.000</td>\n",
       "      <td>5.000</td>\n",
       "      <td>2.000</td>\n",
       "      <td>2.000</td>\n",
       "      <td>2.000</td>\n",
       "      <td>2.000</td>\n",
       "      <td>2.000</td>\n",
       "      <td>2.000</td>\n",
       "      <td>2.000</td>\n",
       "      <td>2.000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>Monthly_Inhand_Salary</th>\n",
       "      <td>1824.843</td>\n",
       "      <td>1824.843</td>\n",
       "      <td>1824.843</td>\n",
       "      <td>1824.843</td>\n",
       "      <td>1824.843</td>\n",
       "      <td>1824.843</td>\n",
       "      <td>1824.843</td>\n",
       "      <td>1824.843</td>\n",
       "      <td>3037.987</td>\n",
       "      <td>3037.987</td>\n",
       "      <td>...</td>\n",
       "      <td>1929.907</td>\n",
       "      <td>1929.907</td>\n",
       "      <td>3359.416</td>\n",
       "      <td>3359.416</td>\n",
       "      <td>3359.416</td>\n",
       "      <td>3359.416</td>\n",
       "      <td>3359.416</td>\n",
       "      <td>3359.416</td>\n",
       "      <td>3359.416</td>\n",
       "      <td>3359.416</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>Changed_Credit_Limit</th>\n",
       "      <td>11.270</td>\n",
       "      <td>11.270</td>\n",
       "      <td>11.270</td>\n",
       "      <td>11.270</td>\n",
       "      <td>11.270</td>\n",
       "      <td>11.270</td>\n",
       "      <td>11.270</td>\n",
       "      <td>11.270</td>\n",
       "      <td>5.420</td>\n",
       "      <td>5.420</td>\n",
       "      <td>...</td>\n",
       "      <td>18.310</td>\n",
       "      <td>18.310</td>\n",
       "      <td>11.500</td>\n",
       "      <td>11.500</td>\n",
       "      <td>11.500</td>\n",
       "      <td>11.500</td>\n",
       "      <td>11.500</td>\n",
       "      <td>11.500</td>\n",
       "      <td>11.500</td>\n",
       "      <td>11.500</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>Outstanding_Debt</th>\n",
       "      <td>809.980</td>\n",
       "      <td>809.980</td>\n",
       "      <td>809.980</td>\n",
       "      <td>809.980</td>\n",
       "      <td>809.980</td>\n",
       "      <td>809.980</td>\n",
       "      <td>809.980</td>\n",
       "      <td>809.980</td>\n",
       "      <td>605.030</td>\n",
       "      <td>605.030</td>\n",
       "      <td>...</td>\n",
       "      <td>3571.700</td>\n",
       "      <td>3571.700</td>\n",
       "      <td>502.380</td>\n",
       "      <td>502.380</td>\n",
       "      <td>502.380</td>\n",
       "      <td>502.380</td>\n",
       "      <td>502.380</td>\n",
       "      <td>502.380</td>\n",
       "      <td>502.380</td>\n",
       "      <td>502.380</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>Total_EMI_per_month</th>\n",
       "      <td>49.575</td>\n",
       "      <td>49.575</td>\n",
       "      <td>49.575</td>\n",
       "      <td>49.575</td>\n",
       "      <td>49.575</td>\n",
       "      <td>49.575</td>\n",
       "      <td>49.575</td>\n",
       "      <td>49.575</td>\n",
       "      <td>18.816</td>\n",
       "      <td>18.816</td>\n",
       "      <td>...</td>\n",
       "      <td>60.965</td>\n",
       "      <td>60.965</td>\n",
       "      <td>35.104</td>\n",
       "      <td>35.104</td>\n",
       "      <td>35.104</td>\n",
       "      <td>35.104</td>\n",
       "      <td>35.104</td>\n",
       "      <td>35.104</td>\n",
       "      <td>35.104</td>\n",
       "      <td>35.104</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>21 rows × 99960 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "                                                     0      \\\n",
       "Delay_from_due_date                                  3.000   \n",
       "Num_of_Delayed_Payment                               7.000   \n",
       "Num_Credit_Inquiries                                 4.000   \n",
       "Credit_Utilization_Ratio                            26.823   \n",
       "Credit_History_Age                                 265.000   \n",
       "Payment_of_Min_Amount                                   No   \n",
       "Amount_invested_monthly                             80.415   \n",
       "Monthly_Balance                                    312.494   \n",
       "Credit_Score                                          Good   \n",
       "Credit_Mix                                            Good   \n",
       "Payment_Behaviour         High_spent_Medium_value_payments   \n",
       "Age                                                 23.000   \n",
       "Annual_Income                                    19114.120   \n",
       "Num_Bank_Accounts                                    3.000   \n",
       "Num_Credit_Card                                      4.000   \n",
       "Interest_Rate                                        3.000   \n",
       "Num_of_Loan                                          4.000   \n",
       "Monthly_Inhand_Salary                             1824.843   \n",
       "Changed_Credit_Limit                                11.270   \n",
       "Outstanding_Debt                                   809.980   \n",
       "Total_EMI_per_month                                 49.575   \n",
       "\n",
       "                                                     1      \\\n",
       "Delay_from_due_date                                  3.000   \n",
       "Num_of_Delayed_Payment                               7.000   \n",
       "Num_Credit_Inquiries                                 4.000   \n",
       "Credit_Utilization_Ratio                            31.945   \n",
       "Credit_History_Age                                 265.000   \n",
       "Payment_of_Min_Amount                                   No   \n",
       "Amount_invested_monthly                            118.280   \n",
       "Monthly_Balance                                    284.629   \n",
       "Credit_Score                                          Good   \n",
       "Credit_Mix                                            Good   \n",
       "Payment_Behaviour         High_spent_Medium_value_payments   \n",
       "Age                                                 23.000   \n",
       "Annual_Income                                    19114.120   \n",
       "Num_Bank_Accounts                                    3.000   \n",
       "Num_Credit_Card                                      4.000   \n",
       "Interest_Rate                                        3.000   \n",
       "Num_of_Loan                                          4.000   \n",
       "Monthly_Inhand_Salary                             1824.843   \n",
       "Changed_Credit_Limit                                11.270   \n",
       "Outstanding_Debt                                   809.980   \n",
       "Total_EMI_per_month                                 49.575   \n",
       "\n",
       "                                                     2      \\\n",
       "Delay_from_due_date                                  3.000   \n",
       "Num_of_Delayed_Payment                               7.000   \n",
       "Num_Credit_Inquiries                                 4.000   \n",
       "Credit_Utilization_Ratio                            28.609   \n",
       "Credit_History_Age                                 267.000   \n",
       "Payment_of_Min_Amount                                   No   \n",
       "Amount_invested_monthly                             81.700   \n",
       "Monthly_Balance                                    331.210   \n",
       "Credit_Score                                          Good   \n",
       "Credit_Mix                                            Good   \n",
       "Payment_Behaviour         High_spent_Medium_value_payments   \n",
       "Age                                                 23.000   \n",
       "Annual_Income                                    19114.120   \n",
       "Num_Bank_Accounts                                    3.000   \n",
       "Num_Credit_Card                                      4.000   \n",
       "Interest_Rate                                        3.000   \n",
       "Num_of_Loan                                          4.000   \n",
       "Monthly_Inhand_Salary                             1824.843   \n",
       "Changed_Credit_Limit                                11.270   \n",
       "Outstanding_Debt                                   809.980   \n",
       "Total_EMI_per_month                                 49.575   \n",
       "\n",
       "                                                     3      \\\n",
       "Delay_from_due_date                                  5.000   \n",
       "Num_of_Delayed_Payment                               4.000   \n",
       "Num_Credit_Inquiries                                 4.000   \n",
       "Credit_Utilization_Ratio                            31.378   \n",
       "Credit_History_Age                                 268.000   \n",
       "Payment_of_Min_Amount                                   No   \n",
       "Amount_invested_monthly                            199.458   \n",
       "Monthly_Balance                                    223.451   \n",
       "Credit_Score                                          Good   \n",
       "Credit_Mix                                            Good   \n",
       "Payment_Behaviour         High_spent_Medium_value_payments   \n",
       "Age                                                 23.000   \n",
       "Annual_Income                                    19114.120   \n",
       "Num_Bank_Accounts                                    3.000   \n",
       "Num_Credit_Card                                      4.000   \n",
       "Interest_Rate                                        3.000   \n",
       "Num_of_Loan                                          4.000   \n",
       "Monthly_Inhand_Salary                             1824.843   \n",
       "Changed_Credit_Limit                                11.270   \n",
       "Outstanding_Debt                                   809.980   \n",
       "Total_EMI_per_month                                 49.575   \n",
       "\n",
       "                                                     4      \\\n",
       "Delay_from_due_date                                  6.000   \n",
       "Num_of_Delayed_Payment                               4.000   \n",
       "Num_Credit_Inquiries                                 4.000   \n",
       "Credit_Utilization_Ratio                            24.797   \n",
       "Credit_History_Age                                 269.000   \n",
       "Payment_of_Min_Amount                                   No   \n",
       "Amount_invested_monthly                             41.420   \n",
       "Monthly_Balance                                    341.489   \n",
       "Credit_Score                                          Good   \n",
       "Credit_Mix                                            Good   \n",
       "Payment_Behaviour         High_spent_Medium_value_payments   \n",
       "Age                                                 23.000   \n",
       "Annual_Income                                    19114.120   \n",
       "Num_Bank_Accounts                                    3.000   \n",
       "Num_Credit_Card                                      4.000   \n",
       "Interest_Rate                                        3.000   \n",
       "Num_of_Loan                                          4.000   \n",
       "Monthly_Inhand_Salary                             1824.843   \n",
       "Changed_Credit_Limit                                11.270   \n",
       "Outstanding_Debt                                   809.980   \n",
       "Total_EMI_per_month                                 49.575   \n",
       "\n",
       "                                                     5      \\\n",
       "Delay_from_due_date                                  8.000   \n",
       "Num_of_Delayed_Payment                               4.000   \n",
       "Num_Credit_Inquiries                                 4.000   \n",
       "Credit_Utilization_Ratio                            27.262   \n",
       "Credit_History_Age                                 270.000   \n",
       "Payment_of_Min_Amount                                   No   \n",
       "Amount_invested_monthly                             62.430   \n",
       "Monthly_Balance                                    340.479   \n",
       "Credit_Score                                          Good   \n",
       "Credit_Mix                                            Good   \n",
       "Payment_Behaviour         High_spent_Medium_value_payments   \n",
       "Age                                                 23.000   \n",
       "Annual_Income                                    19114.120   \n",
       "Num_Bank_Accounts                                    3.000   \n",
       "Num_Credit_Card                                      4.000   \n",
       "Interest_Rate                                        3.000   \n",
       "Num_of_Loan                                          4.000   \n",
       "Monthly_Inhand_Salary                             1824.843   \n",
       "Changed_Credit_Limit                                11.270   \n",
       "Outstanding_Debt                                   809.980   \n",
       "Total_EMI_per_month                                 49.575   \n",
       "\n",
       "                                                     6      \\\n",
       "Delay_from_due_date                                  3.000   \n",
       "Num_of_Delayed_Payment                               8.000   \n",
       "Num_Credit_Inquiries                                 4.000   \n",
       "Credit_Utilization_Ratio                            22.538   \n",
       "Credit_History_Age                                 271.000   \n",
       "Payment_of_Min_Amount                                   No   \n",
       "Amount_invested_monthly                            178.344   \n",
       "Monthly_Balance                                    244.565   \n",
       "Credit_Score                                          Good   \n",
       "Credit_Mix                                            Good   \n",
       "Payment_Behaviour         High_spent_Medium_value_payments   \n",
       "Age                                                 23.000   \n",
       "Annual_Income                                    19114.120   \n",
       "Num_Bank_Accounts                                    3.000   \n",
       "Num_Credit_Card                                      4.000   \n",
       "Interest_Rate                                        3.000   \n",
       "Num_of_Loan                                          4.000   \n",
       "Monthly_Inhand_Salary                             1824.843   \n",
       "Changed_Credit_Limit                                11.270   \n",
       "Outstanding_Debt                                   809.980   \n",
       "Total_EMI_per_month                                 49.575   \n",
       "\n",
       "                                                     7      \\\n",
       "Delay_from_due_date                                  3.000   \n",
       "Num_of_Delayed_Payment                               6.000   \n",
       "Num_Credit_Inquiries                                 4.000   \n",
       "Credit_Utilization_Ratio                            23.934   \n",
       "Credit_History_Age                                 271.000   \n",
       "Payment_of_Min_Amount                                   No   \n",
       "Amount_invested_monthly                             24.785   \n",
       "Monthly_Balance                                    358.124   \n",
       "Credit_Score                                      Standard   \n",
       "Credit_Mix                                            Good   \n",
       "Payment_Behaviour         High_spent_Medium_value_payments   \n",
       "Age                                                 23.000   \n",
       "Annual_Income                                    19114.120   \n",
       "Num_Bank_Accounts                                    3.000   \n",
       "Num_Credit_Card                                      4.000   \n",
       "Interest_Rate                                        3.000   \n",
       "Num_of_Loan                                          4.000   \n",
       "Monthly_Inhand_Salary                             1824.843   \n",
       "Changed_Credit_Limit                                11.270   \n",
       "Outstanding_Debt                                   809.980   \n",
       "Total_EMI_per_month                                 49.575   \n",
       "\n",
       "                                                    8      \\\n",
       "Delay_from_due_date                                 3.000   \n",
       "Num_of_Delayed_Payment                              4.000   \n",
       "Num_Credit_Inquiries                                2.000   \n",
       "Credit_Utilization_Ratio                           24.464   \n",
       "Credit_History_Age                                319.000   \n",
       "Payment_of_Min_Amount                                  No   \n",
       "Amount_invested_monthly                           104.292   \n",
       "Monthly_Balance                                   470.691   \n",
       "Credit_Score                                     Standard   \n",
       "Credit_Mix                                           Good   \n",
       "Payment_Behaviour         High_spent_Large_value_payments   \n",
       "Age                                                28.000   \n",
       "Annual_Income                                   34847.840   \n",
       "Num_Bank_Accounts                                   2.000   \n",
       "Num_Credit_Card                                     4.000   \n",
       "Interest_Rate                                       6.000   \n",
       "Num_of_Loan                                         1.000   \n",
       "Monthly_Inhand_Salary                            3037.987   \n",
       "Changed_Credit_Limit                                5.420   \n",
       "Outstanding_Debt                                  605.030   \n",
       "Total_EMI_per_month                                18.816   \n",
       "\n",
       "                                                    9      ...  \\\n",
       "Delay_from_due_date                                 7.000  ...   \n",
       "Num_of_Delayed_Payment                              1.000  ...   \n",
       "Num_Credit_Inquiries                                2.000  ...   \n",
       "Credit_Utilization_Ratio                           38.551  ...   \n",
       "Credit_History_Age                                320.000  ...   \n",
       "Payment_of_Min_Amount                                  No  ...   \n",
       "Amount_invested_monthly                            40.391  ...   \n",
       "Monthly_Balance                                   484.591  ...   \n",
       "Credit_Score                                         Good  ...   \n",
       "Credit_Mix                                           Good  ...   \n",
       "Payment_Behaviour         High_spent_Large_value_payments  ...   \n",
       "Age                                                28.000  ...   \n",
       "Annual_Income                                   34847.840  ...   \n",
       "Num_Bank_Accounts                                   2.000  ...   \n",
       "Num_Credit_Card                                     4.000  ...   \n",
       "Interest_Rate                                       6.000  ...   \n",
       "Num_of_Loan                                         1.000  ...   \n",
       "Monthly_Inhand_Salary                            3037.987  ...   \n",
       "Changed_Credit_Limit                                5.420  ...   \n",
       "Outstanding_Debt                                  605.030  ...   \n",
       "Total_EMI_per_month                                18.816  ...   \n",
       "\n",
       "                                                    99950  \\\n",
       "Delay_from_due_date                                33.000   \n",
       "Num_of_Delayed_Payment                             26.000   \n",
       "Num_Credit_Inquiries                                9.000   \n",
       "Credit_Utilization_Ratio                           25.124   \n",
       "Credit_History_Age                                 73.000   \n",
       "Payment_of_Min_Amount                                 Yes   \n",
       "Amount_invested_monthly                           173.276   \n",
       "Monthly_Balance                                   228.750   \n",
       "Credit_Score                                     Standard   \n",
       "Credit_Mix                                            Bad   \n",
       "Payment_Behaviour         High_spent_Large_value_payments   \n",
       "Age                                                28.000   \n",
       "Annual_Income                                   20002.880   \n",
       "Num_Bank_Accounts                                  10.000   \n",
       "Num_Credit_Card                                     8.000   \n",
       "Interest_Rate                                      29.000   \n",
       "Num_of_Loan                                         5.000   \n",
       "Monthly_Inhand_Salary                            1929.907   \n",
       "Changed_Credit_Limit                               18.310   \n",
       "Outstanding_Debt                                 3571.700   \n",
       "Total_EMI_per_month                                60.965   \n",
       "\n",
       "                                                    99951  \\\n",
       "Delay_from_due_date                                33.000   \n",
       "Num_of_Delayed_Payment                             25.000   \n",
       "Num_Credit_Inquiries                                9.000   \n",
       "Credit_Utilization_Ratio                           37.141   \n",
       "Credit_History_Age                                 75.000   \n",
       "Payment_of_Min_Amount                                 Yes   \n",
       "Amount_invested_monthly                            34.663   \n",
       "Monthly_Balance                                   337.363   \n",
       "Credit_Score                                     Standard   \n",
       "Credit_Mix                                            Bad   \n",
       "Payment_Behaviour         High_spent_Large_value_payments   \n",
       "Age                                                28.000   \n",
       "Annual_Income                                   20002.880   \n",
       "Num_Bank_Accounts                                  10.000   \n",
       "Num_Credit_Card                                     8.000   \n",
       "Interest_Rate                                      29.000   \n",
       "Num_of_Loan                                         5.000   \n",
       "Monthly_Inhand_Salary                            1929.907   \n",
       "Changed_Credit_Limit                               18.310   \n",
       "Outstanding_Debt                                 3571.700   \n",
       "Total_EMI_per_month                                60.965   \n",
       "\n",
       "                                                     99952  \\\n",
       "Delay_from_due_date                                 23.000   \n",
       "Num_of_Delayed_Payment                               6.000   \n",
       "Num_Credit_Inquiries                                 3.000   \n",
       "Credit_Utilization_Ratio                            32.991   \n",
       "Credit_History_Age                                 375.000   \n",
       "Payment_of_Min_Amount                                   No   \n",
       "Amount_invested_monthly                            401.196   \n",
       "Monthly_Balance                                    189.641   \n",
       "Credit_Score                                          Poor   \n",
       "Credit_Mix                                            Good   \n",
       "Payment_Behaviour         High_spent_Medium_value_payments   \n",
       "Age                                                 25.000   \n",
       "Annual_Income                                    39628.990   \n",
       "Num_Bank_Accounts                                    4.000   \n",
       "Num_Credit_Card                                      6.000   \n",
       "Interest_Rate                                        7.000   \n",
       "Num_of_Loan                                          2.000   \n",
       "Monthly_Inhand_Salary                             3359.416   \n",
       "Changed_Credit_Limit                                11.500   \n",
       "Outstanding_Debt                                   502.380   \n",
       "Total_EMI_per_month                                 35.104   \n",
       "\n",
       "                                                     99953  \\\n",
       "Delay_from_due_date                                 23.000   \n",
       "Num_of_Delayed_Payment                               6.000   \n",
       "Num_Credit_Inquiries                                 3.000   \n",
       "Credit_Utilization_Ratio                            29.135   \n",
       "Credit_History_Age                                 376.000   \n",
       "Payment_of_Min_Amount                                   No   \n",
       "Amount_invested_monthly                            180.733   \n",
       "Monthly_Balance                                    400.104   \n",
       "Credit_Score                                      Standard   \n",
       "Credit_Mix                                            Good   \n",
       "Payment_Behaviour         High_spent_Medium_value_payments   \n",
       "Age                                                 25.000   \n",
       "Annual_Income                                    39628.990   \n",
       "Num_Bank_Accounts                                    4.000   \n",
       "Num_Credit_Card                                      6.000   \n",
       "Interest_Rate                                        7.000   \n",
       "Num_of_Loan                                          2.000   \n",
       "Monthly_Inhand_Salary                             3359.416   \n",
       "Changed_Credit_Limit                                11.500   \n",
       "Outstanding_Debt                                   502.380   \n",
       "Total_EMI_per_month                                 35.104   \n",
       "\n",
       "                                                     99954  \\\n",
       "Delay_from_due_date                                 20.000   \n",
       "Num_of_Delayed_Payment                               6.000   \n",
       "Num_Credit_Inquiries                                 3.000   \n",
       "Credit_Utilization_Ratio                            39.324   \n",
       "Credit_History_Age                                 377.000   \n",
       "Payment_of_Min_Amount                                   No   \n",
       "Amount_invested_monthly                            140.581   \n",
       "Monthly_Balance                                    410.256   \n",
       "Credit_Score                                          Poor   \n",
       "Credit_Mix                                            Good   \n",
       "Payment_Behaviour         High_spent_Medium_value_payments   \n",
       "Age                                                 25.000   \n",
       "Annual_Income                                    39628.990   \n",
       "Num_Bank_Accounts                                    4.000   \n",
       "Num_Credit_Card                                      6.000   \n",
       "Interest_Rate                                        7.000   \n",
       "Num_of_Loan                                          2.000   \n",
       "Monthly_Inhand_Salary                             3359.416   \n",
       "Changed_Credit_Limit                                11.500   \n",
       "Outstanding_Debt                                   502.380   \n",
       "Total_EMI_per_month                                 35.104   \n",
       "\n",
       "                                                     99955  \\\n",
       "Delay_from_due_date                                 23.000   \n",
       "Num_of_Delayed_Payment                               7.000   \n",
       "Num_Credit_Inquiries                                 3.000   \n",
       "Credit_Utilization_Ratio                            34.664   \n",
       "Credit_History_Age                                 378.000   \n",
       "Payment_of_Min_Amount                                   No   \n",
       "Amount_invested_monthly                             60.971   \n",
       "Monthly_Balance                                    479.866   \n",
       "Credit_Score                                          Poor   \n",
       "Credit_Mix                                            Good   \n",
       "Payment_Behaviour         High_spent_Medium_value_payments   \n",
       "Age                                                 25.000   \n",
       "Annual_Income                                    39628.990   \n",
       "Num_Bank_Accounts                                    4.000   \n",
       "Num_Credit_Card                                      6.000   \n",
       "Interest_Rate                                        7.000   \n",
       "Num_of_Loan                                          2.000   \n",
       "Monthly_Inhand_Salary                             3359.416   \n",
       "Changed_Credit_Limit                                11.500   \n",
       "Outstanding_Debt                                   502.380   \n",
       "Total_EMI_per_month                                 35.104   \n",
       "\n",
       "                                                     99956  \\\n",
       "Delay_from_due_date                                 18.000   \n",
       "Num_of_Delayed_Payment                               7.000   \n",
       "Num_Credit_Inquiries                                 3.000   \n",
       "Credit_Utilization_Ratio                            40.566   \n",
       "Credit_History_Age                                 379.000   \n",
       "Payment_of_Min_Amount                                   No   \n",
       "Amount_invested_monthly                             54.186   \n",
       "Monthly_Balance                                    496.652   \n",
       "Credit_Score                                          Poor   \n",
       "Credit_Mix                                            Good   \n",
       "Payment_Behaviour         High_spent_Medium_value_payments   \n",
       "Age                                                 25.000   \n",
       "Annual_Income                                    39628.990   \n",
       "Num_Bank_Accounts                                    4.000   \n",
       "Num_Credit_Card                                      6.000   \n",
       "Interest_Rate                                        7.000   \n",
       "Num_of_Loan                                          2.000   \n",
       "Monthly_Inhand_Salary                             3359.416   \n",
       "Changed_Credit_Limit                                11.500   \n",
       "Outstanding_Debt                                   502.380   \n",
       "Total_EMI_per_month                                 35.104   \n",
       "\n",
       "                                                     99957  \\\n",
       "Delay_from_due_date                                 27.000   \n",
       "Num_of_Delayed_Payment                               6.000   \n",
       "Num_Credit_Inquiries                                 3.000   \n",
       "Credit_Utilization_Ratio                            41.256   \n",
       "Credit_History_Age                                 380.000   \n",
       "Payment_of_Min_Amount                                   No   \n",
       "Amount_invested_monthly                             24.028   \n",
       "Monthly_Balance                                    516.809   \n",
       "Credit_Score                                          Poor   \n",
       "Credit_Mix                                            Good   \n",
       "Payment_Behaviour         High_spent_Medium_value_payments   \n",
       "Age                                                 25.000   \n",
       "Annual_Income                                    39628.990   \n",
       "Num_Bank_Accounts                                    4.000   \n",
       "Num_Credit_Card                                      6.000   \n",
       "Interest_Rate                                        7.000   \n",
       "Num_of_Loan                                          2.000   \n",
       "Monthly_Inhand_Salary                             3359.416   \n",
       "Changed_Credit_Limit                                11.500   \n",
       "Outstanding_Debt                                   502.380   \n",
       "Total_EMI_per_month                                 35.104   \n",
       "\n",
       "                                                     99958  \\\n",
       "Delay_from_due_date                                 20.000   \n",
       "Num_of_Delayed_Payment                               6.000   \n",
       "Num_Credit_Inquiries                                 3.000   \n",
       "Credit_Utilization_Ratio                            33.638   \n",
       "Credit_History_Age                                 381.000   \n",
       "Payment_of_Min_Amount                                   No   \n",
       "Amount_invested_monthly                            251.673   \n",
       "Monthly_Balance                                    319.165   \n",
       "Credit_Score                                      Standard   \n",
       "Credit_Mix                                            Good   \n",
       "Payment_Behaviour         High_spent_Medium_value_payments   \n",
       "Age                                                 25.000   \n",
       "Annual_Income                                    39628.990   \n",
       "Num_Bank_Accounts                                    4.000   \n",
       "Num_Credit_Card                                      6.000   \n",
       "Interest_Rate                                        7.000   \n",
       "Num_of_Loan                                          2.000   \n",
       "Monthly_Inhand_Salary                             3359.416   \n",
       "Changed_Credit_Limit                                11.500   \n",
       "Outstanding_Debt                                   502.380   \n",
       "Total_EMI_per_month                                 35.104   \n",
       "\n",
       "                                                     99959  \n",
       "Delay_from_due_date                                 18.000  \n",
       "Num_of_Delayed_Payment                               6.000  \n",
       "Num_Credit_Inquiries                                 3.000  \n",
       "Credit_Utilization_Ratio                            34.192  \n",
       "Credit_History_Age                                 382.000  \n",
       "Payment_of_Min_Amount                                   No  \n",
       "Amount_invested_monthly                            167.164  \n",
       "Monthly_Balance                                    393.674  \n",
       "Credit_Score                                          Poor  \n",
       "Credit_Mix                                            Good  \n",
       "Payment_Behaviour         High_spent_Medium_value_payments  \n",
       "Age                                                 25.000  \n",
       "Annual_Income                                    39628.990  \n",
       "Num_Bank_Accounts                                    4.000  \n",
       "Num_Credit_Card                                      6.000  \n",
       "Interest_Rate                                        7.000  \n",
       "Num_of_Loan                                          2.000  \n",
       "Monthly_Inhand_Salary                             3359.416  \n",
       "Changed_Credit_Limit                                11.500  \n",
       "Outstanding_Debt                                   502.380  \n",
       "Total_EMI_per_month                                 35.104  \n",
       "\n",
       "[21 rows x 99960 columns]"
      ]
     },
     "execution_count": 3,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df = pd.read_csv(\"Score.csv\")\n",
    "df.T"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 757
    },
    "executionInfo": {
     "elapsed": 615,
     "status": "ok",
     "timestamp": 1705663310824,
     "user": {
      "displayName": "Canan Dülgeroğlu",
      "userId": "00060531196188721276"
     },
     "user_tz": -180
    },
    "id": "Re0684zGsxrd",
    "outputId": "493e0895-7024-414f-95df-6069165c892e",
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "df = pd.read_csv(\"/content/drive/MyDrive/Colab Notebooks/Score.csv\")\n",
    "df.T"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "executionInfo": {
     "elapsed": 255,
     "status": "ok",
     "timestamp": 1705611124758,
     "user": {
      "displayName": "Canan Dülgeroğlu",
      "userId": "00060531196188721276"
     },
     "user_tz": -180
    },
    "id": "jm69nbsttFa9",
    "outputId": "a1c22579-282c-415e-eded-0f726b689517"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "<class 'pandas.core.frame.DataFrame'>\n",
      "RangeIndex: 99960 entries, 0 to 99959\n",
      "Data columns (total 21 columns):\n",
      " #   Column                    Non-Null Count  Dtype  \n",
      "---  ------                    --------------  -----  \n",
      " 0   Delay_from_due_date       99960 non-null  float64\n",
      " 1   Num_of_Delayed_Payment    99960 non-null  float64\n",
      " 2   Num_Credit_Inquiries      99960 non-null  float64\n",
      " 3   Credit_Utilization_Ratio  99960 non-null  float64\n",
      " 4   Credit_History_Age        99960 non-null  float64\n",
      " 5   Payment_of_Min_Amount     99960 non-null  object \n",
      " 6   Amount_invested_monthly   99960 non-null  float64\n",
      " 7   Monthly_Balance           99960 non-null  float64\n",
      " 8   Credit_Score              99960 non-null  object \n",
      " 9   Credit_Mix                99960 non-null  object \n",
      " 10  Payment_Behaviour         99960 non-null  object \n",
      " 11  Age                       99960 non-null  float64\n",
      " 12  Annual_Income             99960 non-null  float64\n",
      " 13  Num_Bank_Accounts         99960 non-null  float64\n",
      " 14  Num_Credit_Card           99960 non-null  float64\n",
      " 15  Interest_Rate             99960 non-null  float64\n",
      " 16  Num_of_Loan               99960 non-null  float64\n",
      " 17  Monthly_Inhand_Salary     99960 non-null  float64\n",
      " 18  Changed_Credit_Limit      99960 non-null  float64\n",
      " 19  Outstanding_Debt          99960 non-null  float64\n",
      " 20  Total_EMI_per_month       99960 non-null  float64\n",
      "dtypes: float64(17), object(4)\n",
      "memory usage: 16.0+ MB\n"
     ]
    }
   ],
   "source": [
    "df.info()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 602
    },
    "executionInfo": {
     "elapsed": 274,
     "status": "ok",
     "timestamp": 1705611128174,
     "user": {
      "displayName": "Canan Dülgeroğlu",
      "userId": "00060531196188721276"
     },
     "user_tz": -180
    },
    "id": "k_xUUNLAuuvn",
    "outputId": "c84b55c0-da37-47a5-bdfe-47cbe7c1640b"
   },
   "outputs": [
    {
     "data": {
      "text/html": [
       "\n",
       "  <div id=\"df-79c0ba29-1f47-4ddd-8212-c14c7e8e5b06\" class=\"colab-df-container\">\n",
       "    <div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>count</th>\n",
       "      <th>mean</th>\n",
       "      <th>std</th>\n",
       "      <th>min</th>\n",
       "      <th>25%</th>\n",
       "      <th>50%</th>\n",
       "      <th>75%</th>\n",
       "      <th>max</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>Delay_from_due_date</th>\n",
       "      <td>99960.000</td>\n",
       "      <td>21.096</td>\n",
       "      <td>14.827</td>\n",
       "      <td>0.000</td>\n",
       "      <td>10.000</td>\n",
       "      <td>18.000</td>\n",
       "      <td>28.000</td>\n",
       "      <td>67.000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>Num_of_Delayed_Payment</th>\n",
       "      <td>99960.000</td>\n",
       "      <td>13.336</td>\n",
       "      <td>6.270</td>\n",
       "      <td>0.000</td>\n",
       "      <td>9.000</td>\n",
       "      <td>14.000</td>\n",
       "      <td>18.000</td>\n",
       "      <td>28.000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>Num_Credit_Inquiries</th>\n",
       "      <td>99960.000</td>\n",
       "      <td>5.775</td>\n",
       "      <td>3.862</td>\n",
       "      <td>0.000</td>\n",
       "      <td>3.000</td>\n",
       "      <td>5.000</td>\n",
       "      <td>8.000</td>\n",
       "      <td>29.000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>Credit_Utilization_Ratio</th>\n",
       "      <td>99960.000</td>\n",
       "      <td>32.285</td>\n",
       "      <td>5.117</td>\n",
       "      <td>20.000</td>\n",
       "      <td>28.052</td>\n",
       "      <td>32.305</td>\n",
       "      <td>36.496</td>\n",
       "      <td>50.000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>Credit_History_Age</th>\n",
       "      <td>99960.000</td>\n",
       "      <td>221.123</td>\n",
       "      <td>99.696</td>\n",
       "      <td>1.000</td>\n",
       "      <td>144.000</td>\n",
       "      <td>219.000</td>\n",
       "      <td>302.000</td>\n",
       "      <td>404.000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>Amount_invested_monthly</th>\n",
       "      <td>99960.000</td>\n",
       "      <td>193.665</td>\n",
       "      <td>194.783</td>\n",
       "      <td>0.000</td>\n",
       "      <td>73.709</td>\n",
       "      <td>129.342</td>\n",
       "      <td>234.324</td>\n",
       "      <td>1977.326</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>Monthly_Balance</th>\n",
       "      <td>99960.000</td>\n",
       "      <td>403.445</td>\n",
       "      <td>214.387</td>\n",
       "      <td>0.008</td>\n",
       "      <td>270.317</td>\n",
       "      <td>337.238</td>\n",
       "      <td>471.905</td>\n",
       "      <td>1602.041</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>Age</th>\n",
       "      <td>99960.000</td>\n",
       "      <td>33.269</td>\n",
       "      <td>10.762</td>\n",
       "      <td>14.000</td>\n",
       "      <td>24.000</td>\n",
       "      <td>33.000</td>\n",
       "      <td>42.000</td>\n",
       "      <td>56.000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>Annual_Income</th>\n",
       "      <td>99960.000</td>\n",
       "      <td>50498.704</td>\n",
       "      <td>38294.243</td>\n",
       "      <td>7005.930</td>\n",
       "      <td>19338.480</td>\n",
       "      <td>36996.830</td>\n",
       "      <td>71681.400</td>\n",
       "      <td>179987.280</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>Num_Bank_Accounts</th>\n",
       "      <td>99960.000</td>\n",
       "      <td>5.369</td>\n",
       "      <td>2.592</td>\n",
       "      <td>0.000</td>\n",
       "      <td>3.000</td>\n",
       "      <td>5.000</td>\n",
       "      <td>7.000</td>\n",
       "      <td>10.000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>Num_Credit_Card</th>\n",
       "      <td>99960.000</td>\n",
       "      <td>5.533</td>\n",
       "      <td>2.068</td>\n",
       "      <td>0.000</td>\n",
       "      <td>4.000</td>\n",
       "      <td>5.000</td>\n",
       "      <td>7.000</td>\n",
       "      <td>11.000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>Interest_Rate</th>\n",
       "      <td>99960.000</td>\n",
       "      <td>14.535</td>\n",
       "      <td>8.741</td>\n",
       "      <td>1.000</td>\n",
       "      <td>7.000</td>\n",
       "      <td>13.000</td>\n",
       "      <td>20.000</td>\n",
       "      <td>34.000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>Num_of_Loan</th>\n",
       "      <td>99960.000</td>\n",
       "      <td>3.534</td>\n",
       "      <td>2.446</td>\n",
       "      <td>0.000</td>\n",
       "      <td>2.000</td>\n",
       "      <td>3.000</td>\n",
       "      <td>5.000</td>\n",
       "      <td>9.000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>Monthly_Inhand_Salary</th>\n",
       "      <td>99960.000</td>\n",
       "      <td>4196.814</td>\n",
       "      <td>3186.518</td>\n",
       "      <td>303.645</td>\n",
       "      <td>1626.594</td>\n",
       "      <td>3091.387</td>\n",
       "      <td>5957.715</td>\n",
       "      <td>15204.633</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>Changed_Credit_Limit</th>\n",
       "      <td>99960.000</td>\n",
       "      <td>10.397</td>\n",
       "      <td>6.511</td>\n",
       "      <td>0.500</td>\n",
       "      <td>5.500</td>\n",
       "      <td>9.340</td>\n",
       "      <td>14.680</td>\n",
       "      <td>29.980</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>Outstanding_Debt</th>\n",
       "      <td>99960.000</td>\n",
       "      <td>1426.515</td>\n",
       "      <td>1155.253</td>\n",
       "      <td>0.230</td>\n",
       "      <td>566.080</td>\n",
       "      <td>1166.470</td>\n",
       "      <td>1948.200</td>\n",
       "      <td>4998.070</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>Total_EMI_per_month</th>\n",
       "      <td>99960.000</td>\n",
       "      <td>105.566</td>\n",
       "      <td>125.821</td>\n",
       "      <td>0.000</td>\n",
       "      <td>29.054</td>\n",
       "      <td>66.058</td>\n",
       "      <td>145.585</td>\n",
       "      <td>1779.103</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>\n",
       "    <div class=\"colab-df-buttons\">\n",
       "\n",
       "  <div class=\"colab-df-container\">\n",
       "    <button class=\"colab-df-convert\" onclick=\"convertToInteractive('df-79c0ba29-1f47-4ddd-8212-c14c7e8e5b06')\"\n",
       "            title=\"Convert this dataframe to an interactive table.\"\n",
       "            style=\"display:none;\">\n",
       "\n",
       "  <svg xmlns=\"http://www.w3.org/2000/svg\" height=\"24px\" viewBox=\"0 -960 960 960\">\n",
       "    <path d=\"M120-120v-720h720v720H120Zm60-500h600v-160H180v160Zm220 220h160v-160H400v160Zm0 220h160v-160H400v160ZM180-400h160v-160H180v160Zm440 0h160v-160H620v160ZM180-180h160v-160H180v160Zm440 0h160v-160H620v160Z\"/>\n",
       "  </svg>\n",
       "    </button>\n",
       "\n",
       "  <style>\n",
       "    .colab-df-container {\n",
       "      display:flex;\n",
       "      gap: 12px;\n",
       "    }\n",
       "\n",
       "    .colab-df-convert {\n",
       "      background-color: #E8F0FE;\n",
       "      border: none;\n",
       "      border-radius: 50%;\n",
       "      cursor: pointer;\n",
       "      display: none;\n",
       "      fill: #1967D2;\n",
       "      height: 32px;\n",
       "      padding: 0 0 0 0;\n",
       "      width: 32px;\n",
       "    }\n",
       "\n",
       "    .colab-df-convert:hover {\n",
       "      background-color: #E2EBFA;\n",
       "      box-shadow: 0px 1px 2px rgba(60, 64, 67, 0.3), 0px 1px 3px 1px rgba(60, 64, 67, 0.15);\n",
       "      fill: #174EA6;\n",
       "    }\n",
       "\n",
       "    .colab-df-buttons div {\n",
       "      margin-bottom: 4px;\n",
       "    }\n",
       "\n",
       "    [theme=dark] .colab-df-convert {\n",
       "      background-color: #3B4455;\n",
       "      fill: #D2E3FC;\n",
       "    }\n",
       "\n",
       "    [theme=dark] .colab-df-convert:hover {\n",
       "      background-color: #434B5C;\n",
       "      box-shadow: 0px 1px 3px 1px rgba(0, 0, 0, 0.15);\n",
       "      filter: drop-shadow(0px 1px 2px rgba(0, 0, 0, 0.3));\n",
       "      fill: #FFFFFF;\n",
       "    }\n",
       "  </style>\n",
       "\n",
       "    <script>\n",
       "      const buttonEl =\n",
       "        document.querySelector('#df-79c0ba29-1f47-4ddd-8212-c14c7e8e5b06 button.colab-df-convert');\n",
       "      buttonEl.style.display =\n",
       "        google.colab.kernel.accessAllowed ? 'block' : 'none';\n",
       "\n",
       "      async function convertToInteractive(key) {\n",
       "        const element = document.querySelector('#df-79c0ba29-1f47-4ddd-8212-c14c7e8e5b06');\n",
       "        const dataTable =\n",
       "          await google.colab.kernel.invokeFunction('convertToInteractive',\n",
       "                                                    [key], {});\n",
       "        if (!dataTable) return;\n",
       "\n",
       "        const docLinkHtml = 'Like what you see? Visit the ' +\n",
       "          '<a target=\"_blank\" href=https://colab.research.google.com/notebooks/data_table.ipynb>data table notebook</a>'\n",
       "          + ' to learn more about interactive tables.';\n",
       "        element.innerHTML = '';\n",
       "        dataTable['output_type'] = 'display_data';\n",
       "        await google.colab.output.renderOutput(dataTable, element);\n",
       "        const docLink = document.createElement('div');\n",
       "        docLink.innerHTML = docLinkHtml;\n",
       "        element.appendChild(docLink);\n",
       "      }\n",
       "    </script>\n",
       "  </div>\n",
       "\n",
       "\n",
       "<div id=\"df-2e168626-f11b-4b17-b5a8-4ab6a3c11a7f\">\n",
       "  <button class=\"colab-df-quickchart\" onclick=\"quickchart('df-2e168626-f11b-4b17-b5a8-4ab6a3c11a7f')\"\n",
       "            title=\"Suggest charts\"\n",
       "            style=\"display:none;\">\n",
       "\n",
       "<svg xmlns=\"http://www.w3.org/2000/svg\" height=\"24px\"viewBox=\"0 0 24 24\"\n",
       "     width=\"24px\">\n",
       "    <g>\n",
       "        <path d=\"M19 3H5c-1.1 0-2 .9-2 2v14c0 1.1.9 2 2 2h14c1.1 0 2-.9 2-2V5c0-1.1-.9-2-2-2zM9 17H7v-7h2v7zm4 0h-2V7h2v10zm4 0h-2v-4h2v4z\"/>\n",
       "    </g>\n",
       "</svg>\n",
       "  </button>\n",
       "\n",
       "<style>\n",
       "  .colab-df-quickchart {\n",
       "      --bg-color: #E8F0FE;\n",
       "      --fill-color: #1967D2;\n",
       "      --hover-bg-color: #E2EBFA;\n",
       "      --hover-fill-color: #174EA6;\n",
       "      --disabled-fill-color: #AAA;\n",
       "      --disabled-bg-color: #DDD;\n",
       "  }\n",
       "\n",
       "  [theme=dark] .colab-df-quickchart {\n",
       "      --bg-color: #3B4455;\n",
       "      --fill-color: #D2E3FC;\n",
       "      --hover-bg-color: #434B5C;\n",
       "      --hover-fill-color: #FFFFFF;\n",
       "      --disabled-bg-color: #3B4455;\n",
       "      --disabled-fill-color: #666;\n",
       "  }\n",
       "\n",
       "  .colab-df-quickchart {\n",
       "    background-color: var(--bg-color);\n",
       "    border: none;\n",
       "    border-radius: 50%;\n",
       "    cursor: pointer;\n",
       "    display: none;\n",
       "    fill: var(--fill-color);\n",
       "    height: 32px;\n",
       "    padding: 0;\n",
       "    width: 32px;\n",
       "  }\n",
       "\n",
       "  .colab-df-quickchart:hover {\n",
       "    background-color: var(--hover-bg-color);\n",
       "    box-shadow: 0 1px 2px rgba(60, 64, 67, 0.3), 0 1px 3px 1px rgba(60, 64, 67, 0.15);\n",
       "    fill: var(--button-hover-fill-color);\n",
       "  }\n",
       "\n",
       "  .colab-df-quickchart-complete:disabled,\n",
       "  .colab-df-quickchart-complete:disabled:hover {\n",
       "    background-color: var(--disabled-bg-color);\n",
       "    fill: var(--disabled-fill-color);\n",
       "    box-shadow: none;\n",
       "  }\n",
       "\n",
       "  .colab-df-spinner {\n",
       "    border: 2px solid var(--fill-color);\n",
       "    border-color: transparent;\n",
       "    border-bottom-color: var(--fill-color);\n",
       "    animation:\n",
       "      spin 1s steps(1) infinite;\n",
       "  }\n",
       "\n",
       "  @keyframes spin {\n",
       "    0% {\n",
       "      border-color: transparent;\n",
       "      border-bottom-color: var(--fill-color);\n",
       "      border-left-color: var(--fill-color);\n",
       "    }\n",
       "    20% {\n",
       "      border-color: transparent;\n",
       "      border-left-color: var(--fill-color);\n",
       "      border-top-color: var(--fill-color);\n",
       "    }\n",
       "    30% {\n",
       "      border-color: transparent;\n",
       "      border-left-color: var(--fill-color);\n",
       "      border-top-color: var(--fill-color);\n",
       "      border-right-color: var(--fill-color);\n",
       "    }\n",
       "    40% {\n",
       "      border-color: transparent;\n",
       "      border-right-color: var(--fill-color);\n",
       "      border-top-color: var(--fill-color);\n",
       "    }\n",
       "    60% {\n",
       "      border-color: transparent;\n",
       "      border-right-color: var(--fill-color);\n",
       "    }\n",
       "    80% {\n",
       "      border-color: transparent;\n",
       "      border-right-color: var(--fill-color);\n",
       "      border-bottom-color: var(--fill-color);\n",
       "    }\n",
       "    90% {\n",
       "      border-color: transparent;\n",
       "      border-bottom-color: var(--fill-color);\n",
       "    }\n",
       "  }\n",
       "</style>\n",
       "\n",
       "  <script>\n",
       "    async function quickchart(key) {\n",
       "      const quickchartButtonEl =\n",
       "        document.querySelector('#' + key + ' button');\n",
       "      quickchartButtonEl.disabled = true;  // To prevent multiple clicks.\n",
       "      quickchartButtonEl.classList.add('colab-df-spinner');\n",
       "      try {\n",
       "        const charts = await google.colab.kernel.invokeFunction(\n",
       "            'suggestCharts', [key], {});\n",
       "      } catch (error) {\n",
       "        console.error('Error during call to suggestCharts:', error);\n",
       "      }\n",
       "      quickchartButtonEl.classList.remove('colab-df-spinner');\n",
       "      quickchartButtonEl.classList.add('colab-df-quickchart-complete');\n",
       "    }\n",
       "    (() => {\n",
       "      let quickchartButtonEl =\n",
       "        document.querySelector('#df-2e168626-f11b-4b17-b5a8-4ab6a3c11a7f button');\n",
       "      quickchartButtonEl.style.display =\n",
       "        google.colab.kernel.accessAllowed ? 'block' : 'none';\n",
       "    })();\n",
       "  </script>\n",
       "</div>\n",
       "\n",
       "    </div>\n",
       "  </div>\n"
      ],
      "text/plain": [
       "                             count      mean       std      min       25%  \\\n",
       "Delay_from_due_date      99960.000    21.096    14.827    0.000    10.000   \n",
       "Num_of_Delayed_Payment   99960.000    13.336     6.270    0.000     9.000   \n",
       "Num_Credit_Inquiries     99960.000     5.775     3.862    0.000     3.000   \n",
       "Credit_Utilization_Ratio 99960.000    32.285     5.117   20.000    28.052   \n",
       "Credit_History_Age       99960.000   221.123    99.696    1.000   144.000   \n",
       "Amount_invested_monthly  99960.000   193.665   194.783    0.000    73.709   \n",
       "Monthly_Balance          99960.000   403.445   214.387    0.008   270.317   \n",
       "Age                      99960.000    33.269    10.762   14.000    24.000   \n",
       "Annual_Income            99960.000 50498.704 38294.243 7005.930 19338.480   \n",
       "Num_Bank_Accounts        99960.000     5.369     2.592    0.000     3.000   \n",
       "Num_Credit_Card          99960.000     5.533     2.068    0.000     4.000   \n",
       "Interest_Rate            99960.000    14.535     8.741    1.000     7.000   \n",
       "Num_of_Loan              99960.000     3.534     2.446    0.000     2.000   \n",
       "Monthly_Inhand_Salary    99960.000  4196.814  3186.518  303.645  1626.594   \n",
       "Changed_Credit_Limit     99960.000    10.397     6.511    0.500     5.500   \n",
       "Outstanding_Debt         99960.000  1426.515  1155.253    0.230   566.080   \n",
       "Total_EMI_per_month      99960.000   105.566   125.821    0.000    29.054   \n",
       "\n",
       "                               50%       75%        max  \n",
       "Delay_from_due_date         18.000    28.000     67.000  \n",
       "Num_of_Delayed_Payment      14.000    18.000     28.000  \n",
       "Num_Credit_Inquiries         5.000     8.000     29.000  \n",
       "Credit_Utilization_Ratio    32.305    36.496     50.000  \n",
       "Credit_History_Age         219.000   302.000    404.000  \n",
       "Amount_invested_monthly    129.342   234.324   1977.326  \n",
       "Monthly_Balance            337.238   471.905   1602.041  \n",
       "Age                         33.000    42.000     56.000  \n",
       "Annual_Income            36996.830 71681.400 179987.280  \n",
       "Num_Bank_Accounts            5.000     7.000     10.000  \n",
       "Num_Credit_Card              5.000     7.000     11.000  \n",
       "Interest_Rate               13.000    20.000     34.000  \n",
       "Num_of_Loan                  3.000     5.000      9.000  \n",
       "Monthly_Inhand_Salary     3091.387  5957.715  15204.633  \n",
       "Changed_Credit_Limit         9.340    14.680     29.980  \n",
       "Outstanding_Debt          1166.470  1948.200   4998.070  \n",
       "Total_EMI_per_month         66.058   145.585   1779.103  "
      ]
     },
     "execution_count": 6,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df.describe().T"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "T21zuSVGwq_Z"
   },
   "source": [
    "Amount_invested_monthly ve Total_EMI_per_month sütunları std > mean olduğu için ve yüzdelik dağılım ve min-max uyumsuzluğu outlier olabileceğini gösteriyor."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 175
    },
    "executionInfo": {
     "elapsed": 259,
     "status": "ok",
     "timestamp": 1705611134140,
     "user": {
      "displayName": "Canan Dülgeroğlu",
      "userId": "00060531196188721276"
     },
     "user_tz": -180
    },
    "id": "ndO3O1KBvKAM",
    "outputId": "beef278e-4a7f-4d56-abc5-044e92b66616"
   },
   "outputs": [
    {
     "data": {
      "text/html": [
       "\n",
       "  <div id=\"df-7e5d398c-bcec-405f-a26f-df3d1c8db573\" class=\"colab-df-container\">\n",
       "    <div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>count</th>\n",
       "      <th>unique</th>\n",
       "      <th>top</th>\n",
       "      <th>freq</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>Payment_of_Min_Amount</th>\n",
       "      <td>99960</td>\n",
       "      <td>3</td>\n",
       "      <td>Yes</td>\n",
       "      <td>52326</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>Credit_Score</th>\n",
       "      <td>99960</td>\n",
       "      <td>3</td>\n",
       "      <td>Standard</td>\n",
       "      <td>53149</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>Credit_Mix</th>\n",
       "      <td>99960</td>\n",
       "      <td>3</td>\n",
       "      <td>Standard</td>\n",
       "      <td>45832</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>Payment_Behaviour</th>\n",
       "      <td>99960</td>\n",
       "      <td>6</td>\n",
       "      <td>Low_spent_Small_value_payments</td>\n",
       "      <td>33912</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>\n",
       "    <div class=\"colab-df-buttons\">\n",
       "\n",
       "  <div class=\"colab-df-container\">\n",
       "    <button class=\"colab-df-convert\" onclick=\"convertToInteractive('df-7e5d398c-bcec-405f-a26f-df3d1c8db573')\"\n",
       "            title=\"Convert this dataframe to an interactive table.\"\n",
       "            style=\"display:none;\">\n",
       "\n",
       "  <svg xmlns=\"http://www.w3.org/2000/svg\" height=\"24px\" viewBox=\"0 -960 960 960\">\n",
       "    <path d=\"M120-120v-720h720v720H120Zm60-500h600v-160H180v160Zm220 220h160v-160H400v160Zm0 220h160v-160H400v160ZM180-400h160v-160H180v160Zm440 0h160v-160H620v160ZM180-180h160v-160H180v160Zm440 0h160v-160H620v160Z\"/>\n",
       "  </svg>\n",
       "    </button>\n",
       "\n",
       "  <style>\n",
       "    .colab-df-container {\n",
       "      display:flex;\n",
       "      gap: 12px;\n",
       "    }\n",
       "\n",
       "    .colab-df-convert {\n",
       "      background-color: #E8F0FE;\n",
       "      border: none;\n",
       "      border-radius: 50%;\n",
       "      cursor: pointer;\n",
       "      display: none;\n",
       "      fill: #1967D2;\n",
       "      height: 32px;\n",
       "      padding: 0 0 0 0;\n",
       "      width: 32px;\n",
       "    }\n",
       "\n",
       "    .colab-df-convert:hover {\n",
       "      background-color: #E2EBFA;\n",
       "      box-shadow: 0px 1px 2px rgba(60, 64, 67, 0.3), 0px 1px 3px 1px rgba(60, 64, 67, 0.15);\n",
       "      fill: #174EA6;\n",
       "    }\n",
       "\n",
       "    .colab-df-buttons div {\n",
       "      margin-bottom: 4px;\n",
       "    }\n",
       "\n",
       "    [theme=dark] .colab-df-convert {\n",
       "      background-color: #3B4455;\n",
       "      fill: #D2E3FC;\n",
       "    }\n",
       "\n",
       "    [theme=dark] .colab-df-convert:hover {\n",
       "      background-color: #434B5C;\n",
       "      box-shadow: 0px 1px 3px 1px rgba(0, 0, 0, 0.15);\n",
       "      filter: drop-shadow(0px 1px 2px rgba(0, 0, 0, 0.3));\n",
       "      fill: #FFFFFF;\n",
       "    }\n",
       "  </style>\n",
       "\n",
       "    <script>\n",
       "      const buttonEl =\n",
       "        document.querySelector('#df-7e5d398c-bcec-405f-a26f-df3d1c8db573 button.colab-df-convert');\n",
       "      buttonEl.style.display =\n",
       "        google.colab.kernel.accessAllowed ? 'block' : 'none';\n",
       "\n",
       "      async function convertToInteractive(key) {\n",
       "        const element = document.querySelector('#df-7e5d398c-bcec-405f-a26f-df3d1c8db573');\n",
       "        const dataTable =\n",
       "          await google.colab.kernel.invokeFunction('convertToInteractive',\n",
       "                                                    [key], {});\n",
       "        if (!dataTable) return;\n",
       "\n",
       "        const docLinkHtml = 'Like what you see? Visit the ' +\n",
       "          '<a target=\"_blank\" href=https://colab.research.google.com/notebooks/data_table.ipynb>data table notebook</a>'\n",
       "          + ' to learn more about interactive tables.';\n",
       "        element.innerHTML = '';\n",
       "        dataTable['output_type'] = 'display_data';\n",
       "        await google.colab.output.renderOutput(dataTable, element);\n",
       "        const docLink = document.createElement('div');\n",
       "        docLink.innerHTML = docLinkHtml;\n",
       "        element.appendChild(docLink);\n",
       "      }\n",
       "    </script>\n",
       "  </div>\n",
       "\n",
       "\n",
       "<div id=\"df-5fa18b9f-b149-4257-b4e7-e38f979eaf10\">\n",
       "  <button class=\"colab-df-quickchart\" onclick=\"quickchart('df-5fa18b9f-b149-4257-b4e7-e38f979eaf10')\"\n",
       "            title=\"Suggest charts\"\n",
       "            style=\"display:none;\">\n",
       "\n",
       "<svg xmlns=\"http://www.w3.org/2000/svg\" height=\"24px\"viewBox=\"0 0 24 24\"\n",
       "     width=\"24px\">\n",
       "    <g>\n",
       "        <path d=\"M19 3H5c-1.1 0-2 .9-2 2v14c0 1.1.9 2 2 2h14c1.1 0 2-.9 2-2V5c0-1.1-.9-2-2-2zM9 17H7v-7h2v7zm4 0h-2V7h2v10zm4 0h-2v-4h2v4z\"/>\n",
       "    </g>\n",
       "</svg>\n",
       "  </button>\n",
       "\n",
       "<style>\n",
       "  .colab-df-quickchart {\n",
       "      --bg-color: #E8F0FE;\n",
       "      --fill-color: #1967D2;\n",
       "      --hover-bg-color: #E2EBFA;\n",
       "      --hover-fill-color: #174EA6;\n",
       "      --disabled-fill-color: #AAA;\n",
       "      --disabled-bg-color: #DDD;\n",
       "  }\n",
       "\n",
       "  [theme=dark] .colab-df-quickchart {\n",
       "      --bg-color: #3B4455;\n",
       "      --fill-color: #D2E3FC;\n",
       "      --hover-bg-color: #434B5C;\n",
       "      --hover-fill-color: #FFFFFF;\n",
       "      --disabled-bg-color: #3B4455;\n",
       "      --disabled-fill-color: #666;\n",
       "  }\n",
       "\n",
       "  .colab-df-quickchart {\n",
       "    background-color: var(--bg-color);\n",
       "    border: none;\n",
       "    border-radius: 50%;\n",
       "    cursor: pointer;\n",
       "    display: none;\n",
       "    fill: var(--fill-color);\n",
       "    height: 32px;\n",
       "    padding: 0;\n",
       "    width: 32px;\n",
       "  }\n",
       "\n",
       "  .colab-df-quickchart:hover {\n",
       "    background-color: var(--hover-bg-color);\n",
       "    box-shadow: 0 1px 2px rgba(60, 64, 67, 0.3), 0 1px 3px 1px rgba(60, 64, 67, 0.15);\n",
       "    fill: var(--button-hover-fill-color);\n",
       "  }\n",
       "\n",
       "  .colab-df-quickchart-complete:disabled,\n",
       "  .colab-df-quickchart-complete:disabled:hover {\n",
       "    background-color: var(--disabled-bg-color);\n",
       "    fill: var(--disabled-fill-color);\n",
       "    box-shadow: none;\n",
       "  }\n",
       "\n",
       "  .colab-df-spinner {\n",
       "    border: 2px solid var(--fill-color);\n",
       "    border-color: transparent;\n",
       "    border-bottom-color: var(--fill-color);\n",
       "    animation:\n",
       "      spin 1s steps(1) infinite;\n",
       "  }\n",
       "\n",
       "  @keyframes spin {\n",
       "    0% {\n",
       "      border-color: transparent;\n",
       "      border-bottom-color: var(--fill-color);\n",
       "      border-left-color: var(--fill-color);\n",
       "    }\n",
       "    20% {\n",
       "      border-color: transparent;\n",
       "      border-left-color: var(--fill-color);\n",
       "      border-top-color: var(--fill-color);\n",
       "    }\n",
       "    30% {\n",
       "      border-color: transparent;\n",
       "      border-left-color: var(--fill-color);\n",
       "      border-top-color: var(--fill-color);\n",
       "      border-right-color: var(--fill-color);\n",
       "    }\n",
       "    40% {\n",
       "      border-color: transparent;\n",
       "      border-right-color: var(--fill-color);\n",
       "      border-top-color: var(--fill-color);\n",
       "    }\n",
       "    60% {\n",
       "      border-color: transparent;\n",
       "      border-right-color: var(--fill-color);\n",
       "    }\n",
       "    80% {\n",
       "      border-color: transparent;\n",
       "      border-right-color: var(--fill-color);\n",
       "      border-bottom-color: var(--fill-color);\n",
       "    }\n",
       "    90% {\n",
       "      border-color: transparent;\n",
       "      border-bottom-color: var(--fill-color);\n",
       "    }\n",
       "  }\n",
       "</style>\n",
       "\n",
       "  <script>\n",
       "    async function quickchart(key) {\n",
       "      const quickchartButtonEl =\n",
       "        document.querySelector('#' + key + ' button');\n",
       "      quickchartButtonEl.disabled = true;  // To prevent multiple clicks.\n",
       "      quickchartButtonEl.classList.add('colab-df-spinner');\n",
       "      try {\n",
       "        const charts = await google.colab.kernel.invokeFunction(\n",
       "            'suggestCharts', [key], {});\n",
       "      } catch (error) {\n",
       "        console.error('Error during call to suggestCharts:', error);\n",
       "      }\n",
       "      quickchartButtonEl.classList.remove('colab-df-spinner');\n",
       "      quickchartButtonEl.classList.add('colab-df-quickchart-complete');\n",
       "    }\n",
       "    (() => {\n",
       "      let quickchartButtonEl =\n",
       "        document.querySelector('#df-5fa18b9f-b149-4257-b4e7-e38f979eaf10 button');\n",
       "      quickchartButtonEl.style.display =\n",
       "        google.colab.kernel.accessAllowed ? 'block' : 'none';\n",
       "    })();\n",
       "  </script>\n",
       "</div>\n",
       "\n",
       "    </div>\n",
       "  </div>\n"
      ],
      "text/plain": [
       "                       count unique                             top   freq\n",
       "Payment_of_Min_Amount  99960      3                             Yes  52326\n",
       "Credit_Score           99960      3                        Standard  53149\n",
       "Credit_Mix             99960      3                        Standard  45832\n",
       "Payment_Behaviour      99960      6  Low_spent_Small_value_payments  33912"
      ]
     },
     "execution_count": 7,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df.describe(include=\"object\").T"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {
    "executionInfo": {
     "elapsed": 388,
     "status": "ok",
     "timestamp": 1705616984319,
     "user": {
      "displayName": "Canan Dülgeroğlu",
      "userId": "00060531196188721276"
     },
     "user_tz": -180
    },
    "id": "_qAsP6qVrwsf"
   },
   "outputs": [],
   "source": [
    "numeric_columns = df.select_dtypes(include='number')\n",
    "category_columns = df.select_dtypes(exclude='number')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "executionInfo": {
     "elapsed": 2,
     "status": "ok",
     "timestamp": 1705617120356,
     "user": {
      "displayName": "Canan Dülgeroğlu",
      "userId": "00060531196188721276"
     },
     "user_tz": -180
    },
    "id": "bqN37oNis5V_",
    "outputId": "b7c1c1f5-e857-47ea-fe2a-93cdf569312f"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "<class 'pandas.core.frame.DataFrame'>\n",
      "RangeIndex: 99960 entries, 0 to 99959\n",
      "Data columns (total 17 columns):\n",
      " #   Column                    Non-Null Count  Dtype  \n",
      "---  ------                    --------------  -----  \n",
      " 0   Delay_from_due_date       99960 non-null  float64\n",
      " 1   Num_of_Delayed_Payment    99960 non-null  float64\n",
      " 2   Num_Credit_Inquiries      99960 non-null  float64\n",
      " 3   Credit_Utilization_Ratio  99960 non-null  float64\n",
      " 4   Credit_History_Age        99960 non-null  float64\n",
      " 5   Amount_invested_monthly   99960 non-null  float64\n",
      " 6   Monthly_Balance           99960 non-null  float64\n",
      " 7   Age                       99960 non-null  float64\n",
      " 8   Annual_Income             99960 non-null  float64\n",
      " 9   Num_Bank_Accounts         99960 non-null  float64\n",
      " 10  Num_Credit_Card           99960 non-null  float64\n",
      " 11  Interest_Rate             99960 non-null  float64\n",
      " 12  Num_of_Loan               99960 non-null  float64\n",
      " 13  Monthly_Inhand_Salary     99960 non-null  float64\n",
      " 14  Changed_Credit_Limit      99960 non-null  float64\n",
      " 15  Outstanding_Debt          99960 non-null  float64\n",
      " 16  Total_EMI_per_month       99960 non-null  float64\n",
      "dtypes: float64(17)\n",
      "memory usage: 13.0 MB\n"
     ]
    }
   ],
   "source": [
    "numeric_columns.info()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "executionInfo": {
     "elapsed": 6,
     "status": "ok",
     "timestamp": 1705617143820,
     "user": {
      "displayName": "Canan Dülgeroğlu",
      "userId": "00060531196188721276"
     },
     "user_tz": -180
    },
    "id": "pXHV0R_ctAWo",
    "outputId": "d3b57662-1a13-48cf-99cc-b00de04fb6ae"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "<class 'pandas.core.frame.DataFrame'>\n",
      "RangeIndex: 99960 entries, 0 to 99959\n",
      "Data columns (total 4 columns):\n",
      " #   Column                 Non-Null Count  Dtype \n",
      "---  ------                 --------------  ----- \n",
      " 0   Payment_of_Min_Amount  99960 non-null  object\n",
      " 1   Credit_Score           99960 non-null  object\n",
      " 2   Credit_Mix             99960 non-null  object\n",
      " 3   Payment_Behaviour      99960 non-null  object\n",
      "dtypes: object(4)\n",
      "memory usage: 3.1+ MB\n"
     ]
    }
   ],
   "source": [
    "category_columns.info()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "mAhRWGA5rifp"
   },
   "outputs": [],
   "source": [
    "for column in numeric_columns:\n",
    "  sns.boxplot(df[column])\n",
    "  plt.title(column)\n",
    "  plt.show()\n",
    "  print(\"*\"*100)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "_a9aVw1Lvb7v"
   },
   "outputs": [],
   "source": [
    "for column in category_columns:\n",
    "  sns.countplot(df[column])\n",
    "  plt.title(column)\n",
    "  plt.show()\n",
    "  print(\"*\"*100)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "executionInfo": {
     "elapsed": 237,
     "status": "ok",
     "timestamp": 1705611768712,
     "user": {
      "displayName": "Canan Dülgeroğlu",
      "userId": "00060531196188721276"
     },
     "user_tz": -180
    },
    "id": "nBkfs-FiYgAm",
    "outputId": "289eca52-afef-4b86-f610-afec6a78a25c"
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "Delay_from_due_date         0\n",
       "Num_of_Delayed_Payment      0\n",
       "Num_Credit_Inquiries        0\n",
       "Credit_Utilization_Ratio    0\n",
       "Credit_History_Age          0\n",
       "Payment_of_Min_Amount       0\n",
       "Amount_invested_monthly     0\n",
       "Monthly_Balance             0\n",
       "Credit_Score                0\n",
       "Credit_Mix                  0\n",
       "Payment_Behaviour           0\n",
       "Age                         0\n",
       "Annual_Income               0\n",
       "Num_Bank_Accounts           0\n",
       "Num_Credit_Card             0\n",
       "Interest_Rate               0\n",
       "Num_of_Loan                 0\n",
       "Monthly_Inhand_Salary       0\n",
       "Changed_Credit_Limit        0\n",
       "Outstanding_Debt            0\n",
       "Total_EMI_per_month         0\n",
       "dtype: int64"
      ]
     },
     "execution_count": 12,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df.isnull().sum()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "executionInfo": {
     "elapsed": 254,
     "status": "ok",
     "timestamp": 1705611177410,
     "user": {
      "displayName": "Canan Dülgeroğlu",
      "userId": "00060531196188721276"
     },
     "user_tz": -180
    },
    "id": "t60zfZG3vcru",
    "outputId": "050a0c8a-1045-46d8-c1b6-df16e8696c48"
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "Yes    52326\n",
       "No     35628\n",
       "NM     12006\n",
       "Name: Payment_of_Min_Amount, dtype: int64"
      ]
     },
     "execution_count": 9,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df.Payment_of_Min_Amount.value_counts()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "executionInfo": {
     "elapsed": 295,
     "status": "ok",
     "timestamp": 1705611216762,
     "user": {
      "displayName": "Canan Dülgeroğlu",
      "userId": "00060531196188721276"
     },
     "user_tz": -180
    },
    "id": "-Akrjh6yVrWg",
    "outputId": "08dde01c-7944-4f07-9a1a-83e272a129eb"
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "Standard    53149\n",
       "Poor        28988\n",
       "Good        17823\n",
       "Name: Credit_Score, dtype: int64"
      ]
     },
     "execution_count": 10,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df.Credit_Score.value_counts()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "executionInfo": {
     "elapsed": 241,
     "status": "ok",
     "timestamp": 1705611238370,
     "user": {
      "displayName": "Canan Dülgeroğlu",
      "userId": "00060531196188721276"
     },
     "user_tz": -180
    },
    "id": "irobRu5eWcQC",
    "outputId": "41dcdb26-f0c0-48af-8a32-a513678e661b"
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "Standard    45832\n",
       "Good        30360\n",
       "Bad         23768\n",
       "Name: Credit_Mix, dtype: int64"
      ]
     },
     "execution_count": 11,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df.Credit_Mix.value_counts()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 734,
     "output_embedded_package_id": "1Jn8RrsFWX22QSkBHiFiGp7C0SsyTC2a7"
    },
    "executionInfo": {
     "elapsed": 130705,
     "status": "ok",
     "timestamp": 1705617788473,
     "user": {
      "displayName": "Canan Dülgeroğlu",
      "userId": "00060531196188721276"
     },
     "user_tz": -180
    },
    "id": "qOeAs_KBuYs1",
    "outputId": "9ba883a3-5b9c-407e-9b7d-fafa5c6defd8"
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "Output hidden; open in https://colab.research.google.com to view."
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "sns.pairplot(df, corner=True);"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 473
    },
    "executionInfo": {
     "elapsed": 1964,
     "status": "ok",
     "timestamp": 1705617482144,
     "user": {
      "displayName": "Canan Dülgeroğlu",
      "userId": "00060531196188721276"
     },
     "user_tz": -180
    },
    "id": "1bvWnOCIWhin",
    "outputId": "a79ee3af-1a39-4467-a1ae-e9adeeeff585"
   },
   "outputs": [
    {
     "data": {
      "image/png": "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\n",
      "text/plain": [
       "<Figure size 1200x600 with 2 Axes>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "sns.heatmap(df.corr(), annot=True);"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 675
    },
    "executionInfo": {
     "elapsed": 485,
     "status": "ok",
     "timestamp": 1705618635139,
     "user": {
      "displayName": "Canan Dülgeroğlu",
      "userId": "00060531196188721276"
     },
     "user_tz": -180
    },
    "id": "4IZNhpTIycrv",
    "outputId": "193b3abe-7844-4297-e40d-f26a0c0b3dd7"
   },
   "outputs": [
    {
     "data": {
      "image/png": "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\n",
      "text/plain": [
       "<Figure size 800x800 with 1 Axes>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "plt.figure(figsize=(8, 8))\n",
    "plt.pie(df['Credit_Score'].value_counts(), labels=df['Credit_Score'].unique(), autopct='%1.1f%%', startangle=140)\n",
    "plt.title('Distribution of Credit Scores')\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "executionInfo": {
     "elapsed": 238,
     "status": "ok",
     "timestamp": 1705663331333,
     "user": {
      "displayName": "Canan Dülgeroğlu",
      "userId": "00060531196188721276"
     },
     "user_tz": -180
    },
    "id": "92eK78tcnGOX",
    "outputId": "d029a8b5-cb54-4e36-dc84-1d10bc050438"
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "0    0\n",
       "1    0\n",
       "2    0\n",
       "3    0\n",
       "4    0\n",
       "Name: Credit_Score, dtype: int64"
      ]
     },
     "execution_count": 4,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Encoding Target\n",
    "from sklearn.preprocessing import LabelEncoder\n",
    "df[\"Credit_Score\"] = LabelEncoder().fit_transform(df[\"Credit_Score\"])\n",
    "df[\"Credit_Score\"].head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "executionInfo": {
     "elapsed": 8946,
     "status": "ok",
     "timestamp": 1705653881745,
     "user": {
      "displayName": "Canan Dülgeroğlu",
      "userId": "00060531196188721276"
     },
     "user_tz": -180
    },
    "id": "uBrFWGN-z67i",
    "outputId": "0ebbeaeb-764f-4c78-c290-6ed4d7f39de6",
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Collecting category_encoders\n",
      "  Downloading category_encoders-2.6.3-py2.py3-none-any.whl.metadata (8.0 kB)\n",
      "Requirement already satisfied: numpy>=1.14.0 in /Users/canan/anaconda3/envs/yeni_ortam/lib/python3.10/site-packages (from category_encoders) (1.26.3)\n",
      "Requirement already satisfied: scikit-learn>=0.20.0 in /Users/canan/anaconda3/envs/yeni_ortam/lib/python3.10/site-packages (from category_encoders) (1.1.2)\n",
      "Requirement already satisfied: scipy>=1.0.0 in /Users/canan/anaconda3/envs/yeni_ortam/lib/python3.10/site-packages (from category_encoders) (1.11.2)\n",
      "Requirement already satisfied: statsmodels>=0.9.0 in /Users/canan/anaconda3/envs/yeni_ortam/lib/python3.10/site-packages (from category_encoders) (0.14.0)\n",
      "Requirement already satisfied: pandas>=1.0.5 in /Users/canan/anaconda3/envs/yeni_ortam/lib/python3.10/site-packages (from category_encoders) (1.4.3)\n",
      "Requirement already satisfied: patsy>=0.5.1 in /Users/canan/anaconda3/envs/yeni_ortam/lib/python3.10/site-packages (from category_encoders) (0.5.3)\n",
      "Requirement already satisfied: python-dateutil>=2.8.1 in /Users/canan/anaconda3/envs/yeni_ortam/lib/python3.10/site-packages (from pandas>=1.0.5->category_encoders) (2.8.2)\n",
      "Requirement already satisfied: pytz>=2020.1 in /Users/canan/anaconda3/envs/yeni_ortam/lib/python3.10/site-packages (from pandas>=1.0.5->category_encoders) (2023.3.post1)\n",
      "Requirement already satisfied: six in /Users/canan/anaconda3/envs/yeni_ortam/lib/python3.10/site-packages (from patsy>=0.5.1->category_encoders) (1.16.0)\n",
      "Requirement already satisfied: joblib>=1.0.0 in /Users/canan/anaconda3/envs/yeni_ortam/lib/python3.10/site-packages (from scikit-learn>=0.20.0->category_encoders) (1.3.2)\n",
      "Requirement already satisfied: threadpoolctl>=2.0.0 in /Users/canan/anaconda3/envs/yeni_ortam/lib/python3.10/site-packages (from scikit-learn>=0.20.0->category_encoders) (3.2.0)\n",
      "Requirement already satisfied: packaging>=21.3 in /Users/canan/anaconda3/envs/yeni_ortam/lib/python3.10/site-packages (from statsmodels>=0.9.0->category_encoders) (23.1)\n",
      "Downloading category_encoders-2.6.3-py2.py3-none-any.whl (81 kB)\n",
      "\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m81.9/81.9 kB\u001b[0m \u001b[31m492.3 kB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\u001b[36m0:00:01\u001b[0m\n",
      "\u001b[?25hInstalling collected packages: category_encoders\n",
      "Successfully installed category_encoders-2.6.3\n",
      "Note: you may need to restart the kernel to use updated packages.\n"
     ]
    }
   ],
   "source": [
    "pip install category_encoders"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 708
    },
    "executionInfo": {
     "elapsed": 601,
     "status": "ok",
     "timestamp": 1705663351115,
     "user": {
      "displayName": "Canan Dülgeroğlu",
      "userId": "00060531196188721276"
     },
     "user_tz": -180
    },
    "id": "bLunf8jInGHk",
    "outputId": "405e47ce-4a5f-4c5b-868d-a318cec7706a"
   },
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>0</th>\n",
       "      <th>1</th>\n",
       "      <th>2</th>\n",
       "      <th>3</th>\n",
       "      <th>4</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>Delay_from_due_date</th>\n",
       "      <td>3.000</td>\n",
       "      <td>3.000</td>\n",
       "      <td>3.000</td>\n",
       "      <td>5.000</td>\n",
       "      <td>6.000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>Num_of_Delayed_Payment</th>\n",
       "      <td>7.000</td>\n",
       "      <td>7.000</td>\n",
       "      <td>7.000</td>\n",
       "      <td>4.000</td>\n",
       "      <td>4.000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>Num_Credit_Inquiries</th>\n",
       "      <td>4.000</td>\n",
       "      <td>4.000</td>\n",
       "      <td>4.000</td>\n",
       "      <td>4.000</td>\n",
       "      <td>4.000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>Credit_Utilization_Ratio</th>\n",
       "      <td>26.823</td>\n",
       "      <td>31.945</td>\n",
       "      <td>28.609</td>\n",
       "      <td>31.378</td>\n",
       "      <td>24.797</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>Credit_History_Age</th>\n",
       "      <td>265.000</td>\n",
       "      <td>265.000</td>\n",
       "      <td>267.000</td>\n",
       "      <td>268.000</td>\n",
       "      <td>269.000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>Payment_of_Min_Amount</th>\n",
       "      <td>1.099</td>\n",
       "      <td>1.099</td>\n",
       "      <td>1.099</td>\n",
       "      <td>1.099</td>\n",
       "      <td>1.099</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>Amount_invested_monthly</th>\n",
       "      <td>80.415</td>\n",
       "      <td>118.280</td>\n",
       "      <td>81.700</td>\n",
       "      <td>199.458</td>\n",
       "      <td>41.420</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>Monthly_Balance</th>\n",
       "      <td>312.494</td>\n",
       "      <td>284.629</td>\n",
       "      <td>331.210</td>\n",
       "      <td>223.451</td>\n",
       "      <td>341.489</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>Credit_Score</th>\n",
       "      <td>0.000</td>\n",
       "      <td>0.000</td>\n",
       "      <td>0.000</td>\n",
       "      <td>0.000</td>\n",
       "      <td>0.000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>Credit_Mix</th>\n",
       "      <td>0.863</td>\n",
       "      <td>0.863</td>\n",
       "      <td>0.863</td>\n",
       "      <td>0.863</td>\n",
       "      <td>0.863</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>Payment_Behaviour</th>\n",
       "      <td>1.348</td>\n",
       "      <td>1.348</td>\n",
       "      <td>1.348</td>\n",
       "      <td>1.348</td>\n",
       "      <td>1.348</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>Age</th>\n",
       "      <td>23.000</td>\n",
       "      <td>23.000</td>\n",
       "      <td>23.000</td>\n",
       "      <td>23.000</td>\n",
       "      <td>23.000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>Annual_Income</th>\n",
       "      <td>19114.120</td>\n",
       "      <td>19114.120</td>\n",
       "      <td>19114.120</td>\n",
       "      <td>19114.120</td>\n",
       "      <td>19114.120</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>Num_Bank_Accounts</th>\n",
       "      <td>3.000</td>\n",
       "      <td>3.000</td>\n",
       "      <td>3.000</td>\n",
       "      <td>3.000</td>\n",
       "      <td>3.000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>Num_Credit_Card</th>\n",
       "      <td>4.000</td>\n",
       "      <td>4.000</td>\n",
       "      <td>4.000</td>\n",
       "      <td>4.000</td>\n",
       "      <td>4.000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>Interest_Rate</th>\n",
       "      <td>3.000</td>\n",
       "      <td>3.000</td>\n",
       "      <td>3.000</td>\n",
       "      <td>3.000</td>\n",
       "      <td>3.000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>Num_of_Loan</th>\n",
       "      <td>4.000</td>\n",
       "      <td>4.000</td>\n",
       "      <td>4.000</td>\n",
       "      <td>4.000</td>\n",
       "      <td>4.000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>Monthly_Inhand_Salary</th>\n",
       "      <td>1824.843</td>\n",
       "      <td>1824.843</td>\n",
       "      <td>1824.843</td>\n",
       "      <td>1824.843</td>\n",
       "      <td>1824.843</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>Changed_Credit_Limit</th>\n",
       "      <td>11.270</td>\n",
       "      <td>11.270</td>\n",
       "      <td>11.270</td>\n",
       "      <td>11.270</td>\n",
       "      <td>11.270</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>Outstanding_Debt</th>\n",
       "      <td>809.980</td>\n",
       "      <td>809.980</td>\n",
       "      <td>809.980</td>\n",
       "      <td>809.980</td>\n",
       "      <td>809.980</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>Total_EMI_per_month</th>\n",
       "      <td>49.575</td>\n",
       "      <td>49.575</td>\n",
       "      <td>49.575</td>\n",
       "      <td>49.575</td>\n",
       "      <td>49.575</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "                                 0         1         2         3         4\n",
       "Delay_from_due_date          3.000     3.000     3.000     5.000     6.000\n",
       "Num_of_Delayed_Payment       7.000     7.000     7.000     4.000     4.000\n",
       "Num_Credit_Inquiries         4.000     4.000     4.000     4.000     4.000\n",
       "Credit_Utilization_Ratio    26.823    31.945    28.609    31.378    24.797\n",
       "Credit_History_Age         265.000   265.000   267.000   268.000   269.000\n",
       "Payment_of_Min_Amount        1.099     1.099     1.099     1.099     1.099\n",
       "Amount_invested_monthly     80.415   118.280    81.700   199.458    41.420\n",
       "Monthly_Balance            312.494   284.629   331.210   223.451   341.489\n",
       "Credit_Score                 0.000     0.000     0.000     0.000     0.000\n",
       "Credit_Mix                   0.863     0.863     0.863     0.863     0.863\n",
       "Payment_Behaviour            1.348     1.348     1.348     1.348     1.348\n",
       "Age                         23.000    23.000    23.000    23.000    23.000\n",
       "Annual_Income            19114.120 19114.120 19114.120 19114.120 19114.120\n",
       "Num_Bank_Accounts            3.000     3.000     3.000     3.000     3.000\n",
       "Num_Credit_Card              4.000     4.000     4.000     4.000     4.000\n",
       "Interest_Rate                3.000     3.000     3.000     3.000     3.000\n",
       "Num_of_Loan                  4.000     4.000     4.000     4.000     4.000\n",
       "Monthly_Inhand_Salary     1824.843  1824.843  1824.843  1824.843  1824.843\n",
       "Changed_Credit_Limit        11.270    11.270    11.270    11.270    11.270\n",
       "Outstanding_Debt           809.980   809.980   809.980   809.980   809.980\n",
       "Total_EMI_per_month         49.575    49.575    49.575    49.575    49.575"
      ]
     },
     "execution_count": 7,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "import category_encoders as ce\n",
    "\n",
    "columns = ['Payment_of_Min_Amount','Payment_Behaviour','Credit_Mix']\n",
    "for item in columns:\n",
    "    df[item] = ce.LeaveOneOutEncoder().fit_transform(df[item],df['Credit_Score'])\n",
    "df.head().T"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "executionInfo": {
     "elapsed": 289,
     "status": "ok",
     "timestamp": 1705620126870,
     "user": {
      "displayName": "Canan Dülgeroğlu",
      "userId": "00060531196188721276"
     },
     "user_tz": -180
    },
    "id": "c82DMc-AnGEU",
    "outputId": "268ab80c-327d-4356-ae0d-62d00393bd00"
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "Delay_from_due_date         float64\n",
       "Num_of_Delayed_Payment      float64\n",
       "Num_Credit_Inquiries        float64\n",
       "Credit_Utilization_Ratio    float64\n",
       "Credit_History_Age          float64\n",
       "Payment_of_Min_Amount       float64\n",
       "Amount_invested_monthly     float64\n",
       "Monthly_Balance             float64\n",
       "Credit_Score                  int64\n",
       "Credit_Mix                  float64\n",
       "Payment_Behaviour           float64\n",
       "Age                         float64\n",
       "Annual_Income               float64\n",
       "Num_Bank_Accounts           float64\n",
       "Num_Credit_Card             float64\n",
       "Interest_Rate               float64\n",
       "Num_of_Loan                 float64\n",
       "Monthly_Inhand_Salary       float64\n",
       "Changed_Credit_Limit        float64\n",
       "Outstanding_Debt            float64\n",
       "Total_EMI_per_month         float64\n",
       "dtype: object"
      ]
     },
     "execution_count": 8,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df.dtypes"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {
    "executionInfo": {
     "elapsed": 259,
     "status": "ok",
     "timestamp": 1705663366588,
     "user": {
      "displayName": "Canan Dülgeroğlu",
      "userId": "00060531196188721276"
     },
     "user_tz": -180
    },
    "id": "BZv0aYlm0rBI"
   },
   "outputs": [],
   "source": [
    "X=df.drop('Credit_Score',axis=1)\n",
    "y = df.Credit_Score"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 225,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>0</th>\n",
       "      <th>1</th>\n",
       "      <th>2</th>\n",
       "      <th>3</th>\n",
       "      <th>4</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>Delay_from_due_date</th>\n",
       "      <td>3.000</td>\n",
       "      <td>3.000</td>\n",
       "      <td>3.000</td>\n",
       "      <td>5.000</td>\n",
       "      <td>6.000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>Num_of_Delayed_Payment</th>\n",
       "      <td>7.000</td>\n",
       "      <td>7.000</td>\n",
       "      <td>7.000</td>\n",
       "      <td>4.000</td>\n",
       "      <td>4.000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>Num_Credit_Inquiries</th>\n",
       "      <td>4.000</td>\n",
       "      <td>4.000</td>\n",
       "      <td>4.000</td>\n",
       "      <td>4.000</td>\n",
       "      <td>4.000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>Credit_Utilization_Ratio</th>\n",
       "      <td>26.823</td>\n",
       "      <td>31.945</td>\n",
       "      <td>28.609</td>\n",
       "      <td>31.378</td>\n",
       "      <td>24.797</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>Credit_History_Age</th>\n",
       "      <td>265.000</td>\n",
       "      <td>265.000</td>\n",
       "      <td>267.000</td>\n",
       "      <td>268.000</td>\n",
       "      <td>269.000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>Payment_of_Min_Amount</th>\n",
       "      <td>1.099</td>\n",
       "      <td>1.099</td>\n",
       "      <td>1.099</td>\n",
       "      <td>1.099</td>\n",
       "      <td>1.099</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>Amount_invested_monthly</th>\n",
       "      <td>80.415</td>\n",
       "      <td>118.280</td>\n",
       "      <td>81.700</td>\n",
       "      <td>199.458</td>\n",
       "      <td>41.420</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>Monthly_Balance</th>\n",
       "      <td>312.494</td>\n",
       "      <td>284.629</td>\n",
       "      <td>331.210</td>\n",
       "      <td>223.451</td>\n",
       "      <td>341.489</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>Credit_Score</th>\n",
       "      <td>0.000</td>\n",
       "      <td>0.000</td>\n",
       "      <td>0.000</td>\n",
       "      <td>0.000</td>\n",
       "      <td>0.000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>Credit_Mix</th>\n",
       "      <td>0.863</td>\n",
       "      <td>0.863</td>\n",
       "      <td>0.863</td>\n",
       "      <td>0.863</td>\n",
       "      <td>0.863</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>Payment_Behaviour</th>\n",
       "      <td>1.348</td>\n",
       "      <td>1.348</td>\n",
       "      <td>1.348</td>\n",
       "      <td>1.348</td>\n",
       "      <td>1.348</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>Age</th>\n",
       "      <td>23.000</td>\n",
       "      <td>23.000</td>\n",
       "      <td>23.000</td>\n",
       "      <td>23.000</td>\n",
       "      <td>23.000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>Num_Bank_Accounts</th>\n",
       "      <td>3.000</td>\n",
       "      <td>3.000</td>\n",
       "      <td>3.000</td>\n",
       "      <td>3.000</td>\n",
       "      <td>3.000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>Num_Credit_Card</th>\n",
       "      <td>4.000</td>\n",
       "      <td>4.000</td>\n",
       "      <td>4.000</td>\n",
       "      <td>4.000</td>\n",
       "      <td>4.000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>Interest_Rate</th>\n",
       "      <td>3.000</td>\n",
       "      <td>3.000</td>\n",
       "      <td>3.000</td>\n",
       "      <td>3.000</td>\n",
       "      <td>3.000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>Num_of_Loan</th>\n",
       "      <td>4.000</td>\n",
       "      <td>4.000</td>\n",
       "      <td>4.000</td>\n",
       "      <td>4.000</td>\n",
       "      <td>4.000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>Monthly_Inhand_Salary</th>\n",
       "      <td>1824.843</td>\n",
       "      <td>1824.843</td>\n",
       "      <td>1824.843</td>\n",
       "      <td>1824.843</td>\n",
       "      <td>1824.843</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>Changed_Credit_Limit</th>\n",
       "      <td>11.270</td>\n",
       "      <td>11.270</td>\n",
       "      <td>11.270</td>\n",
       "      <td>11.270</td>\n",
       "      <td>11.270</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>Outstanding_Debt</th>\n",
       "      <td>809.980</td>\n",
       "      <td>809.980</td>\n",
       "      <td>809.980</td>\n",
       "      <td>809.980</td>\n",
       "      <td>809.980</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>Total_EMI_per_month</th>\n",
       "      <td>49.575</td>\n",
       "      <td>49.575</td>\n",
       "      <td>49.575</td>\n",
       "      <td>49.575</td>\n",
       "      <td>49.575</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "                                0        1        2        3        4\n",
       "Delay_from_due_date         3.000    3.000    3.000    5.000    6.000\n",
       "Num_of_Delayed_Payment      7.000    7.000    7.000    4.000    4.000\n",
       "Num_Credit_Inquiries        4.000    4.000    4.000    4.000    4.000\n",
       "Credit_Utilization_Ratio   26.823   31.945   28.609   31.378   24.797\n",
       "Credit_History_Age        265.000  265.000  267.000  268.000  269.000\n",
       "Payment_of_Min_Amount       1.099    1.099    1.099    1.099    1.099\n",
       "Amount_invested_monthly    80.415  118.280   81.700  199.458   41.420\n",
       "Monthly_Balance           312.494  284.629  331.210  223.451  341.489\n",
       "Credit_Score                0.000    0.000    0.000    0.000    0.000\n",
       "Credit_Mix                  0.863    0.863    0.863    0.863    0.863\n",
       "Payment_Behaviour           1.348    1.348    1.348    1.348    1.348\n",
       "Age                        23.000   23.000   23.000   23.000   23.000\n",
       "Num_Bank_Accounts           3.000    3.000    3.000    3.000    3.000\n",
       "Num_Credit_Card             4.000    4.000    4.000    4.000    4.000\n",
       "Interest_Rate               3.000    3.000    3.000    3.000    3.000\n",
       "Num_of_Loan                 4.000    4.000    4.000    4.000    4.000\n",
       "Monthly_Inhand_Salary    1824.843 1824.843 1824.843 1824.843 1824.843\n",
       "Changed_Credit_Limit       11.270   11.270   11.270   11.270   11.270\n",
       "Outstanding_Debt          809.980  809.980  809.980  809.980  809.980\n",
       "Total_EMI_per_month        49.575   49.575   49.575   49.575   49.575"
      ]
     },
     "execution_count": 225,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df.head().T"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 221,
   "metadata": {},
   "outputs": [],
   "source": [
    "X=df1.drop('Credit_Score',axis=1)\n",
    "y = df1.Credit_Score"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 223,
   "metadata": {
    "collapsed": true,
    "executionInfo": {
     "elapsed": 5656,
     "status": "ok",
     "timestamp": 1705663374851,
     "user": {
      "displayName": "Canan Dülgeroğlu",
      "userId": "00060531196188721276"
     },
     "user_tz": -180
    },
    "id": "csYP6fTY0h4X"
   },
   "outputs": [
    {
     "ename": "ValueError",
     "evalue": "could not convert string to float: 'No'",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mValueError\u001b[0m                                Traceback (most recent call last)",
      "\u001b[0;32m/var/folders/gc/dgrq1wb15vj3d0ks8rg135nm0000gn/T/ipykernel_7913/2820661099.py\u001b[0m in \u001b[0;36m?\u001b[0;34m()\u001b[0m\n\u001b[1;32m      1\u001b[0m \u001b[0;31m# Feature Selection With VIF\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m      2\u001b[0m \u001b[0;32mfrom\u001b[0m \u001b[0mimblearn\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mover_sampling\u001b[0m \u001b[0;32mimport\u001b[0m \u001b[0mSMOTE\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m      3\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m      4\u001b[0m \u001b[0msmote\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mSMOTE\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m \u001b[0;31m# Synthetic Minority Oversampling TEchnique\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m----> 5\u001b[0;31m \u001b[0mX\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0my\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0msmote\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mfit_resample\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mX\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0my\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m",
      "\u001b[0;32m~/anaconda3/envs/yeni_ortam/lib/python3.10/site-packages/imblearn/base.py\u001b[0m in \u001b[0;36m?\u001b[0;34m(self, X, y)\u001b[0m\n\u001b[1;32m    204\u001b[0m         \u001b[0my_resampled\u001b[0m \u001b[0;34m:\u001b[0m \u001b[0marray\u001b[0m\u001b[0;34m-\u001b[0m\u001b[0mlike\u001b[0m \u001b[0mof\u001b[0m \u001b[0mshape\u001b[0m \u001b[0;34m(\u001b[0m\u001b[0mn_samples_new\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    205\u001b[0m             \u001b[0mThe\u001b[0m \u001b[0mcorresponding\u001b[0m \u001b[0mlabel\u001b[0m \u001b[0mof\u001b[0m\u001b[0;31m \u001b[0m\u001b[0;31m`\u001b[0m\u001b[0mX_resampled\u001b[0m\u001b[0;31m`\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    206\u001b[0m         \"\"\"\n\u001b[1;32m    207\u001b[0m         \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_validate_params\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 208\u001b[0;31m         \u001b[0;32mreturn\u001b[0m \u001b[0msuper\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mfit_resample\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mX\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0my\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m",
      "\u001b[0;32m~/anaconda3/envs/yeni_ortam/lib/python3.10/site-packages/imblearn/base.py\u001b[0m in \u001b[0;36m?\u001b[0;34m(self, X, y)\u001b[0m\n\u001b[1;32m    102\u001b[0m             \u001b[0mThe\u001b[0m \u001b[0mcorresponding\u001b[0m \u001b[0mlabel\u001b[0m \u001b[0mof\u001b[0m\u001b[0;31m \u001b[0m\u001b[0;31m`\u001b[0m\u001b[0mX_resampled\u001b[0m\u001b[0;31m`\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    103\u001b[0m         \"\"\"\n\u001b[1;32m    104\u001b[0m         \u001b[0mcheck_classification_targets\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0my\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    105\u001b[0m         \u001b[0marrays_transformer\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mArraysTransformer\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mX\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0my\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 106\u001b[0;31m         \u001b[0mX\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0my\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mbinarize_y\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_check_X_y\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mX\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0my\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    107\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    108\u001b[0m         self.sampling_strategy_ = check_sampling_strategy(\n\u001b[1;32m    109\u001b[0m             \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0msampling_strategy\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0my\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_sampling_type\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m~/anaconda3/envs/yeni_ortam/lib/python3.10/site-packages/imblearn/base.py\u001b[0m in \u001b[0;36m?\u001b[0;34m(self, X, y, accept_sparse)\u001b[0m\n\u001b[1;32m    157\u001b[0m     \u001b[0;32mdef\u001b[0m \u001b[0m_check_X_y\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mX\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0my\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0maccept_sparse\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;32mNone\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    158\u001b[0m         \u001b[0;32mif\u001b[0m \u001b[0maccept_sparse\u001b[0m \u001b[0;32mis\u001b[0m \u001b[0;32mNone\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    159\u001b[0m             \u001b[0maccept_sparse\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0;34m[\u001b[0m\u001b[0;34m\"csr\"\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m\"csc\"\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    160\u001b[0m         \u001b[0my\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mbinarize_y\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mcheck_target_type\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0my\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mindicate_one_vs_all\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;32mTrue\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 161\u001b[0;31m         \u001b[0mX\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0my\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_validate_data\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mX\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0my\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mreset\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;32mTrue\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0maccept_sparse\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0maccept_sparse\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    162\u001b[0m         \u001b[0;32mreturn\u001b[0m \u001b[0mX\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0my\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mbinarize_y\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m~/anaconda3/envs/yeni_ortam/lib/python3.10/site-packages/sklearn/base.py\u001b[0m in \u001b[0;36m?\u001b[0;34m(self, X, y, reset, validate_separately, **check_params)\u001b[0m\n\u001b[1;32m    592\u001b[0m                 \u001b[0;32mif\u001b[0m \u001b[0;34m\"estimator\"\u001b[0m \u001b[0;32mnot\u001b[0m \u001b[0;32min\u001b[0m \u001b[0mcheck_y_params\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    593\u001b[0m                     \u001b[0mcheck_y_params\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0;34m{\u001b[0m\u001b[0;34m**\u001b[0m\u001b[0mdefault_check_params\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m**\u001b[0m\u001b[0mcheck_y_params\u001b[0m\u001b[0;34m}\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    594\u001b[0m                 \u001b[0my\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mcheck_array\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0my\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0minput_name\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;34m\"y\"\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m**\u001b[0m\u001b[0mcheck_y_params\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    595\u001b[0m             \u001b[0;32melse\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 596\u001b[0;31m                 \u001b[0mX\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0my\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mcheck_X_y\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mX\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0my\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m**\u001b[0m\u001b[0mcheck_params\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    597\u001b[0m             \u001b[0mout\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mX\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0my\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    598\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    599\u001b[0m         \u001b[0;32mif\u001b[0m \u001b[0;32mnot\u001b[0m \u001b[0mno_val_X\u001b[0m \u001b[0;32mand\u001b[0m \u001b[0mcheck_params\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mget\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m\"ensure_2d\"\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;32mTrue\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m~/anaconda3/envs/yeni_ortam/lib/python3.10/site-packages/sklearn/utils/validation.py\u001b[0m in \u001b[0;36m?\u001b[0;34m(X, y, accept_sparse, accept_large_sparse, dtype, order, copy, force_all_finite, ensure_2d, allow_nd, multi_output, ensure_min_samples, ensure_min_features, y_numeric, estimator)\u001b[0m\n\u001b[1;32m   1070\u001b[0m         raise ValueError(\n\u001b[1;32m   1071\u001b[0m             \u001b[0;34mf\"{estimator_name} requires y to be passed, but the target y is None\"\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1072\u001b[0m         )\n\u001b[1;32m   1073\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m-> 1074\u001b[0;31m     X = check_array(\n\u001b[0m\u001b[1;32m   1075\u001b[0m         \u001b[0mX\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1076\u001b[0m         \u001b[0maccept_sparse\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0maccept_sparse\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1077\u001b[0m         \u001b[0maccept_large_sparse\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0maccept_large_sparse\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m~/anaconda3/envs/yeni_ortam/lib/python3.10/site-packages/sklearn/utils/validation.py\u001b[0m in \u001b[0;36m?\u001b[0;34m(array, accept_sparse, accept_large_sparse, dtype, order, copy, force_all_finite, ensure_2d, allow_nd, ensure_min_samples, ensure_min_features, estimator, input_name)\u001b[0m\n\u001b[1;32m    853\u001b[0m                         )\n\u001b[1;32m    854\u001b[0m                     \u001b[0marray\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0marray\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mastype\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mdtype\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mcasting\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;34m\"unsafe\"\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mcopy\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;32mFalse\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    855\u001b[0m                 \u001b[0;32melse\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    856\u001b[0m                     \u001b[0marray\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mnp\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0masarray\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0marray\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0morder\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0morder\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mdtype\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mdtype\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 857\u001b[0;31m             \u001b[0;32mexcept\u001b[0m \u001b[0mComplexWarning\u001b[0m \u001b[0;32mas\u001b[0m \u001b[0mcomplex_warning\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    858\u001b[0m                 raise ValueError(\n\u001b[1;32m    859\u001b[0m                     \u001b[0;34m\"Complex data not supported\\n{}\\n\"\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mformat\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0marray\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    860\u001b[0m                 ) from complex_warning\n",
      "\u001b[0;32m~/anaconda3/envs/yeni_ortam/lib/python3.10/site-packages/pandas/core/generic.py\u001b[0m in \u001b[0;36m?\u001b[0;34m(self, dtype)\u001b[0m\n\u001b[1;32m   2063\u001b[0m     \u001b[0;32mdef\u001b[0m \u001b[0m__array__\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mdtype\u001b[0m\u001b[0;34m:\u001b[0m \u001b[0mnpt\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mDTypeLike\u001b[0m \u001b[0;34m|\u001b[0m \u001b[0;32mNone\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0;32mNone\u001b[0m\u001b[0;34m)\u001b[0m \u001b[0;34m->\u001b[0m \u001b[0mnp\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mndarray\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m-> 2064\u001b[0;31m         \u001b[0;32mreturn\u001b[0m \u001b[0mnp\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0masarray\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_values\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mdtype\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mdtype\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m",
      "\u001b[0;31mValueError\u001b[0m: could not convert string to float: 'No'"
     ]
    }
   ],
   "source": [
    "# Feature Selection With VIF\n",
    "from imblearn.over_sampling import SMOTE\n",
    "\n",
    "smote = SMOTE() # Synthetic Minority Oversampling TEchnique\n",
    "X, y = smote.fit_resample(X,y)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 645
    },
    "executionInfo": {
     "elapsed": 4383,
     "status": "ok",
     "timestamp": 1705654035990,
     "user": {
      "displayName": "Canan Dülgeroğlu",
      "userId": "00060531196188721276"
     },
     "user_tz": -180
    },
    "id": "Eo5swIyT3b0C",
    "outputId": "7a29e0ac-5007-46f5-c044-8cd1abddc3d3"
   },
   "outputs": [
    {
     "data": {
      "text/html": [
       "\n",
       "  <div id=\"df-59a1085f-429e-4aca-a6e2-3d975f5d1ca5\" class=\"colab-df-container\">\n",
       "    <div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>target</th>\n",
       "      <th>VIF</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>Delay_from_due_date</td>\n",
       "      <td>6.021</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>Num_of_Delayed_Payment</td>\n",
       "      <td>11.518</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>Num_Credit_Inquiries</td>\n",
       "      <td>7.449</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>Credit_Utilization_Ratio</td>\n",
       "      <td>42.943</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>Credit_History_Age</td>\n",
       "      <td>12.961</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>5</th>\n",
       "      <td>Payment_of_Min_Amount</td>\n",
       "      <td>130.692</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>6</th>\n",
       "      <td>Amount_invested_monthly</td>\n",
       "      <td>8.777</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>7</th>\n",
       "      <td>Monthly_Balance</td>\n",
       "      <td>28.956</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>8</th>\n",
       "      <td>Credit_Mix</td>\n",
       "      <td>36.745</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>9</th>\n",
       "      <td>Payment_Behaviour</td>\n",
       "      <td>169.486</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>10</th>\n",
       "      <td>Age</td>\n",
       "      <td>11.486</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>11</th>\n",
       "      <td>Num_Bank_Accounts</td>\n",
       "      <td>11.185</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>12</th>\n",
       "      <td>Num_Credit_Card</td>\n",
       "      <td>12.474</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>13</th>\n",
       "      <td>Interest_Rate</td>\n",
       "      <td>9.680</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>14</th>\n",
       "      <td>Num_of_Loan</td>\n",
       "      <td>9.059</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>15</th>\n",
       "      <td>Monthly_Inhand_Salary</td>\n",
       "      <td>29.089</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>16</th>\n",
       "      <td>Changed_Credit_Limit</td>\n",
       "      <td>5.461</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>17</th>\n",
       "      <td>Outstanding_Debt</td>\n",
       "      <td>7.293</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>18</th>\n",
       "      <td>Total_EMI_per_month</td>\n",
       "      <td>3.167</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>\n",
       "    <div class=\"colab-df-buttons\">\n",
       "\n",
       "  <div class=\"colab-df-container\">\n",
       "    <button class=\"colab-df-convert\" onclick=\"convertToInteractive('df-59a1085f-429e-4aca-a6e2-3d975f5d1ca5')\"\n",
       "            title=\"Convert this dataframe to an interactive table.\"\n",
       "            style=\"display:none;\">\n",
       "\n",
       "  <svg xmlns=\"http://www.w3.org/2000/svg\" height=\"24px\" viewBox=\"0 -960 960 960\">\n",
       "    <path d=\"M120-120v-720h720v720H120Zm60-500h600v-160H180v160Zm220 220h160v-160H400v160Zm0 220h160v-160H400v160ZM180-400h160v-160H180v160Zm440 0h160v-160H620v160ZM180-180h160v-160H180v160Zm440 0h160v-160H620v160Z\"/>\n",
       "  </svg>\n",
       "    </button>\n",
       "\n",
       "  <style>\n",
       "    .colab-df-container {\n",
       "      display:flex;\n",
       "      gap: 12px;\n",
       "    }\n",
       "\n",
       "    .colab-df-convert {\n",
       "      background-color: #E8F0FE;\n",
       "      border: none;\n",
       "      border-radius: 50%;\n",
       "      cursor: pointer;\n",
       "      display: none;\n",
       "      fill: #1967D2;\n",
       "      height: 32px;\n",
       "      padding: 0 0 0 0;\n",
       "      width: 32px;\n",
       "    }\n",
       "\n",
       "    .colab-df-convert:hover {\n",
       "      background-color: #E2EBFA;\n",
       "      box-shadow: 0px 1px 2px rgba(60, 64, 67, 0.3), 0px 1px 3px 1px rgba(60, 64, 67, 0.15);\n",
       "      fill: #174EA6;\n",
       "    }\n",
       "\n",
       "    .colab-df-buttons div {\n",
       "      margin-bottom: 4px;\n",
       "    }\n",
       "\n",
       "    [theme=dark] .colab-df-convert {\n",
       "      background-color: #3B4455;\n",
       "      fill: #D2E3FC;\n",
       "    }\n",
       "\n",
       "    [theme=dark] .colab-df-convert:hover {\n",
       "      background-color: #434B5C;\n",
       "      box-shadow: 0px 1px 3px 1px rgba(0, 0, 0, 0.15);\n",
       "      filter: drop-shadow(0px 1px 2px rgba(0, 0, 0, 0.3));\n",
       "      fill: #FFFFFF;\n",
       "    }\n",
       "  </style>\n",
       "\n",
       "    <script>\n",
       "      const buttonEl =\n",
       "        document.querySelector('#df-59a1085f-429e-4aca-a6e2-3d975f5d1ca5 button.colab-df-convert');\n",
       "      buttonEl.style.display =\n",
       "        google.colab.kernel.accessAllowed ? 'block' : 'none';\n",
       "\n",
       "      async function convertToInteractive(key) {\n",
       "        const element = document.querySelector('#df-59a1085f-429e-4aca-a6e2-3d975f5d1ca5');\n",
       "        const dataTable =\n",
       "          await google.colab.kernel.invokeFunction('convertToInteractive',\n",
       "                                                    [key], {});\n",
       "        if (!dataTable) return;\n",
       "\n",
       "        const docLinkHtml = 'Like what you see? Visit the ' +\n",
       "          '<a target=\"_blank\" href=https://colab.research.google.com/notebooks/data_table.ipynb>data table notebook</a>'\n",
       "          + ' to learn more about interactive tables.';\n",
       "        element.innerHTML = '';\n",
       "        dataTable['output_type'] = 'display_data';\n",
       "        await google.colab.output.renderOutput(dataTable, element);\n",
       "        const docLink = document.createElement('div');\n",
       "        docLink.innerHTML = docLinkHtml;\n",
       "        element.appendChild(docLink);\n",
       "      }\n",
       "    </script>\n",
       "  </div>\n",
       "\n",
       "\n",
       "<div id=\"df-db07cca8-8bed-4eec-bf16-f3b3737acfae\">\n",
       "  <button class=\"colab-df-quickchart\" onclick=\"quickchart('df-db07cca8-8bed-4eec-bf16-f3b3737acfae')\"\n",
       "            title=\"Suggest charts\"\n",
       "            style=\"display:none;\">\n",
       "\n",
       "<svg xmlns=\"http://www.w3.org/2000/svg\" height=\"24px\"viewBox=\"0 0 24 24\"\n",
       "     width=\"24px\">\n",
       "    <g>\n",
       "        <path d=\"M19 3H5c-1.1 0-2 .9-2 2v14c0 1.1.9 2 2 2h14c1.1 0 2-.9 2-2V5c0-1.1-.9-2-2-2zM9 17H7v-7h2v7zm4 0h-2V7h2v10zm4 0h-2v-4h2v4z\"/>\n",
       "    </g>\n",
       "</svg>\n",
       "  </button>\n",
       "\n",
       "<style>\n",
       "  .colab-df-quickchart {\n",
       "      --bg-color: #E8F0FE;\n",
       "      --fill-color: #1967D2;\n",
       "      --hover-bg-color: #E2EBFA;\n",
       "      --hover-fill-color: #174EA6;\n",
       "      --disabled-fill-color: #AAA;\n",
       "      --disabled-bg-color: #DDD;\n",
       "  }\n",
       "\n",
       "  [theme=dark] .colab-df-quickchart {\n",
       "      --bg-color: #3B4455;\n",
       "      --fill-color: #D2E3FC;\n",
       "      --hover-bg-color: #434B5C;\n",
       "      --hover-fill-color: #FFFFFF;\n",
       "      --disabled-bg-color: #3B4455;\n",
       "      --disabled-fill-color: #666;\n",
       "  }\n",
       "\n",
       "  .colab-df-quickchart {\n",
       "    background-color: var(--bg-color);\n",
       "    border: none;\n",
       "    border-radius: 50%;\n",
       "    cursor: pointer;\n",
       "    display: none;\n",
       "    fill: var(--fill-color);\n",
       "    height: 32px;\n",
       "    padding: 0;\n",
       "    width: 32px;\n",
       "  }\n",
       "\n",
       "  .colab-df-quickchart:hover {\n",
       "    background-color: var(--hover-bg-color);\n",
       "    box-shadow: 0 1px 2px rgba(60, 64, 67, 0.3), 0 1px 3px 1px rgba(60, 64, 67, 0.15);\n",
       "    fill: var(--button-hover-fill-color);\n",
       "  }\n",
       "\n",
       "  .colab-df-quickchart-complete:disabled,\n",
       "  .colab-df-quickchart-complete:disabled:hover {\n",
       "    background-color: var(--disabled-bg-color);\n",
       "    fill: var(--disabled-fill-color);\n",
       "    box-shadow: none;\n",
       "  }\n",
       "\n",
       "  .colab-df-spinner {\n",
       "    border: 2px solid var(--fill-color);\n",
       "    border-color: transparent;\n",
       "    border-bottom-color: var(--fill-color);\n",
       "    animation:\n",
       "      spin 1s steps(1) infinite;\n",
       "  }\n",
       "\n",
       "  @keyframes spin {\n",
       "    0% {\n",
       "      border-color: transparent;\n",
       "      border-bottom-color: var(--fill-color);\n",
       "      border-left-color: var(--fill-color);\n",
       "    }\n",
       "    20% {\n",
       "      border-color: transparent;\n",
       "      border-left-color: var(--fill-color);\n",
       "      border-top-color: var(--fill-color);\n",
       "    }\n",
       "    30% {\n",
       "      border-color: transparent;\n",
       "      border-left-color: var(--fill-color);\n",
       "      border-top-color: var(--fill-color);\n",
       "      border-right-color: var(--fill-color);\n",
       "    }\n",
       "    40% {\n",
       "      border-color: transparent;\n",
       "      border-right-color: var(--fill-color);\n",
       "      border-top-color: var(--fill-color);\n",
       "    }\n",
       "    60% {\n",
       "      border-color: transparent;\n",
       "      border-right-color: var(--fill-color);\n",
       "    }\n",
       "    80% {\n",
       "      border-color: transparent;\n",
       "      border-right-color: var(--fill-color);\n",
       "      border-bottom-color: var(--fill-color);\n",
       "    }\n",
       "    90% {\n",
       "      border-color: transparent;\n",
       "      border-bottom-color: var(--fill-color);\n",
       "    }\n",
       "  }\n",
       "</style>\n",
       "\n",
       "  <script>\n",
       "    async function quickchart(key) {\n",
       "      const quickchartButtonEl =\n",
       "        document.querySelector('#' + key + ' button');\n",
       "      quickchartButtonEl.disabled = true;  // To prevent multiple clicks.\n",
       "      quickchartButtonEl.classList.add('colab-df-spinner');\n",
       "      try {\n",
       "        const charts = await google.colab.kernel.invokeFunction(\n",
       "            'suggestCharts', [key], {});\n",
       "      } catch (error) {\n",
       "        console.error('Error during call to suggestCharts:', error);\n",
       "      }\n",
       "      quickchartButtonEl.classList.remove('colab-df-spinner');\n",
       "      quickchartButtonEl.classList.add('colab-df-quickchart-complete');\n",
       "    }\n",
       "    (() => {\n",
       "      let quickchartButtonEl =\n",
       "        document.querySelector('#df-db07cca8-8bed-4eec-bf16-f3b3737acfae button');\n",
       "      quickchartButtonEl.style.display =\n",
       "        google.colab.kernel.accessAllowed ? 'block' : 'none';\n",
       "    })();\n",
       "  </script>\n",
       "</div>\n",
       "\n",
       "  <div id=\"id_582a7f92-9e22-4955-9b27-20cbfd640aa4\">\n",
       "    <style>\n",
       "      .colab-df-generate {\n",
       "        background-color: #E8F0FE;\n",
       "        border: none;\n",
       "        border-radius: 50%;\n",
       "        cursor: pointer;\n",
       "        display: none;\n",
       "        fill: #1967D2;\n",
       "        height: 32px;\n",
       "        padding: 0 0 0 0;\n",
       "        width: 32px;\n",
       "      }\n",
       "\n",
       "      .colab-df-generate:hover {\n",
       "        background-color: #E2EBFA;\n",
       "        box-shadow: 0px 1px 2px rgba(60, 64, 67, 0.3), 0px 1px 3px 1px rgba(60, 64, 67, 0.15);\n",
       "        fill: #174EA6;\n",
       "      }\n",
       "\n",
       "      [theme=dark] .colab-df-generate {\n",
       "        background-color: #3B4455;\n",
       "        fill: #D2E3FC;\n",
       "      }\n",
       "\n",
       "      [theme=dark] .colab-df-generate:hover {\n",
       "        background-color: #434B5C;\n",
       "        box-shadow: 0px 1px 3px 1px rgba(0, 0, 0, 0.15);\n",
       "        filter: drop-shadow(0px 1px 2px rgba(0, 0, 0, 0.3));\n",
       "        fill: #FFFFFF;\n",
       "      }\n",
       "    </style>\n",
       "    <button class=\"colab-df-generate\" onclick=\"generateWithVariable('vif_data')\"\n",
       "            title=\"Generate code using this dataframe.\"\n",
       "            style=\"display:none;\">\n",
       "\n",
       "  <svg xmlns=\"http://www.w3.org/2000/svg\" height=\"24px\"viewBox=\"0 0 24 24\"\n",
       "       width=\"24px\">\n",
       "    <path d=\"M7,19H8.4L18.45,9,17,7.55,7,17.6ZM5,21V16.75L18.45,3.32a2,2,0,0,1,2.83,0l1.4,1.43a1.91,1.91,0,0,1,.58,1.4,1.91,1.91,0,0,1-.58,1.4L9.25,21ZM18.45,9,17,7.55Zm-12,3A5.31,5.31,0,0,0,4.9,8.1,5.31,5.31,0,0,0,1,6.5,5.31,5.31,0,0,0,4.9,4.9,5.31,5.31,0,0,0,6.5,1,5.31,5.31,0,0,0,8.1,4.9,5.31,5.31,0,0,0,12,6.5,5.46,5.46,0,0,0,6.5,12Z\"/>\n",
       "  </svg>\n",
       "    </button>\n",
       "    <script>\n",
       "      (() => {\n",
       "      const buttonEl =\n",
       "        document.querySelector('#id_582a7f92-9e22-4955-9b27-20cbfd640aa4 button.colab-df-generate');\n",
       "      buttonEl.style.display =\n",
       "        google.colab.kernel.accessAllowed ? 'block' : 'none';\n",
       "\n",
       "      buttonEl.onclick = () => {\n",
       "        google.colab.notebook.generateWithVariable('vif_data');\n",
       "      }\n",
       "      })();\n",
       "    </script>\n",
       "  </div>\n",
       "\n",
       "    </div>\n",
       "  </div>\n"
      ],
      "text/plain": [
       "                      target     VIF\n",
       "0        Delay_from_due_date   6.021\n",
       "1     Num_of_Delayed_Payment  11.518\n",
       "2       Num_Credit_Inquiries   7.449\n",
       "3   Credit_Utilization_Ratio  42.943\n",
       "4         Credit_History_Age  12.961\n",
       "5      Payment_of_Min_Amount 130.692\n",
       "6    Amount_invested_monthly   8.777\n",
       "7            Monthly_Balance  28.956\n",
       "8                 Credit_Mix  36.745\n",
       "9          Payment_Behaviour 169.486\n",
       "10                       Age  11.486\n",
       "11         Num_Bank_Accounts  11.185\n",
       "12           Num_Credit_Card  12.474\n",
       "13             Interest_Rate   9.680\n",
       "14               Num_of_Loan   9.059\n",
       "15     Monthly_Inhand_Salary  29.089\n",
       "16      Changed_Credit_Limit   5.461\n",
       "17          Outstanding_Debt   7.293\n",
       "18       Total_EMI_per_month   3.167"
      ]
     },
     "execution_count": 14,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "## VIF Test\n",
    "\n",
    "from statsmodels.stats.outliers_influence import variance_inflation_factor\n",
    "\n",
    "vif_data=pd.DataFrame()\n",
    "vif_data[\"target\"]=X.columns\n",
    "vif_data[\"VIF\"]=[variance_inflation_factor(X.values, i) for i in range(X.shape[1])]\n",
    "vif_data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {
    "executionInfo": {
     "elapsed": 246,
     "status": "ok",
     "timestamp": 1705663378130,
     "user": {
      "displayName": "Canan Dülgeroğlu",
      "userId": "00060531196188721276"
     },
     "user_tz": -180
    },
    "id": "_XWIoH2o4xFX"
   },
   "outputs": [],
   "source": [
    "df.drop(\"Annual_Income\",axis=1,inplace=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {
    "executionInfo": {
     "elapsed": 226,
     "status": "ok",
     "timestamp": 1705663386540,
     "user": {
      "displayName": "Canan Dülgeroğlu",
      "userId": "00060531196188721276"
     },
     "user_tz": -180
    },
    "id": "aX6xyN450hZb"
   },
   "outputs": [],
   "source": [
    "import tensorflow as tf\n",
    "from tensorflow import keras\n",
    "from keras.utils import to_categorical\n",
    "\n",
    "y=to_categorical(y, num_classes=3)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {
    "executionInfo": {
     "elapsed": 1162,
     "status": "ok",
     "timestamp": 1705663414716,
     "user": {
      "displayName": "Canan Dülgeroğlu",
      "userId": "00060531196188721276"
     },
     "user_tz": -180
    },
    "id": "IzXqNBhV0frA"
   },
   "outputs": [],
   "source": [
    "from sklearn.model_selection import train_test_split\n",
    "X_train, X_test, y_train, y_test = train_test_split(X,y,test_size=0.15,shuffle=True,stratify=y,random_state=42)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {
    "executionInfo": {
     "elapsed": 231,
     "status": "ok",
     "timestamp": 1705663461608,
     "user": {
      "displayName": "Canan Dülgeroğlu",
      "userId": "00060531196188721276"
     },
     "user_tz": -180
    },
    "id": "ENfzSqwI0hjY"
   },
   "outputs": [],
   "source": [
    "# Scaling\n",
    "from sklearn.preprocessing import RobustScaler\n",
    "scaler = RobustScaler()\n",
    "X_train = scaler.fit_transform(X_train)\n",
    "X_test = scaler.transform(X_test)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "executionInfo": {
     "elapsed": 274,
     "status": "ok",
     "timestamp": 1705654745014,
     "user": {
      "displayName": "Canan Dülgeroğlu",
      "userId": "00060531196188721276"
     },
     "user_tz": -180
    },
    "id": "xMDNkGkl5l1g",
    "outputId": "46f58568-9ccc-404e-dda5-9bab40957e6e"
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([[1., 0., 0.],\n",
       "       [1., 0., 0.],\n",
       "       [1., 0., 0.],\n",
       "       ...,\n",
       "       [0., 1., 0.],\n",
       "       [0., 1., 0.],\n",
       "       [0., 1., 0.]], dtype=float32)"
      ]
     },
     "execution_count": 19,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "y"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 67,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "executionInfo": {
     "elapsed": 416,
     "status": "ok",
     "timestamp": 1705622979819,
     "user": {
      "displayName": "Canan Dülgeroğlu",
      "userId": "00060531196188721276"
     },
     "user_tz": -180
    },
    "id": "eyhpSwh_DA-p",
    "outputId": "3e76d320-1a38-4ffa-e388-5d8f5f52c9a4"
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "dtype('float64')"
      ]
     },
     "execution_count": 67,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "X_train.dtype"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {
    "executionInfo": {
     "elapsed": 233,
     "status": "ok",
     "timestamp": 1705663479212,
     "user": {
      "displayName": "Canan Dülgeroğlu",
      "userId": "00060531196188721276"
     },
     "user_tz": -180
    },
    "id": "vv1ZEpKH9VQc"
   },
   "outputs": [],
   "source": [
    "import tensorflow as tf\n",
    "from tensorflow.keras.models import Sequential\n",
    "from tensorflow.keras.layers import Dense, Dropout, Activation, BatchNormalization\n",
    "from sklearn.metrics import f1_score, accuracy_score, recall_score\n",
    "from tensorflow.keras.optimizers import Adam\n",
    "from tensorflow.keras.callbacks import EarlyStopping\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 250
    },
    "executionInfo": {
     "elapsed": 291,
     "status": "error",
     "timestamp": 1705665365762,
     "user": {
      "displayName": "Canan Dülgeroğlu",
      "userId": "00060531196188721276"
     },
     "user_tz": -180
    },
    "id": "kpkJX4nsnGA4",
    "outputId": "2efeb5ab-4853-4933-b01f-90afac3572e8",
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "WARNING:absl:At this time, the v2.11+ optimizer `tf.keras.optimizers.Adam` runs slowly on M1/M2 Macs, please use the legacy Keras optimizer instead, located at `tf.keras.optimizers.legacy.Adam`.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 1/500\n",
      "239/239 [==============================] - 1s 2ms/step - loss: 0.7705 - accuracy: 0.6917 - val_loss: 0.6858 - val_accuracy: 0.7341\n",
      "Epoch 2/500\n",
      "239/239 [==============================] - 1s 3ms/step - loss: 0.6998 - accuracy: 0.7287 - val_loss: 0.6678 - val_accuracy: 0.7399\n",
      "Epoch 3/500\n",
      "239/239 [==============================] - 0s 2ms/step - loss: 0.6873 - accuracy: 0.7331 - val_loss: 0.6594 - val_accuracy: 0.7429\n",
      "Epoch 4/500\n",
      "239/239 [==============================] - 0s 2ms/step - loss: 0.6771 - accuracy: 0.7358 - val_loss: 0.6520 - val_accuracy: 0.7462\n",
      "Epoch 5/500\n",
      "239/239 [==============================] - 0s 2ms/step - loss: 0.6713 - accuracy: 0.7380 - val_loss: 0.6512 - val_accuracy: 0.7469\n",
      "Epoch 6/500\n",
      "239/239 [==============================] - 0s 2ms/step - loss: 0.6646 - accuracy: 0.7395 - val_loss: 0.6416 - val_accuracy: 0.7478\n",
      "Epoch 7/500\n",
      "239/239 [==============================] - 0s 2ms/step - loss: 0.6591 - accuracy: 0.7416 - val_loss: 0.6387 - val_accuracy: 0.7494\n",
      "Epoch 8/500\n",
      "239/239 [==============================] - 0s 2ms/step - loss: 0.6562 - accuracy: 0.7430 - val_loss: 0.6337 - val_accuracy: 0.7504\n",
      "Epoch 9/500\n",
      "239/239 [==============================] - 0s 2ms/step - loss: 0.6501 - accuracy: 0.7450 - val_loss: 0.6300 - val_accuracy: 0.7518\n",
      "Epoch 10/500\n",
      "239/239 [==============================] - 0s 2ms/step - loss: 0.6486 - accuracy: 0.7454 - val_loss: 0.6252 - val_accuracy: 0.7542\n",
      "Epoch 11/500\n",
      "239/239 [==============================] - 0s 2ms/step - loss: 0.6442 - accuracy: 0.7456 - val_loss: 0.6224 - val_accuracy: 0.7565\n",
      "Epoch 12/500\n",
      "239/239 [==============================] - 0s 2ms/step - loss: 0.6416 - accuracy: 0.7474 - val_loss: 0.6192 - val_accuracy: 0.7547\n",
      "Epoch 13/500\n",
      "239/239 [==============================] - 0s 2ms/step - loss: 0.6360 - accuracy: 0.7495 - val_loss: 0.6153 - val_accuracy: 0.7584\n",
      "Epoch 14/500\n",
      "239/239 [==============================] - 0s 2ms/step - loss: 0.6338 - accuracy: 0.7502 - val_loss: 0.6139 - val_accuracy: 0.7578\n",
      "Epoch 15/500\n",
      "239/239 [==============================] - 0s 2ms/step - loss: 0.6313 - accuracy: 0.7515 - val_loss: 0.6100 - val_accuracy: 0.7595\n",
      "Epoch 16/500\n",
      "239/239 [==============================] - 0s 2ms/step - loss: 0.6279 - accuracy: 0.7524 - val_loss: 0.6057 - val_accuracy: 0.7613\n",
      "Epoch 17/500\n",
      "239/239 [==============================] - 0s 2ms/step - loss: 0.6251 - accuracy: 0.7534 - val_loss: 0.6022 - val_accuracy: 0.7620\n",
      "Epoch 18/500\n",
      "239/239 [==============================] - 0s 2ms/step - loss: 0.6235 - accuracy: 0.7530 - val_loss: 0.5983 - val_accuracy: 0.7633\n",
      "Epoch 19/500\n",
      "239/239 [==============================] - 0s 2ms/step - loss: 0.6195 - accuracy: 0.7555 - val_loss: 0.5946 - val_accuracy: 0.7650\n",
      "Epoch 20/500\n",
      "239/239 [==============================] - 0s 2ms/step - loss: 0.6181 - accuracy: 0.7564 - val_loss: 0.5940 - val_accuracy: 0.7663\n",
      "Epoch 21/500\n",
      "239/239 [==============================] - 0s 2ms/step - loss: 0.6147 - accuracy: 0.7569 - val_loss: 0.5928 - val_accuracy: 0.7679\n",
      "Epoch 22/500\n",
      "239/239 [==============================] - 0s 2ms/step - loss: 0.6141 - accuracy: 0.7570 - val_loss: 0.5879 - val_accuracy: 0.7692\n",
      "Epoch 23/500\n",
      "239/239 [==============================] - 0s 2ms/step - loss: 0.6108 - accuracy: 0.7585 - val_loss: 0.5862 - val_accuracy: 0.7691\n",
      "Epoch 24/500\n",
      "239/239 [==============================] - 0s 2ms/step - loss: 0.6094 - accuracy: 0.7585 - val_loss: 0.5883 - val_accuracy: 0.7707\n",
      "Epoch 25/500\n",
      "239/239 [==============================] - 0s 2ms/step - loss: 0.6062 - accuracy: 0.7603 - val_loss: 0.5817 - val_accuracy: 0.7726\n",
      "Epoch 26/500\n",
      "239/239 [==============================] - 0s 2ms/step - loss: 0.6049 - accuracy: 0.7604 - val_loss: 0.5814 - val_accuracy: 0.7747\n",
      "Epoch 27/500\n",
      "239/239 [==============================] - 0s 2ms/step - loss: 0.6021 - accuracy: 0.7618 - val_loss: 0.5771 - val_accuracy: 0.7739\n",
      "Epoch 28/500\n",
      "239/239 [==============================] - 0s 2ms/step - loss: 0.6002 - accuracy: 0.7623 - val_loss: 0.5747 - val_accuracy: 0.7739\n",
      "Epoch 29/500\n",
      "239/239 [==============================] - 0s 2ms/step - loss: 0.5992 - accuracy: 0.7617 - val_loss: 0.5715 - val_accuracy: 0.7787\n",
      "Epoch 30/500\n",
      "239/239 [==============================] - 0s 2ms/step - loss: 0.5983 - accuracy: 0.7632 - val_loss: 0.5713 - val_accuracy: 0.7764\n",
      "Epoch 31/500\n",
      "239/239 [==============================] - 0s 2ms/step - loss: 0.5932 - accuracy: 0.7646 - val_loss: 0.5663 - val_accuracy: 0.7767\n",
      "Epoch 32/500\n",
      "239/239 [==============================] - 0s 2ms/step - loss: 0.5956 - accuracy: 0.7638 - val_loss: 0.5702 - val_accuracy: 0.7776\n",
      "Epoch 33/500\n",
      "239/239 [==============================] - 0s 2ms/step - loss: 0.5913 - accuracy: 0.7641 - val_loss: 0.5647 - val_accuracy: 0.7786\n",
      "Epoch 34/500\n",
      "239/239 [==============================] - 0s 2ms/step - loss: 0.5923 - accuracy: 0.7646 - val_loss: 0.5613 - val_accuracy: 0.7778\n",
      "Epoch 35/500\n",
      "239/239 [==============================] - 0s 2ms/step - loss: 0.5915 - accuracy: 0.7647 - val_loss: 0.5620 - val_accuracy: 0.7778\n",
      "Epoch 36/500\n",
      "239/239 [==============================] - 0s 2ms/step - loss: 0.5893 - accuracy: 0.7662 - val_loss: 0.5610 - val_accuracy: 0.7771\n",
      "Epoch 37/500\n",
      "239/239 [==============================] - 0s 2ms/step - loss: 0.5872 - accuracy: 0.7664 - val_loss: 0.5600 - val_accuracy: 0.7836\n",
      "Epoch 38/500\n",
      "239/239 [==============================] - 0s 2ms/step - loss: 0.5880 - accuracy: 0.7660 - val_loss: 0.5584 - val_accuracy: 0.7799\n",
      "Epoch 39/500\n",
      "239/239 [==============================] - 0s 2ms/step - loss: 0.5840 - accuracy: 0.7683 - val_loss: 0.5558 - val_accuracy: 0.7835\n",
      "Epoch 40/500\n",
      "239/239 [==============================] - 0s 2ms/step - loss: 0.5843 - accuracy: 0.7677 - val_loss: 0.5559 - val_accuracy: 0.7829\n",
      "Epoch 41/500\n",
      "239/239 [==============================] - 0s 2ms/step - loss: 0.5816 - accuracy: 0.7689 - val_loss: 0.5497 - val_accuracy: 0.7859\n",
      "Epoch 42/500\n",
      "239/239 [==============================] - 0s 2ms/step - loss: 0.5824 - accuracy: 0.7677 - val_loss: 0.5482 - val_accuracy: 0.7829\n",
      "Epoch 43/500\n",
      "239/239 [==============================] - 0s 2ms/step - loss: 0.5799 - accuracy: 0.7692 - val_loss: 0.5490 - val_accuracy: 0.7812\n",
      "Epoch 44/500\n",
      "239/239 [==============================] - 0s 2ms/step - loss: 0.5806 - accuracy: 0.7681 - val_loss: 0.5499 - val_accuracy: 0.7831\n",
      "Epoch 45/500\n",
      "239/239 [==============================] - 0s 2ms/step - loss: 0.5780 - accuracy: 0.7690 - val_loss: 0.5458 - val_accuracy: 0.7850\n",
      "Epoch 46/500\n",
      "239/239 [==============================] - 0s 2ms/step - loss: 0.5774 - accuracy: 0.7694 - val_loss: 0.5405 - val_accuracy: 0.7862\n",
      "Epoch 47/500\n",
      "239/239 [==============================] - 0s 2ms/step - loss: 0.5758 - accuracy: 0.7709 - val_loss: 0.5412 - val_accuracy: 0.7876\n",
      "Epoch 48/500\n",
      "239/239 [==============================] - 0s 2ms/step - loss: 0.5751 - accuracy: 0.7714 - val_loss: 0.5408 - val_accuracy: 0.7866\n",
      "Epoch 49/500\n",
      "239/239 [==============================] - 0s 2ms/step - loss: 0.5737 - accuracy: 0.7708 - val_loss: 0.5394 - val_accuracy: 0.7879\n",
      "Epoch 50/500\n",
      "239/239 [==============================] - 0s 2ms/step - loss: 0.5735 - accuracy: 0.7711 - val_loss: 0.5398 - val_accuracy: 0.7890\n",
      "Epoch 51/500\n",
      "239/239 [==============================] - 0s 2ms/step - loss: 0.5719 - accuracy: 0.7725 - val_loss: 0.5337 - val_accuracy: 0.7902\n",
      "Epoch 52/500\n",
      "239/239 [==============================] - 0s 2ms/step - loss: 0.5715 - accuracy: 0.7723 - val_loss: 0.5377 - val_accuracy: 0.7891\n",
      "Epoch 53/500\n",
      "239/239 [==============================] - 0s 2ms/step - loss: 0.5728 - accuracy: 0.7713 - val_loss: 0.5345 - val_accuracy: 0.7921\n",
      "Epoch 54/500\n",
      "239/239 [==============================] - 0s 2ms/step - loss: 0.5694 - accuracy: 0.7727 - val_loss: 0.5310 - val_accuracy: 0.7913\n",
      "Epoch 55/500\n",
      "239/239 [==============================] - 0s 2ms/step - loss: 0.5691 - accuracy: 0.7743 - val_loss: 0.5332 - val_accuracy: 0.7882\n",
      "Epoch 56/500\n",
      "239/239 [==============================] - 0s 2ms/step - loss: 0.5692 - accuracy: 0.7729 - val_loss: 0.5320 - val_accuracy: 0.7913\n",
      "Epoch 57/500\n",
      "239/239 [==============================] - 0s 2ms/step - loss: 0.5677 - accuracy: 0.7734 - val_loss: 0.5322 - val_accuracy: 0.7902\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 58/500\n",
      "239/239 [==============================] - 0s 2ms/step - loss: 0.5673 - accuracy: 0.7747 - val_loss: 0.5326 - val_accuracy: 0.7891\n",
      "Epoch 59/500\n",
      "239/239 [==============================] - 0s 2ms/step - loss: 0.5665 - accuracy: 0.7742 - val_loss: 0.5261 - val_accuracy: 0.7938\n",
      "Epoch 60/500\n",
      "239/239 [==============================] - 0s 2ms/step - loss: 0.5657 - accuracy: 0.7747 - val_loss: 0.5277 - val_accuracy: 0.7936\n",
      "Epoch 61/500\n",
      "239/239 [==============================] - 0s 2ms/step - loss: 0.5638 - accuracy: 0.7740 - val_loss: 0.5245 - val_accuracy: 0.7954\n",
      "Epoch 62/500\n",
      "239/239 [==============================] - 0s 2ms/step - loss: 0.5637 - accuracy: 0.7753 - val_loss: 0.5300 - val_accuracy: 0.7946\n",
      "Epoch 63/500\n",
      "239/239 [==============================] - 0s 2ms/step - loss: 0.5639 - accuracy: 0.7766 - val_loss: 0.5289 - val_accuracy: 0.7928\n",
      "Epoch 64/500\n",
      "239/239 [==============================] - 0s 2ms/step - loss: 0.5632 - accuracy: 0.7753 - val_loss: 0.5230 - val_accuracy: 0.7958\n",
      "Epoch 65/500\n",
      "239/239 [==============================] - 0s 2ms/step - loss: 0.5618 - accuracy: 0.7754 - val_loss: 0.5229 - val_accuracy: 0.7981\n",
      "Epoch 66/500\n",
      "239/239 [==============================] - 0s 2ms/step - loss: 0.5624 - accuracy: 0.7763 - val_loss: 0.5244 - val_accuracy: 0.7937\n",
      "Epoch 67/500\n",
      "239/239 [==============================] - 0s 2ms/step - loss: 0.5592 - accuracy: 0.7773 - val_loss: 0.5247 - val_accuracy: 0.7947\n",
      "Epoch 68/500\n",
      "239/239 [==============================] - 0s 2ms/step - loss: 0.5601 - accuracy: 0.7761 - val_loss: 0.5211 - val_accuracy: 0.7981\n",
      "Epoch 69/500\n",
      "239/239 [==============================] - 0s 2ms/step - loss: 0.5595 - accuracy: 0.7767 - val_loss: 0.5254 - val_accuracy: 0.7936\n",
      "Epoch 70/500\n",
      "239/239 [==============================] - 0s 2ms/step - loss: 0.5598 - accuracy: 0.7765 - val_loss: 0.5225 - val_accuracy: 0.7950\n",
      "Epoch 71/500\n",
      "239/239 [==============================] - 0s 2ms/step - loss: 0.5582 - accuracy: 0.7786 - val_loss: 0.5209 - val_accuracy: 0.7950\n",
      "Epoch 72/500\n",
      "239/239 [==============================] - 0s 2ms/step - loss: 0.5572 - accuracy: 0.7766 - val_loss: 0.5219 - val_accuracy: 0.7947\n",
      "Epoch 73/500\n",
      "239/239 [==============================] - 0s 2ms/step - loss: 0.5569 - accuracy: 0.7781 - val_loss: 0.5193 - val_accuracy: 0.7997\n",
      "Epoch 74/500\n",
      "239/239 [==============================] - 0s 2ms/step - loss: 0.5564 - accuracy: 0.7787 - val_loss: 0.5204 - val_accuracy: 0.7973\n",
      "Epoch 75/500\n",
      "239/239 [==============================] - 0s 2ms/step - loss: 0.5571 - accuracy: 0.7772 - val_loss: 0.5189 - val_accuracy: 0.7965\n",
      "Epoch 76/500\n",
      "239/239 [==============================] - 0s 2ms/step - loss: 0.5564 - accuracy: 0.7783 - val_loss: 0.5163 - val_accuracy: 0.7999\n",
      "Epoch 77/500\n",
      "239/239 [==============================] - 0s 2ms/step - loss: 0.5555 - accuracy: 0.7787 - val_loss: 0.5166 - val_accuracy: 0.7964\n",
      "Epoch 78/500\n",
      "239/239 [==============================] - 0s 2ms/step - loss: 0.5547 - accuracy: 0.7787 - val_loss: 0.5139 - val_accuracy: 0.7985\n",
      "Epoch 79/500\n",
      "239/239 [==============================] - 0s 2ms/step - loss: 0.5545 - accuracy: 0.7791 - val_loss: 0.5129 - val_accuracy: 0.7982\n",
      "Epoch 80/500\n",
      "239/239 [==============================] - 0s 2ms/step - loss: 0.5527 - accuracy: 0.7799 - val_loss: 0.5155 - val_accuracy: 0.7989\n",
      "Epoch 81/500\n",
      "239/239 [==============================] - 0s 2ms/step - loss: 0.5558 - accuracy: 0.7775 - val_loss: 0.5156 - val_accuracy: 0.7975\n",
      "Epoch 82/500\n",
      "239/239 [==============================] - 0s 2ms/step - loss: 0.5530 - accuracy: 0.7795 - val_loss: 0.5123 - val_accuracy: 0.7984\n",
      "Epoch 83/500\n",
      "239/239 [==============================] - 0s 2ms/step - loss: 0.5525 - accuracy: 0.7798 - val_loss: 0.5151 - val_accuracy: 0.7967\n",
      "Epoch 84/500\n",
      "239/239 [==============================] - 0s 2ms/step - loss: 0.5519 - accuracy: 0.7800 - val_loss: 0.5100 - val_accuracy: 0.8009\n",
      "Epoch 85/500\n",
      "239/239 [==============================] - 0s 2ms/step - loss: 0.5518 - accuracy: 0.7806 - val_loss: 0.5114 - val_accuracy: 0.8014\n",
      "Epoch 86/500\n",
      "239/239 [==============================] - 0s 2ms/step - loss: 0.5526 - accuracy: 0.7806 - val_loss: 0.5116 - val_accuracy: 0.7983\n",
      "Epoch 87/500\n",
      "239/239 [==============================] - 0s 2ms/step - loss: 0.5513 - accuracy: 0.7813 - val_loss: 0.5083 - val_accuracy: 0.8011\n",
      "Epoch 88/500\n",
      "239/239 [==============================] - 0s 2ms/step - loss: 0.5495 - accuracy: 0.7806 - val_loss: 0.5107 - val_accuracy: 0.8008\n",
      "Epoch 89/500\n",
      "239/239 [==============================] - 0s 2ms/step - loss: 0.5495 - accuracy: 0.7808 - val_loss: 0.5099 - val_accuracy: 0.8011\n",
      "Epoch 90/500\n",
      "239/239 [==============================] - 0s 2ms/step - loss: 0.5495 - accuracy: 0.7816 - val_loss: 0.5084 - val_accuracy: 0.8020\n",
      "Epoch 91/500\n",
      "239/239 [==============================] - 0s 2ms/step - loss: 0.5482 - accuracy: 0.7816 - val_loss: 0.5077 - val_accuracy: 0.8020\n",
      "Epoch 92/500\n",
      "239/239 [==============================] - 0s 2ms/step - loss: 0.5480 - accuracy: 0.7816 - val_loss: 0.5060 - val_accuracy: 0.8023\n",
      "Epoch 93/500\n",
      "239/239 [==============================] - 0s 2ms/step - loss: 0.5486 - accuracy: 0.7817 - val_loss: 0.5065 - val_accuracy: 0.8021\n",
      "Epoch 94/500\n",
      "239/239 [==============================] - 0s 2ms/step - loss: 0.5480 - accuracy: 0.7819 - val_loss: 0.5098 - val_accuracy: 0.8017\n",
      "Epoch 95/500\n",
      "239/239 [==============================] - 0s 2ms/step - loss: 0.5468 - accuracy: 0.7820 - val_loss: 0.5053 - val_accuracy: 0.8034\n",
      "Epoch 96/500\n",
      "239/239 [==============================] - 0s 2ms/step - loss: 0.5462 - accuracy: 0.7819 - val_loss: 0.5038 - val_accuracy: 0.8005\n",
      "Epoch 97/500\n",
      "239/239 [==============================] - 0s 2ms/step - loss: 0.5473 - accuracy: 0.7825 - val_loss: 0.5045 - val_accuracy: 0.8031\n",
      "Epoch 98/500\n",
      "239/239 [==============================] - 0s 2ms/step - loss: 0.5456 - accuracy: 0.7831 - val_loss: 0.5039 - val_accuracy: 0.8027\n",
      "Epoch 99/500\n",
      "239/239 [==============================] - 0s 2ms/step - loss: 0.5476 - accuracy: 0.7829 - val_loss: 0.5046 - val_accuracy: 0.7996\n",
      "Epoch 100/500\n",
      "239/239 [==============================] - 0s 2ms/step - loss: 0.5462 - accuracy: 0.7824 - val_loss: 0.5020 - val_accuracy: 0.8035\n",
      "Epoch 101/500\n",
      "239/239 [==============================] - 0s 2ms/step - loss: 0.5455 - accuracy: 0.7819 - val_loss: 0.5018 - val_accuracy: 0.8051\n",
      "Epoch 102/500\n",
      "239/239 [==============================] - 0s 2ms/step - loss: 0.5472 - accuracy: 0.7817 - val_loss: 0.5049 - val_accuracy: 0.8023\n",
      "Epoch 103/500\n",
      "239/239 [==============================] - 0s 2ms/step - loss: 0.5469 - accuracy: 0.7814 - val_loss: 0.5035 - val_accuracy: 0.8022\n",
      "Epoch 104/500\n",
      "239/239 [==============================] - 0s 2ms/step - loss: 0.5440 - accuracy: 0.7835 - val_loss: 0.5003 - val_accuracy: 0.8079\n",
      "Epoch 105/500\n",
      "239/239 [==============================] - 0s 2ms/step - loss: 0.5416 - accuracy: 0.7849 - val_loss: 0.5011 - val_accuracy: 0.8036\n",
      "Epoch 106/500\n",
      "239/239 [==============================] - 0s 2ms/step - loss: 0.5446 - accuracy: 0.7828 - val_loss: 0.5013 - val_accuracy: 0.8033\n",
      "Epoch 107/500\n",
      "239/239 [==============================] - 0s 2ms/step - loss: 0.5433 - accuracy: 0.7832 - val_loss: 0.5015 - val_accuracy: 0.8031\n",
      "Epoch 108/500\n",
      "239/239 [==============================] - 0s 2ms/step - loss: 0.5423 - accuracy: 0.7846 - val_loss: 0.4973 - val_accuracy: 0.8043\n",
      "Epoch 109/500\n",
      "239/239 [==============================] - 0s 2ms/step - loss: 0.5436 - accuracy: 0.7837 - val_loss: 0.4986 - val_accuracy: 0.8047\n",
      "Epoch 110/500\n",
      "239/239 [==============================] - 0s 2ms/step - loss: 0.5433 - accuracy: 0.7828 - val_loss: 0.5012 - val_accuracy: 0.8062\n",
      "Epoch 111/500\n",
      "239/239 [==============================] - 0s 2ms/step - loss: 0.5417 - accuracy: 0.7846 - val_loss: 0.4983 - val_accuracy: 0.8056\n",
      "Epoch 112/500\n",
      "239/239 [==============================] - 0s 2ms/step - loss: 0.5418 - accuracy: 0.7839 - val_loss: 0.4992 - val_accuracy: 0.8062\n",
      "Epoch 113/500\n",
      "239/239 [==============================] - 0s 2ms/step - loss: 0.5431 - accuracy: 0.7844 - val_loss: 0.4998 - val_accuracy: 0.8064\n",
      "Epoch 114/500\n",
      "239/239 [==============================] - 0s 2ms/step - loss: 0.5413 - accuracy: 0.7850 - val_loss: 0.4990 - val_accuracy: 0.8046\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 115/500\n",
      "239/239 [==============================] - 0s 2ms/step - loss: 0.5416 - accuracy: 0.7847 - val_loss: 0.4986 - val_accuracy: 0.8038\n",
      "Epoch 116/500\n",
      "239/239 [==============================] - 0s 2ms/step - loss: 0.5426 - accuracy: 0.7846 - val_loss: 0.4981 - val_accuracy: 0.8074\n",
      "Epoch 117/500\n",
      "239/239 [==============================] - 0s 2ms/step - loss: 0.5395 - accuracy: 0.7859 - val_loss: 0.4974 - val_accuracy: 0.8063\n",
      "Epoch 118/500\n",
      "239/239 [==============================] - 0s 2ms/step - loss: 0.5407 - accuracy: 0.7859 - val_loss: 0.4988 - val_accuracy: 0.8045\n",
      "Epoch 119/500\n",
      "239/239 [==============================] - 0s 2ms/step - loss: 0.5410 - accuracy: 0.7849 - val_loss: 0.4968 - val_accuracy: 0.8063\n",
      "Epoch 120/500\n",
      "239/239 [==============================] - 0s 2ms/step - loss: 0.5404 - accuracy: 0.7854 - val_loss: 0.4973 - val_accuracy: 0.8072\n",
      "Epoch 121/500\n",
      "239/239 [==============================] - 0s 2ms/step - loss: 0.5393 - accuracy: 0.7856 - val_loss: 0.4936 - val_accuracy: 0.8079\n",
      "Epoch 122/500\n",
      "239/239 [==============================] - 0s 2ms/step - loss: 0.5409 - accuracy: 0.7845 - val_loss: 0.4965 - val_accuracy: 0.8082\n",
      "Epoch 123/500\n",
      "239/239 [==============================] - 1s 2ms/step - loss: 0.5375 - accuracy: 0.7863 - val_loss: 0.4978 - val_accuracy: 0.8048\n",
      "Epoch 124/500\n",
      "239/239 [==============================] - 0s 2ms/step - loss: 0.5402 - accuracy: 0.7851 - val_loss: 0.4964 - val_accuracy: 0.8065\n",
      "Epoch 125/500\n",
      "239/239 [==============================] - 0s 2ms/step - loss: 0.5382 - accuracy: 0.7849 - val_loss: 0.4969 - val_accuracy: 0.8071\n",
      "Epoch 126/500\n",
      "239/239 [==============================] - 0s 2ms/step - loss: 0.5373 - accuracy: 0.7864 - val_loss: 0.4943 - val_accuracy: 0.8061\n",
      "Epoch 127/500\n",
      "239/239 [==============================] - 0s 2ms/step - loss: 0.5389 - accuracy: 0.7846 - val_loss: 0.4940 - val_accuracy: 0.8086\n",
      "Epoch 128/500\n",
      "239/239 [==============================] - 0s 2ms/step - loss: 0.5379 - accuracy: 0.7862 - val_loss: 0.4962 - val_accuracy: 0.8070\n",
      "Epoch 129/500\n",
      "239/239 [==============================] - 0s 2ms/step - loss: 0.5370 - accuracy: 0.7866 - val_loss: 0.4930 - val_accuracy: 0.8082\n",
      "Epoch 130/500\n",
      "239/239 [==============================] - 0s 2ms/step - loss: 0.5385 - accuracy: 0.7856 - val_loss: 0.4952 - val_accuracy: 0.8068\n",
      "Epoch 131/500\n",
      "239/239 [==============================] - 0s 2ms/step - loss: 0.5358 - accuracy: 0.7871 - val_loss: 0.4922 - val_accuracy: 0.8088\n",
      "Epoch 132/500\n",
      "239/239 [==============================] - 0s 2ms/step - loss: 0.5380 - accuracy: 0.7866 - val_loss: 0.4952 - val_accuracy: 0.8071\n",
      "Epoch 133/500\n",
      "239/239 [==============================] - 0s 2ms/step - loss: 0.5370 - accuracy: 0.7875 - val_loss: 0.4949 - val_accuracy: 0.8085\n",
      "Epoch 134/500\n",
      "239/239 [==============================] - 0s 2ms/step - loss: 0.5366 - accuracy: 0.7864 - val_loss: 0.4933 - val_accuracy: 0.8090\n",
      "Epoch 135/500\n",
      "239/239 [==============================] - 0s 2ms/step - loss: 0.5366 - accuracy: 0.7877 - val_loss: 0.4940 - val_accuracy: 0.8073\n",
      "Epoch 136/500\n",
      "239/239 [==============================] - 0s 2ms/step - loss: 0.5360 - accuracy: 0.7878 - val_loss: 0.4911 - val_accuracy: 0.8085\n",
      "Epoch 137/500\n",
      "239/239 [==============================] - 0s 2ms/step - loss: 0.5351 - accuracy: 0.7884 - val_loss: 0.4932 - val_accuracy: 0.8071\n",
      "Epoch 138/500\n",
      "239/239 [==============================] - 0s 2ms/step - loss: 0.5361 - accuracy: 0.7869 - val_loss: 0.4948 - val_accuracy: 0.8068\n",
      "Epoch 139/500\n",
      "239/239 [==============================] - 0s 2ms/step - loss: 0.5359 - accuracy: 0.7873 - val_loss: 0.4935 - val_accuracy: 0.8068\n",
      "Epoch 140/500\n",
      "239/239 [==============================] - 0s 2ms/step - loss: 0.5370 - accuracy: 0.7864 - val_loss: 0.4880 - val_accuracy: 0.8085\n",
      "Epoch 141/500\n",
      "239/239 [==============================] - 0s 2ms/step - loss: 0.5337 - accuracy: 0.7871 - val_loss: 0.4912 - val_accuracy: 0.8059\n",
      "Epoch 142/500\n",
      "239/239 [==============================] - 0s 2ms/step - loss: 0.5363 - accuracy: 0.7871 - val_loss: 0.4887 - val_accuracy: 0.8075\n",
      "Epoch 143/500\n",
      "239/239 [==============================] - 0s 2ms/step - loss: 0.5345 - accuracy: 0.7860 - val_loss: 0.4921 - val_accuracy: 0.8088\n",
      "Epoch 144/500\n",
      "239/239 [==============================] - 0s 2ms/step - loss: 0.5355 - accuracy: 0.7868 - val_loss: 0.4868 - val_accuracy: 0.8116\n",
      "Epoch 145/500\n",
      "239/239 [==============================] - 0s 2ms/step - loss: 0.5337 - accuracy: 0.7888 - val_loss: 0.4901 - val_accuracy: 0.8086\n",
      "Epoch 146/500\n",
      "239/239 [==============================] - 0s 2ms/step - loss: 0.5337 - accuracy: 0.7875 - val_loss: 0.4915 - val_accuracy: 0.8073\n",
      "Epoch 147/500\n",
      "239/239 [==============================] - 0s 2ms/step - loss: 0.5325 - accuracy: 0.7873 - val_loss: 0.4896 - val_accuracy: 0.8088\n",
      "Epoch 148/500\n",
      "239/239 [==============================] - 0s 2ms/step - loss: 0.5344 - accuracy: 0.7874 - val_loss: 0.4893 - val_accuracy: 0.8115\n",
      "Epoch 149/500\n",
      "239/239 [==============================] - 0s 2ms/step - loss: 0.5315 - accuracy: 0.7886 - val_loss: 0.4876 - val_accuracy: 0.8119\n",
      "Epoch 150/500\n",
      "239/239 [==============================] - 0s 2ms/step - loss: 0.5334 - accuracy: 0.7887 - val_loss: 0.4897 - val_accuracy: 0.8102\n",
      "Epoch 151/500\n",
      "239/239 [==============================] - 0s 2ms/step - loss: 0.5350 - accuracy: 0.7875 - val_loss: 0.4894 - val_accuracy: 0.8105\n",
      "Epoch 152/500\n",
      "239/239 [==============================] - 0s 2ms/step - loss: 0.5337 - accuracy: 0.7872 - val_loss: 0.4902 - val_accuracy: 0.8093\n",
      "Epoch 153/500\n",
      "239/239 [==============================] - 0s 2ms/step - loss: 0.5350 - accuracy: 0.7876 - val_loss: 0.4870 - val_accuracy: 0.8113\n",
      "Epoch 154/500\n",
      "239/239 [==============================] - 0s 2ms/step - loss: 0.5340 - accuracy: 0.7876 - val_loss: 0.4883 - val_accuracy: 0.8098\n",
      "Epoch 155/500\n",
      "239/239 [==============================] - 0s 2ms/step - loss: 0.5331 - accuracy: 0.7882 - val_loss: 0.4879 - val_accuracy: 0.8088\n",
      "Epoch 156/500\n",
      "239/239 [==============================] - 0s 2ms/step - loss: 0.5316 - accuracy: 0.7891 - val_loss: 0.4876 - val_accuracy: 0.8094\n",
      "Epoch 157/500\n",
      "239/239 [==============================] - 0s 2ms/step - loss: 0.5322 - accuracy: 0.7883 - val_loss: 0.4887 - val_accuracy: 0.8096\n",
      "Epoch 158/500\n",
      "239/239 [==============================] - 0s 2ms/step - loss: 0.5315 - accuracy: 0.7886 - val_loss: 0.4883 - val_accuracy: 0.8094\n",
      "Epoch 159/500\n",
      "239/239 [==============================] - 0s 2ms/step - loss: 0.5315 - accuracy: 0.7880 - val_loss: 0.4869 - val_accuracy: 0.8104\n",
      "Epoch 160/500\n",
      "239/239 [==============================] - 0s 2ms/step - loss: 0.5299 - accuracy: 0.7892 - val_loss: 0.4851 - val_accuracy: 0.8110\n",
      "Epoch 161/500\n",
      "239/239 [==============================] - 0s 2ms/step - loss: 0.5329 - accuracy: 0.7877 - val_loss: 0.4870 - val_accuracy: 0.8133\n",
      "Epoch 162/500\n",
      "239/239 [==============================] - 0s 2ms/step - loss: 0.5312 - accuracy: 0.7892 - val_loss: 0.4880 - val_accuracy: 0.8113\n",
      "Epoch 163/500\n",
      "239/239 [==============================] - 0s 2ms/step - loss: 0.5292 - accuracy: 0.7886 - val_loss: 0.4842 - val_accuracy: 0.8107\n",
      "Epoch 164/500\n",
      "239/239 [==============================] - 0s 2ms/step - loss: 0.5311 - accuracy: 0.7884 - val_loss: 0.4847 - val_accuracy: 0.8113\n",
      "Epoch 165/500\n",
      "239/239 [==============================] - 0s 2ms/step - loss: 0.5306 - accuracy: 0.7893 - val_loss: 0.4860 - val_accuracy: 0.8106\n",
      "Epoch 166/500\n",
      "239/239 [==============================] - 0s 2ms/step - loss: 0.5328 - accuracy: 0.7879 - val_loss: 0.4862 - val_accuracy: 0.8116\n",
      "Epoch 167/500\n",
      "239/239 [==============================] - 0s 2ms/step - loss: 0.5295 - accuracy: 0.7897 - val_loss: 0.4846 - val_accuracy: 0.8107\n",
      "Epoch 168/500\n",
      "239/239 [==============================] - 0s 2ms/step - loss: 0.5290 - accuracy: 0.7889 - val_loss: 0.4840 - val_accuracy: 0.8097\n",
      "Epoch 169/500\n",
      "239/239 [==============================] - 0s 2ms/step - loss: 0.5308 - accuracy: 0.7885 - val_loss: 0.4841 - val_accuracy: 0.8112\n",
      "Epoch 170/500\n",
      "239/239 [==============================] - 0s 2ms/step - loss: 0.5312 - accuracy: 0.7891 - val_loss: 0.4844 - val_accuracy: 0.8116\n",
      "Epoch 171/500\n",
      "239/239 [==============================] - 0s 2ms/step - loss: 0.5294 - accuracy: 0.7897 - val_loss: 0.4875 - val_accuracy: 0.8088\n",
      "Epoch 172/500\n",
      "239/239 [==============================] - 0s 2ms/step - loss: 0.5286 - accuracy: 0.7889 - val_loss: 0.4850 - val_accuracy: 0.8133\n",
      "Epoch 173/500\n",
      "239/239 [==============================] - 0s 2ms/step - loss: 0.5296 - accuracy: 0.7894 - val_loss: 0.4859 - val_accuracy: 0.8139\n",
      "Epoch 174/500\n",
      "239/239 [==============================] - 0s 2ms/step - loss: 0.5296 - accuracy: 0.7888 - val_loss: 0.4842 - val_accuracy: 0.8122\n",
      "Epoch 175/500\n",
      "239/239 [==============================] - 0s 2ms/step - loss: 0.5277 - accuracy: 0.7908 - val_loss: 0.4816 - val_accuracy: 0.8133\n",
      "Epoch 176/500\n",
      "239/239 [==============================] - 0s 2ms/step - loss: 0.5291 - accuracy: 0.7899 - val_loss: 0.4827 - val_accuracy: 0.8113\n",
      "Epoch 177/500\n",
      "239/239 [==============================] - 0s 2ms/step - loss: 0.5285 - accuracy: 0.7902 - val_loss: 0.4815 - val_accuracy: 0.8147\n",
      "Epoch 178/500\n",
      "239/239 [==============================] - 0s 2ms/step - loss: 0.5282 - accuracy: 0.7899 - val_loss: 0.4854 - val_accuracy: 0.8105\n",
      "Epoch 179/500\n",
      "239/239 [==============================] - 0s 2ms/step - loss: 0.5277 - accuracy: 0.7918 - val_loss: 0.4837 - val_accuracy: 0.8119\n",
      "Epoch 180/500\n",
      "239/239 [==============================] - 0s 2ms/step - loss: 0.5290 - accuracy: 0.7893 - val_loss: 0.4824 - val_accuracy: 0.8136\n",
      "Epoch 181/500\n",
      "239/239 [==============================] - 0s 2ms/step - loss: 0.5296 - accuracy: 0.7890 - val_loss: 0.4820 - val_accuracy: 0.8137\n",
      "Epoch 182/500\n",
      "239/239 [==============================] - 0s 2ms/step - loss: 0.5271 - accuracy: 0.7909 - val_loss: 0.4843 - val_accuracy: 0.8107\n",
      "Epoch 183/500\n",
      "239/239 [==============================] - 0s 2ms/step - loss: 0.5275 - accuracy: 0.7905 - val_loss: 0.4825 - val_accuracy: 0.8118\n",
      "Epoch 184/500\n",
      "239/239 [==============================] - 0s 2ms/step - loss: 0.5268 - accuracy: 0.7896 - val_loss: 0.4831 - val_accuracy: 0.8113\n",
      "Epoch 185/500\n",
      "239/239 [==============================] - 0s 2ms/step - loss: 0.5259 - accuracy: 0.7906 - val_loss: 0.4815 - val_accuracy: 0.8144\n",
      "Epoch 186/500\n",
      "239/239 [==============================] - 0s 2ms/step - loss: 0.5282 - accuracy: 0.7898 - val_loss: 0.4828 - val_accuracy: 0.8118\n",
      "Epoch 187/500\n",
      "239/239 [==============================] - 1s 2ms/step - loss: 0.5272 - accuracy: 0.7914 - val_loss: 0.4816 - val_accuracy: 0.8118\n",
      "Epoch 188/500\n",
      "239/239 [==============================] - 0s 2ms/step - loss: 0.5275 - accuracy: 0.7908 - val_loss: 0.4813 - val_accuracy: 0.8113\n",
      "Epoch 189/500\n",
      "239/239 [==============================] - 0s 2ms/step - loss: 0.5263 - accuracy: 0.7914 - val_loss: 0.4807 - val_accuracy: 0.8135\n",
      "Epoch 190/500\n",
      "239/239 [==============================] - 0s 2ms/step - loss: 0.5270 - accuracy: 0.7912 - val_loss: 0.4849 - val_accuracy: 0.8108\n",
      "Epoch 191/500\n",
      "239/239 [==============================] - 0s 2ms/step - loss: 0.5259 - accuracy: 0.7918 - val_loss: 0.4823 - val_accuracy: 0.8110\n",
      "Epoch 192/500\n",
      "239/239 [==============================] - 0s 2ms/step - loss: 0.5271 - accuracy: 0.7913 - val_loss: 0.4843 - val_accuracy: 0.8110\n",
      "Epoch 193/500\n",
      "239/239 [==============================] - 0s 2ms/step - loss: 0.5270 - accuracy: 0.7905 - val_loss: 0.4794 - val_accuracy: 0.8142\n",
      "Epoch 194/500\n",
      "239/239 [==============================] - 0s 2ms/step - loss: 0.5256 - accuracy: 0.7900 - val_loss: 0.4806 - val_accuracy: 0.8135\n",
      "Epoch 195/500\n",
      "239/239 [==============================] - 0s 2ms/step - loss: 0.5251 - accuracy: 0.7918 - val_loss: 0.4810 - val_accuracy: 0.8148\n",
      "Epoch 196/500\n",
      "239/239 [==============================] - 0s 2ms/step - loss: 0.5272 - accuracy: 0.7906 - val_loss: 0.4811 - val_accuracy: 0.8117\n",
      "Epoch 197/500\n",
      "239/239 [==============================] - 0s 2ms/step - loss: 0.5266 - accuracy: 0.7898 - val_loss: 0.4804 - val_accuracy: 0.8144\n",
      "Epoch 198/500\n",
      "239/239 [==============================] - 0s 2ms/step - loss: 0.5276 - accuracy: 0.7916 - val_loss: 0.4795 - val_accuracy: 0.8147\n",
      "Epoch 199/500\n",
      "239/239 [==============================] - 0s 2ms/step - loss: 0.5249 - accuracy: 0.7921 - val_loss: 0.4788 - val_accuracy: 0.8156\n",
      "Epoch 200/500\n",
      "239/239 [==============================] - 0s 2ms/step - loss: 0.5251 - accuracy: 0.7920 - val_loss: 0.4795 - val_accuracy: 0.8148\n",
      "Epoch 201/500\n",
      "239/239 [==============================] - 0s 2ms/step - loss: 0.5250 - accuracy: 0.7904 - val_loss: 0.4812 - val_accuracy: 0.8122\n",
      "Epoch 202/500\n",
      "239/239 [==============================] - 0s 2ms/step - loss: 0.5252 - accuracy: 0.7915 - val_loss: 0.4822 - val_accuracy: 0.8126\n",
      "Epoch 203/500\n",
      "239/239 [==============================] - 0s 2ms/step - loss: 0.5245 - accuracy: 0.7917 - val_loss: 0.4805 - val_accuracy: 0.8145\n",
      "Epoch 204/500\n",
      "239/239 [==============================] - 1s 2ms/step - loss: 0.5220 - accuracy: 0.7933 - val_loss: 0.4787 - val_accuracy: 0.8133\n",
      "Epoch 205/500\n",
      "239/239 [==============================] - 0s 2ms/step - loss: 0.5247 - accuracy: 0.7922 - val_loss: 0.4800 - val_accuracy: 0.8147\n",
      "Epoch 206/500\n",
      "239/239 [==============================] - 0s 2ms/step - loss: 0.5251 - accuracy: 0.7910 - val_loss: 0.4804 - val_accuracy: 0.8143\n",
      "Epoch 207/500\n",
      "239/239 [==============================] - 0s 2ms/step - loss: 0.5246 - accuracy: 0.7915 - val_loss: 0.4774 - val_accuracy: 0.8152\n",
      "Epoch 208/500\n",
      "239/239 [==============================] - 0s 2ms/step - loss: 0.5254 - accuracy: 0.7908 - val_loss: 0.4789 - val_accuracy: 0.8141\n",
      "Epoch 209/500\n",
      "239/239 [==============================] - 0s 2ms/step - loss: 0.5241 - accuracy: 0.7925 - val_loss: 0.4785 - val_accuracy: 0.8152\n",
      "Epoch 210/500\n",
      "239/239 [==============================] - 0s 2ms/step - loss: 0.5226 - accuracy: 0.7921 - val_loss: 0.4803 - val_accuracy: 0.8154\n",
      "Epoch 211/500\n",
      "239/239 [==============================] - 0s 2ms/step - loss: 0.5256 - accuracy: 0.7911 - val_loss: 0.4802 - val_accuracy: 0.8148\n",
      "Epoch 212/500\n",
      "239/239 [==============================] - 0s 2ms/step - loss: 0.5240 - accuracy: 0.7921 - val_loss: 0.4786 - val_accuracy: 0.8169\n",
      "Epoch 213/500\n",
      "239/239 [==============================] - 0s 2ms/step - loss: 0.5234 - accuracy: 0.7922 - val_loss: 0.4791 - val_accuracy: 0.8139\n",
      "Epoch 214/500\n",
      "239/239 [==============================] - 0s 2ms/step - loss: 0.5246 - accuracy: 0.7913 - val_loss: 0.4800 - val_accuracy: 0.8127\n",
      "Epoch 215/500\n",
      "239/239 [==============================] - 0s 2ms/step - loss: 0.5242 - accuracy: 0.7921 - val_loss: 0.4805 - val_accuracy: 0.8155\n",
      "Epoch 216/500\n",
      "239/239 [==============================] - 0s 2ms/step - loss: 0.5211 - accuracy: 0.7935 - val_loss: 0.4782 - val_accuracy: 0.8144\n",
      "Epoch 217/500\n",
      "239/239 [==============================] - 0s 2ms/step - loss: 0.5239 - accuracy: 0.7921 - val_loss: 0.4776 - val_accuracy: 0.8162\n",
      "Epoch 218/500\n",
      "239/239 [==============================] - 0s 2ms/step - loss: 0.5250 - accuracy: 0.7931 - val_loss: 0.4781 - val_accuracy: 0.8138\n",
      "Epoch 219/500\n",
      "239/239 [==============================] - 0s 2ms/step - loss: 0.5235 - accuracy: 0.7920 - val_loss: 0.4784 - val_accuracy: 0.8139\n",
      "Epoch 220/500\n",
      "239/239 [==============================] - 0s 2ms/step - loss: 0.5227 - accuracy: 0.7921 - val_loss: 0.4760 - val_accuracy: 0.8177\n",
      "Epoch 221/500\n",
      "239/239 [==============================] - 0s 2ms/step - loss: 0.5243 - accuracy: 0.7916 - val_loss: 0.4795 - val_accuracy: 0.8147\n",
      "Epoch 222/500\n",
      "239/239 [==============================] - 0s 2ms/step - loss: 0.5240 - accuracy: 0.7915 - val_loss: 0.4772 - val_accuracy: 0.8142\n",
      "Epoch 223/500\n",
      "239/239 [==============================] - 0s 2ms/step - loss: 0.5220 - accuracy: 0.7924 - val_loss: 0.4766 - val_accuracy: 0.8138\n",
      "Epoch 224/500\n",
      "239/239 [==============================] - 0s 2ms/step - loss: 0.5236 - accuracy: 0.7917 - val_loss: 0.4780 - val_accuracy: 0.8147\n",
      "Epoch 225/500\n",
      "239/239 [==============================] - 0s 2ms/step - loss: 0.5213 - accuracy: 0.7931 - val_loss: 0.4781 - val_accuracy: 0.8130\n",
      "Epoch 226/500\n",
      "239/239 [==============================] - 0s 2ms/step - loss: 0.5246 - accuracy: 0.7921 - val_loss: 0.4783 - val_accuracy: 0.8154\n",
      "Epoch 227/500\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "239/239 [==============================] - 0s 2ms/step - loss: 0.5207 - accuracy: 0.7922 - val_loss: 0.4779 - val_accuracy: 0.8128\n",
      "Epoch 228/500\n",
      "239/239 [==============================] - 0s 2ms/step - loss: 0.5218 - accuracy: 0.7930 - val_loss: 0.4786 - val_accuracy: 0.8147\n",
      "Epoch 229/500\n",
      "239/239 [==============================] - 0s 2ms/step - loss: 0.5236 - accuracy: 0.7930 - val_loss: 0.4776 - val_accuracy: 0.8163\n",
      "Epoch 230/500\n",
      "239/239 [==============================] - 0s 2ms/step - loss: 0.5220 - accuracy: 0.7927 - val_loss: 0.4754 - val_accuracy: 0.8165\n",
      "Epoch 231/500\n",
      "239/239 [==============================] - 0s 2ms/step - loss: 0.5210 - accuracy: 0.7926 - val_loss: 0.4755 - val_accuracy: 0.8161\n",
      "Epoch 232/500\n",
      "239/239 [==============================] - 0s 2ms/step - loss: 0.5222 - accuracy: 0.7926 - val_loss: 0.4781 - val_accuracy: 0.8154\n",
      "Epoch 233/500\n",
      "239/239 [==============================] - 0s 2ms/step - loss: 0.5234 - accuracy: 0.7938 - val_loss: 0.4782 - val_accuracy: 0.8148\n",
      "Epoch 234/500\n",
      "239/239 [==============================] - 0s 2ms/step - loss: 0.5225 - accuracy: 0.7924 - val_loss: 0.4770 - val_accuracy: 0.8155\n",
      "Epoch 235/500\n",
      "239/239 [==============================] - 0s 2ms/step - loss: 0.5212 - accuracy: 0.7930 - val_loss: 0.4767 - val_accuracy: 0.8138\n",
      "Epoch 236/500\n",
      "239/239 [==============================] - 0s 2ms/step - loss: 0.5212 - accuracy: 0.7932 - val_loss: 0.4762 - val_accuracy: 0.8147\n",
      "Epoch 237/500\n",
      "239/239 [==============================] - 1s 2ms/step - loss: 0.5221 - accuracy: 0.7929 - val_loss: 0.4775 - val_accuracy: 0.8161\n",
      "Epoch 238/500\n",
      "239/239 [==============================] - 0s 2ms/step - loss: 0.5218 - accuracy: 0.7938 - val_loss: 0.4783 - val_accuracy: 0.8146\n",
      "Epoch 239/500\n",
      "239/239 [==============================] - 0s 2ms/step - loss: 0.5205 - accuracy: 0.7931 - val_loss: 0.4751 - val_accuracy: 0.8177\n",
      "Epoch 240/500\n",
      "239/239 [==============================] - 0s 2ms/step - loss: 0.5223 - accuracy: 0.7930 - val_loss: 0.4724 - val_accuracy: 0.8184\n",
      "Epoch 241/500\n",
      "239/239 [==============================] - 0s 2ms/step - loss: 0.5207 - accuracy: 0.7935 - val_loss: 0.4763 - val_accuracy: 0.8158\n",
      "Epoch 242/500\n",
      "239/239 [==============================] - 0s 2ms/step - loss: 0.5212 - accuracy: 0.7939 - val_loss: 0.4773 - val_accuracy: 0.8141\n",
      "Epoch 243/500\n",
      "239/239 [==============================] - 0s 2ms/step - loss: 0.5213 - accuracy: 0.7921 - val_loss: 0.4744 - val_accuracy: 0.8160\n",
      "Epoch 244/500\n",
      "239/239 [==============================] - 0s 2ms/step - loss: 0.5203 - accuracy: 0.7932 - val_loss: 0.4737 - val_accuracy: 0.8161\n",
      "Epoch 245/500\n",
      "239/239 [==============================] - 0s 2ms/step - loss: 0.5187 - accuracy: 0.7945 - val_loss: 0.4772 - val_accuracy: 0.8153\n",
      "Epoch 246/500\n",
      "239/239 [==============================] - 0s 2ms/step - loss: 0.5208 - accuracy: 0.7922 - val_loss: 0.4750 - val_accuracy: 0.8158\n",
      "Epoch 247/500\n",
      "239/239 [==============================] - 0s 2ms/step - loss: 0.5206 - accuracy: 0.7922 - val_loss: 0.4747 - val_accuracy: 0.8163\n",
      "Epoch 248/500\n",
      "239/239 [==============================] - 0s 2ms/step - loss: 0.5209 - accuracy: 0.7942 - val_loss: 0.4752 - val_accuracy: 0.8155\n",
      "Epoch 249/500\n",
      "239/239 [==============================] - 0s 2ms/step - loss: 0.5223 - accuracy: 0.7921 - val_loss: 0.4749 - val_accuracy: 0.8164\n",
      "Epoch 250/500\n",
      "239/239 [==============================] - 0s 2ms/step - loss: 0.5215 - accuracy: 0.7937 - val_loss: 0.4769 - val_accuracy: 0.8162\n",
      "Epoch 251/500\n",
      "239/239 [==============================] - 0s 2ms/step - loss: 0.5190 - accuracy: 0.7940 - val_loss: 0.4747 - val_accuracy: 0.8162\n",
      "Epoch 252/500\n",
      "239/239 [==============================] - 0s 2ms/step - loss: 0.5211 - accuracy: 0.7925 - val_loss: 0.4770 - val_accuracy: 0.8164\n",
      "Epoch 253/500\n",
      "239/239 [==============================] - 0s 2ms/step - loss: 0.5184 - accuracy: 0.7952 - val_loss: 0.4751 - val_accuracy: 0.8161\n",
      "Epoch 254/500\n",
      "239/239 [==============================] - 0s 2ms/step - loss: 0.5210 - accuracy: 0.7935 - val_loss: 0.4737 - val_accuracy: 0.8154\n",
      "Epoch 255/500\n",
      "239/239 [==============================] - 0s 2ms/step - loss: 0.5192 - accuracy: 0.7934 - val_loss: 0.4766 - val_accuracy: 0.8166\n",
      "Epoch 256/500\n",
      "239/239 [==============================] - 0s 2ms/step - loss: 0.5197 - accuracy: 0.7937 - val_loss: 0.4726 - val_accuracy: 0.8172\n",
      "Epoch 257/500\n",
      "239/239 [==============================] - 0s 2ms/step - loss: 0.5177 - accuracy: 0.7937 - val_loss: 0.4765 - val_accuracy: 0.8144\n",
      "Epoch 258/500\n",
      "239/239 [==============================] - 0s 2ms/step - loss: 0.5180 - accuracy: 0.7943 - val_loss: 0.4746 - val_accuracy: 0.8172\n",
      "Epoch 259/500\n",
      "239/239 [==============================] - 0s 2ms/step - loss: 0.5198 - accuracy: 0.7938 - val_loss: 0.4720 - val_accuracy: 0.8173\n",
      "Epoch 260/500\n",
      "239/239 [==============================] - 0s 2ms/step - loss: 0.5191 - accuracy: 0.7943 - val_loss: 0.4743 - val_accuracy: 0.8158\n",
      "Epoch 261/500\n",
      "239/239 [==============================] - 1s 2ms/step - loss: 0.5192 - accuracy: 0.7951 - val_loss: 0.4750 - val_accuracy: 0.8138\n",
      "Epoch 262/500\n",
      "239/239 [==============================] - 0s 2ms/step - loss: 0.5169 - accuracy: 0.7947 - val_loss: 0.4739 - val_accuracy: 0.8164\n",
      "Epoch 263/500\n",
      "239/239 [==============================] - 0s 2ms/step - loss: 0.5191 - accuracy: 0.7942 - val_loss: 0.4745 - val_accuracy: 0.8168\n",
      "Epoch 264/500\n",
      "239/239 [==============================] - 0s 2ms/step - loss: 0.5203 - accuracy: 0.7933 - val_loss: 0.4739 - val_accuracy: 0.8169\n",
      "Epoch 265/500\n",
      "239/239 [==============================] - 0s 2ms/step - loss: 0.5186 - accuracy: 0.7938 - val_loss: 0.4738 - val_accuracy: 0.8167\n",
      "Epoch 266/500\n",
      "239/239 [==============================] - 0s 2ms/step - loss: 0.5212 - accuracy: 0.7935 - val_loss: 0.4746 - val_accuracy: 0.8180\n",
      "Epoch 267/500\n",
      "239/239 [==============================] - 0s 2ms/step - loss: 0.5198 - accuracy: 0.7934 - val_loss: 0.4740 - val_accuracy: 0.8175\n",
      "Epoch 268/500\n",
      "239/239 [==============================] - 0s 2ms/step - loss: 0.5175 - accuracy: 0.7946 - val_loss: 0.4735 - val_accuracy: 0.8156\n",
      "Epoch 269/500\n",
      "239/239 [==============================] - 0s 2ms/step - loss: 0.5194 - accuracy: 0.7942 - val_loss: 0.4722 - val_accuracy: 0.8172\n",
      "Epoch 270/500\n",
      "239/239 [==============================] - 0s 2ms/step - loss: 0.5173 - accuracy: 0.7944 - val_loss: 0.4730 - val_accuracy: 0.8161\n",
      "Epoch 271/500\n",
      "239/239 [==============================] - 0s 2ms/step - loss: 0.5181 - accuracy: 0.7949 - val_loss: 0.4753 - val_accuracy: 0.8180\n",
      "Epoch 272/500\n",
      "239/239 [==============================] - 0s 2ms/step - loss: 0.5208 - accuracy: 0.7932 - val_loss: 0.4717 - val_accuracy: 0.8181\n",
      "Epoch 273/500\n",
      "239/239 [==============================] - 0s 2ms/step - loss: 0.5177 - accuracy: 0.7939 - val_loss: 0.4724 - val_accuracy: 0.8180\n",
      "Epoch 274/500\n",
      "239/239 [==============================] - 0s 2ms/step - loss: 0.5186 - accuracy: 0.7937 - val_loss: 0.4732 - val_accuracy: 0.8170\n",
      "Epoch 275/500\n",
      "239/239 [==============================] - 0s 2ms/step - loss: 0.5186 - accuracy: 0.7949 - val_loss: 0.4732 - val_accuracy: 0.8179\n",
      "Epoch 276/500\n",
      "239/239 [==============================] - 0s 2ms/step - loss: 0.5170 - accuracy: 0.7943 - val_loss: 0.4706 - val_accuracy: 0.8191\n",
      "Epoch 277/500\n",
      "239/239 [==============================] - 0s 2ms/step - loss: 0.5205 - accuracy: 0.7941 - val_loss: 0.4753 - val_accuracy: 0.8190\n",
      "Epoch 278/500\n",
      "239/239 [==============================] - 0s 2ms/step - loss: 0.5194 - accuracy: 0.7949 - val_loss: 0.4739 - val_accuracy: 0.8162\n",
      "Epoch 279/500\n",
      "239/239 [==============================] - 0s 2ms/step - loss: 0.5195 - accuracy: 0.7944 - val_loss: 0.4760 - val_accuracy: 0.8180\n",
      "Epoch 280/500\n",
      "239/239 [==============================] - 0s 2ms/step - loss: 0.5204 - accuracy: 0.7944 - val_loss: 0.4727 - val_accuracy: 0.8172\n",
      "Epoch 281/500\n",
      "239/239 [==============================] - 0s 2ms/step - loss: 0.5169 - accuracy: 0.7946 - val_loss: 0.4739 - val_accuracy: 0.8164\n",
      "Epoch 282/500\n",
      "239/239 [==============================] - 0s 2ms/step - loss: 0.5177 - accuracy: 0.7944 - val_loss: 0.4731 - val_accuracy: 0.8194\n",
      "Epoch 283/500\n",
      "239/239 [==============================] - 0s 2ms/step - loss: 0.5164 - accuracy: 0.7939 - val_loss: 0.4746 - val_accuracy: 0.8168\n",
      "Epoch 284/500\n",
      "239/239 [==============================] - 0s 2ms/step - loss: 0.5173 - accuracy: 0.7948 - val_loss: 0.4729 - val_accuracy: 0.8180\n",
      "Epoch 285/500\n",
      "239/239 [==============================] - 0s 2ms/step - loss: 0.5153 - accuracy: 0.7962 - val_loss: 0.4742 - val_accuracy: 0.8172\n",
      "Epoch 286/500\n",
      "239/239 [==============================] - 0s 2ms/step - loss: 0.5172 - accuracy: 0.7945 - val_loss: 0.4743 - val_accuracy: 0.8158\n",
      "Epoch 287/500\n",
      "239/239 [==============================] - 0s 2ms/step - loss: 0.5181 - accuracy: 0.7949 - val_loss: 0.4718 - val_accuracy: 0.8172\n",
      "Epoch 288/500\n",
      "239/239 [==============================] - 0s 2ms/step - loss: 0.5182 - accuracy: 0.7939 - val_loss: 0.4729 - val_accuracy: 0.8181\n",
      "Epoch 289/500\n",
      "239/239 [==============================] - 0s 2ms/step - loss: 0.5173 - accuracy: 0.7962 - val_loss: 0.4707 - val_accuracy: 0.8189\n",
      "Epoch 290/500\n",
      "239/239 [==============================] - 0s 2ms/step - loss: 0.5164 - accuracy: 0.7950 - val_loss: 0.4724 - val_accuracy: 0.8178\n",
      "Epoch 291/500\n",
      "239/239 [==============================] - 0s 2ms/step - loss: 0.5186 - accuracy: 0.7940 - val_loss: 0.4716 - val_accuracy: 0.8186\n",
      "Epoch 292/500\n",
      "239/239 [==============================] - 0s 2ms/step - loss: 0.5165 - accuracy: 0.7949 - val_loss: 0.4725 - val_accuracy: 0.8180\n",
      "Epoch 293/500\n",
      "239/239 [==============================] - 0s 2ms/step - loss: 0.5176 - accuracy: 0.7943 - val_loss: 0.4759 - val_accuracy: 0.8160\n",
      "Epoch 294/500\n",
      "239/239 [==============================] - 0s 2ms/step - loss: 0.5176 - accuracy: 0.7948 - val_loss: 0.4705 - val_accuracy: 0.8169\n",
      "Epoch 295/500\n",
      "239/239 [==============================] - 1s 2ms/step - loss: 0.5163 - accuracy: 0.7955 - val_loss: 0.4704 - val_accuracy: 0.8172\n",
      "Epoch 296/500\n",
      "239/239 [==============================] - 0s 2ms/step - loss: 0.5166 - accuracy: 0.7952 - val_loss: 0.4706 - val_accuracy: 0.8166\n",
      "Epoch 297/500\n",
      "239/239 [==============================] - 0s 2ms/step - loss: 0.5151 - accuracy: 0.7961 - val_loss: 0.4720 - val_accuracy: 0.8168\n",
      "Epoch 298/500\n",
      "239/239 [==============================] - 1s 2ms/step - loss: 0.5148 - accuracy: 0.7965 - val_loss: 0.4731 - val_accuracy: 0.8163\n",
      "Epoch 299/500\n",
      "239/239 [==============================] - 0s 2ms/step - loss: 0.5161 - accuracy: 0.7954 - val_loss: 0.4680 - val_accuracy: 0.8197\n",
      "Epoch 300/500\n",
      "239/239 [==============================] - 0s 2ms/step - loss: 0.5176 - accuracy: 0.7950 - val_loss: 0.4715 - val_accuracy: 0.8175\n",
      "Epoch 301/500\n",
      "239/239 [==============================] - 0s 2ms/step - loss: 0.5155 - accuracy: 0.7960 - val_loss: 0.4713 - val_accuracy: 0.8190\n",
      "Epoch 302/500\n",
      "239/239 [==============================] - 0s 2ms/step - loss: 0.5164 - accuracy: 0.7949 - val_loss: 0.4705 - val_accuracy: 0.8172\n",
      "Epoch 303/500\n",
      "239/239 [==============================] - 0s 2ms/step - loss: 0.5173 - accuracy: 0.7955 - val_loss: 0.4718 - val_accuracy: 0.8182\n",
      "Epoch 304/500\n",
      "239/239 [==============================] - 0s 2ms/step - loss: 0.5148 - accuracy: 0.7957 - val_loss: 0.4714 - val_accuracy: 0.8168\n",
      "Epoch 305/500\n",
      "239/239 [==============================] - 0s 2ms/step - loss: 0.5144 - accuracy: 0.7951 - val_loss: 0.4722 - val_accuracy: 0.8166\n",
      "Epoch 306/500\n",
      "239/239 [==============================] - 0s 2ms/step - loss: 0.5151 - accuracy: 0.7957 - val_loss: 0.4701 - val_accuracy: 0.8189\n",
      "Epoch 307/500\n",
      "239/239 [==============================] - 0s 2ms/step - loss: 0.5164 - accuracy: 0.7963 - val_loss: 0.4724 - val_accuracy: 0.8182\n",
      "Epoch 308/500\n",
      "239/239 [==============================] - 0s 2ms/step - loss: 0.5134 - accuracy: 0.7972 - val_loss: 0.4693 - val_accuracy: 0.8198\n",
      "Epoch 309/500\n",
      "239/239 [==============================] - 0s 2ms/step - loss: 0.5156 - accuracy: 0.7961 - val_loss: 0.4724 - val_accuracy: 0.8139\n",
      "Epoch 310/500\n",
      "239/239 [==============================] - 0s 2ms/step - loss: 0.5157 - accuracy: 0.7963 - val_loss: 0.4692 - val_accuracy: 0.8192\n",
      "Epoch 311/500\n",
      "239/239 [==============================] - 0s 2ms/step - loss: 0.5170 - accuracy: 0.7959 - val_loss: 0.4716 - val_accuracy: 0.8181\n",
      "Epoch 312/500\n",
      "239/239 [==============================] - 0s 2ms/step - loss: 0.5156 - accuracy: 0.7953 - val_loss: 0.4706 - val_accuracy: 0.8185\n",
      "Epoch 313/500\n",
      "239/239 [==============================] - 0s 2ms/step - loss: 0.5172 - accuracy: 0.7961 - val_loss: 0.4727 - val_accuracy: 0.8186\n",
      "Epoch 314/500\n",
      "239/239 [==============================] - 0s 2ms/step - loss: 0.5158 - accuracy: 0.7950 - val_loss: 0.4716 - val_accuracy: 0.8172\n",
      "Epoch 315/500\n",
      "239/239 [==============================] - 1s 3ms/step - loss: 0.5158 - accuracy: 0.7960 - val_loss: 0.4716 - val_accuracy: 0.8178\n",
      "Epoch 316/500\n",
      "239/239 [==============================] - 0s 2ms/step - loss: 0.5144 - accuracy: 0.7976 - val_loss: 0.4700 - val_accuracy: 0.8186\n",
      "Epoch 317/500\n",
      "239/239 [==============================] - 0s 2ms/step - loss: 0.5151 - accuracy: 0.7957 - val_loss: 0.4713 - val_accuracy: 0.8181\n",
      "Epoch 318/500\n",
      "239/239 [==============================] - 0s 2ms/step - loss: 0.5176 - accuracy: 0.7957 - val_loss: 0.4694 - val_accuracy: 0.8197\n",
      "Epoch 319/500\n",
      "239/239 [==============================] - 0s 2ms/step - loss: 0.5152 - accuracy: 0.7966 - val_loss: 0.4690 - val_accuracy: 0.8198\n",
      "Epoch 320/500\n",
      "239/239 [==============================] - 0s 2ms/step - loss: 0.5147 - accuracy: 0.7966 - val_loss: 0.4716 - val_accuracy: 0.8179\n",
      "Epoch 321/500\n",
      "239/239 [==============================] - 0s 2ms/step - loss: 0.5173 - accuracy: 0.7946 - val_loss: 0.4689 - val_accuracy: 0.8174\n",
      "Epoch 322/500\n",
      "239/239 [==============================] - 0s 2ms/step - loss: 0.5139 - accuracy: 0.7972 - val_loss: 0.4696 - val_accuracy: 0.8178\n",
      "Epoch 323/500\n",
      "239/239 [==============================] - 0s 2ms/step - loss: 0.5155 - accuracy: 0.7966 - val_loss: 0.4701 - val_accuracy: 0.8205\n",
      "Epoch 324/500\n",
      "239/239 [==============================] - 0s 2ms/step - loss: 0.5161 - accuracy: 0.7953 - val_loss: 0.4688 - val_accuracy: 0.8200\n",
      "Epoch 325/500\n",
      "239/239 [==============================] - 0s 2ms/step - loss: 0.5148 - accuracy: 0.7972 - val_loss: 0.4689 - val_accuracy: 0.8203\n",
      "Epoch 326/500\n",
      "239/239 [==============================] - 0s 2ms/step - loss: 0.5176 - accuracy: 0.7954 - val_loss: 0.4728 - val_accuracy: 0.8177\n",
      "Epoch 327/500\n",
      "239/239 [==============================] - 0s 2ms/step - loss: 0.5151 - accuracy: 0.7959 - val_loss: 0.4700 - val_accuracy: 0.8185\n",
      "Epoch 328/500\n",
      "239/239 [==============================] - 0s 2ms/step - loss: 0.5158 - accuracy: 0.7954 - val_loss: 0.4721 - val_accuracy: 0.8184\n",
      "Epoch 329/500\n",
      "239/239 [==============================] - 0s 2ms/step - loss: 0.5148 - accuracy: 0.7956 - val_loss: 0.4693 - val_accuracy: 0.8203\n",
      "Epoch 330/500\n",
      "239/239 [==============================] - 0s 2ms/step - loss: 0.5149 - accuracy: 0.7951 - val_loss: 0.4695 - val_accuracy: 0.8205\n",
      "Epoch 331/500\n",
      "239/239 [==============================] - 0s 2ms/step - loss: 0.5132 - accuracy: 0.7970 - val_loss: 0.4695 - val_accuracy: 0.8212\n",
      "Epoch 332/500\n",
      "239/239 [==============================] - 0s 2ms/step - loss: 0.5160 - accuracy: 0.7970 - val_loss: 0.4691 - val_accuracy: 0.8192\n",
      "Epoch 333/500\n",
      "239/239 [==============================] - 0s 2ms/step - loss: 0.5142 - accuracy: 0.7959 - val_loss: 0.4685 - val_accuracy: 0.8202\n",
      "Epoch 334/500\n",
      "239/239 [==============================] - 0s 2ms/step - loss: 0.5132 - accuracy: 0.7970 - val_loss: 0.4672 - val_accuracy: 0.8202\n",
      "Epoch 335/500\n",
      "239/239 [==============================] - 0s 2ms/step - loss: 0.5136 - accuracy: 0.7968 - val_loss: 0.4685 - val_accuracy: 0.8186\n",
      "Epoch 336/500\n",
      "239/239 [==============================] - 0s 2ms/step - loss: 0.5149 - accuracy: 0.7956 - val_loss: 0.4679 - val_accuracy: 0.8189\n",
      "Epoch 337/500\n",
      "239/239 [==============================] - 0s 2ms/step - loss: 0.5147 - accuracy: 0.7964 - val_loss: 0.4673 - val_accuracy: 0.8189\n",
      "Epoch 338/500\n",
      "239/239 [==============================] - 0s 2ms/step - loss: 0.5135 - accuracy: 0.7976 - val_loss: 0.4687 - val_accuracy: 0.8178\n",
      "Epoch 339/500\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "239/239 [==============================] - 0s 2ms/step - loss: 0.5155 - accuracy: 0.7955 - val_loss: 0.4687 - val_accuracy: 0.8177\n",
      "Epoch 340/500\n",
      "239/239 [==============================] - 0s 2ms/step - loss: 0.5135 - accuracy: 0.7970 - val_loss: 0.4679 - val_accuracy: 0.8192\n",
      "Epoch 341/500\n",
      "239/239 [==============================] - 0s 2ms/step - loss: 0.5119 - accuracy: 0.7986 - val_loss: 0.4680 - val_accuracy: 0.8207\n",
      "Epoch 342/500\n",
      "239/239 [==============================] - 0s 2ms/step - loss: 0.5152 - accuracy: 0.7960 - val_loss: 0.4689 - val_accuracy: 0.8192\n",
      "Epoch 343/500\n",
      "239/239 [==============================] - 0s 2ms/step - loss: 0.5143 - accuracy: 0.7966 - val_loss: 0.4675 - val_accuracy: 0.8196\n",
      "Epoch 344/500\n",
      "239/239 [==============================] - 0s 2ms/step - loss: 0.5143 - accuracy: 0.7962 - val_loss: 0.4691 - val_accuracy: 0.8197\n",
      "Epoch 345/500\n",
      "239/239 [==============================] - 0s 2ms/step - loss: 0.5148 - accuracy: 0.7961 - val_loss: 0.4698 - val_accuracy: 0.8197\n",
      "Epoch 346/500\n",
      "239/239 [==============================] - 0s 2ms/step - loss: 0.5152 - accuracy: 0.7967 - val_loss: 0.4674 - val_accuracy: 0.8203\n",
      "Epoch 347/500\n",
      "239/239 [==============================] - 0s 2ms/step - loss: 0.5124 - accuracy: 0.7980 - val_loss: 0.4674 - val_accuracy: 0.8200\n",
      "Epoch 348/500\n",
      "239/239 [==============================] - 0s 2ms/step - loss: 0.5130 - accuracy: 0.7960 - val_loss: 0.4671 - val_accuracy: 0.8206\n",
      "Epoch 349/500\n",
      "239/239 [==============================] - 0s 2ms/step - loss: 0.5136 - accuracy: 0.7976 - val_loss: 0.4665 - val_accuracy: 0.8191\n",
      "Epoch 350/500\n",
      "239/239 [==============================] - 0s 2ms/step - loss: 0.5139 - accuracy: 0.7972 - val_loss: 0.4685 - val_accuracy: 0.8211\n",
      "Epoch 351/500\n",
      "239/239 [==============================] - 0s 2ms/step - loss: 0.5147 - accuracy: 0.7963 - val_loss: 0.4681 - val_accuracy: 0.8203\n",
      "Epoch 352/500\n",
      "239/239 [==============================] - 0s 2ms/step - loss: 0.5126 - accuracy: 0.7971 - val_loss: 0.4688 - val_accuracy: 0.8200\n",
      "Epoch 353/500\n",
      "239/239 [==============================] - 0s 2ms/step - loss: 0.5153 - accuracy: 0.7969 - val_loss: 0.4707 - val_accuracy: 0.8183\n",
      "Epoch 354/500\n",
      "239/239 [==============================] - 0s 2ms/step - loss: 0.5116 - accuracy: 0.7980 - val_loss: 0.4703 - val_accuracy: 0.8175\n",
      "Epoch 355/500\n",
      "239/239 [==============================] - 0s 2ms/step - loss: 0.5137 - accuracy: 0.7962 - val_loss: 0.4695 - val_accuracy: 0.8193\n",
      "Epoch 356/500\n",
      "239/239 [==============================] - 0s 2ms/step - loss: 0.5125 - accuracy: 0.7970 - val_loss: 0.4705 - val_accuracy: 0.8188\n",
      "Epoch 357/500\n",
      "239/239 [==============================] - 0s 2ms/step - loss: 0.5141 - accuracy: 0.7965 - val_loss: 0.4706 - val_accuracy: 0.8185\n",
      "Epoch 358/500\n",
      "239/239 [==============================] - 0s 2ms/step - loss: 0.5136 - accuracy: 0.7967 - val_loss: 0.4679 - val_accuracy: 0.8188\n",
      "Epoch 359/500\n",
      "239/239 [==============================] - 0s 2ms/step - loss: 0.5129 - accuracy: 0.7974 - val_loss: 0.4695 - val_accuracy: 0.8176\n",
      "Epoch 360/500\n",
      "239/239 [==============================] - 0s 2ms/step - loss: 0.5135 - accuracy: 0.7968 - val_loss: 0.4674 - val_accuracy: 0.8197\n",
      "Epoch 361/500\n",
      "239/239 [==============================] - 0s 2ms/step - loss: 0.5124 - accuracy: 0.7980 - val_loss: 0.4690 - val_accuracy: 0.8193\n",
      "Epoch 362/500\n",
      "239/239 [==============================] - 0s 2ms/step - loss: 0.5124 - accuracy: 0.7973 - val_loss: 0.4695 - val_accuracy: 0.8166\n",
      "Epoch 363/500\n",
      "239/239 [==============================] - 0s 2ms/step - loss: 0.5130 - accuracy: 0.7967 - val_loss: 0.4688 - val_accuracy: 0.8175\n",
      "Epoch 364/500\n",
      "239/239 [==============================] - 0s 2ms/step - loss: 0.5140 - accuracy: 0.7958 - val_loss: 0.4697 - val_accuracy: 0.8194\n",
      "Epoch 365/500\n",
      "239/239 [==============================] - 1s 3ms/step - loss: 0.5119 - accuracy: 0.7978 - val_loss: 0.4686 - val_accuracy: 0.8189\n",
      "Epoch 366/500\n",
      "239/239 [==============================] - 0s 2ms/step - loss: 0.5111 - accuracy: 0.7975 - val_loss: 0.4670 - val_accuracy: 0.8196\n",
      "Epoch 367/500\n",
      "239/239 [==============================] - 0s 2ms/step - loss: 0.5127 - accuracy: 0.7972 - val_loss: 0.4682 - val_accuracy: 0.8186\n",
      "Epoch 368/500\n",
      "239/239 [==============================] - 0s 2ms/step - loss: 0.5127 - accuracy: 0.7964 - val_loss: 0.4683 - val_accuracy: 0.8193\n",
      "Epoch 369/500\n",
      "239/239 [==============================] - 0s 2ms/step - loss: 0.5121 - accuracy: 0.7970 - val_loss: 0.4685 - val_accuracy: 0.8194\n",
      "Epoch 370/500\n",
      "239/239 [==============================] - 0s 2ms/step - loss: 0.5115 - accuracy: 0.7979 - val_loss: 0.4657 - val_accuracy: 0.8201\n",
      "Epoch 371/500\n",
      "239/239 [==============================] - 0s 2ms/step - loss: 0.5094 - accuracy: 0.7978 - val_loss: 0.4668 - val_accuracy: 0.8207\n",
      "Epoch 372/500\n",
      "239/239 [==============================] - 0s 2ms/step - loss: 0.5120 - accuracy: 0.7973 - val_loss: 0.4696 - val_accuracy: 0.8192\n",
      "Epoch 373/500\n",
      "239/239 [==============================] - 0s 2ms/step - loss: 0.5132 - accuracy: 0.7963 - val_loss: 0.4687 - val_accuracy: 0.8185\n",
      "Epoch 374/500\n",
      "239/239 [==============================] - 0s 2ms/step - loss: 0.5109 - accuracy: 0.7987 - val_loss: 0.4653 - val_accuracy: 0.8209\n",
      "Epoch 375/500\n",
      "239/239 [==============================] - 1s 2ms/step - loss: 0.5122 - accuracy: 0.7982 - val_loss: 0.4671 - val_accuracy: 0.8218\n",
      "Epoch 376/500\n",
      "239/239 [==============================] - 0s 2ms/step - loss: 0.5121 - accuracy: 0.7977 - val_loss: 0.4651 - val_accuracy: 0.8215\n",
      "Epoch 377/500\n",
      "239/239 [==============================] - 0s 2ms/step - loss: 0.5112 - accuracy: 0.7990 - val_loss: 0.4654 - val_accuracy: 0.8205\n",
      "Epoch 378/500\n",
      "239/239 [==============================] - 0s 2ms/step - loss: 0.5105 - accuracy: 0.7983 - val_loss: 0.4662 - val_accuracy: 0.8216\n",
      "Epoch 379/500\n",
      "239/239 [==============================] - 0s 2ms/step - loss: 0.5120 - accuracy: 0.7976 - val_loss: 0.4676 - val_accuracy: 0.8218\n",
      "Epoch 380/500\n",
      "239/239 [==============================] - 0s 2ms/step - loss: 0.5118 - accuracy: 0.7974 - val_loss: 0.4688 - val_accuracy: 0.8205\n",
      "Epoch 381/500\n",
      "239/239 [==============================] - 0s 2ms/step - loss: 0.5127 - accuracy: 0.7957 - val_loss: 0.4687 - val_accuracy: 0.8187\n",
      "Epoch 382/500\n",
      "239/239 [==============================] - 0s 2ms/step - loss: 0.5119 - accuracy: 0.7980 - val_loss: 0.4677 - val_accuracy: 0.8194\n",
      "Epoch 383/500\n",
      "239/239 [==============================] - 0s 2ms/step - loss: 0.5123 - accuracy: 0.7982 - val_loss: 0.4693 - val_accuracy: 0.8190\n",
      "Epoch 384/500\n",
      "239/239 [==============================] - 0s 2ms/step - loss: 0.5114 - accuracy: 0.7979 - val_loss: 0.4646 - val_accuracy: 0.8229\n",
      "Epoch 385/500\n",
      "239/239 [==============================] - 0s 2ms/step - loss: 0.5111 - accuracy: 0.7981 - val_loss: 0.4662 - val_accuracy: 0.8204\n",
      "Epoch 386/500\n",
      "239/239 [==============================] - 0s 2ms/step - loss: 0.5110 - accuracy: 0.7979 - val_loss: 0.4674 - val_accuracy: 0.8198\n",
      "Epoch 387/500\n",
      "239/239 [==============================] - 0s 2ms/step - loss: 0.5122 - accuracy: 0.7977 - val_loss: 0.4662 - val_accuracy: 0.8210\n",
      "Epoch 388/500\n",
      "239/239 [==============================] - 0s 2ms/step - loss: 0.5118 - accuracy: 0.7986 - val_loss: 0.4680 - val_accuracy: 0.8186\n",
      "Epoch 389/500\n",
      "239/239 [==============================] - 0s 2ms/step - loss: 0.5109 - accuracy: 0.7971 - val_loss: 0.4678 - val_accuracy: 0.8202\n",
      "Epoch 390/500\n",
      "239/239 [==============================] - 0s 2ms/step - loss: 0.5113 - accuracy: 0.7972 - val_loss: 0.4662 - val_accuracy: 0.8200\n",
      "Epoch 391/500\n",
      "239/239 [==============================] - 0s 2ms/step - loss: 0.5116 - accuracy: 0.7972 - val_loss: 0.4656 - val_accuracy: 0.8205\n",
      "Epoch 392/500\n",
      "239/239 [==============================] - 0s 2ms/step - loss: 0.5110 - accuracy: 0.7974 - val_loss: 0.4653 - val_accuracy: 0.8182\n",
      "Epoch 393/500\n",
      "239/239 [==============================] - 0s 2ms/step - loss: 0.5115 - accuracy: 0.7961 - val_loss: 0.4645 - val_accuracy: 0.8226\n",
      "Epoch 394/500\n",
      "239/239 [==============================] - 0s 2ms/step - loss: 0.5115 - accuracy: 0.7978 - val_loss: 0.4650 - val_accuracy: 0.8201\n",
      "Epoch 395/500\n",
      "239/239 [==============================] - 0s 2ms/step - loss: 0.5107 - accuracy: 0.7983 - val_loss: 0.4654 - val_accuracy: 0.8176\n",
      "Epoch 396/500\n",
      "239/239 [==============================] - 0s 2ms/step - loss: 0.5108 - accuracy: 0.7978 - val_loss: 0.4650 - val_accuracy: 0.8199\n",
      "Epoch 397/500\n",
      "239/239 [==============================] - 0s 2ms/step - loss: 0.5118 - accuracy: 0.7973 - val_loss: 0.4655 - val_accuracy: 0.8211\n",
      "Epoch 398/500\n",
      "239/239 [==============================] - 0s 2ms/step - loss: 0.5099 - accuracy: 0.7986 - val_loss: 0.4668 - val_accuracy: 0.8206\n",
      "Epoch 399/500\n",
      "239/239 [==============================] - 0s 2ms/step - loss: 0.5109 - accuracy: 0.7983 - val_loss: 0.4642 - val_accuracy: 0.8208\n",
      "Epoch 400/500\n",
      "239/239 [==============================] - 0s 2ms/step - loss: 0.5120 - accuracy: 0.7978 - val_loss: 0.4649 - val_accuracy: 0.8224\n",
      "Epoch 401/500\n",
      "239/239 [==============================] - 0s 2ms/step - loss: 0.5118 - accuracy: 0.7978 - val_loss: 0.4663 - val_accuracy: 0.8212\n",
      "Epoch 402/500\n",
      "239/239 [==============================] - 0s 2ms/step - loss: 0.5124 - accuracy: 0.7979 - val_loss: 0.4675 - val_accuracy: 0.8211\n",
      "Epoch 403/500\n",
      "239/239 [==============================] - 0s 2ms/step - loss: 0.5112 - accuracy: 0.7974 - val_loss: 0.4664 - val_accuracy: 0.8201\n",
      "Epoch 404/500\n",
      "239/239 [==============================] - 0s 2ms/step - loss: 0.5089 - accuracy: 0.7991 - val_loss: 0.4639 - val_accuracy: 0.8204\n",
      "Epoch 405/500\n",
      "239/239 [==============================] - 0s 2ms/step - loss: 0.5116 - accuracy: 0.7977 - val_loss: 0.4658 - val_accuracy: 0.8214\n",
      "Epoch 406/500\n",
      "239/239 [==============================] - 0s 2ms/step - loss: 0.5095 - accuracy: 0.7983 - val_loss: 0.4658 - val_accuracy: 0.8211\n",
      "Epoch 407/500\n",
      "239/239 [==============================] - 0s 2ms/step - loss: 0.5121 - accuracy: 0.7975 - val_loss: 0.4660 - val_accuracy: 0.8216\n",
      "Epoch 408/500\n",
      "239/239 [==============================] - 0s 2ms/step - loss: 0.5109 - accuracy: 0.7989 - val_loss: 0.4644 - val_accuracy: 0.8226\n",
      "Epoch 409/500\n",
      "239/239 [==============================] - 0s 2ms/step - loss: 0.5099 - accuracy: 0.7983 - val_loss: 0.4657 - val_accuracy: 0.8211\n",
      "Epoch 410/500\n",
      "239/239 [==============================] - 0s 2ms/step - loss: 0.5106 - accuracy: 0.7981 - val_loss: 0.4633 - val_accuracy: 0.8207\n",
      "Epoch 411/500\n",
      "239/239 [==============================] - 0s 2ms/step - loss: 0.5114 - accuracy: 0.7985 - val_loss: 0.4675 - val_accuracy: 0.8188\n",
      "Epoch 412/500\n",
      "239/239 [==============================] - 0s 2ms/step - loss: 0.5121 - accuracy: 0.7972 - val_loss: 0.4625 - val_accuracy: 0.8240\n",
      "Epoch 413/500\n",
      "239/239 [==============================] - 0s 2ms/step - loss: 0.5100 - accuracy: 0.7981 - val_loss: 0.4644 - val_accuracy: 0.8217\n",
      "Epoch 414/500\n",
      "239/239 [==============================] - 0s 2ms/step - loss: 0.5110 - accuracy: 0.7983 - val_loss: 0.4669 - val_accuracy: 0.8209\n",
      "Epoch 415/500\n",
      "239/239 [==============================] - 0s 2ms/step - loss: 0.5101 - accuracy: 0.7982 - val_loss: 0.4634 - val_accuracy: 0.8221\n",
      "Epoch 416/500\n",
      "239/239 [==============================] - 0s 2ms/step - loss: 0.5103 - accuracy: 0.7980 - val_loss: 0.4633 - val_accuracy: 0.8228\n",
      "Epoch 417/500\n",
      "239/239 [==============================] - 0s 2ms/step - loss: 0.5119 - accuracy: 0.7972 - val_loss: 0.4629 - val_accuracy: 0.8223\n",
      "Epoch 418/500\n",
      "239/239 [==============================] - 0s 2ms/step - loss: 0.5116 - accuracy: 0.7974 - val_loss: 0.4637 - val_accuracy: 0.8224\n",
      "Epoch 419/500\n",
      "239/239 [==============================] - 0s 2ms/step - loss: 0.5088 - accuracy: 0.7995 - val_loss: 0.4632 - val_accuracy: 0.8197\n",
      "Epoch 420/500\n",
      "239/239 [==============================] - 0s 2ms/step - loss: 0.5109 - accuracy: 0.7979 - val_loss: 0.4639 - val_accuracy: 0.8215\n",
      "Epoch 421/500\n",
      "239/239 [==============================] - 0s 2ms/step - loss: 0.5115 - accuracy: 0.7974 - val_loss: 0.4627 - val_accuracy: 0.8232\n",
      "Epoch 422/500\n",
      "239/239 [==============================] - 0s 2ms/step - loss: 0.5098 - accuracy: 0.7987 - val_loss: 0.4644 - val_accuracy: 0.8209\n",
      "Epoch 423/500\n",
      "239/239 [==============================] - 0s 2ms/step - loss: 0.5089 - accuracy: 0.7979 - val_loss: 0.4632 - val_accuracy: 0.8224\n",
      "Epoch 424/500\n",
      "239/239 [==============================] - 0s 2ms/step - loss: 0.5101 - accuracy: 0.7973 - val_loss: 0.4639 - val_accuracy: 0.8227\n",
      "Epoch 425/500\n",
      "239/239 [==============================] - 0s 2ms/step - loss: 0.5098 - accuracy: 0.7982 - val_loss: 0.4667 - val_accuracy: 0.8209\n",
      "Epoch 426/500\n",
      "239/239 [==============================] - 0s 2ms/step - loss: 0.5115 - accuracy: 0.7984 - val_loss: 0.4630 - val_accuracy: 0.8220\n",
      "Epoch 427/500\n",
      "239/239 [==============================] - 0s 2ms/step - loss: 0.5103 - accuracy: 0.7988 - val_loss: 0.4652 - val_accuracy: 0.8213\n",
      "Epoch 428/500\n",
      "239/239 [==============================] - 0s 2ms/step - loss: 0.5083 - accuracy: 0.7987 - val_loss: 0.4667 - val_accuracy: 0.8232\n",
      "Epoch 429/500\n",
      "239/239 [==============================] - 0s 2ms/step - loss: 0.5107 - accuracy: 0.7989 - val_loss: 0.4636 - val_accuracy: 0.8223\n",
      "Epoch 430/500\n",
      "239/239 [==============================] - 0s 2ms/step - loss: 0.5101 - accuracy: 0.7983 - val_loss: 0.4649 - val_accuracy: 0.8216\n",
      "Epoch 431/500\n",
      "239/239 [==============================] - 0s 2ms/step - loss: 0.5124 - accuracy: 0.7970 - val_loss: 0.4623 - val_accuracy: 0.8242\n",
      "Epoch 432/500\n",
      "239/239 [==============================] - 0s 2ms/step - loss: 0.5118 - accuracy: 0.7976 - val_loss: 0.4616 - val_accuracy: 0.8249\n",
      "Epoch 433/500\n",
      "239/239 [==============================] - 0s 2ms/step - loss: 0.5098 - accuracy: 0.7988 - val_loss: 0.4647 - val_accuracy: 0.8217\n",
      "Epoch 434/500\n",
      "239/239 [==============================] - 0s 2ms/step - loss: 0.5083 - accuracy: 0.7991 - val_loss: 0.4603 - val_accuracy: 0.8244\n",
      "Epoch 435/500\n",
      "239/239 [==============================] - 0s 2ms/step - loss: 0.5101 - accuracy: 0.7978 - val_loss: 0.4618 - val_accuracy: 0.8239\n",
      "Epoch 436/500\n",
      "239/239 [==============================] - 0s 2ms/step - loss: 0.5102 - accuracy: 0.7984 - val_loss: 0.4633 - val_accuracy: 0.8221\n",
      "Epoch 437/500\n",
      "239/239 [==============================] - 0s 2ms/step - loss: 0.5112 - accuracy: 0.7983 - val_loss: 0.4654 - val_accuracy: 0.8228\n",
      "Epoch 438/500\n",
      "239/239 [==============================] - 0s 2ms/step - loss: 0.5102 - accuracy: 0.7983 - val_loss: 0.4623 - val_accuracy: 0.8222\n",
      "Epoch 439/500\n",
      "239/239 [==============================] - 0s 2ms/step - loss: 0.5113 - accuracy: 0.7977 - val_loss: 0.4630 - val_accuracy: 0.8209\n",
      "Epoch 440/500\n",
      "239/239 [==============================] - 0s 2ms/step - loss: 0.5104 - accuracy: 0.7985 - val_loss: 0.4650 - val_accuracy: 0.8216\n",
      "Epoch 441/500\n",
      "239/239 [==============================] - 0s 2ms/step - loss: 0.5098 - accuracy: 0.7985 - val_loss: 0.4651 - val_accuracy: 0.8215\n",
      "Epoch 442/500\n",
      "239/239 [==============================] - 0s 2ms/step - loss: 0.5051 - accuracy: 0.7999 - val_loss: 0.4628 - val_accuracy: 0.8216\n",
      "Epoch 443/500\n",
      "239/239 [==============================] - 0s 2ms/step - loss: 0.5108 - accuracy: 0.7981 - val_loss: 0.4660 - val_accuracy: 0.8215\n",
      "Epoch 444/500\n",
      "239/239 [==============================] - 1s 2ms/step - loss: 0.5083 - accuracy: 0.7991 - val_loss: 0.4635 - val_accuracy: 0.8208\n",
      "Epoch 445/500\n",
      "239/239 [==============================] - 0s 2ms/step - loss: 0.5095 - accuracy: 0.7982 - val_loss: 0.4627 - val_accuracy: 0.8224\n",
      "Epoch 446/500\n",
      "239/239 [==============================] - 0s 2ms/step - loss: 0.5083 - accuracy: 0.7996 - val_loss: 0.4617 - val_accuracy: 0.8227\n",
      "Epoch 447/500\n",
      "239/239 [==============================] - 0s 2ms/step - loss: 0.5098 - accuracy: 0.8000 - val_loss: 0.4653 - val_accuracy: 0.8191\n",
      "Epoch 448/500\n",
      "239/239 [==============================] - 0s 2ms/step - loss: 0.5086 - accuracy: 0.7987 - val_loss: 0.4618 - val_accuracy: 0.8233\n",
      "Epoch 449/500\n",
      "239/239 [==============================] - 0s 2ms/step - loss: 0.5073 - accuracy: 0.7990 - val_loss: 0.4647 - val_accuracy: 0.8211\n",
      "Epoch 450/500\n",
      "239/239 [==============================] - 0s 2ms/step - loss: 0.5074 - accuracy: 0.7996 - val_loss: 0.4617 - val_accuracy: 0.8214\n",
      "Epoch 451/500\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "239/239 [==============================] - 0s 2ms/step - loss: 0.5085 - accuracy: 0.7985 - val_loss: 0.4633 - val_accuracy: 0.8221\n",
      "Epoch 452/500\n",
      "239/239 [==============================] - 0s 2ms/step - loss: 0.5081 - accuracy: 0.8003 - val_loss: 0.4622 - val_accuracy: 0.8246\n",
      "Epoch 453/500\n",
      "239/239 [==============================] - 0s 2ms/step - loss: 0.5076 - accuracy: 0.8006 - val_loss: 0.4622 - val_accuracy: 0.8208\n",
      "Epoch 454/500\n",
      "239/239 [==============================] - 0s 2ms/step - loss: 0.5089 - accuracy: 0.7991 - val_loss: 0.4621 - val_accuracy: 0.8230\n",
      "Epoch 455/500\n",
      "239/239 [==============================] - 0s 2ms/step - loss: 0.5078 - accuracy: 0.7998 - val_loss: 0.4630 - val_accuracy: 0.8226\n",
      "Epoch 456/500\n",
      "239/239 [==============================] - 0s 2ms/step - loss: 0.5083 - accuracy: 0.7986 - val_loss: 0.4652 - val_accuracy: 0.8225\n",
      "Epoch 457/500\n",
      "239/239 [==============================] - 0s 2ms/step - loss: 0.5073 - accuracy: 0.7996 - val_loss: 0.4635 - val_accuracy: 0.8225\n",
      "Epoch 458/500\n",
      "239/239 [==============================] - 0s 2ms/step - loss: 0.5100 - accuracy: 0.7988 - val_loss: 0.4660 - val_accuracy: 0.8217\n",
      "Epoch 459/500\n",
      "239/239 [==============================] - 0s 2ms/step - loss: 0.5084 - accuracy: 0.7998 - val_loss: 0.4622 - val_accuracy: 0.8225\n",
      "Epoch 460/500\n",
      "239/239 [==============================] - 0s 2ms/step - loss: 0.5057 - accuracy: 0.8014 - val_loss: 0.4621 - val_accuracy: 0.8217\n",
      "Epoch 461/500\n",
      "239/239 [==============================] - 0s 2ms/step - loss: 0.5066 - accuracy: 0.8013 - val_loss: 0.4638 - val_accuracy: 0.8227\n",
      "Epoch 462/500\n",
      "239/239 [==============================] - 0s 2ms/step - loss: 0.5076 - accuracy: 0.8000 - val_loss: 0.4678 - val_accuracy: 0.8192\n",
      "Epoch 463/500\n",
      "239/239 [==============================] - 0s 2ms/step - loss: 0.5078 - accuracy: 0.7991 - val_loss: 0.4632 - val_accuracy: 0.8217\n",
      "Epoch 464/500\n",
      "239/239 [==============================] - 0s 2ms/step - loss: 0.5090 - accuracy: 0.7987 - val_loss: 0.4642 - val_accuracy: 0.8236\n",
      "Epoch 465/500\n",
      "239/239 [==============================] - 0s 2ms/step - loss: 0.5071 - accuracy: 0.7996 - val_loss: 0.4599 - val_accuracy: 0.8241\n",
      "Epoch 466/500\n",
      "239/239 [==============================] - 0s 2ms/step - loss: 0.5076 - accuracy: 0.7997 - val_loss: 0.4619 - val_accuracy: 0.8239\n",
      "Epoch 467/500\n",
      "239/239 [==============================] - 0s 2ms/step - loss: 0.5054 - accuracy: 0.8012 - val_loss: 0.4595 - val_accuracy: 0.8237\n",
      "Epoch 468/500\n",
      "239/239 [==============================] - 0s 2ms/step - loss: 0.5067 - accuracy: 0.8006 - val_loss: 0.4608 - val_accuracy: 0.8240\n",
      "Epoch 469/500\n",
      "239/239 [==============================] - 0s 2ms/step - loss: 0.5069 - accuracy: 0.8001 - val_loss: 0.4580 - val_accuracy: 0.8251\n",
      "Epoch 470/500\n",
      "239/239 [==============================] - 0s 2ms/step - loss: 0.5082 - accuracy: 0.7989 - val_loss: 0.4600 - val_accuracy: 0.8239\n",
      "Epoch 471/500\n",
      "239/239 [==============================] - 0s 2ms/step - loss: 0.5098 - accuracy: 0.7984 - val_loss: 0.4617 - val_accuracy: 0.8239\n",
      "Epoch 472/500\n",
      "239/239 [==============================] - 0s 2ms/step - loss: 0.5078 - accuracy: 0.8010 - val_loss: 0.4599 - val_accuracy: 0.8237\n",
      "Epoch 473/500\n",
      "239/239 [==============================] - 0s 2ms/step - loss: 0.5079 - accuracy: 0.7985 - val_loss: 0.4621 - val_accuracy: 0.8217\n",
      "Epoch 474/500\n",
      "239/239 [==============================] - 0s 2ms/step - loss: 0.5077 - accuracy: 0.8004 - val_loss: 0.4604 - val_accuracy: 0.8238\n",
      "Epoch 475/500\n",
      "239/239 [==============================] - 0s 2ms/step - loss: 0.5066 - accuracy: 0.8009 - val_loss: 0.4602 - val_accuracy: 0.8224\n",
      "Epoch 476/500\n",
      "239/239 [==============================] - 0s 2ms/step - loss: 0.5090 - accuracy: 0.7988 - val_loss: 0.4602 - val_accuracy: 0.8232\n",
      "Epoch 477/500\n",
      "239/239 [==============================] - 0s 2ms/step - loss: 0.5076 - accuracy: 0.8000 - val_loss: 0.4615 - val_accuracy: 0.8213\n",
      "Epoch 478/500\n",
      "239/239 [==============================] - 0s 2ms/step - loss: 0.5062 - accuracy: 0.8011 - val_loss: 0.4608 - val_accuracy: 0.8229\n",
      "Epoch 479/500\n",
      "239/239 [==============================] - 0s 2ms/step - loss: 0.5078 - accuracy: 0.7996 - val_loss: 0.4614 - val_accuracy: 0.8228\n",
      "Epoch 480/500\n",
      "239/239 [==============================] - 0s 2ms/step - loss: 0.5091 - accuracy: 0.7994 - val_loss: 0.4623 - val_accuracy: 0.8237\n",
      "Epoch 481/500\n",
      "239/239 [==============================] - 0s 2ms/step - loss: 0.5082 - accuracy: 0.8009 - val_loss: 0.4638 - val_accuracy: 0.8226\n",
      "Epoch 482/500\n",
      "239/239 [==============================] - 1s 2ms/step - loss: 0.5069 - accuracy: 0.8005 - val_loss: 0.4605 - val_accuracy: 0.8214\n",
      "Epoch 483/500\n",
      "239/239 [==============================] - 0s 2ms/step - loss: 0.5070 - accuracy: 0.8008 - val_loss: 0.4632 - val_accuracy: 0.8209\n",
      "Epoch 484/500\n",
      "239/239 [==============================] - 0s 2ms/step - loss: 0.5073 - accuracy: 0.8003 - val_loss: 0.4648 - val_accuracy: 0.8215\n",
      "Epoch 485/500\n",
      "239/239 [==============================] - 0s 2ms/step - loss: 0.5071 - accuracy: 0.8002 - val_loss: 0.4642 - val_accuracy: 0.8221\n",
      "Epoch 486/500\n",
      "239/239 [==============================] - 0s 2ms/step - loss: 0.5048 - accuracy: 0.7997 - val_loss: 0.4615 - val_accuracy: 0.8235\n",
      "Epoch 487/500\n",
      "239/239 [==============================] - 0s 2ms/step - loss: 0.5073 - accuracy: 0.7996 - val_loss: 0.4637 - val_accuracy: 0.8226\n",
      "Epoch 488/500\n",
      "239/239 [==============================] - 0s 2ms/step - loss: 0.5071 - accuracy: 0.8006 - val_loss: 0.4610 - val_accuracy: 0.8240\n",
      "Epoch 489/500\n",
      "239/239 [==============================] - 0s 2ms/step - loss: 0.5088 - accuracy: 0.7988 - val_loss: 0.4602 - val_accuracy: 0.8222\n",
      "Epoch 490/500\n",
      "239/239 [==============================] - 0s 2ms/step - loss: 0.5066 - accuracy: 0.8008 - val_loss: 0.4625 - val_accuracy: 0.8228\n",
      "Epoch 491/500\n",
      "239/239 [==============================] - 0s 2ms/step - loss: 0.5059 - accuracy: 0.7999 - val_loss: 0.4609 - val_accuracy: 0.8225\n",
      "Epoch 492/500\n",
      "239/239 [==============================] - 0s 2ms/step - loss: 0.5062 - accuracy: 0.8004 - val_loss: 0.4618 - val_accuracy: 0.8217\n",
      "Epoch 493/500\n",
      "239/239 [==============================] - 0s 2ms/step - loss: 0.5081 - accuracy: 0.8003 - val_loss: 0.4629 - val_accuracy: 0.8223\n",
      "Epoch 494/500\n",
      "239/239 [==============================] - 0s 2ms/step - loss: 0.5070 - accuracy: 0.7997 - val_loss: 0.4623 - val_accuracy: 0.8225\n",
      "Epoch 495/500\n",
      "239/239 [==============================] - 0s 2ms/step - loss: 0.5074 - accuracy: 0.7999 - val_loss: 0.4605 - val_accuracy: 0.8236\n",
      "Epoch 496/500\n",
      "239/239 [==============================] - 0s 2ms/step - loss: 0.5055 - accuracy: 0.8010 - val_loss: 0.4600 - val_accuracy: 0.8234\n",
      "Epoch 497/500\n",
      "239/239 [==============================] - 0s 2ms/step - loss: 0.5083 - accuracy: 0.8000 - val_loss: 0.4627 - val_accuracy: 0.8225\n",
      "Epoch 498/500\n",
      "239/239 [==============================] - 0s 2ms/step - loss: 0.5068 - accuracy: 0.8001 - val_loss: 0.4613 - val_accuracy: 0.8235\n",
      "Epoch 499/500\n",
      "239/239 [==============================] - 1s 2ms/step - loss: 0.5073 - accuracy: 0.7999 - val_loss: 0.4613 - val_accuracy: 0.8216\n",
      "Epoch 500/500\n",
      "239/239 [==============================] - 0s 2ms/step - loss: 0.5074 - accuracy: 0.8001 - val_loss: 0.4580 - val_accuracy: 0.8245\n"
     ]
    }
   ],
   "source": [
    "model=Sequential()\n",
    "model.add(Dense(128, input_dim=X_train.shape[1], activation=\"relu\"))\n",
    "model.add(Dropout(0.2))\n",
    "model.add(Dense(128, activation=\"relu\"))\n",
    "model.add(Dropout(0.2))\n",
    "model.add(Dense(64, activation=\"relu\"))\n",
    "model.add(Dropout(0.2))\n",
    "model.add(Dense(64, activation=\"relu\"))\n",
    "model.add(Dropout(0.2))\n",
    "model.add(Dense(3, activation=\"softmax\"))\n",
    "model.compile(loss='categorical_crossentropy', optimizer=Adam(learning_rate=0.001), metrics=['accuracy'])\n",
    "\n",
    "es=EarlyStopping(monitor=\"val_loss\",patience=50,mode=\"auto\",verbose=1)\n",
    "\n",
    "ann1 = model.fit(X_train,\n",
    "          y_train,\n",
    "          epochs=500,\n",
    "               batch_size=512,\n",
    "               validation_split=0.1,\n",
    "               verbose=1,callbacks=[es])\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "executionInfo": {
     "elapsed": 352,
     "status": "ok",
     "timestamp": 1705656179525,
     "user": {
      "displayName": "Canan Dülgeroğlu",
      "userId": "00060531196188721276"
     },
     "user_tz": -180
    },
    "id": "qLheE9jYB83R",
    "outputId": "caee2c97-e4d9-4a94-8f24-671d1e52db19"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Model: \"sequential\"\n",
      "_________________________________________________________________\n",
      " Layer (type)                Output Shape              Param #   \n",
      "=================================================================\n",
      " dense (Dense)               (None, 128)               2688      \n",
      "                                                                 \n",
      " dropout (Dropout)           (None, 128)               0         \n",
      "                                                                 \n",
      " dense_1 (Dense)             (None, 128)               16512     \n",
      "                                                                 \n",
      " dropout_1 (Dropout)         (None, 128)               0         \n",
      "                                                                 \n",
      " dense_2 (Dense)             (None, 64)                8256      \n",
      "                                                                 \n",
      " dropout_2 (Dropout)         (None, 64)                0         \n",
      "                                                                 \n",
      " dense_3 (Dense)             (None, 64)                4160      \n",
      "                                                                 \n",
      " dropout_3 (Dropout)         (None, 64)                0         \n",
      "                                                                 \n",
      " dense_4 (Dense)             (None, 3)                 195       \n",
      "                                                                 \n",
      "=================================================================\n",
      "Total params: 31811 (124.26 KB)\n",
      "Trainable params: 31811 (124.26 KB)\n",
      "Non-trainable params: 0 (0.00 Byte)\n",
      "_________________________________________________________________\n"
     ]
    }
   ],
   "source": [
    "model.summary()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 401
    },
    "executionInfo": {
     "elapsed": 3920,
     "status": "ok",
     "timestamp": 1705656062743,
     "user": {
      "displayName": "Canan Dülgeroğlu",
      "userId": "00060531196188721276"
     },
     "user_tz": -180
    },
    "id": "ymq2lFjtBLz7",
    "outputId": "dad7c882-e4a8-4e26-eee1-a1827e21615e"
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "<Axes: >"
      ]
     },
     "execution_count": 25,
     "metadata": {},
     "output_type": "execute_result"
    },
    {
     "data": {
      "image/png": "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\n",
      "text/plain": [
       "<Figure size 1200x600 with 1 Axes>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "loss_df = pd.DataFrame(model.history.history)\n",
    "loss_df.plot();"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "4236/4236 - 1s - loss: 0.4036 - accuracy: 0.8476 - 976ms/epoch - 230us/step\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "[0.40357309579849243, 0.8476488590240479]"
      ]
     },
     "execution_count": 20,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "model.evaluate(X_train, y_train, verbose=2) # modeli üçüncü çalıştırdığımda aldığım skor"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 62,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "executionInfo": {
     "elapsed": 10105,
     "status": "ok",
     "timestamp": 1705664457672,
     "user": {
      "displayName": "Canan Dülgeroğlu",
      "userId": "00060531196188721276"
     },
     "user_tz": -180
    },
    "id": "NEE5soKoel47",
    "outputId": "89edb688-747b-4193-cd1d-4971c4150342"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "4236/4236 - 10s - loss: 0.4082 - accuracy: 0.8463 - 10s/epoch - 2ms/step\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "[0.4081869125366211, 0.8462837934494019]"
      ]
     },
     "execution_count": 62,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "model.evaluate(X_train, y_train, verbose=2) # modeli ikinci çalıştırdığımda aldığım skor"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 28,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "executionInfo": {
     "elapsed": 10235,
     "status": "ok",
     "timestamp": 1705656329125,
     "user": {
      "displayName": "Canan Dülgeroğlu",
      "userId": "00060531196188721276"
     },
     "user_tz": -180
    },
    "id": "82dN0Rq6BLpG",
    "outputId": "df49e8b9-61a8-4f1b-bb8e-6ac97f12fc93"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "3987/3987 - 9s - loss: 0.4071 - accuracy: 0.8459 - 9s/epoch - 2ms/step\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "[0.40714719891548157, 0.84586501121521]"
      ]
     },
     "execution_count": 28,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "model.evaluate(X_train, y_train, verbose=2) # modeli ilk çalıştırdığımda aldığım skor"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "metadata": {
    "executionInfo": {
     "elapsed": 9378,
     "status": "ok",
     "timestamp": 1705664786705,
     "user": {
      "displayName": "Canan Dülgeroğlu",
      "userId": "00060531196188721276"
     },
     "user_tz": -180
    },
    "id": "B-6PI1A2f40P"
   },
   "outputs": [],
   "source": [
    "from sklearn.metrics import classification_report, ConfusionMatrixDisplay\n",
    "import tensorflow as tf\n",
    "\n",
    "from tensorflow.keras import Sequential, layers, initializers, losses, optimizers, regularizers"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "748/748 [==============================] - 0s 248us/step\n",
      "Karışıklık Matrisi:\n",
      "[[7440   48  485]\n",
      " [ 217 7077  679]\n",
      " [1386 1507 5079]]\n",
      "\n",
      "Sınıf Bazında Precision Değerleri:\n",
      "[0.82273582 0.81985635 0.81355118]\n",
      "\n",
      "Sınıf Bazında Recall Değerleri:\n",
      "[0.93314938 0.88762072 0.63710487]\n",
      "\n",
      "Weighted F1 Skoru:\n",
      "0.8138248817281443\n"
     ]
    }
   ],
   "source": [
    "from sklearn.metrics import confusion_matrix, f1_score, precision_score, recall_score\n",
    "\n",
    "# Modelinizin tahminleri ve gerçek etiketleri kullanarak karışıklık matrisini oluşturun\n",
    "y_pred = model.predict(X_test)\n",
    "y_pred_classes = np.argmax(y_pred, axis=1)\n",
    "y_true = np.argmax(y_test, axis=1)\n",
    "conf_matrix = confusion_matrix(y_true, y_pred_classes)\n",
    "\n",
    "# Sınıf bazında precision (kesinlik) ve recall (hatırlama) değerlerini hesaplayın\n",
    "precision = precision_score(y_true, y_pred_classes, average=None)\n",
    "recall = recall_score(y_true, y_pred_classes, average=None)\n",
    "\n",
    "# Precision ve recall değerlerini kullanarak F1 skorunu hesaplayın\n",
    "f1 = f1_score(y_true, y_pred_classes, average='weighted')\n",
    "\n",
    "print(\"Karışıklık Matrisi:\")\n",
    "print(conf_matrix)\n",
    "print(\"\\nSınıf Bazında Precision Değerleri:\")\n",
    "print(precision)\n",
    "print(\"\\nSınıf Bazında Recall Değerleri:\")\n",
    "print(recall)\n",
    "print(\"\\nWeighted F1 Skoru:\")\n",
    "print(f1)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 26,
   "metadata": {
    "id": "l4G_USHVepGR",
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0       0.82      0.93      0.87      7973\n",
      "           1       0.82      0.89      0.85      7973\n",
      "           2       0.81      0.64      0.71      7972\n",
      "\n",
      "    accuracy                           0.82     23918\n",
      "   macro avg       0.82      0.82      0.81     23918\n",
      "weighted avg       0.82      0.82      0.81     23918\n",
      "\n"
     ]
    }
   ],
   "source": [
    "y_pred = model.predict(X_test)\n",
    "y_pred_classes = np.argmax(y_pred, axis=1)\n",
    "y_true = np.argmax(y_test, axis=1)\n",
    "print(classification_report(y_true, y_pred_classes))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 28,
   "metadata": {
    "id": "l4G_USHVepGR",
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "4236/4236 [==============================] - 1s 237us/step\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0       0.85      0.95      0.90     45176\n",
      "           1       0.84      0.91      0.87     45176\n",
      "           2       0.86      0.68      0.76     45177\n",
      "\n",
      "    accuracy                           0.85    135529\n",
      "   macro avg       0.85      0.85      0.84    135529\n",
      "weighted avg       0.85      0.85      0.84    135529\n",
      "\n"
     ]
    }
   ],
   "source": [
    "y_t_pred = model.predict(X_train)\n",
    "y_t_pred_classes = np.argmax(y_t_pred, axis=1)\n",
    "y_t_true = np.argmax(y_train, axis=1)\n",
    "print(classification_report(y_t_true, y_t_pred_classes))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 29,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 250
    },
    "executionInfo": {
     "elapsed": 287,
     "status": "error",
     "timestamp": 1705665233408,
     "user": {
      "displayName": "Canan Dülgeroğlu",
      "userId": "00060531196188721276"
     },
     "user_tz": -180
    },
    "id": "46dcf0KSepCh",
    "outputId": "ebb93e4e-e4bd-408a-ae44-a53e5ef24f39"
   },
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "WARNING:absl:At this time, the v2.11+ optimizer `tf.keras.optimizers.Adam` runs slowly on M1/M2 Macs, please use the legacy Keras optimizer instead, located at `tf.keras.optimizers.legacy.Adam`.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 1/500\n",
      "953/953 [==============================] - 1s 1ms/step - loss: 0.7233 - accuracy: 0.7164 - val_loss: 0.6692 - val_accuracy: 0.7409\n",
      "Epoch 2/500\n",
      "953/953 [==============================] - 1s 911us/step - loss: 0.6817 - accuracy: 0.7356 - val_loss: 0.6549 - val_accuracy: 0.7440\n",
      "Epoch 3/500\n",
      "953/953 [==============================] - 1s 908us/step - loss: 0.6678 - accuracy: 0.7394 - val_loss: 0.6432 - val_accuracy: 0.7483\n",
      "Epoch 4/500\n",
      "953/953 [==============================] - 1s 912us/step - loss: 0.6597 - accuracy: 0.7414 - val_loss: 0.6379 - val_accuracy: 0.7494\n",
      "Epoch 5/500\n",
      "953/953 [==============================] - 1s 931us/step - loss: 0.6530 - accuracy: 0.7434 - val_loss: 0.6354 - val_accuracy: 0.7506\n",
      "Epoch 6/500\n",
      "953/953 [==============================] - 1s 928us/step - loss: 0.6458 - accuracy: 0.7462 - val_loss: 0.6207 - val_accuracy: 0.7544\n",
      "Epoch 7/500\n",
      "953/953 [==============================] - 1s 928us/step - loss: 0.6391 - accuracy: 0.7482 - val_loss: 0.6204 - val_accuracy: 0.7570\n",
      "Epoch 8/500\n",
      "953/953 [==============================] - 1s 914us/step - loss: 0.6347 - accuracy: 0.7497 - val_loss: 0.6111 - val_accuracy: 0.7584\n",
      "Epoch 9/500\n",
      "953/953 [==============================] - 1s 916us/step - loss: 0.6272 - accuracy: 0.7530 - val_loss: 0.6069 - val_accuracy: 0.7613\n",
      "Epoch 10/500\n",
      "953/953 [==============================] - 1s 944us/step - loss: 0.6222 - accuracy: 0.7541 - val_loss: 0.5988 - val_accuracy: 0.7630\n",
      "Epoch 11/500\n",
      "953/953 [==============================] - 1s 946us/step - loss: 0.6177 - accuracy: 0.7561 - val_loss: 0.5930 - val_accuracy: 0.7645\n",
      "Epoch 12/500\n",
      "953/953 [==============================] - 1s 943us/step - loss: 0.6131 - accuracy: 0.7565 - val_loss: 0.5882 - val_accuracy: 0.7648\n",
      "Epoch 13/500\n",
      "953/953 [==============================] - 1s 949us/step - loss: 0.6075 - accuracy: 0.7595 - val_loss: 0.5811 - val_accuracy: 0.7696\n",
      "Epoch 14/500\n",
      "953/953 [==============================] - 1s 916us/step - loss: 0.6039 - accuracy: 0.7609 - val_loss: 0.5783 - val_accuracy: 0.7714\n",
      "Epoch 15/500\n",
      "953/953 [==============================] - 1s 919us/step - loss: 0.6007 - accuracy: 0.7612 - val_loss: 0.5742 - val_accuracy: 0.7727\n",
      "Epoch 16/500\n",
      "953/953 [==============================] - 1s 918us/step - loss: 0.5966 - accuracy: 0.7629 - val_loss: 0.5690 - val_accuracy: 0.7733\n",
      "Epoch 17/500\n",
      "953/953 [==============================] - 1s 918us/step - loss: 0.5939 - accuracy: 0.7632 - val_loss: 0.5692 - val_accuracy: 0.7751\n",
      "Epoch 18/500\n",
      "953/953 [==============================] - 1s 918us/step - loss: 0.5908 - accuracy: 0.7647 - val_loss: 0.5641 - val_accuracy: 0.7754\n",
      "Epoch 19/500\n",
      "953/953 [==============================] - 1s 915us/step - loss: 0.5870 - accuracy: 0.7664 - val_loss: 0.5607 - val_accuracy: 0.7778\n",
      "Epoch 20/500\n",
      "953/953 [==============================] - 1s 949us/step - loss: 0.5845 - accuracy: 0.7674 - val_loss: 0.5579 - val_accuracy: 0.7792\n",
      "Epoch 21/500\n",
      "953/953 [==============================] - 1s 920us/step - loss: 0.5819 - accuracy: 0.7676 - val_loss: 0.5546 - val_accuracy: 0.7829\n",
      "Epoch 22/500\n",
      "953/953 [==============================] - 1s 949us/step - loss: 0.5792 - accuracy: 0.7689 - val_loss: 0.5501 - val_accuracy: 0.7837\n",
      "Epoch 23/500\n",
      "953/953 [==============================] - 1s 961us/step - loss: 0.5770 - accuracy: 0.7709 - val_loss: 0.5471 - val_accuracy: 0.7834\n",
      "Epoch 24/500\n",
      "953/953 [==============================] - 1s 919us/step - loss: 0.5759 - accuracy: 0.7708 - val_loss: 0.5453 - val_accuracy: 0.7879\n",
      "Epoch 25/500\n",
      "953/953 [==============================] - 1s 924us/step - loss: 0.5753 - accuracy: 0.7716 - val_loss: 0.5417 - val_accuracy: 0.7867\n",
      "Epoch 26/500\n",
      "953/953 [==============================] - 1s 925us/step - loss: 0.5714 - accuracy: 0.7727 - val_loss: 0.5433 - val_accuracy: 0.7846\n",
      "Epoch 27/500\n",
      "953/953 [==============================] - 1s 942us/step - loss: 0.5689 - accuracy: 0.7735 - val_loss: 0.5396 - val_accuracy: 0.7871\n",
      "Epoch 28/500\n",
      "953/953 [==============================] - 1s 944us/step - loss: 0.5670 - accuracy: 0.7737 - val_loss: 0.5364 - val_accuracy: 0.7903\n",
      "Epoch 29/500\n",
      "953/953 [==============================] - 1s 944us/step - loss: 0.5680 - accuracy: 0.7734 - val_loss: 0.5347 - val_accuracy: 0.7899\n",
      "Epoch 30/500\n",
      "953/953 [==============================] - 1s 1ms/step - loss: 0.5648 - accuracy: 0.7737 - val_loss: 0.5326 - val_accuracy: 0.7945\n",
      "Epoch 31/500\n",
      "953/953 [==============================] - 1s 996us/step - loss: 0.5652 - accuracy: 0.7733 - val_loss: 0.5307 - val_accuracy: 0.7908\n",
      "Epoch 32/500\n",
      "953/953 [==============================] - 1s 945us/step - loss: 0.5610 - accuracy: 0.7771 - val_loss: 0.5304 - val_accuracy: 0.7910\n",
      "Epoch 33/500\n",
      "953/953 [==============================] - 1s 983us/step - loss: 0.5600 - accuracy: 0.7763 - val_loss: 0.5248 - val_accuracy: 0.7913\n",
      "Epoch 34/500\n",
      "953/953 [==============================] - 1s 921us/step - loss: 0.5580 - accuracy: 0.7767 - val_loss: 0.5252 - val_accuracy: 0.7936\n",
      "Epoch 35/500\n",
      "953/953 [==============================] - 1s 978us/step - loss: 0.5586 - accuracy: 0.7790 - val_loss: 0.5207 - val_accuracy: 0.7941\n",
      "Epoch 36/500\n",
      "953/953 [==============================] - 1s 967us/step - loss: 0.5574 - accuracy: 0.7770 - val_loss: 0.5233 - val_accuracy: 0.7941\n",
      "Epoch 37/500\n",
      "953/953 [==============================] - 1s 919us/step - loss: 0.5557 - accuracy: 0.7782 - val_loss: 0.5239 - val_accuracy: 0.7960\n",
      "Epoch 38/500\n",
      "953/953 [==============================] - 1s 944us/step - loss: 0.5532 - accuracy: 0.7782 - val_loss: 0.5199 - val_accuracy: 0.7955\n",
      "Epoch 39/500\n",
      "953/953 [==============================] - 1s 957us/step - loss: 0.5540 - accuracy: 0.7790 - val_loss: 0.5197 - val_accuracy: 0.7937\n",
      "Epoch 40/500\n",
      "953/953 [==============================] - 1s 1ms/step - loss: 0.5497 - accuracy: 0.7797 - val_loss: 0.5174 - val_accuracy: 0.7936\n",
      "Epoch 41/500\n",
      "953/953 [==============================] - 1s 1ms/step - loss: 0.5504 - accuracy: 0.7797 - val_loss: 0.5163 - val_accuracy: 0.7952\n",
      "Epoch 42/500\n",
      "953/953 [==============================] - 1s 941us/step - loss: 0.5512 - accuracy: 0.7800 - val_loss: 0.5137 - val_accuracy: 0.7997\n",
      "Epoch 43/500\n",
      "953/953 [==============================] - 1s 944us/step - loss: 0.5475 - accuracy: 0.7810 - val_loss: 0.5112 - val_accuracy: 0.7993\n",
      "Epoch 44/500\n",
      "953/953 [==============================] - 1s 917us/step - loss: 0.5488 - accuracy: 0.7800 - val_loss: 0.5116 - val_accuracy: 0.7972\n",
      "Epoch 45/500\n",
      "953/953 [==============================] - 1s 920us/step - loss: 0.5473 - accuracy: 0.7816 - val_loss: 0.5144 - val_accuracy: 0.8012\n",
      "Epoch 46/500\n",
      "953/953 [==============================] - 1s 974us/step - loss: 0.5469 - accuracy: 0.7818 - val_loss: 0.5069 - val_accuracy: 0.8018\n",
      "Epoch 47/500\n",
      "953/953 [==============================] - 1s 1ms/step - loss: 0.5446 - accuracy: 0.7826 - val_loss: 0.5095 - val_accuracy: 0.8014\n",
      "Epoch 48/500\n",
      "953/953 [==============================] - 1s 925us/step - loss: 0.5430 - accuracy: 0.7832 - val_loss: 0.5073 - val_accuracy: 0.8001\n",
      "Epoch 49/500\n",
      "953/953 [==============================] - 1s 918us/step - loss: 0.5423 - accuracy: 0.7833 - val_loss: 0.5043 - val_accuracy: 0.8046\n",
      "Epoch 50/500\n",
      "953/953 [==============================] - 1s 915us/step - loss: 0.5424 - accuracy: 0.7833 - val_loss: 0.5019 - val_accuracy: 0.8039\n",
      "Epoch 51/500\n",
      "953/953 [==============================] - 1s 915us/step - loss: 0.5410 - accuracy: 0.7835 - val_loss: 0.5059 - val_accuracy: 0.8018\n",
      "Epoch 52/500\n",
      "953/953 [==============================] - 1s 915us/step - loss: 0.5408 - accuracy: 0.7839 - val_loss: 0.4987 - val_accuracy: 0.8052\n",
      "Epoch 53/500\n",
      "953/953 [==============================] - 1s 930us/step - loss: 0.5383 - accuracy: 0.7847 - val_loss: 0.5026 - val_accuracy: 0.8038\n",
      "Epoch 54/500\n",
      "953/953 [==============================] - 1s 934us/step - loss: 0.5394 - accuracy: 0.7845 - val_loss: 0.4982 - val_accuracy: 0.8065\n",
      "Epoch 55/500\n",
      "953/953 [==============================] - 1s 935us/step - loss: 0.5394 - accuracy: 0.7859 - val_loss: 0.4993 - val_accuracy: 0.8060\n",
      "Epoch 56/500\n",
      "953/953 [==============================] - 1s 935us/step - loss: 0.5377 - accuracy: 0.7850 - val_loss: 0.4967 - val_accuracy: 0.8037\n",
      "Epoch 57/500\n",
      "953/953 [==============================] - 1s 917us/step - loss: 0.5370 - accuracy: 0.7861 - val_loss: 0.4966 - val_accuracy: 0.8075\n",
      "Epoch 58/500\n",
      "953/953 [==============================] - 1s 932us/step - loss: 0.5357 - accuracy: 0.7866 - val_loss: 0.4969 - val_accuracy: 0.8062\n",
      "Epoch 59/500\n",
      "953/953 [==============================] - 1s 916us/step - loss: 0.5348 - accuracy: 0.7863 - val_loss: 0.4960 - val_accuracy: 0.8044\n",
      "Epoch 60/500\n",
      "953/953 [==============================] - 1s 948us/step - loss: 0.5362 - accuracy: 0.7868 - val_loss: 0.4939 - val_accuracy: 0.8054\n",
      "Epoch 61/500\n",
      "953/953 [==============================] - 1s 945us/step - loss: 0.5335 - accuracy: 0.7864 - val_loss: 0.4966 - val_accuracy: 0.8038\n",
      "Epoch 62/500\n",
      "953/953 [==============================] - 1s 926us/step - loss: 0.5336 - accuracy: 0.7866 - val_loss: 0.4946 - val_accuracy: 0.8077\n",
      "Epoch 63/500\n",
      "953/953 [==============================] - 1s 917us/step - loss: 0.5355 - accuracy: 0.7872 - val_loss: 0.4930 - val_accuracy: 0.8092\n",
      "Epoch 64/500\n",
      "953/953 [==============================] - 1s 910us/step - loss: 0.5314 - accuracy: 0.7877 - val_loss: 0.4949 - val_accuracy: 0.8082\n",
      "Epoch 65/500\n",
      "953/953 [==============================] - 1s 921us/step - loss: 0.5344 - accuracy: 0.7875 - val_loss: 0.4945 - val_accuracy: 0.8073\n",
      "Epoch 66/500\n",
      "953/953 [==============================] - 1s 917us/step - loss: 0.5304 - accuracy: 0.7884 - val_loss: 0.4915 - val_accuracy: 0.8096\n",
      "Epoch 67/500\n",
      "953/953 [==============================] - 1s 914us/step - loss: 0.5324 - accuracy: 0.7878 - val_loss: 0.4906 - val_accuracy: 0.8090\n",
      "Epoch 68/500\n",
      "953/953 [==============================] - 1s 914us/step - loss: 0.5286 - accuracy: 0.7895 - val_loss: 0.4893 - val_accuracy: 0.8088\n",
      "Epoch 69/500\n",
      "953/953 [==============================] - 1s 915us/step - loss: 0.5317 - accuracy: 0.7873 - val_loss: 0.4912 - val_accuracy: 0.8077\n",
      "Epoch 70/500\n",
      "953/953 [==============================] - 1s 934us/step - loss: 0.5293 - accuracy: 0.7896 - val_loss: 0.4915 - val_accuracy: 0.8067\n",
      "Epoch 71/500\n",
      "953/953 [==============================] - 1s 936us/step - loss: 0.5296 - accuracy: 0.7898 - val_loss: 0.4891 - val_accuracy: 0.8088\n",
      "Epoch 72/500\n",
      "953/953 [==============================] - 1s 944us/step - loss: 0.5260 - accuracy: 0.7899 - val_loss: 0.4890 - val_accuracy: 0.8096\n",
      "Epoch 73/500\n",
      "953/953 [==============================] - 1s 939us/step - loss: 0.5285 - accuracy: 0.7902 - val_loss: 0.4872 - val_accuracy: 0.8107\n",
      "Epoch 74/500\n",
      "953/953 [==============================] - 1s 916us/step - loss: 0.5275 - accuracy: 0.7907 - val_loss: 0.4875 - val_accuracy: 0.8110\n",
      "Epoch 75/500\n",
      "953/953 [==============================] - 1s 916us/step - loss: 0.5263 - accuracy: 0.7904 - val_loss: 0.4875 - val_accuracy: 0.8131\n",
      "Epoch 76/500\n",
      "953/953 [==============================] - 1s 930us/step - loss: 0.5280 - accuracy: 0.7906 - val_loss: 0.4889 - val_accuracy: 0.8107\n",
      "Epoch 77/500\n",
      "953/953 [==============================] - 1s 918us/step - loss: 0.5267 - accuracy: 0.7909 - val_loss: 0.4854 - val_accuracy: 0.8118\n",
      "Epoch 78/500\n",
      "953/953 [==============================] - 1s 916us/step - loss: 0.5259 - accuracy: 0.7911 - val_loss: 0.4830 - val_accuracy: 0.8117\n",
      "Epoch 79/500\n",
      "953/953 [==============================] - 1s 917us/step - loss: 0.5269 - accuracy: 0.7911 - val_loss: 0.4838 - val_accuracy: 0.8120\n",
      "Epoch 80/500\n",
      "953/953 [==============================] - 1s 915us/step - loss: 0.5277 - accuracy: 0.7902 - val_loss: 0.4885 - val_accuracy: 0.8107\n",
      "Epoch 81/500\n",
      "953/953 [==============================] - 1s 916us/step - loss: 0.5244 - accuracy: 0.7904 - val_loss: 0.4850 - val_accuracy: 0.8118\n",
      "Epoch 82/500\n",
      "953/953 [==============================] - 1s 915us/step - loss: 0.5250 - accuracy: 0.7916 - val_loss: 0.4829 - val_accuracy: 0.8133\n",
      "Epoch 83/500\n",
      "953/953 [==============================] - 1s 915us/step - loss: 0.5219 - accuracy: 0.7924 - val_loss: 0.4837 - val_accuracy: 0.8128\n",
      "Epoch 84/500\n",
      "953/953 [==============================] - 1s 935us/step - loss: 0.5232 - accuracy: 0.7924 - val_loss: 0.4867 - val_accuracy: 0.8105\n",
      "Epoch 85/500\n",
      "953/953 [==============================] - 1s 934us/step - loss: 0.5226 - accuracy: 0.7923 - val_loss: 0.4835 - val_accuracy: 0.8115\n",
      "Epoch 86/500\n",
      "953/953 [==============================] - 1s 915us/step - loss: 0.5241 - accuracy: 0.7912 - val_loss: 0.4797 - val_accuracy: 0.8139\n",
      "Epoch 87/500\n",
      "953/953 [==============================] - 1s 915us/step - loss: 0.5222 - accuracy: 0.7916 - val_loss: 0.4813 - val_accuracy: 0.8110\n",
      "Epoch 88/500\n",
      "953/953 [==============================] - 1s 920us/step - loss: 0.5223 - accuracy: 0.7925 - val_loss: 0.4774 - val_accuracy: 0.8142\n",
      "Epoch 89/500\n",
      "953/953 [==============================] - 1s 915us/step - loss: 0.5224 - accuracy: 0.7922 - val_loss: 0.4780 - val_accuracy: 0.8145\n",
      "Epoch 90/500\n",
      "953/953 [==============================] - 1s 924us/step - loss: 0.5218 - accuracy: 0.7925 - val_loss: 0.4805 - val_accuracy: 0.8133\n",
      "Epoch 91/500\n",
      "953/953 [==============================] - 1s 961us/step - loss: 0.5219 - accuracy: 0.7928 - val_loss: 0.4776 - val_accuracy: 0.8155\n",
      "Epoch 92/500\n",
      "953/953 [==============================] - 1s 946us/step - loss: 0.5217 - accuracy: 0.7930 - val_loss: 0.4830 - val_accuracy: 0.8137\n",
      "Epoch 93/500\n",
      "953/953 [==============================] - 1s 999us/step - loss: 0.5208 - accuracy: 0.7927 - val_loss: 0.4752 - val_accuracy: 0.8171\n",
      "Epoch 94/500\n",
      "953/953 [==============================] - 1s 2ms/step - loss: 0.5194 - accuracy: 0.7926 - val_loss: 0.4778 - val_accuracy: 0.8131\n",
      "Epoch 95/500\n",
      "953/953 [==============================] - 1s 1ms/step - loss: 0.5188 - accuracy: 0.7943 - val_loss: 0.4757 - val_accuracy: 0.8156\n",
      "Epoch 96/500\n",
      "953/953 [==============================] - 1s 966us/step - loss: 0.5211 - accuracy: 0.7929 - val_loss: 0.4785 - val_accuracy: 0.8144\n",
      "Epoch 97/500\n",
      "953/953 [==============================] - 1s 917us/step - loss: 0.5196 - accuracy: 0.7928 - val_loss: 0.4766 - val_accuracy: 0.8160\n",
      "Epoch 98/500\n",
      "953/953 [==============================] - 1s 923us/step - loss: 0.5175 - accuracy: 0.7946 - val_loss: 0.4777 - val_accuracy: 0.8158\n",
      "Epoch 99/500\n",
      "953/953 [==============================] - 1s 912us/step - loss: 0.5170 - accuracy: 0.7956 - val_loss: 0.4764 - val_accuracy: 0.8135\n",
      "Epoch 100/500\n",
      "953/953 [==============================] - 1s 918us/step - loss: 0.5190 - accuracy: 0.7939 - val_loss: 0.4786 - val_accuracy: 0.8152\n",
      "Epoch 101/500\n",
      "953/953 [==============================] - 1s 938us/step - loss: 0.5193 - accuracy: 0.7928 - val_loss: 0.4792 - val_accuracy: 0.8150\n",
      "Epoch 102/500\n",
      "953/953 [==============================] - 1s 946us/step - loss: 0.5181 - accuracy: 0.7938 - val_loss: 0.4825 - val_accuracy: 0.8127\n",
      "Epoch 103/500\n",
      "953/953 [==============================] - 1s 922us/step - loss: 0.5190 - accuracy: 0.7955 - val_loss: 0.4767 - val_accuracy: 0.8133\n",
      "Epoch 104/500\n",
      "953/953 [==============================] - 1s 922us/step - loss: 0.5162 - accuracy: 0.7951 - val_loss: 0.4765 - val_accuracy: 0.8146\n",
      "Epoch 105/500\n",
      "953/953 [==============================] - 1s 917us/step - loss: 0.5169 - accuracy: 0.7950 - val_loss: 0.4776 - val_accuracy: 0.8135\n",
      "Epoch 106/500\n",
      "953/953 [==============================] - 1s 915us/step - loss: 0.5161 - accuracy: 0.7943 - val_loss: 0.4775 - val_accuracy: 0.8147\n",
      "Epoch 107/500\n",
      "953/953 [==============================] - 1s 979us/step - loss: 0.5164 - accuracy: 0.7945 - val_loss: 0.4759 - val_accuracy: 0.8152\n",
      "Epoch 108/500\n",
      "953/953 [==============================] - 1s 973us/step - loss: 0.5171 - accuracy: 0.7943 - val_loss: 0.4724 - val_accuracy: 0.8155\n",
      "Epoch 109/500\n",
      "953/953 [==============================] - 1s 960us/step - loss: 0.5139 - accuracy: 0.7965 - val_loss: 0.4757 - val_accuracy: 0.8155\n",
      "Epoch 110/500\n",
      "953/953 [==============================] - 1s 919us/step - loss: 0.5156 - accuracy: 0.7955 - val_loss: 0.4749 - val_accuracy: 0.8155\n",
      "Epoch 111/500\n",
      "953/953 [==============================] - 1s 947us/step - loss: 0.5141 - accuracy: 0.7950 - val_loss: 0.4746 - val_accuracy: 0.8155\n",
      "Epoch 112/500\n",
      "953/953 [==============================] - 1s 975us/step - loss: 0.5165 - accuracy: 0.7959 - val_loss: 0.4728 - val_accuracy: 0.8152\n",
      "Epoch 113/500\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "953/953 [==============================] - 1s 941us/step - loss: 0.5138 - accuracy: 0.7968 - val_loss: 0.4723 - val_accuracy: 0.8164\n",
      "Epoch 114/500\n",
      "953/953 [==============================] - 1s 943us/step - loss: 0.5172 - accuracy: 0.7941 - val_loss: 0.4719 - val_accuracy: 0.8165\n",
      "Epoch 115/500\n",
      "953/953 [==============================] - 1s 939us/step - loss: 0.5147 - accuracy: 0.7959 - val_loss: 0.4763 - val_accuracy: 0.8173\n",
      "Epoch 116/500\n",
      "953/953 [==============================] - 1s 941us/step - loss: 0.5134 - accuracy: 0.7957 - val_loss: 0.4685 - val_accuracy: 0.8179\n",
      "Epoch 117/500\n",
      "953/953 [==============================] - 1s 944us/step - loss: 0.5145 - accuracy: 0.7957 - val_loss: 0.4735 - val_accuracy: 0.8155\n",
      "Epoch 118/500\n",
      "953/953 [==============================] - 1s 947us/step - loss: 0.5131 - accuracy: 0.7971 - val_loss: 0.4718 - val_accuracy: 0.8140\n",
      "Epoch 119/500\n",
      "953/953 [==============================] - 1s 916us/step - loss: 0.5124 - accuracy: 0.7971 - val_loss: 0.4712 - val_accuracy: 0.8172\n",
      "Epoch 120/500\n",
      "953/953 [==============================] - 1s 916us/step - loss: 0.5132 - accuracy: 0.7968 - val_loss: 0.4714 - val_accuracy: 0.8189\n",
      "Epoch 121/500\n",
      "953/953 [==============================] - 1s 915us/step - loss: 0.5134 - accuracy: 0.7960 - val_loss: 0.4718 - val_accuracy: 0.8181\n",
      "Epoch 122/500\n",
      "953/953 [==============================] - 1s 966us/step - loss: 0.5117 - accuracy: 0.7970 - val_loss: 0.4694 - val_accuracy: 0.8189\n",
      "Epoch 123/500\n",
      "953/953 [==============================] - 1s 945us/step - loss: 0.5140 - accuracy: 0.7967 - val_loss: 0.4717 - val_accuracy: 0.8174\n",
      "Epoch 124/500\n",
      "953/953 [==============================] - 1s 946us/step - loss: 0.5128 - accuracy: 0.7967 - val_loss: 0.4682 - val_accuracy: 0.8189\n",
      "Epoch 125/500\n",
      "953/953 [==============================] - 1s 917us/step - loss: 0.5110 - accuracy: 0.7972 - val_loss: 0.4709 - val_accuracy: 0.8190\n",
      "Epoch 126/500\n",
      "953/953 [==============================] - 1s 917us/step - loss: 0.5097 - accuracy: 0.7974 - val_loss: 0.4681 - val_accuracy: 0.8202\n",
      "Epoch 127/500\n",
      "953/953 [==============================] - 1s 979us/step - loss: 0.5112 - accuracy: 0.7970 - val_loss: 0.4706 - val_accuracy: 0.8178\n",
      "Epoch 128/500\n",
      "953/953 [==============================] - 1s 955us/step - loss: 0.5102 - accuracy: 0.7974 - val_loss: 0.4704 - val_accuracy: 0.8166\n",
      "Epoch 129/500\n",
      "953/953 [==============================] - 1s 929us/step - loss: 0.5112 - accuracy: 0.7968 - val_loss: 0.4697 - val_accuracy: 0.8192\n",
      "Epoch 130/500\n",
      "953/953 [==============================] - 1s 916us/step - loss: 0.5122 - accuracy: 0.7970 - val_loss: 0.4680 - val_accuracy: 0.8189\n",
      "Epoch 131/500\n",
      "953/953 [==============================] - 1s 953us/step - loss: 0.5099 - accuracy: 0.7985 - val_loss: 0.4715 - val_accuracy: 0.8206\n",
      "Epoch 132/500\n",
      "953/953 [==============================] - 1s 921us/step - loss: 0.5104 - accuracy: 0.7979 - val_loss: 0.4715 - val_accuracy: 0.8192\n",
      "Epoch 133/500\n",
      "953/953 [==============================] - 1s 914us/step - loss: 0.5076 - accuracy: 0.7990 - val_loss: 0.4678 - val_accuracy: 0.8202\n",
      "Epoch 134/500\n",
      "953/953 [==============================] - 1s 919us/step - loss: 0.5097 - accuracy: 0.7976 - val_loss: 0.4688 - val_accuracy: 0.8189\n",
      "Epoch 135/500\n",
      "953/953 [==============================] - 1s 917us/step - loss: 0.5090 - accuracy: 0.7975 - val_loss: 0.4671 - val_accuracy: 0.8182\n",
      "Epoch 136/500\n",
      "953/953 [==============================] - 1s 916us/step - loss: 0.5080 - accuracy: 0.7983 - val_loss: 0.4690 - val_accuracy: 0.8211\n",
      "Epoch 137/500\n",
      "953/953 [==============================] - 1s 921us/step - loss: 0.5091 - accuracy: 0.7986 - val_loss: 0.4681 - val_accuracy: 0.8193\n",
      "Epoch 138/500\n",
      "953/953 [==============================] - 1s 941us/step - loss: 0.5111 - accuracy: 0.7976 - val_loss: 0.4707 - val_accuracy: 0.8208\n",
      "Epoch 139/500\n",
      "953/953 [==============================] - 1s 940us/step - loss: 0.5091 - accuracy: 0.7988 - val_loss: 0.4663 - val_accuracy: 0.8213\n",
      "Epoch 140/500\n",
      "953/953 [==============================] - 1s 943us/step - loss: 0.5094 - accuracy: 0.7979 - val_loss: 0.4654 - val_accuracy: 0.8223\n",
      "Epoch 141/500\n",
      "953/953 [==============================] - 1s 949us/step - loss: 0.5093 - accuracy: 0.7988 - val_loss: 0.4693 - val_accuracy: 0.8203\n",
      "Epoch 142/500\n",
      "953/953 [==============================] - 1s 928us/step - loss: 0.5086 - accuracy: 0.7983 - val_loss: 0.4665 - val_accuracy: 0.8179\n",
      "Epoch 143/500\n",
      "953/953 [==============================] - 1s 921us/step - loss: 0.5080 - accuracy: 0.7993 - val_loss: 0.4671 - val_accuracy: 0.8182\n",
      "Epoch 144/500\n",
      "953/953 [==============================] - 1s 918us/step - loss: 0.5094 - accuracy: 0.7986 - val_loss: 0.4683 - val_accuracy: 0.8209\n",
      "Epoch 145/500\n",
      "953/953 [==============================] - 1s 937us/step - loss: 0.5086 - accuracy: 0.7980 - val_loss: 0.4643 - val_accuracy: 0.8197\n",
      "Epoch 146/500\n",
      "953/953 [==============================] - 1s 933us/step - loss: 0.5073 - accuracy: 0.7999 - val_loss: 0.4653 - val_accuracy: 0.8206\n",
      "Epoch 147/500\n",
      "953/953 [==============================] - 1s 949us/step - loss: 0.5066 - accuracy: 0.7993 - val_loss: 0.4656 - val_accuracy: 0.8196\n",
      "Epoch 148/500\n",
      "953/953 [==============================] - 1s 937us/step - loss: 0.5084 - accuracy: 0.7987 - val_loss: 0.4660 - val_accuracy: 0.8197\n",
      "Epoch 149/500\n",
      "953/953 [==============================] - 1s 934us/step - loss: 0.5068 - accuracy: 0.8003 - val_loss: 0.4656 - val_accuracy: 0.8201\n",
      "Epoch 150/500\n",
      "953/953 [==============================] - 1s 972us/step - loss: 0.5080 - accuracy: 0.7991 - val_loss: 0.4625 - val_accuracy: 0.8228\n",
      "Epoch 151/500\n",
      "953/953 [==============================] - 1s 1ms/step - loss: 0.5082 - accuracy: 0.7996 - val_loss: 0.4654 - val_accuracy: 0.8208\n",
      "Epoch 152/500\n",
      "953/953 [==============================] - 1s 1ms/step - loss: 0.5087 - accuracy: 0.7980 - val_loss: 0.4677 - val_accuracy: 0.8180\n",
      "Epoch 153/500\n",
      "953/953 [==============================] - 1s 923us/step - loss: 0.5073 - accuracy: 0.7992 - val_loss: 0.4666 - val_accuracy: 0.8176\n",
      "Epoch 154/500\n",
      "953/953 [==============================] - 1s 917us/step - loss: 0.5079 - accuracy: 0.7979 - val_loss: 0.4649 - val_accuracy: 0.8205\n",
      "Epoch 155/500\n",
      "953/953 [==============================] - 1s 919us/step - loss: 0.5066 - accuracy: 0.7994 - val_loss: 0.4624 - val_accuracy: 0.8188\n",
      "Epoch 156/500\n",
      "953/953 [==============================] - 1s 945us/step - loss: 0.5057 - accuracy: 0.8002 - val_loss: 0.4659 - val_accuracy: 0.8190\n",
      "Epoch 157/500\n",
      "953/953 [==============================] - 1s 944us/step - loss: 0.5063 - accuracy: 0.8011 - val_loss: 0.4614 - val_accuracy: 0.8219\n",
      "Epoch 158/500\n",
      "953/953 [==============================] - 1s 946us/step - loss: 0.5047 - accuracy: 0.8000 - val_loss: 0.4627 - val_accuracy: 0.8211\n",
      "Epoch 159/500\n",
      "953/953 [==============================] - 1s 943us/step - loss: 0.5054 - accuracy: 0.7984 - val_loss: 0.4612 - val_accuracy: 0.8224\n",
      "Epoch 160/500\n",
      "953/953 [==============================] - 1s 922us/step - loss: 0.5035 - accuracy: 0.8000 - val_loss: 0.4588 - val_accuracy: 0.8215\n",
      "Epoch 161/500\n",
      "953/953 [==============================] - 1s 923us/step - loss: 0.5045 - accuracy: 0.8008 - val_loss: 0.4649 - val_accuracy: 0.8207\n",
      "Epoch 162/500\n",
      "953/953 [==============================] - 1s 955us/step - loss: 0.5040 - accuracy: 0.8003 - val_loss: 0.4613 - val_accuracy: 0.8205\n",
      "Epoch 163/500\n",
      "953/953 [==============================] - 1s 945us/step - loss: 0.5044 - accuracy: 0.8006 - val_loss: 0.4623 - val_accuracy: 0.8216\n",
      "Epoch 164/500\n",
      "953/953 [==============================] - 1s 909us/step - loss: 0.5047 - accuracy: 0.8011 - val_loss: 0.4663 - val_accuracy: 0.8220\n",
      "Epoch 165/500\n",
      "953/953 [==============================] - 1s 931us/step - loss: 0.5033 - accuracy: 0.8002 - val_loss: 0.4613 - val_accuracy: 0.8206\n",
      "Epoch 166/500\n",
      "953/953 [==============================] - 1s 916us/step - loss: 0.5054 - accuracy: 0.7995 - val_loss: 0.4630 - val_accuracy: 0.8204\n",
      "Epoch 167/500\n",
      "953/953 [==============================] - 1s 918us/step - loss: 0.5033 - accuracy: 0.8014 - val_loss: 0.4602 - val_accuracy: 0.8223\n",
      "Epoch 168/500\n",
      "953/953 [==============================] - 1s 917us/step - loss: 0.5030 - accuracy: 0.8006 - val_loss: 0.4602 - val_accuracy: 0.8218\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 169/500\n",
      "953/953 [==============================] - 1s 914us/step - loss: 0.5034 - accuracy: 0.8010 - val_loss: 0.4654 - val_accuracy: 0.8215\n",
      "Epoch 170/500\n",
      "953/953 [==============================] - 1s 916us/step - loss: 0.5037 - accuracy: 0.8002 - val_loss: 0.4631 - val_accuracy: 0.8202\n",
      "Epoch 171/500\n",
      "953/953 [==============================] - 1s 917us/step - loss: 0.5043 - accuracy: 0.8000 - val_loss: 0.4651 - val_accuracy: 0.8210\n",
      "Epoch 172/500\n",
      "953/953 [==============================] - 1s 918us/step - loss: 0.5038 - accuracy: 0.8006 - val_loss: 0.4675 - val_accuracy: 0.8189\n",
      "Epoch 173/500\n",
      "953/953 [==============================] - 1s 916us/step - loss: 0.5033 - accuracy: 0.8016 - val_loss: 0.4622 - val_accuracy: 0.8204\n",
      "Epoch 174/500\n",
      "953/953 [==============================] - 1s 922us/step - loss: 0.5039 - accuracy: 0.8016 - val_loss: 0.4602 - val_accuracy: 0.8217\n",
      "Epoch 175/500\n",
      "953/953 [==============================] - 1s 944us/step - loss: 0.5027 - accuracy: 0.8017 - val_loss: 0.4661 - val_accuracy: 0.8168\n",
      "Epoch 176/500\n",
      "953/953 [==============================] - 1s 941us/step - loss: 0.5043 - accuracy: 0.8014 - val_loss: 0.4598 - val_accuracy: 0.8216\n",
      "Epoch 177/500\n",
      "953/953 [==============================] - 1s 915us/step - loss: 0.5025 - accuracy: 0.8018 - val_loss: 0.4638 - val_accuracy: 0.8249\n",
      "Epoch 178/500\n",
      "953/953 [==============================] - 1s 905us/step - loss: 0.5035 - accuracy: 0.8019 - val_loss: 0.4597 - val_accuracy: 0.8239\n",
      "Epoch 179/500\n",
      "953/953 [==============================] - 1s 917us/step - loss: 0.5038 - accuracy: 0.8006 - val_loss: 0.4647 - val_accuracy: 0.8212\n",
      "Epoch 180/500\n",
      "953/953 [==============================] - 1s 938us/step - loss: 0.5015 - accuracy: 0.8026 - val_loss: 0.4630 - val_accuracy: 0.8222\n",
      "Epoch 181/500\n",
      "953/953 [==============================] - 1s 940us/step - loss: 0.5025 - accuracy: 0.8020 - val_loss: 0.4634 - val_accuracy: 0.8229\n",
      "Epoch 182/500\n",
      "953/953 [==============================] - 1s 944us/step - loss: 0.5033 - accuracy: 0.8018 - val_loss: 0.4618 - val_accuracy: 0.8235\n",
      "Epoch 183/500\n",
      "953/953 [==============================] - 1s 958us/step - loss: 0.5013 - accuracy: 0.8019 - val_loss: 0.4588 - val_accuracy: 0.8240\n",
      "Epoch 184/500\n",
      "953/953 [==============================] - 1s 918us/step - loss: 0.5021 - accuracy: 0.8017 - val_loss: 0.4603 - val_accuracy: 0.8235\n",
      "Epoch 185/500\n",
      "953/953 [==============================] - 1s 916us/step - loss: 0.5026 - accuracy: 0.8013 - val_loss: 0.4632 - val_accuracy: 0.8205\n",
      "Epoch 185: early stopping\n"
     ]
    }
   ],
   "source": [
    "model=Sequential()\n",
    "model.add(Dense(128, activation=\"relu\"))\n",
    "model.add(Dropout(0.2))\n",
    "model.add(Dense(128, activation=\"relu\"))\n",
    "model.add(Dropout(0.1))\n",
    "model.add(Dense(64, activation=\"relu\"))\n",
    "model.add(Dropout(0.2))\n",
    "model.add(Dense(64, activation=\"relu\"))\n",
    "model.add(Dropout(0.15))\n",
    "model.add(Dense(3, activation=\"softmax\"))\n",
    "\n",
    "model.compile(loss='categorical_crossentropy', optimizer=Adam(learning_rate=0.001), metrics=['accuracy'])\n",
    "\n",
    "es=EarlyStopping(monitor=\"val_loss\",patience=25,mode=\"auto\",verbose=1)\n",
    "\n",
    "model1 = model.fit(X_train,\n",
    "          y_train,\n",
    "          epochs=500,\n",
    "               batch_size=128,\n",
    "               validation_split=0.1,\n",
    "               verbose=1,callbacks=[es])\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 32,
   "metadata": {
    "id": "2RdkCM0Meo-8"
   },
   "outputs": [],
   "source": [
    "from tensorflow.keras.optimizers.legacy import Adam"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 33,
   "metadata": {
    "id": "nAKYC0A4eox2"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "4236/4236 - 1s - loss: 0.4112 - accuracy: 0.8451 - 999ms/epoch - 236us/step\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "[0.41115710139274597, 0.8451253771781921]"
      ]
     },
     "execution_count": 33,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "model.evaluate(X_train, y_train, verbose=2)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 44,
   "metadata": {
    "collapsed": true
   },
   "outputs": [
    {
     "ename": "TypeError",
     "evalue": "no numeric data to plot",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mTypeError\u001b[0m                                 Traceback (most recent call last)",
      "Cell \u001b[0;32mIn[44], line 2\u001b[0m\n\u001b[1;32m      1\u001b[0m loss_df \u001b[38;5;241m=\u001b[39m pd\u001b[38;5;241m.\u001b[39mDataFrame(model\u001b[38;5;241m.\u001b[39mhistory\u001b[38;5;241m.\u001b[39mhistory)\n\u001b[0;32m----> 2\u001b[0m \u001b[43mloss_df\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mplot\u001b[49m\u001b[43m(\u001b[49m\u001b[43m)\u001b[49m\n",
      "File \u001b[0;32m~/anaconda3/envs/yeni_ortam/lib/python3.10/site-packages/pandas/plotting/_core.py:972\u001b[0m, in \u001b[0;36mPlotAccessor.__call__\u001b[0;34m(self, *args, **kwargs)\u001b[0m\n\u001b[1;32m    969\u001b[0m             label_name \u001b[38;5;241m=\u001b[39m label_kw \u001b[38;5;129;01mor\u001b[39;00m data\u001b[38;5;241m.\u001b[39mcolumns\n\u001b[1;32m    970\u001b[0m             data\u001b[38;5;241m.\u001b[39mcolumns \u001b[38;5;241m=\u001b[39m label_name\n\u001b[0;32m--> 972\u001b[0m \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[43mplot_backend\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mplot\u001b[49m\u001b[43m(\u001b[49m\u001b[43mdata\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mkind\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mkind\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[43mkwargs\u001b[49m\u001b[43m)\u001b[49m\n",
      "File \u001b[0;32m~/anaconda3/envs/yeni_ortam/lib/python3.10/site-packages/pandas/plotting/_matplotlib/__init__.py:71\u001b[0m, in \u001b[0;36mplot\u001b[0;34m(data, kind, **kwargs)\u001b[0m\n\u001b[1;32m     69\u001b[0m         kwargs[\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124max\u001b[39m\u001b[38;5;124m\"\u001b[39m] \u001b[38;5;241m=\u001b[39m \u001b[38;5;28mgetattr\u001b[39m(ax, \u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mleft_ax\u001b[39m\u001b[38;5;124m\"\u001b[39m, ax)\n\u001b[1;32m     70\u001b[0m plot_obj \u001b[38;5;241m=\u001b[39m PLOT_CLASSES[kind](data, \u001b[38;5;241m*\u001b[39m\u001b[38;5;241m*\u001b[39mkwargs)\n\u001b[0;32m---> 71\u001b[0m \u001b[43mplot_obj\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mgenerate\u001b[49m\u001b[43m(\u001b[49m\u001b[43m)\u001b[49m\n\u001b[1;32m     72\u001b[0m plot_obj\u001b[38;5;241m.\u001b[39mdraw()\n\u001b[1;32m     73\u001b[0m \u001b[38;5;28;01mreturn\u001b[39;00m plot_obj\u001b[38;5;241m.\u001b[39mresult\n",
      "File \u001b[0;32m~/anaconda3/envs/yeni_ortam/lib/python3.10/site-packages/pandas/plotting/_matplotlib/core.py:327\u001b[0m, in \u001b[0;36mMPLPlot.generate\u001b[0;34m(self)\u001b[0m\n\u001b[1;32m    325\u001b[0m \u001b[38;5;28;01mdef\u001b[39;00m \u001b[38;5;21mgenerate\u001b[39m(\u001b[38;5;28mself\u001b[39m):\n\u001b[1;32m    326\u001b[0m     \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_args_adjust()\n\u001b[0;32m--> 327\u001b[0m     \u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43m_compute_plot_data\u001b[49m\u001b[43m(\u001b[49m\u001b[43m)\u001b[49m\n\u001b[1;32m    328\u001b[0m     \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_setup_subplots()\n\u001b[1;32m    329\u001b[0m     \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_make_plot()\n",
      "File \u001b[0;32m~/anaconda3/envs/yeni_ortam/lib/python3.10/site-packages/pandas/plotting/_matplotlib/core.py:506\u001b[0m, in \u001b[0;36mMPLPlot._compute_plot_data\u001b[0;34m(self)\u001b[0m\n\u001b[1;32m    504\u001b[0m \u001b[38;5;66;03m# no non-numeric frames or series allowed\u001b[39;00m\n\u001b[1;32m    505\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m is_empty:\n\u001b[0;32m--> 506\u001b[0m     \u001b[38;5;28;01mraise\u001b[39;00m \u001b[38;5;167;01mTypeError\u001b[39;00m(\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mno numeric data to plot\u001b[39m\u001b[38;5;124m\"\u001b[39m)\n\u001b[1;32m    508\u001b[0m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mdata \u001b[38;5;241m=\u001b[39m numeric_data\u001b[38;5;241m.\u001b[39mapply(\u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_convert_to_ndarray)\n",
      "\u001b[0;31mTypeError\u001b[0m: no numeric data to plot"
     ]
    }
   ],
   "source": [
    "loss_df = pd.DataFrame(model.history.history)\n",
    "loss_df.plot()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 43,
   "metadata": {
    "id": "xrylTe5OeotM"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "748/748 [==============================] - 0s 252us/step\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0       0.83      0.93      0.88      7973\n",
      "           1       0.81      0.90      0.85      7973\n",
      "           2       0.82      0.64      0.72      7972\n",
      "\n",
      "    accuracy                           0.82     23918\n",
      "   macro avg       0.82      0.82      0.82     23918\n",
      "weighted avg       0.82      0.82      0.82     23918\n",
      "\n"
     ]
    }
   ],
   "source": [
    "y_pred = model.predict(X_test)\n",
    "y_pred_classes = np.argmax(y_pred, axis=1)\n",
    "y_true = np.argmax(y_test, axis=1)\n",
    "print(classification_report(y_true, y_pred_classes))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 35,
   "metadata": {
    "id": "5BcvMNVgeopQ",
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "4236/4236 [==============================] - 1s 238us/step\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0       0.85      0.95      0.90     45176\n",
      "           1       0.83      0.92      0.87     45176\n",
      "           2       0.86      0.67      0.75     45177\n",
      "\n",
      "    accuracy                           0.85    135529\n",
      "   macro avg       0.85      0.85      0.84    135529\n",
      "weighted avg       0.85      0.85      0.84    135529\n",
      "\n"
     ]
    }
   ],
   "source": [
    "y_t_pred = model.predict(X_train)\n",
    "y_t_pred_classes = np.argmax(y_t_pred, axis=1)\n",
    "y_t_true = np.argmax(y_train, axis=1)\n",
    "print(classification_report(y_t_true, y_t_pred_classes))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 45,
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 1/500\n",
      "1800/1800 [==============================] - 2s 875us/step - loss: 0.7269 - accuracy: 0.7131 - val_loss: 0.6799 - val_accuracy: 0.7352\n",
      "Epoch 2/500\n",
      "1800/1800 [==============================] - 1s 763us/step - loss: 0.6813 - accuracy: 0.7354 - val_loss: 0.6638 - val_accuracy: 0.7421\n",
      "Epoch 3/500\n",
      "1800/1800 [==============================] - 1s 750us/step - loss: 0.6683 - accuracy: 0.7389 - val_loss: 0.6552 - val_accuracy: 0.7414\n",
      "Epoch 4/500\n",
      "1800/1800 [==============================] - 1s 752us/step - loss: 0.6614 - accuracy: 0.7412 - val_loss: 0.6461 - val_accuracy: 0.7458\n",
      "Epoch 5/500\n",
      "1800/1800 [==============================] - 1s 748us/step - loss: 0.6534 - accuracy: 0.7441 - val_loss: 0.6409 - val_accuracy: 0.7476\n",
      "Epoch 6/500\n",
      "1800/1800 [==============================] - 1s 766us/step - loss: 0.6469 - accuracy: 0.7459 - val_loss: 0.6355 - val_accuracy: 0.7495\n",
      "Epoch 7/500\n",
      "1800/1800 [==============================] - 1s 749us/step - loss: 0.6415 - accuracy: 0.7483 - val_loss: 0.6290 - val_accuracy: 0.7540\n",
      "Epoch 8/500\n",
      "1800/1800 [==============================] - 1s 753us/step - loss: 0.6358 - accuracy: 0.7499 - val_loss: 0.6239 - val_accuracy: 0.7552\n",
      "Epoch 9/500\n",
      "1800/1800 [==============================] - 1s 748us/step - loss: 0.6307 - accuracy: 0.7522 - val_loss: 0.6142 - val_accuracy: 0.7596\n",
      "Epoch 10/500\n",
      "1800/1800 [==============================] - 1s 757us/step - loss: 0.6270 - accuracy: 0.7531 - val_loss: 0.6133 - val_accuracy: 0.7585\n",
      "Epoch 11/500\n",
      "1800/1800 [==============================] - 1s 760us/step - loss: 0.6223 - accuracy: 0.7545 - val_loss: 0.6076 - val_accuracy: 0.7625\n",
      "Epoch 12/500\n",
      "1800/1800 [==============================] - 1s 756us/step - loss: 0.6173 - accuracy: 0.7565 - val_loss: 0.6038 - val_accuracy: 0.7608\n",
      "Epoch 13/500\n",
      "1800/1800 [==============================] - 1s 757us/step - loss: 0.6133 - accuracy: 0.7579 - val_loss: 0.6001 - val_accuracy: 0.7648\n",
      "Epoch 14/500\n",
      "1800/1800 [==============================] - 1s 758us/step - loss: 0.6080 - accuracy: 0.7599 - val_loss: 0.5940 - val_accuracy: 0.7652\n",
      "Epoch 15/500\n",
      "1800/1800 [==============================] - 1s 758us/step - loss: 0.6064 - accuracy: 0.7595 - val_loss: 0.5843 - val_accuracy: 0.7696\n",
      "Epoch 16/500\n",
      "1800/1800 [==============================] - 1s 758us/step - loss: 0.6010 - accuracy: 0.7616 - val_loss: 0.5830 - val_accuracy: 0.7689\n",
      "Epoch 17/500\n",
      "1800/1800 [==============================] - 1s 757us/step - loss: 0.5982 - accuracy: 0.7630 - val_loss: 0.5838 - val_accuracy: 0.7710\n",
      "Epoch 18/500\n",
      "1800/1800 [==============================] - 1s 773us/step - loss: 0.5972 - accuracy: 0.7626 - val_loss: 0.5776 - val_accuracy: 0.7696\n",
      "Epoch 19/500\n",
      "1800/1800 [==============================] - 1s 758us/step - loss: 0.5941 - accuracy: 0.7648 - val_loss: 0.5735 - val_accuracy: 0.7753\n",
      "Epoch 20/500\n",
      "1800/1800 [==============================] - 1s 759us/step - loss: 0.5895 - accuracy: 0.7659 - val_loss: 0.5714 - val_accuracy: 0.7725\n",
      "Epoch 21/500\n",
      "1800/1800 [==============================] - 1s 749us/step - loss: 0.5851 - accuracy: 0.7675 - val_loss: 0.5665 - val_accuracy: 0.7756\n",
      "Epoch 22/500\n",
      "1800/1800 [==============================] - 1s 758us/step - loss: 0.5845 - accuracy: 0.7668 - val_loss: 0.5642 - val_accuracy: 0.7783\n",
      "Epoch 23/500\n",
      "1800/1800 [==============================] - 1s 760us/step - loss: 0.5817 - accuracy: 0.7670 - val_loss: 0.5572 - val_accuracy: 0.7786\n",
      "Epoch 24/500\n",
      "1800/1800 [==============================] - 1s 763us/step - loss: 0.5816 - accuracy: 0.7681 - val_loss: 0.5588 - val_accuracy: 0.7778\n",
      "Epoch 25/500\n",
      "1800/1800 [==============================] - 1s 756us/step - loss: 0.5796 - accuracy: 0.7680 - val_loss: 0.5604 - val_accuracy: 0.7784\n",
      "Epoch 26/500\n",
      "1800/1800 [==============================] - 1s 757us/step - loss: 0.5760 - accuracy: 0.7697 - val_loss: 0.5561 - val_accuracy: 0.7787\n",
      "Epoch 27/500\n",
      "1800/1800 [==============================] - 1s 775us/step - loss: 0.5757 - accuracy: 0.7706 - val_loss: 0.5541 - val_accuracy: 0.7800\n",
      "Epoch 28/500\n",
      "1800/1800 [==============================] - 1s 756us/step - loss: 0.5723 - accuracy: 0.7703 - val_loss: 0.5500 - val_accuracy: 0.7812\n",
      "Epoch 29/500\n",
      "1800/1800 [==============================] - 1s 758us/step - loss: 0.5720 - accuracy: 0.7705 - val_loss: 0.5435 - val_accuracy: 0.7815\n",
      "Epoch 30/500\n",
      "1800/1800 [==============================] - 1s 756us/step - loss: 0.5696 - accuracy: 0.7721 - val_loss: 0.5465 - val_accuracy: 0.7835\n",
      "Epoch 31/500\n",
      "1800/1800 [==============================] - 1s 756us/step - loss: 0.5688 - accuracy: 0.7721 - val_loss: 0.5450 - val_accuracy: 0.7823\n",
      "Epoch 32/500\n",
      "1800/1800 [==============================] - 1s 759us/step - loss: 0.5668 - accuracy: 0.7731 - val_loss: 0.5390 - val_accuracy: 0.7851\n",
      "Epoch 33/500\n",
      "1800/1800 [==============================] - 1s 758us/step - loss: 0.5667 - accuracy: 0.7722 - val_loss: 0.5423 - val_accuracy: 0.7823\n",
      "Epoch 34/500\n",
      "1800/1800 [==============================] - 1s 757us/step - loss: 0.5631 - accuracy: 0.7737 - val_loss: 0.5398 - val_accuracy: 0.7870\n",
      "Epoch 35/500\n",
      "1800/1800 [==============================] - 1s 775us/step - loss: 0.5637 - accuracy: 0.7744 - val_loss: 0.5399 - val_accuracy: 0.7871\n",
      "Epoch 36/500\n",
      "1800/1800 [==============================] - 1s 757us/step - loss: 0.5606 - accuracy: 0.7753 - val_loss: 0.5368 - val_accuracy: 0.7872\n",
      "Epoch 37/500\n",
      "1800/1800 [==============================] - 1s 755us/step - loss: 0.5594 - accuracy: 0.7748 - val_loss: 0.5348 - val_accuracy: 0.7871\n",
      "Epoch 38/500\n",
      "1800/1800 [==============================] - 1s 759us/step - loss: 0.5577 - accuracy: 0.7769 - val_loss: 0.5357 - val_accuracy: 0.7895\n",
      "Epoch 39/500\n",
      "1800/1800 [==============================] - 1s 756us/step - loss: 0.5578 - accuracy: 0.7768 - val_loss: 0.5346 - val_accuracy: 0.7864\n",
      "Epoch 40/500\n",
      "1800/1800 [==============================] - 1s 787us/step - loss: 0.5567 - accuracy: 0.7768 - val_loss: 0.5273 - val_accuracy: 0.7914\n",
      "Epoch 41/500\n",
      "1800/1800 [==============================] - 1s 759us/step - loss: 0.5547 - accuracy: 0.7767 - val_loss: 0.5248 - val_accuracy: 0.7932\n",
      "Epoch 42/500\n",
      "1800/1800 [==============================] - 1s 756us/step - loss: 0.5532 - accuracy: 0.7776 - val_loss: 0.5273 - val_accuracy: 0.7941\n",
      "Epoch 43/500\n",
      "1800/1800 [==============================] - 1s 756us/step - loss: 0.5537 - accuracy: 0.7770 - val_loss: 0.5282 - val_accuracy: 0.7904\n",
      "Epoch 44/500\n",
      "1800/1800 [==============================] - 1s 747us/step - loss: 0.5505 - accuracy: 0.7782 - val_loss: 0.5265 - val_accuracy: 0.7918\n",
      "Epoch 45/500\n",
      "1800/1800 [==============================] - 1s 778us/step - loss: 0.5514 - accuracy: 0.7783 - val_loss: 0.5240 - val_accuracy: 0.7922\n",
      "Epoch 46/500\n",
      "1800/1800 [==============================] - 1s 755us/step - loss: 0.5499 - accuracy: 0.7787 - val_loss: 0.5226 - val_accuracy: 0.7916\n",
      "Epoch 47/500\n",
      "1800/1800 [==============================] - 1s 755us/step - loss: 0.5467 - accuracy: 0.7799 - val_loss: 0.5179 - val_accuracy: 0.7946\n",
      "Epoch 48/500\n",
      "1800/1800 [==============================] - 1s 756us/step - loss: 0.5474 - accuracy: 0.7796 - val_loss: 0.5185 - val_accuracy: 0.7951\n",
      "Epoch 49/500\n",
      "1800/1800 [==============================] - 1s 754us/step - loss: 0.5475 - accuracy: 0.7807 - val_loss: 0.5188 - val_accuracy: 0.7944\n",
      "Epoch 50/500\n",
      "1800/1800 [==============================] - 1s 754us/step - loss: 0.5461 - accuracy: 0.7812 - val_loss: 0.5208 - val_accuracy: 0.7931\n",
      "Epoch 51/500\n",
      "1800/1800 [==============================] - 1s 772us/step - loss: 0.5457 - accuracy: 0.7813 - val_loss: 0.5173 - val_accuracy: 0.7944\n",
      "Epoch 52/500\n",
      "1800/1800 [==============================] - 1s 756us/step - loss: 0.5451 - accuracy: 0.7811 - val_loss: 0.5190 - val_accuracy: 0.7965\n",
      "Epoch 53/500\n",
      "1800/1800 [==============================] - 1s 755us/step - loss: 0.5428 - accuracy: 0.7821 - val_loss: 0.5116 - val_accuracy: 0.7974\n",
      "Epoch 54/500\n",
      "1800/1800 [==============================] - 1s 755us/step - loss: 0.5446 - accuracy: 0.7808 - val_loss: 0.5133 - val_accuracy: 0.7951\n",
      "Epoch 55/500\n",
      "1800/1800 [==============================] - 1s 755us/step - loss: 0.5420 - accuracy: 0.7814 - val_loss: 0.5156 - val_accuracy: 0.7968\n",
      "Epoch 56/500\n",
      "1800/1800 [==============================] - 1s 748us/step - loss: 0.5406 - accuracy: 0.7826 - val_loss: 0.5133 - val_accuracy: 0.7963\n",
      "Epoch 57/500\n",
      "1800/1800 [==============================] - 1s 757us/step - loss: 0.5398 - accuracy: 0.7831 - val_loss: 0.5099 - val_accuracy: 0.8003\n",
      "Epoch 58/500\n",
      "1800/1800 [==============================] - 1s 756us/step - loss: 0.5386 - accuracy: 0.7831 - val_loss: 0.5070 - val_accuracy: 0.7977\n",
      "Epoch 59/500\n",
      "1800/1800 [==============================] - 1s 757us/step - loss: 0.5384 - accuracy: 0.7835 - val_loss: 0.5106 - val_accuracy: 0.7971\n",
      "Epoch 60/500\n",
      "1800/1800 [==============================] - 1s 758us/step - loss: 0.5378 - accuracy: 0.7847 - val_loss: 0.5090 - val_accuracy: 0.8007\n",
      "Epoch 61/500\n",
      "1800/1800 [==============================] - 1s 757us/step - loss: 0.5388 - accuracy: 0.7837 - val_loss: 0.5106 - val_accuracy: 0.7999\n",
      "Epoch 62/500\n",
      "1800/1800 [==============================] - 1s 782us/step - loss: 0.5362 - accuracy: 0.7841 - val_loss: 0.5039 - val_accuracy: 0.8001\n",
      "Epoch 63/500\n",
      "1800/1800 [==============================] - 1s 780us/step - loss: 0.5351 - accuracy: 0.7861 - val_loss: 0.5071 - val_accuracy: 0.8000\n",
      "Epoch 64/500\n",
      "1800/1800 [==============================] - 1s 759us/step - loss: 0.5370 - accuracy: 0.7852 - val_loss: 0.5039 - val_accuracy: 0.8010\n",
      "Epoch 65/500\n",
      "1800/1800 [==============================] - 1s 756us/step - loss: 0.5356 - accuracy: 0.7850 - val_loss: 0.5054 - val_accuracy: 0.7977\n",
      "Epoch 66/500\n",
      "1800/1800 [==============================] - 1s 758us/step - loss: 0.5356 - accuracy: 0.7857 - val_loss: 0.5021 - val_accuracy: 0.8005\n",
      "Epoch 67/500\n",
      "1800/1800 [==============================] - 1s 754us/step - loss: 0.5348 - accuracy: 0.7854 - val_loss: 0.5021 - val_accuracy: 0.8024\n",
      "Epoch 68/500\n",
      "1800/1800 [==============================] - 1s 757us/step - loss: 0.5337 - accuracy: 0.7872 - val_loss: 0.5018 - val_accuracy: 0.8026\n",
      "Epoch 69/500\n",
      "1800/1800 [==============================] - 1s 758us/step - loss: 0.5343 - accuracy: 0.7850 - val_loss: 0.5037 - val_accuracy: 0.8009\n",
      "Epoch 70/500\n",
      "1800/1800 [==============================] - 1s 759us/step - loss: 0.5350 - accuracy: 0.7851 - val_loss: 0.5056 - val_accuracy: 0.8018\n",
      "Epoch 71/500\n",
      "1800/1800 [==============================] - 1s 757us/step - loss: 0.5330 - accuracy: 0.7867 - val_loss: 0.5006 - val_accuracy: 0.8038\n",
      "Epoch 72/500\n",
      "1800/1800 [==============================] - 1s 758us/step - loss: 0.5331 - accuracy: 0.7861 - val_loss: 0.4981 - val_accuracy: 0.8015\n",
      "Epoch 73/500\n",
      "1800/1800 [==============================] - 1s 774us/step - loss: 0.5298 - accuracy: 0.7875 - val_loss: 0.5012 - val_accuracy: 0.8027\n",
      "Epoch 74/500\n",
      "1800/1800 [==============================] - 1s 769us/step - loss: 0.5323 - accuracy: 0.7860 - val_loss: 0.4963 - val_accuracy: 0.8049\n",
      "Epoch 75/500\n",
      "1800/1800 [==============================] - 1s 758us/step - loss: 0.5300 - accuracy: 0.7878 - val_loss: 0.4959 - val_accuracy: 0.8075\n",
      "Epoch 76/500\n",
      "1800/1800 [==============================] - 1s 756us/step - loss: 0.5298 - accuracy: 0.7885 - val_loss: 0.4985 - val_accuracy: 0.8052\n",
      "Epoch 77/500\n",
      "1800/1800 [==============================] - 1s 756us/step - loss: 0.5283 - accuracy: 0.7884 - val_loss: 0.4971 - val_accuracy: 0.8028\n",
      "Epoch 78/500\n",
      "1800/1800 [==============================] - 1s 756us/step - loss: 0.5300 - accuracy: 0.7884 - val_loss: 0.4987 - val_accuracy: 0.8027\n",
      "Epoch 79/500\n",
      "1800/1800 [==============================] - 1s 745us/step - loss: 0.5278 - accuracy: 0.7886 - val_loss: 0.4983 - val_accuracy: 0.8049\n",
      "Epoch 80/500\n",
      "1800/1800 [==============================] - 1s 756us/step - loss: 0.5262 - accuracy: 0.7889 - val_loss: 0.4955 - val_accuracy: 0.8051\n",
      "Epoch 81/500\n",
      "1800/1800 [==============================] - 1s 756us/step - loss: 0.5275 - accuracy: 0.7884 - val_loss: 0.4976 - val_accuracy: 0.8061\n",
      "Epoch 82/500\n",
      "1800/1800 [==============================] - 1s 755us/step - loss: 0.5280 - accuracy: 0.7885 - val_loss: 0.4954 - val_accuracy: 0.8057\n",
      "Epoch 83/500\n",
      "1800/1800 [==============================] - 1s 777us/step - loss: 0.5275 - accuracy: 0.7887 - val_loss: 0.4938 - val_accuracy: 0.8042\n",
      "Epoch 84/500\n",
      "1800/1800 [==============================] - 1s 756us/step - loss: 0.5275 - accuracy: 0.7894 - val_loss: 0.4979 - val_accuracy: 0.8044\n",
      "Epoch 85/500\n",
      "1800/1800 [==============================] - 1s 756us/step - loss: 0.5265 - accuracy: 0.7890 - val_loss: 0.4951 - val_accuracy: 0.8048\n",
      "Epoch 86/500\n",
      "1800/1800 [==============================] - 1s 756us/step - loss: 0.5246 - accuracy: 0.7897 - val_loss: 0.4981 - val_accuracy: 0.8032\n",
      "Epoch 87/500\n",
      "1800/1800 [==============================] - 1s 756us/step - loss: 0.5266 - accuracy: 0.7892 - val_loss: 0.4906 - val_accuracy: 0.8089\n",
      "Epoch 88/500\n",
      "1800/1800 [==============================] - 1s 758us/step - loss: 0.5246 - accuracy: 0.7890 - val_loss: 0.4934 - val_accuracy: 0.8063\n",
      "Epoch 89/500\n",
      "1800/1800 [==============================] - 1s 757us/step - loss: 0.5239 - accuracy: 0.7901 - val_loss: 0.4929 - val_accuracy: 0.8091\n",
      "Epoch 90/500\n",
      "1800/1800 [==============================] - 1s 756us/step - loss: 0.5233 - accuracy: 0.7905 - val_loss: 0.4911 - val_accuracy: 0.8096\n",
      "Epoch 91/500\n",
      "1800/1800 [==============================] - 1s 772us/step - loss: 0.5237 - accuracy: 0.7903 - val_loss: 0.4916 - val_accuracy: 0.8091\n",
      "Epoch 92/500\n",
      "1800/1800 [==============================] - 1s 756us/step - loss: 0.5257 - accuracy: 0.7900 - val_loss: 0.4899 - val_accuracy: 0.8064\n",
      "Epoch 93/500\n",
      "1800/1800 [==============================] - 1s 755us/step - loss: 0.5240 - accuracy: 0.7895 - val_loss: 0.4919 - val_accuracy: 0.8071\n",
      "Epoch 94/500\n",
      "1800/1800 [==============================] - 1s 756us/step - loss: 0.5234 - accuracy: 0.7903 - val_loss: 0.4902 - val_accuracy: 0.8054\n",
      "Epoch 95/500\n",
      "1800/1800 [==============================] - 1s 756us/step - loss: 0.5215 - accuracy: 0.7913 - val_loss: 0.4926 - val_accuracy: 0.8088\n",
      "Epoch 96/500\n",
      "1800/1800 [==============================] - 1s 755us/step - loss: 0.5215 - accuracy: 0.7910 - val_loss: 0.4926 - val_accuracy: 0.8098\n",
      "Epoch 97/500\n",
      "1800/1800 [==============================] - 1s 755us/step - loss: 0.5202 - accuracy: 0.7917 - val_loss: 0.4882 - val_accuracy: 0.8114\n",
      "Epoch 98/500\n",
      "1800/1800 [==============================] - 1s 775us/step - loss: 0.5211 - accuracy: 0.7913 - val_loss: 0.4898 - val_accuracy: 0.8097\n",
      "Epoch 99/500\n",
      "1800/1800 [==============================] - 1s 755us/step - loss: 0.5207 - accuracy: 0.7913 - val_loss: 0.4904 - val_accuracy: 0.8088\n",
      "Epoch 100/500\n",
      "1800/1800 [==============================] - 1s 756us/step - loss: 0.5204 - accuracy: 0.7927 - val_loss: 0.4874 - val_accuracy: 0.8117\n",
      "Epoch 101/500\n",
      "1800/1800 [==============================] - 1s 757us/step - loss: 0.5209 - accuracy: 0.7910 - val_loss: 0.4884 - val_accuracy: 0.8101\n",
      "Epoch 102/500\n",
      "1800/1800 [==============================] - 1s 755us/step - loss: 0.5235 - accuracy: 0.7899 - val_loss: 0.4862 - val_accuracy: 0.8102\n",
      "Epoch 103/500\n",
      "1800/1800 [==============================] - 1s 759us/step - loss: 0.5206 - accuracy: 0.7909 - val_loss: 0.4892 - val_accuracy: 0.8095\n",
      "Epoch 104/500\n",
      "1800/1800 [==============================] - 1s 773us/step - loss: 0.5195 - accuracy: 0.7919 - val_loss: 0.4848 - val_accuracy: 0.8096\n",
      "Epoch 105/500\n",
      "1800/1800 [==============================] - 1s 756us/step - loss: 0.5175 - accuracy: 0.7922 - val_loss: 0.4823 - val_accuracy: 0.8128\n",
      "Epoch 106/500\n",
      "1800/1800 [==============================] - 1s 754us/step - loss: 0.5175 - accuracy: 0.7934 - val_loss: 0.4862 - val_accuracy: 0.8107\n",
      "Epoch 107/500\n",
      "1800/1800 [==============================] - 1s 756us/step - loss: 0.5190 - accuracy: 0.7929 - val_loss: 0.4851 - val_accuracy: 0.8108\n",
      "Epoch 108/500\n",
      "1800/1800 [==============================] - 1s 756us/step - loss: 0.5188 - accuracy: 0.7929 - val_loss: 0.4824 - val_accuracy: 0.8113\n",
      "Epoch 109/500\n",
      "1800/1800 [==============================] - 1s 754us/step - loss: 0.5170 - accuracy: 0.7930 - val_loss: 0.4867 - val_accuracy: 0.8112\n",
      "Epoch 110/500\n",
      "1800/1800 [==============================] - 1s 777us/step - loss: 0.5164 - accuracy: 0.7939 - val_loss: 0.4805 - val_accuracy: 0.8140\n",
      "Epoch 111/500\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "1800/1800 [==============================] - 1s 759us/step - loss: 0.5176 - accuracy: 0.7935 - val_loss: 0.4833 - val_accuracy: 0.8125\n",
      "Epoch 112/500\n",
      "1800/1800 [==============================] - 1s 759us/step - loss: 0.5188 - accuracy: 0.7920 - val_loss: 0.4849 - val_accuracy: 0.8106\n",
      "Epoch 113/500\n",
      "1800/1800 [==============================] - 1s 760us/step - loss: 0.5157 - accuracy: 0.7942 - val_loss: 0.4829 - val_accuracy: 0.8118\n",
      "Epoch 114/500\n",
      "1800/1800 [==============================] - 1s 748us/step - loss: 0.5158 - accuracy: 0.7939 - val_loss: 0.4827 - val_accuracy: 0.8120\n",
      "Epoch 115/500\n",
      "1800/1800 [==============================] - 1s 760us/step - loss: 0.5174 - accuracy: 0.7933 - val_loss: 0.4851 - val_accuracy: 0.8132\n",
      "Epoch 116/500\n",
      "1800/1800 [==============================] - 1s 757us/step - loss: 0.5167 - accuracy: 0.7932 - val_loss: 0.4842 - val_accuracy: 0.8121\n",
      "Epoch 117/500\n",
      "1800/1800 [==============================] - 1s 759us/step - loss: 0.5163 - accuracy: 0.7940 - val_loss: 0.4818 - val_accuracy: 0.8133\n",
      "Epoch 118/500\n",
      "1800/1800 [==============================] - 1s 758us/step - loss: 0.5156 - accuracy: 0.7941 - val_loss: 0.4791 - val_accuracy: 0.8151\n",
      "Epoch 119/500\n",
      "1800/1800 [==============================] - 1s 758us/step - loss: 0.5129 - accuracy: 0.7947 - val_loss: 0.4799 - val_accuracy: 0.8135\n",
      "Epoch 120/500\n",
      "1800/1800 [==============================] - 1s 758us/step - loss: 0.5152 - accuracy: 0.7943 - val_loss: 0.4825 - val_accuracy: 0.8152\n",
      "Epoch 121/500\n",
      "1800/1800 [==============================] - 1s 757us/step - loss: 0.5145 - accuracy: 0.7935 - val_loss: 0.4832 - val_accuracy: 0.8123\n",
      "Epoch 122/500\n",
      "1800/1800 [==============================] - 1s 757us/step - loss: 0.5148 - accuracy: 0.7943 - val_loss: 0.4794 - val_accuracy: 0.8149\n",
      "Epoch 123/500\n",
      "1800/1800 [==============================] - 1s 757us/step - loss: 0.5156 - accuracy: 0.7945 - val_loss: 0.4814 - val_accuracy: 0.8136\n",
      "Epoch 124/500\n",
      "1800/1800 [==============================] - 1s 756us/step - loss: 0.5146 - accuracy: 0.7952 - val_loss: 0.4766 - val_accuracy: 0.8169\n",
      "Epoch 125/500\n",
      "1800/1800 [==============================] - 1s 774us/step - loss: 0.5151 - accuracy: 0.7944 - val_loss: 0.4791 - val_accuracy: 0.8134\n",
      "Epoch 126/500\n",
      "1800/1800 [==============================] - 1s 757us/step - loss: 0.5141 - accuracy: 0.7952 - val_loss: 0.4801 - val_accuracy: 0.8157\n",
      "Epoch 127/500\n",
      "1800/1800 [==============================] - 1s 758us/step - loss: 0.5143 - accuracy: 0.7938 - val_loss: 0.4815 - val_accuracy: 0.8166\n",
      "Epoch 128/500\n",
      "1800/1800 [==============================] - 1s 757us/step - loss: 0.5136 - accuracy: 0.7956 - val_loss: 0.4809 - val_accuracy: 0.8139\n",
      "Epoch 129/500\n",
      "1800/1800 [==============================] - 1s 758us/step - loss: 0.5125 - accuracy: 0.7959 - val_loss: 0.4810 - val_accuracy: 0.8135\n",
      "Epoch 130/500\n",
      "1800/1800 [==============================] - 1s 787us/step - loss: 0.5124 - accuracy: 0.7953 - val_loss: 0.4801 - val_accuracy: 0.8130\n",
      "Epoch 131/500\n",
      "1800/1800 [==============================] - 1s 758us/step - loss: 0.5117 - accuracy: 0.7960 - val_loss: 0.4752 - val_accuracy: 0.8151\n",
      "Epoch 132/500\n",
      "1800/1800 [==============================] - 1s 760us/step - loss: 0.5112 - accuracy: 0.7968 - val_loss: 0.4773 - val_accuracy: 0.8141\n",
      "Epoch 133/500\n",
      "1800/1800 [==============================] - 1s 759us/step - loss: 0.5135 - accuracy: 0.7957 - val_loss: 0.4825 - val_accuracy: 0.8142\n",
      "Epoch 134/500\n",
      "1800/1800 [==============================] - 1s 758us/step - loss: 0.5142 - accuracy: 0.7939 - val_loss: 0.4795 - val_accuracy: 0.8163\n",
      "Epoch 135/500\n",
      "1800/1800 [==============================] - 1s 773us/step - loss: 0.5111 - accuracy: 0.7963 - val_loss: 0.4780 - val_accuracy: 0.8151\n",
      "Epoch 136/500\n",
      "1800/1800 [==============================] - 1s 759us/step - loss: 0.5109 - accuracy: 0.7963 - val_loss: 0.4803 - val_accuracy: 0.8163\n",
      "Epoch 137/500\n",
      "1800/1800 [==============================] - 1s 758us/step - loss: 0.5115 - accuracy: 0.7962 - val_loss: 0.4758 - val_accuracy: 0.8170\n",
      "Epoch 138/500\n",
      "1800/1800 [==============================] - 1s 758us/step - loss: 0.5081 - accuracy: 0.7969 - val_loss: 0.4789 - val_accuracy: 0.8149\n",
      "Epoch 139/500\n",
      "1800/1800 [==============================] - 1s 759us/step - loss: 0.5107 - accuracy: 0.7965 - val_loss: 0.4743 - val_accuracy: 0.8185\n",
      "Epoch 140/500\n",
      "1800/1800 [==============================] - 1s 759us/step - loss: 0.5093 - accuracy: 0.7966 - val_loss: 0.4771 - val_accuracy: 0.8170\n",
      "Epoch 141/500\n",
      "1800/1800 [==============================] - 1s 758us/step - loss: 0.5104 - accuracy: 0.7974 - val_loss: 0.4753 - val_accuracy: 0.8150\n",
      "Epoch 142/500\n",
      "1800/1800 [==============================] - 1s 759us/step - loss: 0.5100 - accuracy: 0.7970 - val_loss: 0.4751 - val_accuracy: 0.8163\n",
      "Epoch 143/500\n",
      "1800/1800 [==============================] - 1s 772us/step - loss: 0.5090 - accuracy: 0.7972 - val_loss: 0.4750 - val_accuracy: 0.8170\n",
      "Epoch 144/500\n",
      "1800/1800 [==============================] - 1s 758us/step - loss: 0.5086 - accuracy: 0.7974 - val_loss: 0.4749 - val_accuracy: 0.8170\n",
      "Epoch 145/500\n",
      "1800/1800 [==============================] - 1s 756us/step - loss: 0.5092 - accuracy: 0.7969 - val_loss: 0.4726 - val_accuracy: 0.8173\n",
      "Epoch 146/500\n",
      "1800/1800 [==============================] - 1s 757us/step - loss: 0.5087 - accuracy: 0.7976 - val_loss: 0.4711 - val_accuracy: 0.8218\n",
      "Epoch 147/500\n",
      "1800/1800 [==============================] - 1s 757us/step - loss: 0.5096 - accuracy: 0.7967 - val_loss: 0.4748 - val_accuracy: 0.8181\n",
      "Epoch 148/500\n",
      "1800/1800 [==============================] - 1s 756us/step - loss: 0.5085 - accuracy: 0.7972 - val_loss: 0.4801 - val_accuracy: 0.8149\n",
      "Epoch 149/500\n",
      "1800/1800 [==============================] - 1s 758us/step - loss: 0.5078 - accuracy: 0.7971 - val_loss: 0.4739 - val_accuracy: 0.8175\n",
      "Epoch 150/500\n",
      "1800/1800 [==============================] - 1s 759us/step - loss: 0.5086 - accuracy: 0.7975 - val_loss: 0.4759 - val_accuracy: 0.8175\n",
      "Epoch 151/500\n",
      "1800/1800 [==============================] - 1s 776us/step - loss: 0.5075 - accuracy: 0.7971 - val_loss: 0.4800 - val_accuracy: 0.8171\n",
      "Epoch 152/500\n",
      "1800/1800 [==============================] - 1s 760us/step - loss: 0.5096 - accuracy: 0.7963 - val_loss: 0.4723 - val_accuracy: 0.8185\n",
      "Epoch 153/500\n",
      "1800/1800 [==============================] - 1s 757us/step - loss: 0.5082 - accuracy: 0.7976 - val_loss: 0.4735 - val_accuracy: 0.8190\n",
      "Epoch 154/500\n",
      "1800/1800 [==============================] - 1s 758us/step - loss: 0.5081 - accuracy: 0.7972 - val_loss: 0.4755 - val_accuracy: 0.8155\n",
      "Epoch 155/500\n",
      "1800/1800 [==============================] - 1s 757us/step - loss: 0.5084 - accuracy: 0.7971 - val_loss: 0.4755 - val_accuracy: 0.8166\n",
      "Epoch 156/500\n",
      "1800/1800 [==============================] - 1s 778us/step - loss: 0.5071 - accuracy: 0.7983 - val_loss: 0.4701 - val_accuracy: 0.8180\n",
      "Epoch 157/500\n",
      "1800/1800 [==============================] - 1s 758us/step - loss: 0.5069 - accuracy: 0.7983 - val_loss: 0.4745 - val_accuracy: 0.8203\n",
      "Epoch 158/500\n",
      "1800/1800 [==============================] - 1s 756us/step - loss: 0.5087 - accuracy: 0.7972 - val_loss: 0.4718 - val_accuracy: 0.8174\n",
      "Epoch 159/500\n",
      "1800/1800 [==============================] - 1s 756us/step - loss: 0.5081 - accuracy: 0.7975 - val_loss: 0.4757 - val_accuracy: 0.8180\n",
      "Epoch 160/500\n",
      "1800/1800 [==============================] - 1s 757us/step - loss: 0.5078 - accuracy: 0.7987 - val_loss: 0.4731 - val_accuracy: 0.8194\n",
      "Epoch 161/500\n",
      "1800/1800 [==============================] - 1s 745us/step - loss: 0.5064 - accuracy: 0.7982 - val_loss: 0.4683 - val_accuracy: 0.8201\n",
      "Epoch 162/500\n",
      "1800/1800 [==============================] - 1s 776us/step - loss: 0.5061 - accuracy: 0.7986 - val_loss: 0.4702 - val_accuracy: 0.8177\n",
      "Epoch 163/500\n",
      "1800/1800 [==============================] - 1s 756us/step - loss: 0.5076 - accuracy: 0.7984 - val_loss: 0.4718 - val_accuracy: 0.8179\n",
      "Epoch 164/500\n",
      "1800/1800 [==============================] - 1s 778us/step - loss: 0.5069 - accuracy: 0.7980 - val_loss: 0.4736 - val_accuracy: 0.8175\n",
      "Epoch 165/500\n",
      "1800/1800 [==============================] - 1s 756us/step - loss: 0.5058 - accuracy: 0.7991 - val_loss: 0.4704 - val_accuracy: 0.8160\n",
      "Epoch 166/500\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "1800/1800 [==============================] - 1s 759us/step - loss: 0.5057 - accuracy: 0.7986 - val_loss: 0.4690 - val_accuracy: 0.8189\n",
      "Epoch 167/500\n",
      "1800/1800 [==============================] - 1s 757us/step - loss: 0.5045 - accuracy: 0.7982 - val_loss: 0.4729 - val_accuracy: 0.8181\n",
      "Epoch 168/500\n",
      "1800/1800 [==============================] - 1s 759us/step - loss: 0.5072 - accuracy: 0.7977 - val_loss: 0.4714 - val_accuracy: 0.8202\n",
      "Epoch 169/500\n",
      "1800/1800 [==============================] - 1s 756us/step - loss: 0.5064 - accuracy: 0.7985 - val_loss: 0.4702 - val_accuracy: 0.8180\n",
      "Epoch 170/500\n",
      "1800/1800 [==============================] - 1s 761us/step - loss: 0.5044 - accuracy: 0.7993 - val_loss: 0.4659 - val_accuracy: 0.8204\n",
      "Epoch 171/500\n",
      "1800/1800 [==============================] - 1s 759us/step - loss: 0.5064 - accuracy: 0.7990 - val_loss: 0.4688 - val_accuracy: 0.8193\n",
      "Epoch 172/500\n",
      "1800/1800 [==============================] - 1s 759us/step - loss: 0.5066 - accuracy: 0.7983 - val_loss: 0.4679 - val_accuracy: 0.8181\n",
      "Epoch 173/500\n",
      "1800/1800 [==============================] - 1s 747us/step - loss: 0.5044 - accuracy: 0.7991 - val_loss: 0.4706 - val_accuracy: 0.8195\n",
      "Epoch 174/500\n",
      "1800/1800 [==============================] - 1s 776us/step - loss: 0.5056 - accuracy: 0.7994 - val_loss: 0.4684 - val_accuracy: 0.8175\n",
      "Epoch 175/500\n",
      "1800/1800 [==============================] - 1s 761us/step - loss: 0.5051 - accuracy: 0.7993 - val_loss: 0.4666 - val_accuracy: 0.8214\n",
      "Epoch 176/500\n",
      "1800/1800 [==============================] - 1s 759us/step - loss: 0.5045 - accuracy: 0.7993 - val_loss: 0.4703 - val_accuracy: 0.8205\n",
      "Epoch 177/500\n",
      "1800/1800 [==============================] - 1s 758us/step - loss: 0.5041 - accuracy: 0.8003 - val_loss: 0.4647 - val_accuracy: 0.8200\n",
      "Epoch 178/500\n",
      "1800/1800 [==============================] - 1s 757us/step - loss: 0.5042 - accuracy: 0.8004 - val_loss: 0.4688 - val_accuracy: 0.8210\n",
      "Epoch 179/500\n",
      "1800/1800 [==============================] - 1s 758us/step - loss: 0.5046 - accuracy: 0.7995 - val_loss: 0.4672 - val_accuracy: 0.8212\n",
      "Epoch 180/500\n",
      "1800/1800 [==============================] - 1s 757us/step - loss: 0.5025 - accuracy: 0.7985 - val_loss: 0.4663 - val_accuracy: 0.8195\n",
      "Epoch 181/500\n",
      "1800/1800 [==============================] - 1s 757us/step - loss: 0.5052 - accuracy: 0.7994 - val_loss: 0.4692 - val_accuracy: 0.8185\n",
      "Epoch 182/500\n",
      "1800/1800 [==============================] - 1s 757us/step - loss: 0.5054 - accuracy: 0.7984 - val_loss: 0.4704 - val_accuracy: 0.8191\n",
      "Epoch 183/500\n",
      "1800/1800 [==============================] - 1s 758us/step - loss: 0.5042 - accuracy: 0.8001 - val_loss: 0.4684 - val_accuracy: 0.8210\n",
      "Epoch 184/500\n",
      "1800/1800 [==============================] - 1s 748us/step - loss: 0.5051 - accuracy: 0.7991 - val_loss: 0.4730 - val_accuracy: 0.8156\n",
      "Epoch 185/500\n",
      "1800/1800 [==============================] - 1s 759us/step - loss: 0.5038 - accuracy: 0.8005 - val_loss: 0.4702 - val_accuracy: 0.8193\n",
      "Epoch 186/500\n",
      "1800/1800 [==============================] - 1s 774us/step - loss: 0.5053 - accuracy: 0.7997 - val_loss: 0.4696 - val_accuracy: 0.8202\n",
      "Epoch 187/500\n",
      "1800/1800 [==============================] - 1s 758us/step - loss: 0.5032 - accuracy: 0.7994 - val_loss: 0.4714 - val_accuracy: 0.8204\n",
      "Epoch 188/500\n",
      "1800/1800 [==============================] - 1s 757us/step - loss: 0.5028 - accuracy: 0.7999 - val_loss: 0.4665 - val_accuracy: 0.8219\n",
      "Epoch 189/500\n",
      "1800/1800 [==============================] - 1s 757us/step - loss: 0.5040 - accuracy: 0.7989 - val_loss: 0.4655 - val_accuracy: 0.8202\n",
      "Epoch 190/500\n",
      "1800/1800 [==============================] - 1s 758us/step - loss: 0.5028 - accuracy: 0.8011 - val_loss: 0.4658 - val_accuracy: 0.8216\n",
      "Epoch 191/500\n",
      "1800/1800 [==============================] - 1s 756us/step - loss: 0.5035 - accuracy: 0.8004 - val_loss: 0.4672 - val_accuracy: 0.8231\n",
      "Epoch 192/500\n",
      "1800/1800 [==============================] - 1s 767us/step - loss: 0.5003 - accuracy: 0.8012 - val_loss: 0.4644 - val_accuracy: 0.8233\n",
      "Epoch 193/500\n",
      "1800/1800 [==============================] - 1s 758us/step - loss: 0.5026 - accuracy: 0.8007 - val_loss: 0.4686 - val_accuracy: 0.8192\n",
      "Epoch 194/500\n",
      "1800/1800 [==============================] - 1s 756us/step - loss: 0.5015 - accuracy: 0.8015 - val_loss: 0.4703 - val_accuracy: 0.8197\n",
      "Epoch 195/500\n",
      "1800/1800 [==============================] - 1s 774us/step - loss: 0.5012 - accuracy: 0.8006 - val_loss: 0.4716 - val_accuracy: 0.8213\n",
      "Epoch 196/500\n",
      "1800/1800 [==============================] - 1s 758us/step - loss: 0.5022 - accuracy: 0.8003 - val_loss: 0.4704 - val_accuracy: 0.8216\n",
      "Epoch 197/500\n",
      "1800/1800 [==============================] - 1s 756us/step - loss: 0.5011 - accuracy: 0.7998 - val_loss: 0.4689 - val_accuracy: 0.8209\n",
      "Epoch 198/500\n",
      "1800/1800 [==============================] - 1s 754us/step - loss: 0.5011 - accuracy: 0.8007 - val_loss: 0.4649 - val_accuracy: 0.8213\n",
      "Epoch 199/500\n",
      "1800/1800 [==============================] - 1s 758us/step - loss: 0.5010 - accuracy: 0.8014 - val_loss: 0.4715 - val_accuracy: 0.8219\n",
      "Epoch 200/500\n",
      "1800/1800 [==============================] - 1s 758us/step - loss: 0.5004 - accuracy: 0.8013 - val_loss: 0.4702 - val_accuracy: 0.8191\n",
      "Epoch 201/500\n",
      "1800/1800 [==============================] - 1s 762us/step - loss: 0.5016 - accuracy: 0.8010 - val_loss: 0.4684 - val_accuracy: 0.8201\n",
      "Epoch 202/500\n",
      "1800/1800 [==============================] - 1s 759us/step - loss: 0.5004 - accuracy: 0.8020 - val_loss: 0.4671 - val_accuracy: 0.8205\n",
      "Epoch 203/500\n",
      "1800/1800 [==============================] - 1s 773us/step - loss: 0.5008 - accuracy: 0.8020 - val_loss: 0.4636 - val_accuracy: 0.8219\n",
      "Epoch 204/500\n",
      "1800/1800 [==============================] - 1s 758us/step - loss: 0.5002 - accuracy: 0.8014 - val_loss: 0.4652 - val_accuracy: 0.8226\n",
      "Epoch 205/500\n",
      "1800/1800 [==============================] - 1s 758us/step - loss: 0.5013 - accuracy: 0.8006 - val_loss: 0.4665 - val_accuracy: 0.8209\n",
      "Epoch 206/500\n",
      "1800/1800 [==============================] - 1s 757us/step - loss: 0.4998 - accuracy: 0.8019 - val_loss: 0.4703 - val_accuracy: 0.8181\n",
      "Epoch 207/500\n",
      "1800/1800 [==============================] - 1s 758us/step - loss: 0.5000 - accuracy: 0.8010 - val_loss: 0.4695 - val_accuracy: 0.8203\n",
      "Epoch 208/500\n",
      "1800/1800 [==============================] - 1s 756us/step - loss: 0.5022 - accuracy: 0.8008 - val_loss: 0.4645 - val_accuracy: 0.8214\n",
      "Epoch 209/500\n",
      "1800/1800 [==============================] - 1s 759us/step - loss: 0.4991 - accuracy: 0.8019 - val_loss: 0.4684 - val_accuracy: 0.8199\n",
      "Epoch 210/500\n",
      "1800/1800 [==============================] - 1s 778us/step - loss: 0.5015 - accuracy: 0.8019 - val_loss: 0.4668 - val_accuracy: 0.8203\n",
      "Epoch 211/500\n",
      "1800/1800 [==============================] - 1s 757us/step - loss: 0.4982 - accuracy: 0.8026 - val_loss: 0.4654 - val_accuracy: 0.8203\n",
      "Epoch 212/500\n",
      "1800/1800 [==============================] - 1s 756us/step - loss: 0.4996 - accuracy: 0.8011 - val_loss: 0.4658 - val_accuracy: 0.8219\n",
      "Epoch 213/500\n",
      "1800/1800 [==============================] - 1s 758us/step - loss: 0.4988 - accuracy: 0.8025 - val_loss: 0.4625 - val_accuracy: 0.8216\n",
      "Epoch 214/500\n",
      "1800/1800 [==============================] - 1s 756us/step - loss: 0.4998 - accuracy: 0.8019 - val_loss: 0.4666 - val_accuracy: 0.8210\n",
      "Epoch 215/500\n",
      "1800/1800 [==============================] - 1s 758us/step - loss: 0.5000 - accuracy: 0.8020 - val_loss: 0.4646 - val_accuracy: 0.8195\n",
      "Epoch 216/500\n",
      "1800/1800 [==============================] - 1s 777us/step - loss: 0.5005 - accuracy: 0.8014 - val_loss: 0.4656 - val_accuracy: 0.8216\n",
      "Epoch 217/500\n",
      "1800/1800 [==============================] - 1s 754us/step - loss: 0.5002 - accuracy: 0.8016 - val_loss: 0.4630 - val_accuracy: 0.8217\n",
      "Epoch 218/500\n",
      "1800/1800 [==============================] - 1s 784us/step - loss: 0.4978 - accuracy: 0.8029 - val_loss: 0.4661 - val_accuracy: 0.8233\n",
      "Epoch 219/500\n",
      "1800/1800 [==============================] - 1s 753us/step - loss: 0.4998 - accuracy: 0.8016 - val_loss: 0.4645 - val_accuracy: 0.8238\n",
      "Epoch 220/500\n",
      "1800/1800 [==============================] - 1s 757us/step - loss: 0.4986 - accuracy: 0.8010 - val_loss: 0.4668 - val_accuracy: 0.8210\n",
      "Epoch 221/500\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "1800/1800 [==============================] - 1s 758us/step - loss: 0.4992 - accuracy: 0.8023 - val_loss: 0.4619 - val_accuracy: 0.8217\n",
      "Epoch 222/500\n",
      "1800/1800 [==============================] - 1s 759us/step - loss: 0.4969 - accuracy: 0.8038 - val_loss: 0.4602 - val_accuracy: 0.8242\n",
      "Epoch 223/500\n",
      "1800/1800 [==============================] - 1s 759us/step - loss: 0.4988 - accuracy: 0.8027 - val_loss: 0.4616 - val_accuracy: 0.8216\n",
      "Epoch 224/500\n",
      "1800/1800 [==============================] - 1s 760us/step - loss: 0.4984 - accuracy: 0.8011 - val_loss: 0.4641 - val_accuracy: 0.8230\n",
      "Epoch 225/500\n",
      "1800/1800 [==============================] - 1s 774us/step - loss: 0.4980 - accuracy: 0.8018 - val_loss: 0.4616 - val_accuracy: 0.8227\n",
      "Epoch 226/500\n",
      "1800/1800 [==============================] - 1s 757us/step - loss: 0.4978 - accuracy: 0.8019 - val_loss: 0.4638 - val_accuracy: 0.8212\n",
      "Epoch 227/500\n",
      "1800/1800 [==============================] - 1s 760us/step - loss: 0.4980 - accuracy: 0.8008 - val_loss: 0.4625 - val_accuracy: 0.8214\n",
      "Epoch 228/500\n",
      "1800/1800 [==============================] - 1s 759us/step - loss: 0.4965 - accuracy: 0.8024 - val_loss: 0.4602 - val_accuracy: 0.8242\n",
      "Epoch 229/500\n",
      "1800/1800 [==============================] - 1s 758us/step - loss: 0.4953 - accuracy: 0.8030 - val_loss: 0.4650 - val_accuracy: 0.8206\n",
      "Epoch 230/500\n",
      "1800/1800 [==============================] - 1s 760us/step - loss: 0.4992 - accuracy: 0.8026 - val_loss: 0.4627 - val_accuracy: 0.8225\n",
      "Epoch 231/500\n",
      "1800/1800 [==============================] - 1s 761us/step - loss: 0.4980 - accuracy: 0.8029 - val_loss: 0.4625 - val_accuracy: 0.8241\n",
      "Epoch 232/500\n",
      "1800/1800 [==============================] - 1s 757us/step - loss: 0.4972 - accuracy: 0.8026 - val_loss: 0.4592 - val_accuracy: 0.8232\n",
      "Epoch 233/500\n",
      "1800/1800 [==============================] - 1s 758us/step - loss: 0.4967 - accuracy: 0.8035 - val_loss: 0.4605 - val_accuracy: 0.8237\n",
      "Epoch 234/500\n",
      "1800/1800 [==============================] - 1s 759us/step - loss: 0.4962 - accuracy: 0.8023 - val_loss: 0.4596 - val_accuracy: 0.8221\n",
      "Epoch 235/500\n",
      "1800/1800 [==============================] - 1s 756us/step - loss: 0.4958 - accuracy: 0.8046 - val_loss: 0.4621 - val_accuracy: 0.8246\n",
      "Epoch 236/500\n",
      "1800/1800 [==============================] - 1s 760us/step - loss: 0.4999 - accuracy: 0.8023 - val_loss: 0.4599 - val_accuracy: 0.8239\n",
      "Epoch 237/500\n",
      "1800/1800 [==============================] - 1s 758us/step - loss: 0.4968 - accuracy: 0.8033 - val_loss: 0.4620 - val_accuracy: 0.8235\n",
      "Epoch 238/500\n",
      "1800/1800 [==============================] - 1s 776us/step - loss: 0.4946 - accuracy: 0.8034 - val_loss: 0.4591 - val_accuracy: 0.8254\n",
      "Epoch 239/500\n",
      "1800/1800 [==============================] - 1s 761us/step - loss: 0.4964 - accuracy: 0.8035 - val_loss: 0.4607 - val_accuracy: 0.8240\n",
      "Epoch 240/500\n",
      "1800/1800 [==============================] - 1s 759us/step - loss: 0.4979 - accuracy: 0.8043 - val_loss: 0.4599 - val_accuracy: 0.8245\n",
      "Epoch 241/500\n",
      "1800/1800 [==============================] - 1s 754us/step - loss: 0.4958 - accuracy: 0.8034 - val_loss: 0.4635 - val_accuracy: 0.8212\n",
      "Epoch 242/500\n",
      "1800/1800 [==============================] - 1s 757us/step - loss: 0.4961 - accuracy: 0.8026 - val_loss: 0.4625 - val_accuracy: 0.8230\n",
      "Epoch 243/500\n",
      "1800/1800 [==============================] - 1s 750us/step - loss: 0.4957 - accuracy: 0.8038 - val_loss: 0.4583 - val_accuracy: 0.8250\n",
      "Epoch 244/500\n",
      "1800/1800 [==============================] - 1s 756us/step - loss: 0.4940 - accuracy: 0.8039 - val_loss: 0.4631 - val_accuracy: 0.8239\n",
      "Epoch 245/500\n",
      "1800/1800 [==============================] - 1s 757us/step - loss: 0.4951 - accuracy: 0.8043 - val_loss: 0.4602 - val_accuracy: 0.8239\n",
      "Epoch 246/500\n",
      "1800/1800 [==============================] - 1s 774us/step - loss: 0.4936 - accuracy: 0.8041 - val_loss: 0.4584 - val_accuracy: 0.8234\n",
      "Epoch 247/500\n",
      "1800/1800 [==============================] - 1s 757us/step - loss: 0.4952 - accuracy: 0.8045 - val_loss: 0.4573 - val_accuracy: 0.8246\n",
      "Epoch 248/500\n",
      "1800/1800 [==============================] - 1s 760us/step - loss: 0.4958 - accuracy: 0.8044 - val_loss: 0.4583 - val_accuracy: 0.8227\n",
      "Epoch 249/500\n",
      "1800/1800 [==============================] - 1s 757us/step - loss: 0.4951 - accuracy: 0.8033 - val_loss: 0.4577 - val_accuracy: 0.8250\n",
      "Epoch 250/500\n",
      "1800/1800 [==============================] - 1s 757us/step - loss: 0.4959 - accuracy: 0.8029 - val_loss: 0.4617 - val_accuracy: 0.8236\n",
      "Epoch 251/500\n",
      "1800/1800 [==============================] - 1s 757us/step - loss: 0.4962 - accuracy: 0.8029 - val_loss: 0.4563 - val_accuracy: 0.8251\n",
      "Epoch 252/500\n",
      "1800/1800 [==============================] - 1s 757us/step - loss: 0.4958 - accuracy: 0.8046 - val_loss: 0.4590 - val_accuracy: 0.8240\n",
      "Epoch 253/500\n",
      "1800/1800 [==============================] - 1s 759us/step - loss: 0.4938 - accuracy: 0.8050 - val_loss: 0.4607 - val_accuracy: 0.8247\n",
      "Epoch 254/500\n",
      "1800/1800 [==============================] - 1s 758us/step - loss: 0.4931 - accuracy: 0.8046 - val_loss: 0.4597 - val_accuracy: 0.8260\n",
      "Epoch 255/500\n",
      "1800/1800 [==============================] - 1s 782us/step - loss: 0.4946 - accuracy: 0.8053 - val_loss: 0.4592 - val_accuracy: 0.8239\n",
      "Epoch 256/500\n",
      "1800/1800 [==============================] - 1s 757us/step - loss: 0.4940 - accuracy: 0.8055 - val_loss: 0.4637 - val_accuracy: 0.8243\n",
      "Epoch 257/500\n",
      "1800/1800 [==============================] - 1s 756us/step - loss: 0.4947 - accuracy: 0.8046 - val_loss: 0.4598 - val_accuracy: 0.8231\n",
      "Epoch 258/500\n",
      "1800/1800 [==============================] - 1s 759us/step - loss: 0.4946 - accuracy: 0.8033 - val_loss: 0.4614 - val_accuracy: 0.8240\n",
      "Epoch 259/500\n",
      "1800/1800 [==============================] - 1s 758us/step - loss: 0.4930 - accuracy: 0.8050 - val_loss: 0.4591 - val_accuracy: 0.8242\n",
      "Epoch 260/500\n",
      "1800/1800 [==============================] - 1s 757us/step - loss: 0.4958 - accuracy: 0.8029 - val_loss: 0.4583 - val_accuracy: 0.8240\n",
      "Epoch 261/500\n",
      "1800/1800 [==============================] - 1s 757us/step - loss: 0.4923 - accuracy: 0.8048 - val_loss: 0.4564 - val_accuracy: 0.8252\n",
      "Epoch 262/500\n",
      "1800/1800 [==============================] - 1s 773us/step - loss: 0.4955 - accuracy: 0.8045 - val_loss: 0.4583 - val_accuracy: 0.8257\n",
      "Epoch 263/500\n",
      "1800/1800 [==============================] - 1s 756us/step - loss: 0.4957 - accuracy: 0.8036 - val_loss: 0.4573 - val_accuracy: 0.8260\n",
      "Epoch 264/500\n",
      "1800/1800 [==============================] - 1s 756us/step - loss: 0.4940 - accuracy: 0.8042 - val_loss: 0.4590 - val_accuracy: 0.8261\n",
      "Epoch 265/500\n",
      "1800/1800 [==============================] - 1s 756us/step - loss: 0.4926 - accuracy: 0.8047 - val_loss: 0.4591 - val_accuracy: 0.8242\n",
      "Epoch 266/500\n",
      "1800/1800 [==============================] - 1s 753us/step - loss: 0.4918 - accuracy: 0.8067 - val_loss: 0.4620 - val_accuracy: 0.8238\n",
      "Epoch 267/500\n",
      "1800/1800 [==============================] - 1s 757us/step - loss: 0.4974 - accuracy: 0.8033 - val_loss: 0.4625 - val_accuracy: 0.8256\n",
      "Epoch 268/500\n",
      "1800/1800 [==============================] - 1s 772us/step - loss: 0.4949 - accuracy: 0.8053 - val_loss: 0.4574 - val_accuracy: 0.8260\n",
      "Epoch 269/500\n",
      "1800/1800 [==============================] - 1s 757us/step - loss: 0.4937 - accuracy: 0.8056 - val_loss: 0.4641 - val_accuracy: 0.8223\n",
      "Epoch 270/500\n",
      "1800/1800 [==============================] - 1s 756us/step - loss: 0.4944 - accuracy: 0.8041 - val_loss: 0.4598 - val_accuracy: 0.8246\n",
      "Epoch 271/500\n",
      "1800/1800 [==============================] - 1s 756us/step - loss: 0.4927 - accuracy: 0.8062 - val_loss: 0.4608 - val_accuracy: 0.8250\n",
      "Epoch 272/500\n",
      "1800/1800 [==============================] - 1s 756us/step - loss: 0.4964 - accuracy: 0.8036 - val_loss: 0.4604 - val_accuracy: 0.8261\n",
      "Epoch 273/500\n",
      "1800/1800 [==============================] - 1s 756us/step - loss: 0.4954 - accuracy: 0.8045 - val_loss: 0.4565 - val_accuracy: 0.8246\n",
      "Epoch 274/500\n",
      "1800/1800 [==============================] - 1s 776us/step - loss: 0.4945 - accuracy: 0.8039 - val_loss: 0.4584 - val_accuracy: 0.8253\n",
      "Epoch 275/500\n",
      "1800/1800 [==============================] - 1s 755us/step - loss: 0.4933 - accuracy: 0.8051 - val_loss: 0.4575 - val_accuracy: 0.8246\n",
      "Epoch 276/500\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "1800/1800 [==============================] - 1s 757us/step - loss: 0.4933 - accuracy: 0.8044 - val_loss: 0.4589 - val_accuracy: 0.8249\n",
      "Epoch 276: early stopping\n"
     ]
    }
   ],
   "source": [
    "model=Sequential()\n",
    "model.add(Dense(128, activation=\"relu\"))\n",
    "model.add(Dropout(0.2))\n",
    "model.add(Dense(128, activation=\"relu\"))\n",
    "model.add(Dropout(0.1))\n",
    "model.add(Dense(64, activation=\"relu\"))\n",
    "model.add(Dropout(0.15))\n",
    "model.add(Dense(32, activation=\"relu\"))\n",
    "model.add(Dropout(0.15))\n",
    "model.add(Dense(16, activation=\"relu\"))\n",
    "model.add(Dense(8, activation=\"relu\"))\n",
    "model.add(Dense(3, activation=\"softmax\"))\n",
    "\n",
    "model.compile(loss='categorical_crossentropy', optimizer=Adam(learning_rate=0.001), metrics=['accuracy'])\n",
    "\n",
    "es=EarlyStopping(monitor=\"val_loss\",patience=25,mode=\"auto\",verbose=1)\n",
    "\n",
    "model1 = model.fit(X_train,\n",
    "          y_train,\n",
    "          epochs=500,\n",
    "               batch_size=64,\n",
    "               validation_split=0.15,\n",
    "               verbose=1,callbacks=[es])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 46,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "<AxesSubplot:>"
      ]
     },
     "execution_count": 46,
     "metadata": {},
     "output_type": "execute_result"
    },
    {
     "data": {
      "image/png": "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",
      "text/plain": [
       "<Figure size 1200x600 with 1 Axes>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "loss_df = pd.DataFrame(model.history.history)\n",
    "loss_df.plot()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 47,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "748/748 [==============================] - 0s 247us/step\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0       0.83      0.93      0.88      7973\n",
      "           1       0.82      0.87      0.85      7973\n",
      "           2       0.79      0.66      0.72      7972\n",
      "\n",
      "    accuracy                           0.82     23918\n",
      "   macro avg       0.82      0.82      0.81     23918\n",
      "weighted avg       0.82      0.82      0.81     23918\n",
      "\n"
     ]
    }
   ],
   "source": [
    "y_pred = model.predict(X_test)\n",
    "y_pred_classes = np.argmax(y_pred, axis=1)\n",
    "y_true = np.argmax(y_test, axis=1)\n",
    "print(classification_report(y_true, y_pred_classes))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 48,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "4236/4236 [==============================] - 1s 254us/step\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0       0.86      0.95      0.90     45176\n",
      "           1       0.84      0.90      0.87     45176\n",
      "           2       0.84      0.70      0.76     45177\n",
      "\n",
      "    accuracy                           0.85    135529\n",
      "   macro avg       0.85      0.85      0.84    135529\n",
      "weighted avg       0.85      0.85      0.84    135529\n",
      "\n"
     ]
    }
   ],
   "source": [
    "y_t_pred = model.predict(X_train)\n",
    "y_t_pred_classes = np.argmax(y_t_pred, axis=1)\n",
    "y_t_true = np.argmax(y_train, axis=1)\n",
    "print(classification_report(y_t_true, y_t_pred_classes))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 49,
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 1/500\n",
      "1800/1800 [==============================] - 2s 880us/step - loss: 0.7394 - accuracy: 0.7123 - val_loss: 0.7170 - val_accuracy: 0.7263\n",
      "Epoch 2/500\n",
      "1800/1800 [==============================] - 1s 763us/step - loss: 0.7153 - accuracy: 0.7253 - val_loss: 0.7002 - val_accuracy: 0.7225\n",
      "Epoch 3/500\n",
      "1800/1800 [==============================] - 1s 748us/step - loss: 0.7141 - accuracy: 0.7255 - val_loss: 0.6936 - val_accuracy: 0.7308\n",
      "Epoch 4/500\n",
      "1800/1800 [==============================] - 1s 747us/step - loss: 0.7218 - accuracy: 0.7215 - val_loss: 0.7243 - val_accuracy: 0.7279\n",
      "Epoch 5/500\n",
      "1800/1800 [==============================] - 1s 749us/step - loss: 0.8116 - accuracy: 0.6306 - val_loss: 0.8459 - val_accuracy: 0.5762\n",
      "Epoch 6/500\n",
      "1800/1800 [==============================] - 1s 750us/step - loss: 0.7930 - accuracy: 0.6879 - val_loss: 0.7425 - val_accuracy: 0.7077\n",
      "Epoch 7/500\n",
      "1800/1800 [==============================] - 1s 752us/step - loss: 0.7637 - accuracy: 0.6979 - val_loss: 0.7529 - val_accuracy: 0.7001\n",
      "Epoch 8/500\n",
      "1800/1800 [==============================] - 1s 772us/step - loss: 0.7582 - accuracy: 0.7041 - val_loss: 0.7525 - val_accuracy: 0.7095\n",
      "Epoch 9/500\n",
      "1800/1800 [==============================] - 1s 771us/step - loss: 0.8068 - accuracy: 0.6777 - val_loss: 0.7801 - val_accuracy: 0.6949\n",
      "Epoch 10/500\n",
      "1800/1800 [==============================] - 1s 770us/step - loss: 1.2149 - accuracy: 0.5841 - val_loss: 0.8907 - val_accuracy: 0.5408\n",
      "Epoch 11/500\n",
      "1800/1800 [==============================] - 1s 793us/step - loss: 0.8543 - accuracy: 0.6270 - val_loss: 0.9031 - val_accuracy: 0.5414\n",
      "Epoch 12/500\n",
      "1800/1800 [==============================] - 1s 779us/step - loss: 0.8609 - accuracy: 0.6111 - val_loss: 0.7624 - val_accuracy: 0.7166\n",
      "Epoch 13/500\n",
      "1800/1800 [==============================] - 1s 776us/step - loss: 0.9471 - accuracy: 0.5264 - val_loss: 0.9873 - val_accuracy: 0.4793\n",
      "Epoch 14/500\n",
      "1800/1800 [==============================] - 1s 775us/step - loss: 0.9019 - accuracy: 0.5613 - val_loss: 0.8639 - val_accuracy: 0.6142\n",
      "Epoch 15/500\n",
      "1800/1800 [==============================] - 1s 776us/step - loss: 0.7778 - accuracy: 0.7072 - val_loss: 0.7683 - val_accuracy: 0.7146\n",
      "Epoch 16/500\n",
      "1800/1800 [==============================] - 1s 779us/step - loss: 0.7876 - accuracy: 0.6976 - val_loss: 0.7746 - val_accuracy: 0.7067\n",
      "Epoch 17/500\n",
      "1800/1800 [==============================] - 1s 775us/step - loss: 0.8113 - accuracy: 0.6923 - val_loss: 0.9501 - val_accuracy: 0.5196\n",
      "Epoch 18/500\n",
      "1800/1800 [==============================] - 1s 777us/step - loss: 0.8843 - accuracy: 0.5738 - val_loss: 0.8833 - val_accuracy: 0.5545\n",
      "Epoch 19/500\n",
      "1800/1800 [==============================] - 1s 761us/step - loss: 0.8855 - accuracy: 0.5765 - val_loss: 0.8417 - val_accuracy: 0.6359\n",
      "Epoch 20/500\n",
      "1800/1800 [==============================] - 1s 761us/step - loss: 0.8067 - accuracy: 0.6844 - val_loss: 0.7755 - val_accuracy: 0.7091\n",
      "Epoch 21/500\n",
      "1800/1800 [==============================] - 1s 774us/step - loss: 0.7766 - accuracy: 0.7051 - val_loss: 0.7654 - val_accuracy: 0.7144\n",
      "Epoch 22/500\n",
      "1800/1800 [==============================] - 1s 795us/step - loss: 0.7715 - accuracy: 0.7072 - val_loss: 0.7652 - val_accuracy: 0.7117\n",
      "Epoch 23/500\n",
      "1800/1800 [==============================] - 1s 781us/step - loss: 0.7780 - accuracy: 0.7033 - val_loss: 0.8045 - val_accuracy: 0.6876\n",
      "Epoch 24/500\n",
      "1800/1800 [==============================] - 1s 770us/step - loss: 0.8566 - accuracy: 0.6266 - val_loss: 0.7960 - val_accuracy: 0.7004\n",
      "Epoch 25/500\n",
      "1800/1800 [==============================] - 1s 757us/step - loss: 0.8290 - accuracy: 0.6448 - val_loss: 0.7725 - val_accuracy: 0.7095\n",
      "Epoch 26/500\n",
      "1800/1800 [==============================] - 1s 759us/step - loss: 0.7815 - accuracy: 0.7014 - val_loss: 0.7754 - val_accuracy: 0.7060\n",
      "Epoch 27/500\n",
      "1800/1800 [==============================] - 1s 760us/step - loss: 0.7778 - accuracy: 0.7047 - val_loss: 0.7829 - val_accuracy: 0.7025\n",
      "Epoch 28/500\n",
      "1800/1800 [==============================] - 1s 777us/step - loss: 0.7847 - accuracy: 0.7030 - val_loss: 0.7725 - val_accuracy: 0.7100\n",
      "Epoch 28: early stopping\n"
     ]
    }
   ],
   "source": [
    "# learning rate = 0.01\n",
    "model=Sequential()\n",
    "model.add(Dense(128, activation=\"relu\"))\n",
    "model.add(Dropout(0.2))\n",
    "model.add(Dense(128, activation=\"relu\"))\n",
    "model.add(Dropout(0.1))\n",
    "model.add(Dense(64, activation=\"relu\"))\n",
    "model.add(Dropout(0.15))\n",
    "model.add(Dense(32, activation=\"relu\"))\n",
    "model.add(Dropout(0.15))\n",
    "model.add(Dense(16, activation=\"relu\"))\n",
    "model.add(Dense(8, activation=\"relu\"))\n",
    "model.add(Dense(3, activation=\"softmax\"))\n",
    "\n",
    "model.compile(loss='categorical_crossentropy', optimizer=Adam(learning_rate=0.01), metrics=['accuracy'])\n",
    "\n",
    "es=EarlyStopping(monitor=\"val_loss\",patience=25,mode=\"auto\",verbose=1)\n",
    "\n",
    "model1 = model.fit(X_train,\n",
    "          y_train,\n",
    "          epochs=500,\n",
    "               batch_size=64,\n",
    "               validation_split=0.15,\n",
    "               verbose=1,callbacks=[es])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 50,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "748/748 [==============================] - 0s 249us/step\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0       0.69      0.84      0.76      7973\n",
      "           1       0.73      0.73      0.73      7973\n",
      "           2       0.70      0.55      0.62      7972\n",
      "\n",
      "    accuracy                           0.71     23918\n",
      "   macro avg       0.71      0.71      0.70     23918\n",
      "weighted avg       0.71      0.71      0.70     23918\n",
      "\n"
     ]
    }
   ],
   "source": [
    "y_pred = model.predict(X_test)\n",
    "y_pred_classes = np.argmax(y_pred, axis=1)\n",
    "y_true = np.argmax(y_test, axis=1)\n",
    "print(classification_report(y_true, y_pred_classes))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 51,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "4236/4236 [==============================] - 1s 253us/step\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0       0.69      0.85      0.76     45176\n",
      "           1       0.74      0.73      0.73     45176\n",
      "           2       0.71      0.56      0.63     45177\n",
      "\n",
      "    accuracy                           0.71    135529\n",
      "   macro avg       0.71      0.71      0.71    135529\n",
      "weighted avg       0.71      0.71      0.71    135529\n",
      "\n"
     ]
    }
   ],
   "source": [
    "y_t_pred = model.predict(X_train)\n",
    "y_t_pred_classes = np.argmax(y_t_pred, axis=1)\n",
    "y_t_true = np.argmax(y_train, axis=1)\n",
    "print(classification_report(y_t_true, y_t_pred_classes))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 52,
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 1/500\n",
      "1800/1800 [==============================] - 2s 899us/step - loss: 0.7172 - accuracy: 0.7222 - val_loss: 0.6783 - val_accuracy: 0.7315\n",
      "Epoch 2/500\n",
      "1800/1800 [==============================] - 1s 781us/step - loss: 0.6771 - accuracy: 0.7361 - val_loss: 0.6620 - val_accuracy: 0.7430\n",
      "Epoch 3/500\n",
      "1800/1800 [==============================] - 1s 773us/step - loss: 0.6674 - accuracy: 0.7384 - val_loss: 0.6615 - val_accuracy: 0.7359\n",
      "Epoch 4/500\n",
      "1800/1800 [==============================] - 1s 775us/step - loss: 0.6613 - accuracy: 0.7416 - val_loss: 0.6558 - val_accuracy: 0.7449\n",
      "Epoch 5/500\n",
      "1800/1800 [==============================] - 1s 777us/step - loss: 0.6564 - accuracy: 0.7427 - val_loss: 0.6485 - val_accuracy: 0.7441\n",
      "Epoch 6/500\n",
      "1800/1800 [==============================] - 1s 776us/step - loss: 0.6526 - accuracy: 0.7447 - val_loss: 0.6455 - val_accuracy: 0.7472\n",
      "Epoch 7/500\n",
      "1800/1800 [==============================] - 1s 769us/step - loss: 0.6490 - accuracy: 0.7453 - val_loss: 0.6343 - val_accuracy: 0.7503\n",
      "Epoch 8/500\n",
      "1800/1800 [==============================] - 1s 793us/step - loss: 0.6444 - accuracy: 0.7468 - val_loss: 0.6315 - val_accuracy: 0.7511\n",
      "Epoch 9/500\n",
      "1800/1800 [==============================] - 1s 778us/step - loss: 0.6431 - accuracy: 0.7479 - val_loss: 0.6335 - val_accuracy: 0.7519\n",
      "Epoch 10/500\n",
      "1800/1800 [==============================] - 1s 793us/step - loss: 0.6390 - accuracy: 0.7480 - val_loss: 0.6259 - val_accuracy: 0.7543\n",
      "Epoch 11/500\n",
      "1800/1800 [==============================] - 1s 758us/step - loss: 0.6363 - accuracy: 0.7489 - val_loss: 0.6212 - val_accuracy: 0.7550\n",
      "Epoch 12/500\n",
      "1800/1800 [==============================] - 1s 761us/step - loss: 0.6326 - accuracy: 0.7504 - val_loss: 0.6225 - val_accuracy: 0.7563\n",
      "Epoch 13/500\n",
      "1800/1800 [==============================] - 1s 784us/step - loss: 0.6292 - accuracy: 0.7523 - val_loss: 0.6162 - val_accuracy: 0.7589\n",
      "Epoch 14/500\n",
      "1800/1800 [==============================] - 1s 789us/step - loss: 0.6282 - accuracy: 0.7520 - val_loss: 0.6152 - val_accuracy: 0.7574\n",
      "Epoch 15/500\n",
      "1800/1800 [==============================] - 1s 765us/step - loss: 0.6246 - accuracy: 0.7533 - val_loss: 0.6167 - val_accuracy: 0.7576\n",
      "Epoch 16/500\n",
      "1800/1800 [==============================] - 1s 762us/step - loss: 0.6240 - accuracy: 0.7545 - val_loss: 0.6099 - val_accuracy: 0.7590\n",
      "Epoch 17/500\n",
      "1800/1800 [==============================] - 1s 757us/step - loss: 0.6211 - accuracy: 0.7541 - val_loss: 0.6083 - val_accuracy: 0.7608\n",
      "Epoch 18/500\n",
      "1800/1800 [==============================] - 1s 806us/step - loss: 0.6188 - accuracy: 0.7550 - val_loss: 0.6038 - val_accuracy: 0.7612\n",
      "Epoch 19/500\n",
      "1800/1800 [==============================] - 2s 864us/step - loss: 0.6162 - accuracy: 0.7552 - val_loss: 0.5985 - val_accuracy: 0.7622\n",
      "Epoch 20/500\n",
      "1800/1800 [==============================] - 1s 795us/step - loss: 0.6147 - accuracy: 0.7564 - val_loss: 0.5999 - val_accuracy: 0.7610\n",
      "Epoch 21/500\n",
      "1800/1800 [==============================] - 1s 784us/step - loss: 0.6124 - accuracy: 0.7563 - val_loss: 0.5968 - val_accuracy: 0.7644\n",
      "Epoch 22/500\n",
      "1800/1800 [==============================] - 1s 777us/step - loss: 0.6098 - accuracy: 0.7585 - val_loss: 0.5930 - val_accuracy: 0.7645\n",
      "Epoch 23/500\n",
      "1800/1800 [==============================] - 1s 781us/step - loss: 0.6101 - accuracy: 0.7574 - val_loss: 0.5913 - val_accuracy: 0.7644\n",
      "Epoch 24/500\n",
      "1800/1800 [==============================] - 1s 788us/step - loss: 0.6076 - accuracy: 0.7599 - val_loss: 0.5932 - val_accuracy: 0.7660\n",
      "Epoch 25/500\n",
      "1800/1800 [==============================] - 1s 782us/step - loss: 0.6063 - accuracy: 0.7600 - val_loss: 0.5869 - val_accuracy: 0.7679\n",
      "Epoch 26/500\n",
      "1800/1800 [==============================] - 1s 807us/step - loss: 0.6048 - accuracy: 0.7596 - val_loss: 0.5917 - val_accuracy: 0.7633\n",
      "Epoch 27/500\n",
      "1800/1800 [==============================] - 1s 788us/step - loss: 0.6022 - accuracy: 0.7607 - val_loss: 0.5882 - val_accuracy: 0.7698\n",
      "Epoch 28/500\n",
      "1800/1800 [==============================] - 1s 788us/step - loss: 0.6014 - accuracy: 0.7611 - val_loss: 0.5800 - val_accuracy: 0.7708\n",
      "Epoch 29/500\n",
      "1800/1800 [==============================] - 1s 784us/step - loss: 0.6014 - accuracy: 0.7610 - val_loss: 0.5849 - val_accuracy: 0.7675\n",
      "Epoch 30/500\n",
      "1800/1800 [==============================] - 1s 787us/step - loss: 0.5993 - accuracy: 0.7614 - val_loss: 0.5816 - val_accuracy: 0.7702\n",
      "Epoch 31/500\n",
      "1800/1800 [==============================] - 1s 785us/step - loss: 0.5997 - accuracy: 0.7622 - val_loss: 0.5845 - val_accuracy: 0.7621\n",
      "Epoch 32/500\n",
      "1800/1800 [==============================] - 1s 789us/step - loss: 0.5974 - accuracy: 0.7627 - val_loss: 0.5726 - val_accuracy: 0.7711\n",
      "Epoch 33/500\n",
      "1800/1800 [==============================] - 1s 780us/step - loss: 0.5949 - accuracy: 0.7633 - val_loss: 0.5797 - val_accuracy: 0.7714\n",
      "Epoch 34/500\n",
      "1800/1800 [==============================] - 1s 796us/step - loss: 0.5945 - accuracy: 0.7631 - val_loss: 0.5726 - val_accuracy: 0.7712\n",
      "Epoch 35/500\n",
      "1800/1800 [==============================] - 1s 779us/step - loss: 0.5938 - accuracy: 0.7627 - val_loss: 0.5771 - val_accuracy: 0.7722\n",
      "Epoch 36/500\n",
      "1800/1800 [==============================] - 1s 780us/step - loss: 0.5913 - accuracy: 0.7654 - val_loss: 0.5755 - val_accuracy: 0.7745\n",
      "Epoch 37/500\n",
      "1800/1800 [==============================] - 1s 781us/step - loss: 0.5928 - accuracy: 0.7640 - val_loss: 0.5745 - val_accuracy: 0.7736\n",
      "Epoch 38/500\n",
      "1800/1800 [==============================] - 1s 779us/step - loss: 0.5922 - accuracy: 0.7644 - val_loss: 0.5751 - val_accuracy: 0.7744\n",
      "Epoch 39/500\n",
      "1800/1800 [==============================] - 1s 780us/step - loss: 0.5894 - accuracy: 0.7659 - val_loss: 0.5674 - val_accuracy: 0.7761\n",
      "Epoch 40/500\n",
      "1800/1800 [==============================] - 1s 777us/step - loss: 0.5888 - accuracy: 0.7662 - val_loss: 0.5668 - val_accuracy: 0.7785\n",
      "Epoch 41/500\n",
      "1800/1800 [==============================] - 1s 803us/step - loss: 0.5884 - accuracy: 0.7656 - val_loss: 0.5613 - val_accuracy: 0.7760\n",
      "Epoch 42/500\n",
      "1800/1800 [==============================] - 1s 780us/step - loss: 0.5880 - accuracy: 0.7662 - val_loss: 0.5703 - val_accuracy: 0.7715\n",
      "Epoch 43/500\n",
      "1800/1800 [==============================] - 1s 788us/step - loss: 0.5863 - accuracy: 0.7663 - val_loss: 0.5638 - val_accuracy: 0.7767\n",
      "Epoch 44/500\n",
      "1800/1800 [==============================] - 1s 788us/step - loss: 0.5849 - accuracy: 0.7669 - val_loss: 0.5646 - val_accuracy: 0.7781\n",
      "Epoch 45/500\n",
      "1800/1800 [==============================] - 1s 787us/step - loss: 0.5845 - accuracy: 0.7668 - val_loss: 0.5656 - val_accuracy: 0.7766\n",
      "Epoch 46/500\n",
      "1800/1800 [==============================] - 1s 785us/step - loss: 0.5859 - accuracy: 0.7660 - val_loss: 0.5613 - val_accuracy: 0.7767\n",
      "Epoch 47/500\n",
      "1800/1800 [==============================] - 1s 784us/step - loss: 0.5840 - accuracy: 0.7675 - val_loss: 0.5624 - val_accuracy: 0.7792\n",
      "Epoch 48/500\n",
      "1800/1800 [==============================] - 1s 807us/step - loss: 0.5829 - accuracy: 0.7677 - val_loss: 0.5586 - val_accuracy: 0.7788\n",
      "Epoch 49/500\n",
      "1800/1800 [==============================] - 1s 785us/step - loss: 0.5818 - accuracy: 0.7678 - val_loss: 0.5568 - val_accuracy: 0.7777\n",
      "Epoch 50/500\n",
      "1800/1800 [==============================] - 1s 783us/step - loss: 0.5804 - accuracy: 0.7677 - val_loss: 0.5572 - val_accuracy: 0.7801\n",
      "Epoch 51/500\n",
      "1800/1800 [==============================] - 1s 783us/step - loss: 0.5806 - accuracy: 0.7679 - val_loss: 0.5559 - val_accuracy: 0.7798\n",
      "Epoch 52/500\n",
      "1800/1800 [==============================] - 1s 777us/step - loss: 0.5802 - accuracy: 0.7676 - val_loss: 0.5544 - val_accuracy: 0.7807\n",
      "Epoch 53/500\n",
      "1800/1800 [==============================] - 1s 777us/step - loss: 0.5781 - accuracy: 0.7687 - val_loss: 0.5546 - val_accuracy: 0.7811\n",
      "Epoch 54/500\n",
      "1800/1800 [==============================] - 1s 804us/step - loss: 0.5775 - accuracy: 0.7695 - val_loss: 0.5556 - val_accuracy: 0.7813\n",
      "Epoch 55/500\n",
      "1800/1800 [==============================] - 1s 770us/step - loss: 0.5772 - accuracy: 0.7694 - val_loss: 0.5555 - val_accuracy: 0.7801\n",
      "Epoch 56/500\n",
      "1800/1800 [==============================] - 1s 762us/step - loss: 0.5778 - accuracy: 0.7699 - val_loss: 0.5592 - val_accuracy: 0.7839\n",
      "Epoch 57/500\n",
      "1800/1800 [==============================] - 1s 785us/step - loss: 0.5782 - accuracy: 0.7684 - val_loss: 0.5512 - val_accuracy: 0.7801\n",
      "Epoch 58/500\n",
      "1800/1800 [==============================] - 1s 784us/step - loss: 0.5737 - accuracy: 0.7706 - val_loss: 0.5469 - val_accuracy: 0.7841\n",
      "Epoch 59/500\n",
      "1800/1800 [==============================] - 1s 788us/step - loss: 0.5767 - accuracy: 0.7701 - val_loss: 0.5474 - val_accuracy: 0.7850\n",
      "Epoch 60/500\n",
      "1800/1800 [==============================] - 1s 784us/step - loss: 0.5730 - accuracy: 0.7703 - val_loss: 0.5549 - val_accuracy: 0.7810\n",
      "Epoch 61/500\n",
      "1800/1800 [==============================] - 1s 762us/step - loss: 0.5756 - accuracy: 0.7703 - val_loss: 0.5442 - val_accuracy: 0.7861\n",
      "Epoch 62/500\n",
      "1800/1800 [==============================] - 1s 760us/step - loss: 0.5735 - accuracy: 0.7708 - val_loss: 0.5524 - val_accuracy: 0.7792\n",
      "Epoch 63/500\n",
      "1800/1800 [==============================] - 1s 786us/step - loss: 0.5720 - accuracy: 0.7720 - val_loss: 0.5447 - val_accuracy: 0.7820\n",
      "Epoch 64/500\n",
      "1800/1800 [==============================] - 1s 785us/step - loss: 0.5736 - accuracy: 0.7703 - val_loss: 0.5506 - val_accuracy: 0.7807\n",
      "Epoch 65/500\n",
      "1800/1800 [==============================] - 1s 786us/step - loss: 0.5690 - accuracy: 0.7732 - val_loss: 0.5534 - val_accuracy: 0.7839\n",
      "Epoch 66/500\n",
      "1800/1800 [==============================] - 1s 812us/step - loss: 0.5717 - accuracy: 0.7715 - val_loss: 0.5431 - val_accuracy: 0.7844\n",
      "Epoch 67/500\n",
      "1800/1800 [==============================] - 1s 786us/step - loss: 0.5699 - accuracy: 0.7710 - val_loss: 0.5458 - val_accuracy: 0.7863\n",
      "Epoch 68/500\n",
      "1800/1800 [==============================] - 1s 788us/step - loss: 0.5700 - accuracy: 0.7722 - val_loss: 0.5451 - val_accuracy: 0.7877\n",
      "Epoch 69/500\n",
      "1800/1800 [==============================] - 1s 785us/step - loss: 0.5699 - accuracy: 0.7721 - val_loss: 0.5417 - val_accuracy: 0.7840\n",
      "Epoch 70/500\n",
      "1800/1800 [==============================] - 1s 763us/step - loss: 0.5698 - accuracy: 0.7716 - val_loss: 0.5461 - val_accuracy: 0.7850\n",
      "Epoch 71/500\n",
      "1800/1800 [==============================] - 1s 760us/step - loss: 0.5672 - accuracy: 0.7729 - val_loss: 0.5425 - val_accuracy: 0.7861\n",
      "Epoch 72/500\n",
      "1800/1800 [==============================] - 1s 784us/step - loss: 0.5690 - accuracy: 0.7728 - val_loss: 0.5397 - val_accuracy: 0.7850\n",
      "Epoch 73/500\n",
      "1800/1800 [==============================] - 1s 783us/step - loss: 0.5674 - accuracy: 0.7726 - val_loss: 0.5434 - val_accuracy: 0.7848\n",
      "Epoch 74/500\n",
      "1800/1800 [==============================] - 1s 763us/step - loss: 0.5676 - accuracy: 0.7727 - val_loss: 0.5428 - val_accuracy: 0.7854\n",
      "Epoch 75/500\n",
      "1800/1800 [==============================] - 1s 762us/step - loss: 0.5673 - accuracy: 0.7725 - val_loss: 0.5391 - val_accuracy: 0.7877\n",
      "Epoch 76/500\n",
      "1800/1800 [==============================] - 1s 783us/step - loss: 0.5667 - accuracy: 0.7737 - val_loss: 0.5407 - val_accuracy: 0.7870\n",
      "Epoch 77/500\n",
      "1800/1800 [==============================] - 1s 809us/step - loss: 0.5650 - accuracy: 0.7738 - val_loss: 0.5436 - val_accuracy: 0.7857\n",
      "Epoch 78/500\n",
      "1800/1800 [==============================] - 1s 790us/step - loss: 0.5652 - accuracy: 0.7736 - val_loss: 0.5366 - val_accuracy: 0.7897\n",
      "Epoch 79/500\n",
      "1800/1800 [==============================] - 1s 773us/step - loss: 0.5631 - accuracy: 0.7737 - val_loss: 0.5386 - val_accuracy: 0.7862\n",
      "Epoch 80/500\n",
      "1800/1800 [==============================] - 1s 774us/step - loss: 0.5629 - accuracy: 0.7743 - val_loss: 0.5310 - val_accuracy: 0.7873\n",
      "Epoch 81/500\n",
      "1800/1800 [==============================] - 1s 801us/step - loss: 0.5636 - accuracy: 0.7745 - val_loss: 0.5367 - val_accuracy: 0.7869\n",
      "Epoch 82/500\n",
      "1800/1800 [==============================] - 1s 785us/step - loss: 0.5627 - accuracy: 0.7745 - val_loss: 0.5384 - val_accuracy: 0.7866\n",
      "Epoch 83/500\n",
      "1800/1800 [==============================] - 1s 782us/step - loss: 0.5622 - accuracy: 0.7750 - val_loss: 0.5371 - val_accuracy: 0.7893\n",
      "Epoch 84/500\n",
      "1800/1800 [==============================] - 1s 777us/step - loss: 0.5620 - accuracy: 0.7748 - val_loss: 0.5346 - val_accuracy: 0.7867\n",
      "Epoch 85/500\n",
      "1800/1800 [==============================] - 1s 781us/step - loss: 0.5642 - accuracy: 0.7741 - val_loss: 0.5359 - val_accuracy: 0.7893\n",
      "Epoch 86/500\n",
      "1800/1800 [==============================] - 1s 778us/step - loss: 0.5632 - accuracy: 0.7742 - val_loss: 0.5375 - val_accuracy: 0.7860\n",
      "Epoch 87/500\n",
      "1800/1800 [==============================] - 1s 775us/step - loss: 0.5633 - accuracy: 0.7744 - val_loss: 0.5431 - val_accuracy: 0.7842\n",
      "Epoch 88/500\n",
      "1800/1800 [==============================] - 1s 780us/step - loss: 0.5643 - accuracy: 0.7738 - val_loss: 0.5342 - val_accuracy: 0.7872\n",
      "Epoch 89/500\n",
      "1800/1800 [==============================] - 1s 796us/step - loss: 0.5620 - accuracy: 0.7745 - val_loss: 0.5278 - val_accuracy: 0.7914\n",
      "Epoch 90/500\n",
      "1800/1800 [==============================] - 1s 789us/step - loss: 0.5606 - accuracy: 0.7749 - val_loss: 0.5327 - val_accuracy: 0.7876\n",
      "Epoch 91/500\n",
      "1800/1800 [==============================] - 1s 787us/step - loss: 0.5604 - accuracy: 0.7760 - val_loss: 0.5298 - val_accuracy: 0.7881\n",
      "Epoch 92/500\n",
      "1800/1800 [==============================] - 1s 783us/step - loss: 0.5581 - accuracy: 0.7762 - val_loss: 0.5312 - val_accuracy: 0.7935\n",
      "Epoch 93/500\n",
      "1800/1800 [==============================] - 1s 801us/step - loss: 0.5591 - accuracy: 0.7754 - val_loss: 0.5269 - val_accuracy: 0.7865\n",
      "Epoch 94/500\n",
      "1800/1800 [==============================] - 1s 785us/step - loss: 0.5619 - accuracy: 0.7747 - val_loss: 0.5283 - val_accuracy: 0.7911\n",
      "Epoch 95/500\n",
      "1800/1800 [==============================] - 1s 784us/step - loss: 0.5586 - accuracy: 0.7762 - val_loss: 0.5337 - val_accuracy: 0.7918\n",
      "Epoch 96/500\n",
      "1800/1800 [==============================] - 1s 787us/step - loss: 0.5596 - accuracy: 0.7768 - val_loss: 0.5323 - val_accuracy: 0.7930\n",
      "Epoch 97/500\n",
      "1800/1800 [==============================] - 1s 785us/step - loss: 0.5608 - accuracy: 0.7753 - val_loss: 0.5319 - val_accuracy: 0.7902\n",
      "Epoch 98/500\n",
      "1800/1800 [==============================] - 1s 786us/step - loss: 0.5579 - accuracy: 0.7765 - val_loss: 0.5237 - val_accuracy: 0.7916\n",
      "Epoch 99/500\n",
      "1800/1800 [==============================] - 1s 786us/step - loss: 0.5595 - accuracy: 0.7764 - val_loss: 0.5239 - val_accuracy: 0.7942\n",
      "Epoch 100/500\n",
      "1800/1800 [==============================] - 1s 812us/step - loss: 0.5598 - accuracy: 0.7759 - val_loss: 0.5277 - val_accuracy: 0.7929\n",
      "Epoch 101/500\n",
      "1800/1800 [==============================] - 1s 785us/step - loss: 0.5566 - accuracy: 0.7764 - val_loss: 0.5306 - val_accuracy: 0.7896\n",
      "Epoch 102/500\n",
      "1800/1800 [==============================] - 1s 782us/step - loss: 0.5572 - accuracy: 0.7767 - val_loss: 0.5278 - val_accuracy: 0.7916\n",
      "Epoch 103/500\n",
      "1800/1800 [==============================] - 1s 786us/step - loss: 0.5577 - accuracy: 0.7778 - val_loss: 0.5256 - val_accuracy: 0.7926\n",
      "Epoch 104/500\n",
      "1800/1800 [==============================] - 1s 784us/step - loss: 0.5581 - accuracy: 0.7773 - val_loss: 0.5248 - val_accuracy: 0.7956\n",
      "Epoch 105/500\n",
      "1800/1800 [==============================] - 1s 786us/step - loss: 0.5560 - accuracy: 0.7776 - val_loss: 0.5276 - val_accuracy: 0.7898\n",
      "Epoch 106/500\n",
      "1800/1800 [==============================] - 1s 805us/step - loss: 0.5543 - accuracy: 0.7790 - val_loss: 0.5253 - val_accuracy: 0.7946\n",
      "Epoch 107/500\n",
      "1800/1800 [==============================] - 1s 779us/step - loss: 0.5556 - accuracy: 0.7779 - val_loss: 0.5241 - val_accuracy: 0.7952\n",
      "Epoch 108/500\n",
      "1800/1800 [==============================] - 1s 778us/step - loss: 0.5580 - accuracy: 0.7768 - val_loss: 0.5225 - val_accuracy: 0.7936\n",
      "Epoch 109/500\n",
      "1800/1800 [==============================] - 1s 789us/step - loss: 0.5544 - accuracy: 0.7777 - val_loss: 0.5213 - val_accuracy: 0.7954\n",
      "Epoch 110/500\n",
      "1800/1800 [==============================] - 1s 787us/step - loss: 0.5551 - accuracy: 0.7774 - val_loss: 0.5226 - val_accuracy: 0.7939\n",
      "Epoch 111/500\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "1800/1800 [==============================] - 1s 811us/step - loss: 0.5564 - accuracy: 0.7768 - val_loss: 0.5239 - val_accuracy: 0.7918\n",
      "Epoch 112/500\n",
      "1800/1800 [==============================] - 1s 788us/step - loss: 0.5573 - accuracy: 0.7776 - val_loss: 0.5269 - val_accuracy: 0.7921\n",
      "Epoch 113/500\n",
      "1800/1800 [==============================] - 1s 787us/step - loss: 0.5543 - accuracy: 0.7772 - val_loss: 0.5217 - val_accuracy: 0.7946\n",
      "Epoch 114/500\n",
      "1800/1800 [==============================] - 1s 787us/step - loss: 0.5551 - accuracy: 0.7768 - val_loss: 0.5206 - val_accuracy: 0.7962\n",
      "Epoch 115/500\n",
      "1800/1800 [==============================] - 1s 783us/step - loss: 0.5529 - accuracy: 0.7789 - val_loss: 0.5207 - val_accuracy: 0.7946\n",
      "Epoch 116/500\n",
      "1800/1800 [==============================] - 1s 761us/step - loss: 0.5510 - accuracy: 0.7793 - val_loss: 0.5163 - val_accuracy: 0.7974\n",
      "Epoch 117/500\n",
      "1800/1800 [==============================] - 1s 760us/step - loss: 0.5542 - accuracy: 0.7771 - val_loss: 0.5238 - val_accuracy: 0.7910\n",
      "Epoch 118/500\n",
      "1800/1800 [==============================] - 1s 756us/step - loss: 0.5520 - accuracy: 0.7786 - val_loss: 0.5228 - val_accuracy: 0.7948\n",
      "Epoch 119/500\n",
      "1800/1800 [==============================] - 1s 787us/step - loss: 0.5532 - accuracy: 0.7783 - val_loss: 0.5262 - val_accuracy: 0.7955\n",
      "Epoch 120/500\n",
      "1800/1800 [==============================] - 1s 790us/step - loss: 0.5534 - accuracy: 0.7784 - val_loss: 0.5203 - val_accuracy: 0.7958\n",
      "Epoch 121/500\n",
      "1800/1800 [==============================] - 1s 789us/step - loss: 0.5528 - accuracy: 0.7783 - val_loss: 0.5206 - val_accuracy: 0.7949\n",
      "Epoch 122/500\n",
      "1800/1800 [==============================] - 1s 787us/step - loss: 0.5518 - accuracy: 0.7789 - val_loss: 0.5157 - val_accuracy: 0.7963\n",
      "Epoch 123/500\n",
      "1800/1800 [==============================] - 1s 792us/step - loss: 0.5517 - accuracy: 0.7781 - val_loss: 0.5169 - val_accuracy: 0.7970\n",
      "Epoch 124/500\n",
      "1800/1800 [==============================] - 1s 788us/step - loss: 0.5496 - accuracy: 0.7798 - val_loss: 0.5157 - val_accuracy: 0.7948\n",
      "Epoch 125/500\n",
      "1800/1800 [==============================] - 1s 784us/step - loss: 0.5505 - accuracy: 0.7794 - val_loss: 0.5270 - val_accuracy: 0.7967\n",
      "Epoch 126/500\n",
      "1800/1800 [==============================] - 1s 802us/step - loss: 0.5502 - accuracy: 0.7791 - val_loss: 0.5187 - val_accuracy: 0.7955\n",
      "Epoch 127/500\n",
      "1800/1800 [==============================] - 1s 786us/step - loss: 0.5503 - accuracy: 0.7794 - val_loss: 0.5184 - val_accuracy: 0.7950\n",
      "Epoch 128/500\n",
      "1800/1800 [==============================] - 1s 777us/step - loss: 0.5497 - accuracy: 0.7788 - val_loss: 0.5214 - val_accuracy: 0.7949\n",
      "Epoch 129/500\n",
      "1800/1800 [==============================] - 1s 777us/step - loss: 0.5486 - accuracy: 0.7816 - val_loss: 0.5143 - val_accuracy: 0.7985\n",
      "Epoch 130/500\n",
      "1800/1800 [==============================] - 1s 785us/step - loss: 0.5506 - accuracy: 0.7799 - val_loss: 0.5146 - val_accuracy: 0.7962\n",
      "Epoch 131/500\n",
      "1800/1800 [==============================] - 1s 776us/step - loss: 0.5512 - accuracy: 0.7800 - val_loss: 0.5165 - val_accuracy: 0.7986\n",
      "Epoch 132/500\n",
      "1800/1800 [==============================] - 1s 773us/step - loss: 0.5506 - accuracy: 0.7804 - val_loss: 0.5124 - val_accuracy: 0.7993\n",
      "Epoch 133/500\n",
      "1800/1800 [==============================] - 1s 787us/step - loss: 0.5488 - accuracy: 0.7813 - val_loss: 0.5124 - val_accuracy: 0.7965\n",
      "Epoch 134/500\n",
      "1800/1800 [==============================] - 1s 790us/step - loss: 0.5491 - accuracy: 0.7807 - val_loss: 0.5184 - val_accuracy: 0.7999\n",
      "Epoch 135/500\n",
      "1800/1800 [==============================] - 1s 774us/step - loss: 0.5497 - accuracy: 0.7810 - val_loss: 0.5165 - val_accuracy: 0.7960\n",
      "Epoch 136/500\n",
      "1800/1800 [==============================] - 1s 811us/step - loss: 0.5483 - accuracy: 0.7806 - val_loss: 0.5145 - val_accuracy: 0.7989\n",
      "Epoch 137/500\n",
      "1800/1800 [==============================] - 1s 789us/step - loss: 0.5483 - accuracy: 0.7800 - val_loss: 0.5203 - val_accuracy: 0.7987\n",
      "Epoch 138/500\n",
      "1800/1800 [==============================] - 1s 784us/step - loss: 0.5463 - accuracy: 0.7828 - val_loss: 0.5155 - val_accuracy: 0.8001\n",
      "Epoch 139/500\n",
      "1800/1800 [==============================] - 1s 778us/step - loss: 0.5474 - accuracy: 0.7825 - val_loss: 0.5112 - val_accuracy: 0.8001\n",
      "Epoch 140/500\n",
      "1800/1800 [==============================] - 1s 778us/step - loss: 0.5476 - accuracy: 0.7809 - val_loss: 0.5235 - val_accuracy: 0.7975\n",
      "Epoch 141/500\n",
      "1800/1800 [==============================] - 1s 784us/step - loss: 0.5495 - accuracy: 0.7802 - val_loss: 0.5216 - val_accuracy: 0.7940\n",
      "Epoch 142/500\n",
      "1800/1800 [==============================] - 1s 783us/step - loss: 0.5499 - accuracy: 0.7793 - val_loss: 0.5195 - val_accuracy: 0.7949\n",
      "Epoch 143/500\n",
      "1800/1800 [==============================] - 1s 782us/step - loss: 0.5472 - accuracy: 0.7813 - val_loss: 0.5131 - val_accuracy: 0.8003\n",
      "Epoch 144/500\n",
      "1800/1800 [==============================] - 1s 779us/step - loss: 0.5472 - accuracy: 0.7807 - val_loss: 0.5151 - val_accuracy: 0.7969\n",
      "Epoch 145/500\n",
      "1800/1800 [==============================] - 1s 766us/step - loss: 0.5463 - accuracy: 0.7816 - val_loss: 0.5175 - val_accuracy: 0.7972\n",
      "Epoch 146/500\n",
      "1800/1800 [==============================] - 1s 754us/step - loss: 0.5452 - accuracy: 0.7810 - val_loss: 0.5098 - val_accuracy: 0.7986\n",
      "Epoch 147/500\n",
      "1800/1800 [==============================] - 1s 782us/step - loss: 0.5462 - accuracy: 0.7819 - val_loss: 0.5139 - val_accuracy: 0.7999\n",
      "Epoch 148/500\n",
      "1800/1800 [==============================] - 1s 758us/step - loss: 0.5464 - accuracy: 0.7813 - val_loss: 0.5135 - val_accuracy: 0.8008\n",
      "Epoch 149/500\n",
      "1800/1800 [==============================] - 1s 762us/step - loss: 0.5461 - accuracy: 0.7818 - val_loss: 0.5076 - val_accuracy: 0.8018\n",
      "Epoch 150/500\n",
      "1800/1800 [==============================] - 1s 786us/step - loss: 0.5471 - accuracy: 0.7817 - val_loss: 0.5148 - val_accuracy: 0.7985\n",
      "Epoch 151/500\n",
      "1800/1800 [==============================] - 1s 803us/step - loss: 0.5450 - accuracy: 0.7817 - val_loss: 0.5150 - val_accuracy: 0.7988\n",
      "Epoch 152/500\n",
      "1800/1800 [==============================] - 1s 773us/step - loss: 0.5471 - accuracy: 0.7800 - val_loss: 0.5109 - val_accuracy: 0.7991\n",
      "Epoch 153/500\n",
      "1800/1800 [==============================] - 1s 773us/step - loss: 0.5462 - accuracy: 0.7822 - val_loss: 0.5176 - val_accuracy: 0.8010\n",
      "Epoch 154/500\n",
      "1800/1800 [==============================] - 1s 784us/step - loss: 0.5464 - accuracy: 0.7819 - val_loss: 0.5121 - val_accuracy: 0.8023\n",
      "Epoch 155/500\n",
      "1800/1800 [==============================] - 1s 790us/step - loss: 0.5461 - accuracy: 0.7811 - val_loss: 0.5148 - val_accuracy: 0.7982\n",
      "Epoch 156/500\n",
      "1800/1800 [==============================] - 1s 785us/step - loss: 0.5441 - accuracy: 0.7817 - val_loss: 0.5137 - val_accuracy: 0.8025\n",
      "Epoch 157/500\n",
      "1800/1800 [==============================] - 2s 834us/step - loss: 0.5462 - accuracy: 0.7821 - val_loss: 0.5087 - val_accuracy: 0.8015\n",
      "Epoch 158/500\n",
      "1800/1800 [==============================] - 1s 760us/step - loss: 0.5447 - accuracy: 0.7826 - val_loss: 0.5139 - val_accuracy: 0.8026\n",
      "Epoch 159/500\n",
      "1800/1800 [==============================] - 1s 756us/step - loss: 0.5455 - accuracy: 0.7835 - val_loss: 0.5092 - val_accuracy: 0.7998\n",
      "Epoch 160/500\n",
      "1800/1800 [==============================] - 1s 754us/step - loss: 0.5447 - accuracy: 0.7833 - val_loss: 0.5097 - val_accuracy: 0.7997\n",
      "Epoch 161/500\n",
      "1800/1800 [==============================] - 1s 786us/step - loss: 0.5443 - accuracy: 0.7840 - val_loss: 0.5058 - val_accuracy: 0.8011\n",
      "Epoch 162/500\n",
      "1800/1800 [==============================] - 1s 788us/step - loss: 0.5430 - accuracy: 0.7827 - val_loss: 0.5103 - val_accuracy: 0.7994\n",
      "Epoch 163/500\n",
      "1800/1800 [==============================] - 1s 806us/step - loss: 0.5462 - accuracy: 0.7817 - val_loss: 0.5143 - val_accuracy: 0.7968\n",
      "Epoch 164/500\n",
      "1800/1800 [==============================] - 1s 775us/step - loss: 0.5441 - accuracy: 0.7832 - val_loss: 0.5100 - val_accuracy: 0.8000\n",
      "Epoch 165/500\n",
      "1800/1800 [==============================] - 1s 782us/step - loss: 0.5435 - accuracy: 0.7824 - val_loss: 0.5056 - val_accuracy: 0.8040\n",
      "Epoch 166/500\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "1800/1800 [==============================] - 1s 787us/step - loss: 0.5426 - accuracy: 0.7830 - val_loss: 0.5126 - val_accuracy: 0.8000\n",
      "Epoch 167/500\n",
      "1800/1800 [==============================] - 1s 787us/step - loss: 0.5423 - accuracy: 0.7832 - val_loss: 0.5059 - val_accuracy: 0.8020\n",
      "Epoch 168/500\n",
      "1800/1800 [==============================] - 1s 794us/step - loss: 0.5434 - accuracy: 0.7838 - val_loss: 0.5114 - val_accuracy: 0.8012\n",
      "Epoch 169/500\n",
      "1800/1800 [==============================] - 1s 763us/step - loss: 0.5424 - accuracy: 0.7833 - val_loss: 0.5026 - val_accuracy: 0.8024\n",
      "Epoch 170/500\n",
      "1800/1800 [==============================] - 1s 764us/step - loss: 0.5447 - accuracy: 0.7838 - val_loss: 0.5097 - val_accuracy: 0.8015\n",
      "Epoch 171/500\n",
      "1800/1800 [==============================] - 1s 762us/step - loss: 0.5419 - accuracy: 0.7833 - val_loss: 0.5126 - val_accuracy: 0.7995\n",
      "Epoch 172/500\n",
      "1800/1800 [==============================] - 1s 762us/step - loss: 0.5441 - accuracy: 0.7819 - val_loss: 0.5120 - val_accuracy: 0.8025\n",
      "Epoch 173/500\n",
      "1800/1800 [==============================] - 1s 766us/step - loss: 0.5419 - accuracy: 0.7843 - val_loss: 0.5154 - val_accuracy: 0.8013\n",
      "Epoch 174/500\n",
      "1800/1800 [==============================] - 1s 764us/step - loss: 0.5433 - accuracy: 0.7826 - val_loss: 0.5095 - val_accuracy: 0.8039\n",
      "Epoch 175/500\n",
      "1800/1800 [==============================] - 1s 809us/step - loss: 0.5423 - accuracy: 0.7834 - val_loss: 0.5075 - val_accuracy: 0.8017\n",
      "Epoch 176/500\n",
      "1800/1800 [==============================] - 1s 763us/step - loss: 0.5424 - accuracy: 0.7829 - val_loss: 0.5150 - val_accuracy: 0.7995\n",
      "Epoch 177/500\n",
      "1800/1800 [==============================] - 1s 760us/step - loss: 0.5413 - accuracy: 0.7849 - val_loss: 0.5074 - val_accuracy: 0.8026\n",
      "Epoch 178/500\n",
      "1800/1800 [==============================] - 1s 761us/step - loss: 0.5424 - accuracy: 0.7830 - val_loss: 0.5108 - val_accuracy: 0.8000\n",
      "Epoch 179/500\n",
      "1800/1800 [==============================] - 1s 761us/step - loss: 0.5413 - accuracy: 0.7845 - val_loss: 0.5035 - val_accuracy: 0.8040\n",
      "Epoch 180/500\n",
      "1800/1800 [==============================] - 1s 792us/step - loss: 0.5438 - accuracy: 0.7835 - val_loss: 0.5018 - val_accuracy: 0.8021\n",
      "Epoch 181/500\n",
      "1800/1800 [==============================] - 1s 791us/step - loss: 0.5428 - accuracy: 0.7843 - val_loss: 0.5096 - val_accuracy: 0.8035\n",
      "Epoch 182/500\n",
      "1800/1800 [==============================] - 1s 786us/step - loss: 0.5402 - accuracy: 0.7849 - val_loss: 0.5067 - val_accuracy: 0.8014\n",
      "Epoch 183/500\n",
      "1800/1800 [==============================] - 1s 782us/step - loss: 0.5400 - accuracy: 0.7849 - val_loss: 0.5016 - val_accuracy: 0.8016\n",
      "Epoch 184/500\n",
      "1800/1800 [==============================] - 1s 780us/step - loss: 0.5374 - accuracy: 0.7869 - val_loss: 0.5123 - val_accuracy: 0.8054\n",
      "Epoch 185/500\n",
      "1800/1800 [==============================] - 1s 778us/step - loss: 0.5402 - accuracy: 0.7853 - val_loss: 0.5007 - val_accuracy: 0.8036\n",
      "Epoch 186/500\n",
      "1800/1800 [==============================] - 1s 807us/step - loss: 0.5408 - accuracy: 0.7864 - val_loss: 0.5029 - val_accuracy: 0.8052\n",
      "Epoch 187/500\n",
      "1800/1800 [==============================] - 1s 776us/step - loss: 0.5401 - accuracy: 0.7853 - val_loss: 0.5065 - val_accuracy: 0.8026\n",
      "Epoch 188/500\n",
      "1800/1800 [==============================] - 1s 777us/step - loss: 0.5386 - accuracy: 0.7858 - val_loss: 0.4993 - val_accuracy: 0.8066\n",
      "Epoch 189/500\n",
      "1800/1800 [==============================] - 1s 774us/step - loss: 0.5398 - accuracy: 0.7848 - val_loss: 0.5043 - val_accuracy: 0.8031\n",
      "Epoch 190/500\n",
      "1800/1800 [==============================] - 1s 776us/step - loss: 0.5378 - accuracy: 0.7869 - val_loss: 0.5049 - val_accuracy: 0.8048\n",
      "Epoch 191/500\n",
      "1800/1800 [==============================] - 1s 793us/step - loss: 0.5391 - accuracy: 0.7848 - val_loss: 0.5100 - val_accuracy: 0.8043\n",
      "Epoch 192/500\n",
      "1800/1800 [==============================] - 1s 788us/step - loss: 0.5405 - accuracy: 0.7857 - val_loss: 0.5047 - val_accuracy: 0.8030\n",
      "Epoch 193/500\n",
      "1800/1800 [==============================] - 1s 789us/step - loss: 0.5377 - accuracy: 0.7871 - val_loss: 0.5053 - val_accuracy: 0.8065\n",
      "Epoch 194/500\n",
      "1800/1800 [==============================] - 1s 803us/step - loss: 0.5383 - accuracy: 0.7853 - val_loss: 0.5129 - val_accuracy: 0.8036\n",
      "Epoch 195/500\n",
      "1800/1800 [==============================] - 1s 783us/step - loss: 0.5394 - accuracy: 0.7859 - val_loss: 0.5061 - val_accuracy: 0.8047\n",
      "Epoch 196/500\n",
      "1800/1800 [==============================] - 1s 789us/step - loss: 0.5406 - accuracy: 0.7847 - val_loss: 0.5029 - val_accuracy: 0.8059\n",
      "Epoch 197/500\n",
      "1800/1800 [==============================] - 1s 790us/step - loss: 0.5367 - accuracy: 0.7866 - val_loss: 0.4969 - val_accuracy: 0.8060\n",
      "Epoch 198/500\n",
      "1800/1800 [==============================] - 1s 788us/step - loss: 0.5405 - accuracy: 0.7850 - val_loss: 0.5034 - val_accuracy: 0.8048\n",
      "Epoch 199/500\n",
      "1800/1800 [==============================] - 1s 786us/step - loss: 0.5400 - accuracy: 0.7863 - val_loss: 0.5056 - val_accuracy: 0.8057\n",
      "Epoch 200/500\n",
      "1800/1800 [==============================] - 1s 786us/step - loss: 0.5366 - accuracy: 0.7869 - val_loss: 0.5034 - val_accuracy: 0.8052\n",
      "Epoch 201/500\n",
      "1800/1800 [==============================] - 1s 783us/step - loss: 0.5379 - accuracy: 0.7877 - val_loss: 0.4998 - val_accuracy: 0.8037\n",
      "Epoch 202/500\n",
      "1800/1800 [==============================] - 1s 792us/step - loss: 0.5401 - accuracy: 0.7842 - val_loss: 0.5026 - val_accuracy: 0.8045\n",
      "Epoch 203/500\n",
      "1800/1800 [==============================] - 1s 795us/step - loss: 0.5375 - accuracy: 0.7860 - val_loss: 0.5032 - val_accuracy: 0.8030\n",
      "Epoch 204/500\n",
      "1800/1800 [==============================] - 1s 777us/step - loss: 0.5376 - accuracy: 0.7862 - val_loss: 0.5014 - val_accuracy: 0.8047\n",
      "Epoch 205/500\n",
      "1800/1800 [==============================] - 1s 810us/step - loss: 0.5368 - accuracy: 0.7859 - val_loss: 0.4969 - val_accuracy: 0.8068\n",
      "Epoch 206/500\n",
      "1800/1800 [==============================] - 1s 786us/step - loss: 0.5383 - accuracy: 0.7865 - val_loss: 0.4986 - val_accuracy: 0.8065\n",
      "Epoch 207/500\n",
      "1800/1800 [==============================] - 1s 791us/step - loss: 0.5372 - accuracy: 0.7867 - val_loss: 0.4963 - val_accuracy: 0.8063\n",
      "Epoch 208/500\n",
      "1800/1800 [==============================] - 1s 790us/step - loss: 0.5389 - accuracy: 0.7851 - val_loss: 0.5063 - val_accuracy: 0.8046\n",
      "Epoch 209/500\n",
      "1800/1800 [==============================] - 1s 787us/step - loss: 0.5383 - accuracy: 0.7862 - val_loss: 0.5058 - val_accuracy: 0.8041\n",
      "Epoch 210/500\n",
      "1800/1800 [==============================] - 1s 804us/step - loss: 0.5370 - accuracy: 0.7880 - val_loss: 0.4976 - val_accuracy: 0.8066\n",
      "Epoch 211/500\n",
      "1800/1800 [==============================] - 1s 788us/step - loss: 0.5390 - accuracy: 0.7853 - val_loss: 0.5026 - val_accuracy: 0.8006\n",
      "Epoch 212/500\n",
      "1800/1800 [==============================] - 1s 788us/step - loss: 0.5365 - accuracy: 0.7870 - val_loss: 0.5040 - val_accuracy: 0.8066\n",
      "Epoch 213/500\n",
      "1800/1800 [==============================] - 1s 788us/step - loss: 0.5366 - accuracy: 0.7864 - val_loss: 0.5018 - val_accuracy: 0.8077\n",
      "Epoch 214/500\n",
      "1800/1800 [==============================] - 1s 796us/step - loss: 0.5379 - accuracy: 0.7857 - val_loss: 0.4959 - val_accuracy: 0.8063\n",
      "Epoch 215/500\n",
      "1800/1800 [==============================] - 1s 786us/step - loss: 0.5350 - accuracy: 0.7874 - val_loss: 0.4994 - val_accuracy: 0.8053\n",
      "Epoch 216/500\n",
      "1800/1800 [==============================] - 1s 809us/step - loss: 0.5360 - accuracy: 0.7868 - val_loss: 0.4975 - val_accuracy: 0.8066\n",
      "Epoch 217/500\n",
      "1800/1800 [==============================] - 1s 762us/step - loss: 0.5367 - accuracy: 0.7865 - val_loss: 0.5041 - val_accuracy: 0.8051\n",
      "Epoch 218/500\n",
      "1800/1800 [==============================] - 1s 762us/step - loss: 0.5367 - accuracy: 0.7854 - val_loss: 0.4993 - val_accuracy: 0.8031\n",
      "Epoch 219/500\n",
      "1800/1800 [==============================] - 1s 757us/step - loss: 0.5359 - accuracy: 0.7869 - val_loss: 0.5065 - val_accuracy: 0.8040\n",
      "Epoch 220/500\n",
      "1800/1800 [==============================] - 1s 757us/step - loss: 0.5364 - accuracy: 0.7859 - val_loss: 0.5042 - val_accuracy: 0.8066\n",
      "Epoch 221/500\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "1800/1800 [==============================] - 1s 763us/step - loss: 0.5372 - accuracy: 0.7862 - val_loss: 0.5050 - val_accuracy: 0.8042\n",
      "Epoch 222/500\n",
      "1800/1800 [==============================] - 1s 764us/step - loss: 0.5357 - accuracy: 0.7889 - val_loss: 0.5047 - val_accuracy: 0.8048\n",
      "Epoch 223/500\n",
      "1800/1800 [==============================] - 1s 760us/step - loss: 0.5363 - accuracy: 0.7876 - val_loss: 0.5005 - val_accuracy: 0.8031\n",
      "Epoch 224/500\n",
      "1800/1800 [==============================] - 1s 825us/step - loss: 0.5348 - accuracy: 0.7858 - val_loss: 0.5014 - val_accuracy: 0.8067\n",
      "Epoch 225/500\n",
      "1800/1800 [==============================] - 1s 799us/step - loss: 0.5364 - accuracy: 0.7876 - val_loss: 0.4996 - val_accuracy: 0.8077\n",
      "Epoch 226/500\n",
      "1800/1800 [==============================] - 1s 766us/step - loss: 0.5389 - accuracy: 0.7860 - val_loss: 0.5070 - val_accuracy: 0.8071\n",
      "Epoch 227/500\n",
      "1800/1800 [==============================] - 1s 763us/step - loss: 0.5397 - accuracy: 0.7845 - val_loss: 0.5061 - val_accuracy: 0.8110\n",
      "Epoch 228/500\n",
      "1800/1800 [==============================] - 1s 758us/step - loss: 0.5353 - accuracy: 0.7878 - val_loss: 0.5035 - val_accuracy: 0.8060\n",
      "Epoch 229/500\n",
      "1800/1800 [==============================] - 1s 787us/step - loss: 0.5379 - accuracy: 0.7872 - val_loss: 0.5047 - val_accuracy: 0.8046\n",
      "Epoch 230/500\n",
      "1800/1800 [==============================] - 1s 789us/step - loss: 0.5359 - accuracy: 0.7879 - val_loss: 0.5031 - val_accuracy: 0.8070\n",
      "Epoch 231/500\n",
      "1800/1800 [==============================] - 1s 788us/step - loss: 0.5346 - accuracy: 0.7879 - val_loss: 0.4952 - val_accuracy: 0.8078\n",
      "Epoch 232/500\n",
      "1800/1800 [==============================] - 1s 785us/step - loss: 0.5338 - accuracy: 0.7879 - val_loss: 0.5031 - val_accuracy: 0.8072\n",
      "Epoch 233/500\n",
      "1800/1800 [==============================] - 1s 778us/step - loss: 0.5355 - accuracy: 0.7887 - val_loss: 0.5001 - val_accuracy: 0.8066\n",
      "Epoch 234/500\n",
      "1800/1800 [==============================] - 1s 779us/step - loss: 0.5368 - accuracy: 0.7869 - val_loss: 0.5002 - val_accuracy: 0.8091\n",
      "Epoch 235/500\n",
      "1800/1800 [==============================] - 1s 761us/step - loss: 0.5357 - accuracy: 0.7872 - val_loss: 0.4929 - val_accuracy: 0.8081\n",
      "Epoch 236/500\n",
      "1800/1800 [==============================] - 1s 762us/step - loss: 0.5346 - accuracy: 0.7887 - val_loss: 0.5008 - val_accuracy: 0.8079\n",
      "Epoch 237/500\n",
      "1800/1800 [==============================] - 1s 761us/step - loss: 0.5364 - accuracy: 0.7876 - val_loss: 0.4978 - val_accuracy: 0.8047\n",
      "Epoch 238/500\n",
      "1800/1800 [==============================] - 1s 802us/step - loss: 0.5357 - accuracy: 0.7882 - val_loss: 0.4974 - val_accuracy: 0.8063\n",
      "Epoch 239/500\n",
      "1800/1800 [==============================] - 1s 789us/step - loss: 0.5347 - accuracy: 0.7880 - val_loss: 0.5065 - val_accuracy: 0.8043\n",
      "Epoch 240/500\n",
      "1800/1800 [==============================] - 1s 787us/step - loss: 0.5354 - accuracy: 0.7878 - val_loss: 0.5009 - val_accuracy: 0.8040\n",
      "Epoch 241/500\n",
      "1800/1800 [==============================] - 1s 786us/step - loss: 0.5331 - accuracy: 0.7872 - val_loss: 0.5000 - val_accuracy: 0.8059\n",
      "Epoch 242/500\n",
      "1800/1800 [==============================] - 1s 761us/step - loss: 0.5348 - accuracy: 0.7874 - val_loss: 0.4948 - val_accuracy: 0.8065\n",
      "Epoch 243/500\n",
      "1800/1800 [==============================] - 1s 763us/step - loss: 0.5356 - accuracy: 0.7891 - val_loss: 0.5035 - val_accuracy: 0.8079\n",
      "Epoch 244/500\n",
      "1800/1800 [==============================] - 1s 789us/step - loss: 0.5350 - accuracy: 0.7885 - val_loss: 0.5035 - val_accuracy: 0.8052\n",
      "Epoch 245/500\n",
      "1800/1800 [==============================] - 1s 791us/step - loss: 0.5350 - accuracy: 0.7881 - val_loss: 0.4953 - val_accuracy: 0.8070\n",
      "Epoch 246/500\n",
      "1800/1800 [==============================] - 1s 787us/step - loss: 0.5361 - accuracy: 0.7875 - val_loss: 0.4978 - val_accuracy: 0.8064\n",
      "Epoch 247/500\n",
      "1800/1800 [==============================] - 1s 803us/step - loss: 0.5331 - accuracy: 0.7890 - val_loss: 0.4952 - val_accuracy: 0.8081\n",
      "Epoch 248/500\n",
      "1800/1800 [==============================] - 1s 795us/step - loss: 0.5336 - accuracy: 0.7886 - val_loss: 0.5007 - val_accuracy: 0.8083\n",
      "Epoch 249/500\n",
      "1800/1800 [==============================] - 1s 785us/step - loss: 0.5342 - accuracy: 0.7874 - val_loss: 0.4995 - val_accuracy: 0.8070\n",
      "Epoch 250/500\n",
      "1800/1800 [==============================] - 1s 782us/step - loss: 0.5337 - accuracy: 0.7881 - val_loss: 0.4979 - val_accuracy: 0.8085\n",
      "Epoch 251/500\n",
      "1800/1800 [==============================] - 1s 788us/step - loss: 0.5358 - accuracy: 0.7876 - val_loss: 0.4995 - val_accuracy: 0.8075\n",
      "Epoch 252/500\n",
      "1800/1800 [==============================] - 1s 761us/step - loss: 0.5340 - accuracy: 0.7885 - val_loss: 0.5014 - val_accuracy: 0.8028\n",
      "Epoch 253/500\n",
      "1800/1800 [==============================] - 1s 758us/step - loss: 0.5334 - accuracy: 0.7888 - val_loss: 0.5026 - val_accuracy: 0.8090\n",
      "Epoch 254/500\n",
      "1800/1800 [==============================] - 1s 762us/step - loss: 0.5323 - accuracy: 0.7893 - val_loss: 0.4944 - val_accuracy: 0.8072\n",
      "Epoch 255/500\n",
      "1800/1800 [==============================] - 1s 760us/step - loss: 0.5321 - accuracy: 0.7885 - val_loss: 0.4957 - val_accuracy: 0.8081\n",
      "Epoch 256/500\n",
      "1800/1800 [==============================] - 1s 781us/step - loss: 0.5329 - accuracy: 0.7880 - val_loss: 0.5004 - val_accuracy: 0.8086\n",
      "Epoch 257/500\n",
      "1800/1800 [==============================] - 1s 763us/step - loss: 0.5341 - accuracy: 0.7887 - val_loss: 0.4963 - val_accuracy: 0.8104\n",
      "Epoch 258/500\n",
      "1800/1800 [==============================] - 1s 764us/step - loss: 0.5353 - accuracy: 0.7888 - val_loss: 0.4975 - val_accuracy: 0.8086\n",
      "Epoch 259/500\n",
      "1800/1800 [==============================] - 1s 765us/step - loss: 0.5332 - accuracy: 0.7890 - val_loss: 0.5007 - val_accuracy: 0.8069\n",
      "Epoch 260/500\n",
      "1800/1800 [==============================] - 1s 789us/step - loss: 0.5326 - accuracy: 0.7884 - val_loss: 0.4944 - val_accuracy: 0.8093\n",
      "Epoch 260: early stopping\n"
     ]
    }
   ],
   "source": [
    "# learning rate = 0.002\n",
    "model=Sequential()\n",
    "model.add(Dense(128, activation=\"relu\"))\n",
    "model.add(Dropout(0.2))\n",
    "model.add(Dense(128, activation=\"relu\"))\n",
    "model.add(Dropout(0.2))\n",
    "model.add(Dense(64, activation=\"relu\"))\n",
    "model.add(Dropout(0.15))\n",
    "model.add(Dense(32, activation=\"relu\"))\n",
    "model.add(Dropout(0.15))\n",
    "model.add(Dense(16, activation=\"relu\"))\n",
    "model.add(Dense(8, activation=\"relu\"))\n",
    "model.add(Dense(3, activation=\"softmax\"))\n",
    "\n",
    "model.compile(loss='categorical_crossentropy', optimizer=Adam(learning_rate=0.002), metrics=['accuracy'])\n",
    "\n",
    "es=EarlyStopping(monitor=\"val_loss\",patience=25,mode=\"auto\",verbose=1)\n",
    "\n",
    "model1 = model.fit(X_train,\n",
    "          y_train,\n",
    "          epochs=500,\n",
    "               batch_size=64,\n",
    "               validation_split=0.15,\n",
    "               verbose=1,callbacks=[es])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 53,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "748/748 [==============================] - 0s 252us/step\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0       0.83      0.90      0.87      7973\n",
      "           1       0.82      0.84      0.83      7973\n",
      "           2       0.76      0.67      0.71      7972\n",
      "\n",
      "    accuracy                           0.80     23918\n",
      "   macro avg       0.80      0.80      0.80     23918\n",
      "weighted avg       0.80      0.80      0.80     23918\n",
      "\n"
     ]
    }
   ],
   "source": [
    "y_pred = model.predict(X_test)\n",
    "y_pred_classes = np.argmax(y_pred, axis=1)\n",
    "y_true = np.argmax(y_test, axis=1)\n",
    "print(classification_report(y_true, y_pred_classes))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 54,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "4236/4236 [==============================] - 1s 253us/step\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0       0.85      0.92      0.89     45176\n",
      "           1       0.83      0.87      0.85     45176\n",
      "           2       0.80      0.70      0.74     45177\n",
      "\n",
      "    accuracy                           0.83    135529\n",
      "   macro avg       0.83      0.83      0.83    135529\n",
      "weighted avg       0.83      0.83      0.83    135529\n",
      "\n"
     ]
    }
   ],
   "source": [
    "y_t_pred = model.predict(X_train)\n",
    "y_t_pred_classes = np.argmax(y_t_pred, axis=1)\n",
    "y_t_true = np.argmax(y_train, axis=1)\n",
    "print(classification_report(y_t_true, y_t_pred_classes))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 55,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "4236/4236 - 1s - loss: 0.4520 - accuracy: 0.8282 - 1s/epoch - 238us/step\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "[0.45198869705200195, 0.8282360434532166]"
      ]
     },
     "execution_count": 55,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "model.evaluate(X_train, y_train, verbose=2)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 56,
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 1/500\n",
      "3812/3812 [==============================] - 2s 610us/step - loss: 0.7115 - accuracy: 0.7234 - val_loss: 0.6637 - val_accuracy: 0.7443\n",
      "Epoch 2/500\n",
      "3812/3812 [==============================] - 2s 527us/step - loss: 0.6789 - accuracy: 0.7362 - val_loss: 0.6567 - val_accuracy: 0.7464\n",
      "Epoch 3/500\n",
      "3812/3812 [==============================] - 2s 580us/step - loss: 0.6667 - accuracy: 0.7391 - val_loss: 0.6439 - val_accuracy: 0.7473\n",
      "Epoch 4/500\n",
      "3812/3812 [==============================] - 2s 568us/step - loss: 0.6594 - accuracy: 0.7409 - val_loss: 0.6365 - val_accuracy: 0.7527\n",
      "Epoch 5/500\n",
      "3812/3812 [==============================] - 2s 571us/step - loss: 0.6527 - accuracy: 0.7439 - val_loss: 0.6351 - val_accuracy: 0.7534\n",
      "Epoch 6/500\n",
      "3812/3812 [==============================] - 2s 572us/step - loss: 0.6471 - accuracy: 0.7457 - val_loss: 0.6214 - val_accuracy: 0.7556\n",
      "Epoch 7/500\n",
      "3812/3812 [==============================] - 2s 574us/step - loss: 0.6412 - accuracy: 0.7468 - val_loss: 0.6201 - val_accuracy: 0.7554\n",
      "Epoch 8/500\n",
      "3812/3812 [==============================] - 2s 576us/step - loss: 0.6387 - accuracy: 0.7479 - val_loss: 0.6160 - val_accuracy: 0.7578\n",
      "Epoch 9/500\n",
      "3812/3812 [==============================] - 2s 573us/step - loss: 0.6341 - accuracy: 0.7505 - val_loss: 0.6111 - val_accuracy: 0.7591\n",
      "Epoch 10/500\n",
      "3812/3812 [==============================] - 2s 573us/step - loss: 0.6310 - accuracy: 0.7513 - val_loss: 0.6065 - val_accuracy: 0.7619\n",
      "Epoch 11/500\n",
      "3812/3812 [==============================] - 2s 574us/step - loss: 0.6270 - accuracy: 0.7530 - val_loss: 0.6049 - val_accuracy: 0.7610\n",
      "Epoch 12/500\n",
      "3812/3812 [==============================] - 2s 573us/step - loss: 0.6229 - accuracy: 0.7537 - val_loss: 0.5987 - val_accuracy: 0.7620\n",
      "Epoch 13/500\n",
      "3812/3812 [==============================] - 2s 573us/step - loss: 0.6208 - accuracy: 0.7532 - val_loss: 0.5951 - val_accuracy: 0.7659\n",
      "Epoch 14/500\n",
      "3812/3812 [==============================] - 2s 575us/step - loss: 0.6177 - accuracy: 0.7548 - val_loss: 0.5890 - val_accuracy: 0.7663\n",
      "Epoch 15/500\n",
      "3812/3812 [==============================] - 2s 577us/step - loss: 0.6148 - accuracy: 0.7563 - val_loss: 0.5871 - val_accuracy: 0.7677\n",
      "Epoch 16/500\n",
      "3812/3812 [==============================] - 2s 581us/step - loss: 0.6126 - accuracy: 0.7577 - val_loss: 0.5853 - val_accuracy: 0.7686\n",
      "Epoch 17/500\n",
      "3812/3812 [==============================] - 2s 573us/step - loss: 0.6101 - accuracy: 0.7572 - val_loss: 0.5793 - val_accuracy: 0.7707\n",
      "Epoch 18/500\n",
      "3812/3812 [==============================] - 2s 574us/step - loss: 0.6070 - accuracy: 0.7583 - val_loss: 0.5787 - val_accuracy: 0.7712\n",
      "Epoch 19/500\n",
      "3812/3812 [==============================] - 2s 573us/step - loss: 0.6065 - accuracy: 0.7590 - val_loss: 0.5766 - val_accuracy: 0.7701\n",
      "Epoch 20/500\n",
      "3812/3812 [==============================] - 2s 573us/step - loss: 0.6039 - accuracy: 0.7601 - val_loss: 0.5757 - val_accuracy: 0.7750\n",
      "Epoch 21/500\n",
      "3812/3812 [==============================] - 2s 573us/step - loss: 0.6032 - accuracy: 0.7602 - val_loss: 0.5741 - val_accuracy: 0.7758\n",
      "Epoch 22/500\n",
      "3812/3812 [==============================] - 2s 574us/step - loss: 0.6013 - accuracy: 0.7606 - val_loss: 0.5679 - val_accuracy: 0.7739\n",
      "Epoch 23/500\n",
      "3812/3812 [==============================] - 2s 580us/step - loss: 0.5982 - accuracy: 0.7619 - val_loss: 0.5649 - val_accuracy: 0.7760\n",
      "Epoch 24/500\n",
      "3812/3812 [==============================] - 2s 573us/step - loss: 0.5958 - accuracy: 0.7620 - val_loss: 0.5662 - val_accuracy: 0.7784\n",
      "Epoch 25/500\n",
      "3812/3812 [==============================] - 2s 574us/step - loss: 0.5950 - accuracy: 0.7627 - val_loss: 0.5641 - val_accuracy: 0.7772\n",
      "Epoch 26/500\n",
      "3812/3812 [==============================] - 2s 573us/step - loss: 0.5938 - accuracy: 0.7635 - val_loss: 0.5612 - val_accuracy: 0.7775\n",
      "Epoch 27/500\n",
      "3812/3812 [==============================] - 2s 572us/step - loss: 0.5910 - accuracy: 0.7642 - val_loss: 0.5621 - val_accuracy: 0.7764\n",
      "Epoch 28/500\n",
      "3812/3812 [==============================] - 2s 584us/step - loss: 0.5912 - accuracy: 0.7655 - val_loss: 0.5572 - val_accuracy: 0.7803\n",
      "Epoch 29/500\n",
      "3812/3812 [==============================] - 2s 572us/step - loss: 0.5901 - accuracy: 0.7653 - val_loss: 0.5601 - val_accuracy: 0.7812\n",
      "Epoch 30/500\n",
      "3812/3812 [==============================] - 2s 574us/step - loss: 0.5878 - accuracy: 0.7655 - val_loss: 0.5537 - val_accuracy: 0.7800\n",
      "Epoch 31/500\n",
      "3812/3812 [==============================] - 2s 573us/step - loss: 0.5882 - accuracy: 0.7655 - val_loss: 0.5509 - val_accuracy: 0.7829\n",
      "Epoch 32/500\n",
      "3812/3812 [==============================] - 2s 573us/step - loss: 0.5880 - accuracy: 0.7654 - val_loss: 0.5570 - val_accuracy: 0.7817\n",
      "Epoch 33/500\n",
      "3812/3812 [==============================] - 2s 583us/step - loss: 0.5841 - accuracy: 0.7664 - val_loss: 0.5533 - val_accuracy: 0.7835\n",
      "Epoch 34/500\n",
      "3812/3812 [==============================] - 2s 581us/step - loss: 0.5832 - accuracy: 0.7677 - val_loss: 0.5474 - val_accuracy: 0.7847\n",
      "Epoch 35/500\n",
      "3812/3812 [==============================] - 2s 572us/step - loss: 0.5826 - accuracy: 0.7676 - val_loss: 0.5462 - val_accuracy: 0.7835\n",
      "Epoch 36/500\n",
      "3812/3812 [==============================] - 2s 574us/step - loss: 0.5819 - accuracy: 0.7677 - val_loss: 0.5512 - val_accuracy: 0.7838\n",
      "Epoch 37/500\n",
      "3812/3812 [==============================] - 2s 571us/step - loss: 0.5814 - accuracy: 0.7671 - val_loss: 0.5480 - val_accuracy: 0.7854\n",
      "Epoch 38/500\n",
      "3812/3812 [==============================] - 2s 594us/step - loss: 0.5813 - accuracy: 0.7681 - val_loss: 0.5473 - val_accuracy: 0.7846\n",
      "Epoch 39/500\n",
      "3812/3812 [==============================] - 2s 572us/step - loss: 0.5804 - accuracy: 0.7692 - val_loss: 0.5464 - val_accuracy: 0.7851\n",
      "Epoch 40/500\n",
      "3812/3812 [==============================] - 2s 573us/step - loss: 0.5790 - accuracy: 0.7698 - val_loss: 0.5450 - val_accuracy: 0.7854\n",
      "Epoch 41/500\n",
      "3812/3812 [==============================] - 2s 573us/step - loss: 0.5783 - accuracy: 0.7696 - val_loss: 0.5411 - val_accuracy: 0.7885\n",
      "Epoch 42/500\n",
      "3812/3812 [==============================] - 2s 573us/step - loss: 0.5769 - accuracy: 0.7708 - val_loss: 0.5418 - val_accuracy: 0.7868\n",
      "Epoch 43/500\n",
      "3812/3812 [==============================] - 2s 581us/step - loss: 0.5744 - accuracy: 0.7715 - val_loss: 0.5374 - val_accuracy: 0.7845\n",
      "Epoch 44/500\n",
      "3812/3812 [==============================] - 2s 572us/step - loss: 0.5769 - accuracy: 0.7710 - val_loss: 0.5415 - val_accuracy: 0.7872\n",
      "Epoch 45/500\n",
      "3812/3812 [==============================] - 2s 572us/step - loss: 0.5744 - accuracy: 0.7711 - val_loss: 0.5400 - val_accuracy: 0.7856\n",
      "Epoch 46/500\n",
      "3812/3812 [==============================] - 2s 572us/step - loss: 0.5752 - accuracy: 0.7709 - val_loss: 0.5391 - val_accuracy: 0.7863\n",
      "Epoch 47/500\n",
      "3812/3812 [==============================] - 2s 580us/step - loss: 0.5728 - accuracy: 0.7721 - val_loss: 0.5340 - val_accuracy: 0.7885\n",
      "Epoch 48/500\n",
      "3812/3812 [==============================] - 2s 572us/step - loss: 0.5729 - accuracy: 0.7704 - val_loss: 0.5365 - val_accuracy: 0.7880\n",
      "Epoch 49/500\n",
      "3812/3812 [==============================] - 2s 572us/step - loss: 0.5716 - accuracy: 0.7728 - val_loss: 0.5349 - val_accuracy: 0.7882\n",
      "Epoch 50/500\n",
      "3812/3812 [==============================] - 2s 573us/step - loss: 0.5719 - accuracy: 0.7717 - val_loss: 0.5360 - val_accuracy: 0.7845\n",
      "Epoch 51/500\n",
      "3812/3812 [==============================] - 2s 581us/step - loss: 0.5704 - accuracy: 0.7726 - val_loss: 0.5333 - val_accuracy: 0.7892\n",
      "Epoch 52/500\n",
      "3812/3812 [==============================] - 2s 572us/step - loss: 0.5706 - accuracy: 0.7728 - val_loss: 0.5279 - val_accuracy: 0.7896\n",
      "Epoch 53/500\n",
      "3812/3812 [==============================] - 2s 572us/step - loss: 0.5687 - accuracy: 0.7726 - val_loss: 0.5276 - val_accuracy: 0.7909\n",
      "Epoch 54/500\n",
      "3812/3812 [==============================] - 2s 572us/step - loss: 0.5697 - accuracy: 0.7730 - val_loss: 0.5284 - val_accuracy: 0.7931\n",
      "Epoch 55/500\n",
      "3812/3812 [==============================] - 2s 583us/step - loss: 0.5683 - accuracy: 0.7739 - val_loss: 0.5301 - val_accuracy: 0.7902\n",
      "Epoch 56/500\n",
      "3812/3812 [==============================] - 2s 573us/step - loss: 0.5683 - accuracy: 0.7733 - val_loss: 0.5324 - val_accuracy: 0.7945\n",
      "Epoch 57/500\n",
      "3812/3812 [==============================] - 2s 576us/step - loss: 0.5667 - accuracy: 0.7734 - val_loss: 0.5300 - val_accuracy: 0.7907\n",
      "Epoch 58/500\n",
      "3812/3812 [==============================] - 2s 575us/step - loss: 0.5685 - accuracy: 0.7733 - val_loss: 0.5295 - val_accuracy: 0.7919\n",
      "Epoch 59/500\n",
      "3812/3812 [==============================] - 2s 574us/step - loss: 0.5673 - accuracy: 0.7735 - val_loss: 0.5256 - val_accuracy: 0.7936\n",
      "Epoch 60/500\n",
      "3812/3812 [==============================] - 2s 573us/step - loss: 0.5670 - accuracy: 0.7744 - val_loss: 0.5328 - val_accuracy: 0.7923\n",
      "Epoch 61/500\n",
      "3812/3812 [==============================] - 2s 575us/step - loss: 0.5659 - accuracy: 0.7748 - val_loss: 0.5285 - val_accuracy: 0.7929\n",
      "Epoch 62/500\n",
      "3812/3812 [==============================] - 2s 573us/step - loss: 0.5659 - accuracy: 0.7750 - val_loss: 0.5209 - val_accuracy: 0.7953\n",
      "Epoch 63/500\n",
      "3812/3812 [==============================] - 2s 574us/step - loss: 0.5670 - accuracy: 0.7748 - val_loss: 0.5234 - val_accuracy: 0.7893\n",
      "Epoch 64/500\n",
      "3812/3812 [==============================] - 2s 583us/step - loss: 0.5647 - accuracy: 0.7751 - val_loss: 0.5298 - val_accuracy: 0.7951\n",
      "Epoch 65/500\n",
      "3812/3812 [==============================] - 2s 573us/step - loss: 0.5642 - accuracy: 0.7755 - val_loss: 0.5206 - val_accuracy: 0.7961\n",
      "Epoch 66/500\n",
      "3812/3812 [==============================] - 2s 573us/step - loss: 0.5641 - accuracy: 0.7750 - val_loss: 0.5243 - val_accuracy: 0.7960\n",
      "Epoch 67/500\n",
      "3812/3812 [==============================] - 2s 573us/step - loss: 0.5635 - accuracy: 0.7755 - val_loss: 0.5243 - val_accuracy: 0.7956\n",
      "Epoch 68/500\n",
      "3812/3812 [==============================] - 2s 573us/step - loss: 0.5634 - accuracy: 0.7755 - val_loss: 0.5224 - val_accuracy: 0.7945\n",
      "Epoch 69/500\n",
      "3812/3812 [==============================] - 2s 572us/step - loss: 0.5632 - accuracy: 0.7756 - val_loss: 0.5160 - val_accuracy: 0.7981\n",
      "Epoch 70/500\n",
      "3812/3812 [==============================] - 2s 574us/step - loss: 0.5624 - accuracy: 0.7768 - val_loss: 0.5163 - val_accuracy: 0.7968\n",
      "Epoch 71/500\n",
      "3812/3812 [==============================] - 2s 573us/step - loss: 0.5616 - accuracy: 0.7763 - val_loss: 0.5185 - val_accuracy: 0.7948\n",
      "Epoch 72/500\n",
      "3812/3812 [==============================] - 2s 583us/step - loss: 0.5607 - accuracy: 0.7763 - val_loss: 0.5157 - val_accuracy: 0.7946\n",
      "Epoch 73/500\n",
      "3812/3812 [==============================] - 2s 574us/step - loss: 0.5607 - accuracy: 0.7766 - val_loss: 0.5207 - val_accuracy: 0.7946\n",
      "Epoch 74/500\n",
      "3812/3812 [==============================] - 2s 575us/step - loss: 0.5620 - accuracy: 0.7770 - val_loss: 0.5218 - val_accuracy: 0.7944\n",
      "Epoch 75/500\n",
      "3812/3812 [==============================] - 2s 573us/step - loss: 0.5599 - accuracy: 0.7767 - val_loss: 0.5178 - val_accuracy: 0.7961\n",
      "Epoch 76/500\n",
      "3812/3812 [==============================] - 2s 573us/step - loss: 0.5605 - accuracy: 0.7764 - val_loss: 0.5286 - val_accuracy: 0.7946\n",
      "Epoch 77/500\n",
      "3812/3812 [==============================] - 2s 573us/step - loss: 0.5578 - accuracy: 0.7776 - val_loss: 0.5238 - val_accuracy: 0.7950\n",
      "Epoch 78/500\n",
      "3812/3812 [==============================] - 2s 572us/step - loss: 0.5601 - accuracy: 0.7765 - val_loss: 0.5176 - val_accuracy: 0.7998\n",
      "Epoch 79/500\n",
      "3812/3812 [==============================] - 2s 583us/step - loss: 0.5569 - accuracy: 0.7802 - val_loss: 0.5159 - val_accuracy: 0.7978\n",
      "Epoch 80/500\n",
      "3812/3812 [==============================] - 2s 573us/step - loss: 0.5573 - accuracy: 0.7772 - val_loss: 0.5176 - val_accuracy: 0.7970\n",
      "Epoch 81/500\n",
      "3812/3812 [==============================] - 2s 574us/step - loss: 0.5575 - accuracy: 0.7774 - val_loss: 0.5111 - val_accuracy: 0.8007\n",
      "Epoch 82/500\n",
      "3812/3812 [==============================] - 2s 573us/step - loss: 0.5580 - accuracy: 0.7779 - val_loss: 0.5198 - val_accuracy: 0.8008\n",
      "Epoch 83/500\n",
      "3812/3812 [==============================] - 2s 573us/step - loss: 0.5575 - accuracy: 0.7785 - val_loss: 0.5135 - val_accuracy: 0.7959\n",
      "Epoch 84/500\n",
      "3812/3812 [==============================] - 2s 582us/step - loss: 0.5563 - accuracy: 0.7783 - val_loss: 0.5127 - val_accuracy: 0.7986\n",
      "Epoch 85/500\n",
      "3812/3812 [==============================] - 2s 572us/step - loss: 0.5556 - accuracy: 0.7800 - val_loss: 0.5146 - val_accuracy: 0.7995\n",
      "Epoch 86/500\n",
      "3812/3812 [==============================] - 2s 573us/step - loss: 0.5534 - accuracy: 0.7800 - val_loss: 0.5157 - val_accuracy: 0.7978\n",
      "Epoch 87/500\n",
      "3812/3812 [==============================] - 2s 573us/step - loss: 0.5540 - accuracy: 0.7794 - val_loss: 0.5130 - val_accuracy: 0.7989\n",
      "Epoch 88/500\n",
      "3812/3812 [==============================] - 2s 574us/step - loss: 0.5548 - accuracy: 0.7790 - val_loss: 0.5132 - val_accuracy: 0.8009\n",
      "Epoch 89/500\n",
      "3812/3812 [==============================] - 2s 582us/step - loss: 0.5554 - accuracy: 0.7791 - val_loss: 0.5195 - val_accuracy: 0.7997\n",
      "Epoch 90/500\n",
      "3812/3812 [==============================] - 2s 580us/step - loss: 0.5558 - accuracy: 0.7792 - val_loss: 0.5080 - val_accuracy: 0.7983\n",
      "Epoch 91/500\n",
      "3812/3812 [==============================] - 2s 572us/step - loss: 0.5557 - accuracy: 0.7799 - val_loss: 0.5149 - val_accuracy: 0.8017\n",
      "Epoch 92/500\n",
      "3812/3812 [==============================] - 2s 572us/step - loss: 0.5550 - accuracy: 0.7791 - val_loss: 0.5169 - val_accuracy: 0.7963\n",
      "Epoch 93/500\n",
      "3812/3812 [==============================] - 2s 572us/step - loss: 0.5564 - accuracy: 0.7788 - val_loss: 0.5103 - val_accuracy: 0.8006\n",
      "Epoch 94/500\n",
      "3812/3812 [==============================] - 2s 582us/step - loss: 0.5523 - accuracy: 0.7826 - val_loss: 0.5055 - val_accuracy: 0.8010\n",
      "Epoch 95/500\n",
      "3812/3812 [==============================] - 2s 572us/step - loss: 0.5532 - accuracy: 0.7808 - val_loss: 0.5042 - val_accuracy: 0.8031\n",
      "Epoch 96/500\n",
      "3812/3812 [==============================] - 2s 572us/step - loss: 0.5515 - accuracy: 0.7812 - val_loss: 0.5067 - val_accuracy: 0.8020\n",
      "Epoch 97/500\n",
      "3812/3812 [==============================] - 2s 572us/step - loss: 0.5541 - accuracy: 0.7796 - val_loss: 0.5107 - val_accuracy: 0.8012\n",
      "Epoch 98/500\n",
      "3812/3812 [==============================] - 2s 580us/step - loss: 0.5542 - accuracy: 0.7791 - val_loss: 0.5100 - val_accuracy: 0.8046\n",
      "Epoch 99/500\n",
      "3812/3812 [==============================] - 2s 572us/step - loss: 0.5513 - accuracy: 0.7816 - val_loss: 0.5077 - val_accuracy: 0.8023\n",
      "Epoch 100/500\n",
      "3812/3812 [==============================] - 2s 572us/step - loss: 0.5523 - accuracy: 0.7814 - val_loss: 0.5100 - val_accuracy: 0.8020\n",
      "Epoch 101/500\n",
      "3812/3812 [==============================] - 2s 574us/step - loss: 0.5501 - accuracy: 0.7816 - val_loss: 0.5082 - val_accuracy: 0.8021\n",
      "Epoch 102/500\n",
      "3812/3812 [==============================] - 2s 572us/step - loss: 0.5527 - accuracy: 0.7812 - val_loss: 0.5195 - val_accuracy: 0.8026\n",
      "Epoch 103/500\n",
      "3812/3812 [==============================] - 2s 582us/step - loss: 0.5531 - accuracy: 0.7812 - val_loss: 0.5088 - val_accuracy: 0.8048\n",
      "Epoch 104/500\n",
      "3812/3812 [==============================] - 2s 573us/step - loss: 0.5514 - accuracy: 0.7819 - val_loss: 0.5102 - val_accuracy: 0.8066\n",
      "Epoch 105/500\n",
      "3812/3812 [==============================] - 2s 572us/step - loss: 0.5496 - accuracy: 0.7820 - val_loss: 0.5068 - val_accuracy: 0.8026\n",
      "Epoch 106/500\n",
      "3812/3812 [==============================] - 2s 572us/step - loss: 0.5514 - accuracy: 0.7818 - val_loss: 0.5107 - val_accuracy: 0.8002\n",
      "Epoch 107/500\n",
      "3812/3812 [==============================] - 2s 581us/step - loss: 0.5513 - accuracy: 0.7814 - val_loss: 0.5092 - val_accuracy: 0.8051\n",
      "Epoch 108/500\n",
      "3812/3812 [==============================] - 2s 574us/step - loss: 0.5523 - accuracy: 0.7812 - val_loss: 0.5146 - val_accuracy: 0.8013\n",
      "Epoch 109/500\n",
      "3812/3812 [==============================] - 2s 572us/step - loss: 0.5510 - accuracy: 0.7820 - val_loss: 0.5063 - val_accuracy: 0.8037\n",
      "Epoch 110/500\n",
      "3812/3812 [==============================] - 2s 580us/step - loss: 0.5492 - accuracy: 0.7832 - val_loss: 0.5067 - val_accuracy: 0.8021\n",
      "Epoch 111/500\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "3812/3812 [==============================] - 2s 574us/step - loss: 0.5520 - accuracy: 0.7821 - val_loss: 0.5134 - val_accuracy: 0.8017\n",
      "Epoch 112/500\n",
      "3812/3812 [==============================] - 2s 573us/step - loss: 0.5507 - accuracy: 0.7820 - val_loss: 0.5090 - val_accuracy: 0.8032\n",
      "Epoch 113/500\n",
      "3812/3812 [==============================] - 2s 572us/step - loss: 0.5486 - accuracy: 0.7826 - val_loss: 0.5114 - val_accuracy: 0.7993\n",
      "Epoch 114/500\n",
      "3812/3812 [==============================] - 2s 573us/step - loss: 0.5497 - accuracy: 0.7820 - val_loss: 0.5117 - val_accuracy: 0.8026\n",
      "Epoch 115/500\n",
      "3812/3812 [==============================] - 2s 576us/step - loss: 0.5477 - accuracy: 0.7833 - val_loss: 0.5059 - val_accuracy: 0.8045\n",
      "Epoch 116/500\n",
      "3812/3812 [==============================] - 2s 574us/step - loss: 0.5492 - accuracy: 0.7834 - val_loss: 0.5048 - val_accuracy: 0.8034\n",
      "Epoch 117/500\n",
      "3812/3812 [==============================] - 2s 574us/step - loss: 0.5491 - accuracy: 0.7838 - val_loss: 0.5118 - val_accuracy: 0.8004\n",
      "Epoch 118/500\n",
      "3812/3812 [==============================] - 2s 572us/step - loss: 0.5497 - accuracy: 0.7828 - val_loss: 0.5089 - val_accuracy: 0.8040\n",
      "Epoch 119/500\n",
      "3812/3812 [==============================] - 2s 572us/step - loss: 0.5493 - accuracy: 0.7826 - val_loss: 0.5047 - val_accuracy: 0.8042\n",
      "Epoch 120/500\n",
      "3812/3812 [==============================] - 2s 581us/step - loss: 0.5484 - accuracy: 0.7835 - val_loss: 0.5045 - val_accuracy: 0.8040\n",
      "Epoch 121/500\n",
      "3812/3812 [==============================] - 2s 573us/step - loss: 0.5472 - accuracy: 0.7837 - val_loss: 0.5038 - val_accuracy: 0.8030\n",
      "Epoch 122/500\n",
      "3812/3812 [==============================] - 2s 602us/step - loss: 0.5470 - accuracy: 0.7839 - val_loss: 0.5019 - val_accuracy: 0.8066\n",
      "Epoch 123/500\n",
      "3812/3812 [==============================] - 2s 576us/step - loss: 0.5480 - accuracy: 0.7833 - val_loss: 0.5073 - val_accuracy: 0.8060\n",
      "Epoch 124/500\n",
      "3812/3812 [==============================] - 2s 573us/step - loss: 0.5471 - accuracy: 0.7831 - val_loss: 0.5082 - val_accuracy: 0.8017\n",
      "Epoch 125/500\n",
      "3812/3812 [==============================] - 2s 573us/step - loss: 0.5448 - accuracy: 0.7844 - val_loss: 0.5077 - val_accuracy: 0.8037\n",
      "Epoch 126/500\n",
      "3812/3812 [==============================] - 2s 573us/step - loss: 0.5462 - accuracy: 0.7837 - val_loss: 0.5032 - val_accuracy: 0.8034\n",
      "Epoch 127/500\n",
      "3812/3812 [==============================] - 2s 572us/step - loss: 0.5455 - accuracy: 0.7845 - val_loss: 0.4987 - val_accuracy: 0.8050\n",
      "Epoch 128/500\n",
      "3812/3812 [==============================] - 2s 582us/step - loss: 0.5436 - accuracy: 0.7853 - val_loss: 0.5039 - val_accuracy: 0.8058\n",
      "Epoch 129/500\n",
      "3812/3812 [==============================] - 2s 574us/step - loss: 0.5484 - accuracy: 0.7833 - val_loss: 0.5026 - val_accuracy: 0.8072\n",
      "Epoch 130/500\n",
      "3812/3812 [==============================] - 2s 573us/step - loss: 0.5469 - accuracy: 0.7835 - val_loss: 0.5072 - val_accuracy: 0.8048\n",
      "Epoch 131/500\n",
      "3812/3812 [==============================] - 2s 572us/step - loss: 0.5447 - accuracy: 0.7849 - val_loss: 0.5007 - val_accuracy: 0.8052\n",
      "Epoch 132/500\n",
      "3812/3812 [==============================] - 2s 570us/step - loss: 0.5460 - accuracy: 0.7841 - val_loss: 0.5028 - val_accuracy: 0.8070\n",
      "Epoch 133/500\n",
      "3812/3812 [==============================] - 2s 592us/step - loss: 0.5450 - accuracy: 0.7842 - val_loss: 0.5117 - val_accuracy: 0.8065\n",
      "Epoch 134/500\n",
      "3812/3812 [==============================] - 2s 572us/step - loss: 0.5439 - accuracy: 0.7838 - val_loss: 0.4971 - val_accuracy: 0.8077\n",
      "Epoch 135/500\n",
      "3812/3812 [==============================] - 2s 573us/step - loss: 0.5462 - accuracy: 0.7842 - val_loss: 0.4991 - val_accuracy: 0.8058\n",
      "Epoch 136/500\n",
      "3812/3812 [==============================] - 2s 572us/step - loss: 0.5430 - accuracy: 0.7856 - val_loss: 0.4997 - val_accuracy: 0.8052\n",
      "Epoch 137/500\n",
      "3812/3812 [==============================] - 2s 581us/step - loss: 0.5449 - accuracy: 0.7853 - val_loss: 0.4990 - val_accuracy: 0.8031\n",
      "Epoch 138/500\n",
      "3812/3812 [==============================] - 2s 573us/step - loss: 0.5431 - accuracy: 0.7851 - val_loss: 0.5000 - val_accuracy: 0.8082\n",
      "Epoch 139/500\n",
      "3812/3812 [==============================] - 2s 584us/step - loss: 0.5435 - accuracy: 0.7838 - val_loss: 0.5007 - val_accuracy: 0.8026\n",
      "Epoch 140/500\n",
      "3812/3812 [==============================] - 2s 572us/step - loss: 0.5434 - accuracy: 0.7856 - val_loss: 0.5030 - val_accuracy: 0.8045\n",
      "Epoch 141/500\n",
      "3812/3812 [==============================] - 2s 572us/step - loss: 0.5455 - accuracy: 0.7838 - val_loss: 0.5020 - val_accuracy: 0.8031\n",
      "Epoch 142/500\n",
      "3812/3812 [==============================] - 2s 572us/step - loss: 0.5438 - accuracy: 0.7848 - val_loss: 0.5037 - val_accuracy: 0.8041\n",
      "Epoch 143/500\n",
      "3812/3812 [==============================] - 2s 574us/step - loss: 0.5429 - accuracy: 0.7846 - val_loss: 0.4974 - val_accuracy: 0.8041\n",
      "Epoch 144/500\n",
      "3812/3812 [==============================] - 2s 582us/step - loss: 0.5432 - accuracy: 0.7844 - val_loss: 0.5036 - val_accuracy: 0.8056\n",
      "Epoch 145/500\n",
      "3812/3812 [==============================] - 2s 570us/step - loss: 0.5429 - accuracy: 0.7846 - val_loss: 0.4988 - val_accuracy: 0.8065\n",
      "Epoch 146/500\n",
      "3812/3812 [==============================] - 2s 568us/step - loss: 0.5429 - accuracy: 0.7851 - val_loss: 0.4977 - val_accuracy: 0.8085\n",
      "Epoch 147/500\n",
      "3812/3812 [==============================] - 2s 573us/step - loss: 0.5438 - accuracy: 0.7855 - val_loss: 0.4978 - val_accuracy: 0.8088\n",
      "Epoch 148/500\n",
      "3812/3812 [==============================] - 2s 574us/step - loss: 0.5412 - accuracy: 0.7867 - val_loss: 0.5003 - val_accuracy: 0.8110\n",
      "Epoch 149/500\n",
      "3812/3812 [==============================] - 2s 582us/step - loss: 0.5420 - accuracy: 0.7853 - val_loss: 0.5009 - val_accuracy: 0.8030\n",
      "Epoch 150/500\n",
      "3812/3812 [==============================] - 2s 576us/step - loss: 0.5427 - accuracy: 0.7853 - val_loss: 0.5066 - val_accuracy: 0.8057\n",
      "Epoch 151/500\n",
      "3812/3812 [==============================] - 2s 572us/step - loss: 0.5419 - accuracy: 0.7854 - val_loss: 0.5002 - val_accuracy: 0.8099\n",
      "Epoch 152/500\n",
      "3812/3812 [==============================] - 2s 575us/step - loss: 0.5429 - accuracy: 0.7854 - val_loss: 0.4962 - val_accuracy: 0.8076\n",
      "Epoch 153/500\n",
      "3812/3812 [==============================] - 2s 584us/step - loss: 0.5426 - accuracy: 0.7850 - val_loss: 0.4981 - val_accuracy: 0.8051\n",
      "Epoch 154/500\n",
      "3812/3812 [==============================] - 2s 574us/step - loss: 0.5426 - accuracy: 0.7861 - val_loss: 0.4996 - val_accuracy: 0.8068\n",
      "Epoch 155/500\n",
      "3812/3812 [==============================] - 2s 574us/step - loss: 0.5439 - accuracy: 0.7849 - val_loss: 0.4994 - val_accuracy: 0.8116\n",
      "Epoch 156/500\n",
      "3812/3812 [==============================] - 2s 573us/step - loss: 0.5412 - accuracy: 0.7868 - val_loss: 0.4989 - val_accuracy: 0.8088\n",
      "Epoch 157/500\n",
      "3812/3812 [==============================] - 2s 574us/step - loss: 0.5414 - accuracy: 0.7863 - val_loss: 0.5005 - val_accuracy: 0.8076\n",
      "Epoch 158/500\n",
      "3812/3812 [==============================] - 2s 583us/step - loss: 0.5433 - accuracy: 0.7840 - val_loss: 0.4931 - val_accuracy: 0.8119\n",
      "Epoch 159/500\n",
      "3812/3812 [==============================] - 2s 576us/step - loss: 0.5417 - accuracy: 0.7855 - val_loss: 0.4993 - val_accuracy: 0.8092\n",
      "Epoch 160/500\n",
      "3812/3812 [==============================] - 2s 574us/step - loss: 0.5410 - accuracy: 0.7864 - val_loss: 0.5097 - val_accuracy: 0.8038\n",
      "Epoch 161/500\n",
      "3812/3812 [==============================] - 2s 576us/step - loss: 0.5422 - accuracy: 0.7847 - val_loss: 0.5003 - val_accuracy: 0.8055\n",
      "Epoch 162/500\n",
      "3812/3812 [==============================] - 2s 585us/step - loss: 0.5424 - accuracy: 0.7852 - val_loss: 0.4955 - val_accuracy: 0.8085\n",
      "Epoch 163/500\n",
      "3812/3812 [==============================] - 2s 574us/step - loss: 0.5405 - accuracy: 0.7862 - val_loss: 0.5006 - val_accuracy: 0.8063\n",
      "Epoch 164/500\n",
      "3812/3812 [==============================] - 2s 573us/step - loss: 0.5408 - accuracy: 0.7875 - val_loss: 0.5020 - val_accuracy: 0.8108\n",
      "Epoch 165/500\n",
      "3812/3812 [==============================] - 2s 581us/step - loss: 0.5429 - accuracy: 0.7855 - val_loss: 0.5008 - val_accuracy: 0.8086\n",
      "Epoch 166/500\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "3812/3812 [==============================] - 2s 575us/step - loss: 0.5391 - accuracy: 0.7864 - val_loss: 0.4988 - val_accuracy: 0.8088\n",
      "Epoch 167/500\n",
      "3812/3812 [==============================] - 2s 571us/step - loss: 0.5406 - accuracy: 0.7859 - val_loss: 0.4928 - val_accuracy: 0.8102\n",
      "Epoch 168/500\n",
      "3812/3812 [==============================] - 2s 574us/step - loss: 0.5405 - accuracy: 0.7875 - val_loss: 0.4977 - val_accuracy: 0.8082\n",
      "Epoch 169/500\n",
      "3812/3812 [==============================] - 2s 575us/step - loss: 0.5413 - accuracy: 0.7866 - val_loss: 0.4974 - val_accuracy: 0.8076\n",
      "Epoch 170/500\n",
      "3812/3812 [==============================] - 2s 577us/step - loss: 0.5403 - accuracy: 0.7856 - val_loss: 0.4970 - val_accuracy: 0.8114\n",
      "Epoch 171/500\n",
      "3812/3812 [==============================] - 2s 574us/step - loss: 0.5429 - accuracy: 0.7847 - val_loss: 0.4988 - val_accuracy: 0.8085\n",
      "Epoch 172/500\n",
      "3812/3812 [==============================] - 2s 574us/step - loss: 0.5395 - accuracy: 0.7889 - val_loss: 0.4957 - val_accuracy: 0.8082\n",
      "Epoch 173/500\n",
      "3812/3812 [==============================] - 2s 572us/step - loss: 0.5406 - accuracy: 0.7866 - val_loss: 0.4941 - val_accuracy: 0.8102\n",
      "Epoch 174/500\n",
      "3812/3812 [==============================] - 2s 576us/step - loss: 0.5404 - accuracy: 0.7882 - val_loss: 0.4961 - val_accuracy: 0.8049\n",
      "Epoch 175/500\n",
      "3812/3812 [==============================] - 2s 581us/step - loss: 0.5396 - accuracy: 0.7866 - val_loss: 0.4922 - val_accuracy: 0.8116\n",
      "Epoch 176/500\n",
      "3812/3812 [==============================] - 2s 572us/step - loss: 0.5376 - accuracy: 0.7886 - val_loss: 0.4966 - val_accuracy: 0.8109\n",
      "Epoch 177/500\n",
      "3812/3812 [==============================] - 2s 572us/step - loss: 0.5398 - accuracy: 0.7864 - val_loss: 0.4922 - val_accuracy: 0.8078\n",
      "Epoch 178/500\n",
      "3812/3812 [==============================] - 2s 618us/step - loss: 0.5402 - accuracy: 0.7868 - val_loss: 0.4931 - val_accuracy: 0.8084\n",
      "Epoch 179/500\n",
      "3812/3812 [==============================] - 2s 571us/step - loss: 0.5390 - accuracy: 0.7864 - val_loss: 0.4981 - val_accuracy: 0.8056\n",
      "Epoch 180/500\n",
      "3812/3812 [==============================] - 2s 566us/step - loss: 0.5377 - accuracy: 0.7874 - val_loss: 0.5032 - val_accuracy: 0.8062\n",
      "Epoch 181/500\n",
      "3812/3812 [==============================] - 2s 572us/step - loss: 0.5392 - accuracy: 0.7862 - val_loss: 0.5027 - val_accuracy: 0.8090\n",
      "Epoch 182/500\n",
      "3812/3812 [==============================] - 2s 572us/step - loss: 0.5380 - accuracy: 0.7876 - val_loss: 0.4968 - val_accuracy: 0.8090\n",
      "Epoch 183/500\n",
      "3812/3812 [==============================] - 2s 580us/step - loss: 0.5378 - accuracy: 0.7875 - val_loss: 0.4917 - val_accuracy: 0.8081\n",
      "Epoch 184/500\n",
      "3812/3812 [==============================] - 2s 572us/step - loss: 0.5376 - accuracy: 0.7878 - val_loss: 0.4979 - val_accuracy: 0.8074\n",
      "Epoch 185/500\n",
      "3812/3812 [==============================] - 2s 575us/step - loss: 0.5375 - accuracy: 0.7870 - val_loss: 0.4979 - val_accuracy: 0.8072\n",
      "Epoch 186/500\n",
      "3812/3812 [==============================] - 2s 574us/step - loss: 0.5394 - accuracy: 0.7872 - val_loss: 0.4995 - val_accuracy: 0.8097\n",
      "Epoch 187/500\n",
      "3812/3812 [==============================] - 2s 574us/step - loss: 0.5371 - accuracy: 0.7881 - val_loss: 0.4910 - val_accuracy: 0.8118\n",
      "Epoch 188/500\n",
      "3812/3812 [==============================] - 2s 574us/step - loss: 0.5376 - accuracy: 0.7859 - val_loss: 0.4970 - val_accuracy: 0.8079\n",
      "Epoch 189/500\n",
      "3812/3812 [==============================] - 2s 570us/step - loss: 0.5392 - accuracy: 0.7858 - val_loss: 0.4921 - val_accuracy: 0.8098\n",
      "Epoch 190/500\n",
      "3812/3812 [==============================] - 2s 580us/step - loss: 0.5390 - accuracy: 0.7866 - val_loss: 0.4972 - val_accuracy: 0.8077\n",
      "Epoch 191/500\n",
      "3812/3812 [==============================] - 2s 571us/step - loss: 0.5363 - accuracy: 0.7881 - val_loss: 0.4959 - val_accuracy: 0.8096\n",
      "Epoch 192/500\n",
      "3812/3812 [==============================] - 2s 571us/step - loss: 0.5392 - accuracy: 0.7863 - val_loss: 0.4938 - val_accuracy: 0.8094\n",
      "Epoch 193/500\n",
      "3812/3812 [==============================] - 2s 572us/step - loss: 0.5361 - accuracy: 0.7892 - val_loss: 0.4890 - val_accuracy: 0.8099\n",
      "Epoch 194/500\n",
      "3812/3812 [==============================] - 2s 571us/step - loss: 0.5359 - accuracy: 0.7886 - val_loss: 0.5038 - val_accuracy: 0.8077\n",
      "Epoch 195/500\n",
      "3812/3812 [==============================] - 2s 581us/step - loss: 0.5367 - accuracy: 0.7881 - val_loss: 0.4947 - val_accuracy: 0.8070\n",
      "Epoch 196/500\n",
      "3812/3812 [==============================] - 2s 572us/step - loss: 0.5383 - accuracy: 0.7873 - val_loss: 0.4940 - val_accuracy: 0.8057\n",
      "Epoch 197/500\n",
      "3812/3812 [==============================] - 2s 572us/step - loss: 0.5378 - accuracy: 0.7872 - val_loss: 0.4924 - val_accuracy: 0.8110\n",
      "Epoch 198/500\n",
      "3812/3812 [==============================] - 2s 572us/step - loss: 0.5379 - accuracy: 0.7879 - val_loss: 0.4907 - val_accuracy: 0.8112\n",
      "Epoch 199/500\n",
      "3812/3812 [==============================] - 2s 573us/step - loss: 0.5380 - accuracy: 0.7878 - val_loss: 0.4938 - val_accuracy: 0.8073\n",
      "Epoch 200/500\n",
      "3812/3812 [==============================] - 2s 580us/step - loss: 0.5376 - accuracy: 0.7878 - val_loss: 0.4900 - val_accuracy: 0.8085\n",
      "Epoch 201/500\n",
      "3812/3812 [==============================] - 2s 570us/step - loss: 0.5371 - accuracy: 0.7881 - val_loss: 0.4958 - val_accuracy: 0.8067\n",
      "Epoch 202/500\n",
      "3812/3812 [==============================] - 2s 570us/step - loss: 0.5376 - accuracy: 0.7885 - val_loss: 0.4935 - val_accuracy: 0.8113\n",
      "Epoch 203/500\n",
      "3812/3812 [==============================] - 2s 571us/step - loss: 0.5383 - accuracy: 0.7872 - val_loss: 0.4924 - val_accuracy: 0.8090\n",
      "Epoch 204/500\n",
      "3812/3812 [==============================] - 2s 571us/step - loss: 0.5355 - accuracy: 0.7889 - val_loss: 0.4942 - val_accuracy: 0.8064\n",
      "Epoch 205/500\n",
      "3812/3812 [==============================] - 2s 581us/step - loss: 0.5388 - accuracy: 0.7881 - val_loss: 0.4883 - val_accuracy: 0.8104\n",
      "Epoch 206/500\n",
      "3812/3812 [==============================] - 2s 572us/step - loss: 0.5372 - accuracy: 0.7877 - val_loss: 0.4950 - val_accuracy: 0.8102\n",
      "Epoch 207/500\n",
      "3812/3812 [==============================] - 2s 573us/step - loss: 0.5343 - accuracy: 0.7896 - val_loss: 0.4837 - val_accuracy: 0.8138\n",
      "Epoch 208/500\n",
      "3812/3812 [==============================] - 2s 587us/step - loss: 0.5351 - accuracy: 0.7888 - val_loss: 0.4865 - val_accuracy: 0.8110\n",
      "Epoch 209/500\n",
      "3812/3812 [==============================] - 2s 584us/step - loss: 0.5367 - accuracy: 0.7881 - val_loss: 0.4961 - val_accuracy: 0.8102\n",
      "Epoch 210/500\n",
      "3812/3812 [==============================] - 2s 571us/step - loss: 0.5368 - accuracy: 0.7884 - val_loss: 0.4879 - val_accuracy: 0.8079\n",
      "Epoch 211/500\n",
      "3812/3812 [==============================] - 2s 574us/step - loss: 0.5333 - accuracy: 0.7896 - val_loss: 0.4926 - val_accuracy: 0.8135\n",
      "Epoch 212/500\n",
      "3812/3812 [==============================] - 2s 574us/step - loss: 0.5381 - accuracy: 0.7869 - val_loss: 0.4958 - val_accuracy: 0.8111\n",
      "Epoch 213/500\n",
      "3812/3812 [==============================] - 2s 582us/step - loss: 0.5353 - accuracy: 0.7890 - val_loss: 0.4928 - val_accuracy: 0.8037\n",
      "Epoch 214/500\n",
      "3812/3812 [==============================] - 2s 572us/step - loss: 0.5357 - accuracy: 0.7882 - val_loss: 0.4928 - val_accuracy: 0.8100\n",
      "Epoch 215/500\n",
      "3812/3812 [==============================] - 2s 574us/step - loss: 0.5375 - accuracy: 0.7883 - val_loss: 0.4936 - val_accuracy: 0.8090\n",
      "Epoch 216/500\n",
      "3812/3812 [==============================] - 2s 572us/step - loss: 0.5385 - accuracy: 0.7882 - val_loss: 0.4961 - val_accuracy: 0.8096\n",
      "Epoch 217/500\n",
      "3812/3812 [==============================] - 2s 584us/step - loss: 0.5354 - accuracy: 0.7889 - val_loss: 0.4865 - val_accuracy: 0.8097\n",
      "Epoch 218/500\n",
      "3812/3812 [==============================] - 2s 573us/step - loss: 0.5357 - accuracy: 0.7886 - val_loss: 0.4895 - val_accuracy: 0.8116\n",
      "Epoch 219/500\n",
      "3812/3812 [==============================] - 2s 570us/step - loss: 0.5353 - accuracy: 0.7893 - val_loss: 0.4857 - val_accuracy: 0.8112\n",
      "Epoch 220/500\n",
      "3812/3812 [==============================] - 2s 569us/step - loss: 0.5362 - accuracy: 0.7879 - val_loss: 0.4872 - val_accuracy: 0.8147\n",
      "Epoch 221/500\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "3812/3812 [==============================] - 2s 581us/step - loss: 0.5353 - accuracy: 0.7891 - val_loss: 0.4935 - val_accuracy: 0.8085\n",
      "Epoch 222/500\n",
      "3812/3812 [==============================] - 2s 572us/step - loss: 0.5352 - accuracy: 0.7890 - val_loss: 0.4903 - val_accuracy: 0.8132\n",
      "Epoch 223/500\n",
      "3812/3812 [==============================] - 2s 568us/step - loss: 0.5320 - accuracy: 0.7900 - val_loss: 0.4880 - val_accuracy: 0.8118\n",
      "Epoch 224/500\n",
      "3812/3812 [==============================] - 2s 570us/step - loss: 0.5365 - accuracy: 0.7884 - val_loss: 0.4890 - val_accuracy: 0.8132\n",
      "Epoch 225/500\n",
      "3812/3812 [==============================] - 2s 574us/step - loss: 0.5336 - accuracy: 0.7912 - val_loss: 0.4886 - val_accuracy: 0.8109\n",
      "Epoch 226/500\n",
      "3812/3812 [==============================] - 2s 570us/step - loss: 0.5356 - accuracy: 0.7891 - val_loss: 0.4918 - val_accuracy: 0.8082\n",
      "Epoch 227/500\n",
      "3812/3812 [==============================] - 2s 578us/step - loss: 0.5349 - accuracy: 0.7883 - val_loss: 0.4850 - val_accuracy: 0.8123\n",
      "Epoch 228/500\n",
      "3812/3812 [==============================] - 2s 573us/step - loss: 0.5339 - accuracy: 0.7899 - val_loss: 0.4839 - val_accuracy: 0.8133\n",
      "Epoch 229/500\n",
      "3812/3812 [==============================] - 2s 574us/step - loss: 0.5354 - accuracy: 0.7882 - val_loss: 0.4870 - val_accuracy: 0.8083\n",
      "Epoch 230/500\n",
      "3812/3812 [==============================] - 2s 573us/step - loss: 0.5362 - accuracy: 0.7897 - val_loss: 0.4928 - val_accuracy: 0.8099\n",
      "Epoch 231/500\n",
      "3812/3812 [==============================] - 2s 573us/step - loss: 0.5325 - accuracy: 0.7906 - val_loss: 0.4864 - val_accuracy: 0.8118\n",
      "Epoch 232/500\n",
      "3812/3812 [==============================] - 2s 583us/step - loss: 0.5357 - accuracy: 0.7887 - val_loss: 0.4872 - val_accuracy: 0.8107\n",
      "Epoch 233/500\n",
      "3812/3812 [==============================] - 2s 574us/step - loss: 0.5354 - accuracy: 0.7888 - val_loss: 0.4877 - val_accuracy: 0.8126\n",
      "Epoch 234/500\n",
      "3812/3812 [==============================] - 2s 573us/step - loss: 0.5328 - accuracy: 0.7910 - val_loss: 0.4960 - val_accuracy: 0.8119\n",
      "Epoch 235/500\n",
      "3812/3812 [==============================] - 2s 574us/step - loss: 0.5349 - accuracy: 0.7895 - val_loss: 0.4942 - val_accuracy: 0.8102\n",
      "Epoch 236/500\n",
      "3812/3812 [==============================] - 2s 573us/step - loss: 0.5340 - accuracy: 0.7906 - val_loss: 0.4938 - val_accuracy: 0.8121\n",
      "Epoch 237/500\n",
      "3812/3812 [==============================] - 2s 573us/step - loss: 0.5345 - accuracy: 0.7897 - val_loss: 0.4855 - val_accuracy: 0.8124\n",
      "Epoch 238/500\n",
      "3812/3812 [==============================] - 2s 573us/step - loss: 0.5359 - accuracy: 0.7888 - val_loss: 0.4837 - val_accuracy: 0.8116\n",
      "Epoch 239/500\n",
      "3812/3812 [==============================] - 2s 574us/step - loss: 0.5360 - accuracy: 0.7899 - val_loss: 0.4904 - val_accuracy: 0.8123\n",
      "Epoch 240/500\n",
      "3812/3812 [==============================] - 2s 581us/step - loss: 0.5340 - accuracy: 0.7912 - val_loss: 0.4950 - val_accuracy: 0.8109\n",
      "Epoch 241/500\n",
      "3812/3812 [==============================] - 2s 574us/step - loss: 0.5346 - accuracy: 0.7904 - val_loss: 0.4902 - val_accuracy: 0.8133\n",
      "Epoch 242/500\n",
      "3812/3812 [==============================] - 2s 573us/step - loss: 0.5341 - accuracy: 0.7895 - val_loss: 0.4901 - val_accuracy: 0.8097\n",
      "Epoch 243/500\n",
      "3812/3812 [==============================] - 2s 572us/step - loss: 0.5323 - accuracy: 0.7901 - val_loss: 0.4877 - val_accuracy: 0.8091\n",
      "Epoch 244/500\n",
      "3812/3812 [==============================] - 2s 575us/step - loss: 0.5343 - accuracy: 0.7896 - val_loss: 0.4832 - val_accuracy: 0.8109\n",
      "Epoch 245/500\n",
      "3812/3812 [==============================] - 2s 582us/step - loss: 0.5347 - accuracy: 0.7896 - val_loss: 0.4915 - val_accuracy: 0.8149\n",
      "Epoch 246/500\n",
      "3812/3812 [==============================] - 2s 574us/step - loss: 0.5316 - accuracy: 0.7908 - val_loss: 0.4996 - val_accuracy: 0.8103\n",
      "Epoch 247/500\n",
      "3812/3812 [==============================] - 2s 573us/step - loss: 0.5335 - accuracy: 0.7890 - val_loss: 0.4875 - val_accuracy: 0.8121\n",
      "Epoch 248/500\n",
      "3812/3812 [==============================] - 2s 572us/step - loss: 0.5337 - accuracy: 0.7895 - val_loss: 0.4887 - val_accuracy: 0.8118\n",
      "Epoch 249/500\n",
      "3812/3812 [==============================] - 2s 571us/step - loss: 0.5343 - accuracy: 0.7898 - val_loss: 0.4842 - val_accuracy: 0.8121\n",
      "Epoch 250/500\n",
      "3812/3812 [==============================] - 2s 574us/step - loss: 0.5347 - accuracy: 0.7901 - val_loss: 0.4891 - val_accuracy: 0.8135\n",
      "Epoch 251/500\n",
      "3812/3812 [==============================] - 2s 581us/step - loss: 0.5356 - accuracy: 0.7890 - val_loss: 0.4936 - val_accuracy: 0.8100\n",
      "Epoch 252/500\n",
      "3812/3812 [==============================] - 2s 573us/step - loss: 0.5353 - accuracy: 0.7892 - val_loss: 0.4908 - val_accuracy: 0.8109\n",
      "Epoch 253/500\n",
      "3812/3812 [==============================] - 2s 576us/step - loss: 0.5345 - accuracy: 0.7906 - val_loss: 0.4903 - val_accuracy: 0.8083\n",
      "Epoch 254/500\n",
      "3812/3812 [==============================] - 2s 573us/step - loss: 0.5345 - accuracy: 0.7901 - val_loss: 0.4895 - val_accuracy: 0.8118\n",
      "Epoch 255/500\n",
      "3812/3812 [==============================] - 2s 572us/step - loss: 0.5342 - accuracy: 0.7899 - val_loss: 0.4945 - val_accuracy: 0.8102\n",
      "Epoch 256/500\n",
      "3812/3812 [==============================] - 2s 572us/step - loss: 0.5323 - accuracy: 0.7895 - val_loss: 0.4861 - val_accuracy: 0.8127\n",
      "Epoch 257/500\n",
      "3812/3812 [==============================] - 2s 581us/step - loss: 0.5328 - accuracy: 0.7901 - val_loss: 0.4860 - val_accuracy: 0.8118\n",
      "Epoch 258/500\n",
      "3812/3812 [==============================] - 2s 573us/step - loss: 0.5332 - accuracy: 0.7913 - val_loss: 0.4831 - val_accuracy: 0.8160\n",
      "Epoch 259/500\n",
      "3812/3812 [==============================] - 2s 573us/step - loss: 0.5315 - accuracy: 0.7914 - val_loss: 0.4834 - val_accuracy: 0.8130\n",
      "Epoch 260/500\n",
      "3812/3812 [==============================] - 2s 572us/step - loss: 0.5334 - accuracy: 0.7899 - val_loss: 0.4817 - val_accuracy: 0.8129\n",
      "Epoch 261/500\n",
      "3812/3812 [==============================] - 2s 584us/step - loss: 0.5342 - accuracy: 0.7898 - val_loss: 0.4851 - val_accuracy: 0.8145\n",
      "Epoch 262/500\n",
      "3812/3812 [==============================] - 2s 573us/step - loss: 0.5320 - accuracy: 0.7910 - val_loss: 0.4854 - val_accuracy: 0.8108\n",
      "Epoch 263/500\n",
      "3812/3812 [==============================] - 2s 574us/step - loss: 0.5329 - accuracy: 0.7905 - val_loss: 0.4888 - val_accuracy: 0.8090\n",
      "Epoch 264/500\n",
      "3812/3812 [==============================] - 2s 573us/step - loss: 0.5314 - accuracy: 0.7911 - val_loss: 0.4843 - val_accuracy: 0.8119\n",
      "Epoch 265/500\n",
      "3812/3812 [==============================] - 2s 572us/step - loss: 0.5320 - accuracy: 0.7898 - val_loss: 0.4872 - val_accuracy: 0.8099\n",
      "Epoch 266/500\n",
      "3812/3812 [==============================] - 2s 582us/step - loss: 0.5327 - accuracy: 0.7898 - val_loss: 0.4832 - val_accuracy: 0.8117\n",
      "Epoch 267/500\n",
      "3812/3812 [==============================] - 2s 572us/step - loss: 0.5333 - accuracy: 0.7908 - val_loss: 0.4845 - val_accuracy: 0.8112\n",
      "Epoch 268/500\n",
      "3812/3812 [==============================] - 2s 574us/step - loss: 0.5332 - accuracy: 0.7910 - val_loss: 0.4898 - val_accuracy: 0.8107\n",
      "Epoch 269/500\n",
      "3812/3812 [==============================] - 2s 572us/step - loss: 0.5322 - accuracy: 0.7910 - val_loss: 0.4854 - val_accuracy: 0.8093\n",
      "Epoch 270/500\n",
      "3812/3812 [==============================] - 2s 581us/step - loss: 0.5318 - accuracy: 0.7895 - val_loss: 0.4898 - val_accuracy: 0.8093\n",
      "Epoch 271/500\n",
      "3812/3812 [==============================] - 2s 572us/step - loss: 0.5317 - accuracy: 0.7907 - val_loss: 0.4881 - val_accuracy: 0.8107\n",
      "Epoch 272/500\n",
      "3812/3812 [==============================] - 2s 572us/step - loss: 0.5316 - accuracy: 0.7900 - val_loss: 0.4804 - val_accuracy: 0.8129\n",
      "Epoch 273/500\n",
      "3812/3812 [==============================] - 2s 572us/step - loss: 0.5304 - accuracy: 0.7913 - val_loss: 0.4849 - val_accuracy: 0.8137\n",
      "Epoch 274/500\n",
      "3812/3812 [==============================] - 2s 580us/step - loss: 0.5293 - accuracy: 0.7921 - val_loss: 0.4909 - val_accuracy: 0.8118\n",
      "Epoch 275/500\n",
      "3812/3812 [==============================] - 2s 573us/step - loss: 0.5333 - accuracy: 0.7911 - val_loss: 0.4912 - val_accuracy: 0.8087\n",
      "Epoch 276/500\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "3812/3812 [==============================] - 2s 575us/step - loss: 0.5319 - accuracy: 0.7916 - val_loss: 0.4930 - val_accuracy: 0.8120\n",
      "Epoch 277/500\n",
      "3812/3812 [==============================] - 2s 574us/step - loss: 0.5304 - accuracy: 0.7915 - val_loss: 0.4844 - val_accuracy: 0.8124\n",
      "Epoch 278/500\n",
      "3812/3812 [==============================] - 2s 571us/step - loss: 0.5318 - accuracy: 0.7912 - val_loss: 0.4832 - val_accuracy: 0.8135\n",
      "Epoch 279/500\n",
      "3812/3812 [==============================] - 2s 574us/step - loss: 0.5333 - accuracy: 0.7902 - val_loss: 0.4863 - val_accuracy: 0.8139\n",
      "Epoch 280/500\n",
      "3812/3812 [==============================] - 2s 573us/step - loss: 0.5296 - accuracy: 0.7924 - val_loss: 0.4877 - val_accuracy: 0.8142\n",
      "Epoch 281/500\n",
      "3812/3812 [==============================] - 2s 574us/step - loss: 0.5323 - accuracy: 0.7920 - val_loss: 0.4857 - val_accuracy: 0.8130\n",
      "Epoch 282/500\n",
      "3812/3812 [==============================] - 2s 582us/step - loss: 0.5301 - accuracy: 0.7922 - val_loss: 0.4822 - val_accuracy: 0.8127\n",
      "Epoch 283/500\n",
      "3812/3812 [==============================] - 2s 574us/step - loss: 0.5305 - accuracy: 0.7921 - val_loss: 0.4891 - val_accuracy: 0.8125\n",
      "Epoch 284/500\n",
      "3812/3812 [==============================] - 2s 574us/step - loss: 0.5315 - accuracy: 0.7908 - val_loss: 0.4907 - val_accuracy: 0.8121\n",
      "Epoch 285/500\n",
      "3812/3812 [==============================] - 2s 574us/step - loss: 0.5326 - accuracy: 0.7910 - val_loss: 0.4850 - val_accuracy: 0.8133\n",
      "Epoch 286/500\n",
      "3812/3812 [==============================] - 2s 574us/step - loss: 0.5312 - accuracy: 0.7904 - val_loss: 0.4896 - val_accuracy: 0.8118\n",
      "Epoch 287/500\n",
      "3812/3812 [==============================] - 2s 573us/step - loss: 0.5297 - accuracy: 0.7907 - val_loss: 0.4839 - val_accuracy: 0.8118\n",
      "Epoch 288/500\n",
      "3812/3812 [==============================] - 2s 573us/step - loss: 0.5310 - accuracy: 0.7920 - val_loss: 0.4867 - val_accuracy: 0.8118\n",
      "Epoch 289/500\n",
      "3812/3812 [==============================] - 2s 574us/step - loss: 0.5281 - accuracy: 0.7930 - val_loss: 0.4901 - val_accuracy: 0.8093\n",
      "Epoch 290/500\n",
      "3812/3812 [==============================] - 2s 574us/step - loss: 0.5321 - accuracy: 0.7916 - val_loss: 0.4853 - val_accuracy: 0.8118\n",
      "Epoch 291/500\n",
      "3812/3812 [==============================] - 2s 580us/step - loss: 0.5319 - accuracy: 0.7916 - val_loss: 0.4952 - val_accuracy: 0.8077\n",
      "Epoch 292/500\n",
      "3812/3812 [==============================] - 2s 572us/step - loss: 0.5312 - accuracy: 0.7909 - val_loss: 0.4956 - val_accuracy: 0.8085\n",
      "Epoch 293/500\n",
      "3812/3812 [==============================] - 2s 573us/step - loss: 0.5281 - accuracy: 0.7927 - val_loss: 0.4812 - val_accuracy: 0.8136\n",
      "Epoch 294/500\n",
      "3812/3812 [==============================] - 2s 574us/step - loss: 0.5310 - accuracy: 0.7914 - val_loss: 0.4780 - val_accuracy: 0.8149\n",
      "Epoch 295/500\n",
      "3812/3812 [==============================] - 2s 571us/step - loss: 0.5297 - accuracy: 0.7922 - val_loss: 0.4812 - val_accuracy: 0.8136\n",
      "Epoch 296/500\n",
      "3812/3812 [==============================] - 2s 572us/step - loss: 0.5301 - accuracy: 0.7932 - val_loss: 0.4778 - val_accuracy: 0.8142\n",
      "Epoch 297/500\n",
      "3812/3812 [==============================] - 2s 572us/step - loss: 0.5293 - accuracy: 0.7926 - val_loss: 0.4854 - val_accuracy: 0.8126\n",
      "Epoch 298/500\n",
      "3812/3812 [==============================] - 2s 583us/step - loss: 0.5299 - accuracy: 0.7915 - val_loss: 0.4805 - val_accuracy: 0.8130\n",
      "Epoch 299/500\n",
      "3812/3812 [==============================] - 2s 582us/step - loss: 0.5322 - accuracy: 0.7912 - val_loss: 0.4922 - val_accuracy: 0.8118\n",
      "Epoch 300/500\n",
      "3812/3812 [==============================] - 2s 572us/step - loss: 0.5292 - accuracy: 0.7933 - val_loss: 0.4855 - val_accuracy: 0.8116\n",
      "Epoch 301/500\n",
      "3812/3812 [==============================] - 2s 575us/step - loss: 0.5295 - accuracy: 0.7916 - val_loss: 0.4888 - val_accuracy: 0.8134\n",
      "Epoch 302/500\n",
      "3812/3812 [==============================] - 2s 572us/step - loss: 0.5324 - accuracy: 0.7905 - val_loss: 0.4835 - val_accuracy: 0.8104\n",
      "Epoch 303/500\n",
      "3812/3812 [==============================] - 2s 582us/step - loss: 0.5305 - accuracy: 0.7917 - val_loss: 0.4810 - val_accuracy: 0.8149\n",
      "Epoch 304/500\n",
      "3812/3812 [==============================] - 2s 573us/step - loss: 0.5315 - accuracy: 0.7915 - val_loss: 0.4827 - val_accuracy: 0.8138\n",
      "Epoch 305/500\n",
      "3812/3812 [==============================] - 2s 574us/step - loss: 0.5322 - accuracy: 0.7910 - val_loss: 0.4887 - val_accuracy: 0.8106\n",
      "Epoch 306/500\n",
      "3812/3812 [==============================] - 2s 573us/step - loss: 0.5286 - accuracy: 0.7927 - val_loss: 0.4812 - val_accuracy: 0.8172\n",
      "Epoch 307/500\n",
      "3812/3812 [==============================] - 2s 581us/step - loss: 0.5309 - accuracy: 0.7911 - val_loss: 0.4843 - val_accuracy: 0.8121\n",
      "Epoch 308/500\n",
      "3812/3812 [==============================] - 2s 572us/step - loss: 0.5300 - accuracy: 0.7929 - val_loss: 0.4755 - val_accuracy: 0.8144\n",
      "Epoch 309/500\n",
      "3812/3812 [==============================] - 2s 580us/step - loss: 0.5305 - accuracy: 0.7916 - val_loss: 0.4807 - val_accuracy: 0.8142\n",
      "Epoch 310/500\n",
      "3812/3812 [==============================] - 2s 571us/step - loss: 0.5299 - accuracy: 0.7914 - val_loss: 0.4783 - val_accuracy: 0.8177\n",
      "Epoch 311/500\n",
      "3812/3812 [==============================] - 2s 571us/step - loss: 0.5319 - accuracy: 0.7917 - val_loss: 0.4830 - val_accuracy: 0.8145\n",
      "Epoch 312/500\n",
      "3812/3812 [==============================] - 2s 573us/step - loss: 0.5296 - accuracy: 0.7919 - val_loss: 0.4852 - val_accuracy: 0.8124\n",
      "Epoch 313/500\n",
      "3812/3812 [==============================] - 2s 571us/step - loss: 0.5295 - accuracy: 0.7933 - val_loss: 0.4827 - val_accuracy: 0.8124\n",
      "Epoch 314/500\n",
      "3812/3812 [==============================] - 2s 580us/step - loss: 0.5309 - accuracy: 0.7918 - val_loss: 0.4852 - val_accuracy: 0.8143\n",
      "Epoch 315/500\n",
      "3812/3812 [==============================] - 2s 573us/step - loss: 0.5298 - accuracy: 0.7923 - val_loss: 0.4802 - val_accuracy: 0.8117\n",
      "Epoch 316/500\n",
      "3812/3812 [==============================] - 2s 573us/step - loss: 0.5301 - accuracy: 0.7929 - val_loss: 0.4812 - val_accuracy: 0.8156\n",
      "Epoch 317/500\n",
      "3812/3812 [==============================] - 2s 571us/step - loss: 0.5299 - accuracy: 0.7924 - val_loss: 0.4839 - val_accuracy: 0.8145\n",
      "Epoch 318/500\n",
      "3812/3812 [==============================] - 2s 581us/step - loss: 0.5295 - accuracy: 0.7923 - val_loss: 0.4827 - val_accuracy: 0.8139\n",
      "Epoch 319/500\n",
      "3812/3812 [==============================] - 2s 572us/step - loss: 0.5306 - accuracy: 0.7934 - val_loss: 0.4829 - val_accuracy: 0.8149\n",
      "Epoch 320/500\n",
      "3812/3812 [==============================] - 2s 574us/step - loss: 0.5308 - accuracy: 0.7912 - val_loss: 0.4873 - val_accuracy: 0.8121\n",
      "Epoch 321/500\n",
      "3812/3812 [==============================] - 2s 572us/step - loss: 0.5298 - accuracy: 0.7923 - val_loss: 0.4817 - val_accuracy: 0.8165\n",
      "Epoch 322/500\n",
      "3812/3812 [==============================] - 2s 572us/step - loss: 0.5298 - accuracy: 0.7929 - val_loss: 0.4859 - val_accuracy: 0.8141\n",
      "Epoch 323/500\n",
      "3812/3812 [==============================] - 2s 580us/step - loss: 0.5273 - accuracy: 0.7942 - val_loss: 0.4860 - val_accuracy: 0.8140\n",
      "Epoch 324/500\n",
      "3812/3812 [==============================] - 2s 571us/step - loss: 0.5288 - accuracy: 0.7911 - val_loss: 0.4807 - val_accuracy: 0.8169\n",
      "Epoch 325/500\n",
      "3812/3812 [==============================] - 2s 572us/step - loss: 0.5291 - accuracy: 0.7931 - val_loss: 0.4811 - val_accuracy: 0.8171\n",
      "Epoch 326/500\n",
      "3812/3812 [==============================] - 2s 571us/step - loss: 0.5270 - accuracy: 0.7942 - val_loss: 0.4731 - val_accuracy: 0.8173\n",
      "Epoch 327/500\n",
      "3812/3812 [==============================] - 2s 582us/step - loss: 0.5281 - accuracy: 0.7943 - val_loss: 0.4815 - val_accuracy: 0.8176\n",
      "Epoch 328/500\n",
      "3812/3812 [==============================] - 2s 571us/step - loss: 0.5295 - accuracy: 0.7923 - val_loss: 0.4789 - val_accuracy: 0.8172\n",
      "Epoch 329/500\n",
      "3812/3812 [==============================] - 2s 572us/step - loss: 0.5286 - accuracy: 0.7916 - val_loss: 0.4845 - val_accuracy: 0.8120\n",
      "Epoch 330/500\n",
      "3812/3812 [==============================] - 2s 579us/step - loss: 0.5292 - accuracy: 0.7915 - val_loss: 0.4875 - val_accuracy: 0.8122\n",
      "Epoch 331/500\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "3812/3812 [==============================] - 2s 574us/step - loss: 0.5297 - accuracy: 0.7923 - val_loss: 0.4893 - val_accuracy: 0.8176\n",
      "Epoch 332/500\n",
      "3812/3812 [==============================] - 2s 573us/step - loss: 0.5279 - accuracy: 0.7930 - val_loss: 0.4804 - val_accuracy: 0.8144\n",
      "Epoch 333/500\n",
      "3812/3812 [==============================] - 2s 573us/step - loss: 0.5295 - accuracy: 0.7916 - val_loss: 0.4794 - val_accuracy: 0.8175\n",
      "Epoch 334/500\n",
      "3812/3812 [==============================] - 2s 575us/step - loss: 0.5297 - accuracy: 0.7922 - val_loss: 0.4778 - val_accuracy: 0.8178\n",
      "Epoch 335/500\n",
      "3812/3812 [==============================] - 2s 574us/step - loss: 0.5297 - accuracy: 0.7915 - val_loss: 0.4833 - val_accuracy: 0.8172\n",
      "Epoch 336/500\n",
      "3812/3812 [==============================] - 2s 574us/step - loss: 0.5277 - accuracy: 0.7939 - val_loss: 0.4882 - val_accuracy: 0.8120\n",
      "Epoch 337/500\n",
      "3812/3812 [==============================] - 2s 573us/step - loss: 0.5289 - accuracy: 0.7931 - val_loss: 0.4784 - val_accuracy: 0.8141\n",
      "Epoch 338/500\n",
      "3812/3812 [==============================] - 2s 572us/step - loss: 0.5290 - accuracy: 0.7917 - val_loss: 0.4906 - val_accuracy: 0.8174\n",
      "Epoch 339/500\n",
      "3812/3812 [==============================] - 2s 573us/step - loss: 0.5284 - accuracy: 0.7936 - val_loss: 0.4835 - val_accuracy: 0.8166\n",
      "Epoch 340/500\n",
      "3812/3812 [==============================] - 2s 572us/step - loss: 0.5282 - accuracy: 0.7928 - val_loss: 0.4805 - val_accuracy: 0.8123\n",
      "Epoch 341/500\n",
      "3812/3812 [==============================] - 2s 572us/step - loss: 0.5279 - accuracy: 0.7931 - val_loss: 0.4831 - val_accuracy: 0.8154\n",
      "Epoch 342/500\n",
      "3812/3812 [==============================] - 2s 585us/step - loss: 0.5283 - accuracy: 0.7929 - val_loss: 0.4780 - val_accuracy: 0.8126\n",
      "Epoch 343/500\n",
      "3812/3812 [==============================] - 2s 573us/step - loss: 0.5266 - accuracy: 0.7946 - val_loss: 0.4802 - val_accuracy: 0.8162\n",
      "Epoch 344/500\n",
      "3812/3812 [==============================] - 2s 573us/step - loss: 0.5283 - accuracy: 0.7926 - val_loss: 0.4807 - val_accuracy: 0.8137\n",
      "Epoch 345/500\n",
      "3812/3812 [==============================] - 2s 573us/step - loss: 0.5274 - accuracy: 0.7921 - val_loss: 0.4844 - val_accuracy: 0.8124\n",
      "Epoch 346/500\n",
      "3812/3812 [==============================] - 2s 573us/step - loss: 0.5274 - accuracy: 0.7925 - val_loss: 0.4806 - val_accuracy: 0.8157\n",
      "Epoch 347/500\n",
      "3812/3812 [==============================] - 2s 573us/step - loss: 0.5246 - accuracy: 0.7936 - val_loss: 0.4793 - val_accuracy: 0.8132\n",
      "Epoch 348/500\n",
      "3812/3812 [==============================] - 2s 572us/step - loss: 0.5285 - accuracy: 0.7929 - val_loss: 0.4828 - val_accuracy: 0.8153\n",
      "Epoch 349/500\n",
      "3812/3812 [==============================] - 2s 582us/step - loss: 0.5292 - accuracy: 0.7945 - val_loss: 0.4803 - val_accuracy: 0.8217\n",
      "Epoch 350/500\n",
      "3812/3812 [==============================] - 2s 573us/step - loss: 0.5307 - accuracy: 0.7928 - val_loss: 0.4782 - val_accuracy: 0.8148\n",
      "Epoch 351/500\n",
      "3812/3812 [==============================] - 2s 571us/step - loss: 0.5274 - accuracy: 0.7958 - val_loss: 0.4830 - val_accuracy: 0.8150\n",
      "Epoch 352/500\n",
      "3812/3812 [==============================] - 2s 573us/step - loss: 0.5271 - accuracy: 0.7938 - val_loss: 0.4852 - val_accuracy: 0.8145\n",
      "Epoch 353/500\n",
      "3812/3812 [==============================] - 2s 573us/step - loss: 0.5284 - accuracy: 0.7929 - val_loss: 0.4867 - val_accuracy: 0.8166\n",
      "Epoch 354/500\n",
      "3812/3812 [==============================] - 2s 573us/step - loss: 0.5289 - accuracy: 0.7925 - val_loss: 0.4800 - val_accuracy: 0.8147\n",
      "Epoch 355/500\n",
      "3812/3812 [==============================] - 2s 578us/step - loss: 0.5272 - accuracy: 0.7952 - val_loss: 0.4850 - val_accuracy: 0.8152\n",
      "Epoch 356/500\n",
      "3812/3812 [==============================] - 2s 575us/step - loss: 0.5275 - accuracy: 0.7930 - val_loss: 0.4856 - val_accuracy: 0.8141\n",
      "Epoch 357/500\n",
      "3812/3812 [==============================] - 2s 574us/step - loss: 0.5285 - accuracy: 0.7918 - val_loss: 0.4792 - val_accuracy: 0.8178\n",
      "Epoch 358/500\n",
      "3812/3812 [==============================] - 2s 573us/step - loss: 0.5263 - accuracy: 0.7944 - val_loss: 0.4797 - val_accuracy: 0.8166\n",
      "Epoch 359/500\n",
      "3812/3812 [==============================] - 2s 572us/step - loss: 0.5279 - accuracy: 0.7932 - val_loss: 0.4751 - val_accuracy: 0.8212\n",
      "Epoch 360/500\n",
      "3812/3812 [==============================] - 2s 572us/step - loss: 0.5272 - accuracy: 0.7930 - val_loss: 0.4810 - val_accuracy: 0.8160\n",
      "Epoch 361/500\n",
      "3812/3812 [==============================] - 2s 580us/step - loss: 0.5276 - accuracy: 0.7929 - val_loss: 0.4796 - val_accuracy: 0.8166\n",
      "Epoch 362/500\n",
      "3812/3812 [==============================] - 2s 573us/step - loss: 0.5273 - accuracy: 0.7941 - val_loss: 0.4943 - val_accuracy: 0.8151\n",
      "Epoch 363/500\n",
      "3812/3812 [==============================] - 2s 573us/step - loss: 0.5295 - accuracy: 0.7930 - val_loss: 0.4840 - val_accuracy: 0.8174\n",
      "Epoch 364/500\n",
      "3812/3812 [==============================] - 2s 582us/step - loss: 0.5282 - accuracy: 0.7912 - val_loss: 0.4791 - val_accuracy: 0.8145\n",
      "Epoch 365/500\n",
      "3812/3812 [==============================] - 2s 572us/step - loss: 0.5278 - accuracy: 0.7937 - val_loss: 0.4836 - val_accuracy: 0.8149\n",
      "Epoch 366/500\n",
      "3812/3812 [==============================] - 2s 580us/step - loss: 0.5274 - accuracy: 0.7931 - val_loss: 0.4884 - val_accuracy: 0.8158\n",
      "Epoch 367/500\n",
      "3812/3812 [==============================] - 2s 572us/step - loss: 0.5277 - accuracy: 0.7923 - val_loss: 0.4799 - val_accuracy: 0.8156\n",
      "Epoch 368/500\n",
      "3812/3812 [==============================] - 2s 572us/step - loss: 0.5283 - accuracy: 0.7929 - val_loss: 0.4806 - val_accuracy: 0.8169\n",
      "Epoch 369/500\n",
      "3812/3812 [==============================] - 2s 577us/step - loss: 0.5293 - accuracy: 0.7917 - val_loss: 0.4819 - val_accuracy: 0.8172\n",
      "Epoch 370/500\n",
      "3812/3812 [==============================] - 2s 574us/step - loss: 0.5280 - accuracy: 0.7939 - val_loss: 0.4856 - val_accuracy: 0.8152\n",
      "Epoch 371/500\n",
      "3812/3812 [==============================] - 2s 580us/step - loss: 0.5270 - accuracy: 0.7928 - val_loss: 0.4786 - val_accuracy: 0.8170\n",
      "Epoch 372/500\n",
      "3812/3812 [==============================] - 2s 573us/step - loss: 0.5248 - accuracy: 0.7947 - val_loss: 0.4778 - val_accuracy: 0.8148\n",
      "Epoch 373/500\n",
      "3812/3812 [==============================] - 2s 572us/step - loss: 0.5274 - accuracy: 0.7940 - val_loss: 0.4873 - val_accuracy: 0.8161\n",
      "Epoch 374/500\n",
      "3812/3812 [==============================] - 2s 573us/step - loss: 0.5272 - accuracy: 0.7941 - val_loss: 0.4821 - val_accuracy: 0.8159\n",
      "Epoch 375/500\n",
      "3812/3812 [==============================] - 2s 572us/step - loss: 0.5284 - accuracy: 0.7932 - val_loss: 0.4815 - val_accuracy: 0.8164\n",
      "Epoch 376/500\n",
      "3812/3812 [==============================] - 2s 581us/step - loss: 0.5272 - accuracy: 0.7936 - val_loss: 0.4832 - val_accuracy: 0.8169\n",
      "Epoch 376: early stopping\n"
     ]
    }
   ],
   "source": [
    "# batch size=32\n",
    "model=Sequential()\n",
    "model.add(Dense(128, input_dim=X_train.shape[1], activation=\"relu\"))\n",
    "model.add(Dropout(0.2))\n",
    "model.add(Dense(128, activation=\"relu\"))\n",
    "model.add(Dropout(0.2))\n",
    "model.add(Dense(64, activation=\"relu\"))\n",
    "model.add(Dropout(0.2))\n",
    "model.add(Dense(64, activation=\"relu\"))\n",
    "model.add(Dropout(0.2))\n",
    "model.add(Dense(3, activation=\"softmax\"))\n",
    "model.compile(loss='categorical_crossentropy', optimizer=Adam(learning_rate=0.001), metrics=['accuracy'])\n",
    "\n",
    "es=EarlyStopping(monitor=\"val_loss\",patience=50,mode=\"auto\",verbose=1)\n",
    "\n",
    "ann1 = model.fit(X_train,\n",
    "          y_train,\n",
    "          epochs=500,\n",
    "               batch_size=32,\n",
    "               validation_split=0.1,\n",
    "               verbose=1,callbacks=[es])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 57,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "748/748 [==============================] - 0s 245us/step\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0       0.83      0.91      0.87      7973\n",
      "           1       0.82      0.87      0.84      7973\n",
      "           2       0.79      0.65      0.71      7972\n",
      "\n",
      "    accuracy                           0.81     23918\n",
      "   macro avg       0.81      0.81      0.81     23918\n",
      "weighted avg       0.81      0.81      0.81     23918\n",
      "\n"
     ]
    }
   ],
   "source": [
    "y_pred = model.predict(X_test)\n",
    "y_pred_classes = np.argmax(y_pred, axis=1)\n",
    "y_true = np.argmax(y_test, axis=1)\n",
    "print(classification_report(y_true, y_pred_classes))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 58,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "4236/4236 [==============================] - 1s 246us/step\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0       0.85      0.93      0.89     45176\n",
      "           1       0.83      0.90      0.86     45176\n",
      "           2       0.83      0.68      0.75     45177\n",
      "\n",
      "    accuracy                           0.84    135529\n",
      "   macro avg       0.84      0.84      0.83    135529\n",
      "weighted avg       0.84      0.84      0.83    135529\n",
      "\n"
     ]
    }
   ],
   "source": [
    "y_t_pred = model.predict(X_train)\n",
    "y_t_pred_classes = np.argmax(y_t_pred, axis=1)\n",
    "y_t_true = np.argmax(y_train, axis=1)\n",
    "print(classification_report(y_t_true, y_t_pred_classes))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 62,
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 1/500\n",
      "477/477 [==============================] - 1s 1ms/step - loss: 0.7692 - accuracy: 0.6970 - val_loss: 0.6812 - val_accuracy: 0.7373\n",
      "Epoch 2/500\n",
      "477/477 [==============================] - 1s 2ms/step - loss: 0.7060 - accuracy: 0.7315 - val_loss: 0.6582 - val_accuracy: 0.7443\n",
      "Epoch 3/500\n",
      "477/477 [==============================] - 1s 1ms/step - loss: 0.6886 - accuracy: 0.7353 - val_loss: 0.6579 - val_accuracy: 0.7433\n",
      "Epoch 4/500\n",
      "477/477 [==============================] - 1s 1ms/step - loss: 0.6809 - accuracy: 0.7377 - val_loss: 0.6489 - val_accuracy: 0.7480\n",
      "Epoch 5/500\n",
      "477/477 [==============================] - 1s 1ms/step - loss: 0.6712 - accuracy: 0.7413 - val_loss: 0.6419 - val_accuracy: 0.7506\n",
      "Epoch 6/500\n",
      "477/477 [==============================] - 1s 1ms/step - loss: 0.6654 - accuracy: 0.7426 - val_loss: 0.6352 - val_accuracy: 0.7515\n",
      "Epoch 7/500\n",
      "477/477 [==============================] - 1s 1ms/step - loss: 0.6582 - accuracy: 0.7438 - val_loss: 0.6287 - val_accuracy: 0.7527\n",
      "Epoch 8/500\n",
      "477/477 [==============================] - 1s 1ms/step - loss: 0.6525 - accuracy: 0.7447 - val_loss: 0.6223 - val_accuracy: 0.7560\n",
      "Epoch 9/500\n",
      "477/477 [==============================] - 1s 1ms/step - loss: 0.6482 - accuracy: 0.7477 - val_loss: 0.6124 - val_accuracy: 0.7585\n",
      "Epoch 10/500\n",
      "477/477 [==============================] - 1s 1ms/step - loss: 0.6420 - accuracy: 0.7493 - val_loss: 0.6091 - val_accuracy: 0.7596\n",
      "Epoch 11/500\n",
      "477/477 [==============================] - 1s 1ms/step - loss: 0.6365 - accuracy: 0.7518 - val_loss: 0.6025 - val_accuracy: 0.7626\n",
      "Epoch 12/500\n",
      "477/477 [==============================] - 1s 1ms/step - loss: 0.6327 - accuracy: 0.7531 - val_loss: 0.5972 - val_accuracy: 0.7631\n",
      "Epoch 13/500\n",
      "477/477 [==============================] - 1s 1ms/step - loss: 0.6285 - accuracy: 0.7541 - val_loss: 0.5981 - val_accuracy: 0.7639\n",
      "Epoch 14/500\n",
      "477/477 [==============================] - 1s 1ms/step - loss: 0.6236 - accuracy: 0.7554 - val_loss: 0.5882 - val_accuracy: 0.7703\n",
      "Epoch 15/500\n",
      "477/477 [==============================] - 1s 1ms/step - loss: 0.6180 - accuracy: 0.7586 - val_loss: 0.5803 - val_accuracy: 0.7716\n",
      "Epoch 16/500\n",
      "477/477 [==============================] - 1s 1ms/step - loss: 0.6138 - accuracy: 0.7592 - val_loss: 0.5753 - val_accuracy: 0.7744\n",
      "Epoch 17/500\n",
      "477/477 [==============================] - 1s 1ms/step - loss: 0.6088 - accuracy: 0.7608 - val_loss: 0.5707 - val_accuracy: 0.7739\n",
      "Epoch 18/500\n",
      "477/477 [==============================] - 1s 1ms/step - loss: 0.6045 - accuracy: 0.7630 - val_loss: 0.5678 - val_accuracy: 0.7769\n",
      "Epoch 19/500\n",
      "477/477 [==============================] - 1s 1ms/step - loss: 0.6021 - accuracy: 0.7626 - val_loss: 0.5648 - val_accuracy: 0.7741\n",
      "Epoch 20/500\n",
      "477/477 [==============================] - 1s 1ms/step - loss: 0.5988 - accuracy: 0.7642 - val_loss: 0.5612 - val_accuracy: 0.7760\n",
      "Epoch 21/500\n",
      "477/477 [==============================] - 1s 1ms/step - loss: 0.5958 - accuracy: 0.7646 - val_loss: 0.5597 - val_accuracy: 0.7778\n",
      "Epoch 22/500\n",
      "477/477 [==============================] - 1s 1ms/step - loss: 0.5928 - accuracy: 0.7672 - val_loss: 0.5552 - val_accuracy: 0.7798\n",
      "Epoch 23/500\n",
      "477/477 [==============================] - 1s 1ms/step - loss: 0.5881 - accuracy: 0.7679 - val_loss: 0.5489 - val_accuracy: 0.7815\n",
      "Epoch 24/500\n",
      "477/477 [==============================] - 1s 1ms/step - loss: 0.5862 - accuracy: 0.7683 - val_loss: 0.5499 - val_accuracy: 0.7837\n",
      "Epoch 25/500\n",
      "477/477 [==============================] - 1s 1ms/step - loss: 0.5826 - accuracy: 0.7692 - val_loss: 0.5412 - val_accuracy: 0.7855\n",
      "Epoch 26/500\n",
      "477/477 [==============================] - 1s 1ms/step - loss: 0.5793 - accuracy: 0.7723 - val_loss: 0.5429 - val_accuracy: 0.7851\n",
      "Epoch 27/500\n",
      "477/477 [==============================] - 1s 1ms/step - loss: 0.5798 - accuracy: 0.7701 - val_loss: 0.5403 - val_accuracy: 0.7857\n",
      "Epoch 28/500\n",
      "477/477 [==============================] - 1s 1ms/step - loss: 0.5748 - accuracy: 0.7728 - val_loss: 0.5321 - val_accuracy: 0.7889\n",
      "Epoch 29/500\n",
      "477/477 [==============================] - 1s 1ms/step - loss: 0.5722 - accuracy: 0.7735 - val_loss: 0.5317 - val_accuracy: 0.7923\n",
      "Epoch 30/500\n",
      "477/477 [==============================] - 1s 1ms/step - loss: 0.5712 - accuracy: 0.7738 - val_loss: 0.5276 - val_accuracy: 0.7882\n",
      "Epoch 31/500\n",
      "477/477 [==============================] - 1s 1ms/step - loss: 0.5667 - accuracy: 0.7749 - val_loss: 0.5288 - val_accuracy: 0.7906\n",
      "Epoch 32/500\n",
      "477/477 [==============================] - 1s 1ms/step - loss: 0.5668 - accuracy: 0.7745 - val_loss: 0.5251 - val_accuracy: 0.7907\n",
      "Epoch 33/500\n",
      "477/477 [==============================] - 1s 1ms/step - loss: 0.5623 - accuracy: 0.7773 - val_loss: 0.5237 - val_accuracy: 0.7936\n",
      "Epoch 34/500\n",
      "477/477 [==============================] - 1s 1ms/step - loss: 0.5622 - accuracy: 0.7772 - val_loss: 0.5234 - val_accuracy: 0.7924\n",
      "Epoch 35/500\n",
      "477/477 [==============================] - 1s 1ms/step - loss: 0.5610 - accuracy: 0.7776 - val_loss: 0.5148 - val_accuracy: 0.7981\n",
      "Epoch 36/500\n",
      "477/477 [==============================] - 1s 1ms/step - loss: 0.5574 - accuracy: 0.7803 - val_loss: 0.5175 - val_accuracy: 0.7952\n",
      "Epoch 37/500\n",
      "477/477 [==============================] - 1s 1ms/step - loss: 0.5567 - accuracy: 0.7795 - val_loss: 0.5128 - val_accuracy: 0.7979\n",
      "Epoch 38/500\n",
      "477/477 [==============================] - 1s 1ms/step - loss: 0.5551 - accuracy: 0.7798 - val_loss: 0.5089 - val_accuracy: 0.7983\n",
      "Epoch 39/500\n",
      "477/477 [==============================] - 1s 1ms/step - loss: 0.5522 - accuracy: 0.7821 - val_loss: 0.5122 - val_accuracy: 0.8003\n",
      "Epoch 40/500\n",
      "477/477 [==============================] - 1s 1ms/step - loss: 0.5508 - accuracy: 0.7819 - val_loss: 0.5046 - val_accuracy: 0.8011\n",
      "Epoch 41/500\n",
      "477/477 [==============================] - 1s 1ms/step - loss: 0.5484 - accuracy: 0.7831 - val_loss: 0.5068 - val_accuracy: 0.8003\n",
      "Epoch 42/500\n",
      "477/477 [==============================] - 1s 1ms/step - loss: 0.5498 - accuracy: 0.7828 - val_loss: 0.5076 - val_accuracy: 0.7994\n",
      "Epoch 43/500\n",
      "477/477 [==============================] - 1s 1ms/step - loss: 0.5452 - accuracy: 0.7846 - val_loss: 0.5032 - val_accuracy: 0.8012\n",
      "Epoch 44/500\n",
      "477/477 [==============================] - 1s 1ms/step - loss: 0.5445 - accuracy: 0.7846 - val_loss: 0.5000 - val_accuracy: 0.8037\n",
      "Epoch 45/500\n",
      "477/477 [==============================] - 1s 1ms/step - loss: 0.5444 - accuracy: 0.7842 - val_loss: 0.4989 - val_accuracy: 0.8043\n",
      "Epoch 46/500\n",
      "477/477 [==============================] - 1s 1ms/step - loss: 0.5414 - accuracy: 0.7860 - val_loss: 0.4965 - val_accuracy: 0.8073\n",
      "Epoch 47/500\n",
      "477/477 [==============================] - 1s 1ms/step - loss: 0.5410 - accuracy: 0.7865 - val_loss: 0.4981 - val_accuracy: 0.8018\n",
      "Epoch 48/500\n",
      "477/477 [==============================] - 1s 1ms/step - loss: 0.5397 - accuracy: 0.7878 - val_loss: 0.4949 - val_accuracy: 0.8064\n",
      "Epoch 49/500\n",
      "477/477 [==============================] - 1s 1ms/step - loss: 0.5393 - accuracy: 0.7874 - val_loss: 0.4933 - val_accuracy: 0.8051\n",
      "Epoch 50/500\n",
      "477/477 [==============================] - 1s 1ms/step - loss: 0.5364 - accuracy: 0.7888 - val_loss: 0.4975 - val_accuracy: 0.8054\n",
      "Epoch 51/500\n",
      "477/477 [==============================] - 1s 1ms/step - loss: 0.5359 - accuracy: 0.7885 - val_loss: 0.4910 - val_accuracy: 0.8116\n",
      "Epoch 52/500\n",
      "477/477 [==============================] - 1s 1ms/step - loss: 0.5331 - accuracy: 0.7890 - val_loss: 0.4898 - val_accuracy: 0.8104\n",
      "Epoch 53/500\n",
      "477/477 [==============================] - 1s 1ms/step - loss: 0.5332 - accuracy: 0.7893 - val_loss: 0.4915 - val_accuracy: 0.8045\n",
      "Epoch 54/500\n",
      "477/477 [==============================] - 1s 1ms/step - loss: 0.5355 - accuracy: 0.7889 - val_loss: 0.4907 - val_accuracy: 0.8087\n",
      "Epoch 55/500\n",
      "477/477 [==============================] - 1s 1ms/step - loss: 0.5316 - accuracy: 0.7900 - val_loss: 0.4892 - val_accuracy: 0.8116\n",
      "Epoch 56/500\n",
      "477/477 [==============================] - 1s 1ms/step - loss: 0.5333 - accuracy: 0.7893 - val_loss: 0.4890 - val_accuracy: 0.8097\n",
      "Epoch 57/500\n",
      "477/477 [==============================] - 1s 1ms/step - loss: 0.5328 - accuracy: 0.7886 - val_loss: 0.4828 - val_accuracy: 0.8121\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 58/500\n",
      "477/477 [==============================] - 1s 1ms/step - loss: 0.5297 - accuracy: 0.7907 - val_loss: 0.4869 - val_accuracy: 0.8129\n",
      "Epoch 59/500\n",
      "477/477 [==============================] - 1s 1ms/step - loss: 0.5285 - accuracy: 0.7910 - val_loss: 0.4823 - val_accuracy: 0.8112\n",
      "Epoch 60/500\n",
      "477/477 [==============================] - 1s 1ms/step - loss: 0.5271 - accuracy: 0.7932 - val_loss: 0.4828 - val_accuracy: 0.8129\n",
      "Epoch 61/500\n",
      "477/477 [==============================] - 1s 1ms/step - loss: 0.5276 - accuracy: 0.7922 - val_loss: 0.4781 - val_accuracy: 0.8116\n",
      "Epoch 62/500\n",
      "477/477 [==============================] - 1s 1ms/step - loss: 0.5260 - accuracy: 0.7919 - val_loss: 0.4812 - val_accuracy: 0.8120\n",
      "Epoch 63/500\n",
      "477/477 [==============================] - 1s 1ms/step - loss: 0.5265 - accuracy: 0.7927 - val_loss: 0.4798 - val_accuracy: 0.8116\n",
      "Epoch 64/500\n",
      "477/477 [==============================] - 1s 1ms/step - loss: 0.5209 - accuracy: 0.7946 - val_loss: 0.4771 - val_accuracy: 0.8117\n",
      "Epoch 65/500\n",
      "477/477 [==============================] - 1s 1ms/step - loss: 0.5249 - accuracy: 0.7929 - val_loss: 0.4803 - val_accuracy: 0.8118\n",
      "Epoch 66/500\n",
      "477/477 [==============================] - 1s 1ms/step - loss: 0.5239 - accuracy: 0.7922 - val_loss: 0.4786 - val_accuracy: 0.8108\n",
      "Epoch 67/500\n",
      "477/477 [==============================] - 1s 1ms/step - loss: 0.5224 - accuracy: 0.7936 - val_loss: 0.4788 - val_accuracy: 0.8126\n",
      "Epoch 68/500\n",
      "477/477 [==============================] - 1s 1ms/step - loss: 0.5219 - accuracy: 0.7948 - val_loss: 0.4761 - val_accuracy: 0.8151\n",
      "Epoch 69/500\n",
      "477/477 [==============================] - 1s 1ms/step - loss: 0.5210 - accuracy: 0.7939 - val_loss: 0.4774 - val_accuracy: 0.8150\n",
      "Epoch 70/500\n",
      "477/477 [==============================] - 1s 1ms/step - loss: 0.5202 - accuracy: 0.7952 - val_loss: 0.4762 - val_accuracy: 0.8152\n",
      "Epoch 71/500\n",
      "477/477 [==============================] - 1s 1ms/step - loss: 0.5201 - accuracy: 0.7951 - val_loss: 0.4734 - val_accuracy: 0.8146\n",
      "Epoch 72/500\n",
      "477/477 [==============================] - 1s 1ms/step - loss: 0.5202 - accuracy: 0.7954 - val_loss: 0.4771 - val_accuracy: 0.8135\n",
      "Epoch 73/500\n",
      "477/477 [==============================] - 1s 1ms/step - loss: 0.5160 - accuracy: 0.7970 - val_loss: 0.4714 - val_accuracy: 0.8178\n",
      "Epoch 74/500\n",
      "477/477 [==============================] - 1s 1ms/step - loss: 0.5185 - accuracy: 0.7955 - val_loss: 0.4716 - val_accuracy: 0.8169\n",
      "Epoch 75/500\n",
      "477/477 [==============================] - 1s 1ms/step - loss: 0.5159 - accuracy: 0.7973 - val_loss: 0.4744 - val_accuracy: 0.8159\n",
      "Epoch 76/500\n",
      "477/477 [==============================] - 1s 1ms/step - loss: 0.5154 - accuracy: 0.7972 - val_loss: 0.4749 - val_accuracy: 0.8142\n",
      "Epoch 77/500\n",
      "477/477 [==============================] - 1s 1ms/step - loss: 0.5142 - accuracy: 0.7975 - val_loss: 0.4700 - val_accuracy: 0.8166\n",
      "Epoch 78/500\n",
      "477/477 [==============================] - 1s 1ms/step - loss: 0.5154 - accuracy: 0.7984 - val_loss: 0.4694 - val_accuracy: 0.8166\n",
      "Epoch 79/500\n",
      "477/477 [==============================] - 1s 1ms/step - loss: 0.5139 - accuracy: 0.7981 - val_loss: 0.4634 - val_accuracy: 0.8209\n",
      "Epoch 80/500\n",
      "477/477 [==============================] - 1s 1ms/step - loss: 0.5152 - accuracy: 0.7979 - val_loss: 0.4662 - val_accuracy: 0.8178\n",
      "Epoch 81/500\n",
      "477/477 [==============================] - 1s 1ms/step - loss: 0.5146 - accuracy: 0.7978 - val_loss: 0.4702 - val_accuracy: 0.8172\n",
      "Epoch 82/500\n",
      "477/477 [==============================] - 1s 1ms/step - loss: 0.5132 - accuracy: 0.7964 - val_loss: 0.4680 - val_accuracy: 0.8194\n",
      "Epoch 83/500\n",
      "477/477 [==============================] - 1s 1ms/step - loss: 0.5122 - accuracy: 0.7990 - val_loss: 0.4651 - val_accuracy: 0.8221\n",
      "Epoch 84/500\n",
      "477/477 [==============================] - 1s 1ms/step - loss: 0.5123 - accuracy: 0.7984 - val_loss: 0.4679 - val_accuracy: 0.8193\n",
      "Epoch 85/500\n",
      "477/477 [==============================] - 1s 1ms/step - loss: 0.5119 - accuracy: 0.7985 - val_loss: 0.4671 - val_accuracy: 0.8176\n",
      "Epoch 86/500\n",
      "477/477 [==============================] - 1s 1ms/step - loss: 0.5098 - accuracy: 0.7992 - val_loss: 0.4629 - val_accuracy: 0.8209\n",
      "Epoch 87/500\n",
      "477/477 [==============================] - 1s 1ms/step - loss: 0.5092 - accuracy: 0.7994 - val_loss: 0.4663 - val_accuracy: 0.8200\n",
      "Epoch 88/500\n",
      "477/477 [==============================] - 1s 1ms/step - loss: 0.5085 - accuracy: 0.7996 - val_loss: 0.4629 - val_accuracy: 0.8231\n",
      "Epoch 89/500\n",
      "477/477 [==============================] - 1s 1ms/step - loss: 0.5103 - accuracy: 0.7997 - val_loss: 0.4640 - val_accuracy: 0.8196\n",
      "Epoch 90/500\n",
      "477/477 [==============================] - 1s 1ms/step - loss: 0.5088 - accuracy: 0.7999 - val_loss: 0.4631 - val_accuracy: 0.8213\n",
      "Epoch 91/500\n",
      "477/477 [==============================] - 1s 1ms/step - loss: 0.5068 - accuracy: 0.8015 - val_loss: 0.4588 - val_accuracy: 0.8235\n",
      "Epoch 92/500\n",
      "477/477 [==============================] - 1s 1ms/step - loss: 0.5091 - accuracy: 0.7988 - val_loss: 0.4597 - val_accuracy: 0.8208\n",
      "Epoch 93/500\n",
      "477/477 [==============================] - 1s 1ms/step - loss: 0.5058 - accuracy: 0.8007 - val_loss: 0.4611 - val_accuracy: 0.8208\n",
      "Epoch 94/500\n",
      "477/477 [==============================] - 1s 1ms/step - loss: 0.5093 - accuracy: 0.7994 - val_loss: 0.4594 - val_accuracy: 0.8222\n",
      "Epoch 95/500\n",
      "477/477 [==============================] - 1s 1ms/step - loss: 0.5077 - accuracy: 0.8005 - val_loss: 0.4604 - val_accuracy: 0.8211\n",
      "Epoch 96/500\n",
      "477/477 [==============================] - 1s 1ms/step - loss: 0.5042 - accuracy: 0.8028 - val_loss: 0.4617 - val_accuracy: 0.8214\n",
      "Epoch 97/500\n",
      "477/477 [==============================] - 1s 1ms/step - loss: 0.5058 - accuracy: 0.8013 - val_loss: 0.4590 - val_accuracy: 0.8206\n",
      "Epoch 98/500\n",
      "477/477 [==============================] - 1s 1ms/step - loss: 0.5050 - accuracy: 0.8022 - val_loss: 0.4577 - val_accuracy: 0.8217\n",
      "Epoch 99/500\n",
      "477/477 [==============================] - 1s 1ms/step - loss: 0.5042 - accuracy: 0.8012 - val_loss: 0.4584 - val_accuracy: 0.8246\n",
      "Epoch 100/500\n",
      "477/477 [==============================] - 1s 1ms/step - loss: 0.5010 - accuracy: 0.8026 - val_loss: 0.4558 - val_accuracy: 0.8236\n",
      "Epoch 101/500\n",
      "477/477 [==============================] - 1s 1ms/step - loss: 0.5037 - accuracy: 0.8019 - val_loss: 0.4574 - val_accuracy: 0.8228\n",
      "Epoch 102/500\n",
      "477/477 [==============================] - 1s 1ms/step - loss: 0.5026 - accuracy: 0.8022 - val_loss: 0.4575 - val_accuracy: 0.8231\n",
      "Epoch 103/500\n",
      "477/477 [==============================] - 1s 1ms/step - loss: 0.5031 - accuracy: 0.8024 - val_loss: 0.4584 - val_accuracy: 0.8225\n",
      "Epoch 104/500\n",
      "477/477 [==============================] - 1s 1ms/step - loss: 0.5019 - accuracy: 0.8032 - val_loss: 0.4542 - val_accuracy: 0.8232\n",
      "Epoch 105/500\n",
      "477/477 [==============================] - 1s 1ms/step - loss: 0.5029 - accuracy: 0.8024 - val_loss: 0.4558 - val_accuracy: 0.8234\n",
      "Epoch 106/500\n",
      "477/477 [==============================] - 1s 1ms/step - loss: 0.5023 - accuracy: 0.8035 - val_loss: 0.4561 - val_accuracy: 0.8232\n",
      "Epoch 107/500\n",
      "477/477 [==============================] - 1s 1ms/step - loss: 0.5018 - accuracy: 0.8026 - val_loss: 0.4590 - val_accuracy: 0.8225\n",
      "Epoch 108/500\n",
      "477/477 [==============================] - 1s 1ms/step - loss: 0.5013 - accuracy: 0.8039 - val_loss: 0.4556 - val_accuracy: 0.8233\n",
      "Epoch 109/500\n",
      "477/477 [==============================] - 1s 1ms/step - loss: 0.5012 - accuracy: 0.8037 - val_loss: 0.4528 - val_accuracy: 0.8254\n",
      "Epoch 110/500\n",
      "477/477 [==============================] - 1s 1ms/step - loss: 0.5020 - accuracy: 0.8028 - val_loss: 0.4561 - val_accuracy: 0.8242\n",
      "Epoch 111/500\n",
      "477/477 [==============================] - 1s 1ms/step - loss: 0.5001 - accuracy: 0.8035 - val_loss: 0.4548 - val_accuracy: 0.8231\n",
      "Epoch 112/500\n",
      "477/477 [==============================] - 1s 1ms/step - loss: 0.5022 - accuracy: 0.8034 - val_loss: 0.4526 - val_accuracy: 0.8219\n",
      "Epoch 113/500\n",
      "477/477 [==============================] - 1s 1ms/step - loss: 0.4993 - accuracy: 0.8036 - val_loss: 0.4565 - val_accuracy: 0.8225\n",
      "Epoch 114/500\n",
      "477/477 [==============================] - 1s 1ms/step - loss: 0.4993 - accuracy: 0.8038 - val_loss: 0.4523 - val_accuracy: 0.8239\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 115/500\n",
      "477/477 [==============================] - 1s 1ms/step - loss: 0.4979 - accuracy: 0.8054 - val_loss: 0.4520 - val_accuracy: 0.8254\n",
      "Epoch 116/500\n",
      "477/477 [==============================] - 1s 1ms/step - loss: 0.4988 - accuracy: 0.8057 - val_loss: 0.4537 - val_accuracy: 0.8231\n",
      "Epoch 117/500\n",
      "477/477 [==============================] - 1s 1ms/step - loss: 0.4959 - accuracy: 0.8050 - val_loss: 0.4557 - val_accuracy: 0.8251\n",
      "Epoch 118/500\n",
      "477/477 [==============================] - 1s 1ms/step - loss: 0.4961 - accuracy: 0.8042 - val_loss: 0.4517 - val_accuracy: 0.8237\n",
      "Epoch 119/500\n",
      "477/477 [==============================] - 1s 1ms/step - loss: 0.4970 - accuracy: 0.8041 - val_loss: 0.4519 - val_accuracy: 0.8270\n",
      "Epoch 120/500\n",
      "477/477 [==============================] - 1s 1ms/step - loss: 0.4968 - accuracy: 0.8052 - val_loss: 0.4518 - val_accuracy: 0.8252\n",
      "Epoch 121/500\n",
      "477/477 [==============================] - 1s 1ms/step - loss: 0.4986 - accuracy: 0.8050 - val_loss: 0.4518 - val_accuracy: 0.8253\n",
      "Epoch 122/500\n",
      "477/477 [==============================] - 1s 1ms/step - loss: 0.4966 - accuracy: 0.8050 - val_loss: 0.4523 - val_accuracy: 0.8252\n",
      "Epoch 123/500\n",
      "477/477 [==============================] - 1s 1ms/step - loss: 0.4941 - accuracy: 0.8063 - val_loss: 0.4530 - val_accuracy: 0.8237\n",
      "Epoch 124/500\n",
      "477/477 [==============================] - 1s 1ms/step - loss: 0.4957 - accuracy: 0.8049 - val_loss: 0.4526 - val_accuracy: 0.8246\n",
      "Epoch 125/500\n",
      "477/477 [==============================] - 1s 1ms/step - loss: 0.4959 - accuracy: 0.8060 - val_loss: 0.4483 - val_accuracy: 0.8276\n",
      "Epoch 126/500\n",
      "477/477 [==============================] - 1s 1ms/step - loss: 0.4931 - accuracy: 0.8059 - val_loss: 0.4477 - val_accuracy: 0.8278\n",
      "Epoch 127/500\n",
      "477/477 [==============================] - 1s 1ms/step - loss: 0.4944 - accuracy: 0.8067 - val_loss: 0.4481 - val_accuracy: 0.8273\n",
      "Epoch 128/500\n",
      "477/477 [==============================] - 1s 1ms/step - loss: 0.4946 - accuracy: 0.8065 - val_loss: 0.4473 - val_accuracy: 0.8279\n",
      "Epoch 129/500\n",
      "477/477 [==============================] - 1s 1ms/step - loss: 0.4930 - accuracy: 0.8062 - val_loss: 0.4492 - val_accuracy: 0.8275\n",
      "Epoch 130/500\n",
      "477/477 [==============================] - 1s 1ms/step - loss: 0.4952 - accuracy: 0.8063 - val_loss: 0.4478 - val_accuracy: 0.8269\n",
      "Epoch 131/500\n",
      "477/477 [==============================] - 1s 1ms/step - loss: 0.4940 - accuracy: 0.8061 - val_loss: 0.4494 - val_accuracy: 0.8289\n",
      "Epoch 132/500\n",
      "477/477 [==============================] - 1s 1ms/step - loss: 0.4914 - accuracy: 0.8075 - val_loss: 0.4462 - val_accuracy: 0.8292\n",
      "Epoch 133/500\n",
      "477/477 [==============================] - 1s 1ms/step - loss: 0.4936 - accuracy: 0.8066 - val_loss: 0.4481 - val_accuracy: 0.8276\n",
      "Epoch 134/500\n",
      "477/477 [==============================] - 1s 1ms/step - loss: 0.4919 - accuracy: 0.8079 - val_loss: 0.4518 - val_accuracy: 0.8268\n",
      "Epoch 135/500\n",
      "477/477 [==============================] - 1s 1ms/step - loss: 0.4941 - accuracy: 0.8059 - val_loss: 0.4479 - val_accuracy: 0.8282\n",
      "Epoch 136/500\n",
      "477/477 [==============================] - 1s 1ms/step - loss: 0.4892 - accuracy: 0.8086 - val_loss: 0.4483 - val_accuracy: 0.8262\n",
      "Epoch 137/500\n",
      "477/477 [==============================] - 1s 1ms/step - loss: 0.4923 - accuracy: 0.8076 - val_loss: 0.4441 - val_accuracy: 0.8290\n",
      "Epoch 138/500\n",
      "477/477 [==============================] - 1s 1ms/step - loss: 0.4936 - accuracy: 0.8066 - val_loss: 0.4491 - val_accuracy: 0.8285\n",
      "Epoch 139/500\n",
      "477/477 [==============================] - 1s 1ms/step - loss: 0.4905 - accuracy: 0.8074 - val_loss: 0.4507 - val_accuracy: 0.8282\n",
      "Epoch 140/500\n",
      "477/477 [==============================] - 1s 1ms/step - loss: 0.4915 - accuracy: 0.8085 - val_loss: 0.4455 - val_accuracy: 0.8297\n",
      "Epoch 141/500\n",
      "477/477 [==============================] - 1s 1ms/step - loss: 0.4900 - accuracy: 0.8087 - val_loss: 0.4505 - val_accuracy: 0.8245\n",
      "Epoch 142/500\n",
      "477/477 [==============================] - 1s 1ms/step - loss: 0.4919 - accuracy: 0.8065 - val_loss: 0.4483 - val_accuracy: 0.8239\n",
      "Epoch 143/500\n",
      "477/477 [==============================] - 1s 1ms/step - loss: 0.4902 - accuracy: 0.8084 - val_loss: 0.4462 - val_accuracy: 0.8285\n",
      "Epoch 144/500\n",
      "477/477 [==============================] - 1s 1ms/step - loss: 0.4901 - accuracy: 0.8081 - val_loss: 0.4440 - val_accuracy: 0.8290\n",
      "Epoch 145/500\n",
      "477/477 [==============================] - 1s 1ms/step - loss: 0.4899 - accuracy: 0.8084 - val_loss: 0.4483 - val_accuracy: 0.8258\n",
      "Epoch 146/500\n",
      "477/477 [==============================] - 1s 1ms/step - loss: 0.4886 - accuracy: 0.8088 - val_loss: 0.4473 - val_accuracy: 0.8276\n",
      "Epoch 147/500\n",
      "477/477 [==============================] - 1s 1ms/step - loss: 0.4890 - accuracy: 0.8087 - val_loss: 0.4421 - val_accuracy: 0.8305\n",
      "Epoch 148/500\n",
      "477/477 [==============================] - 1s 1ms/step - loss: 0.4886 - accuracy: 0.8082 - val_loss: 0.4462 - val_accuracy: 0.8287\n",
      "Epoch 149/500\n",
      "477/477 [==============================] - 1s 1ms/step - loss: 0.4896 - accuracy: 0.8079 - val_loss: 0.4470 - val_accuracy: 0.8299\n",
      "Epoch 150/500\n",
      "477/477 [==============================] - 1s 1ms/step - loss: 0.4894 - accuracy: 0.8099 - val_loss: 0.4451 - val_accuracy: 0.8286\n",
      "Epoch 151/500\n",
      "477/477 [==============================] - 1s 1ms/step - loss: 0.4895 - accuracy: 0.8093 - val_loss: 0.4436 - val_accuracy: 0.8304\n",
      "Epoch 152/500\n",
      "477/477 [==============================] - 1s 1ms/step - loss: 0.4875 - accuracy: 0.8080 - val_loss: 0.4448 - val_accuracy: 0.8306\n",
      "Epoch 153/500\n",
      "477/477 [==============================] - 1s 1ms/step - loss: 0.4868 - accuracy: 0.8101 - val_loss: 0.4431 - val_accuracy: 0.8330\n",
      "Epoch 154/500\n",
      "477/477 [==============================] - 1s 1ms/step - loss: 0.4876 - accuracy: 0.8092 - val_loss: 0.4424 - val_accuracy: 0.8300\n",
      "Epoch 155/500\n",
      "477/477 [==============================] - 1s 1ms/step - loss: 0.4882 - accuracy: 0.8101 - val_loss: 0.4457 - val_accuracy: 0.8262\n",
      "Epoch 156/500\n",
      "477/477 [==============================] - 1s 1ms/step - loss: 0.4878 - accuracy: 0.8086 - val_loss: 0.4461 - val_accuracy: 0.8281\n",
      "Epoch 157/500\n",
      "477/477 [==============================] - 1s 2ms/step - loss: 0.4887 - accuracy: 0.8088 - val_loss: 0.4437 - val_accuracy: 0.8313\n",
      "Epoch 158/500\n",
      "477/477 [==============================] - 1s 1ms/step - loss: 0.4861 - accuracy: 0.8103 - val_loss: 0.4432 - val_accuracy: 0.8296\n",
      "Epoch 159/500\n",
      "477/477 [==============================] - 1s 1ms/step - loss: 0.4860 - accuracy: 0.8085 - val_loss: 0.4459 - val_accuracy: 0.8284\n",
      "Epoch 160/500\n",
      "477/477 [==============================] - 1s 1ms/step - loss: 0.4867 - accuracy: 0.8107 - val_loss: 0.4446 - val_accuracy: 0.8295\n",
      "Epoch 161/500\n",
      "477/477 [==============================] - 1s 1ms/step - loss: 0.4863 - accuracy: 0.8102 - val_loss: 0.4428 - val_accuracy: 0.8318\n",
      "Epoch 162/500\n",
      "477/477 [==============================] - 1s 1ms/step - loss: 0.4864 - accuracy: 0.8085 - val_loss: 0.4478 - val_accuracy: 0.8276\n",
      "Epoch 163/500\n",
      "477/477 [==============================] - 1s 1ms/step - loss: 0.4869 - accuracy: 0.8090 - val_loss: 0.4425 - val_accuracy: 0.8320\n",
      "Epoch 164/500\n",
      "477/477 [==============================] - 1s 1ms/step - loss: 0.4843 - accuracy: 0.8115 - val_loss: 0.4419 - val_accuracy: 0.8333\n",
      "Epoch 165/500\n",
      "477/477 [==============================] - 1s 1ms/step - loss: 0.4860 - accuracy: 0.8102 - val_loss: 0.4447 - val_accuracy: 0.8304\n",
      "Epoch 166/500\n",
      "477/477 [==============================] - 1s 1ms/step - loss: 0.4845 - accuracy: 0.8117 - val_loss: 0.4427 - val_accuracy: 0.8313\n",
      "Epoch 167/500\n",
      "477/477 [==============================] - 1s 1ms/step - loss: 0.4850 - accuracy: 0.8115 - val_loss: 0.4427 - val_accuracy: 0.8314\n",
      "Epoch 168/500\n",
      "477/477 [==============================] - 1s 1ms/step - loss: 0.4858 - accuracy: 0.8093 - val_loss: 0.4402 - val_accuracy: 0.8307\n",
      "Epoch 169/500\n",
      "477/477 [==============================] - 1s 1ms/step - loss: 0.4842 - accuracy: 0.8097 - val_loss: 0.4439 - val_accuracy: 0.8302\n",
      "Epoch 170/500\n",
      "477/477 [==============================] - 1s 1ms/step - loss: 0.4847 - accuracy: 0.8096 - val_loss: 0.4475 - val_accuracy: 0.8268\n",
      "Epoch 171/500\n",
      "477/477 [==============================] - 1s 1ms/step - loss: 0.4860 - accuracy: 0.8098 - val_loss: 0.4413 - val_accuracy: 0.8339\n",
      "Epoch 172/500\n",
      "477/477 [==============================] - 1s 1ms/step - loss: 0.4824 - accuracy: 0.8118 - val_loss: 0.4437 - val_accuracy: 0.8323\n",
      "Epoch 173/500\n",
      "477/477 [==============================] - 1s 1ms/step - loss: 0.4862 - accuracy: 0.8106 - val_loss: 0.4414 - val_accuracy: 0.8318\n",
      "Epoch 174/500\n",
      "477/477 [==============================] - 1s 1ms/step - loss: 0.4818 - accuracy: 0.8111 - val_loss: 0.4436 - val_accuracy: 0.8299\n",
      "Epoch 175/500\n",
      "477/477 [==============================] - 1s 1ms/step - loss: 0.4836 - accuracy: 0.8108 - val_loss: 0.4438 - val_accuracy: 0.8296\n",
      "Epoch 176/500\n",
      "477/477 [==============================] - 1s 1ms/step - loss: 0.4844 - accuracy: 0.8103 - val_loss: 0.4399 - val_accuracy: 0.8331\n",
      "Epoch 177/500\n",
      "477/477 [==============================] - 1s 1ms/step - loss: 0.4833 - accuracy: 0.8109 - val_loss: 0.4423 - val_accuracy: 0.8325\n",
      "Epoch 178/500\n",
      "477/477 [==============================] - 1s 1ms/step - loss: 0.4847 - accuracy: 0.8107 - val_loss: 0.4424 - val_accuracy: 0.8304\n",
      "Epoch 179/500\n",
      "477/477 [==============================] - 1s 1ms/step - loss: 0.4844 - accuracy: 0.8113 - val_loss: 0.4409 - val_accuracy: 0.8329\n",
      "Epoch 180/500\n",
      "477/477 [==============================] - 1s 1ms/step - loss: 0.4835 - accuracy: 0.8098 - val_loss: 0.4418 - val_accuracy: 0.8344\n",
      "Epoch 181/500\n",
      "477/477 [==============================] - 1s 1ms/step - loss: 0.4824 - accuracy: 0.8122 - val_loss: 0.4397 - val_accuracy: 0.8321\n",
      "Epoch 182/500\n",
      "477/477 [==============================] - 1s 1ms/step - loss: 0.4830 - accuracy: 0.8111 - val_loss: 0.4381 - val_accuracy: 0.8361\n",
      "Epoch 183/500\n",
      "477/477 [==============================] - 1s 1ms/step - loss: 0.4801 - accuracy: 0.8127 - val_loss: 0.4406 - val_accuracy: 0.8327\n",
      "Epoch 184/500\n",
      "477/477 [==============================] - 1s 1ms/step - loss: 0.4836 - accuracy: 0.8119 - val_loss: 0.4395 - val_accuracy: 0.8330\n",
      "Epoch 185/500\n",
      "477/477 [==============================] - 1s 1ms/step - loss: 0.4825 - accuracy: 0.8127 - val_loss: 0.4398 - val_accuracy: 0.8333\n",
      "Epoch 186/500\n",
      "477/477 [==============================] - 1s 1ms/step - loss: 0.4819 - accuracy: 0.8115 - val_loss: 0.4404 - val_accuracy: 0.8298\n",
      "Epoch 187/500\n",
      "477/477 [==============================] - 1s 1ms/step - loss: 0.4793 - accuracy: 0.8125 - val_loss: 0.4381 - val_accuracy: 0.8327\n",
      "Epoch 188/500\n",
      "477/477 [==============================] - 1s 1ms/step - loss: 0.4825 - accuracy: 0.8110 - val_loss: 0.4388 - val_accuracy: 0.8315\n",
      "Epoch 189/500\n",
      "477/477 [==============================] - 1s 1ms/step - loss: 0.4808 - accuracy: 0.8133 - val_loss: 0.4381 - val_accuracy: 0.8356\n",
      "Epoch 190/500\n",
      "477/477 [==============================] - 1s 1ms/step - loss: 0.4810 - accuracy: 0.8123 - val_loss: 0.4411 - val_accuracy: 0.8324\n",
      "Epoch 191/500\n",
      "477/477 [==============================] - 1s 1ms/step - loss: 0.4786 - accuracy: 0.8140 - val_loss: 0.4393 - val_accuracy: 0.8350\n",
      "Epoch 192/500\n",
      "477/477 [==============================] - 1s 1ms/step - loss: 0.4801 - accuracy: 0.8128 - val_loss: 0.4427 - val_accuracy: 0.8307\n",
      "Epoch 193/500\n",
      "477/477 [==============================] - 1s 1ms/step - loss: 0.4809 - accuracy: 0.8130 - val_loss: 0.4413 - val_accuracy: 0.8296\n",
      "Epoch 194/500\n",
      "477/477 [==============================] - 1s 1ms/step - loss: 0.4775 - accuracy: 0.8151 - val_loss: 0.4366 - val_accuracy: 0.8348\n",
      "Epoch 195/500\n",
      "477/477 [==============================] - 1s 1ms/step - loss: 0.4772 - accuracy: 0.8146 - val_loss: 0.4379 - val_accuracy: 0.8333\n",
      "Epoch 196/500\n",
      "477/477 [==============================] - 1s 1ms/step - loss: 0.4805 - accuracy: 0.8133 - val_loss: 0.4402 - val_accuracy: 0.8322\n",
      "Epoch 197/500\n",
      "477/477 [==============================] - 1s 1ms/step - loss: 0.4794 - accuracy: 0.8116 - val_loss: 0.4457 - val_accuracy: 0.8302\n",
      "Epoch 198/500\n",
      "477/477 [==============================] - 1s 1ms/step - loss: 0.4799 - accuracy: 0.8132 - val_loss: 0.4394 - val_accuracy: 0.8343\n",
      "Epoch 199/500\n",
      "477/477 [==============================] - 1s 1ms/step - loss: 0.4795 - accuracy: 0.8131 - val_loss: 0.4396 - val_accuracy: 0.8327\n",
      "Epoch 200/500\n",
      "477/477 [==============================] - 1s 1ms/step - loss: 0.4809 - accuracy: 0.8132 - val_loss: 0.4392 - val_accuracy: 0.8334\n",
      "Epoch 201/500\n",
      "477/477 [==============================] - 1s 1ms/step - loss: 0.4794 - accuracy: 0.8140 - val_loss: 0.4351 - val_accuracy: 0.8361\n",
      "Epoch 202/500\n",
      "477/477 [==============================] - 1s 1ms/step - loss: 0.4772 - accuracy: 0.8149 - val_loss: 0.4395 - val_accuracy: 0.8347\n",
      "Epoch 203/500\n",
      "477/477 [==============================] - 1s 1ms/step - loss: 0.4778 - accuracy: 0.8130 - val_loss: 0.4367 - val_accuracy: 0.8337\n",
      "Epoch 204/500\n",
      "477/477 [==============================] - 1s 1ms/step - loss: 0.4799 - accuracy: 0.8133 - val_loss: 0.4383 - val_accuracy: 0.8334\n",
      "Epoch 205/500\n",
      "477/477 [==============================] - 1s 1ms/step - loss: 0.4780 - accuracy: 0.8130 - val_loss: 0.4369 - val_accuracy: 0.8350\n",
      "Epoch 206/500\n",
      "477/477 [==============================] - 1s 1ms/step - loss: 0.4789 - accuracy: 0.8129 - val_loss: 0.4376 - val_accuracy: 0.8327\n",
      "Epoch 207/500\n",
      "477/477 [==============================] - 1s 1ms/step - loss: 0.4773 - accuracy: 0.8138 - val_loss: 0.4372 - val_accuracy: 0.8308\n",
      "Epoch 208/500\n",
      "477/477 [==============================] - 1s 1ms/step - loss: 0.4773 - accuracy: 0.8140 - val_loss: 0.4381 - val_accuracy: 0.8341\n",
      "Epoch 209/500\n",
      "477/477 [==============================] - 1s 1ms/step - loss: 0.4758 - accuracy: 0.8143 - val_loss: 0.4355 - val_accuracy: 0.8340\n",
      "Epoch 210/500\n",
      "477/477 [==============================] - 1s 1ms/step - loss: 0.4806 - accuracy: 0.8126 - val_loss: 0.4401 - val_accuracy: 0.8342\n",
      "Epoch 211/500\n",
      "477/477 [==============================] - 1s 1ms/step - loss: 0.4775 - accuracy: 0.8143 - val_loss: 0.4395 - val_accuracy: 0.8318\n",
      "Epoch 212/500\n",
      "477/477 [==============================] - 1s 1ms/step - loss: 0.4771 - accuracy: 0.8132 - val_loss: 0.4365 - val_accuracy: 0.8342\n",
      "Epoch 213/500\n",
      "477/477 [==============================] - 1s 1ms/step - loss: 0.4752 - accuracy: 0.8144 - val_loss: 0.4324 - val_accuracy: 0.8366\n",
      "Epoch 214/500\n",
      "477/477 [==============================] - 1s 1ms/step - loss: 0.4752 - accuracy: 0.8152 - val_loss: 0.4364 - val_accuracy: 0.8348\n",
      "Epoch 215/500\n",
      "477/477 [==============================] - 1s 1ms/step - loss: 0.4787 - accuracy: 0.8133 - val_loss: 0.4357 - val_accuracy: 0.8344\n",
      "Epoch 216/500\n",
      "477/477 [==============================] - 1s 1ms/step - loss: 0.4757 - accuracy: 0.8142 - val_loss: 0.4366 - val_accuracy: 0.8347\n",
      "Epoch 217/500\n",
      "477/477 [==============================] - 1s 1ms/step - loss: 0.4762 - accuracy: 0.8140 - val_loss: 0.4395 - val_accuracy: 0.8335\n",
      "Epoch 218/500\n",
      "477/477 [==============================] - 1s 1ms/step - loss: 0.4745 - accuracy: 0.8143 - val_loss: 0.4371 - val_accuracy: 0.8339\n",
      "Epoch 219/500\n",
      "477/477 [==============================] - 1s 1ms/step - loss: 0.4759 - accuracy: 0.8151 - val_loss: 0.4359 - val_accuracy: 0.8339\n",
      "Epoch 220/500\n",
      "477/477 [==============================] - 1s 1ms/step - loss: 0.4736 - accuracy: 0.8145 - val_loss: 0.4338 - val_accuracy: 0.8372\n",
      "Epoch 221/500\n",
      "477/477 [==============================] - 1s 1ms/step - loss: 0.4756 - accuracy: 0.8141 - val_loss: 0.4368 - val_accuracy: 0.8357\n",
      "Epoch 222/500\n",
      "477/477 [==============================] - 1s 1ms/step - loss: 0.4758 - accuracy: 0.8148 - val_loss: 0.4363 - val_accuracy: 0.8350\n",
      "Epoch 223/500\n",
      "477/477 [==============================] - 1s 1ms/step - loss: 0.4763 - accuracy: 0.8147 - val_loss: 0.4364 - val_accuracy: 0.8349\n",
      "Epoch 224/500\n",
      "477/477 [==============================] - 1s 1ms/step - loss: 0.4756 - accuracy: 0.8148 - val_loss: 0.4363 - val_accuracy: 0.8340\n",
      "Epoch 225/500\n",
      "477/477 [==============================] - 1s 1ms/step - loss: 0.4767 - accuracy: 0.8138 - val_loss: 0.4366 - val_accuracy: 0.8356\n",
      "Epoch 226/500\n",
      "477/477 [==============================] - 1s 1ms/step - loss: 0.4757 - accuracy: 0.8144 - val_loss: 0.4370 - val_accuracy: 0.8352\n",
      "Epoch 227/500\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "477/477 [==============================] - 1s 1ms/step - loss: 0.4741 - accuracy: 0.8150 - val_loss: 0.4370 - val_accuracy: 0.8354\n",
      "Epoch 228/500\n",
      "477/477 [==============================] - 1s 1ms/step - loss: 0.4752 - accuracy: 0.8159 - val_loss: 0.4360 - val_accuracy: 0.8344\n",
      "Epoch 229/500\n",
      "477/477 [==============================] - 1s 1ms/step - loss: 0.4758 - accuracy: 0.8153 - val_loss: 0.4363 - val_accuracy: 0.8351\n",
      "Epoch 230/500\n",
      "477/477 [==============================] - 1s 1ms/step - loss: 0.4745 - accuracy: 0.8148 - val_loss: 0.4358 - val_accuracy: 0.8360\n",
      "Epoch 231/500\n",
      "477/477 [==============================] - 1s 1ms/step - loss: 0.4755 - accuracy: 0.8159 - val_loss: 0.4363 - val_accuracy: 0.8347\n",
      "Epoch 232/500\n",
      "477/477 [==============================] - 1s 1ms/step - loss: 0.4746 - accuracy: 0.8152 - val_loss: 0.4353 - val_accuracy: 0.8374\n",
      "Epoch 233/500\n",
      "477/477 [==============================] - 1s 1ms/step - loss: 0.4748 - accuracy: 0.8145 - val_loss: 0.4361 - val_accuracy: 0.8368\n",
      "Epoch 234/500\n",
      "477/477 [==============================] - 1s 1ms/step - loss: 0.4740 - accuracy: 0.8158 - val_loss: 0.4364 - val_accuracy: 0.8344\n",
      "Epoch 235/500\n",
      "477/477 [==============================] - 1s 1ms/step - loss: 0.4751 - accuracy: 0.8151 - val_loss: 0.4360 - val_accuracy: 0.8338\n",
      "Epoch 236/500\n",
      "477/477 [==============================] - 1s 1ms/step - loss: 0.4759 - accuracy: 0.8154 - val_loss: 0.4370 - val_accuracy: 0.8347\n",
      "Epoch 237/500\n",
      "477/477 [==============================] - 1s 1ms/step - loss: 0.4741 - accuracy: 0.8153 - val_loss: 0.4342 - val_accuracy: 0.8339\n",
      "Epoch 238/500\n",
      "477/477 [==============================] - 1s 1ms/step - loss: 0.4722 - accuracy: 0.8173 - val_loss: 0.4362 - val_accuracy: 0.8338\n",
      "Epoch 239/500\n",
      "477/477 [==============================] - 1s 1ms/step - loss: 0.4748 - accuracy: 0.8158 - val_loss: 0.4336 - val_accuracy: 0.8356\n",
      "Epoch 240/500\n",
      "477/477 [==============================] - 1s 1ms/step - loss: 0.4711 - accuracy: 0.8166 - val_loss: 0.4337 - val_accuracy: 0.8369\n",
      "Epoch 241/500\n",
      "477/477 [==============================] - 1s 1ms/step - loss: 0.4724 - accuracy: 0.8158 - val_loss: 0.4361 - val_accuracy: 0.8350\n",
      "Epoch 242/500\n",
      "477/477 [==============================] - 1s 1ms/step - loss: 0.4738 - accuracy: 0.8157 - val_loss: 0.4352 - val_accuracy: 0.8346\n",
      "Epoch 243/500\n",
      "477/477 [==============================] - 1s 1ms/step - loss: 0.4720 - accuracy: 0.8171 - val_loss: 0.4371 - val_accuracy: 0.8333\n",
      "Epoch 244/500\n",
      "477/477 [==============================] - 1s 1ms/step - loss: 0.4735 - accuracy: 0.8155 - val_loss: 0.4373 - val_accuracy: 0.8352\n",
      "Epoch 245/500\n",
      "477/477 [==============================] - 1s 1ms/step - loss: 0.4740 - accuracy: 0.8153 - val_loss: 0.4332 - val_accuracy: 0.8338\n",
      "Epoch 246/500\n",
      "477/477 [==============================] - 1s 1ms/step - loss: 0.4737 - accuracy: 0.8160 - val_loss: 0.4334 - val_accuracy: 0.8359\n",
      "Epoch 247/500\n",
      "477/477 [==============================] - 1s 1ms/step - loss: 0.4733 - accuracy: 0.8165 - val_loss: 0.4321 - val_accuracy: 0.8382\n",
      "Epoch 248/500\n",
      "477/477 [==============================] - 1s 1ms/step - loss: 0.4722 - accuracy: 0.8165 - val_loss: 0.4364 - val_accuracy: 0.8347\n",
      "Epoch 249/500\n",
      "477/477 [==============================] - 1s 1ms/step - loss: 0.4723 - accuracy: 0.8171 - val_loss: 0.4339 - val_accuracy: 0.8363\n",
      "Epoch 250/500\n",
      "477/477 [==============================] - 1s 1ms/step - loss: 0.4730 - accuracy: 0.8174 - val_loss: 0.4326 - val_accuracy: 0.8355\n",
      "Epoch 251/500\n",
      "477/477 [==============================] - 1s 1ms/step - loss: 0.4708 - accuracy: 0.8163 - val_loss: 0.4349 - val_accuracy: 0.8369\n",
      "Epoch 252/500\n",
      "477/477 [==============================] - 1s 1ms/step - loss: 0.4735 - accuracy: 0.8161 - val_loss: 0.4314 - val_accuracy: 0.8400\n",
      "Epoch 253/500\n",
      "477/477 [==============================] - 1s 1ms/step - loss: 0.4721 - accuracy: 0.8165 - val_loss: 0.4305 - val_accuracy: 0.8377\n",
      "Epoch 254/500\n",
      "477/477 [==============================] - 1s 1ms/step - loss: 0.4706 - accuracy: 0.8180 - val_loss: 0.4299 - val_accuracy: 0.8358\n",
      "Epoch 255/500\n",
      "477/477 [==============================] - 1s 1ms/step - loss: 0.4716 - accuracy: 0.8163 - val_loss: 0.4314 - val_accuracy: 0.8355\n",
      "Epoch 256/500\n",
      "477/477 [==============================] - 1s 1ms/step - loss: 0.4710 - accuracy: 0.8155 - val_loss: 0.4311 - val_accuracy: 0.8356\n",
      "Epoch 257/500\n",
      "477/477 [==============================] - 1s 1ms/step - loss: 0.4720 - accuracy: 0.8175 - val_loss: 0.4362 - val_accuracy: 0.8331\n",
      "Epoch 258/500\n",
      "477/477 [==============================] - 1s 1ms/step - loss: 0.4727 - accuracy: 0.8173 - val_loss: 0.4317 - val_accuracy: 0.8385\n",
      "Epoch 259/500\n",
      "477/477 [==============================] - 1s 1ms/step - loss: 0.4722 - accuracy: 0.8163 - val_loss: 0.4318 - val_accuracy: 0.8356\n",
      "Epoch 260/500\n",
      "477/477 [==============================] - 1s 1ms/step - loss: 0.4708 - accuracy: 0.8170 - val_loss: 0.4332 - val_accuracy: 0.8365\n",
      "Epoch 261/500\n",
      "477/477 [==============================] - 1s 1ms/step - loss: 0.4724 - accuracy: 0.8158 - val_loss: 0.4301 - val_accuracy: 0.8376\n",
      "Epoch 262/500\n",
      "477/477 [==============================] - 1s 1ms/step - loss: 0.4717 - accuracy: 0.8170 - val_loss: 0.4335 - val_accuracy: 0.8366\n",
      "Epoch 263/500\n",
      "477/477 [==============================] - 1s 1ms/step - loss: 0.4711 - accuracy: 0.8168 - val_loss: 0.4320 - val_accuracy: 0.8366\n",
      "Epoch 264/500\n",
      "477/477 [==============================] - 1s 1ms/step - loss: 0.4716 - accuracy: 0.8162 - val_loss: 0.4306 - val_accuracy: 0.8384\n",
      "Epoch 265/500\n",
      "477/477 [==============================] - 1s 1ms/step - loss: 0.4704 - accuracy: 0.8165 - val_loss: 0.4334 - val_accuracy: 0.8387\n",
      "Epoch 266/500\n",
      "477/477 [==============================] - 1s 1ms/step - loss: 0.4701 - accuracy: 0.8173 - val_loss: 0.4331 - val_accuracy: 0.8362\n",
      "Epoch 267/500\n",
      "477/477 [==============================] - 1s 1ms/step - loss: 0.4717 - accuracy: 0.8165 - val_loss: 0.4324 - val_accuracy: 0.8386\n",
      "Epoch 268/500\n",
      "477/477 [==============================] - 1s 1ms/step - loss: 0.4711 - accuracy: 0.8166 - val_loss: 0.4314 - val_accuracy: 0.8375\n",
      "Epoch 269/500\n",
      "477/477 [==============================] - 1s 1ms/step - loss: 0.4708 - accuracy: 0.8163 - val_loss: 0.4302 - val_accuracy: 0.8373\n",
      "Epoch 270/500\n",
      "477/477 [==============================] - 1s 1ms/step - loss: 0.4688 - accuracy: 0.8170 - val_loss: 0.4293 - val_accuracy: 0.8380\n",
      "Epoch 271/500\n",
      "477/477 [==============================] - 1s 1ms/step - loss: 0.4713 - accuracy: 0.8174 - val_loss: 0.4330 - val_accuracy: 0.8358\n",
      "Epoch 272/500\n",
      "477/477 [==============================] - 1s 1ms/step - loss: 0.4717 - accuracy: 0.8171 - val_loss: 0.4314 - val_accuracy: 0.8372\n",
      "Epoch 273/500\n",
      "477/477 [==============================] - 1s 1ms/step - loss: 0.4696 - accuracy: 0.8184 - val_loss: 0.4322 - val_accuracy: 0.8388\n",
      "Epoch 274/500\n",
      "477/477 [==============================] - 1s 1ms/step - loss: 0.4709 - accuracy: 0.8172 - val_loss: 0.4277 - val_accuracy: 0.8402\n",
      "Epoch 275/500\n",
      "477/477 [==============================] - 1s 1ms/step - loss: 0.4670 - accuracy: 0.8190 - val_loss: 0.4338 - val_accuracy: 0.8356\n",
      "Epoch 276/500\n",
      "477/477 [==============================] - 1s 1ms/step - loss: 0.4690 - accuracy: 0.8180 - val_loss: 0.4315 - val_accuracy: 0.8391\n",
      "Epoch 277/500\n",
      "477/477 [==============================] - 1s 1ms/step - loss: 0.4685 - accuracy: 0.8179 - val_loss: 0.4309 - val_accuracy: 0.8408\n",
      "Epoch 278/500\n",
      "477/477 [==============================] - 1s 1ms/step - loss: 0.4690 - accuracy: 0.8191 - val_loss: 0.4317 - val_accuracy: 0.8381\n",
      "Epoch 279/500\n",
      "477/477 [==============================] - 1s 1ms/step - loss: 0.4682 - accuracy: 0.8192 - val_loss: 0.4282 - val_accuracy: 0.8384\n",
      "Epoch 280/500\n",
      "477/477 [==============================] - 1s 1ms/step - loss: 0.4685 - accuracy: 0.8195 - val_loss: 0.4298 - val_accuracy: 0.8368\n",
      "Epoch 281/500\n",
      "477/477 [==============================] - 1s 1ms/step - loss: 0.4703 - accuracy: 0.8177 - val_loss: 0.4309 - val_accuracy: 0.8363\n",
      "Epoch 282/500\n",
      "477/477 [==============================] - 1s 1ms/step - loss: 0.4691 - accuracy: 0.8185 - val_loss: 0.4300 - val_accuracy: 0.8383\n",
      "Epoch 283/500\n",
      "477/477 [==============================] - 1s 1ms/step - loss: 0.4694 - accuracy: 0.8189 - val_loss: 0.4304 - val_accuracy: 0.8376\n",
      "Epoch 284/500\n",
      "477/477 [==============================] - 1s 1ms/step - loss: 0.4691 - accuracy: 0.8182 - val_loss: 0.4328 - val_accuracy: 0.8387\n",
      "Epoch 285/500\n",
      "477/477 [==============================] - 1s 1ms/step - loss: 0.4686 - accuracy: 0.8181 - val_loss: 0.4342 - val_accuracy: 0.8386\n",
      "Epoch 286/500\n",
      "477/477 [==============================] - 1s 1ms/step - loss: 0.4685 - accuracy: 0.8187 - val_loss: 0.4318 - val_accuracy: 0.8375\n",
      "Epoch 287/500\n",
      "477/477 [==============================] - 1s 1ms/step - loss: 0.4674 - accuracy: 0.8183 - val_loss: 0.4325 - val_accuracy: 0.8383\n",
      "Epoch 288/500\n",
      "477/477 [==============================] - 1s 1ms/step - loss: 0.4673 - accuracy: 0.8176 - val_loss: 0.4261 - val_accuracy: 0.8392\n",
      "Epoch 289/500\n",
      "477/477 [==============================] - 1s 1ms/step - loss: 0.4677 - accuracy: 0.8191 - val_loss: 0.4318 - val_accuracy: 0.8377\n",
      "Epoch 290/500\n",
      "477/477 [==============================] - 1s 1ms/step - loss: 0.4683 - accuracy: 0.8178 - val_loss: 0.4327 - val_accuracy: 0.8383\n",
      "Epoch 291/500\n",
      "477/477 [==============================] - 1s 1ms/step - loss: 0.4688 - accuracy: 0.8183 - val_loss: 0.4298 - val_accuracy: 0.8384\n",
      "Epoch 292/500\n",
      "477/477 [==============================] - 1s 1ms/step - loss: 0.4679 - accuracy: 0.8189 - val_loss: 0.4293 - val_accuracy: 0.8406\n",
      "Epoch 293/500\n",
      "477/477 [==============================] - 1s 1ms/step - loss: 0.4682 - accuracy: 0.8173 - val_loss: 0.4299 - val_accuracy: 0.8383\n",
      "Epoch 294/500\n",
      "477/477 [==============================] - 1s 1ms/step - loss: 0.4688 - accuracy: 0.8188 - val_loss: 0.4291 - val_accuracy: 0.8390\n",
      "Epoch 295/500\n",
      "477/477 [==============================] - 1s 1ms/step - loss: 0.4690 - accuracy: 0.8187 - val_loss: 0.4323 - val_accuracy: 0.8372\n",
      "Epoch 296/500\n",
      "477/477 [==============================] - 1s 1ms/step - loss: 0.4670 - accuracy: 0.8195 - val_loss: 0.4310 - val_accuracy: 0.8377\n",
      "Epoch 297/500\n",
      "477/477 [==============================] - 1s 1ms/step - loss: 0.4676 - accuracy: 0.8193 - val_loss: 0.4285 - val_accuracy: 0.8404\n",
      "Epoch 298/500\n",
      "477/477 [==============================] - 1s 1ms/step - loss: 0.4669 - accuracy: 0.8192 - val_loss: 0.4284 - val_accuracy: 0.8396\n",
      "Epoch 299/500\n",
      "477/477 [==============================] - 1s 1ms/step - loss: 0.4670 - accuracy: 0.8201 - val_loss: 0.4301 - val_accuracy: 0.8391\n",
      "Epoch 300/500\n",
      "477/477 [==============================] - 1s 1ms/step - loss: 0.4687 - accuracy: 0.8177 - val_loss: 0.4302 - val_accuracy: 0.8397\n",
      "Epoch 301/500\n",
      "477/477 [==============================] - 1s 1ms/step - loss: 0.4661 - accuracy: 0.8190 - val_loss: 0.4286 - val_accuracy: 0.8392\n",
      "Epoch 302/500\n",
      "477/477 [==============================] - 1s 1ms/step - loss: 0.4664 - accuracy: 0.8193 - val_loss: 0.4291 - val_accuracy: 0.8393\n",
      "Epoch 303/500\n",
      "477/477 [==============================] - 1s 1ms/step - loss: 0.4668 - accuracy: 0.8187 - val_loss: 0.4268 - val_accuracy: 0.8400\n",
      "Epoch 304/500\n",
      "477/477 [==============================] - 1s 1ms/step - loss: 0.4648 - accuracy: 0.8200 - val_loss: 0.4253 - val_accuracy: 0.8408\n",
      "Epoch 305/500\n",
      "477/477 [==============================] - 1s 1ms/step - loss: 0.4674 - accuracy: 0.8186 - val_loss: 0.4277 - val_accuracy: 0.8398\n",
      "Epoch 306/500\n",
      "477/477 [==============================] - 1s 1ms/step - loss: 0.4657 - accuracy: 0.8198 - val_loss: 0.4295 - val_accuracy: 0.8397\n",
      "Epoch 307/500\n",
      "477/477 [==============================] - 1s 1ms/step - loss: 0.4670 - accuracy: 0.8195 - val_loss: 0.4292 - val_accuracy: 0.8389\n",
      "Epoch 308/500\n",
      "477/477 [==============================] - 1s 1ms/step - loss: 0.4667 - accuracy: 0.8202 - val_loss: 0.4288 - val_accuracy: 0.8397\n",
      "Epoch 309/500\n",
      "477/477 [==============================] - 1s 1ms/step - loss: 0.4667 - accuracy: 0.8185 - val_loss: 0.4280 - val_accuracy: 0.8376\n",
      "Epoch 310/500\n",
      "477/477 [==============================] - 1s 1ms/step - loss: 0.4652 - accuracy: 0.8190 - val_loss: 0.4301 - val_accuracy: 0.8388\n",
      "Epoch 311/500\n",
      "477/477 [==============================] - 1s 1ms/step - loss: 0.4679 - accuracy: 0.8188 - val_loss: 0.4288 - val_accuracy: 0.8384\n",
      "Epoch 312/500\n",
      "477/477 [==============================] - 1s 1ms/step - loss: 0.4654 - accuracy: 0.8192 - val_loss: 0.4320 - val_accuracy: 0.8377\n",
      "Epoch 313/500\n",
      "477/477 [==============================] - 1s 1ms/step - loss: 0.4661 - accuracy: 0.8196 - val_loss: 0.4307 - val_accuracy: 0.8379\n",
      "Epoch 314/500\n",
      "477/477 [==============================] - 1s 1ms/step - loss: 0.4649 - accuracy: 0.8200 - val_loss: 0.4285 - val_accuracy: 0.8396\n",
      "Epoch 315/500\n",
      "477/477 [==============================] - 1s 1ms/step - loss: 0.4675 - accuracy: 0.8173 - val_loss: 0.4279 - val_accuracy: 0.8403\n",
      "Epoch 316/500\n",
      "477/477 [==============================] - 1s 1ms/step - loss: 0.4646 - accuracy: 0.8202 - val_loss: 0.4252 - val_accuracy: 0.8412\n",
      "Epoch 317/500\n",
      "477/477 [==============================] - 1s 1ms/step - loss: 0.4654 - accuracy: 0.8192 - val_loss: 0.4303 - val_accuracy: 0.8371\n",
      "Epoch 318/500\n",
      "477/477 [==============================] - 1s 1ms/step - loss: 0.4667 - accuracy: 0.8197 - val_loss: 0.4274 - val_accuracy: 0.8393\n",
      "Epoch 319/500\n",
      "477/477 [==============================] - 1s 1ms/step - loss: 0.4637 - accuracy: 0.8203 - val_loss: 0.4289 - val_accuracy: 0.8406\n",
      "Epoch 320/500\n",
      "477/477 [==============================] - 1s 1ms/step - loss: 0.4670 - accuracy: 0.8194 - val_loss: 0.4303 - val_accuracy: 0.8371\n",
      "Epoch 321/500\n",
      "477/477 [==============================] - 1s 1ms/step - loss: 0.4675 - accuracy: 0.8189 - val_loss: 0.4292 - val_accuracy: 0.8392\n",
      "Epoch 322/500\n",
      "477/477 [==============================] - 1s 1ms/step - loss: 0.4655 - accuracy: 0.8198 - val_loss: 0.4313 - val_accuracy: 0.8399\n",
      "Epoch 323/500\n",
      "477/477 [==============================] - 1s 1ms/step - loss: 0.4656 - accuracy: 0.8192 - val_loss: 0.4322 - val_accuracy: 0.8377\n",
      "Epoch 324/500\n",
      "477/477 [==============================] - 1s 1ms/step - loss: 0.4671 - accuracy: 0.8192 - val_loss: 0.4307 - val_accuracy: 0.8372\n",
      "Epoch 325/500\n",
      "477/477 [==============================] - 1s 1ms/step - loss: 0.4658 - accuracy: 0.8198 - val_loss: 0.4308 - val_accuracy: 0.8367\n",
      "Epoch 326/500\n",
      "477/477 [==============================] - 1s 1ms/step - loss: 0.4657 - accuracy: 0.8197 - val_loss: 0.4292 - val_accuracy: 0.8384\n",
      "Epoch 327/500\n",
      "477/477 [==============================] - 1s 1ms/step - loss: 0.4673 - accuracy: 0.8195 - val_loss: 0.4301 - val_accuracy: 0.8370\n",
      "Epoch 328/500\n",
      "477/477 [==============================] - 1s 1ms/step - loss: 0.4664 - accuracy: 0.8199 - val_loss: 0.4263 - val_accuracy: 0.8400\n",
      "Epoch 329/500\n",
      "477/477 [==============================] - 1s 1ms/step - loss: 0.4652 - accuracy: 0.8201 - val_loss: 0.4269 - val_accuracy: 0.8414\n",
      "Epoch 330/500\n",
      "477/477 [==============================] - 1s 1ms/step - loss: 0.4647 - accuracy: 0.8199 - val_loss: 0.4245 - val_accuracy: 0.8406\n",
      "Epoch 331/500\n",
      "477/477 [==============================] - 1s 1ms/step - loss: 0.4645 - accuracy: 0.8196 - val_loss: 0.4303 - val_accuracy: 0.8388\n",
      "Epoch 332/500\n",
      "477/477 [==============================] - 1s 1ms/step - loss: 0.4644 - accuracy: 0.8204 - val_loss: 0.4252 - val_accuracy: 0.8392\n",
      "Epoch 333/500\n",
      "477/477 [==============================] - 1s 1ms/step - loss: 0.4630 - accuracy: 0.8202 - val_loss: 0.4264 - val_accuracy: 0.8391\n",
      "Epoch 334/500\n",
      "477/477 [==============================] - 1s 1ms/step - loss: 0.4657 - accuracy: 0.8197 - val_loss: 0.4277 - val_accuracy: 0.8383\n",
      "Epoch 335/500\n",
      "477/477 [==============================] - 1s 1ms/step - loss: 0.4651 - accuracy: 0.8203 - val_loss: 0.4283 - val_accuracy: 0.8376\n",
      "Epoch 336/500\n",
      "477/477 [==============================] - 1s 1ms/step - loss: 0.4633 - accuracy: 0.8203 - val_loss: 0.4285 - val_accuracy: 0.8404\n",
      "Epoch 337/500\n",
      "477/477 [==============================] - 1s 1ms/step - loss: 0.4642 - accuracy: 0.8208 - val_loss: 0.4283 - val_accuracy: 0.8397\n",
      "Epoch 338/500\n",
      "477/477 [==============================] - 1s 1ms/step - loss: 0.4638 - accuracy: 0.8205 - val_loss: 0.4317 - val_accuracy: 0.8381\n",
      "Epoch 339/500\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "477/477 [==============================] - 1s 1ms/step - loss: 0.4651 - accuracy: 0.8198 - val_loss: 0.4258 - val_accuracy: 0.8388\n",
      "Epoch 340/500\n",
      "477/477 [==============================] - 1s 1ms/step - loss: 0.4664 - accuracy: 0.8195 - val_loss: 0.4282 - val_accuracy: 0.8399\n",
      "Epoch 341/500\n",
      "477/477 [==============================] - 1s 1ms/step - loss: 0.4625 - accuracy: 0.8212 - val_loss: 0.4280 - val_accuracy: 0.8390\n",
      "Epoch 342/500\n",
      "477/477 [==============================] - 1s 1ms/step - loss: 0.4664 - accuracy: 0.8198 - val_loss: 0.4272 - val_accuracy: 0.8402\n",
      "Epoch 343/500\n",
      "477/477 [==============================] - 1s 1ms/step - loss: 0.4655 - accuracy: 0.8213 - val_loss: 0.4293 - val_accuracy: 0.8401\n",
      "Epoch 344/500\n",
      "477/477 [==============================] - 1s 1ms/step - loss: 0.4645 - accuracy: 0.8212 - val_loss: 0.4263 - val_accuracy: 0.8397\n",
      "Epoch 345/500\n",
      "477/477 [==============================] - 1s 1ms/step - loss: 0.4641 - accuracy: 0.8203 - val_loss: 0.4256 - val_accuracy: 0.8389\n",
      "Epoch 346/500\n",
      "477/477 [==============================] - 1s 1ms/step - loss: 0.4626 - accuracy: 0.8206 - val_loss: 0.4259 - val_accuracy: 0.8382\n",
      "Epoch 347/500\n",
      "477/477 [==============================] - 1s 1ms/step - loss: 0.4629 - accuracy: 0.8210 - val_loss: 0.4248 - val_accuracy: 0.8398\n",
      "Epoch 348/500\n",
      "477/477 [==============================] - 1s 1ms/step - loss: 0.4620 - accuracy: 0.8203 - val_loss: 0.4255 - val_accuracy: 0.8397\n",
      "Epoch 349/500\n",
      "477/477 [==============================] - 1s 1ms/step - loss: 0.4637 - accuracy: 0.8203 - val_loss: 0.4274 - val_accuracy: 0.8392\n",
      "Epoch 350/500\n",
      "477/477 [==============================] - 1s 1ms/step - loss: 0.4626 - accuracy: 0.8208 - val_loss: 0.4303 - val_accuracy: 0.8387\n",
      "Epoch 351/500\n",
      "477/477 [==============================] - 1s 1ms/step - loss: 0.4633 - accuracy: 0.8206 - val_loss: 0.4317 - val_accuracy: 0.8369\n",
      "Epoch 352/500\n",
      "477/477 [==============================] - 1s 1ms/step - loss: 0.4636 - accuracy: 0.8204 - val_loss: 0.4297 - val_accuracy: 0.8379\n",
      "Epoch 353/500\n",
      "477/477 [==============================] - 1s 1ms/step - loss: 0.4638 - accuracy: 0.8205 - val_loss: 0.4279 - val_accuracy: 0.8393\n",
      "Epoch 354/500\n",
      "477/477 [==============================] - 1s 1ms/step - loss: 0.4641 - accuracy: 0.8207 - val_loss: 0.4274 - val_accuracy: 0.8377\n",
      "Epoch 355/500\n",
      "477/477 [==============================] - 1s 1ms/step - loss: 0.4611 - accuracy: 0.8213 - val_loss: 0.4257 - val_accuracy: 0.8383\n",
      "Epoch 356/500\n",
      "477/477 [==============================] - 1s 1ms/step - loss: 0.4625 - accuracy: 0.8206 - val_loss: 0.4279 - val_accuracy: 0.8397\n",
      "Epoch 357/500\n",
      "477/477 [==============================] - 1s 1ms/step - loss: 0.4651 - accuracy: 0.8194 - val_loss: 0.4316 - val_accuracy: 0.8357\n",
      "Epoch 358/500\n",
      "477/477 [==============================] - 1s 1ms/step - loss: 0.4636 - accuracy: 0.8194 - val_loss: 0.4263 - val_accuracy: 0.8414\n",
      "Epoch 359/500\n",
      "477/477 [==============================] - 1s 1ms/step - loss: 0.4651 - accuracy: 0.8205 - val_loss: 0.4293 - val_accuracy: 0.8364\n",
      "Epoch 360/500\n",
      "477/477 [==============================] - 1s 1ms/step - loss: 0.4609 - accuracy: 0.8198 - val_loss: 0.4260 - val_accuracy: 0.8380\n",
      "Epoch 361/500\n",
      "477/477 [==============================] - 1s 1ms/step - loss: 0.4626 - accuracy: 0.8212 - val_loss: 0.4217 - val_accuracy: 0.8426\n",
      "Epoch 362/500\n",
      "477/477 [==============================] - 1s 1ms/step - loss: 0.4620 - accuracy: 0.8215 - val_loss: 0.4284 - val_accuracy: 0.8380\n",
      "Epoch 363/500\n",
      "477/477 [==============================] - 1s 1ms/step - loss: 0.4614 - accuracy: 0.8206 - val_loss: 0.4302 - val_accuracy: 0.8410\n",
      "Epoch 364/500\n",
      "477/477 [==============================] - 1s 1ms/step - loss: 0.4632 - accuracy: 0.8201 - val_loss: 0.4273 - val_accuracy: 0.8398\n",
      "Epoch 365/500\n",
      "477/477 [==============================] - 1s 1ms/step - loss: 0.4618 - accuracy: 0.8213 - val_loss: 0.4258 - val_accuracy: 0.8394\n",
      "Epoch 366/500\n",
      "477/477 [==============================] - 1s 1ms/step - loss: 0.4632 - accuracy: 0.8205 - val_loss: 0.4283 - val_accuracy: 0.8376\n",
      "Epoch 367/500\n",
      "477/477 [==============================] - 1s 1ms/step - loss: 0.4636 - accuracy: 0.8205 - val_loss: 0.4280 - val_accuracy: 0.8380\n",
      "Epoch 368/500\n",
      "477/477 [==============================] - 1s 1ms/step - loss: 0.4639 - accuracy: 0.8195 - val_loss: 0.4293 - val_accuracy: 0.8392\n",
      "Epoch 369/500\n",
      "477/477 [==============================] - 1s 1ms/step - loss: 0.4607 - accuracy: 0.8215 - val_loss: 0.4275 - val_accuracy: 0.8398\n",
      "Epoch 370/500\n",
      "477/477 [==============================] - 1s 1ms/step - loss: 0.4609 - accuracy: 0.8226 - val_loss: 0.4263 - val_accuracy: 0.8376\n",
      "Epoch 371/500\n",
      "477/477 [==============================] - 1s 1ms/step - loss: 0.4629 - accuracy: 0.8214 - val_loss: 0.4267 - val_accuracy: 0.8390\n",
      "Epoch 372/500\n",
      "477/477 [==============================] - 1s 1ms/step - loss: 0.4617 - accuracy: 0.8212 - val_loss: 0.4280 - val_accuracy: 0.8406\n",
      "Epoch 373/500\n",
      "477/477 [==============================] - 1s 1ms/step - loss: 0.4604 - accuracy: 0.8228 - val_loss: 0.4271 - val_accuracy: 0.8389\n",
      "Epoch 374/500\n",
      "477/477 [==============================] - 1s 1ms/step - loss: 0.4610 - accuracy: 0.8215 - val_loss: 0.4255 - val_accuracy: 0.8428\n",
      "Epoch 375/500\n",
      "477/477 [==============================] - 1s 1ms/step - loss: 0.4599 - accuracy: 0.8226 - val_loss: 0.4245 - val_accuracy: 0.8422\n",
      "Epoch 376/500\n",
      "477/477 [==============================] - 1s 1ms/step - loss: 0.4625 - accuracy: 0.8211 - val_loss: 0.4230 - val_accuracy: 0.8403\n",
      "Epoch 377/500\n",
      "477/477 [==============================] - 1s 1ms/step - loss: 0.4605 - accuracy: 0.8211 - val_loss: 0.4264 - val_accuracy: 0.8400\n",
      "Epoch 378/500\n",
      "477/477 [==============================] - 1s 1ms/step - loss: 0.4600 - accuracy: 0.8218 - val_loss: 0.4239 - val_accuracy: 0.8414\n",
      "Epoch 379/500\n",
      "477/477 [==============================] - 1s 1ms/step - loss: 0.4607 - accuracy: 0.8224 - val_loss: 0.4262 - val_accuracy: 0.8391\n",
      "Epoch 380/500\n",
      "477/477 [==============================] - 1s 1ms/step - loss: 0.4601 - accuracy: 0.8220 - val_loss: 0.4226 - val_accuracy: 0.8443\n",
      "Epoch 381/500\n",
      "477/477 [==============================] - 1s 1ms/step - loss: 0.4620 - accuracy: 0.8210 - val_loss: 0.4230 - val_accuracy: 0.8420\n",
      "Epoch 382/500\n",
      "477/477 [==============================] - 1s 1ms/step - loss: 0.4610 - accuracy: 0.8218 - val_loss: 0.4233 - val_accuracy: 0.8411\n",
      "Epoch 383/500\n",
      "477/477 [==============================] - 1s 1ms/step - loss: 0.4599 - accuracy: 0.8222 - val_loss: 0.4263 - val_accuracy: 0.8425\n",
      "Epoch 384/500\n",
      "477/477 [==============================] - 1s 1ms/step - loss: 0.4603 - accuracy: 0.8212 - val_loss: 0.4238 - val_accuracy: 0.8432\n",
      "Epoch 385/500\n",
      "477/477 [==============================] - 1s 1ms/step - loss: 0.4606 - accuracy: 0.8216 - val_loss: 0.4273 - val_accuracy: 0.8407\n",
      "Epoch 386/500\n",
      "477/477 [==============================] - 1s 1ms/step - loss: 0.4606 - accuracy: 0.8212 - val_loss: 0.4254 - val_accuracy: 0.8395\n",
      "Epoch 387/500\n",
      "477/477 [==============================] - 1s 1ms/step - loss: 0.4602 - accuracy: 0.8215 - val_loss: 0.4244 - val_accuracy: 0.8404\n",
      "Epoch 388/500\n",
      "477/477 [==============================] - 1s 1ms/step - loss: 0.4632 - accuracy: 0.8222 - val_loss: 0.4273 - val_accuracy: 0.8397\n",
      "Epoch 389/500\n",
      "477/477 [==============================] - 1s 1ms/step - loss: 0.4578 - accuracy: 0.8235 - val_loss: 0.4251 - val_accuracy: 0.8408\n",
      "Epoch 390/500\n",
      "477/477 [==============================] - 1s 1ms/step - loss: 0.4614 - accuracy: 0.8220 - val_loss: 0.4239 - val_accuracy: 0.8403\n",
      "Epoch 391/500\n",
      "477/477 [==============================] - 1s 1ms/step - loss: 0.4596 - accuracy: 0.8216 - val_loss: 0.4224 - val_accuracy: 0.8392\n",
      "Epoch 392/500\n",
      "477/477 [==============================] - 1s 1ms/step - loss: 0.4619 - accuracy: 0.8219 - val_loss: 0.4242 - val_accuracy: 0.8411\n",
      "Epoch 393/500\n",
      "477/477 [==============================] - 1s 1ms/step - loss: 0.4598 - accuracy: 0.8215 - val_loss: 0.4209 - val_accuracy: 0.8422\n",
      "Epoch 394/500\n",
      "477/477 [==============================] - 1s 1ms/step - loss: 0.4593 - accuracy: 0.8222 - val_loss: 0.4184 - val_accuracy: 0.8439\n",
      "Epoch 395/500\n",
      "477/477 [==============================] - 1s 1ms/step - loss: 0.4604 - accuracy: 0.8222 - val_loss: 0.4200 - val_accuracy: 0.8449\n",
      "Epoch 396/500\n",
      "477/477 [==============================] - 1s 1ms/step - loss: 0.4586 - accuracy: 0.8221 - val_loss: 0.4236 - val_accuracy: 0.8414\n",
      "Epoch 397/500\n",
      "477/477 [==============================] - 1s 1ms/step - loss: 0.4601 - accuracy: 0.8224 - val_loss: 0.4238 - val_accuracy: 0.8409\n",
      "Epoch 398/500\n",
      "477/477 [==============================] - 1s 1ms/step - loss: 0.4611 - accuracy: 0.8218 - val_loss: 0.4261 - val_accuracy: 0.8403\n",
      "Epoch 399/500\n",
      "477/477 [==============================] - 1s 1ms/step - loss: 0.4589 - accuracy: 0.8230 - val_loss: 0.4234 - val_accuracy: 0.8399\n",
      "Epoch 400/500\n",
      "477/477 [==============================] - 1s 1ms/step - loss: 0.4584 - accuracy: 0.8218 - val_loss: 0.4235 - val_accuracy: 0.8400\n",
      "Epoch 401/500\n",
      "477/477 [==============================] - 1s 1ms/step - loss: 0.4595 - accuracy: 0.8240 - val_loss: 0.4223 - val_accuracy: 0.8412\n",
      "Epoch 402/500\n",
      "477/477 [==============================] - 1s 1ms/step - loss: 0.4603 - accuracy: 0.8220 - val_loss: 0.4247 - val_accuracy: 0.8397\n",
      "Epoch 403/500\n",
      "477/477 [==============================] - 1s 1ms/step - loss: 0.4600 - accuracy: 0.8226 - val_loss: 0.4251 - val_accuracy: 0.8388\n",
      "Epoch 404/500\n",
      "477/477 [==============================] - 1s 1ms/step - loss: 0.4598 - accuracy: 0.8235 - val_loss: 0.4265 - val_accuracy: 0.8418\n",
      "Epoch 405/500\n",
      "477/477 [==============================] - 1s 1ms/step - loss: 0.4588 - accuracy: 0.8232 - val_loss: 0.4250 - val_accuracy: 0.8380\n",
      "Epoch 406/500\n",
      "477/477 [==============================] - 1s 1ms/step - loss: 0.4581 - accuracy: 0.8234 - val_loss: 0.4257 - val_accuracy: 0.8378\n",
      "Epoch 407/500\n",
      "477/477 [==============================] - 1s 1ms/step - loss: 0.4618 - accuracy: 0.8223 - val_loss: 0.4227 - val_accuracy: 0.8420\n",
      "Epoch 408/500\n",
      "477/477 [==============================] - 1s 1ms/step - loss: 0.4573 - accuracy: 0.8234 - val_loss: 0.4223 - val_accuracy: 0.8413\n",
      "Epoch 409/500\n",
      "477/477 [==============================] - 1s 1ms/step - loss: 0.4591 - accuracy: 0.8232 - val_loss: 0.4222 - val_accuracy: 0.8405\n",
      "Epoch 410/500\n",
      "477/477 [==============================] - 1s 1ms/step - loss: 0.4589 - accuracy: 0.8231 - val_loss: 0.4242 - val_accuracy: 0.8425\n",
      "Epoch 411/500\n",
      "477/477 [==============================] - 1s 1ms/step - loss: 0.4579 - accuracy: 0.8230 - val_loss: 0.4254 - val_accuracy: 0.8422\n",
      "Epoch 412/500\n",
      "477/477 [==============================] - 1s 1ms/step - loss: 0.4589 - accuracy: 0.8223 - val_loss: 0.4269 - val_accuracy: 0.8390\n",
      "Epoch 413/500\n",
      "477/477 [==============================] - 1s 1ms/step - loss: 0.4601 - accuracy: 0.8234 - val_loss: 0.4256 - val_accuracy: 0.8387\n",
      "Epoch 414/500\n",
      "477/477 [==============================] - 1s 1ms/step - loss: 0.4575 - accuracy: 0.8232 - val_loss: 0.4238 - val_accuracy: 0.8407\n",
      "Epoch 415/500\n",
      "477/477 [==============================] - 1s 1ms/step - loss: 0.4577 - accuracy: 0.8234 - val_loss: 0.4230 - val_accuracy: 0.8420\n",
      "Epoch 416/500\n",
      "477/477 [==============================] - 1s 1ms/step - loss: 0.4586 - accuracy: 0.8237 - val_loss: 0.4238 - val_accuracy: 0.8390\n",
      "Epoch 417/500\n",
      "477/477 [==============================] - 1s 1ms/step - loss: 0.4591 - accuracy: 0.8233 - val_loss: 0.4218 - val_accuracy: 0.8448\n",
      "Epoch 418/500\n",
      "477/477 [==============================] - 1s 1ms/step - loss: 0.4597 - accuracy: 0.8230 - val_loss: 0.4242 - val_accuracy: 0.8413\n",
      "Epoch 419/500\n",
      "477/477 [==============================] - 1s 1ms/step - loss: 0.4576 - accuracy: 0.8224 - val_loss: 0.4267 - val_accuracy: 0.8406\n",
      "Epoch 420/500\n",
      "477/477 [==============================] - 1s 1ms/step - loss: 0.4581 - accuracy: 0.8222 - val_loss: 0.4244 - val_accuracy: 0.8423\n",
      "Epoch 421/500\n",
      "477/477 [==============================] - 1s 1ms/step - loss: 0.4607 - accuracy: 0.8216 - val_loss: 0.4231 - val_accuracy: 0.8444\n",
      "Epoch 422/500\n",
      "477/477 [==============================] - 1s 1ms/step - loss: 0.4588 - accuracy: 0.8221 - val_loss: 0.4216 - val_accuracy: 0.8434\n",
      "Epoch 423/500\n",
      "477/477 [==============================] - 1s 1ms/step - loss: 0.4574 - accuracy: 0.8230 - val_loss: 0.4247 - val_accuracy: 0.8434\n",
      "Epoch 424/500\n",
      "477/477 [==============================] - 1s 1ms/step - loss: 0.4598 - accuracy: 0.8222 - val_loss: 0.4230 - val_accuracy: 0.8424\n",
      "Epoch 425/500\n",
      "477/477 [==============================] - 1s 1ms/step - loss: 0.4587 - accuracy: 0.8233 - val_loss: 0.4242 - val_accuracy: 0.8437\n",
      "Epoch 426/500\n",
      "477/477 [==============================] - 1s 1ms/step - loss: 0.4577 - accuracy: 0.8242 - val_loss: 0.4226 - val_accuracy: 0.8425\n",
      "Epoch 427/500\n",
      "477/477 [==============================] - 1s 1ms/step - loss: 0.4599 - accuracy: 0.8224 - val_loss: 0.4220 - val_accuracy: 0.8458\n",
      "Epoch 428/500\n",
      "477/477 [==============================] - 1s 1ms/step - loss: 0.4597 - accuracy: 0.8232 - val_loss: 0.4245 - val_accuracy: 0.8442\n",
      "Epoch 429/500\n",
      "477/477 [==============================] - 1s 1ms/step - loss: 0.4570 - accuracy: 0.8238 - val_loss: 0.4250 - val_accuracy: 0.8416\n",
      "Epoch 430/500\n",
      "477/477 [==============================] - 1s 1ms/step - loss: 0.4583 - accuracy: 0.8229 - val_loss: 0.4255 - val_accuracy: 0.8396\n",
      "Epoch 431/500\n",
      "477/477 [==============================] - 1s 1ms/step - loss: 0.4584 - accuracy: 0.8221 - val_loss: 0.4218 - val_accuracy: 0.8422\n",
      "Epoch 432/500\n",
      "477/477 [==============================] - 1s 1ms/step - loss: 0.4584 - accuracy: 0.8230 - val_loss: 0.4229 - val_accuracy: 0.8417\n",
      "Epoch 433/500\n",
      "477/477 [==============================] - 1s 1ms/step - loss: 0.4590 - accuracy: 0.8239 - val_loss: 0.4214 - val_accuracy: 0.8426\n",
      "Epoch 434/500\n",
      "477/477 [==============================] - 1s 1ms/step - loss: 0.4595 - accuracy: 0.8224 - val_loss: 0.4210 - val_accuracy: 0.8439\n",
      "Epoch 435/500\n",
      "477/477 [==============================] - 1s 1ms/step - loss: 0.4589 - accuracy: 0.8224 - val_loss: 0.4228 - val_accuracy: 0.8452\n",
      "Epoch 436/500\n",
      "477/477 [==============================] - 1s 1ms/step - loss: 0.4581 - accuracy: 0.8244 - val_loss: 0.4247 - val_accuracy: 0.8403\n",
      "Epoch 437/500\n",
      "477/477 [==============================] - 1s 1ms/step - loss: 0.4576 - accuracy: 0.8236 - val_loss: 0.4205 - val_accuracy: 0.8433\n",
      "Epoch 438/500\n",
      "477/477 [==============================] - 1s 1ms/step - loss: 0.4582 - accuracy: 0.8239 - val_loss: 0.4216 - val_accuracy: 0.8433\n",
      "Epoch 439/500\n",
      "477/477 [==============================] - 1s 1ms/step - loss: 0.4560 - accuracy: 0.8236 - val_loss: 0.4208 - val_accuracy: 0.8418\n",
      "Epoch 440/500\n",
      "477/477 [==============================] - 1s 1ms/step - loss: 0.4572 - accuracy: 0.8230 - val_loss: 0.4213 - val_accuracy: 0.8414\n",
      "Epoch 441/500\n",
      "477/477 [==============================] - 1s 1ms/step - loss: 0.4589 - accuracy: 0.8236 - val_loss: 0.4234 - val_accuracy: 0.8406\n",
      "Epoch 442/500\n",
      "477/477 [==============================] - 1s 1ms/step - loss: 0.4566 - accuracy: 0.8238 - val_loss: 0.4207 - val_accuracy: 0.8441\n",
      "Epoch 443/500\n",
      "477/477 [==============================] - 1s 1ms/step - loss: 0.4560 - accuracy: 0.8239 - val_loss: 0.4215 - val_accuracy: 0.8416\n",
      "Epoch 444/500\n",
      "477/477 [==============================] - 1s 1ms/step - loss: 0.4555 - accuracy: 0.8238 - val_loss: 0.4265 - val_accuracy: 0.8392\n",
      "Epoch 444: early stopping\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "<keras.src.callbacks.History at 0x1439b7c40>"
      ]
     },
     "execution_count": 62,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# batch size=256\n",
    "model=Sequential()\n",
    "model.add(Dense(128, input_dim=X_train.shape[1], activation=\"relu\"))\n",
    "model.add(Dropout(0.2))\n",
    "model.add(Dense(128, activation=\"relu\"))\n",
    "\n",
    "model.add(Dense(64, activation=\"relu\"))\n",
    "model.add(Dropout(0.2))\n",
    "model.add(Dense(64, activation=\"relu\"))\n",
    "\n",
    "model.add(Dense(32, activation=\"relu\"))\n",
    "model.add(Dropout(0.2))\n",
    "model.add(Dense(16, activation=\"relu\"))\n",
    "model.add(Dropout(0.2))\n",
    "model.add(Dense(3, activation=\"softmax\"))\n",
    "\n",
    "model.compile(loss='categorical_crossentropy', optimizer=Adam(learning_rate=0.001), metrics=['accuracy'])\n",
    "\n",
    "es=EarlyStopping(monitor=\"val_loss\",patience=50,mode=\"auto\",verbose=1)\n",
    "\n",
    "model.fit(X_train,\n",
    "          y_train,\n",
    "          epochs=500,\n",
    "               batch_size=256,\n",
    "               validation_split=0.1,\n",
    "               verbose=1,callbacks=[es])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 63,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "748/748 [==============================] - 0s 252us/step\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0       0.84      0.95      0.89      7973\n",
      "           1       0.83      0.91      0.87      7973\n",
      "           2       0.85      0.66      0.74      7972\n",
      "\n",
      "    accuracy                           0.84     23918\n",
      "   macro avg       0.84      0.84      0.83     23918\n",
      "weighted avg       0.84      0.84      0.83     23918\n",
      "\n"
     ]
    }
   ],
   "source": [
    "y_pred = model.predict(X_test)\n",
    "y_pred_classes = np.argmax(y_pred, axis=1)\n",
    "y_true = np.argmax(y_test, axis=1)\n",
    "print(classification_report(y_true, y_pred_classes))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 64,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "4236/4236 [==============================] - 1s 258us/step\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0       0.86      0.97      0.92     45176\n",
      "           1       0.85      0.94      0.89     45176\n",
      "           2       0.90      0.70      0.78     45177\n",
      "\n",
      "    accuracy                           0.87    135529\n",
      "   macro avg       0.87      0.87      0.86    135529\n",
      "weighted avg       0.87      0.87      0.86    135529\n",
      "\n"
     ]
    }
   ],
   "source": [
    "y_t_pred = model.predict(X_train)\n",
    "y_t_pred_classes = np.argmax(y_t_pred, axis=1)\n",
    "y_t_true = np.argmax(y_train, axis=1)\n",
    "print(classification_report(y_t_true, y_t_pred_classes))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 69,
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 1/1000\n",
      "239/239 [==============================] - 1s 2ms/step - loss: 0.8119 - accuracy: 0.6712 - val_loss: 0.6890 - val_accuracy: 0.7291\n",
      "Epoch 2/1000\n",
      "239/239 [==============================] - 1s 3ms/step - loss: 0.7181 - accuracy: 0.7276 - val_loss: 0.6690 - val_accuracy: 0.7415\n",
      "Epoch 3/1000\n",
      "239/239 [==============================] - 1s 2ms/step - loss: 0.6991 - accuracy: 0.7334 - val_loss: 0.6559 - val_accuracy: 0.7454\n",
      "Epoch 4/1000\n",
      "239/239 [==============================] - 1s 2ms/step - loss: 0.6900 - accuracy: 0.7361 - val_loss: 0.6506 - val_accuracy: 0.7466\n",
      "Epoch 5/1000\n",
      "239/239 [==============================] - 1s 2ms/step - loss: 0.6797 - accuracy: 0.7392 - val_loss: 0.6436 - val_accuracy: 0.7479\n",
      "Epoch 6/1000\n",
      "239/239 [==============================] - 1s 2ms/step - loss: 0.6734 - accuracy: 0.7405 - val_loss: 0.6375 - val_accuracy: 0.7530\n",
      "Epoch 7/1000\n",
      "239/239 [==============================] - 1s 2ms/step - loss: 0.6666 - accuracy: 0.7428 - val_loss: 0.6309 - val_accuracy: 0.7531\n",
      "Epoch 8/1000\n",
      "239/239 [==============================] - 1s 2ms/step - loss: 0.6623 - accuracy: 0.7454 - val_loss: 0.6275 - val_accuracy: 0.7536\n",
      "Epoch 9/1000\n",
      "239/239 [==============================] - 1s 2ms/step - loss: 0.6569 - accuracy: 0.7470 - val_loss: 0.6242 - val_accuracy: 0.7536\n",
      "Epoch 10/1000\n",
      "239/239 [==============================] - 1s 2ms/step - loss: 0.6514 - accuracy: 0.7483 - val_loss: 0.6152 - val_accuracy: 0.7581\n",
      "Epoch 11/1000\n",
      "239/239 [==============================] - 1s 2ms/step - loss: 0.6458 - accuracy: 0.7487 - val_loss: 0.6138 - val_accuracy: 0.7607\n",
      "Epoch 12/1000\n",
      "239/239 [==============================] - 1s 2ms/step - loss: 0.6415 - accuracy: 0.7510 - val_loss: 0.6051 - val_accuracy: 0.7608\n",
      "Epoch 13/1000\n",
      "239/239 [==============================] - 1s 2ms/step - loss: 0.6364 - accuracy: 0.7517 - val_loss: 0.5985 - val_accuracy: 0.7634\n",
      "Epoch 14/1000\n",
      "239/239 [==============================] - 1s 2ms/step - loss: 0.6319 - accuracy: 0.7535 - val_loss: 0.5952 - val_accuracy: 0.7651\n",
      "Epoch 15/1000\n",
      "239/239 [==============================] - 1s 2ms/step - loss: 0.6259 - accuracy: 0.7566 - val_loss: 0.5941 - val_accuracy: 0.7662\n",
      "Epoch 16/1000\n",
      "239/239 [==============================] - 1s 2ms/step - loss: 0.6213 - accuracy: 0.7569 - val_loss: 0.5841 - val_accuracy: 0.7691\n",
      "Epoch 17/1000\n",
      "239/239 [==============================] - 1s 2ms/step - loss: 0.6182 - accuracy: 0.7595 - val_loss: 0.5793 - val_accuracy: 0.7708\n",
      "Epoch 18/1000\n",
      "239/239 [==============================] - 1s 2ms/step - loss: 0.6137 - accuracy: 0.7606 - val_loss: 0.5748 - val_accuracy: 0.7744\n",
      "Epoch 19/1000\n",
      "239/239 [==============================] - 1s 2ms/step - loss: 0.6103 - accuracy: 0.7614 - val_loss: 0.5754 - val_accuracy: 0.7713\n",
      "Epoch 20/1000\n",
      "239/239 [==============================] - 1s 2ms/step - loss: 0.6071 - accuracy: 0.7629 - val_loss: 0.5826 - val_accuracy: 0.7683\n",
      "Epoch 21/1000\n",
      "239/239 [==============================] - 1s 2ms/step - loss: 0.6040 - accuracy: 0.7656 - val_loss: 0.5652 - val_accuracy: 0.7777\n",
      "Epoch 22/1000\n",
      "239/239 [==============================] - 1s 2ms/step - loss: 0.5997 - accuracy: 0.7648 - val_loss: 0.5603 - val_accuracy: 0.7794\n",
      "Epoch 23/1000\n",
      "239/239 [==============================] - 1s 2ms/step - loss: 0.5949 - accuracy: 0.7653 - val_loss: 0.5549 - val_accuracy: 0.7796\n",
      "Epoch 24/1000\n",
      "239/239 [==============================] - 1s 2ms/step - loss: 0.5930 - accuracy: 0.7668 - val_loss: 0.5584 - val_accuracy: 0.7797\n",
      "Epoch 25/1000\n",
      "239/239 [==============================] - 1s 2ms/step - loss: 0.5885 - accuracy: 0.7685 - val_loss: 0.5499 - val_accuracy: 0.7861\n",
      "Epoch 26/1000\n",
      "239/239 [==============================] - 1s 2ms/step - loss: 0.5874 - accuracy: 0.7705 - val_loss: 0.5448 - val_accuracy: 0.7842\n",
      "Epoch 27/1000\n",
      "239/239 [==============================] - 1s 2ms/step - loss: 0.5853 - accuracy: 0.7700 - val_loss: 0.5462 - val_accuracy: 0.7845\n",
      "Epoch 28/1000\n",
      "239/239 [==============================] - 0s 2ms/step - loss: 0.5822 - accuracy: 0.7716 - val_loss: 0.5449 - val_accuracy: 0.7834\n",
      "Epoch 29/1000\n",
      "239/239 [==============================] - 1s 2ms/step - loss: 0.5804 - accuracy: 0.7734 - val_loss: 0.5389 - val_accuracy: 0.7854\n",
      "Epoch 30/1000\n",
      "239/239 [==============================] - 1s 2ms/step - loss: 0.5767 - accuracy: 0.7735 - val_loss: 0.5403 - val_accuracy: 0.7862\n",
      "Epoch 31/1000\n",
      "239/239 [==============================] - 0s 2ms/step - loss: 0.5757 - accuracy: 0.7743 - val_loss: 0.5339 - val_accuracy: 0.7907\n",
      "Epoch 32/1000\n",
      "239/239 [==============================] - 0s 2ms/step - loss: 0.5720 - accuracy: 0.7746 - val_loss: 0.5331 - val_accuracy: 0.7885\n",
      "Epoch 33/1000\n",
      "239/239 [==============================] - 0s 2ms/step - loss: 0.5701 - accuracy: 0.7757 - val_loss: 0.5298 - val_accuracy: 0.7919\n",
      "Epoch 34/1000\n",
      "239/239 [==============================] - 1s 2ms/step - loss: 0.5692 - accuracy: 0.7768 - val_loss: 0.5249 - val_accuracy: 0.7942\n",
      "Epoch 35/1000\n",
      "239/239 [==============================] - 0s 2ms/step - loss: 0.5665 - accuracy: 0.7769 - val_loss: 0.5292 - val_accuracy: 0.7898\n",
      "Epoch 36/1000\n",
      "239/239 [==============================] - 1s 2ms/step - loss: 0.5655 - accuracy: 0.7776 - val_loss: 0.5289 - val_accuracy: 0.7890\n",
      "Epoch 37/1000\n",
      "239/239 [==============================] - 0s 2ms/step - loss: 0.5638 - accuracy: 0.7784 - val_loss: 0.5251 - val_accuracy: 0.7937\n",
      "Epoch 38/1000\n",
      "239/239 [==============================] - 0s 2ms/step - loss: 0.5626 - accuracy: 0.7791 - val_loss: 0.5250 - val_accuracy: 0.7919\n",
      "Epoch 39/1000\n",
      "239/239 [==============================] - 0s 2ms/step - loss: 0.5607 - accuracy: 0.7804 - val_loss: 0.5179 - val_accuracy: 0.7967\n",
      "Epoch 40/1000\n",
      "239/239 [==============================] - 1s 2ms/step - loss: 0.5599 - accuracy: 0.7805 - val_loss: 0.5206 - val_accuracy: 0.7936\n",
      "Epoch 41/1000\n",
      "239/239 [==============================] - 1s 2ms/step - loss: 0.5544 - accuracy: 0.7827 - val_loss: 0.5139 - val_accuracy: 0.7964\n",
      "Epoch 42/1000\n",
      "239/239 [==============================] - 1s 2ms/step - loss: 0.5541 - accuracy: 0.7816 - val_loss: 0.5140 - val_accuracy: 0.7975\n",
      "Epoch 43/1000\n",
      "239/239 [==============================] - 1s 2ms/step - loss: 0.5534 - accuracy: 0.7826 - val_loss: 0.5128 - val_accuracy: 0.7961\n",
      "Epoch 44/1000\n",
      "239/239 [==============================] - 1s 2ms/step - loss: 0.5503 - accuracy: 0.7839 - val_loss: 0.5107 - val_accuracy: 0.7981\n",
      "Epoch 45/1000\n",
      "239/239 [==============================] - 1s 2ms/step - loss: 0.5505 - accuracy: 0.7834 - val_loss: 0.5118 - val_accuracy: 0.7987\n",
      "Epoch 46/1000\n",
      "239/239 [==============================] - 0s 2ms/step - loss: 0.5492 - accuracy: 0.7840 - val_loss: 0.5089 - val_accuracy: 0.8012\n",
      "Epoch 47/1000\n",
      "239/239 [==============================] - 0s 2ms/step - loss: 0.5494 - accuracy: 0.7841 - val_loss: 0.5101 - val_accuracy: 0.7988\n",
      "Epoch 48/1000\n",
      "239/239 [==============================] - 0s 2ms/step - loss: 0.5453 - accuracy: 0.7854 - val_loss: 0.5041 - val_accuracy: 0.8004\n",
      "Epoch 49/1000\n",
      "239/239 [==============================] - 1s 2ms/step - loss: 0.5460 - accuracy: 0.7855 - val_loss: 0.5068 - val_accuracy: 0.7994\n",
      "Epoch 50/1000\n",
      "239/239 [==============================] - 1s 2ms/step - loss: 0.5452 - accuracy: 0.7857 - val_loss: 0.5029 - val_accuracy: 0.8034\n",
      "Epoch 51/1000\n",
      "239/239 [==============================] - 0s 2ms/step - loss: 0.5452 - accuracy: 0.7864 - val_loss: 0.5033 - val_accuracy: 0.8031\n",
      "Epoch 52/1000\n",
      "239/239 [==============================] - 0s 2ms/step - loss: 0.5415 - accuracy: 0.7884 - val_loss: 0.5016 - val_accuracy: 0.8033\n",
      "Epoch 53/1000\n",
      "239/239 [==============================] - 0s 2ms/step - loss: 0.5413 - accuracy: 0.7873 - val_loss: 0.4977 - val_accuracy: 0.8065\n",
      "Epoch 54/1000\n",
      "239/239 [==============================] - 1s 2ms/step - loss: 0.5397 - accuracy: 0.7883 - val_loss: 0.5002 - val_accuracy: 0.8040\n",
      "Epoch 55/1000\n",
      "239/239 [==============================] - 1s 2ms/step - loss: 0.5407 - accuracy: 0.7883 - val_loss: 0.4980 - val_accuracy: 0.8040\n",
      "Epoch 56/1000\n",
      "239/239 [==============================] - 1s 2ms/step - loss: 0.5380 - accuracy: 0.7885 - val_loss: 0.4978 - val_accuracy: 0.8031\n",
      "Epoch 57/1000\n",
      "239/239 [==============================] - 1s 2ms/step - loss: 0.5379 - accuracy: 0.7888 - val_loss: 0.4937 - val_accuracy: 0.8062\n",
      "Epoch 58/1000\n",
      "239/239 [==============================] - 1s 2ms/step - loss: 0.5360 - accuracy: 0.7897 - val_loss: 0.4987 - val_accuracy: 0.8028\n",
      "Epoch 59/1000\n",
      "239/239 [==============================] - 1s 2ms/step - loss: 0.5359 - accuracy: 0.7900 - val_loss: 0.4944 - val_accuracy: 0.8076\n",
      "Epoch 60/1000\n",
      "239/239 [==============================] - 1s 2ms/step - loss: 0.5322 - accuracy: 0.7903 - val_loss: 0.4947 - val_accuracy: 0.8040\n",
      "Epoch 61/1000\n",
      "239/239 [==============================] - 1s 2ms/step - loss: 0.5318 - accuracy: 0.7917 - val_loss: 0.4940 - val_accuracy: 0.8052\n",
      "Epoch 62/1000\n",
      "239/239 [==============================] - 1s 2ms/step - loss: 0.5315 - accuracy: 0.7912 - val_loss: 0.4928 - val_accuracy: 0.8051\n",
      "Epoch 63/1000\n",
      "239/239 [==============================] - 1s 2ms/step - loss: 0.5317 - accuracy: 0.7914 - val_loss: 0.4947 - val_accuracy: 0.8058\n",
      "Epoch 64/1000\n",
      "239/239 [==============================] - 1s 2ms/step - loss: 0.5336 - accuracy: 0.7908 - val_loss: 0.4917 - val_accuracy: 0.8071\n",
      "Epoch 65/1000\n",
      "239/239 [==============================] - 1s 2ms/step - loss: 0.5301 - accuracy: 0.7918 - val_loss: 0.4940 - val_accuracy: 0.8045\n",
      "Epoch 66/1000\n",
      "239/239 [==============================] - 0s 2ms/step - loss: 0.5312 - accuracy: 0.7912 - val_loss: 0.4909 - val_accuracy: 0.8077\n",
      "Epoch 67/1000\n",
      "239/239 [==============================] - 1s 2ms/step - loss: 0.5266 - accuracy: 0.7934 - val_loss: 0.4861 - val_accuracy: 0.8097\n",
      "Epoch 68/1000\n",
      "239/239 [==============================] - 1s 2ms/step - loss: 0.5275 - accuracy: 0.7928 - val_loss: 0.4891 - val_accuracy: 0.8081\n",
      "Epoch 69/1000\n",
      "239/239 [==============================] - 1s 2ms/step - loss: 0.5268 - accuracy: 0.7929 - val_loss: 0.4862 - val_accuracy: 0.8110\n",
      "Epoch 70/1000\n",
      "239/239 [==============================] - 0s 2ms/step - loss: 0.5280 - accuracy: 0.7928 - val_loss: 0.4851 - val_accuracy: 0.8106\n",
      "Epoch 71/1000\n",
      "239/239 [==============================] - 0s 2ms/step - loss: 0.5256 - accuracy: 0.7943 - val_loss: 0.4856 - val_accuracy: 0.8095\n",
      "Epoch 72/1000\n",
      "239/239 [==============================] - 1s 2ms/step - loss: 0.5243 - accuracy: 0.7944 - val_loss: 0.4852 - val_accuracy: 0.8090\n",
      "Epoch 73/1000\n",
      "239/239 [==============================] - 0s 2ms/step - loss: 0.5225 - accuracy: 0.7953 - val_loss: 0.4868 - val_accuracy: 0.8059\n",
      "Epoch 74/1000\n",
      "239/239 [==============================] - 0s 2ms/step - loss: 0.5241 - accuracy: 0.7940 - val_loss: 0.4839 - val_accuracy: 0.8111\n",
      "Epoch 75/1000\n",
      "239/239 [==============================] - 0s 2ms/step - loss: 0.5224 - accuracy: 0.7946 - val_loss: 0.4812 - val_accuracy: 0.8129\n",
      "Epoch 76/1000\n",
      "239/239 [==============================] - 1s 2ms/step - loss: 0.5227 - accuracy: 0.7938 - val_loss: 0.4830 - val_accuracy: 0.8114\n",
      "Epoch 77/1000\n",
      "239/239 [==============================] - 1s 2ms/step - loss: 0.5216 - accuracy: 0.7954 - val_loss: 0.4868 - val_accuracy: 0.8073\n",
      "Epoch 78/1000\n",
      "239/239 [==============================] - 1s 2ms/step - loss: 0.5199 - accuracy: 0.7965 - val_loss: 0.4822 - val_accuracy: 0.8116\n",
      "Epoch 79/1000\n",
      "239/239 [==============================] - 1s 2ms/step - loss: 0.5209 - accuracy: 0.7944 - val_loss: 0.4817 - val_accuracy: 0.8126\n",
      "Epoch 80/1000\n",
      "239/239 [==============================] - 1s 2ms/step - loss: 0.5203 - accuracy: 0.7954 - val_loss: 0.4789 - val_accuracy: 0.8142\n",
      "Epoch 81/1000\n",
      "239/239 [==============================] - 1s 2ms/step - loss: 0.5185 - accuracy: 0.7953 - val_loss: 0.4799 - val_accuracy: 0.8128\n",
      "Epoch 82/1000\n",
      "239/239 [==============================] - 0s 2ms/step - loss: 0.5185 - accuracy: 0.7967 - val_loss: 0.4773 - val_accuracy: 0.8152\n",
      "Epoch 83/1000\n",
      "239/239 [==============================] - 0s 2ms/step - loss: 0.5196 - accuracy: 0.7958 - val_loss: 0.4766 - val_accuracy: 0.8152\n",
      "Epoch 84/1000\n",
      "239/239 [==============================] - 0s 2ms/step - loss: 0.5166 - accuracy: 0.7967 - val_loss: 0.4779 - val_accuracy: 0.8129\n",
      "Epoch 85/1000\n",
      "239/239 [==============================] - 0s 2ms/step - loss: 0.5159 - accuracy: 0.7975 - val_loss: 0.4754 - val_accuracy: 0.8148\n",
      "Epoch 86/1000\n",
      "239/239 [==============================] - 0s 2ms/step - loss: 0.5167 - accuracy: 0.7964 - val_loss: 0.4731 - val_accuracy: 0.8165\n",
      "Epoch 87/1000\n",
      "239/239 [==============================] - 1s 2ms/step - loss: 0.5151 - accuracy: 0.7969 - val_loss: 0.4805 - val_accuracy: 0.8133\n",
      "Epoch 88/1000\n",
      "239/239 [==============================] - 1s 2ms/step - loss: 0.5168 - accuracy: 0.7965 - val_loss: 0.4761 - val_accuracy: 0.8154\n",
      "Epoch 89/1000\n",
      "239/239 [==============================] - 1s 2ms/step - loss: 0.5137 - accuracy: 0.7983 - val_loss: 0.4753 - val_accuracy: 0.8147\n",
      "Epoch 90/1000\n",
      "239/239 [==============================] - 0s 2ms/step - loss: 0.5135 - accuracy: 0.7979 - val_loss: 0.4728 - val_accuracy: 0.8166\n",
      "Epoch 91/1000\n",
      "239/239 [==============================] - 1s 2ms/step - loss: 0.5151 - accuracy: 0.7986 - val_loss: 0.4735 - val_accuracy: 0.8158\n",
      "Epoch 92/1000\n",
      "239/239 [==============================] - 0s 2ms/step - loss: 0.5127 - accuracy: 0.7998 - val_loss: 0.4747 - val_accuracy: 0.8126\n",
      "Epoch 93/1000\n",
      "239/239 [==============================] - 1s 2ms/step - loss: 0.5127 - accuracy: 0.7996 - val_loss: 0.4736 - val_accuracy: 0.8155\n",
      "Epoch 94/1000\n",
      "239/239 [==============================] - 1s 2ms/step - loss: 0.5133 - accuracy: 0.7981 - val_loss: 0.4719 - val_accuracy: 0.8180\n",
      "Epoch 95/1000\n",
      "239/239 [==============================] - 1s 2ms/step - loss: 0.5100 - accuracy: 0.8000 - val_loss: 0.4715 - val_accuracy: 0.8175\n",
      "Epoch 96/1000\n",
      "239/239 [==============================] - 1s 2ms/step - loss: 0.5109 - accuracy: 0.8008 - val_loss: 0.4718 - val_accuracy: 0.8164\n",
      "Epoch 97/1000\n",
      "239/239 [==============================] - 1s 2ms/step - loss: 0.5097 - accuracy: 0.8004 - val_loss: 0.4699 - val_accuracy: 0.8158\n",
      "Epoch 98/1000\n",
      "239/239 [==============================] - 0s 2ms/step - loss: 0.5094 - accuracy: 0.7999 - val_loss: 0.4695 - val_accuracy: 0.8145\n",
      "Epoch 99/1000\n",
      "239/239 [==============================] - 1s 2ms/step - loss: 0.5095 - accuracy: 0.8006 - val_loss: 0.4693 - val_accuracy: 0.8155\n",
      "Epoch 100/1000\n",
      "239/239 [==============================] - 1s 2ms/step - loss: 0.5072 - accuracy: 0.8013 - val_loss: 0.4676 - val_accuracy: 0.8156\n",
      "Epoch 101/1000\n",
      "239/239 [==============================] - 0s 2ms/step - loss: 0.5086 - accuracy: 0.8013 - val_loss: 0.4725 - val_accuracy: 0.8157\n",
      "Epoch 102/1000\n",
      "239/239 [==============================] - 0s 2ms/step - loss: 0.5086 - accuracy: 0.8009 - val_loss: 0.4680 - val_accuracy: 0.8175\n",
      "Epoch 103/1000\n",
      "239/239 [==============================] - 0s 2ms/step - loss: 0.5070 - accuracy: 0.8013 - val_loss: 0.4649 - val_accuracy: 0.8193\n",
      "Epoch 104/1000\n",
      "239/239 [==============================] - 1s 2ms/step - loss: 0.5078 - accuracy: 0.8015 - val_loss: 0.4670 - val_accuracy: 0.8175\n",
      "Epoch 105/1000\n",
      "239/239 [==============================] - 0s 2ms/step - loss: 0.5054 - accuracy: 0.8014 - val_loss: 0.4653 - val_accuracy: 0.8185\n",
      "Epoch 106/1000\n",
      "239/239 [==============================] - 1s 2ms/step - loss: 0.5069 - accuracy: 0.8013 - val_loss: 0.4634 - val_accuracy: 0.8193\n",
      "Epoch 107/1000\n",
      "239/239 [==============================] - 1s 2ms/step - loss: 0.5061 - accuracy: 0.8016 - val_loss: 0.4705 - val_accuracy: 0.8170\n",
      "Epoch 108/1000\n",
      "239/239 [==============================] - 1s 2ms/step - loss: 0.5049 - accuracy: 0.8016 - val_loss: 0.4673 - val_accuracy: 0.8177\n",
      "Epoch 109/1000\n",
      "239/239 [==============================] - 1s 2ms/step - loss: 0.5051 - accuracy: 0.8025 - val_loss: 0.4631 - val_accuracy: 0.8204\n",
      "Epoch 110/1000\n",
      "239/239 [==============================] - 1s 2ms/step - loss: 0.5048 - accuracy: 0.8021 - val_loss: 0.4627 - val_accuracy: 0.8198\n",
      "Epoch 111/1000\n",
      "239/239 [==============================] - 1s 2ms/step - loss: 0.5037 - accuracy: 0.8024 - val_loss: 0.4633 - val_accuracy: 0.8196\n",
      "Epoch 112/1000\n",
      "239/239 [==============================] - 1s 2ms/step - loss: 0.5049 - accuracy: 0.8027 - val_loss: 0.4654 - val_accuracy: 0.8185\n",
      "Epoch 113/1000\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "239/239 [==============================] - 1s 2ms/step - loss: 0.5052 - accuracy: 0.8037 - val_loss: 0.4618 - val_accuracy: 0.8204\n",
      "Epoch 114/1000\n",
      "239/239 [==============================] - 1s 2ms/step - loss: 0.5036 - accuracy: 0.8033 - val_loss: 0.4641 - val_accuracy: 0.8205\n",
      "Epoch 115/1000\n",
      "239/239 [==============================] - 1s 2ms/step - loss: 0.5024 - accuracy: 0.8027 - val_loss: 0.4603 - val_accuracy: 0.8214\n",
      "Epoch 116/1000\n",
      "239/239 [==============================] - 1s 2ms/step - loss: 0.5038 - accuracy: 0.8038 - val_loss: 0.4552 - val_accuracy: 0.8214\n",
      "Epoch 117/1000\n",
      "239/239 [==============================] - 1s 2ms/step - loss: 0.5028 - accuracy: 0.8045 - val_loss: 0.4621 - val_accuracy: 0.8207\n",
      "Epoch 118/1000\n",
      "239/239 [==============================] - 1s 2ms/step - loss: 0.5018 - accuracy: 0.8042 - val_loss: 0.4585 - val_accuracy: 0.8190\n",
      "Epoch 119/1000\n",
      "239/239 [==============================] - 0s 2ms/step - loss: 0.5010 - accuracy: 0.8040 - val_loss: 0.4611 - val_accuracy: 0.8193\n",
      "Epoch 120/1000\n",
      "239/239 [==============================] - 1s 2ms/step - loss: 0.5021 - accuracy: 0.8045 - val_loss: 0.4589 - val_accuracy: 0.8213\n",
      "Epoch 121/1000\n",
      "239/239 [==============================] - 1s 2ms/step - loss: 0.4995 - accuracy: 0.8040 - val_loss: 0.4581 - val_accuracy: 0.8233\n",
      "Epoch 122/1000\n",
      "239/239 [==============================] - 1s 2ms/step - loss: 0.4995 - accuracy: 0.8039 - val_loss: 0.4580 - val_accuracy: 0.8229\n",
      "Epoch 123/1000\n",
      "239/239 [==============================] - 0s 2ms/step - loss: 0.4992 - accuracy: 0.8053 - val_loss: 0.4592 - val_accuracy: 0.8198\n",
      "Epoch 124/1000\n",
      "239/239 [==============================] - 1s 2ms/step - loss: 0.5008 - accuracy: 0.8041 - val_loss: 0.4589 - val_accuracy: 0.8214\n",
      "Epoch 125/1000\n",
      "239/239 [==============================] - 1s 2ms/step - loss: 0.4991 - accuracy: 0.8041 - val_loss: 0.4574 - val_accuracy: 0.8224\n",
      "Epoch 126/1000\n",
      "239/239 [==============================] - 1s 2ms/step - loss: 0.5008 - accuracy: 0.8047 - val_loss: 0.4588 - val_accuracy: 0.8209\n",
      "Epoch 127/1000\n",
      "239/239 [==============================] - 1s 2ms/step - loss: 0.4995 - accuracy: 0.8050 - val_loss: 0.4564 - val_accuracy: 0.8223\n",
      "Epoch 128/1000\n",
      "239/239 [==============================] - 1s 2ms/step - loss: 0.4986 - accuracy: 0.8057 - val_loss: 0.4603 - val_accuracy: 0.8200\n",
      "Epoch 129/1000\n",
      "239/239 [==============================] - 1s 2ms/step - loss: 0.4984 - accuracy: 0.8049 - val_loss: 0.4570 - val_accuracy: 0.8217\n",
      "Epoch 130/1000\n",
      "239/239 [==============================] - 1s 2ms/step - loss: 0.4985 - accuracy: 0.8056 - val_loss: 0.4571 - val_accuracy: 0.8235\n",
      "Epoch 131/1000\n",
      "239/239 [==============================] - 1s 2ms/step - loss: 0.4973 - accuracy: 0.8067 - val_loss: 0.4546 - val_accuracy: 0.8218\n",
      "Epoch 132/1000\n",
      "239/239 [==============================] - 0s 2ms/step - loss: 0.4964 - accuracy: 0.8064 - val_loss: 0.4561 - val_accuracy: 0.8198\n",
      "Epoch 133/1000\n",
      "239/239 [==============================] - 1s 2ms/step - loss: 0.4946 - accuracy: 0.8075 - val_loss: 0.4559 - val_accuracy: 0.8217\n",
      "Epoch 134/1000\n",
      "239/239 [==============================] - 1s 2ms/step - loss: 0.4955 - accuracy: 0.8066 - val_loss: 0.4552 - val_accuracy: 0.8228\n",
      "Epoch 135/1000\n",
      "239/239 [==============================] - 1s 2ms/step - loss: 0.4963 - accuracy: 0.8061 - val_loss: 0.4541 - val_accuracy: 0.8244\n",
      "Epoch 136/1000\n",
      "239/239 [==============================] - 0s 2ms/step - loss: 0.4946 - accuracy: 0.8067 - val_loss: 0.4554 - val_accuracy: 0.8233\n",
      "Epoch 137/1000\n",
      "239/239 [==============================] - 0s 2ms/step - loss: 0.4959 - accuracy: 0.8070 - val_loss: 0.4560 - val_accuracy: 0.8226\n",
      "Epoch 138/1000\n",
      "239/239 [==============================] - 1s 2ms/step - loss: 0.4958 - accuracy: 0.8065 - val_loss: 0.4527 - val_accuracy: 0.8240\n",
      "Epoch 139/1000\n",
      "239/239 [==============================] - 1s 2ms/step - loss: 0.4970 - accuracy: 0.8045 - val_loss: 0.4535 - val_accuracy: 0.8267\n",
      "Epoch 140/1000\n",
      "239/239 [==============================] - 0s 2ms/step - loss: 0.4944 - accuracy: 0.8066 - val_loss: 0.4527 - val_accuracy: 0.8262\n",
      "Epoch 141/1000\n",
      "239/239 [==============================] - 1s 2ms/step - loss: 0.4934 - accuracy: 0.8061 - val_loss: 0.4549 - val_accuracy: 0.8240\n",
      "Epoch 142/1000\n",
      "239/239 [==============================] - 1s 2ms/step - loss: 0.4924 - accuracy: 0.8080 - val_loss: 0.4537 - val_accuracy: 0.8244\n",
      "Epoch 143/1000\n",
      "239/239 [==============================] - 0s 2ms/step - loss: 0.4929 - accuracy: 0.8067 - val_loss: 0.4548 - val_accuracy: 0.8251\n",
      "Epoch 144/1000\n",
      "239/239 [==============================] - 1s 2ms/step - loss: 0.4927 - accuracy: 0.8062 - val_loss: 0.4499 - val_accuracy: 0.8282\n",
      "Epoch 145/1000\n",
      "239/239 [==============================] - 1s 2ms/step - loss: 0.4928 - accuracy: 0.8086 - val_loss: 0.4512 - val_accuracy: 0.8249\n",
      "Epoch 146/1000\n",
      "239/239 [==============================] - 0s 2ms/step - loss: 0.4935 - accuracy: 0.8079 - val_loss: 0.4507 - val_accuracy: 0.8276\n",
      "Epoch 147/1000\n",
      "239/239 [==============================] - 0s 2ms/step - loss: 0.4939 - accuracy: 0.8085 - val_loss: 0.4530 - val_accuracy: 0.8271\n",
      "Epoch 148/1000\n",
      "239/239 [==============================] - 1s 2ms/step - loss: 0.4927 - accuracy: 0.8079 - val_loss: 0.4493 - val_accuracy: 0.8273\n",
      "Epoch 149/1000\n",
      "239/239 [==============================] - 1s 2ms/step - loss: 0.4906 - accuracy: 0.8078 - val_loss: 0.4509 - val_accuracy: 0.8252\n",
      "Epoch 150/1000\n",
      "239/239 [==============================] - 1s 2ms/step - loss: 0.4918 - accuracy: 0.8081 - val_loss: 0.4492 - val_accuracy: 0.8264\n",
      "Epoch 151/1000\n",
      "239/239 [==============================] - 1s 2ms/step - loss: 0.4906 - accuracy: 0.8100 - val_loss: 0.4501 - val_accuracy: 0.8256\n",
      "Epoch 152/1000\n",
      "239/239 [==============================] - 1s 2ms/step - loss: 0.4924 - accuracy: 0.8076 - val_loss: 0.4560 - val_accuracy: 0.8226\n",
      "Epoch 153/1000\n",
      "239/239 [==============================] - 1s 2ms/step - loss: 0.4917 - accuracy: 0.8088 - val_loss: 0.4562 - val_accuracy: 0.8223\n",
      "Epoch 154/1000\n",
      "239/239 [==============================] - 1s 2ms/step - loss: 0.4904 - accuracy: 0.8083 - val_loss: 0.4521 - val_accuracy: 0.8264\n",
      "Epoch 155/1000\n",
      "239/239 [==============================] - 1s 2ms/step - loss: 0.4916 - accuracy: 0.8068 - val_loss: 0.4495 - val_accuracy: 0.8284\n",
      "Epoch 156/1000\n",
      "239/239 [==============================] - 1s 2ms/step - loss: 0.4919 - accuracy: 0.8078 - val_loss: 0.4509 - val_accuracy: 0.8259\n",
      "Epoch 157/1000\n",
      "239/239 [==============================] - 0s 2ms/step - loss: 0.4896 - accuracy: 0.8091 - val_loss: 0.4513 - val_accuracy: 0.8256\n",
      "Epoch 158/1000\n",
      "239/239 [==============================] - 0s 2ms/step - loss: 0.4881 - accuracy: 0.8104 - val_loss: 0.4485 - val_accuracy: 0.8279\n",
      "Epoch 159/1000\n",
      "239/239 [==============================] - 0s 2ms/step - loss: 0.4887 - accuracy: 0.8091 - val_loss: 0.4490 - val_accuracy: 0.8254\n",
      "Epoch 160/1000\n",
      "239/239 [==============================] - 1s 2ms/step - loss: 0.4879 - accuracy: 0.8093 - val_loss: 0.4474 - val_accuracy: 0.8274\n",
      "Epoch 161/1000\n",
      "239/239 [==============================] - 1s 2ms/step - loss: 0.4887 - accuracy: 0.8103 - val_loss: 0.4480 - val_accuracy: 0.8289\n",
      "Epoch 162/1000\n",
      "239/239 [==============================] - 1s 3ms/step - loss: 0.4928 - accuracy: 0.8090 - val_loss: 0.4488 - val_accuracy: 0.8274\n",
      "Epoch 163/1000\n",
      "239/239 [==============================] - 1s 2ms/step - loss: 0.4890 - accuracy: 0.8099 - val_loss: 0.4471 - val_accuracy: 0.8272\n",
      "Epoch 164/1000\n",
      "239/239 [==============================] - 1s 2ms/step - loss: 0.4884 - accuracy: 0.8092 - val_loss: 0.4497 - val_accuracy: 0.8259\n",
      "Epoch 165/1000\n",
      "239/239 [==============================] - 1s 2ms/step - loss: 0.4892 - accuracy: 0.8089 - val_loss: 0.4466 - val_accuracy: 0.8270\n",
      "Epoch 166/1000\n",
      "239/239 [==============================] - 1s 2ms/step - loss: 0.4899 - accuracy: 0.8094 - val_loss: 0.4463 - val_accuracy: 0.8279\n",
      "Epoch 167/1000\n",
      "239/239 [==============================] - 1s 2ms/step - loss: 0.4867 - accuracy: 0.8101 - val_loss: 0.4479 - val_accuracy: 0.8270\n",
      "Epoch 168/1000\n",
      "239/239 [==============================] - 1s 2ms/step - loss: 0.4879 - accuracy: 0.8108 - val_loss: 0.4478 - val_accuracy: 0.8272\n",
      "Epoch 169/1000\n",
      "239/239 [==============================] - 0s 2ms/step - loss: 0.4863 - accuracy: 0.8109 - val_loss: 0.4452 - val_accuracy: 0.8276\n",
      "Epoch 170/1000\n",
      "239/239 [==============================] - 0s 2ms/step - loss: 0.4869 - accuracy: 0.8095 - val_loss: 0.4474 - val_accuracy: 0.8278\n",
      "Epoch 171/1000\n",
      "239/239 [==============================] - 0s 2ms/step - loss: 0.4861 - accuracy: 0.8112 - val_loss: 0.4477 - val_accuracy: 0.8277\n",
      "Epoch 172/1000\n",
      "239/239 [==============================] - 0s 2ms/step - loss: 0.4874 - accuracy: 0.8097 - val_loss: 0.4466 - val_accuracy: 0.8273\n",
      "Epoch 173/1000\n",
      "239/239 [==============================] - 0s 2ms/step - loss: 0.4867 - accuracy: 0.8109 - val_loss: 0.4499 - val_accuracy: 0.8254\n",
      "Epoch 174/1000\n",
      "239/239 [==============================] - 0s 2ms/step - loss: 0.4889 - accuracy: 0.8099 - val_loss: 0.4462 - val_accuracy: 0.8287\n",
      "Epoch 175/1000\n",
      "239/239 [==============================] - 0s 2ms/step - loss: 0.4854 - accuracy: 0.8101 - val_loss: 0.4461 - val_accuracy: 0.8251\n",
      "Epoch 176/1000\n",
      "239/239 [==============================] - 1s 2ms/step - loss: 0.4845 - accuracy: 0.8113 - val_loss: 0.4460 - val_accuracy: 0.8271\n",
      "Epoch 177/1000\n",
      "239/239 [==============================] - 1s 2ms/step - loss: 0.4864 - accuracy: 0.8103 - val_loss: 0.4475 - val_accuracy: 0.8271\n",
      "Epoch 178/1000\n",
      "239/239 [==============================] - 1s 2ms/step - loss: 0.4840 - accuracy: 0.8124 - val_loss: 0.4496 - val_accuracy: 0.8275\n",
      "Epoch 179/1000\n",
      "239/239 [==============================] - 1s 2ms/step - loss: 0.4851 - accuracy: 0.8116 - val_loss: 0.4449 - val_accuracy: 0.8282\n",
      "Epoch 180/1000\n",
      "239/239 [==============================] - 1s 2ms/step - loss: 0.4855 - accuracy: 0.8109 - val_loss: 0.4424 - val_accuracy: 0.8296\n",
      "Epoch 181/1000\n",
      "239/239 [==============================] - 1s 2ms/step - loss: 0.4855 - accuracy: 0.8114 - val_loss: 0.4421 - val_accuracy: 0.8301\n",
      "Epoch 182/1000\n",
      "239/239 [==============================] - 1s 2ms/step - loss: 0.4863 - accuracy: 0.8114 - val_loss: 0.4477 - val_accuracy: 0.8262\n",
      "Epoch 183/1000\n",
      "239/239 [==============================] - 1s 2ms/step - loss: 0.4836 - accuracy: 0.8114 - val_loss: 0.4493 - val_accuracy: 0.8279\n",
      "Epoch 184/1000\n",
      "239/239 [==============================] - 1s 2ms/step - loss: 0.4839 - accuracy: 0.8123 - val_loss: 0.4434 - val_accuracy: 0.8287\n",
      "Epoch 185/1000\n",
      "239/239 [==============================] - 1s 2ms/step - loss: 0.4843 - accuracy: 0.8102 - val_loss: 0.4438 - val_accuracy: 0.8270\n",
      "Epoch 186/1000\n",
      "239/239 [==============================] - 1s 2ms/step - loss: 0.4855 - accuracy: 0.8116 - val_loss: 0.4424 - val_accuracy: 0.8293\n",
      "Epoch 187/1000\n",
      "239/239 [==============================] - 1s 2ms/step - loss: 0.4836 - accuracy: 0.8121 - val_loss: 0.4449 - val_accuracy: 0.8274\n",
      "Epoch 188/1000\n",
      "239/239 [==============================] - 1s 2ms/step - loss: 0.4840 - accuracy: 0.8122 - val_loss: 0.4423 - val_accuracy: 0.8312\n",
      "Epoch 189/1000\n",
      "239/239 [==============================] - 1s 2ms/step - loss: 0.4848 - accuracy: 0.8124 - val_loss: 0.4451 - val_accuracy: 0.8299\n",
      "Epoch 190/1000\n",
      "239/239 [==============================] - 1s 2ms/step - loss: 0.4838 - accuracy: 0.8106 - val_loss: 0.4446 - val_accuracy: 0.8303\n",
      "Epoch 191/1000\n",
      "239/239 [==============================] - 0s 2ms/step - loss: 0.4822 - accuracy: 0.8116 - val_loss: 0.4436 - val_accuracy: 0.8301\n",
      "Epoch 192/1000\n",
      "239/239 [==============================] - 1s 2ms/step - loss: 0.4839 - accuracy: 0.8115 - val_loss: 0.4427 - val_accuracy: 0.8307\n",
      "Epoch 193/1000\n",
      "239/239 [==============================] - 1s 2ms/step - loss: 0.4840 - accuracy: 0.8098 - val_loss: 0.4392 - val_accuracy: 0.8309\n",
      "Epoch 194/1000\n",
      "239/239 [==============================] - 1s 2ms/step - loss: 0.4846 - accuracy: 0.8113 - val_loss: 0.4434 - val_accuracy: 0.8310\n",
      "Epoch 195/1000\n",
      "239/239 [==============================] - 0s 2ms/step - loss: 0.4826 - accuracy: 0.8115 - val_loss: 0.4384 - val_accuracy: 0.8310\n",
      "Epoch 196/1000\n",
      "239/239 [==============================] - 1s 2ms/step - loss: 0.4814 - accuracy: 0.8122 - val_loss: 0.4422 - val_accuracy: 0.8298\n",
      "Epoch 197/1000\n",
      "239/239 [==============================] - 1s 2ms/step - loss: 0.4835 - accuracy: 0.8115 - val_loss: 0.4424 - val_accuracy: 0.8304\n",
      "Epoch 198/1000\n",
      "239/239 [==============================] - 0s 2ms/step - loss: 0.4802 - accuracy: 0.8131 - val_loss: 0.4425 - val_accuracy: 0.8290\n",
      "Epoch 199/1000\n",
      "239/239 [==============================] - 1s 2ms/step - loss: 0.4819 - accuracy: 0.8121 - val_loss: 0.4418 - val_accuracy: 0.8304\n",
      "Epoch 200/1000\n",
      "239/239 [==============================] - 1s 2ms/step - loss: 0.4832 - accuracy: 0.8116 - val_loss: 0.4421 - val_accuracy: 0.8280\n",
      "Epoch 201/1000\n",
      "239/239 [==============================] - 1s 2ms/step - loss: 0.4825 - accuracy: 0.8125 - val_loss: 0.4430 - val_accuracy: 0.8303\n",
      "Epoch 202/1000\n",
      "239/239 [==============================] - 1s 2ms/step - loss: 0.4806 - accuracy: 0.8131 - val_loss: 0.4396 - val_accuracy: 0.8318\n",
      "Epoch 203/1000\n",
      "239/239 [==============================] - 1s 2ms/step - loss: 0.4810 - accuracy: 0.8131 - val_loss: 0.4401 - val_accuracy: 0.8294\n",
      "Epoch 204/1000\n",
      "239/239 [==============================] - 1s 2ms/step - loss: 0.4801 - accuracy: 0.8130 - val_loss: 0.4415 - val_accuracy: 0.8288\n",
      "Epoch 205/1000\n",
      "239/239 [==============================] - 1s 2ms/step - loss: 0.4790 - accuracy: 0.8144 - val_loss: 0.4412 - val_accuracy: 0.8290\n",
      "Epoch 206/1000\n",
      "239/239 [==============================] - 1s 2ms/step - loss: 0.4810 - accuracy: 0.8119 - val_loss: 0.4394 - val_accuracy: 0.8303\n",
      "Epoch 207/1000\n",
      "239/239 [==============================] - 1s 2ms/step - loss: 0.4803 - accuracy: 0.8138 - val_loss: 0.4394 - val_accuracy: 0.8288\n",
      "Epoch 208/1000\n",
      "239/239 [==============================] - 1s 2ms/step - loss: 0.4815 - accuracy: 0.8130 - val_loss: 0.4426 - val_accuracy: 0.8292\n",
      "Epoch 209/1000\n",
      "239/239 [==============================] - 1s 2ms/step - loss: 0.4801 - accuracy: 0.8116 - val_loss: 0.4417 - val_accuracy: 0.8301\n",
      "Epoch 210/1000\n",
      "239/239 [==============================] - 1s 2ms/step - loss: 0.4812 - accuracy: 0.8129 - val_loss: 0.4393 - val_accuracy: 0.8317\n",
      "Epoch 211/1000\n",
      "239/239 [==============================] - 1s 2ms/step - loss: 0.4801 - accuracy: 0.8140 - val_loss: 0.4392 - val_accuracy: 0.8313\n",
      "Epoch 212/1000\n",
      "239/239 [==============================] - 0s 2ms/step - loss: 0.4805 - accuracy: 0.8140 - val_loss: 0.4431 - val_accuracy: 0.8310\n",
      "Epoch 213/1000\n",
      "239/239 [==============================] - 1s 2ms/step - loss: 0.4797 - accuracy: 0.8140 - val_loss: 0.4371 - val_accuracy: 0.8324\n",
      "Epoch 214/1000\n",
      "239/239 [==============================] - 1s 2ms/step - loss: 0.4809 - accuracy: 0.8127 - val_loss: 0.4385 - val_accuracy: 0.8306\n",
      "Epoch 215/1000\n",
      "239/239 [==============================] - 1s 2ms/step - loss: 0.4784 - accuracy: 0.8145 - val_loss: 0.4397 - val_accuracy: 0.8334\n",
      "Epoch 216/1000\n",
      "239/239 [==============================] - 0s 2ms/step - loss: 0.4793 - accuracy: 0.8134 - val_loss: 0.4417 - val_accuracy: 0.8287\n",
      "Epoch 217/1000\n",
      "239/239 [==============================] - 0s 2ms/step - loss: 0.4802 - accuracy: 0.8137 - val_loss: 0.4388 - val_accuracy: 0.8327\n",
      "Epoch 218/1000\n",
      "239/239 [==============================] - 0s 2ms/step - loss: 0.4795 - accuracy: 0.8135 - val_loss: 0.4373 - val_accuracy: 0.8305\n",
      "Epoch 219/1000\n",
      "239/239 [==============================] - 1s 2ms/step - loss: 0.4789 - accuracy: 0.8134 - val_loss: 0.4381 - val_accuracy: 0.8308\n",
      "Epoch 220/1000\n",
      "239/239 [==============================] - 1s 2ms/step - loss: 0.4766 - accuracy: 0.8145 - val_loss: 0.4348 - val_accuracy: 0.8346\n",
      "Epoch 221/1000\n",
      "239/239 [==============================] - 1s 2ms/step - loss: 0.4796 - accuracy: 0.8137 - val_loss: 0.4377 - val_accuracy: 0.8304\n",
      "Epoch 222/1000\n",
      "239/239 [==============================] - 1s 2ms/step - loss: 0.4779 - accuracy: 0.8138 - val_loss: 0.4430 - val_accuracy: 0.8295\n",
      "Epoch 223/1000\n",
      "239/239 [==============================] - 1s 2ms/step - loss: 0.4790 - accuracy: 0.8128 - val_loss: 0.4404 - val_accuracy: 0.8311\n",
      "Epoch 224/1000\n",
      "239/239 [==============================] - 1s 2ms/step - loss: 0.4796 - accuracy: 0.8137 - val_loss: 0.4348 - val_accuracy: 0.8331\n",
      "Epoch 225/1000\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "239/239 [==============================] - 1s 2ms/step - loss: 0.4784 - accuracy: 0.8148 - val_loss: 0.4365 - val_accuracy: 0.8343\n",
      "Epoch 226/1000\n",
      "239/239 [==============================] - 1s 2ms/step - loss: 0.4794 - accuracy: 0.8148 - val_loss: 0.4395 - val_accuracy: 0.8321\n",
      "Epoch 227/1000\n",
      "239/239 [==============================] - 1s 2ms/step - loss: 0.4782 - accuracy: 0.8152 - val_loss: 0.4360 - val_accuracy: 0.8331\n",
      "Epoch 228/1000\n",
      "239/239 [==============================] - 0s 2ms/step - loss: 0.4774 - accuracy: 0.8147 - val_loss: 0.4352 - val_accuracy: 0.8350\n",
      "Epoch 229/1000\n",
      "239/239 [==============================] - 1s 2ms/step - loss: 0.4768 - accuracy: 0.8147 - val_loss: 0.4346 - val_accuracy: 0.8340\n",
      "Epoch 230/1000\n",
      "239/239 [==============================] - 1s 2ms/step - loss: 0.4788 - accuracy: 0.8148 - val_loss: 0.4410 - val_accuracy: 0.8298\n",
      "Epoch 231/1000\n",
      "239/239 [==============================] - 1s 2ms/step - loss: 0.4780 - accuracy: 0.8148 - val_loss: 0.4356 - val_accuracy: 0.8332\n",
      "Epoch 232/1000\n",
      "239/239 [==============================] - 1s 2ms/step - loss: 0.4761 - accuracy: 0.8163 - val_loss: 0.4351 - val_accuracy: 0.8336\n",
      "Epoch 233/1000\n",
      "239/239 [==============================] - 1s 2ms/step - loss: 0.4771 - accuracy: 0.8151 - val_loss: 0.4383 - val_accuracy: 0.8303\n",
      "Epoch 234/1000\n",
      "239/239 [==============================] - 0s 2ms/step - loss: 0.4758 - accuracy: 0.8153 - val_loss: 0.4360 - val_accuracy: 0.8330\n",
      "Epoch 235/1000\n",
      "239/239 [==============================] - 1s 2ms/step - loss: 0.4759 - accuracy: 0.8147 - val_loss: 0.4341 - val_accuracy: 0.8330\n",
      "Epoch 236/1000\n",
      "239/239 [==============================] - 0s 2ms/step - loss: 0.4780 - accuracy: 0.8138 - val_loss: 0.4379 - val_accuracy: 0.8310\n",
      "Epoch 237/1000\n",
      "239/239 [==============================] - 1s 2ms/step - loss: 0.4757 - accuracy: 0.8151 - val_loss: 0.4322 - val_accuracy: 0.8361\n",
      "Epoch 238/1000\n",
      "239/239 [==============================] - 0s 2ms/step - loss: 0.4795 - accuracy: 0.8145 - val_loss: 0.4376 - val_accuracy: 0.8310\n",
      "Epoch 239/1000\n",
      "239/239 [==============================] - 1s 2ms/step - loss: 0.4758 - accuracy: 0.8163 - val_loss: 0.4349 - val_accuracy: 0.8335\n",
      "Epoch 240/1000\n",
      "239/239 [==============================] - 1s 2ms/step - loss: 0.4753 - accuracy: 0.8165 - val_loss: 0.4375 - val_accuracy: 0.8314\n",
      "Epoch 241/1000\n",
      "239/239 [==============================] - 1s 2ms/step - loss: 0.4780 - accuracy: 0.8150 - val_loss: 0.4363 - val_accuracy: 0.8338\n",
      "Epoch 242/1000\n",
      "239/239 [==============================] - 1s 2ms/step - loss: 0.4768 - accuracy: 0.8155 - val_loss: 0.4368 - val_accuracy: 0.8334\n",
      "Epoch 243/1000\n",
      "239/239 [==============================] - 1s 2ms/step - loss: 0.4768 - accuracy: 0.8154 - val_loss: 0.4336 - val_accuracy: 0.8359\n",
      "Epoch 244/1000\n",
      "239/239 [==============================] - 1s 2ms/step - loss: 0.4749 - accuracy: 0.8154 - val_loss: 0.4389 - val_accuracy: 0.8315\n",
      "Epoch 245/1000\n",
      "239/239 [==============================] - 1s 2ms/step - loss: 0.4763 - accuracy: 0.8153 - val_loss: 0.4350 - val_accuracy: 0.8344\n",
      "Epoch 246/1000\n",
      "239/239 [==============================] - 1s 2ms/step - loss: 0.4735 - accuracy: 0.8160 - val_loss: 0.4353 - val_accuracy: 0.8344\n",
      "Epoch 247/1000\n",
      "239/239 [==============================] - 1s 2ms/step - loss: 0.4748 - accuracy: 0.8164 - val_loss: 0.4342 - val_accuracy: 0.8359\n",
      "Epoch 248/1000\n",
      "239/239 [==============================] - 0s 2ms/step - loss: 0.4742 - accuracy: 0.8151 - val_loss: 0.4349 - val_accuracy: 0.8305\n",
      "Epoch 249/1000\n",
      "239/239 [==============================] - 0s 2ms/step - loss: 0.4733 - accuracy: 0.8156 - val_loss: 0.4330 - val_accuracy: 0.8346\n",
      "Epoch 250/1000\n",
      "239/239 [==============================] - 0s 2ms/step - loss: 0.4752 - accuracy: 0.8151 - val_loss: 0.4358 - val_accuracy: 0.8320\n",
      "Epoch 251/1000\n",
      "239/239 [==============================] - 0s 2ms/step - loss: 0.4732 - accuracy: 0.8168 - val_loss: 0.4321 - val_accuracy: 0.8368\n",
      "Epoch 252/1000\n",
      "239/239 [==============================] - 0s 2ms/step - loss: 0.4764 - accuracy: 0.8155 - val_loss: 0.4335 - val_accuracy: 0.8332\n",
      "Epoch 253/1000\n",
      "239/239 [==============================] - 0s 2ms/step - loss: 0.4748 - accuracy: 0.8153 - val_loss: 0.4330 - val_accuracy: 0.8338\n",
      "Epoch 254/1000\n",
      "239/239 [==============================] - 1s 2ms/step - loss: 0.4742 - accuracy: 0.8159 - val_loss: 0.4333 - val_accuracy: 0.8340\n",
      "Epoch 255/1000\n",
      "239/239 [==============================] - 1s 2ms/step - loss: 0.4744 - accuracy: 0.8164 - val_loss: 0.4331 - val_accuracy: 0.8358\n",
      "Epoch 256/1000\n",
      "239/239 [==============================] - 1s 2ms/step - loss: 0.4744 - accuracy: 0.8163 - val_loss: 0.4335 - val_accuracy: 0.8327\n",
      "Epoch 257/1000\n",
      "239/239 [==============================] - 1s 2ms/step - loss: 0.4720 - accuracy: 0.8180 - val_loss: 0.4298 - val_accuracy: 0.8360\n",
      "Epoch 258/1000\n",
      "239/239 [==============================] - 0s 2ms/step - loss: 0.4754 - accuracy: 0.8166 - val_loss: 0.4330 - val_accuracy: 0.8354\n",
      "Epoch 259/1000\n",
      "239/239 [==============================] - 0s 2ms/step - loss: 0.4740 - accuracy: 0.8168 - val_loss: 0.4338 - val_accuracy: 0.8333\n",
      "Epoch 260/1000\n",
      "239/239 [==============================] - 1s 2ms/step - loss: 0.4733 - accuracy: 0.8175 - val_loss: 0.4355 - val_accuracy: 0.8331\n",
      "Epoch 261/1000\n",
      "239/239 [==============================] - 1s 2ms/step - loss: 0.4736 - accuracy: 0.8161 - val_loss: 0.4353 - val_accuracy: 0.8321\n",
      "Epoch 262/1000\n",
      "239/239 [==============================] - 1s 2ms/step - loss: 0.4733 - accuracy: 0.8164 - val_loss: 0.4311 - val_accuracy: 0.8327\n",
      "Epoch 263/1000\n",
      "239/239 [==============================] - 1s 2ms/step - loss: 0.4727 - accuracy: 0.8165 - val_loss: 0.4317 - val_accuracy: 0.8342\n",
      "Epoch 264/1000\n",
      "239/239 [==============================] - 1s 2ms/step - loss: 0.4736 - accuracy: 0.8166 - val_loss: 0.4309 - val_accuracy: 0.8339\n",
      "Epoch 265/1000\n",
      "239/239 [==============================] - 1s 2ms/step - loss: 0.4737 - accuracy: 0.8153 - val_loss: 0.4307 - val_accuracy: 0.8349\n",
      "Epoch 266/1000\n",
      "239/239 [==============================] - 1s 2ms/step - loss: 0.4739 - accuracy: 0.8162 - val_loss: 0.4324 - val_accuracy: 0.8335\n",
      "Epoch 267/1000\n",
      "239/239 [==============================] - 1s 2ms/step - loss: 0.4719 - accuracy: 0.8175 - val_loss: 0.4294 - val_accuracy: 0.8368\n",
      "Epoch 268/1000\n",
      "239/239 [==============================] - 0s 2ms/step - loss: 0.4723 - accuracy: 0.8159 - val_loss: 0.4319 - val_accuracy: 0.8356\n",
      "Epoch 269/1000\n",
      "239/239 [==============================] - 1s 2ms/step - loss: 0.4706 - accuracy: 0.8173 - val_loss: 0.4296 - val_accuracy: 0.8361\n",
      "Epoch 270/1000\n",
      "239/239 [==============================] - 1s 2ms/step - loss: 0.4727 - accuracy: 0.8162 - val_loss: 0.4302 - val_accuracy: 0.8361\n",
      "Epoch 271/1000\n",
      "239/239 [==============================] - 0s 2ms/step - loss: 0.4722 - accuracy: 0.8168 - val_loss: 0.4311 - val_accuracy: 0.8338\n",
      "Epoch 272/1000\n",
      "239/239 [==============================] - 0s 2ms/step - loss: 0.4729 - accuracy: 0.8171 - val_loss: 0.4301 - val_accuracy: 0.8342\n",
      "Epoch 273/1000\n",
      "239/239 [==============================] - 1s 2ms/step - loss: 0.4717 - accuracy: 0.8161 - val_loss: 0.4321 - val_accuracy: 0.8344\n",
      "Epoch 274/1000\n",
      "239/239 [==============================] - 1s 2ms/step - loss: 0.4709 - accuracy: 0.8165 - val_loss: 0.4291 - val_accuracy: 0.8358\n",
      "Epoch 275/1000\n",
      "239/239 [==============================] - 1s 2ms/step - loss: 0.4719 - accuracy: 0.8171 - val_loss: 0.4327 - val_accuracy: 0.8333\n",
      "Epoch 276/1000\n",
      "239/239 [==============================] - 0s 2ms/step - loss: 0.4741 - accuracy: 0.8165 - val_loss: 0.4339 - val_accuracy: 0.8340\n",
      "Epoch 277/1000\n",
      "239/239 [==============================] - 0s 2ms/step - loss: 0.4737 - accuracy: 0.8166 - val_loss: 0.4302 - val_accuracy: 0.8355\n",
      "Epoch 278/1000\n",
      "239/239 [==============================] - 0s 2ms/step - loss: 0.4734 - accuracy: 0.8172 - val_loss: 0.4315 - val_accuracy: 0.8350\n",
      "Epoch 279/1000\n",
      "239/239 [==============================] - 1s 2ms/step - loss: 0.4732 - accuracy: 0.8175 - val_loss: 0.4306 - val_accuracy: 0.8361\n",
      "Epoch 280/1000\n",
      "239/239 [==============================] - 1s 2ms/step - loss: 0.4735 - accuracy: 0.8167 - val_loss: 0.4303 - val_accuracy: 0.8364\n",
      "Epoch 281/1000\n",
      "239/239 [==============================] - 0s 2ms/step - loss: 0.4717 - accuracy: 0.8175 - val_loss: 0.4276 - val_accuracy: 0.8392\n",
      "Epoch 282/1000\n",
      "239/239 [==============================] - 0s 2ms/step - loss: 0.4713 - accuracy: 0.8170 - val_loss: 0.4325 - val_accuracy: 0.8343\n",
      "Epoch 283/1000\n",
      "239/239 [==============================] - 1s 2ms/step - loss: 0.4732 - accuracy: 0.8177 - val_loss: 0.4276 - val_accuracy: 0.8374\n",
      "Epoch 284/1000\n",
      "239/239 [==============================] - 0s 2ms/step - loss: 0.4715 - accuracy: 0.8184 - val_loss: 0.4279 - val_accuracy: 0.8369\n",
      "Epoch 285/1000\n",
      "239/239 [==============================] - 1s 2ms/step - loss: 0.4713 - accuracy: 0.8175 - val_loss: 0.4281 - val_accuracy: 0.8369\n",
      "Epoch 286/1000\n",
      "239/239 [==============================] - 1s 2ms/step - loss: 0.4711 - accuracy: 0.8181 - val_loss: 0.4303 - val_accuracy: 0.8372\n",
      "Epoch 287/1000\n",
      "239/239 [==============================] - 0s 2ms/step - loss: 0.4707 - accuracy: 0.8178 - val_loss: 0.4323 - val_accuracy: 0.8353\n",
      "Epoch 288/1000\n",
      "239/239 [==============================] - 1s 2ms/step - loss: 0.4694 - accuracy: 0.8183 - val_loss: 0.4288 - val_accuracy: 0.8363\n",
      "Epoch 289/1000\n",
      "239/239 [==============================] - 1s 2ms/step - loss: 0.4710 - accuracy: 0.8181 - val_loss: 0.4310 - val_accuracy: 0.8344\n",
      "Epoch 290/1000\n",
      "239/239 [==============================] - 1s 2ms/step - loss: 0.4707 - accuracy: 0.8164 - val_loss: 0.4301 - val_accuracy: 0.8369\n",
      "Epoch 291/1000\n",
      "239/239 [==============================] - 1s 2ms/step - loss: 0.4714 - accuracy: 0.8169 - val_loss: 0.4312 - val_accuracy: 0.8378\n",
      "Epoch 292/1000\n",
      "239/239 [==============================] - 1s 2ms/step - loss: 0.4718 - accuracy: 0.8175 - val_loss: 0.4317 - val_accuracy: 0.8340\n",
      "Epoch 293/1000\n",
      "239/239 [==============================] - 1s 2ms/step - loss: 0.4722 - accuracy: 0.8172 - val_loss: 0.4314 - val_accuracy: 0.8349\n",
      "Epoch 294/1000\n",
      "239/239 [==============================] - 0s 2ms/step - loss: 0.4685 - accuracy: 0.8189 - val_loss: 0.4283 - val_accuracy: 0.8389\n",
      "Epoch 295/1000\n",
      "239/239 [==============================] - 0s 2ms/step - loss: 0.4704 - accuracy: 0.8186 - val_loss: 0.4299 - val_accuracy: 0.8338\n",
      "Epoch 296/1000\n",
      "239/239 [==============================] - 1s 2ms/step - loss: 0.4712 - accuracy: 0.8171 - val_loss: 0.4278 - val_accuracy: 0.8372\n",
      "Epoch 297/1000\n",
      "239/239 [==============================] - 1s 2ms/step - loss: 0.4676 - accuracy: 0.8198 - val_loss: 0.4274 - val_accuracy: 0.8366\n",
      "Epoch 298/1000\n",
      "239/239 [==============================] - 1s 2ms/step - loss: 0.4681 - accuracy: 0.8180 - val_loss: 0.4268 - val_accuracy: 0.8368\n",
      "Epoch 299/1000\n",
      "239/239 [==============================] - 1s 2ms/step - loss: 0.4700 - accuracy: 0.8183 - val_loss: 0.4286 - val_accuracy: 0.8352\n",
      "Epoch 300/1000\n",
      "239/239 [==============================] - 1s 2ms/step - loss: 0.4702 - accuracy: 0.8181 - val_loss: 0.4294 - val_accuracy: 0.8394\n",
      "Epoch 301/1000\n",
      "239/239 [==============================] - 1s 2ms/step - loss: 0.4699 - accuracy: 0.8194 - val_loss: 0.4302 - val_accuracy: 0.8358\n",
      "Epoch 302/1000\n",
      "239/239 [==============================] - 1s 2ms/step - loss: 0.4700 - accuracy: 0.8177 - val_loss: 0.4271 - val_accuracy: 0.8383\n",
      "Epoch 303/1000\n",
      "239/239 [==============================] - 1s 2ms/step - loss: 0.4709 - accuracy: 0.8178 - val_loss: 0.4317 - val_accuracy: 0.8345\n",
      "Epoch 304/1000\n",
      "239/239 [==============================] - 1s 2ms/step - loss: 0.4696 - accuracy: 0.8179 - val_loss: 0.4289 - val_accuracy: 0.8364\n",
      "Epoch 305/1000\n",
      "239/239 [==============================] - 1s 2ms/step - loss: 0.4693 - accuracy: 0.8182 - val_loss: 0.4321 - val_accuracy: 0.8332\n",
      "Epoch 306/1000\n",
      "239/239 [==============================] - 1s 2ms/step - loss: 0.4693 - accuracy: 0.8190 - val_loss: 0.4274 - val_accuracy: 0.8376\n",
      "Epoch 307/1000\n",
      "239/239 [==============================] - 1s 2ms/step - loss: 0.4710 - accuracy: 0.8182 - val_loss: 0.4290 - val_accuracy: 0.8358\n",
      "Epoch 308/1000\n",
      "239/239 [==============================] - 1s 2ms/step - loss: 0.4696 - accuracy: 0.8187 - val_loss: 0.4294 - val_accuracy: 0.8367\n",
      "Epoch 309/1000\n",
      "239/239 [==============================] - 1s 2ms/step - loss: 0.4687 - accuracy: 0.8201 - val_loss: 0.4275 - val_accuracy: 0.8386\n",
      "Epoch 310/1000\n",
      "239/239 [==============================] - 1s 2ms/step - loss: 0.4681 - accuracy: 0.8193 - val_loss: 0.4270 - val_accuracy: 0.8397\n",
      "Epoch 311/1000\n",
      "239/239 [==============================] - 1s 2ms/step - loss: 0.4687 - accuracy: 0.8174 - val_loss: 0.4261 - val_accuracy: 0.8377\n",
      "Epoch 312/1000\n",
      "239/239 [==============================] - 1s 3ms/step - loss: 0.4677 - accuracy: 0.8203 - val_loss: 0.4281 - val_accuracy: 0.8358\n",
      "Epoch 313/1000\n",
      "239/239 [==============================] - 1s 2ms/step - loss: 0.4691 - accuracy: 0.8190 - val_loss: 0.4272 - val_accuracy: 0.8393\n",
      "Epoch 314/1000\n",
      "239/239 [==============================] - 1s 2ms/step - loss: 0.4698 - accuracy: 0.8181 - val_loss: 0.4263 - val_accuracy: 0.8369\n",
      "Epoch 315/1000\n",
      "239/239 [==============================] - 1s 2ms/step - loss: 0.4669 - accuracy: 0.8194 - val_loss: 0.4283 - val_accuracy: 0.8373\n",
      "Epoch 316/1000\n",
      "239/239 [==============================] - 1s 2ms/step - loss: 0.4692 - accuracy: 0.8190 - val_loss: 0.4284 - val_accuracy: 0.8347\n",
      "Epoch 317/1000\n",
      "239/239 [==============================] - 1s 2ms/step - loss: 0.4699 - accuracy: 0.8184 - val_loss: 0.4286 - val_accuracy: 0.8362\n",
      "Epoch 318/1000\n",
      "239/239 [==============================] - 1s 2ms/step - loss: 0.4712 - accuracy: 0.8182 - val_loss: 0.4270 - val_accuracy: 0.8367\n",
      "Epoch 319/1000\n",
      "239/239 [==============================] - 1s 2ms/step - loss: 0.4690 - accuracy: 0.8190 - val_loss: 0.4268 - val_accuracy: 0.8361\n",
      "Epoch 320/1000\n",
      "239/239 [==============================] - 1s 2ms/step - loss: 0.4664 - accuracy: 0.8195 - val_loss: 0.4282 - val_accuracy: 0.8346\n",
      "Epoch 321/1000\n",
      "239/239 [==============================] - 1s 2ms/step - loss: 0.4686 - accuracy: 0.8184 - val_loss: 0.4266 - val_accuracy: 0.8367\n",
      "Epoch 322/1000\n",
      "239/239 [==============================] - 1s 2ms/step - loss: 0.4670 - accuracy: 0.8189 - val_loss: 0.4271 - val_accuracy: 0.8377\n",
      "Epoch 323/1000\n",
      "239/239 [==============================] - 1s 2ms/step - loss: 0.4675 - accuracy: 0.8197 - val_loss: 0.4287 - val_accuracy: 0.8361\n",
      "Epoch 324/1000\n",
      "239/239 [==============================] - 1s 2ms/step - loss: 0.4677 - accuracy: 0.8195 - val_loss: 0.4301 - val_accuracy: 0.8346\n",
      "Epoch 325/1000\n",
      "239/239 [==============================] - 0s 2ms/step - loss: 0.4700 - accuracy: 0.8195 - val_loss: 0.4287 - val_accuracy: 0.8352\n",
      "Epoch 326/1000\n",
      "239/239 [==============================] - 1s 2ms/step - loss: 0.4647 - accuracy: 0.8201 - val_loss: 0.4255 - val_accuracy: 0.8375\n",
      "Epoch 327/1000\n",
      "239/239 [==============================] - 1s 2ms/step - loss: 0.4694 - accuracy: 0.8191 - val_loss: 0.4267 - val_accuracy: 0.8375\n",
      "Epoch 328/1000\n",
      "239/239 [==============================] - 1s 2ms/step - loss: 0.4693 - accuracy: 0.8183 - val_loss: 0.4237 - val_accuracy: 0.8416\n",
      "Epoch 329/1000\n",
      "239/239 [==============================] - 1s 2ms/step - loss: 0.4655 - accuracy: 0.8203 - val_loss: 0.4260 - val_accuracy: 0.8373\n",
      "Epoch 330/1000\n",
      "239/239 [==============================] - 1s 2ms/step - loss: 0.4658 - accuracy: 0.8191 - val_loss: 0.4254 - val_accuracy: 0.8369\n",
      "Epoch 331/1000\n",
      "239/239 [==============================] - 1s 2ms/step - loss: 0.4695 - accuracy: 0.8188 - val_loss: 0.4241 - val_accuracy: 0.8390\n",
      "Epoch 332/1000\n",
      "239/239 [==============================] - 1s 2ms/step - loss: 0.4647 - accuracy: 0.8206 - val_loss: 0.4258 - val_accuracy: 0.8385\n",
      "Epoch 333/1000\n",
      "239/239 [==============================] - 1s 2ms/step - loss: 0.4666 - accuracy: 0.8203 - val_loss: 0.4260 - val_accuracy: 0.8383\n",
      "Epoch 334/1000\n",
      "239/239 [==============================] - 1s 2ms/step - loss: 0.4669 - accuracy: 0.8197 - val_loss: 0.4257 - val_accuracy: 0.8394\n",
      "Epoch 335/1000\n",
      "239/239 [==============================] - 1s 2ms/step - loss: 0.4694 - accuracy: 0.8192 - val_loss: 0.4273 - val_accuracy: 0.8366\n",
      "Epoch 336/1000\n",
      "239/239 [==============================] - 1s 2ms/step - loss: 0.4678 - accuracy: 0.8194 - val_loss: 0.4282 - val_accuracy: 0.8380\n",
      "Epoch 337/1000\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "239/239 [==============================] - 1s 2ms/step - loss: 0.4680 - accuracy: 0.8174 - val_loss: 0.4305 - val_accuracy: 0.8358\n",
      "Epoch 338/1000\n",
      "239/239 [==============================] - 1s 2ms/step - loss: 0.4673 - accuracy: 0.8198 - val_loss: 0.4254 - val_accuracy: 0.8360\n",
      "Epoch 339/1000\n",
      "239/239 [==============================] - 1s 2ms/step - loss: 0.4674 - accuracy: 0.8191 - val_loss: 0.4272 - val_accuracy: 0.8378\n",
      "Epoch 340/1000\n",
      "239/239 [==============================] - 0s 2ms/step - loss: 0.4667 - accuracy: 0.8198 - val_loss: 0.4249 - val_accuracy: 0.8408\n",
      "Epoch 341/1000\n",
      "239/239 [==============================] - 1s 2ms/step - loss: 0.4661 - accuracy: 0.8198 - val_loss: 0.4244 - val_accuracy: 0.8366\n",
      "Epoch 342/1000\n",
      "239/239 [==============================] - 1s 2ms/step - loss: 0.4671 - accuracy: 0.8187 - val_loss: 0.4256 - val_accuracy: 0.8397\n",
      "Epoch 343/1000\n",
      "239/239 [==============================] - 1s 2ms/step - loss: 0.4671 - accuracy: 0.8198 - val_loss: 0.4246 - val_accuracy: 0.8406\n",
      "Epoch 344/1000\n",
      "239/239 [==============================] - 1s 2ms/step - loss: 0.4655 - accuracy: 0.8207 - val_loss: 0.4250 - val_accuracy: 0.8412\n",
      "Epoch 345/1000\n",
      "239/239 [==============================] - 1s 2ms/step - loss: 0.4656 - accuracy: 0.8204 - val_loss: 0.4269 - val_accuracy: 0.8369\n",
      "Epoch 346/1000\n",
      "239/239 [==============================] - 1s 2ms/step - loss: 0.4682 - accuracy: 0.8187 - val_loss: 0.4263 - val_accuracy: 0.8378\n",
      "Epoch 347/1000\n",
      "239/239 [==============================] - 1s 2ms/step - loss: 0.4666 - accuracy: 0.8193 - val_loss: 0.4274 - val_accuracy: 0.8387\n",
      "Epoch 348/1000\n",
      "239/239 [==============================] - 1s 2ms/step - loss: 0.4659 - accuracy: 0.8207 - val_loss: 0.4250 - val_accuracy: 0.8371\n",
      "Epoch 349/1000\n",
      "239/239 [==============================] - 1s 2ms/step - loss: 0.4633 - accuracy: 0.8208 - val_loss: 0.4247 - val_accuracy: 0.8383\n",
      "Epoch 350/1000\n",
      "239/239 [==============================] - 1s 2ms/step - loss: 0.4660 - accuracy: 0.8197 - val_loss: 0.4222 - val_accuracy: 0.8386\n",
      "Epoch 351/1000\n",
      "239/239 [==============================] - 1s 2ms/step - loss: 0.4646 - accuracy: 0.8219 - val_loss: 0.4222 - val_accuracy: 0.8386\n",
      "Epoch 352/1000\n",
      "239/239 [==============================] - 1s 2ms/step - loss: 0.4662 - accuracy: 0.8205 - val_loss: 0.4242 - val_accuracy: 0.8399\n",
      "Epoch 353/1000\n",
      "239/239 [==============================] - 1s 2ms/step - loss: 0.4658 - accuracy: 0.8199 - val_loss: 0.4221 - val_accuracy: 0.8387\n",
      "Epoch 354/1000\n",
      "239/239 [==============================] - 1s 2ms/step - loss: 0.4629 - accuracy: 0.8220 - val_loss: 0.4227 - val_accuracy: 0.8389\n",
      "Epoch 355/1000\n",
      "239/239 [==============================] - 0s 2ms/step - loss: 0.4643 - accuracy: 0.8208 - val_loss: 0.4238 - val_accuracy: 0.8389\n",
      "Epoch 356/1000\n",
      "239/239 [==============================] - 0s 2ms/step - loss: 0.4665 - accuracy: 0.8191 - val_loss: 0.4226 - val_accuracy: 0.8404\n",
      "Epoch 357/1000\n",
      "239/239 [==============================] - 1s 2ms/step - loss: 0.4646 - accuracy: 0.8206 - val_loss: 0.4243 - val_accuracy: 0.8380\n",
      "Epoch 358/1000\n",
      "239/239 [==============================] - 0s 2ms/step - loss: 0.4634 - accuracy: 0.8214 - val_loss: 0.4205 - val_accuracy: 0.8408\n",
      "Epoch 359/1000\n",
      "239/239 [==============================] - 1s 2ms/step - loss: 0.4650 - accuracy: 0.8209 - val_loss: 0.4251 - val_accuracy: 0.8372\n",
      "Epoch 360/1000\n",
      "239/239 [==============================] - 1s 2ms/step - loss: 0.4651 - accuracy: 0.8196 - val_loss: 0.4242 - val_accuracy: 0.8397\n",
      "Epoch 361/1000\n",
      "239/239 [==============================] - 1s 2ms/step - loss: 0.4638 - accuracy: 0.8205 - val_loss: 0.4222 - val_accuracy: 0.8402\n",
      "Epoch 362/1000\n",
      "239/239 [==============================] - 1s 2ms/step - loss: 0.4655 - accuracy: 0.8205 - val_loss: 0.4204 - val_accuracy: 0.8412\n",
      "Epoch 363/1000\n",
      "239/239 [==============================] - 0s 2ms/step - loss: 0.4661 - accuracy: 0.8195 - val_loss: 0.4209 - val_accuracy: 0.8415\n",
      "Epoch 364/1000\n",
      "239/239 [==============================] - 0s 2ms/step - loss: 0.4671 - accuracy: 0.8198 - val_loss: 0.4226 - val_accuracy: 0.8379\n",
      "Epoch 365/1000\n",
      "239/239 [==============================] - 1s 2ms/step - loss: 0.4656 - accuracy: 0.8206 - val_loss: 0.4238 - val_accuracy: 0.8382\n",
      "Epoch 366/1000\n",
      "239/239 [==============================] - 1s 2ms/step - loss: 0.4671 - accuracy: 0.8193 - val_loss: 0.4203 - val_accuracy: 0.8394\n",
      "Epoch 367/1000\n",
      "239/239 [==============================] - 1s 2ms/step - loss: 0.4643 - accuracy: 0.8219 - val_loss: 0.4253 - val_accuracy: 0.8376\n",
      "Epoch 368/1000\n",
      "239/239 [==============================] - 1s 2ms/step - loss: 0.4624 - accuracy: 0.8214 - val_loss: 0.4246 - val_accuracy: 0.8388\n",
      "Epoch 369/1000\n",
      "239/239 [==============================] - 0s 2ms/step - loss: 0.4649 - accuracy: 0.8205 - val_loss: 0.4215 - val_accuracy: 0.8421\n",
      "Epoch 370/1000\n",
      "239/239 [==============================] - 0s 2ms/step - loss: 0.4633 - accuracy: 0.8221 - val_loss: 0.4219 - val_accuracy: 0.8397\n",
      "Epoch 371/1000\n",
      "239/239 [==============================] - 0s 2ms/step - loss: 0.4640 - accuracy: 0.8208 - val_loss: 0.4219 - val_accuracy: 0.8377\n",
      "Epoch 372/1000\n",
      "239/239 [==============================] - 1s 2ms/step - loss: 0.4662 - accuracy: 0.8204 - val_loss: 0.4238 - val_accuracy: 0.8394\n",
      "Epoch 373/1000\n",
      "239/239 [==============================] - 1s 2ms/step - loss: 0.4643 - accuracy: 0.8209 - val_loss: 0.4204 - val_accuracy: 0.8411\n",
      "Epoch 374/1000\n",
      "239/239 [==============================] - 1s 2ms/step - loss: 0.4638 - accuracy: 0.8205 - val_loss: 0.4201 - val_accuracy: 0.8411\n",
      "Epoch 375/1000\n",
      "239/239 [==============================] - 1s 2ms/step - loss: 0.4632 - accuracy: 0.8213 - val_loss: 0.4191 - val_accuracy: 0.8432\n",
      "Epoch 376/1000\n",
      "239/239 [==============================] - 1s 2ms/step - loss: 0.4622 - accuracy: 0.8208 - val_loss: 0.4234 - val_accuracy: 0.8397\n",
      "Epoch 377/1000\n",
      "239/239 [==============================] - 1s 2ms/step - loss: 0.4641 - accuracy: 0.8218 - val_loss: 0.4218 - val_accuracy: 0.8413\n",
      "Epoch 378/1000\n",
      "239/239 [==============================] - 0s 2ms/step - loss: 0.4640 - accuracy: 0.8213 - val_loss: 0.4212 - val_accuracy: 0.8409\n",
      "Epoch 379/1000\n",
      "239/239 [==============================] - 1s 2ms/step - loss: 0.4633 - accuracy: 0.8205 - val_loss: 0.4265 - val_accuracy: 0.8407\n",
      "Epoch 380/1000\n",
      "239/239 [==============================] - 1s 2ms/step - loss: 0.4621 - accuracy: 0.8215 - val_loss: 0.4207 - val_accuracy: 0.8409\n",
      "Epoch 381/1000\n",
      "239/239 [==============================] - 1s 2ms/step - loss: 0.4665 - accuracy: 0.8202 - val_loss: 0.4195 - val_accuracy: 0.8407\n",
      "Epoch 382/1000\n",
      "239/239 [==============================] - 1s 2ms/step - loss: 0.4639 - accuracy: 0.8213 - val_loss: 0.4207 - val_accuracy: 0.8427\n",
      "Epoch 383/1000\n",
      "239/239 [==============================] - 1s 2ms/step - loss: 0.4639 - accuracy: 0.8201 - val_loss: 0.4210 - val_accuracy: 0.8398\n",
      "Epoch 384/1000\n",
      "239/239 [==============================] - 1s 2ms/step - loss: 0.4640 - accuracy: 0.8209 - val_loss: 0.4235 - val_accuracy: 0.8390\n",
      "Epoch 385/1000\n",
      "239/239 [==============================] - 1s 2ms/step - loss: 0.4647 - accuracy: 0.8199 - val_loss: 0.4204 - val_accuracy: 0.8403\n",
      "Epoch 386/1000\n",
      "239/239 [==============================] - 1s 2ms/step - loss: 0.4627 - accuracy: 0.8211 - val_loss: 0.4224 - val_accuracy: 0.8390\n",
      "Epoch 387/1000\n",
      "239/239 [==============================] - 1s 2ms/step - loss: 0.4641 - accuracy: 0.8213 - val_loss: 0.4227 - val_accuracy: 0.8397\n",
      "Epoch 388/1000\n",
      "239/239 [==============================] - 1s 2ms/step - loss: 0.4623 - accuracy: 0.8215 - val_loss: 0.4232 - val_accuracy: 0.8400\n",
      "Epoch 389/1000\n",
      "239/239 [==============================] - 1s 2ms/step - loss: 0.4634 - accuracy: 0.8204 - val_loss: 0.4206 - val_accuracy: 0.8417\n",
      "Epoch 390/1000\n",
      "239/239 [==============================] - 1s 2ms/step - loss: 0.4645 - accuracy: 0.8207 - val_loss: 0.4204 - val_accuracy: 0.8394\n",
      "Epoch 391/1000\n",
      "239/239 [==============================] - 1s 2ms/step - loss: 0.4615 - accuracy: 0.8216 - val_loss: 0.4204 - val_accuracy: 0.8410\n",
      "Epoch 392/1000\n",
      "239/239 [==============================] - 1s 2ms/step - loss: 0.4602 - accuracy: 0.8234 - val_loss: 0.4196 - val_accuracy: 0.8406\n",
      "Epoch 393/1000\n",
      "239/239 [==============================] - 1s 2ms/step - loss: 0.4602 - accuracy: 0.8227 - val_loss: 0.4179 - val_accuracy: 0.8414\n",
      "Epoch 394/1000\n",
      "239/239 [==============================] - 0s 2ms/step - loss: 0.4621 - accuracy: 0.8225 - val_loss: 0.4207 - val_accuracy: 0.8414\n",
      "Epoch 395/1000\n",
      "239/239 [==============================] - 0s 2ms/step - loss: 0.4621 - accuracy: 0.8231 - val_loss: 0.4203 - val_accuracy: 0.8403\n",
      "Epoch 396/1000\n",
      "239/239 [==============================] - 0s 2ms/step - loss: 0.4610 - accuracy: 0.8224 - val_loss: 0.4212 - val_accuracy: 0.8394\n",
      "Epoch 397/1000\n",
      "239/239 [==============================] - 1s 2ms/step - loss: 0.4625 - accuracy: 0.8225 - val_loss: 0.4199 - val_accuracy: 0.8417\n",
      "Epoch 398/1000\n",
      "239/239 [==============================] - 1s 2ms/step - loss: 0.4624 - accuracy: 0.8221 - val_loss: 0.4215 - val_accuracy: 0.8395\n",
      "Epoch 399/1000\n",
      "239/239 [==============================] - 1s 2ms/step - loss: 0.4610 - accuracy: 0.8231 - val_loss: 0.4212 - val_accuracy: 0.8406\n",
      "Epoch 400/1000\n",
      "239/239 [==============================] - 1s 2ms/step - loss: 0.4628 - accuracy: 0.8217 - val_loss: 0.4210 - val_accuracy: 0.8416\n",
      "Epoch 401/1000\n",
      "239/239 [==============================] - 1s 2ms/step - loss: 0.4627 - accuracy: 0.8205 - val_loss: 0.4232 - val_accuracy: 0.8408\n",
      "Epoch 402/1000\n",
      "239/239 [==============================] - 1s 2ms/step - loss: 0.4634 - accuracy: 0.8213 - val_loss: 0.4200 - val_accuracy: 0.8415\n",
      "Epoch 403/1000\n",
      "239/239 [==============================] - 1s 2ms/step - loss: 0.4619 - accuracy: 0.8216 - val_loss: 0.4176 - val_accuracy: 0.8427\n",
      "Epoch 404/1000\n",
      "239/239 [==============================] - 1s 2ms/step - loss: 0.4630 - accuracy: 0.8226 - val_loss: 0.4207 - val_accuracy: 0.8419\n",
      "Epoch 405/1000\n",
      "239/239 [==============================] - 0s 2ms/step - loss: 0.4629 - accuracy: 0.8211 - val_loss: 0.4206 - val_accuracy: 0.8422\n",
      "Epoch 406/1000\n",
      "239/239 [==============================] - 0s 2ms/step - loss: 0.4598 - accuracy: 0.8229 - val_loss: 0.4191 - val_accuracy: 0.8432\n",
      "Epoch 407/1000\n",
      "239/239 [==============================] - 1s 2ms/step - loss: 0.4616 - accuracy: 0.8227 - val_loss: 0.4205 - val_accuracy: 0.8431\n",
      "Epoch 408/1000\n",
      "239/239 [==============================] - 1s 2ms/step - loss: 0.4585 - accuracy: 0.8234 - val_loss: 0.4202 - val_accuracy: 0.8403\n",
      "Epoch 409/1000\n",
      "239/239 [==============================] - 1s 2ms/step - loss: 0.4613 - accuracy: 0.8222 - val_loss: 0.4224 - val_accuracy: 0.8381\n",
      "Epoch 410/1000\n",
      "239/239 [==============================] - 1s 2ms/step - loss: 0.4618 - accuracy: 0.8214 - val_loss: 0.4186 - val_accuracy: 0.8397\n",
      "Epoch 411/1000\n",
      "239/239 [==============================] - 1s 2ms/step - loss: 0.4608 - accuracy: 0.8228 - val_loss: 0.4174 - val_accuracy: 0.8451\n",
      "Epoch 412/1000\n",
      "239/239 [==============================] - 1s 2ms/step - loss: 0.4610 - accuracy: 0.8228 - val_loss: 0.4190 - val_accuracy: 0.8426\n",
      "Epoch 413/1000\n",
      "239/239 [==============================] - 1s 2ms/step - loss: 0.4615 - accuracy: 0.8222 - val_loss: 0.4225 - val_accuracy: 0.8415\n",
      "Epoch 414/1000\n",
      "239/239 [==============================] - 1s 2ms/step - loss: 0.4595 - accuracy: 0.8226 - val_loss: 0.4170 - val_accuracy: 0.8411\n",
      "Epoch 415/1000\n",
      "239/239 [==============================] - 1s 2ms/step - loss: 0.4601 - accuracy: 0.8233 - val_loss: 0.4181 - val_accuracy: 0.8419\n",
      "Epoch 416/1000\n",
      "239/239 [==============================] - 1s 2ms/step - loss: 0.4627 - accuracy: 0.8226 - val_loss: 0.4198 - val_accuracy: 0.8423\n",
      "Epoch 417/1000\n",
      "239/239 [==============================] - 1s 2ms/step - loss: 0.4616 - accuracy: 0.8220 - val_loss: 0.4210 - val_accuracy: 0.8403\n",
      "Epoch 418/1000\n",
      "239/239 [==============================] - 1s 2ms/step - loss: 0.4617 - accuracy: 0.8220 - val_loss: 0.4197 - val_accuracy: 0.8430\n",
      "Epoch 419/1000\n",
      "239/239 [==============================] - 1s 2ms/step - loss: 0.4621 - accuracy: 0.8220 - val_loss: 0.4187 - val_accuracy: 0.8448\n",
      "Epoch 420/1000\n",
      "239/239 [==============================] - 1s 2ms/step - loss: 0.4616 - accuracy: 0.8224 - val_loss: 0.4196 - val_accuracy: 0.8416\n",
      "Epoch 421/1000\n",
      "239/239 [==============================] - 1s 2ms/step - loss: 0.4612 - accuracy: 0.8212 - val_loss: 0.4204 - val_accuracy: 0.8404\n",
      "Epoch 422/1000\n",
      "239/239 [==============================] - 1s 2ms/step - loss: 0.4613 - accuracy: 0.8219 - val_loss: 0.4197 - val_accuracy: 0.8416\n",
      "Epoch 423/1000\n",
      "239/239 [==============================] - 1s 2ms/step - loss: 0.4585 - accuracy: 0.8234 - val_loss: 0.4199 - val_accuracy: 0.8421\n",
      "Epoch 424/1000\n",
      "239/239 [==============================] - 0s 2ms/step - loss: 0.4612 - accuracy: 0.8230 - val_loss: 0.4174 - val_accuracy: 0.8432\n",
      "Epoch 425/1000\n",
      "239/239 [==============================] - 0s 2ms/step - loss: 0.4611 - accuracy: 0.8223 - val_loss: 0.4181 - val_accuracy: 0.8430\n",
      "Epoch 426/1000\n",
      "239/239 [==============================] - 0s 2ms/step - loss: 0.4590 - accuracy: 0.8232 - val_loss: 0.4193 - val_accuracy: 0.8411\n",
      "Epoch 427/1000\n",
      "239/239 [==============================] - 1s 2ms/step - loss: 0.4588 - accuracy: 0.8230 - val_loss: 0.4173 - val_accuracy: 0.8422\n",
      "Epoch 428/1000\n",
      "239/239 [==============================] - 1s 2ms/step - loss: 0.4585 - accuracy: 0.8232 - val_loss: 0.4173 - val_accuracy: 0.8406\n",
      "Epoch 429/1000\n",
      "239/239 [==============================] - 1s 2ms/step - loss: 0.4581 - accuracy: 0.8227 - val_loss: 0.4174 - val_accuracy: 0.8405\n",
      "Epoch 430/1000\n",
      "239/239 [==============================] - 1s 2ms/step - loss: 0.4617 - accuracy: 0.8219 - val_loss: 0.4158 - val_accuracy: 0.8433\n",
      "Epoch 431/1000\n",
      "239/239 [==============================] - 0s 2ms/step - loss: 0.4615 - accuracy: 0.8220 - val_loss: 0.4198 - val_accuracy: 0.8445\n",
      "Epoch 432/1000\n",
      "239/239 [==============================] - 1s 2ms/step - loss: 0.4598 - accuracy: 0.8225 - val_loss: 0.4209 - val_accuracy: 0.8417\n",
      "Epoch 433/1000\n",
      "239/239 [==============================] - 1s 2ms/step - loss: 0.4597 - accuracy: 0.8224 - val_loss: 0.4189 - val_accuracy: 0.8413\n",
      "Epoch 434/1000\n",
      "239/239 [==============================] - 1s 2ms/step - loss: 0.4573 - accuracy: 0.8228 - val_loss: 0.4162 - val_accuracy: 0.8444\n",
      "Epoch 435/1000\n",
      "239/239 [==============================] - 1s 2ms/step - loss: 0.4606 - accuracy: 0.8229 - val_loss: 0.4150 - val_accuracy: 0.8458\n",
      "Epoch 436/1000\n",
      "239/239 [==============================] - 1s 2ms/step - loss: 0.4590 - accuracy: 0.8237 - val_loss: 0.4161 - val_accuracy: 0.8436\n",
      "Epoch 437/1000\n",
      "239/239 [==============================] - 1s 2ms/step - loss: 0.4599 - accuracy: 0.8238 - val_loss: 0.4159 - val_accuracy: 0.8434\n",
      "Epoch 438/1000\n",
      "239/239 [==============================] - 1s 2ms/step - loss: 0.4603 - accuracy: 0.8226 - val_loss: 0.4195 - val_accuracy: 0.8403\n",
      "Epoch 439/1000\n",
      "239/239 [==============================] - 1s 2ms/step - loss: 0.4583 - accuracy: 0.8238 - val_loss: 0.4164 - val_accuracy: 0.8430\n",
      "Epoch 440/1000\n",
      "239/239 [==============================] - 0s 2ms/step - loss: 0.4616 - accuracy: 0.8213 - val_loss: 0.4190 - val_accuracy: 0.8408\n",
      "Epoch 441/1000\n",
      "239/239 [==============================] - 0s 2ms/step - loss: 0.4607 - accuracy: 0.8223 - val_loss: 0.4155 - val_accuracy: 0.8437\n",
      "Epoch 442/1000\n",
      "239/239 [==============================] - 1s 2ms/step - loss: 0.4594 - accuracy: 0.8225 - val_loss: 0.4204 - val_accuracy: 0.8411\n",
      "Epoch 443/1000\n",
      "239/239 [==============================] - 1s 2ms/step - loss: 0.4607 - accuracy: 0.8222 - val_loss: 0.4175 - val_accuracy: 0.8430\n",
      "Epoch 444/1000\n",
      "239/239 [==============================] - 1s 2ms/step - loss: 0.4601 - accuracy: 0.8232 - val_loss: 0.4189 - val_accuracy: 0.8382\n",
      "Epoch 445/1000\n",
      "239/239 [==============================] - 1s 2ms/step - loss: 0.4603 - accuracy: 0.8225 - val_loss: 0.4190 - val_accuracy: 0.8415\n",
      "Epoch 446/1000\n",
      "239/239 [==============================] - 1s 2ms/step - loss: 0.4609 - accuracy: 0.8221 - val_loss: 0.4190 - val_accuracy: 0.8408\n",
      "Epoch 447/1000\n",
      "239/239 [==============================] - 1s 2ms/step - loss: 0.4605 - accuracy: 0.8241 - val_loss: 0.4190 - val_accuracy: 0.8411\n",
      "Epoch 448/1000\n",
      "239/239 [==============================] - 1s 2ms/step - loss: 0.4617 - accuracy: 0.8220 - val_loss: 0.4162 - val_accuracy: 0.8445\n",
      "Epoch 449/1000\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "239/239 [==============================] - 1s 2ms/step - loss: 0.4596 - accuracy: 0.8221 - val_loss: 0.4170 - val_accuracy: 0.8440\n",
      "Epoch 450/1000\n",
      "239/239 [==============================] - 1s 2ms/step - loss: 0.4578 - accuracy: 0.8235 - val_loss: 0.4142 - val_accuracy: 0.8443\n",
      "Epoch 451/1000\n",
      "239/239 [==============================] - 1s 2ms/step - loss: 0.4595 - accuracy: 0.8230 - val_loss: 0.4209 - val_accuracy: 0.8403\n",
      "Epoch 452/1000\n",
      "239/239 [==============================] - 1s 2ms/step - loss: 0.4598 - accuracy: 0.8224 - val_loss: 0.4187 - val_accuracy: 0.8419\n",
      "Epoch 453/1000\n",
      "239/239 [==============================] - 1s 2ms/step - loss: 0.4591 - accuracy: 0.8227 - val_loss: 0.4205 - val_accuracy: 0.8422\n",
      "Epoch 454/1000\n",
      "239/239 [==============================] - 1s 2ms/step - loss: 0.4584 - accuracy: 0.8231 - val_loss: 0.4157 - val_accuracy: 0.8442\n",
      "Epoch 455/1000\n",
      "239/239 [==============================] - 1s 2ms/step - loss: 0.4596 - accuracy: 0.8219 - val_loss: 0.4166 - val_accuracy: 0.8423\n",
      "Epoch 456/1000\n",
      "239/239 [==============================] - 1s 2ms/step - loss: 0.4579 - accuracy: 0.8240 - val_loss: 0.4138 - val_accuracy: 0.8456\n",
      "Epoch 457/1000\n",
      "239/239 [==============================] - 1s 2ms/step - loss: 0.4589 - accuracy: 0.8239 - val_loss: 0.4154 - val_accuracy: 0.8441\n",
      "Epoch 458/1000\n",
      "239/239 [==============================] - 1s 2ms/step - loss: 0.4595 - accuracy: 0.8239 - val_loss: 0.4147 - val_accuracy: 0.8448\n",
      "Epoch 459/1000\n",
      "239/239 [==============================] - 1s 2ms/step - loss: 0.4590 - accuracy: 0.8234 - val_loss: 0.4159 - val_accuracy: 0.8434\n",
      "Epoch 460/1000\n",
      "239/239 [==============================] - 1s 2ms/step - loss: 0.4578 - accuracy: 0.8237 - val_loss: 0.4170 - val_accuracy: 0.8439\n",
      "Epoch 461/1000\n",
      "239/239 [==============================] - 1s 2ms/step - loss: 0.4579 - accuracy: 0.8244 - val_loss: 0.4169 - val_accuracy: 0.8423\n",
      "Epoch 462/1000\n",
      "239/239 [==============================] - 1s 2ms/step - loss: 0.4584 - accuracy: 0.8238 - val_loss: 0.4189 - val_accuracy: 0.8431\n",
      "Epoch 463/1000\n",
      "239/239 [==============================] - 1s 2ms/step - loss: 0.4599 - accuracy: 0.8238 - val_loss: 0.4197 - val_accuracy: 0.8414\n",
      "Epoch 464/1000\n",
      "239/239 [==============================] - 1s 2ms/step - loss: 0.4577 - accuracy: 0.8246 - val_loss: 0.4196 - val_accuracy: 0.8413\n",
      "Epoch 465/1000\n",
      "239/239 [==============================] - 1s 2ms/step - loss: 0.4579 - accuracy: 0.8250 - val_loss: 0.4179 - val_accuracy: 0.8453\n",
      "Epoch 466/1000\n",
      "239/239 [==============================] - 1s 2ms/step - loss: 0.4587 - accuracy: 0.8229 - val_loss: 0.4152 - val_accuracy: 0.8441\n",
      "Epoch 467/1000\n",
      "239/239 [==============================] - 1s 2ms/step - loss: 0.4605 - accuracy: 0.8230 - val_loss: 0.4161 - val_accuracy: 0.8451\n",
      "Epoch 468/1000\n",
      "239/239 [==============================] - 1s 2ms/step - loss: 0.4604 - accuracy: 0.8233 - val_loss: 0.4186 - val_accuracy: 0.8400\n",
      "Epoch 469/1000\n",
      "239/239 [==============================] - 1s 2ms/step - loss: 0.4593 - accuracy: 0.8228 - val_loss: 0.4191 - val_accuracy: 0.8420\n",
      "Epoch 470/1000\n",
      "239/239 [==============================] - 1s 2ms/step - loss: 0.4587 - accuracy: 0.8239 - val_loss: 0.4194 - val_accuracy: 0.8423\n",
      "Epoch 471/1000\n",
      "239/239 [==============================] - 1s 2ms/step - loss: 0.4585 - accuracy: 0.8232 - val_loss: 0.4164 - val_accuracy: 0.8428\n",
      "Epoch 472/1000\n",
      "239/239 [==============================] - 1s 2ms/step - loss: 0.4554 - accuracy: 0.8245 - val_loss: 0.4179 - val_accuracy: 0.8430\n",
      "Epoch 473/1000\n",
      "239/239 [==============================] - 1s 2ms/step - loss: 0.4605 - accuracy: 0.8226 - val_loss: 0.4164 - val_accuracy: 0.8416\n",
      "Epoch 474/1000\n",
      "239/239 [==============================] - 1s 2ms/step - loss: 0.4588 - accuracy: 0.8243 - val_loss: 0.4169 - val_accuracy: 0.8428\n",
      "Epoch 475/1000\n",
      "239/239 [==============================] - 1s 2ms/step - loss: 0.4577 - accuracy: 0.8238 - val_loss: 0.4173 - val_accuracy: 0.8442\n",
      "Epoch 476/1000\n",
      "239/239 [==============================] - 1s 2ms/step - loss: 0.4588 - accuracy: 0.8231 - val_loss: 0.4160 - val_accuracy: 0.8422\n",
      "Epoch 477/1000\n",
      "239/239 [==============================] - 1s 2ms/step - loss: 0.4571 - accuracy: 0.8239 - val_loss: 0.4181 - val_accuracy: 0.8429\n",
      "Epoch 478/1000\n",
      "239/239 [==============================] - 1s 2ms/step - loss: 0.4569 - accuracy: 0.8243 - val_loss: 0.4173 - val_accuracy: 0.8425\n",
      "Epoch 479/1000\n",
      "239/239 [==============================] - 1s 2ms/step - loss: 0.4596 - accuracy: 0.8230 - val_loss: 0.4184 - val_accuracy: 0.8438\n",
      "Epoch 480/1000\n",
      "239/239 [==============================] - 1s 2ms/step - loss: 0.4585 - accuracy: 0.8237 - val_loss: 0.4158 - val_accuracy: 0.8447\n",
      "Epoch 481/1000\n",
      "239/239 [==============================] - 1s 2ms/step - loss: 0.4571 - accuracy: 0.8243 - val_loss: 0.4178 - val_accuracy: 0.8441\n",
      "Epoch 482/1000\n",
      "239/239 [==============================] - 1s 2ms/step - loss: 0.4595 - accuracy: 0.8233 - val_loss: 0.4168 - val_accuracy: 0.8441\n",
      "Epoch 483/1000\n",
      "239/239 [==============================] - 1s 2ms/step - loss: 0.4565 - accuracy: 0.8235 - val_loss: 0.4156 - val_accuracy: 0.8437\n",
      "Epoch 484/1000\n",
      "239/239 [==============================] - 1s 2ms/step - loss: 0.4564 - accuracy: 0.8238 - val_loss: 0.4145 - val_accuracy: 0.8462\n",
      "Epoch 485/1000\n",
      "239/239 [==============================] - 1s 2ms/step - loss: 0.4579 - accuracy: 0.8232 - val_loss: 0.4142 - val_accuracy: 0.8445\n",
      "Epoch 486/1000\n",
      "239/239 [==============================] - 1s 2ms/step - loss: 0.4577 - accuracy: 0.8229 - val_loss: 0.4114 - val_accuracy: 0.8472\n",
      "Epoch 487/1000\n",
      "239/239 [==============================] - 1s 2ms/step - loss: 0.4577 - accuracy: 0.8244 - val_loss: 0.4139 - val_accuracy: 0.8436\n",
      "Epoch 488/1000\n",
      "239/239 [==============================] - 1s 2ms/step - loss: 0.4614 - accuracy: 0.8229 - val_loss: 0.4156 - val_accuracy: 0.8448\n",
      "Epoch 489/1000\n",
      "239/239 [==============================] - 1s 2ms/step - loss: 0.4566 - accuracy: 0.8247 - val_loss: 0.4165 - val_accuracy: 0.8452\n",
      "Epoch 490/1000\n",
      "239/239 [==============================] - 1s 2ms/step - loss: 0.4563 - accuracy: 0.8243 - val_loss: 0.4159 - val_accuracy: 0.8439\n",
      "Epoch 491/1000\n",
      "239/239 [==============================] - 1s 2ms/step - loss: 0.4569 - accuracy: 0.8224 - val_loss: 0.4163 - val_accuracy: 0.8422\n",
      "Epoch 492/1000\n",
      "239/239 [==============================] - 1s 2ms/step - loss: 0.4574 - accuracy: 0.8233 - val_loss: 0.4143 - val_accuracy: 0.8438\n",
      "Epoch 493/1000\n",
      "239/239 [==============================] - 1s 2ms/step - loss: 0.4588 - accuracy: 0.8235 - val_loss: 0.4167 - val_accuracy: 0.8430\n",
      "Epoch 494/1000\n",
      "239/239 [==============================] - 1s 2ms/step - loss: 0.4583 - accuracy: 0.8235 - val_loss: 0.4133 - val_accuracy: 0.8464\n",
      "Epoch 495/1000\n",
      "239/239 [==============================] - 1s 2ms/step - loss: 0.4572 - accuracy: 0.8232 - val_loss: 0.4134 - val_accuracy: 0.8460\n",
      "Epoch 496/1000\n",
      "239/239 [==============================] - 1s 2ms/step - loss: 0.4565 - accuracy: 0.8247 - val_loss: 0.4145 - val_accuracy: 0.8452\n",
      "Epoch 497/1000\n",
      "239/239 [==============================] - 1s 2ms/step - loss: 0.4563 - accuracy: 0.8233 - val_loss: 0.4144 - val_accuracy: 0.8434\n",
      "Epoch 498/1000\n",
      "239/239 [==============================] - 1s 2ms/step - loss: 0.4564 - accuracy: 0.8241 - val_loss: 0.4160 - val_accuracy: 0.8429\n",
      "Epoch 499/1000\n",
      "239/239 [==============================] - 1s 2ms/step - loss: 0.4578 - accuracy: 0.8244 - val_loss: 0.4161 - val_accuracy: 0.8442\n",
      "Epoch 500/1000\n",
      "239/239 [==============================] - 1s 2ms/step - loss: 0.4608 - accuracy: 0.8235 - val_loss: 0.4178 - val_accuracy: 0.8438\n",
      "Epoch 501/1000\n",
      "239/239 [==============================] - 0s 2ms/step - loss: 0.4566 - accuracy: 0.8239 - val_loss: 0.4154 - val_accuracy: 0.8473\n",
      "Epoch 502/1000\n",
      "239/239 [==============================] - 1s 2ms/step - loss: 0.4558 - accuracy: 0.8240 - val_loss: 0.4138 - val_accuracy: 0.8448\n",
      "Epoch 503/1000\n",
      "239/239 [==============================] - 1s 2ms/step - loss: 0.4576 - accuracy: 0.8230 - val_loss: 0.4133 - val_accuracy: 0.8461\n",
      "Epoch 504/1000\n",
      "239/239 [==============================] - 1s 2ms/step - loss: 0.4563 - accuracy: 0.8237 - val_loss: 0.4160 - val_accuracy: 0.8454\n",
      "Epoch 505/1000\n",
      "239/239 [==============================] - 0s 2ms/step - loss: 0.4564 - accuracy: 0.8229 - val_loss: 0.4123 - val_accuracy: 0.8460\n",
      "Epoch 506/1000\n",
      "239/239 [==============================] - 0s 2ms/step - loss: 0.4593 - accuracy: 0.8237 - val_loss: 0.4137 - val_accuracy: 0.8469\n",
      "Epoch 507/1000\n",
      "239/239 [==============================] - 1s 2ms/step - loss: 0.4567 - accuracy: 0.8243 - val_loss: 0.4155 - val_accuracy: 0.8456\n",
      "Epoch 508/1000\n",
      "239/239 [==============================] - 1s 2ms/step - loss: 0.4549 - accuracy: 0.8254 - val_loss: 0.4134 - val_accuracy: 0.8465\n",
      "Epoch 509/1000\n",
      "239/239 [==============================] - 1s 2ms/step - loss: 0.4551 - accuracy: 0.8247 - val_loss: 0.4133 - val_accuracy: 0.8484\n",
      "Epoch 510/1000\n",
      "239/239 [==============================] - 1s 2ms/step - loss: 0.4565 - accuracy: 0.8249 - val_loss: 0.4137 - val_accuracy: 0.8457\n",
      "Epoch 511/1000\n",
      "239/239 [==============================] - 1s 2ms/step - loss: 0.4573 - accuracy: 0.8234 - val_loss: 0.4179 - val_accuracy: 0.8429\n",
      "Epoch 512/1000\n",
      "239/239 [==============================] - 1s 2ms/step - loss: 0.4568 - accuracy: 0.8246 - val_loss: 0.4166 - val_accuracy: 0.8450\n",
      "Epoch 513/1000\n",
      "239/239 [==============================] - 1s 2ms/step - loss: 0.4568 - accuracy: 0.8254 - val_loss: 0.4158 - val_accuracy: 0.8439\n",
      "Epoch 514/1000\n",
      "239/239 [==============================] - 1s 2ms/step - loss: 0.4564 - accuracy: 0.8235 - val_loss: 0.4135 - val_accuracy: 0.8453\n",
      "Epoch 515/1000\n",
      "239/239 [==============================] - 1s 2ms/step - loss: 0.4579 - accuracy: 0.8238 - val_loss: 0.4150 - val_accuracy: 0.8449\n",
      "Epoch 516/1000\n",
      "239/239 [==============================] - 1s 2ms/step - loss: 0.4568 - accuracy: 0.8235 - val_loss: 0.4146 - val_accuracy: 0.8442\n",
      "Epoch 517/1000\n",
      "239/239 [==============================] - 1s 2ms/step - loss: 0.4566 - accuracy: 0.8242 - val_loss: 0.4126 - val_accuracy: 0.8461\n",
      "Epoch 518/1000\n",
      "239/239 [==============================] - 1s 2ms/step - loss: 0.4570 - accuracy: 0.8250 - val_loss: 0.4122 - val_accuracy: 0.8465\n",
      "Epoch 519/1000\n",
      "239/239 [==============================] - 1s 2ms/step - loss: 0.4572 - accuracy: 0.8245 - val_loss: 0.4099 - val_accuracy: 0.8473\n",
      "Epoch 520/1000\n",
      "239/239 [==============================] - 1s 2ms/step - loss: 0.4549 - accuracy: 0.8256 - val_loss: 0.4149 - val_accuracy: 0.8449\n",
      "Epoch 521/1000\n",
      "239/239 [==============================] - 1s 2ms/step - loss: 0.4561 - accuracy: 0.8252 - val_loss: 0.4135 - val_accuracy: 0.8441\n",
      "Epoch 522/1000\n",
      "239/239 [==============================] - 1s 2ms/step - loss: 0.4574 - accuracy: 0.8245 - val_loss: 0.4136 - val_accuracy: 0.8452\n",
      "Epoch 523/1000\n",
      "239/239 [==============================] - 1s 2ms/step - loss: 0.4568 - accuracy: 0.8241 - val_loss: 0.4170 - val_accuracy: 0.8440\n",
      "Epoch 524/1000\n",
      "239/239 [==============================] - 1s 2ms/step - loss: 0.4549 - accuracy: 0.8246 - val_loss: 0.4134 - val_accuracy: 0.8456\n",
      "Epoch 525/1000\n",
      "239/239 [==============================] - 1s 2ms/step - loss: 0.4581 - accuracy: 0.8243 - val_loss: 0.4128 - val_accuracy: 0.8474\n",
      "Epoch 526/1000\n",
      "239/239 [==============================] - 0s 2ms/step - loss: 0.4562 - accuracy: 0.8246 - val_loss: 0.4167 - val_accuracy: 0.8438\n",
      "Epoch 527/1000\n",
      "239/239 [==============================] - 1s 2ms/step - loss: 0.4574 - accuracy: 0.8242 - val_loss: 0.4140 - val_accuracy: 0.8465\n",
      "Epoch 528/1000\n",
      "239/239 [==============================] - 1s 2ms/step - loss: 0.4564 - accuracy: 0.8241 - val_loss: 0.4173 - val_accuracy: 0.8448\n",
      "Epoch 529/1000\n",
      "239/239 [==============================] - 1s 2ms/step - loss: 0.4575 - accuracy: 0.8230 - val_loss: 0.4133 - val_accuracy: 0.8466\n",
      "Epoch 530/1000\n",
      "239/239 [==============================] - 1s 2ms/step - loss: 0.4554 - accuracy: 0.8251 - val_loss: 0.4146 - val_accuracy: 0.8449\n",
      "Epoch 531/1000\n",
      "239/239 [==============================] - 1s 2ms/step - loss: 0.4543 - accuracy: 0.8254 - val_loss: 0.4135 - val_accuracy: 0.8451\n",
      "Epoch 532/1000\n",
      "239/239 [==============================] - 0s 2ms/step - loss: 0.4566 - accuracy: 0.8244 - val_loss: 0.4119 - val_accuracy: 0.8477\n",
      "Epoch 533/1000\n",
      "239/239 [==============================] - 1s 2ms/step - loss: 0.4572 - accuracy: 0.8238 - val_loss: 0.4138 - val_accuracy: 0.8427\n",
      "Epoch 534/1000\n",
      "239/239 [==============================] - 1s 2ms/step - loss: 0.4575 - accuracy: 0.8236 - val_loss: 0.4132 - val_accuracy: 0.8468\n",
      "Epoch 535/1000\n",
      "239/239 [==============================] - 1s 2ms/step - loss: 0.4548 - accuracy: 0.8239 - val_loss: 0.4150 - val_accuracy: 0.8437\n",
      "Epoch 536/1000\n",
      "239/239 [==============================] - 1s 2ms/step - loss: 0.4572 - accuracy: 0.8237 - val_loss: 0.4152 - val_accuracy: 0.8441\n",
      "Epoch 537/1000\n",
      "239/239 [==============================] - 1s 2ms/step - loss: 0.4556 - accuracy: 0.8251 - val_loss: 0.4136 - val_accuracy: 0.8448\n",
      "Epoch 538/1000\n",
      "239/239 [==============================] - 1s 2ms/step - loss: 0.4552 - accuracy: 0.8240 - val_loss: 0.4172 - val_accuracy: 0.8449\n",
      "Epoch 539/1000\n",
      "239/239 [==============================] - 1s 2ms/step - loss: 0.4530 - accuracy: 0.8250 - val_loss: 0.4102 - val_accuracy: 0.8500\n",
      "Epoch 540/1000\n",
      "239/239 [==============================] - 1s 2ms/step - loss: 0.4550 - accuracy: 0.8251 - val_loss: 0.4157 - val_accuracy: 0.8448\n",
      "Epoch 541/1000\n",
      "239/239 [==============================] - 1s 2ms/step - loss: 0.4567 - accuracy: 0.8227 - val_loss: 0.4125 - val_accuracy: 0.8447\n",
      "Epoch 542/1000\n",
      "239/239 [==============================] - 1s 2ms/step - loss: 0.4554 - accuracy: 0.8243 - val_loss: 0.4109 - val_accuracy: 0.8458\n",
      "Epoch 543/1000\n",
      "239/239 [==============================] - 1s 2ms/step - loss: 0.4556 - accuracy: 0.8239 - val_loss: 0.4130 - val_accuracy: 0.8459\n",
      "Epoch 544/1000\n",
      "239/239 [==============================] - 1s 2ms/step - loss: 0.4521 - accuracy: 0.8259 - val_loss: 0.4138 - val_accuracy: 0.8446\n",
      "Epoch 545/1000\n",
      "239/239 [==============================] - 1s 2ms/step - loss: 0.4544 - accuracy: 0.8245 - val_loss: 0.4134 - val_accuracy: 0.8449\n",
      "Epoch 546/1000\n",
      "239/239 [==============================] - 1s 2ms/step - loss: 0.4545 - accuracy: 0.8260 - val_loss: 0.4147 - val_accuracy: 0.8470\n",
      "Epoch 547/1000\n",
      "239/239 [==============================] - 1s 2ms/step - loss: 0.4535 - accuracy: 0.8270 - val_loss: 0.4142 - val_accuracy: 0.8447\n",
      "Epoch 548/1000\n",
      "239/239 [==============================] - 1s 2ms/step - loss: 0.4552 - accuracy: 0.8253 - val_loss: 0.4112 - val_accuracy: 0.8459\n",
      "Epoch 549/1000\n",
      "239/239 [==============================] - 1s 2ms/step - loss: 0.4542 - accuracy: 0.8247 - val_loss: 0.4145 - val_accuracy: 0.8451\n",
      "Epoch 550/1000\n",
      "239/239 [==============================] - 1s 2ms/step - loss: 0.4553 - accuracy: 0.8247 - val_loss: 0.4137 - val_accuracy: 0.8446\n",
      "Epoch 551/1000\n",
      "239/239 [==============================] - 1s 2ms/step - loss: 0.4553 - accuracy: 0.8239 - val_loss: 0.4122 - val_accuracy: 0.8449\n",
      "Epoch 552/1000\n",
      "239/239 [==============================] - 1s 2ms/step - loss: 0.4535 - accuracy: 0.8260 - val_loss: 0.4147 - val_accuracy: 0.8454\n",
      "Epoch 553/1000\n",
      "239/239 [==============================] - 1s 2ms/step - loss: 0.4574 - accuracy: 0.8247 - val_loss: 0.4138 - val_accuracy: 0.8445\n",
      "Epoch 554/1000\n",
      "239/239 [==============================] - 1s 2ms/step - loss: 0.4555 - accuracy: 0.8241 - val_loss: 0.4105 - val_accuracy: 0.8461\n",
      "Epoch 555/1000\n",
      "239/239 [==============================] - 1s 2ms/step - loss: 0.4525 - accuracy: 0.8254 - val_loss: 0.4163 - val_accuracy: 0.8430\n",
      "Epoch 556/1000\n",
      "239/239 [==============================] - 1s 2ms/step - loss: 0.4548 - accuracy: 0.8255 - val_loss: 0.4161 - val_accuracy: 0.8437\n",
      "Epoch 557/1000\n",
      "239/239 [==============================] - 1s 2ms/step - loss: 0.4549 - accuracy: 0.8242 - val_loss: 0.4122 - val_accuracy: 0.8438\n",
      "Epoch 558/1000\n",
      "239/239 [==============================] - 1s 2ms/step - loss: 0.4566 - accuracy: 0.8232 - val_loss: 0.4148 - val_accuracy: 0.8440\n",
      "Epoch 559/1000\n",
      "239/239 [==============================] - 1s 2ms/step - loss: 0.4538 - accuracy: 0.8251 - val_loss: 0.4145 - val_accuracy: 0.8441\n",
      "Epoch 560/1000\n",
      "239/239 [==============================] - 1s 2ms/step - loss: 0.4557 - accuracy: 0.8245 - val_loss: 0.4124 - val_accuracy: 0.8436\n",
      "Epoch 561/1000\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "239/239 [==============================] - 1s 2ms/step - loss: 0.4546 - accuracy: 0.8256 - val_loss: 0.4136 - val_accuracy: 0.8439\n",
      "Epoch 562/1000\n",
      "239/239 [==============================] - 1s 2ms/step - loss: 0.4526 - accuracy: 0.8251 - val_loss: 0.4156 - val_accuracy: 0.8446\n",
      "Epoch 563/1000\n",
      "239/239 [==============================] - 1s 2ms/step - loss: 0.4546 - accuracy: 0.8241 - val_loss: 0.4136 - val_accuracy: 0.8446\n",
      "Epoch 564/1000\n",
      "239/239 [==============================] - 1s 2ms/step - loss: 0.4534 - accuracy: 0.8254 - val_loss: 0.4140 - val_accuracy: 0.8430\n",
      "Epoch 565/1000\n",
      "239/239 [==============================] - 1s 2ms/step - loss: 0.4560 - accuracy: 0.8243 - val_loss: 0.4142 - val_accuracy: 0.8455\n",
      "Epoch 566/1000\n",
      "239/239 [==============================] - 1s 2ms/step - loss: 0.4535 - accuracy: 0.8251 - val_loss: 0.4123 - val_accuracy: 0.8457\n",
      "Epoch 567/1000\n",
      "239/239 [==============================] - 1s 2ms/step - loss: 0.4516 - accuracy: 0.8256 - val_loss: 0.4153 - val_accuracy: 0.8438\n",
      "Epoch 568/1000\n",
      "239/239 [==============================] - 1s 2ms/step - loss: 0.4526 - accuracy: 0.8263 - val_loss: 0.4147 - val_accuracy: 0.8424\n",
      "Epoch 569/1000\n",
      "239/239 [==============================] - 1s 2ms/step - loss: 0.4561 - accuracy: 0.8248 - val_loss: 0.4159 - val_accuracy: 0.8439\n",
      "Epoch 569: early stopping\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "<keras.src.callbacks.History at 0x145939330>"
      ]
     },
     "execution_count": 69,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# batch size=512\n",
    "model=Sequential()\n",
    "model.add(Dense(128, input_dim=X_train.shape[1], activation=\"relu\"))\n",
    "model.add(Dropout(0.2))\n",
    "model.add(Dense(128, activation=\"relu\"))\n",
    "\n",
    "model.add(Dense(64, activation=\"relu\"))\n",
    "model.add(Dropout(0.2))\n",
    "model.add(Dense(64, activation=\"relu\"))\n",
    "\n",
    "model.add(Dense(32, activation=\"relu\"))\n",
    "model.add(Dropout(0.2))\n",
    "model.add(Dense(16, activation=\"relu\"))\n",
    "model.add(Dropout(0.2))\n",
    "model.add(Dense(3, activation=\"softmax\"))\n",
    "\n",
    "model.compile(loss='categorical_crossentropy', optimizer=Adam(learning_rate=0.001), metrics=['accuracy'])\n",
    "\n",
    "es=EarlyStopping(monitor=\"val_loss\",patience=50,mode=\"auto\",verbose=1)\n",
    "\n",
    "model.fit(X_train,\n",
    "          y_train,\n",
    "          epochs=1000,\n",
    "               batch_size=512,\n",
    "               validation_split=0.1,\n",
    "               verbose=1,callbacks=[es])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 70,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "748/748 [==============================] - 0s 253us/step\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0       0.86      0.94      0.90      7973\n",
      "           1       0.83      0.92      0.87      7973\n",
      "           2       0.85      0.68      0.75      7972\n",
      "\n",
      "    accuracy                           0.85     23918\n",
      "   macro avg       0.85      0.85      0.84     23918\n",
      "weighted avg       0.85      0.85      0.84     23918\n",
      "\n"
     ]
    }
   ],
   "source": [
    "y_pred = model.predict(X_test)\n",
    "y_pred_classes = np.argmax(y_pred, axis=1)\n",
    "y_true = np.argmax(y_test, axis=1)\n",
    "print(classification_report(y_true, y_pred_classes))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 71,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "4236/4236 [==============================] - 1s 252us/step\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0       0.88      0.96      0.92     45176\n",
      "           1       0.85      0.95      0.90     45176\n",
      "           2       0.90      0.71      0.80     45177\n",
      "\n",
      "    accuracy                           0.87    135529\n",
      "   macro avg       0.88      0.87      0.87    135529\n",
      "weighted avg       0.88      0.87      0.87    135529\n",
      "\n"
     ]
    }
   ],
   "source": [
    "y_t_pred = model.predict(X_train)\n",
    "y_t_pred_classes = np.argmax(y_t_pred, axis=1)\n",
    "y_t_true = np.argmax(y_train, axis=1)\n",
    "print(classification_report(y_t_true, y_t_pred_classes))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 72,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "4236/4236 - 1s - loss: 0.3523 - accuracy: 0.8744 - 1s/epoch - 243us/step\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "[0.35226401686668396, 0.8744401335716248]"
      ]
     },
     "execution_count": 72,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "model.evaluate(X_train, y_train, verbose=2)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 73,
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 1/1000\n",
      "239/239 [==============================] - 1s 2ms/step - loss: 0.8332 - accuracy: 0.6470 - val_loss: 0.7083 - val_accuracy: 0.7272\n",
      "Epoch 2/1000\n",
      "239/239 [==============================] - 1s 3ms/step - loss: 0.7607 - accuracy: 0.7060 - val_loss: 0.6958 - val_accuracy: 0.7308\n",
      "Epoch 3/1000\n",
      "239/239 [==============================] - 0s 2ms/step - loss: 0.7475 - accuracy: 0.7116 - val_loss: 0.6950 - val_accuracy: 0.7335\n",
      "Epoch 4/1000\n",
      "239/239 [==============================] - 0s 2ms/step - loss: 0.7424 - accuracy: 0.7125 - val_loss: 0.6955 - val_accuracy: 0.7356\n",
      "Epoch 5/1000\n",
      "239/239 [==============================] - 0s 2ms/step - loss: 0.7387 - accuracy: 0.7154 - val_loss: 0.6950 - val_accuracy: 0.7328\n",
      "Epoch 6/1000\n",
      "239/239 [==============================] - 0s 2ms/step - loss: 0.7365 - accuracy: 0.7154 - val_loss: 0.6915 - val_accuracy: 0.7350\n",
      "Epoch 7/1000\n",
      "239/239 [==============================] - 0s 2ms/step - loss: 0.7343 - accuracy: 0.7152 - val_loss: 0.6865 - val_accuracy: 0.7360\n",
      "Epoch 8/1000\n",
      "239/239 [==============================] - 0s 2ms/step - loss: 0.7329 - accuracy: 0.7162 - val_loss: 0.6906 - val_accuracy: 0.7353\n",
      "Epoch 9/1000\n",
      "239/239 [==============================] - 0s 2ms/step - loss: 0.7293 - accuracy: 0.7172 - val_loss: 0.6931 - val_accuracy: 0.7383\n",
      "Epoch 10/1000\n",
      "239/239 [==============================] - 0s 2ms/step - loss: 0.7308 - accuracy: 0.7159 - val_loss: 0.6932 - val_accuracy: 0.7367\n",
      "Epoch 11/1000\n",
      "239/239 [==============================] - 0s 2ms/step - loss: 0.7299 - accuracy: 0.7176 - val_loss: 0.6937 - val_accuracy: 0.7321\n",
      "Epoch 12/1000\n",
      "239/239 [==============================] - 0s 2ms/step - loss: 0.7293 - accuracy: 0.7200 - val_loss: 0.6865 - val_accuracy: 0.7343\n",
      "Epoch 13/1000\n",
      "239/239 [==============================] - 0s 2ms/step - loss: 0.7289 - accuracy: 0.7202 - val_loss: 0.6934 - val_accuracy: 0.7359\n",
      "Epoch 14/1000\n",
      "239/239 [==============================] - 0s 2ms/step - loss: 0.7259 - accuracy: 0.7224 - val_loss: 0.6895 - val_accuracy: 0.7329\n",
      "Epoch 15/1000\n",
      "239/239 [==============================] - 0s 2ms/step - loss: 0.7253 - accuracy: 0.7216 - val_loss: 0.6892 - val_accuracy: 0.7352\n",
      "Epoch 16/1000\n",
      "239/239 [==============================] - 0s 2ms/step - loss: 0.7272 - accuracy: 0.7213 - val_loss: 0.6872 - val_accuracy: 0.7392\n",
      "Epoch 17/1000\n",
      "239/239 [==============================] - 1s 2ms/step - loss: 0.7254 - accuracy: 0.7220 - val_loss: 0.6936 - val_accuracy: 0.7384\n",
      "Epoch 18/1000\n",
      "239/239 [==============================] - 0s 2ms/step - loss: 0.7251 - accuracy: 0.7224 - val_loss: 0.6945 - val_accuracy: 0.7358\n",
      "Epoch 19/1000\n",
      "239/239 [==============================] - 0s 2ms/step - loss: 0.7235 - accuracy: 0.7224 - val_loss: 0.6945 - val_accuracy: 0.7330\n",
      "Epoch 20/1000\n",
      "239/239 [==============================] - 0s 2ms/step - loss: 0.7235 - accuracy: 0.7220 - val_loss: 0.6862 - val_accuracy: 0.7328\n",
      "Epoch 21/1000\n",
      "239/239 [==============================] - 0s 2ms/step - loss: 0.7221 - accuracy: 0.7221 - val_loss: 0.6914 - val_accuracy: 0.7350\n",
      "Epoch 22/1000\n",
      "239/239 [==============================] - 0s 2ms/step - loss: 0.7222 - accuracy: 0.7235 - val_loss: 0.6871 - val_accuracy: 0.7395\n",
      "Epoch 23/1000\n",
      "239/239 [==============================] - 0s 2ms/step - loss: 0.7251 - accuracy: 0.7213 - val_loss: 0.6884 - val_accuracy: 0.7366\n",
      "Epoch 24/1000\n",
      "239/239 [==============================] - 0s 2ms/step - loss: 0.7243 - accuracy: 0.7205 - val_loss: 0.6926 - val_accuracy: 0.7359\n",
      "Epoch 25/1000\n",
      "239/239 [==============================] - 1s 2ms/step - loss: 0.7230 - accuracy: 0.7228 - val_loss: 0.6911 - val_accuracy: 0.7372\n",
      "Epoch 26/1000\n",
      "239/239 [==============================] - 0s 2ms/step - loss: 0.7234 - accuracy: 0.7217 - val_loss: 0.6913 - val_accuracy: 0.7367\n",
      "Epoch 27/1000\n",
      "239/239 [==============================] - 0s 2ms/step - loss: 0.7233 - accuracy: 0.7219 - val_loss: 0.6919 - val_accuracy: 0.7326\n",
      "Epoch 28/1000\n",
      "239/239 [==============================] - 0s 2ms/step - loss: 0.7215 - accuracy: 0.7231 - val_loss: 0.6852 - val_accuracy: 0.7336\n",
      "Epoch 29/1000\n",
      "239/239 [==============================] - 0s 2ms/step - loss: 0.7199 - accuracy: 0.7244 - val_loss: 0.6916 - val_accuracy: 0.7345\n",
      "Epoch 30/1000\n",
      "239/239 [==============================] - 0s 2ms/step - loss: 0.7202 - accuracy: 0.7245 - val_loss: 0.6877 - val_accuracy: 0.7378\n",
      "Epoch 31/1000\n",
      "239/239 [==============================] - 0s 2ms/step - loss: 0.7211 - accuracy: 0.7239 - val_loss: 0.6921 - val_accuracy: 0.7347\n",
      "Epoch 32/1000\n",
      "239/239 [==============================] - 0s 2ms/step - loss: 0.7210 - accuracy: 0.7233 - val_loss: 0.6870 - val_accuracy: 0.7386\n",
      "Epoch 33/1000\n",
      "239/239 [==============================] - 1s 2ms/step - loss: 0.7212 - accuracy: 0.7237 - val_loss: 0.6903 - val_accuracy: 0.7380\n",
      "Epoch 34/1000\n",
      "239/239 [==============================] - 1s 2ms/step - loss: 0.7205 - accuracy: 0.7243 - val_loss: 0.7020 - val_accuracy: 0.7379\n",
      "Epoch 35/1000\n",
      "239/239 [==============================] - 1s 2ms/step - loss: 0.7234 - accuracy: 0.7230 - val_loss: 0.6912 - val_accuracy: 0.7347\n",
      "Epoch 36/1000\n",
      "239/239 [==============================] - 1s 2ms/step - loss: 0.7231 - accuracy: 0.7225 - val_loss: 0.6963 - val_accuracy: 0.7354\n",
      "Epoch 37/1000\n",
      "239/239 [==============================] - 1s 2ms/step - loss: 0.7203 - accuracy: 0.7236 - val_loss: 0.6874 - val_accuracy: 0.7368\n",
      "Epoch 38/1000\n",
      "239/239 [==============================] - 1s 2ms/step - loss: 0.7210 - accuracy: 0.7236 - val_loss: 0.6898 - val_accuracy: 0.7353\n",
      "Epoch 39/1000\n",
      "239/239 [==============================] - 0s 2ms/step - loss: 0.7206 - accuracy: 0.7234 - val_loss: 0.6875 - val_accuracy: 0.7365\n",
      "Epoch 40/1000\n",
      "239/239 [==============================] - 0s 2ms/step - loss: 0.7218 - accuracy: 0.7233 - val_loss: 0.6888 - val_accuracy: 0.7349\n",
      "Epoch 41/1000\n",
      "239/239 [==============================] - 0s 2ms/step - loss: 0.7221 - accuracy: 0.7229 - val_loss: 0.6923 - val_accuracy: 0.7371\n",
      "Epoch 42/1000\n",
      "239/239 [==============================] - 0s 2ms/step - loss: 0.7211 - accuracy: 0.7225 - val_loss: 0.6857 - val_accuracy: 0.7353\n",
      "Epoch 43/1000\n",
      "239/239 [==============================] - 1s 2ms/step - loss: 0.7208 - accuracy: 0.7222 - val_loss: 0.6910 - val_accuracy: 0.7340\n",
      "Epoch 44/1000\n",
      "239/239 [==============================] - 1s 2ms/step - loss: 0.7203 - accuracy: 0.7225 - val_loss: 0.6879 - val_accuracy: 0.7397\n",
      "Epoch 45/1000\n",
      "239/239 [==============================] - 1s 2ms/step - loss: 0.7215 - accuracy: 0.7233 - val_loss: 0.6989 - val_accuracy: 0.7395\n",
      "Epoch 46/1000\n",
      "239/239 [==============================] - 1s 2ms/step - loss: 0.7207 - accuracy: 0.7232 - val_loss: 0.6832 - val_accuracy: 0.7347\n",
      "Epoch 47/1000\n",
      "239/239 [==============================] - 0s 2ms/step - loss: 0.7197 - accuracy: 0.7251 - val_loss: 0.6851 - val_accuracy: 0.7371\n",
      "Epoch 48/1000\n",
      "239/239 [==============================] - 0s 2ms/step - loss: 0.7209 - accuracy: 0.7226 - val_loss: 0.6976 - val_accuracy: 0.7353\n",
      "Epoch 49/1000\n",
      "239/239 [==============================] - 0s 2ms/step - loss: 0.7204 - accuracy: 0.7234 - val_loss: 0.6899 - val_accuracy: 0.7363\n",
      "Epoch 50/1000\n",
      "239/239 [==============================] - 0s 2ms/step - loss: 0.7173 - accuracy: 0.7255 - val_loss: 0.6960 - val_accuracy: 0.7387\n",
      "Epoch 51/1000\n",
      "239/239 [==============================] - 0s 2ms/step - loss: 0.7199 - accuracy: 0.7242 - val_loss: 0.6950 - val_accuracy: 0.7351\n",
      "Epoch 52/1000\n",
      "239/239 [==============================] - 0s 2ms/step - loss: 0.7214 - accuracy: 0.7226 - val_loss: 0.6921 - val_accuracy: 0.7350\n",
      "Epoch 53/1000\n",
      "239/239 [==============================] - 0s 2ms/step - loss: 0.7205 - accuracy: 0.7227 - val_loss: 0.6908 - val_accuracy: 0.7326\n",
      "Epoch 54/1000\n",
      "239/239 [==============================] - 0s 2ms/step - loss: 0.7189 - accuracy: 0.7227 - val_loss: 0.6896 - val_accuracy: 0.7349\n",
      "Epoch 55/1000\n",
      "239/239 [==============================] - 0s 2ms/step - loss: 0.7191 - accuracy: 0.7240 - val_loss: 0.6935 - val_accuracy: 0.7310\n",
      "Epoch 56/1000\n",
      "239/239 [==============================] - 1s 2ms/step - loss: 0.7187 - accuracy: 0.7239 - val_loss: 0.6843 - val_accuracy: 0.7384\n",
      "Epoch 57/1000\n",
      "239/239 [==============================] - 0s 2ms/step - loss: 0.7202 - accuracy: 0.7228 - val_loss: 0.6859 - val_accuracy: 0.7375\n",
      "Epoch 58/1000\n",
      "239/239 [==============================] - 0s 2ms/step - loss: 0.7181 - accuracy: 0.7232 - val_loss: 0.6961 - val_accuracy: 0.7392\n",
      "Epoch 59/1000\n",
      "239/239 [==============================] - 0s 2ms/step - loss: 0.7182 - accuracy: 0.7235 - val_loss: 0.6879 - val_accuracy: 0.7401\n",
      "Epoch 60/1000\n",
      "239/239 [==============================] - 1s 2ms/step - loss: 0.7224 - accuracy: 0.7233 - val_loss: 0.6882 - val_accuracy: 0.7382\n",
      "Epoch 61/1000\n",
      "239/239 [==============================] - 0s 2ms/step - loss: 0.7228 - accuracy: 0.7231 - val_loss: 0.6967 - val_accuracy: 0.7400\n",
      "Epoch 62/1000\n",
      "239/239 [==============================] - 0s 2ms/step - loss: 0.7232 - accuracy: 0.7232 - val_loss: 0.6935 - val_accuracy: 0.7338\n",
      "Epoch 63/1000\n",
      "239/239 [==============================] - 1s 2ms/step - loss: 0.7210 - accuracy: 0.7236 - val_loss: 0.6921 - val_accuracy: 0.7361\n",
      "Epoch 64/1000\n",
      "239/239 [==============================] - 0s 2ms/step - loss: 0.7199 - accuracy: 0.7251 - val_loss: 0.6911 - val_accuracy: 0.7395\n",
      "Epoch 65/1000\n",
      "239/239 [==============================] - 0s 2ms/step - loss: 0.7221 - accuracy: 0.7232 - val_loss: 0.6976 - val_accuracy: 0.7353\n",
      "Epoch 66/1000\n",
      "239/239 [==============================] - 0s 2ms/step - loss: 0.7209 - accuracy: 0.7234 - val_loss: 0.6907 - val_accuracy: 0.7376\n",
      "Epoch 67/1000\n",
      "239/239 [==============================] - 0s 2ms/step - loss: 0.7215 - accuracy: 0.7223 - val_loss: 0.6891 - val_accuracy: 0.7395\n",
      "Epoch 68/1000\n",
      "239/239 [==============================] - 0s 2ms/step - loss: 0.7206 - accuracy: 0.7232 - val_loss: 0.6862 - val_accuracy: 0.7393\n",
      "Epoch 69/1000\n",
      "239/239 [==============================] - 0s 2ms/step - loss: 0.7216 - accuracy: 0.7226 - val_loss: 0.6883 - val_accuracy: 0.7387\n",
      "Epoch 70/1000\n",
      "239/239 [==============================] - 0s 2ms/step - loss: 0.7241 - accuracy: 0.7215 - val_loss: 0.6974 - val_accuracy: 0.7399\n",
      "Epoch 71/1000\n",
      "239/239 [==============================] - 0s 2ms/step - loss: 0.7227 - accuracy: 0.7231 - val_loss: 0.6972 - val_accuracy: 0.7401\n",
      "Epoch 72/1000\n",
      "239/239 [==============================] - 0s 2ms/step - loss: 0.7214 - accuracy: 0.7252 - val_loss: 0.6901 - val_accuracy: 0.7358\n",
      "Epoch 73/1000\n",
      "239/239 [==============================] - 0s 2ms/step - loss: 0.7205 - accuracy: 0.7234 - val_loss: 0.6933 - val_accuracy: 0.7373\n",
      "Epoch 74/1000\n",
      "239/239 [==============================] - 0s 2ms/step - loss: 0.7207 - accuracy: 0.7249 - val_loss: 0.6916 - val_accuracy: 0.7357\n",
      "Epoch 75/1000\n",
      "239/239 [==============================] - 0s 2ms/step - loss: 0.7219 - accuracy: 0.7249 - val_loss: 0.6912 - val_accuracy: 0.7380\n",
      "Epoch 76/1000\n",
      "239/239 [==============================] - 0s 2ms/step - loss: 0.7220 - accuracy: 0.7244 - val_loss: 0.6913 - val_accuracy: 0.7367\n",
      "Epoch 77/1000\n",
      "239/239 [==============================] - 0s 2ms/step - loss: 0.7225 - accuracy: 0.7235 - val_loss: 0.6962 - val_accuracy: 0.7373\n",
      "Epoch 78/1000\n",
      "239/239 [==============================] - 0s 2ms/step - loss: 0.7216 - accuracy: 0.7239 - val_loss: 0.6880 - val_accuracy: 0.7376\n",
      "Epoch 79/1000\n",
      "239/239 [==============================] - 0s 2ms/step - loss: 0.7205 - accuracy: 0.7243 - val_loss: 0.7032 - val_accuracy: 0.7367\n",
      "Epoch 80/1000\n",
      "239/239 [==============================] - 0s 2ms/step - loss: 0.7211 - accuracy: 0.7236 - val_loss: 0.6930 - val_accuracy: 0.7377\n",
      "Epoch 81/1000\n",
      "239/239 [==============================] - 0s 2ms/step - loss: 0.7225 - accuracy: 0.7220 - val_loss: 0.6888 - val_accuracy: 0.7367\n",
      "Epoch 82/1000\n",
      "239/239 [==============================] - 0s 2ms/step - loss: 0.7213 - accuracy: 0.7237 - val_loss: 0.6855 - val_accuracy: 0.7380\n",
      "Epoch 83/1000\n",
      "239/239 [==============================] - 0s 2ms/step - loss: 0.7211 - accuracy: 0.7249 - val_loss: 0.6915 - val_accuracy: 0.7386\n",
      "Epoch 84/1000\n",
      "239/239 [==============================] - 0s 2ms/step - loss: 0.7210 - accuracy: 0.7246 - val_loss: 0.6927 - val_accuracy: 0.7383\n",
      "Epoch 85/1000\n",
      "239/239 [==============================] - 0s 2ms/step - loss: 0.7242 - accuracy: 0.7230 - val_loss: 0.6944 - val_accuracy: 0.7375\n",
      "Epoch 86/1000\n",
      "239/239 [==============================] - 0s 2ms/step - loss: 0.7232 - accuracy: 0.7238 - val_loss: 0.6850 - val_accuracy: 0.7394\n",
      "Epoch 87/1000\n",
      "239/239 [==============================] - 0s 2ms/step - loss: 0.7233 - accuracy: 0.7217 - val_loss: 0.6934 - val_accuracy: 0.7401\n",
      "Epoch 88/1000\n",
      "239/239 [==============================] - 0s 2ms/step - loss: 0.7222 - accuracy: 0.7238 - val_loss: 0.6839 - val_accuracy: 0.7404\n",
      "Epoch 89/1000\n",
      "239/239 [==============================] - 0s 2ms/step - loss: 0.7218 - accuracy: 0.7244 - val_loss: 0.6908 - val_accuracy: 0.7351\n",
      "Epoch 90/1000\n",
      "239/239 [==============================] - 0s 2ms/step - loss: 0.7214 - accuracy: 0.7233 - val_loss: 0.6924 - val_accuracy: 0.7355\n",
      "Epoch 91/1000\n",
      "239/239 [==============================] - 0s 2ms/step - loss: 0.7220 - accuracy: 0.7230 - val_loss: 0.6959 - val_accuracy: 0.7402\n",
      "Epoch 92/1000\n",
      "239/239 [==============================] - 0s 2ms/step - loss: 0.7223 - accuracy: 0.7226 - val_loss: 0.6890 - val_accuracy: 0.7390\n",
      "Epoch 93/1000\n",
      "239/239 [==============================] - 0s 2ms/step - loss: 0.7216 - accuracy: 0.7237 - val_loss: 0.6874 - val_accuracy: 0.7387\n",
      "Epoch 94/1000\n",
      "239/239 [==============================] - 0s 2ms/step - loss: 0.7210 - accuracy: 0.7243 - val_loss: 0.6849 - val_accuracy: 0.7394\n",
      "Epoch 95/1000\n",
      "239/239 [==============================] - 0s 2ms/step - loss: 0.7213 - accuracy: 0.7247 - val_loss: 0.6871 - val_accuracy: 0.7370\n",
      "Epoch 96/1000\n",
      "239/239 [==============================] - 0s 2ms/step - loss: 0.7213 - accuracy: 0.7233 - val_loss: 0.6936 - val_accuracy: 0.7374\n",
      "Epoch 96: early stopping\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "<keras.src.callbacks.History at 0x144e4fb50>"
      ]
     },
     "execution_count": 73,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# batch size=512, lr=0.005\n",
    "model=Sequential()\n",
    "model.add(Dense(128, activation=\"relu\"))\n",
    "model.add(Dropout(0.8))\n",
    "model.add(Dense(128, activation=\"relu\"))\n",
    "\n",
    "model.add(Dense(64, activation=\"relu\"))\n",
    "model.add(Dropout(0.2))\n",
    "model.add(Dense(32, activation=\"relu\"))\n",
    "\n",
    "model.add(Dense(16, activation=\"relu\"))\n",
    "model.add(Dropout(0.2))\n",
    "model.add(Dense(8, activation=\"relu\"))\n",
    "model.add(Dropout(0.2))\n",
    "model.add(Dense(3, activation=\"softmax\"))\n",
    "\n",
    "model.compile(loss='categorical_crossentropy', optimizer=Adam(learning_rate=0.005), metrics=['accuracy'])\n",
    "\n",
    "es=EarlyStopping(monitor=\"val_loss\",patience=50,mode=\"auto\",verbose=1)\n",
    "\n",
    "model.fit(X_train,\n",
    "          y_train,\n",
    "          epochs=1000,\n",
    "               batch_size=512,\n",
    "               validation_split=0.1,\n",
    "               verbose=1,callbacks=[es])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 74,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "748/748 [==============================] - 0s 248us/step\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0       0.71      0.86      0.78      7973\n",
      "           1       0.74      0.78      0.76      7973\n",
      "           2       0.75      0.55      0.64      7972\n",
      "\n",
      "    accuracy                           0.73     23918\n",
      "   macro avg       0.73      0.73      0.73     23918\n",
      "weighted avg       0.73      0.73      0.73     23918\n",
      "\n"
     ]
    }
   ],
   "source": [
    "y_pred = model.predict(X_test)\n",
    "y_pred_classes = np.argmax(y_pred, axis=1)\n",
    "y_true = np.argmax(y_test, axis=1)\n",
    "print(classification_report(y_true, y_pred_classes))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 75,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "4236/4236 [==============================] - 1s 258us/step\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0       0.71      0.86      0.78     45176\n",
      "           1       0.75      0.77      0.76     45176\n",
      "           2       0.75      0.57      0.65     45177\n",
      "\n",
      "    accuracy                           0.73    135529\n",
      "   macro avg       0.74      0.73      0.73    135529\n",
      "weighted avg       0.74      0.73      0.73    135529\n",
      "\n"
     ]
    }
   ],
   "source": [
    "y_t_pred = model.predict(X_train)\n",
    "y_t_pred_classes = np.argmax(y_t_pred, axis=1)\n",
    "y_t_true = np.argmax(y_train, axis=1)\n",
    "print(classification_report(y_t_true, y_t_pred_classes))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 78,
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 1/1000\n",
      "239/239 [==============================] - 0s 1ms/step - loss: 0.8604 - accuracy: 0.6218 - val_loss: 0.7108 - val_accuracy: 0.7251\n",
      "Epoch 2/1000\n",
      "239/239 [==============================] - 0s 974us/step - loss: 0.7581 - accuracy: 0.7081 - val_loss: 0.6912 - val_accuracy: 0.7331\n",
      "Epoch 3/1000\n",
      "239/239 [==============================] - 0s 960us/step - loss: 0.7378 - accuracy: 0.7169 - val_loss: 0.6809 - val_accuracy: 0.7384\n",
      "Epoch 4/1000\n",
      "239/239 [==============================] - 0s 1ms/step - loss: 0.7279 - accuracy: 0.7213 - val_loss: 0.6734 - val_accuracy: 0.7393\n",
      "Epoch 5/1000\n",
      "239/239 [==============================] - 0s 1ms/step - loss: 0.7214 - accuracy: 0.7242 - val_loss: 0.6687 - val_accuracy: 0.7407\n",
      "Epoch 6/1000\n",
      "239/239 [==============================] - 0s 904us/step - loss: 0.7155 - accuracy: 0.7260 - val_loss: 0.6662 - val_accuracy: 0.7430\n",
      "Epoch 7/1000\n",
      "239/239 [==============================] - 0s 955us/step - loss: 0.7091 - accuracy: 0.7282 - val_loss: 0.6609 - val_accuracy: 0.7435\n",
      "Epoch 8/1000\n",
      "239/239 [==============================] - 0s 957us/step - loss: 0.7069 - accuracy: 0.7294 - val_loss: 0.6608 - val_accuracy: 0.7454\n",
      "Epoch 9/1000\n",
      "239/239 [==============================] - 0s 967us/step - loss: 0.7036 - accuracy: 0.7306 - val_loss: 0.6557 - val_accuracy: 0.7469\n",
      "Epoch 10/1000\n",
      "239/239 [==============================] - 0s 962us/step - loss: 0.7002 - accuracy: 0.7316 - val_loss: 0.6549 - val_accuracy: 0.7474\n",
      "Epoch 11/1000\n",
      "239/239 [==============================] - 0s 960us/step - loss: 0.6962 - accuracy: 0.7335 - val_loss: 0.6504 - val_accuracy: 0.7487\n",
      "Epoch 12/1000\n",
      "239/239 [==============================] - 0s 958us/step - loss: 0.6960 - accuracy: 0.7329 - val_loss: 0.6485 - val_accuracy: 0.7488\n",
      "Epoch 13/1000\n",
      "239/239 [==============================] - 0s 957us/step - loss: 0.6929 - accuracy: 0.7342 - val_loss: 0.6500 - val_accuracy: 0.7487\n",
      "Epoch 14/1000\n",
      "239/239 [==============================] - 0s 960us/step - loss: 0.6908 - accuracy: 0.7345 - val_loss: 0.6451 - val_accuracy: 0.7500\n",
      "Epoch 15/1000\n",
      "239/239 [==============================] - 0s 984us/step - loss: 0.6890 - accuracy: 0.7347 - val_loss: 0.6432 - val_accuracy: 0.7505\n",
      "Epoch 16/1000\n",
      "239/239 [==============================] - 0s 984us/step - loss: 0.6889 - accuracy: 0.7348 - val_loss: 0.6452 - val_accuracy: 0.7498\n",
      "Epoch 17/1000\n",
      "239/239 [==============================] - 0s 923us/step - loss: 0.6859 - accuracy: 0.7356 - val_loss: 0.6419 - val_accuracy: 0.7503\n",
      "Epoch 18/1000\n",
      "239/239 [==============================] - 0s 944us/step - loss: 0.6844 - accuracy: 0.7377 - val_loss: 0.6389 - val_accuracy: 0.7503\n",
      "Epoch 19/1000\n",
      "239/239 [==============================] - 0s 1ms/step - loss: 0.6835 - accuracy: 0.7364 - val_loss: 0.6389 - val_accuracy: 0.7505\n",
      "Epoch 20/1000\n",
      "239/239 [==============================] - 0s 985us/step - loss: 0.6837 - accuracy: 0.7362 - val_loss: 0.6395 - val_accuracy: 0.7513\n",
      "Epoch 21/1000\n",
      "239/239 [==============================] - 0s 1ms/step - loss: 0.6831 - accuracy: 0.7365 - val_loss: 0.6399 - val_accuracy: 0.7516\n",
      "Epoch 22/1000\n",
      "239/239 [==============================] - 0s 1ms/step - loss: 0.6798 - accuracy: 0.7371 - val_loss: 0.6373 - val_accuracy: 0.7526\n",
      "Epoch 23/1000\n",
      "239/239 [==============================] - 0s 1ms/step - loss: 0.6793 - accuracy: 0.7380 - val_loss: 0.6369 - val_accuracy: 0.7519\n",
      "Epoch 24/1000\n",
      "239/239 [==============================] - 0s 1ms/step - loss: 0.6794 - accuracy: 0.7381 - val_loss: 0.6335 - val_accuracy: 0.7517\n",
      "Epoch 25/1000\n",
      "239/239 [==============================] - 0s 970us/step - loss: 0.6789 - accuracy: 0.7380 - val_loss: 0.6385 - val_accuracy: 0.7542\n",
      "Epoch 26/1000\n",
      "239/239 [==============================] - 0s 954us/step - loss: 0.6758 - accuracy: 0.7378 - val_loss: 0.6315 - val_accuracy: 0.7541\n",
      "Epoch 27/1000\n",
      "239/239 [==============================] - 0s 943us/step - loss: 0.6764 - accuracy: 0.7390 - val_loss: 0.6333 - val_accuracy: 0.7550\n",
      "Epoch 28/1000\n",
      "239/239 [==============================] - 0s 970us/step - loss: 0.6751 - accuracy: 0.7388 - val_loss: 0.6316 - val_accuracy: 0.7544\n",
      "Epoch 29/1000\n",
      "239/239 [==============================] - 0s 961us/step - loss: 0.6758 - accuracy: 0.7379 - val_loss: 0.6316 - val_accuracy: 0.7539\n",
      "Epoch 30/1000\n",
      "239/239 [==============================] - 0s 949us/step - loss: 0.6749 - accuracy: 0.7388 - val_loss: 0.6303 - val_accuracy: 0.7540\n",
      "Epoch 31/1000\n",
      "239/239 [==============================] - 0s 896us/step - loss: 0.6724 - accuracy: 0.7401 - val_loss: 0.6299 - val_accuracy: 0.7543\n",
      "Epoch 32/1000\n",
      "239/239 [==============================] - 0s 890us/step - loss: 0.6729 - accuracy: 0.7390 - val_loss: 0.6287 - val_accuracy: 0.7556\n",
      "Epoch 33/1000\n",
      "239/239 [==============================] - 0s 910us/step - loss: 0.6714 - accuracy: 0.7409 - val_loss: 0.6273 - val_accuracy: 0.7559\n",
      "Epoch 34/1000\n",
      "239/239 [==============================] - 0s 1ms/step - loss: 0.6692 - accuracy: 0.7404 - val_loss: 0.6276 - val_accuracy: 0.7555\n",
      "Epoch 35/1000\n",
      "239/239 [==============================] - 0s 889us/step - loss: 0.6709 - accuracy: 0.7402 - val_loss: 0.6268 - val_accuracy: 0.7556\n",
      "Epoch 36/1000\n",
      "239/239 [==============================] - 0s 891us/step - loss: 0.6686 - accuracy: 0.7407 - val_loss: 0.6268 - val_accuracy: 0.7559\n",
      "Epoch 37/1000\n",
      "239/239 [==============================] - 0s 888us/step - loss: 0.6693 - accuracy: 0.7404 - val_loss: 0.6280 - val_accuracy: 0.7558\n",
      "Epoch 38/1000\n",
      "239/239 [==============================] - 0s 917us/step - loss: 0.6705 - accuracy: 0.7399 - val_loss: 0.6235 - val_accuracy: 0.7558\n",
      "Epoch 39/1000\n",
      "239/239 [==============================] - 0s 928us/step - loss: 0.6685 - accuracy: 0.7395 - val_loss: 0.6244 - val_accuracy: 0.7563\n",
      "Epoch 40/1000\n",
      "239/239 [==============================] - 0s 956us/step - loss: 0.6693 - accuracy: 0.7410 - val_loss: 0.6240 - val_accuracy: 0.7561\n",
      "Epoch 41/1000\n",
      "239/239 [==============================] - 0s 966us/step - loss: 0.6677 - accuracy: 0.7396 - val_loss: 0.6234 - val_accuracy: 0.7558\n",
      "Epoch 42/1000\n",
      "239/239 [==============================] - 0s 955us/step - loss: 0.6640 - accuracy: 0.7418 - val_loss: 0.6214 - val_accuracy: 0.7567\n",
      "Epoch 43/1000\n",
      "239/239 [==============================] - 0s 979us/step - loss: 0.6665 - accuracy: 0.7411 - val_loss: 0.6224 - val_accuracy: 0.7547\n",
      "Epoch 44/1000\n",
      "239/239 [==============================] - 0s 950us/step - loss: 0.6649 - accuracy: 0.7414 - val_loss: 0.6197 - val_accuracy: 0.7576\n",
      "Epoch 45/1000\n",
      "239/239 [==============================] - 0s 957us/step - loss: 0.6653 - accuracy: 0.7406 - val_loss: 0.6210 - val_accuracy: 0.7561\n",
      "Epoch 46/1000\n",
      "239/239 [==============================] - 0s 965us/step - loss: 0.6630 - accuracy: 0.7415 - val_loss: 0.6207 - val_accuracy: 0.7564\n",
      "Epoch 47/1000\n",
      "239/239 [==============================] - 0s 967us/step - loss: 0.6649 - accuracy: 0.7407 - val_loss: 0.6217 - val_accuracy: 0.7553\n",
      "Epoch 48/1000\n",
      "239/239 [==============================] - 0s 960us/step - loss: 0.6635 - accuracy: 0.7423 - val_loss: 0.6214 - val_accuracy: 0.7568\n",
      "Epoch 49/1000\n",
      "239/239 [==============================] - 0s 964us/step - loss: 0.6635 - accuracy: 0.7412 - val_loss: 0.6195 - val_accuracy: 0.7569\n",
      "Epoch 50/1000\n",
      "239/239 [==============================] - 0s 959us/step - loss: 0.6630 - accuracy: 0.7410 - val_loss: 0.6185 - val_accuracy: 0.7578\n",
      "Epoch 51/1000\n",
      "239/239 [==============================] - 0s 958us/step - loss: 0.6623 - accuracy: 0.7420 - val_loss: 0.6209 - val_accuracy: 0.7571\n",
      "Epoch 52/1000\n",
      "239/239 [==============================] - 0s 946us/step - loss: 0.6616 - accuracy: 0.7411 - val_loss: 0.6172 - val_accuracy: 0.7572\n",
      "Epoch 53/1000\n",
      "239/239 [==============================] - 0s 979us/step - loss: 0.6605 - accuracy: 0.7424 - val_loss: 0.6161 - val_accuracy: 0.7574\n",
      "Epoch 54/1000\n",
      "239/239 [==============================] - 0s 958us/step - loss: 0.6623 - accuracy: 0.7424 - val_loss: 0.6183 - val_accuracy: 0.7584\n",
      "Epoch 55/1000\n",
      "239/239 [==============================] - 0s 1ms/step - loss: 0.6619 - accuracy: 0.7419 - val_loss: 0.6175 - val_accuracy: 0.7578\n",
      "Epoch 56/1000\n",
      "239/239 [==============================] - 0s 943us/step - loss: 0.6596 - accuracy: 0.7420 - val_loss: 0.6154 - val_accuracy: 0.7591\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 57/1000\n",
      "239/239 [==============================] - 0s 949us/step - loss: 0.6615 - accuracy: 0.7421 - val_loss: 0.6170 - val_accuracy: 0.7564\n",
      "Epoch 58/1000\n",
      "239/239 [==============================] - 0s 944us/step - loss: 0.6601 - accuracy: 0.7424 - val_loss: 0.6151 - val_accuracy: 0.7582\n",
      "Epoch 59/1000\n",
      "239/239 [==============================] - 0s 932us/step - loss: 0.6616 - accuracy: 0.7422 - val_loss: 0.6154 - val_accuracy: 0.7589\n",
      "Epoch 60/1000\n",
      "239/239 [==============================] - 0s 956us/step - loss: 0.6612 - accuracy: 0.7421 - val_loss: 0.6204 - val_accuracy: 0.7559\n",
      "Epoch 61/1000\n",
      "239/239 [==============================] - 0s 956us/step - loss: 0.6587 - accuracy: 0.7430 - val_loss: 0.6138 - val_accuracy: 0.7587\n",
      "Epoch 62/1000\n",
      "239/239 [==============================] - 0s 949us/step - loss: 0.6605 - accuracy: 0.7436 - val_loss: 0.6142 - val_accuracy: 0.7586\n",
      "Epoch 63/1000\n",
      "239/239 [==============================] - 0s 967us/step - loss: 0.6592 - accuracy: 0.7427 - val_loss: 0.6151 - val_accuracy: 0.7567\n",
      "Epoch 64/1000\n",
      "239/239 [==============================] - 0s 959us/step - loss: 0.6579 - accuracy: 0.7427 - val_loss: 0.6141 - val_accuracy: 0.7587\n",
      "Epoch 65/1000\n",
      "239/239 [==============================] - 0s 945us/step - loss: 0.6581 - accuracy: 0.7426 - val_loss: 0.6130 - val_accuracy: 0.7596\n",
      "Epoch 66/1000\n",
      "239/239 [==============================] - 0s 968us/step - loss: 0.6575 - accuracy: 0.7440 - val_loss: 0.6114 - val_accuracy: 0.7596\n",
      "Epoch 67/1000\n",
      "239/239 [==============================] - 0s 944us/step - loss: 0.6575 - accuracy: 0.7430 - val_loss: 0.6152 - val_accuracy: 0.7577\n",
      "Epoch 68/1000\n",
      "239/239 [==============================] - 0s 942us/step - loss: 0.6563 - accuracy: 0.7441 - val_loss: 0.6119 - val_accuracy: 0.7605\n",
      "Epoch 69/1000\n",
      "239/239 [==============================] - 0s 958us/step - loss: 0.6578 - accuracy: 0.7434 - val_loss: 0.6124 - val_accuracy: 0.7581\n",
      "Epoch 70/1000\n",
      "239/239 [==============================] - 0s 920us/step - loss: 0.6555 - accuracy: 0.7440 - val_loss: 0.6120 - val_accuracy: 0.7587\n",
      "Epoch 71/1000\n",
      "239/239 [==============================] - 0s 925us/step - loss: 0.6547 - accuracy: 0.7449 - val_loss: 0.6104 - val_accuracy: 0.7599\n",
      "Epoch 72/1000\n",
      "239/239 [==============================] - 0s 899us/step - loss: 0.6551 - accuracy: 0.7437 - val_loss: 0.6101 - val_accuracy: 0.7603\n",
      "Epoch 73/1000\n",
      "239/239 [==============================] - 0s 895us/step - loss: 0.6551 - accuracy: 0.7432 - val_loss: 0.6114 - val_accuracy: 0.7615\n",
      "Epoch 74/1000\n",
      "239/239 [==============================] - 0s 890us/step - loss: 0.6555 - accuracy: 0.7447 - val_loss: 0.6095 - val_accuracy: 0.7604\n",
      "Epoch 75/1000\n",
      "239/239 [==============================] - 0s 920us/step - loss: 0.6543 - accuracy: 0.7445 - val_loss: 0.6096 - val_accuracy: 0.7614\n",
      "Epoch 76/1000\n",
      "239/239 [==============================] - 0s 954us/step - loss: 0.6539 - accuracy: 0.7437 - val_loss: 0.6086 - val_accuracy: 0.7612\n",
      "Epoch 77/1000\n",
      "239/239 [==============================] - 0s 952us/step - loss: 0.6550 - accuracy: 0.7443 - val_loss: 0.6085 - val_accuracy: 0.7602\n",
      "Epoch 78/1000\n",
      "239/239 [==============================] - 0s 940us/step - loss: 0.6537 - accuracy: 0.7443 - val_loss: 0.6098 - val_accuracy: 0.7604\n",
      "Epoch 79/1000\n",
      "239/239 [==============================] - 0s 934us/step - loss: 0.6543 - accuracy: 0.7444 - val_loss: 0.6096 - val_accuracy: 0.7603\n",
      "Epoch 80/1000\n",
      "239/239 [==============================] - 0s 909us/step - loss: 0.6547 - accuracy: 0.7442 - val_loss: 0.6082 - val_accuracy: 0.7626\n",
      "Epoch 81/1000\n",
      "239/239 [==============================] - 0s 872us/step - loss: 0.6538 - accuracy: 0.7443 - val_loss: 0.6080 - val_accuracy: 0.7607\n",
      "Epoch 82/1000\n",
      "239/239 [==============================] - 0s 856us/step - loss: 0.6537 - accuracy: 0.7442 - val_loss: 0.6089 - val_accuracy: 0.7609\n",
      "Epoch 83/1000\n",
      "239/239 [==============================] - 0s 850us/step - loss: 0.6519 - accuracy: 0.7449 - val_loss: 0.6084 - val_accuracy: 0.7599\n",
      "Epoch 84/1000\n",
      "239/239 [==============================] - 0s 918us/step - loss: 0.6514 - accuracy: 0.7447 - val_loss: 0.6092 - val_accuracy: 0.7605\n",
      "Epoch 85/1000\n",
      "239/239 [==============================] - 0s 923us/step - loss: 0.6522 - accuracy: 0.7455 - val_loss: 0.6084 - val_accuracy: 0.7609\n",
      "Epoch 86/1000\n",
      "239/239 [==============================] - 0s 920us/step - loss: 0.6510 - accuracy: 0.7456 - val_loss: 0.6069 - val_accuracy: 0.7606\n",
      "Epoch 87/1000\n",
      "239/239 [==============================] - 0s 873us/step - loss: 0.6514 - accuracy: 0.7455 - val_loss: 0.6050 - val_accuracy: 0.7617\n",
      "Epoch 88/1000\n",
      "239/239 [==============================] - 0s 845us/step - loss: 0.6523 - accuracy: 0.7446 - val_loss: 0.6066 - val_accuracy: 0.7603\n",
      "Epoch 89/1000\n",
      "239/239 [==============================] - 0s 851us/step - loss: 0.6521 - accuracy: 0.7452 - val_loss: 0.6074 - val_accuracy: 0.7622\n",
      "Epoch 90/1000\n",
      "239/239 [==============================] - 0s 856us/step - loss: 0.6509 - accuracy: 0.7444 - val_loss: 0.6076 - val_accuracy: 0.7638\n",
      "Epoch 91/1000\n",
      "239/239 [==============================] - 0s 935us/step - loss: 0.6520 - accuracy: 0.7452 - val_loss: 0.6060 - val_accuracy: 0.7620\n",
      "Epoch 92/1000\n",
      "239/239 [==============================] - 0s 926us/step - loss: 0.6511 - accuracy: 0.7453 - val_loss: 0.6044 - val_accuracy: 0.7617\n",
      "Epoch 93/1000\n",
      "239/239 [==============================] - 0s 871us/step - loss: 0.6522 - accuracy: 0.7447 - val_loss: 0.6047 - val_accuracy: 0.7615\n",
      "Epoch 94/1000\n",
      "239/239 [==============================] - 0s 861us/step - loss: 0.6512 - accuracy: 0.7455 - val_loss: 0.6075 - val_accuracy: 0.7618\n",
      "Epoch 95/1000\n",
      "239/239 [==============================] - 0s 918us/step - loss: 0.6502 - accuracy: 0.7446 - val_loss: 0.6070 - val_accuracy: 0.7610\n",
      "Epoch 96/1000\n",
      "239/239 [==============================] - 0s 919us/step - loss: 0.6511 - accuracy: 0.7459 - val_loss: 0.6065 - val_accuracy: 0.7623\n",
      "Epoch 97/1000\n",
      "239/239 [==============================] - 0s 932us/step - loss: 0.6502 - accuracy: 0.7461 - val_loss: 0.6044 - val_accuracy: 0.7636\n",
      "Epoch 98/1000\n",
      "239/239 [==============================] - 0s 929us/step - loss: 0.6488 - accuracy: 0.7476 - val_loss: 0.6055 - val_accuracy: 0.7629\n",
      "Epoch 99/1000\n",
      "239/239 [==============================] - 0s 924us/step - loss: 0.6493 - accuracy: 0.7456 - val_loss: 0.6051 - val_accuracy: 0.7614\n",
      "Epoch 100/1000\n",
      "239/239 [==============================] - 0s 915us/step - loss: 0.6514 - accuracy: 0.7454 - val_loss: 0.6065 - val_accuracy: 0.7600\n",
      "Epoch 101/1000\n",
      "239/239 [==============================] - 0s 919us/step - loss: 0.6495 - accuracy: 0.7460 - val_loss: 0.6037 - val_accuracy: 0.7606\n",
      "Epoch 102/1000\n",
      "239/239 [==============================] - 0s 926us/step - loss: 0.6494 - accuracy: 0.7454 - val_loss: 0.6053 - val_accuracy: 0.7629\n",
      "Epoch 103/1000\n",
      "239/239 [==============================] - 0s 914us/step - loss: 0.6499 - accuracy: 0.7452 - val_loss: 0.6040 - val_accuracy: 0.7615\n",
      "Epoch 104/1000\n",
      "239/239 [==============================] - 0s 914us/step - loss: 0.6505 - accuracy: 0.7455 - val_loss: 0.6029 - val_accuracy: 0.7623\n",
      "Epoch 105/1000\n",
      "239/239 [==============================] - 0s 924us/step - loss: 0.6485 - accuracy: 0.7460 - val_loss: 0.6030 - val_accuracy: 0.7627\n",
      "Epoch 106/1000\n",
      "239/239 [==============================] - 0s 941us/step - loss: 0.6490 - accuracy: 0.7458 - val_loss: 0.6061 - val_accuracy: 0.7608\n",
      "Epoch 107/1000\n",
      "239/239 [==============================] - 0s 932us/step - loss: 0.6485 - accuracy: 0.7466 - val_loss: 0.6047 - val_accuracy: 0.7644\n",
      "Epoch 108/1000\n",
      "239/239 [==============================] - 0s 898us/step - loss: 0.6485 - accuracy: 0.7460 - val_loss: 0.6049 - val_accuracy: 0.7631\n",
      "Epoch 109/1000\n",
      "239/239 [==============================] - 0s 922us/step - loss: 0.6488 - accuracy: 0.7471 - val_loss: 0.6035 - val_accuracy: 0.7631\n",
      "Epoch 110/1000\n",
      "239/239 [==============================] - 0s 911us/step - loss: 0.6498 - accuracy: 0.7461 - val_loss: 0.6027 - val_accuracy: 0.7625\n",
      "Epoch 111/1000\n",
      "239/239 [==============================] - 0s 906us/step - loss: 0.6483 - accuracy: 0.7452 - val_loss: 0.6055 - val_accuracy: 0.7603\n",
      "Epoch 112/1000\n",
      "239/239 [==============================] - 0s 923us/step - loss: 0.6481 - accuracy: 0.7464 - val_loss: 0.6037 - val_accuracy: 0.7616\n",
      "Epoch 113/1000\n",
      "239/239 [==============================] - 0s 1ms/step - loss: 0.6482 - accuracy: 0.7458 - val_loss: 0.6026 - val_accuracy: 0.7629\n",
      "Epoch 114/1000\n",
      "239/239 [==============================] - 0s 941us/step - loss: 0.6477 - accuracy: 0.7459 - val_loss: 0.6046 - val_accuracy: 0.7634\n",
      "Epoch 115/1000\n",
      "239/239 [==============================] - 0s 1ms/step - loss: 0.6474 - accuracy: 0.7467 - val_loss: 0.6056 - val_accuracy: 0.7625\n",
      "Epoch 116/1000\n",
      "239/239 [==============================] - 0s 953us/step - loss: 0.6474 - accuracy: 0.7472 - val_loss: 0.6027 - val_accuracy: 0.7618\n",
      "Epoch 117/1000\n",
      "239/239 [==============================] - 0s 912us/step - loss: 0.6477 - accuracy: 0.7465 - val_loss: 0.6043 - val_accuracy: 0.7618\n",
      "Epoch 118/1000\n",
      "239/239 [==============================] - 0s 1ms/step - loss: 0.6485 - accuracy: 0.7462 - val_loss: 0.6045 - val_accuracy: 0.7623\n",
      "Epoch 119/1000\n",
      "239/239 [==============================] - 0s 986us/step - loss: 0.6491 - accuracy: 0.7455 - val_loss: 0.6028 - val_accuracy: 0.7618\n",
      "Epoch 120/1000\n",
      "239/239 [==============================] - 0s 1ms/step - loss: 0.6472 - accuracy: 0.7463 - val_loss: 0.6031 - val_accuracy: 0.7615\n",
      "Epoch 121/1000\n",
      "239/239 [==============================] - 0s 1ms/step - loss: 0.6469 - accuracy: 0.7466 - val_loss: 0.6017 - val_accuracy: 0.7620\n",
      "Epoch 122/1000\n",
      "239/239 [==============================] - 0s 1ms/step - loss: 0.6477 - accuracy: 0.7466 - val_loss: 0.5994 - val_accuracy: 0.7632\n",
      "Epoch 123/1000\n",
      "239/239 [==============================] - 0s 932us/step - loss: 0.6474 - accuracy: 0.7468 - val_loss: 0.6019 - val_accuracy: 0.7623\n",
      "Epoch 124/1000\n",
      "239/239 [==============================] - 0s 1ms/step - loss: 0.6477 - accuracy: 0.7462 - val_loss: 0.6009 - val_accuracy: 0.7619\n",
      "Epoch 125/1000\n",
      "239/239 [==============================] - 0s 1ms/step - loss: 0.6479 - accuracy: 0.7466 - val_loss: 0.6017 - val_accuracy: 0.7644\n",
      "Epoch 126/1000\n",
      "239/239 [==============================] - 0s 1ms/step - loss: 0.6458 - accuracy: 0.7473 - val_loss: 0.6038 - val_accuracy: 0.7615\n",
      "Epoch 127/1000\n",
      "239/239 [==============================] - 0s 985us/step - loss: 0.6459 - accuracy: 0.7463 - val_loss: 0.6012 - val_accuracy: 0.7629\n",
      "Epoch 128/1000\n",
      "239/239 [==============================] - 0s 936us/step - loss: 0.6465 - accuracy: 0.7472 - val_loss: 0.5990 - val_accuracy: 0.7637\n",
      "Epoch 129/1000\n",
      "239/239 [==============================] - 0s 896us/step - loss: 0.6450 - accuracy: 0.7478 - val_loss: 0.6014 - val_accuracy: 0.7629\n",
      "Epoch 130/1000\n",
      "239/239 [==============================] - 0s 927us/step - loss: 0.6442 - accuracy: 0.7475 - val_loss: 0.6011 - val_accuracy: 0.7634\n",
      "Epoch 131/1000\n",
      "239/239 [==============================] - 0s 916us/step - loss: 0.6476 - accuracy: 0.7462 - val_loss: 0.6027 - val_accuracy: 0.7631\n",
      "Epoch 132/1000\n",
      "239/239 [==============================] - 0s 919us/step - loss: 0.6464 - accuracy: 0.7471 - val_loss: 0.5999 - val_accuracy: 0.7640\n",
      "Epoch 133/1000\n",
      "239/239 [==============================] - 0s 915us/step - loss: 0.6452 - accuracy: 0.7470 - val_loss: 0.5992 - val_accuracy: 0.7646\n",
      "Epoch 134/1000\n",
      "239/239 [==============================] - 0s 901us/step - loss: 0.6439 - accuracy: 0.7464 - val_loss: 0.6029 - val_accuracy: 0.7632\n",
      "Epoch 135/1000\n",
      "239/239 [==============================] - 0s 1ms/step - loss: 0.6458 - accuracy: 0.7467 - val_loss: 0.6019 - val_accuracy: 0.7623\n",
      "Epoch 136/1000\n",
      "239/239 [==============================] - 0s 950us/step - loss: 0.6445 - accuracy: 0.7470 - val_loss: 0.5995 - val_accuracy: 0.7634\n",
      "Epoch 137/1000\n",
      "239/239 [==============================] - 0s 926us/step - loss: 0.6453 - accuracy: 0.7468 - val_loss: 0.6036 - val_accuracy: 0.7626\n",
      "Epoch 138/1000\n",
      "239/239 [==============================] - 0s 931us/step - loss: 0.6466 - accuracy: 0.7468 - val_loss: 0.5994 - val_accuracy: 0.7633\n",
      "Epoch 139/1000\n",
      "239/239 [==============================] - 0s 904us/step - loss: 0.6435 - accuracy: 0.7495 - val_loss: 0.6011 - val_accuracy: 0.7652\n",
      "Epoch 140/1000\n",
      "239/239 [==============================] - 0s 922us/step - loss: 0.6441 - accuracy: 0.7485 - val_loss: 0.5978 - val_accuracy: 0.7646\n",
      "Epoch 141/1000\n",
      "239/239 [==============================] - 0s 929us/step - loss: 0.6437 - accuracy: 0.7475 - val_loss: 0.5988 - val_accuracy: 0.7640\n",
      "Epoch 142/1000\n",
      "239/239 [==============================] - 0s 893us/step - loss: 0.6463 - accuracy: 0.7480 - val_loss: 0.6000 - val_accuracy: 0.7638\n",
      "Epoch 143/1000\n",
      "239/239 [==============================] - 0s 887us/step - loss: 0.6460 - accuracy: 0.7473 - val_loss: 0.5995 - val_accuracy: 0.7640\n",
      "Epoch 144/1000\n",
      "239/239 [==============================] - 0s 852us/step - loss: 0.6466 - accuracy: 0.7472 - val_loss: 0.6020 - val_accuracy: 0.7629\n",
      "Epoch 145/1000\n",
      "239/239 [==============================] - 0s 920us/step - loss: 0.6438 - accuracy: 0.7476 - val_loss: 0.6000 - val_accuracy: 0.7620\n",
      "Epoch 146/1000\n",
      "239/239 [==============================] - 0s 919us/step - loss: 0.6441 - accuracy: 0.7479 - val_loss: 0.6001 - val_accuracy: 0.7632\n",
      "Epoch 147/1000\n",
      "239/239 [==============================] - 0s 900us/step - loss: 0.6450 - accuracy: 0.7487 - val_loss: 0.6016 - val_accuracy: 0.7621\n",
      "Epoch 148/1000\n",
      "239/239 [==============================] - 0s 908us/step - loss: 0.6442 - accuracy: 0.7489 - val_loss: 0.6009 - val_accuracy: 0.7646\n",
      "Epoch 149/1000\n",
      "239/239 [==============================] - 0s 881us/step - loss: 0.6453 - accuracy: 0.7477 - val_loss: 0.5974 - val_accuracy: 0.7658\n",
      "Epoch 150/1000\n",
      "239/239 [==============================] - 0s 901us/step - loss: 0.6451 - accuracy: 0.7475 - val_loss: 0.5995 - val_accuracy: 0.7634\n",
      "Epoch 151/1000\n",
      "239/239 [==============================] - 0s 917us/step - loss: 0.6448 - accuracy: 0.7472 - val_loss: 0.6001 - val_accuracy: 0.7621\n",
      "Epoch 152/1000\n",
      "239/239 [==============================] - 0s 904us/step - loss: 0.6434 - accuracy: 0.7483 - val_loss: 0.6001 - val_accuracy: 0.7624\n",
      "Epoch 153/1000\n",
      "239/239 [==============================] - 0s 928us/step - loss: 0.6423 - accuracy: 0.7481 - val_loss: 0.5966 - val_accuracy: 0.7628\n",
      "Epoch 154/1000\n",
      "239/239 [==============================] - 0s 918us/step - loss: 0.6428 - accuracy: 0.7486 - val_loss: 0.5955 - val_accuracy: 0.7632\n",
      "Epoch 155/1000\n",
      "239/239 [==============================] - 0s 882us/step - loss: 0.6439 - accuracy: 0.7482 - val_loss: 0.5978 - val_accuracy: 0.7647\n",
      "Epoch 156/1000\n",
      "239/239 [==============================] - 0s 886us/step - loss: 0.6448 - accuracy: 0.7482 - val_loss: 0.5987 - val_accuracy: 0.7641\n",
      "Epoch 157/1000\n",
      "239/239 [==============================] - 0s 864us/step - loss: 0.6424 - accuracy: 0.7485 - val_loss: 0.5976 - val_accuracy: 0.7644\n",
      "Epoch 158/1000\n",
      "239/239 [==============================] - 0s 907us/step - loss: 0.6408 - accuracy: 0.7486 - val_loss: 0.6001 - val_accuracy: 0.7627\n",
      "Epoch 159/1000\n",
      "239/239 [==============================] - 0s 901us/step - loss: 0.6438 - accuracy: 0.7476 - val_loss: 0.5966 - val_accuracy: 0.7646\n",
      "Epoch 160/1000\n",
      "239/239 [==============================] - 0s 922us/step - loss: 0.6450 - accuracy: 0.7476 - val_loss: 0.5969 - val_accuracy: 0.7656\n",
      "Epoch 161/1000\n",
      "239/239 [==============================] - 0s 923us/step - loss: 0.6433 - accuracy: 0.7486 - val_loss: 0.5956 - val_accuracy: 0.7657\n",
      "Epoch 162/1000\n",
      "239/239 [==============================] - 0s 906us/step - loss: 0.6427 - accuracy: 0.7477 - val_loss: 0.5968 - val_accuracy: 0.7624\n",
      "Epoch 163/1000\n",
      "239/239 [==============================] - 0s 899us/step - loss: 0.6434 - accuracy: 0.7473 - val_loss: 0.5977 - val_accuracy: 0.7641\n",
      "Epoch 164/1000\n",
      "239/239 [==============================] - 0s 905us/step - loss: 0.6422 - accuracy: 0.7484 - val_loss: 0.5953 - val_accuracy: 0.7644\n",
      "Epoch 165/1000\n",
      "239/239 [==============================] - 0s 902us/step - loss: 0.6418 - accuracy: 0.7474 - val_loss: 0.5964 - val_accuracy: 0.7634\n",
      "Epoch 166/1000\n",
      "239/239 [==============================] - 0s 883us/step - loss: 0.6428 - accuracy: 0.7480 - val_loss: 0.5966 - val_accuracy: 0.7643\n",
      "Epoch 167/1000\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "239/239 [==============================] - 0s 864us/step - loss: 0.6429 - accuracy: 0.7481 - val_loss: 0.5952 - val_accuracy: 0.7641\n",
      "Epoch 168/1000\n",
      "239/239 [==============================] - 0s 871us/step - loss: 0.6420 - accuracy: 0.7483 - val_loss: 0.5964 - val_accuracy: 0.7634\n",
      "Epoch 169/1000\n",
      "239/239 [==============================] - 0s 853us/step - loss: 0.6432 - accuracy: 0.7482 - val_loss: 0.5959 - val_accuracy: 0.7646\n",
      "Epoch 170/1000\n",
      "239/239 [==============================] - 0s 904us/step - loss: 0.6416 - accuracy: 0.7490 - val_loss: 0.5971 - val_accuracy: 0.7646\n",
      "Epoch 171/1000\n",
      "239/239 [==============================] - 0s 917us/step - loss: 0.6419 - accuracy: 0.7490 - val_loss: 0.5986 - val_accuracy: 0.7637\n",
      "Epoch 172/1000\n",
      "239/239 [==============================] - 0s 918us/step - loss: 0.6419 - accuracy: 0.7481 - val_loss: 0.5966 - val_accuracy: 0.7635\n",
      "Epoch 173/1000\n",
      "239/239 [==============================] - 0s 904us/step - loss: 0.6431 - accuracy: 0.7483 - val_loss: 0.5970 - val_accuracy: 0.7636\n",
      "Epoch 174/1000\n",
      "239/239 [==============================] - 0s 921us/step - loss: 0.6407 - accuracy: 0.7480 - val_loss: 0.5968 - val_accuracy: 0.7646\n",
      "Epoch 175/1000\n",
      "239/239 [==============================] - 0s 919us/step - loss: 0.6420 - accuracy: 0.7479 - val_loss: 0.5976 - val_accuracy: 0.7641\n",
      "Epoch 176/1000\n",
      "239/239 [==============================] - 0s 904us/step - loss: 0.6409 - accuracy: 0.7481 - val_loss: 0.5978 - val_accuracy: 0.7637\n",
      "Epoch 177/1000\n",
      "239/239 [==============================] - 0s 907us/step - loss: 0.6421 - accuracy: 0.7493 - val_loss: 0.5963 - val_accuracy: 0.7664\n",
      "Epoch 178/1000\n",
      "239/239 [==============================] - 0s 906us/step - loss: 0.6420 - accuracy: 0.7479 - val_loss: 0.5969 - val_accuracy: 0.7660\n",
      "Epoch 179/1000\n",
      "239/239 [==============================] - 0s 906us/step - loss: 0.6397 - accuracy: 0.7481 - val_loss: 0.5963 - val_accuracy: 0.7660\n",
      "Epoch 180/1000\n",
      "239/239 [==============================] - 0s 906us/step - loss: 0.6427 - accuracy: 0.7492 - val_loss: 0.5965 - val_accuracy: 0.7655\n",
      "Epoch 181/1000\n",
      "239/239 [==============================] - 0s 914us/step - loss: 0.6397 - accuracy: 0.7489 - val_loss: 0.5964 - val_accuracy: 0.7651\n",
      "Epoch 182/1000\n",
      "239/239 [==============================] - 0s 921us/step - loss: 0.6434 - accuracy: 0.7479 - val_loss: 0.5971 - val_accuracy: 0.7632\n",
      "Epoch 183/1000\n",
      "239/239 [==============================] - 0s 894us/step - loss: 0.6417 - accuracy: 0.7485 - val_loss: 0.5967 - val_accuracy: 0.7641\n",
      "Epoch 184/1000\n",
      "239/239 [==============================] - 0s 858us/step - loss: 0.6411 - accuracy: 0.7498 - val_loss: 0.5978 - val_accuracy: 0.7643\n",
      "Epoch 185/1000\n",
      "239/239 [==============================] - 0s 851us/step - loss: 0.6412 - accuracy: 0.7497 - val_loss: 0.5960 - val_accuracy: 0.7639\n",
      "Epoch 186/1000\n",
      "239/239 [==============================] - 0s 926us/step - loss: 0.6403 - accuracy: 0.7496 - val_loss: 0.5948 - val_accuracy: 0.7646\n",
      "Epoch 187/1000\n",
      "239/239 [==============================] - 0s 905us/step - loss: 0.6405 - accuracy: 0.7487 - val_loss: 0.5948 - val_accuracy: 0.7653\n",
      "Epoch 188/1000\n",
      "239/239 [==============================] - 0s 1ms/step - loss: 0.6396 - accuracy: 0.7480 - val_loss: 0.5948 - val_accuracy: 0.7643\n",
      "Epoch 189/1000\n",
      "239/239 [==============================] - 0s 906us/step - loss: 0.6407 - accuracy: 0.7487 - val_loss: 0.5942 - val_accuracy: 0.7659\n",
      "Epoch 190/1000\n",
      "239/239 [==============================] - 0s 903us/step - loss: 0.6401 - accuracy: 0.7489 - val_loss: 0.5952 - val_accuracy: 0.7662\n",
      "Epoch 191/1000\n",
      "239/239 [==============================] - 0s 898us/step - loss: 0.6412 - accuracy: 0.7494 - val_loss: 0.5988 - val_accuracy: 0.7633\n",
      "Epoch 192/1000\n",
      "239/239 [==============================] - 0s 906us/step - loss: 0.6411 - accuracy: 0.7492 - val_loss: 0.5965 - val_accuracy: 0.7659\n",
      "Epoch 193/1000\n",
      "239/239 [==============================] - 0s 905us/step - loss: 0.6401 - accuracy: 0.7493 - val_loss: 0.5967 - val_accuracy: 0.7652\n",
      "Epoch 194/1000\n",
      "239/239 [==============================] - 0s 899us/step - loss: 0.6404 - accuracy: 0.7481 - val_loss: 0.5951 - val_accuracy: 0.7659\n",
      "Epoch 195/1000\n",
      "239/239 [==============================] - 0s 895us/step - loss: 0.6406 - accuracy: 0.7489 - val_loss: 0.5956 - val_accuracy: 0.7651\n",
      "Epoch 196/1000\n",
      "239/239 [==============================] - 0s 897us/step - loss: 0.6407 - accuracy: 0.7494 - val_loss: 0.5924 - val_accuracy: 0.7668\n",
      "Epoch 197/1000\n",
      "239/239 [==============================] - 0s 959us/step - loss: 0.6399 - accuracy: 0.7488 - val_loss: 0.5959 - val_accuracy: 0.7646\n",
      "Epoch 198/1000\n",
      "239/239 [==============================] - 0s 981us/step - loss: 0.6396 - accuracy: 0.7481 - val_loss: 0.5942 - val_accuracy: 0.7642\n",
      "Epoch 199/1000\n",
      "239/239 [==============================] - 0s 903us/step - loss: 0.6398 - accuracy: 0.7486 - val_loss: 0.5944 - val_accuracy: 0.7665\n",
      "Epoch 200/1000\n",
      "239/239 [==============================] - 0s 902us/step - loss: 0.6397 - accuracy: 0.7490 - val_loss: 0.5939 - val_accuracy: 0.7658\n",
      "Epoch 201/1000\n",
      "239/239 [==============================] - 0s 891us/step - loss: 0.6399 - accuracy: 0.7491 - val_loss: 0.5949 - val_accuracy: 0.7651\n",
      "Epoch 202/1000\n",
      "239/239 [==============================] - 0s 887us/step - loss: 0.6388 - accuracy: 0.7490 - val_loss: 0.5954 - val_accuracy: 0.7652\n",
      "Epoch 203/1000\n",
      "239/239 [==============================] - 0s 846us/step - loss: 0.6403 - accuracy: 0.7488 - val_loss: 0.5927 - val_accuracy: 0.7646\n",
      "Epoch 204/1000\n",
      "239/239 [==============================] - 0s 845us/step - loss: 0.6410 - accuracy: 0.7485 - val_loss: 0.5945 - val_accuracy: 0.7654\n",
      "Epoch 205/1000\n",
      "239/239 [==============================] - 0s 849us/step - loss: 0.6407 - accuracy: 0.7491 - val_loss: 0.5964 - val_accuracy: 0.7646\n",
      "Epoch 206/1000\n",
      "239/239 [==============================] - 0s 904us/step - loss: 0.6405 - accuracy: 0.7483 - val_loss: 0.5949 - val_accuracy: 0.7651\n",
      "Epoch 207/1000\n",
      "239/239 [==============================] - 0s 913us/step - loss: 0.6402 - accuracy: 0.7498 - val_loss: 0.5955 - val_accuracy: 0.7654\n",
      "Epoch 208/1000\n",
      "239/239 [==============================] - 0s 919us/step - loss: 0.6397 - accuracy: 0.7490 - val_loss: 0.5958 - val_accuracy: 0.7645\n",
      "Epoch 209/1000\n",
      "239/239 [==============================] - 0s 908us/step - loss: 0.6371 - accuracy: 0.7501 - val_loss: 0.5927 - val_accuracy: 0.7646\n",
      "Epoch 210/1000\n",
      "239/239 [==============================] - 0s 905us/step - loss: 0.6399 - accuracy: 0.7498 - val_loss: 0.5929 - val_accuracy: 0.7655\n",
      "Epoch 211/1000\n",
      "239/239 [==============================] - 0s 900us/step - loss: 0.6376 - accuracy: 0.7495 - val_loss: 0.5946 - val_accuracy: 0.7652\n",
      "Epoch 212/1000\n",
      "239/239 [==============================] - 0s 936us/step - loss: 0.6390 - accuracy: 0.7485 - val_loss: 0.5928 - val_accuracy: 0.7649\n",
      "Epoch 213/1000\n",
      "239/239 [==============================] - 0s 922us/step - loss: 0.6394 - accuracy: 0.7495 - val_loss: 0.5932 - val_accuracy: 0.7654\n",
      "Epoch 214/1000\n",
      "239/239 [==============================] - 0s 925us/step - loss: 0.6392 - accuracy: 0.7507 - val_loss: 0.5946 - val_accuracy: 0.7644\n",
      "Epoch 215/1000\n",
      "239/239 [==============================] - 0s 900us/step - loss: 0.6386 - accuracy: 0.7492 - val_loss: 0.5929 - val_accuracy: 0.7651\n",
      "Epoch 216/1000\n",
      "239/239 [==============================] - 0s 911us/step - loss: 0.6375 - accuracy: 0.7504 - val_loss: 0.5958 - val_accuracy: 0.7636\n",
      "Epoch 217/1000\n",
      "239/239 [==============================] - 0s 897us/step - loss: 0.6372 - accuracy: 0.7497 - val_loss: 0.5965 - val_accuracy: 0.7623\n",
      "Epoch 218/1000\n",
      "239/239 [==============================] - 0s 853us/step - loss: 0.6383 - accuracy: 0.7489 - val_loss: 0.5915 - val_accuracy: 0.7663\n",
      "Epoch 219/1000\n",
      "239/239 [==============================] - 0s 921us/step - loss: 0.6391 - accuracy: 0.7492 - val_loss: 0.5929 - val_accuracy: 0.7657\n",
      "Epoch 220/1000\n",
      "239/239 [==============================] - 0s 939us/step - loss: 0.6369 - accuracy: 0.7493 - val_loss: 0.5929 - val_accuracy: 0.7660\n",
      "Epoch 221/1000\n",
      "239/239 [==============================] - 0s 939us/step - loss: 0.6377 - accuracy: 0.7511 - val_loss: 0.5925 - val_accuracy: 0.7647\n",
      "Epoch 222/1000\n",
      "239/239 [==============================] - 0s 934us/step - loss: 0.6402 - accuracy: 0.7491 - val_loss: 0.5941 - val_accuracy: 0.7674\n",
      "Epoch 223/1000\n",
      "239/239 [==============================] - 0s 919us/step - loss: 0.6386 - accuracy: 0.7501 - val_loss: 0.5940 - val_accuracy: 0.7677\n",
      "Epoch 224/1000\n",
      "239/239 [==============================] - 0s 904us/step - loss: 0.6388 - accuracy: 0.7491 - val_loss: 0.5949 - val_accuracy: 0.7659\n",
      "Epoch 225/1000\n",
      "239/239 [==============================] - 0s 921us/step - loss: 0.6393 - accuracy: 0.7494 - val_loss: 0.5952 - val_accuracy: 0.7644\n",
      "Epoch 226/1000\n",
      "239/239 [==============================] - 0s 910us/step - loss: 0.6389 - accuracy: 0.7494 - val_loss: 0.5907 - val_accuracy: 0.7676\n",
      "Epoch 227/1000\n",
      "239/239 [==============================] - 0s 907us/step - loss: 0.6375 - accuracy: 0.7501 - val_loss: 0.5923 - val_accuracy: 0.7663\n",
      "Epoch 228/1000\n",
      "239/239 [==============================] - 0s 911us/step - loss: 0.6369 - accuracy: 0.7496 - val_loss: 0.5922 - val_accuracy: 0.7671\n",
      "Epoch 229/1000\n",
      "239/239 [==============================] - 0s 901us/step - loss: 0.6392 - accuracy: 0.7493 - val_loss: 0.5913 - val_accuracy: 0.7650\n",
      "Epoch 230/1000\n",
      "239/239 [==============================] - 0s 925us/step - loss: 0.6389 - accuracy: 0.7497 - val_loss: 0.5915 - val_accuracy: 0.7673\n",
      "Epoch 231/1000\n",
      "239/239 [==============================] - 0s 921us/step - loss: 0.6375 - accuracy: 0.7497 - val_loss: 0.5919 - val_accuracy: 0.7657\n",
      "Epoch 232/1000\n",
      "239/239 [==============================] - 0s 888us/step - loss: 0.6370 - accuracy: 0.7503 - val_loss: 0.5926 - val_accuracy: 0.7656\n",
      "Epoch 233/1000\n",
      "239/239 [==============================] - 0s 896us/step - loss: 0.6366 - accuracy: 0.7498 - val_loss: 0.5934 - val_accuracy: 0.7639\n",
      "Epoch 234/1000\n",
      "239/239 [==============================] - 0s 903us/step - loss: 0.6352 - accuracy: 0.7499 - val_loss: 0.5918 - val_accuracy: 0.7663\n",
      "Epoch 235/1000\n",
      "239/239 [==============================] - 0s 920us/step - loss: 0.6361 - accuracy: 0.7508 - val_loss: 0.5915 - val_accuracy: 0.7671\n",
      "Epoch 236/1000\n",
      "239/239 [==============================] - 0s 954us/step - loss: 0.6386 - accuracy: 0.7508 - val_loss: 0.5933 - val_accuracy: 0.7660\n",
      "Epoch 237/1000\n",
      "239/239 [==============================] - 0s 905us/step - loss: 0.6375 - accuracy: 0.7497 - val_loss: 0.5934 - val_accuracy: 0.7637\n",
      "Epoch 238/1000\n",
      "239/239 [==============================] - 0s 908us/step - loss: 0.6374 - accuracy: 0.7500 - val_loss: 0.5936 - val_accuracy: 0.7651\n",
      "Epoch 239/1000\n",
      "239/239 [==============================] - 0s 900us/step - loss: 0.6368 - accuracy: 0.7499 - val_loss: 0.5921 - val_accuracy: 0.7640\n",
      "Epoch 240/1000\n",
      "239/239 [==============================] - 0s 1ms/step - loss: 0.6360 - accuracy: 0.7516 - val_loss: 0.5925 - val_accuracy: 0.7648\n",
      "Epoch 241/1000\n",
      "239/239 [==============================] - 0s 926us/step - loss: 0.6377 - accuracy: 0.7509 - val_loss: 0.5937 - val_accuracy: 0.7657\n",
      "Epoch 242/1000\n",
      "239/239 [==============================] - 0s 900us/step - loss: 0.6364 - accuracy: 0.7495 - val_loss: 0.5914 - val_accuracy: 0.7653\n",
      "Epoch 243/1000\n",
      "239/239 [==============================] - 0s 925us/step - loss: 0.6362 - accuracy: 0.7506 - val_loss: 0.5920 - val_accuracy: 0.7659\n",
      "Epoch 244/1000\n",
      "239/239 [==============================] - 0s 906us/step - loss: 0.6373 - accuracy: 0.7504 - val_loss: 0.5907 - val_accuracy: 0.7657\n",
      "Epoch 245/1000\n",
      "239/239 [==============================] - 0s 919us/step - loss: 0.6363 - accuracy: 0.7499 - val_loss: 0.5916 - val_accuracy: 0.7676\n",
      "Epoch 246/1000\n",
      "239/239 [==============================] - 0s 905us/step - loss: 0.6355 - accuracy: 0.7507 - val_loss: 0.5920 - val_accuracy: 0.7677\n",
      "Epoch 247/1000\n",
      "239/239 [==============================] - 0s 908us/step - loss: 0.6366 - accuracy: 0.7495 - val_loss: 0.5910 - val_accuracy: 0.7669\n",
      "Epoch 248/1000\n",
      "239/239 [==============================] - 0s 905us/step - loss: 0.6374 - accuracy: 0.7497 - val_loss: 0.5927 - val_accuracy: 0.7657\n",
      "Epoch 249/1000\n",
      "239/239 [==============================] - 0s 911us/step - loss: 0.6377 - accuracy: 0.7504 - val_loss: 0.5919 - val_accuracy: 0.7656\n",
      "Epoch 250/1000\n",
      "239/239 [==============================] - 0s 938us/step - loss: 0.6348 - accuracy: 0.7513 - val_loss: 0.5917 - val_accuracy: 0.7662\n",
      "Epoch 251/1000\n",
      "239/239 [==============================] - 0s 933us/step - loss: 0.6362 - accuracy: 0.7501 - val_loss: 0.5903 - val_accuracy: 0.7656\n",
      "Epoch 252/1000\n",
      "239/239 [==============================] - 0s 915us/step - loss: 0.6381 - accuracy: 0.7506 - val_loss: 0.5924 - val_accuracy: 0.7669\n",
      "Epoch 253/1000\n",
      "239/239 [==============================] - 0s 927us/step - loss: 0.6351 - accuracy: 0.7501 - val_loss: 0.5902 - val_accuracy: 0.7675\n",
      "Epoch 254/1000\n",
      "239/239 [==============================] - 0s 990us/step - loss: 0.6368 - accuracy: 0.7497 - val_loss: 0.5921 - val_accuracy: 0.7656\n",
      "Epoch 255/1000\n",
      "239/239 [==============================] - 0s 999us/step - loss: 0.6357 - accuracy: 0.7500 - val_loss: 0.5912 - val_accuracy: 0.7665\n",
      "Epoch 256/1000\n",
      "239/239 [==============================] - 0s 976us/step - loss: 0.6359 - accuracy: 0.7508 - val_loss: 0.5883 - val_accuracy: 0.7678\n",
      "Epoch 257/1000\n",
      "239/239 [==============================] - 0s 985us/step - loss: 0.6362 - accuracy: 0.7508 - val_loss: 0.5906 - val_accuracy: 0.7668\n",
      "Epoch 258/1000\n",
      "239/239 [==============================] - 0s 986us/step - loss: 0.6357 - accuracy: 0.7500 - val_loss: 0.5916 - val_accuracy: 0.7659\n",
      "Epoch 259/1000\n",
      "239/239 [==============================] - 0s 996us/step - loss: 0.6354 - accuracy: 0.7500 - val_loss: 0.5913 - val_accuracy: 0.7664\n",
      "Epoch 260/1000\n",
      "239/239 [==============================] - 0s 1ms/step - loss: 0.6351 - accuracy: 0.7494 - val_loss: 0.5909 - val_accuracy: 0.7662\n",
      "Epoch 261/1000\n",
      "239/239 [==============================] - 0s 1ms/step - loss: 0.6367 - accuracy: 0.7509 - val_loss: 0.5897 - val_accuracy: 0.7660\n",
      "Epoch 262/1000\n",
      "239/239 [==============================] - 0s 945us/step - loss: 0.6365 - accuracy: 0.7499 - val_loss: 0.5909 - val_accuracy: 0.7671\n",
      "Epoch 263/1000\n",
      "239/239 [==============================] - 0s 932us/step - loss: 0.6351 - accuracy: 0.7503 - val_loss: 0.5890 - val_accuracy: 0.7673\n",
      "Epoch 264/1000\n",
      "239/239 [==============================] - 0s 929us/step - loss: 0.6366 - accuracy: 0.7499 - val_loss: 0.5901 - val_accuracy: 0.7661\n",
      "Epoch 265/1000\n",
      "239/239 [==============================] - 0s 935us/step - loss: 0.6375 - accuracy: 0.7504 - val_loss: 0.5883 - val_accuracy: 0.7671\n",
      "Epoch 266/1000\n",
      "239/239 [==============================] - 0s 903us/step - loss: 0.6362 - accuracy: 0.7504 - val_loss: 0.5890 - val_accuracy: 0.7671\n",
      "Epoch 267/1000\n",
      "239/239 [==============================] - 0s 893us/step - loss: 0.6347 - accuracy: 0.7511 - val_loss: 0.5896 - val_accuracy: 0.7671\n",
      "Epoch 268/1000\n",
      "239/239 [==============================] - 0s 1000us/step - loss: 0.6366 - accuracy: 0.7501 - val_loss: 0.5878 - val_accuracy: 0.7701\n",
      "Epoch 269/1000\n",
      "239/239 [==============================] - 0s 943us/step - loss: 0.6345 - accuracy: 0.7511 - val_loss: 0.5896 - val_accuracy: 0.7668\n",
      "Epoch 270/1000\n",
      "239/239 [==============================] - 0s 907us/step - loss: 0.6356 - accuracy: 0.7514 - val_loss: 0.5907 - val_accuracy: 0.7663\n",
      "Epoch 271/1000\n",
      "239/239 [==============================] - 0s 967us/step - loss: 0.6341 - accuracy: 0.7511 - val_loss: 0.5883 - val_accuracy: 0.7674\n",
      "Epoch 272/1000\n",
      "239/239 [==============================] - 0s 947us/step - loss: 0.6354 - accuracy: 0.7505 - val_loss: 0.5875 - val_accuracy: 0.7665\n",
      "Epoch 273/1000\n",
      "239/239 [==============================] - 0s 959us/step - loss: 0.6352 - accuracy: 0.7510 - val_loss: 0.5911 - val_accuracy: 0.7677\n",
      "Epoch 274/1000\n",
      "239/239 [==============================] - 0s 913us/step - loss: 0.6358 - accuracy: 0.7504 - val_loss: 0.5889 - val_accuracy: 0.7688\n",
      "Epoch 275/1000\n",
      "239/239 [==============================] - 0s 929us/step - loss: 0.6342 - accuracy: 0.7504 - val_loss: 0.5886 - val_accuracy: 0.7660\n",
      "Epoch 276/1000\n",
      "239/239 [==============================] - 0s 934us/step - loss: 0.6351 - accuracy: 0.7510 - val_loss: 0.5887 - val_accuracy: 0.7686\n",
      "Epoch 277/1000\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "239/239 [==============================] - 0s 958us/step - loss: 0.6352 - accuracy: 0.7502 - val_loss: 0.5888 - val_accuracy: 0.7684\n",
      "Epoch 278/1000\n",
      "239/239 [==============================] - 0s 928us/step - loss: 0.6361 - accuracy: 0.7498 - val_loss: 0.5875 - val_accuracy: 0.7657\n",
      "Epoch 279/1000\n",
      "239/239 [==============================] - 0s 967us/step - loss: 0.6355 - accuracy: 0.7504 - val_loss: 0.5875 - val_accuracy: 0.7679\n",
      "Epoch 280/1000\n",
      "239/239 [==============================] - 0s 936us/step - loss: 0.6340 - accuracy: 0.7511 - val_loss: 0.5893 - val_accuracy: 0.7669\n",
      "Epoch 281/1000\n",
      "239/239 [==============================] - 0s 883us/step - loss: 0.6352 - accuracy: 0.7515 - val_loss: 0.5877 - val_accuracy: 0.7670\n",
      "Epoch 282/1000\n",
      "239/239 [==============================] - 0s 1ms/step - loss: 0.6346 - accuracy: 0.7506 - val_loss: 0.5892 - val_accuracy: 0.7674\n",
      "Epoch 283/1000\n",
      "239/239 [==============================] - 0s 939us/step - loss: 0.6349 - accuracy: 0.7513 - val_loss: 0.5877 - val_accuracy: 0.7679\n",
      "Epoch 284/1000\n",
      "239/239 [==============================] - 0s 911us/step - loss: 0.6351 - accuracy: 0.7516 - val_loss: 0.5867 - val_accuracy: 0.7682\n",
      "Epoch 285/1000\n",
      "239/239 [==============================] - 0s 864us/step - loss: 0.6360 - accuracy: 0.7501 - val_loss: 0.5881 - val_accuracy: 0.7682\n",
      "Epoch 286/1000\n",
      "239/239 [==============================] - 0s 863us/step - loss: 0.6344 - accuracy: 0.7513 - val_loss: 0.5867 - val_accuracy: 0.7696\n",
      "Epoch 287/1000\n",
      "239/239 [==============================] - 0s 890us/step - loss: 0.6348 - accuracy: 0.7510 - val_loss: 0.5898 - val_accuracy: 0.7688\n",
      "Epoch 288/1000\n",
      "239/239 [==============================] - 0s 867us/step - loss: 0.6357 - accuracy: 0.7508 - val_loss: 0.5885 - val_accuracy: 0.7687\n",
      "Epoch 289/1000\n",
      "239/239 [==============================] - 0s 906us/step - loss: 0.6340 - accuracy: 0.7507 - val_loss: 0.5873 - val_accuracy: 0.7678\n",
      "Epoch 290/1000\n",
      "239/239 [==============================] - 0s 1ms/step - loss: 0.6350 - accuracy: 0.7507 - val_loss: 0.5870 - val_accuracy: 0.7683\n",
      "Epoch 291/1000\n",
      "239/239 [==============================] - 0s 957us/step - loss: 0.6336 - accuracy: 0.7506 - val_loss: 0.5872 - val_accuracy: 0.7701\n",
      "Epoch 292/1000\n",
      "239/239 [==============================] - 0s 913us/step - loss: 0.6351 - accuracy: 0.7508 - val_loss: 0.5890 - val_accuracy: 0.7677\n",
      "Epoch 293/1000\n",
      "239/239 [==============================] - 0s 1ms/step - loss: 0.6342 - accuracy: 0.7506 - val_loss: 0.5861 - val_accuracy: 0.7693\n",
      "Epoch 294/1000\n",
      "239/239 [==============================] - 0s 961us/step - loss: 0.6342 - accuracy: 0.7514 - val_loss: 0.5887 - val_accuracy: 0.7695\n",
      "Epoch 295/1000\n",
      "239/239 [==============================] - 0s 946us/step - loss: 0.6334 - accuracy: 0.7507 - val_loss: 0.5875 - val_accuracy: 0.7685\n",
      "Epoch 296/1000\n",
      "239/239 [==============================] - 0s 955us/step - loss: 0.6360 - accuracy: 0.7511 - val_loss: 0.5875 - val_accuracy: 0.7692\n",
      "Epoch 297/1000\n",
      "239/239 [==============================] - 0s 938us/step - loss: 0.6336 - accuracy: 0.7512 - val_loss: 0.5888 - val_accuracy: 0.7685\n",
      "Epoch 298/1000\n",
      "239/239 [==============================] - 0s 1ms/step - loss: 0.6351 - accuracy: 0.7523 - val_loss: 0.5885 - val_accuracy: 0.7698\n",
      "Epoch 299/1000\n",
      "239/239 [==============================] - 0s 1ms/step - loss: 0.6349 - accuracy: 0.7506 - val_loss: 0.5887 - val_accuracy: 0.7663\n",
      "Epoch 300/1000\n",
      "239/239 [==============================] - 0s 1ms/step - loss: 0.6328 - accuracy: 0.7509 - val_loss: 0.5884 - val_accuracy: 0.7693\n",
      "Epoch 301/1000\n",
      "239/239 [==============================] - 0s 1ms/step - loss: 0.6350 - accuracy: 0.7503 - val_loss: 0.5885 - val_accuracy: 0.7680\n",
      "Epoch 302/1000\n",
      "239/239 [==============================] - 0s 1ms/step - loss: 0.6350 - accuracy: 0.7506 - val_loss: 0.5883 - val_accuracy: 0.7688\n",
      "Epoch 303/1000\n",
      "239/239 [==============================] - 0s 1ms/step - loss: 0.6342 - accuracy: 0.7498 - val_loss: 0.5857 - val_accuracy: 0.7672\n",
      "Epoch 304/1000\n",
      "239/239 [==============================] - 0s 1ms/step - loss: 0.6327 - accuracy: 0.7519 - val_loss: 0.5904 - val_accuracy: 0.7669\n",
      "Epoch 305/1000\n",
      "239/239 [==============================] - 0s 1ms/step - loss: 0.6352 - accuracy: 0.7513 - val_loss: 0.5865 - val_accuracy: 0.7688\n",
      "Epoch 306/1000\n",
      "239/239 [==============================] - 0s 993us/step - loss: 0.6333 - accuracy: 0.7510 - val_loss: 0.5882 - val_accuracy: 0.7677\n",
      "Epoch 307/1000\n",
      "239/239 [==============================] - 0s 1ms/step - loss: 0.6342 - accuracy: 0.7514 - val_loss: 0.5867 - val_accuracy: 0.7678\n",
      "Epoch 308/1000\n",
      "239/239 [==============================] - 0s 1ms/step - loss: 0.6365 - accuracy: 0.7506 - val_loss: 0.5857 - val_accuracy: 0.7682\n",
      "Epoch 309/1000\n",
      "239/239 [==============================] - 0s 1ms/step - loss: 0.6348 - accuracy: 0.7510 - val_loss: 0.5871 - val_accuracy: 0.7679\n",
      "Epoch 310/1000\n",
      "239/239 [==============================] - 0s 1ms/step - loss: 0.6317 - accuracy: 0.7523 - val_loss: 0.5859 - val_accuracy: 0.7682\n",
      "Epoch 311/1000\n",
      "239/239 [==============================] - 0s 2ms/step - loss: 0.6332 - accuracy: 0.7519 - val_loss: 0.5864 - val_accuracy: 0.7688\n",
      "Epoch 312/1000\n",
      "239/239 [==============================] - 0s 1ms/step - loss: 0.6325 - accuracy: 0.7522 - val_loss: 0.5879 - val_accuracy: 0.7691\n",
      "Epoch 313/1000\n",
      "239/239 [==============================] - 0s 1ms/step - loss: 0.6328 - accuracy: 0.7515 - val_loss: 0.5873 - val_accuracy: 0.7671\n",
      "Epoch 314/1000\n",
      "239/239 [==============================] - 0s 1ms/step - loss: 0.6344 - accuracy: 0.7518 - val_loss: 0.5864 - val_accuracy: 0.7701\n",
      "Epoch 315/1000\n",
      "239/239 [==============================] - 0s 1ms/step - loss: 0.6327 - accuracy: 0.7502 - val_loss: 0.5860 - val_accuracy: 0.7679\n",
      "Epoch 316/1000\n",
      "239/239 [==============================] - 0s 1ms/step - loss: 0.6355 - accuracy: 0.7506 - val_loss: 0.5862 - val_accuracy: 0.7681\n",
      "Epoch 317/1000\n",
      "239/239 [==============================] - 0s 1ms/step - loss: 0.6336 - accuracy: 0.7515 - val_loss: 0.5858 - val_accuracy: 0.7677\n",
      "Epoch 318/1000\n",
      "239/239 [==============================] - 0s 1ms/step - loss: 0.6306 - accuracy: 0.7527 - val_loss: 0.5862 - val_accuracy: 0.7699\n",
      "Epoch 319/1000\n",
      "239/239 [==============================] - 0s 1ms/step - loss: 0.6326 - accuracy: 0.7518 - val_loss: 0.5864 - val_accuracy: 0.7688\n",
      "Epoch 320/1000\n",
      "239/239 [==============================] - 0s 2ms/step - loss: 0.6335 - accuracy: 0.7516 - val_loss: 0.5839 - val_accuracy: 0.7705\n",
      "Epoch 321/1000\n",
      "239/239 [==============================] - 1s 3ms/step - loss: 0.6320 - accuracy: 0.7524 - val_loss: 0.5867 - val_accuracy: 0.7676\n",
      "Epoch 322/1000\n",
      "239/239 [==============================] - 0s 2ms/step - loss: 0.6334 - accuracy: 0.7510 - val_loss: 0.5865 - val_accuracy: 0.7660\n",
      "Epoch 323/1000\n",
      "239/239 [==============================] - 0s 1ms/step - loss: 0.6329 - accuracy: 0.7525 - val_loss: 0.5870 - val_accuracy: 0.7682\n",
      "Epoch 324/1000\n",
      "239/239 [==============================] - 0s 1ms/step - loss: 0.6329 - accuracy: 0.7522 - val_loss: 0.5869 - val_accuracy: 0.7696\n",
      "Epoch 325/1000\n",
      "239/239 [==============================] - 0s 980us/step - loss: 0.6336 - accuracy: 0.7521 - val_loss: 0.5862 - val_accuracy: 0.7691\n",
      "Epoch 326/1000\n",
      "239/239 [==============================] - 0s 1ms/step - loss: 0.6328 - accuracy: 0.7518 - val_loss: 0.5850 - val_accuracy: 0.7710\n",
      "Epoch 327/1000\n",
      "239/239 [==============================] - 0s 1ms/step - loss: 0.6324 - accuracy: 0.7519 - val_loss: 0.5882 - val_accuracy: 0.7699\n",
      "Epoch 328/1000\n",
      "239/239 [==============================] - 0s 1ms/step - loss: 0.6322 - accuracy: 0.7519 - val_loss: 0.5864 - val_accuracy: 0.7694\n",
      "Epoch 329/1000\n",
      "239/239 [==============================] - 0s 1ms/step - loss: 0.6340 - accuracy: 0.7515 - val_loss: 0.5856 - val_accuracy: 0.7677\n",
      "Epoch 330/1000\n",
      "239/239 [==============================] - 0s 2ms/step - loss: 0.6332 - accuracy: 0.7523 - val_loss: 0.5870 - val_accuracy: 0.7674\n",
      "Epoch 331/1000\n",
      "239/239 [==============================] - 0s 1ms/step - loss: 0.6329 - accuracy: 0.7511 - val_loss: 0.5849 - val_accuracy: 0.7693\n",
      "Epoch 332/1000\n",
      "239/239 [==============================] - 0s 1ms/step - loss: 0.6331 - accuracy: 0.7514 - val_loss: 0.5868 - val_accuracy: 0.7679\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 333/1000\n",
      "239/239 [==============================] - 0s 1ms/step - loss: 0.6341 - accuracy: 0.7516 - val_loss: 0.5868 - val_accuracy: 0.7694\n",
      "Epoch 334/1000\n",
      "239/239 [==============================] - 0s 1ms/step - loss: 0.6335 - accuracy: 0.7517 - val_loss: 0.5863 - val_accuracy: 0.7698\n",
      "Epoch 335/1000\n",
      "239/239 [==============================] - 0s 972us/step - loss: 0.6330 - accuracy: 0.7516 - val_loss: 0.5865 - val_accuracy: 0.7679\n",
      "Epoch 336/1000\n",
      "239/239 [==============================] - 0s 978us/step - loss: 0.6313 - accuracy: 0.7531 - val_loss: 0.5869 - val_accuracy: 0.7691\n",
      "Epoch 337/1000\n",
      "239/239 [==============================] - 0s 1ms/step - loss: 0.6335 - accuracy: 0.7514 - val_loss: 0.5874 - val_accuracy: 0.7680\n",
      "Epoch 338/1000\n",
      "239/239 [==============================] - 0s 961us/step - loss: 0.6333 - accuracy: 0.7513 - val_loss: 0.5851 - val_accuracy: 0.7666\n",
      "Epoch 339/1000\n",
      "239/239 [==============================] - 0s 1ms/step - loss: 0.6335 - accuracy: 0.7513 - val_loss: 0.5862 - val_accuracy: 0.7679\n",
      "Epoch 340/1000\n",
      "239/239 [==============================] - 0s 1ms/step - loss: 0.6314 - accuracy: 0.7537 - val_loss: 0.5875 - val_accuracy: 0.7675\n",
      "Epoch 341/1000\n",
      "239/239 [==============================] - 0s 1ms/step - loss: 0.6324 - accuracy: 0.7513 - val_loss: 0.5861 - val_accuracy: 0.7669\n",
      "Epoch 342/1000\n",
      "239/239 [==============================] - 0s 1ms/step - loss: 0.6335 - accuracy: 0.7505 - val_loss: 0.5839 - val_accuracy: 0.7682\n",
      "Epoch 343/1000\n",
      "239/239 [==============================] - 0s 990us/step - loss: 0.6328 - accuracy: 0.7517 - val_loss: 0.5859 - val_accuracy: 0.7674\n",
      "Epoch 344/1000\n",
      "239/239 [==============================] - 0s 990us/step - loss: 0.6328 - accuracy: 0.7514 - val_loss: 0.5845 - val_accuracy: 0.7689\n",
      "Epoch 345/1000\n",
      "239/239 [==============================] - 0s 994us/step - loss: 0.6318 - accuracy: 0.7529 - val_loss: 0.5842 - val_accuracy: 0.7682\n",
      "Epoch 346/1000\n",
      "239/239 [==============================] - 0s 961us/step - loss: 0.6323 - accuracy: 0.7519 - val_loss: 0.5858 - val_accuracy: 0.7682\n",
      "Epoch 347/1000\n",
      "239/239 [==============================] - 0s 981us/step - loss: 0.6326 - accuracy: 0.7514 - val_loss: 0.5846 - val_accuracy: 0.7674\n",
      "Epoch 348/1000\n",
      "239/239 [==============================] - 0s 959us/step - loss: 0.6311 - accuracy: 0.7524 - val_loss: 0.5850 - val_accuracy: 0.7700\n",
      "Epoch 349/1000\n",
      "239/239 [==============================] - 0s 953us/step - loss: 0.6330 - accuracy: 0.7515 - val_loss: 0.5851 - val_accuracy: 0.7702\n",
      "Epoch 350/1000\n",
      "239/239 [==============================] - 0s 977us/step - loss: 0.6305 - accuracy: 0.7510 - val_loss: 0.5842 - val_accuracy: 0.7705\n",
      "Epoch 351/1000\n",
      "239/239 [==============================] - 0s 952us/step - loss: 0.6326 - accuracy: 0.7522 - val_loss: 0.5846 - val_accuracy: 0.7682\n",
      "Epoch 352/1000\n",
      "239/239 [==============================] - 0s 954us/step - loss: 0.6344 - accuracy: 0.7503 - val_loss: 0.5869 - val_accuracy: 0.7698\n",
      "Epoch 353/1000\n",
      "239/239 [==============================] - 0s 920us/step - loss: 0.6316 - accuracy: 0.7524 - val_loss: 0.5851 - val_accuracy: 0.7705\n",
      "Epoch 354/1000\n",
      "239/239 [==============================] - 0s 919us/step - loss: 0.6327 - accuracy: 0.7518 - val_loss: 0.5835 - val_accuracy: 0.7703\n",
      "Epoch 355/1000\n",
      "239/239 [==============================] - 0s 960us/step - loss: 0.6327 - accuracy: 0.7517 - val_loss: 0.5861 - val_accuracy: 0.7678\n",
      "Epoch 356/1000\n",
      "239/239 [==============================] - 0s 988us/step - loss: 0.6307 - accuracy: 0.7518 - val_loss: 0.5838 - val_accuracy: 0.7702\n",
      "Epoch 357/1000\n",
      "239/239 [==============================] - 0s 929us/step - loss: 0.6331 - accuracy: 0.7514 - val_loss: 0.5859 - val_accuracy: 0.7708\n",
      "Epoch 358/1000\n",
      "239/239 [==============================] - 0s 952us/step - loss: 0.6311 - accuracy: 0.7520 - val_loss: 0.5860 - val_accuracy: 0.7682\n",
      "Epoch 359/1000\n",
      "239/239 [==============================] - 0s 941us/step - loss: 0.6333 - accuracy: 0.7512 - val_loss: 0.5841 - val_accuracy: 0.7674\n",
      "Epoch 360/1000\n",
      "239/239 [==============================] - 0s 945us/step - loss: 0.6312 - accuracy: 0.7525 - val_loss: 0.5852 - val_accuracy: 0.7690\n",
      "Epoch 361/1000\n",
      "239/239 [==============================] - 0s 1ms/step - loss: 0.6321 - accuracy: 0.7506 - val_loss: 0.5839 - val_accuracy: 0.7710\n",
      "Epoch 362/1000\n",
      "239/239 [==============================] - 0s 920us/step - loss: 0.6307 - accuracy: 0.7527 - val_loss: 0.5828 - val_accuracy: 0.7697\n",
      "Epoch 363/1000\n",
      "239/239 [==============================] - 0s 932us/step - loss: 0.6344 - accuracy: 0.7510 - val_loss: 0.5831 - val_accuracy: 0.7697\n",
      "Epoch 364/1000\n",
      "239/239 [==============================] - 0s 923us/step - loss: 0.6303 - accuracy: 0.7525 - val_loss: 0.5850 - val_accuracy: 0.7696\n",
      "Epoch 365/1000\n",
      "239/239 [==============================] - 0s 921us/step - loss: 0.6318 - accuracy: 0.7525 - val_loss: 0.5831 - val_accuracy: 0.7689\n",
      "Epoch 366/1000\n",
      "239/239 [==============================] - 0s 910us/step - loss: 0.6307 - accuracy: 0.7524 - val_loss: 0.5835 - val_accuracy: 0.7692\n",
      "Epoch 367/1000\n",
      "239/239 [==============================] - 0s 934us/step - loss: 0.6328 - accuracy: 0.7512 - val_loss: 0.5846 - val_accuracy: 0.7673\n",
      "Epoch 368/1000\n",
      "239/239 [==============================] - 0s 907us/step - loss: 0.6324 - accuracy: 0.7516 - val_loss: 0.5848 - val_accuracy: 0.7685\n",
      "Epoch 369/1000\n",
      "239/239 [==============================] - 0s 981us/step - loss: 0.6315 - accuracy: 0.7518 - val_loss: 0.5831 - val_accuracy: 0.7708\n",
      "Epoch 370/1000\n",
      "239/239 [==============================] - 0s 1ms/step - loss: 0.6327 - accuracy: 0.7510 - val_loss: 0.5834 - val_accuracy: 0.7688\n",
      "Epoch 371/1000\n",
      "239/239 [==============================] - 0s 1ms/step - loss: 0.6316 - accuracy: 0.7524 - val_loss: 0.5845 - val_accuracy: 0.7691\n",
      "Epoch 372/1000\n",
      "239/239 [==============================] - 0s 1ms/step - loss: 0.6330 - accuracy: 0.7526 - val_loss: 0.5835 - val_accuracy: 0.7693\n",
      "Epoch 373/1000\n",
      "239/239 [==============================] - 0s 986us/step - loss: 0.6310 - accuracy: 0.7517 - val_loss: 0.5836 - val_accuracy: 0.7686\n",
      "Epoch 374/1000\n",
      "239/239 [==============================] - 0s 928us/step - loss: 0.6306 - accuracy: 0.7523 - val_loss: 0.5831 - val_accuracy: 0.7688\n",
      "Epoch 375/1000\n",
      "239/239 [==============================] - 0s 922us/step - loss: 0.6321 - accuracy: 0.7506 - val_loss: 0.5841 - val_accuracy: 0.7699\n",
      "Epoch 376/1000\n",
      "239/239 [==============================] - 0s 1ms/step - loss: 0.6318 - accuracy: 0.7517 - val_loss: 0.5834 - val_accuracy: 0.7707\n",
      "Epoch 377/1000\n",
      "239/239 [==============================] - 0s 922us/step - loss: 0.6320 - accuracy: 0.7517 - val_loss: 0.5847 - val_accuracy: 0.7698\n",
      "Epoch 378/1000\n",
      "239/239 [==============================] - 0s 1ms/step - loss: 0.6299 - accuracy: 0.7516 - val_loss: 0.5856 - val_accuracy: 0.7691\n",
      "Epoch 379/1000\n",
      "239/239 [==============================] - 0s 941us/step - loss: 0.6320 - accuracy: 0.7518 - val_loss: 0.5832 - val_accuracy: 0.7689\n",
      "Epoch 380/1000\n",
      "239/239 [==============================] - 0s 907us/step - loss: 0.6299 - accuracy: 0.7519 - val_loss: 0.5840 - val_accuracy: 0.7685\n",
      "Epoch 381/1000\n",
      "239/239 [==============================] - 0s 898us/step - loss: 0.6309 - accuracy: 0.7511 - val_loss: 0.5838 - val_accuracy: 0.7699\n",
      "Epoch 382/1000\n",
      "239/239 [==============================] - 0s 915us/step - loss: 0.6308 - accuracy: 0.7526 - val_loss: 0.5833 - val_accuracy: 0.7701\n",
      "Epoch 383/1000\n",
      "239/239 [==============================] - 0s 846us/step - loss: 0.6327 - accuracy: 0.7519 - val_loss: 0.5811 - val_accuracy: 0.7696\n",
      "Epoch 384/1000\n",
      "239/239 [==============================] - 0s 905us/step - loss: 0.6307 - accuracy: 0.7517 - val_loss: 0.5834 - val_accuracy: 0.7682\n",
      "Epoch 385/1000\n",
      "239/239 [==============================] - 0s 850us/step - loss: 0.6317 - accuracy: 0.7511 - val_loss: 0.5839 - val_accuracy: 0.7695\n",
      "Epoch 386/1000\n",
      "239/239 [==============================] - 0s 845us/step - loss: 0.6329 - accuracy: 0.7516 - val_loss: 0.5859 - val_accuracy: 0.7701\n",
      "Epoch 387/1000\n",
      "239/239 [==============================] - 0s 876us/step - loss: 0.6333 - accuracy: 0.7515 - val_loss: 0.5853 - val_accuracy: 0.7675\n",
      "Epoch 388/1000\n",
      "239/239 [==============================] - 0s 940us/step - loss: 0.6300 - accuracy: 0.7523 - val_loss: 0.5815 - val_accuracy: 0.7710\n",
      "Epoch 389/1000\n",
      "239/239 [==============================] - 0s 909us/step - loss: 0.6314 - accuracy: 0.7532 - val_loss: 0.5839 - val_accuracy: 0.7692\n",
      "Epoch 390/1000\n",
      "239/239 [==============================] - 0s 904us/step - loss: 0.6327 - accuracy: 0.7515 - val_loss: 0.5843 - val_accuracy: 0.7693\n",
      "Epoch 391/1000\n",
      "239/239 [==============================] - 0s 949us/step - loss: 0.6309 - accuracy: 0.7508 - val_loss: 0.5820 - val_accuracy: 0.7701\n",
      "Epoch 392/1000\n",
      "239/239 [==============================] - 0s 1ms/step - loss: 0.6313 - accuracy: 0.7521 - val_loss: 0.5830 - val_accuracy: 0.7696\n",
      "Epoch 393/1000\n",
      "239/239 [==============================] - 0s 1ms/step - loss: 0.6324 - accuracy: 0.7529 - val_loss: 0.5822 - val_accuracy: 0.7687\n",
      "Epoch 394/1000\n",
      "239/239 [==============================] - 0s 965us/step - loss: 0.6313 - accuracy: 0.7525 - val_loss: 0.5838 - val_accuracy: 0.7705\n",
      "Epoch 395/1000\n",
      "239/239 [==============================] - 0s 858us/step - loss: 0.6307 - accuracy: 0.7525 - val_loss: 0.5838 - val_accuracy: 0.7696\n",
      "Epoch 396/1000\n",
      "239/239 [==============================] - 0s 926us/step - loss: 0.6301 - accuracy: 0.7529 - val_loss: 0.5823 - val_accuracy: 0.7705\n",
      "Epoch 397/1000\n",
      "239/239 [==============================] - 0s 956us/step - loss: 0.6320 - accuracy: 0.7518 - val_loss: 0.5840 - val_accuracy: 0.7695\n",
      "Epoch 398/1000\n",
      "239/239 [==============================] - 0s 973us/step - loss: 0.6305 - accuracy: 0.7523 - val_loss: 0.5825 - val_accuracy: 0.7705\n",
      "Epoch 399/1000\n",
      "239/239 [==============================] - 0s 934us/step - loss: 0.6312 - accuracy: 0.7525 - val_loss: 0.5810 - val_accuracy: 0.7710\n",
      "Epoch 400/1000\n",
      "239/239 [==============================] - 0s 922us/step - loss: 0.6336 - accuracy: 0.7513 - val_loss: 0.5830 - val_accuracy: 0.7702\n",
      "Epoch 401/1000\n",
      "239/239 [==============================] - 0s 903us/step - loss: 0.6300 - accuracy: 0.7518 - val_loss: 0.5840 - val_accuracy: 0.7702\n",
      "Epoch 402/1000\n",
      "239/239 [==============================] - 0s 899us/step - loss: 0.6294 - accuracy: 0.7531 - val_loss: 0.5812 - val_accuracy: 0.7688\n",
      "Epoch 403/1000\n",
      "239/239 [==============================] - 0s 899us/step - loss: 0.6295 - accuracy: 0.7513 - val_loss: 0.5828 - val_accuracy: 0.7705\n",
      "Epoch 404/1000\n",
      "239/239 [==============================] - 0s 900us/step - loss: 0.6290 - accuracy: 0.7524 - val_loss: 0.5813 - val_accuracy: 0.7691\n",
      "Epoch 405/1000\n",
      "239/239 [==============================] - 0s 934us/step - loss: 0.6298 - accuracy: 0.7518 - val_loss: 0.5829 - val_accuracy: 0.7722\n",
      "Epoch 406/1000\n",
      "239/239 [==============================] - 0s 925us/step - loss: 0.6284 - accuracy: 0.7530 - val_loss: 0.5828 - val_accuracy: 0.7701\n",
      "Epoch 407/1000\n",
      "239/239 [==============================] - 0s 920us/step - loss: 0.6293 - accuracy: 0.7526 - val_loss: 0.5833 - val_accuracy: 0.7693\n",
      "Epoch 408/1000\n",
      "239/239 [==============================] - 0s 911us/step - loss: 0.6311 - accuracy: 0.7522 - val_loss: 0.5857 - val_accuracy: 0.7702\n",
      "Epoch 409/1000\n",
      "239/239 [==============================] - 0s 919us/step - loss: 0.6308 - accuracy: 0.7518 - val_loss: 0.5836 - val_accuracy: 0.7698\n",
      "Epoch 410/1000\n",
      "239/239 [==============================] - 0s 953us/step - loss: 0.6322 - accuracy: 0.7516 - val_loss: 0.5847 - val_accuracy: 0.7687\n",
      "Epoch 411/1000\n",
      "239/239 [==============================] - 0s 913us/step - loss: 0.6318 - accuracy: 0.7525 - val_loss: 0.5816 - val_accuracy: 0.7701\n",
      "Epoch 412/1000\n",
      "239/239 [==============================] - 0s 912us/step - loss: 0.6301 - accuracy: 0.7520 - val_loss: 0.5829 - val_accuracy: 0.7709\n",
      "Epoch 413/1000\n",
      "239/239 [==============================] - 0s 904us/step - loss: 0.6304 - accuracy: 0.7518 - val_loss: 0.5828 - val_accuracy: 0.7683\n",
      "Epoch 414/1000\n",
      "239/239 [==============================] - 0s 933us/step - loss: 0.6318 - accuracy: 0.7525 - val_loss: 0.5827 - val_accuracy: 0.7702\n",
      "Epoch 415/1000\n",
      "239/239 [==============================] - 0s 916us/step - loss: 0.6287 - accuracy: 0.7520 - val_loss: 0.5816 - val_accuracy: 0.7699\n",
      "Epoch 416/1000\n",
      "239/239 [==============================] - 0s 918us/step - loss: 0.6308 - accuracy: 0.7525 - val_loss: 0.5854 - val_accuracy: 0.7683\n",
      "Epoch 417/1000\n",
      "239/239 [==============================] - 0s 945us/step - loss: 0.6300 - accuracy: 0.7521 - val_loss: 0.5825 - val_accuracy: 0.7716\n",
      "Epoch 418/1000\n",
      "239/239 [==============================] - 0s 957us/step - loss: 0.6298 - accuracy: 0.7526 - val_loss: 0.5843 - val_accuracy: 0.7682\n",
      "Epoch 419/1000\n",
      "239/239 [==============================] - 0s 917us/step - loss: 0.6301 - accuracy: 0.7525 - val_loss: 0.5806 - val_accuracy: 0.7698\n",
      "Epoch 420/1000\n",
      "239/239 [==============================] - 0s 1ms/step - loss: 0.6296 - accuracy: 0.7532 - val_loss: 0.5819 - val_accuracy: 0.7699\n",
      "Epoch 421/1000\n",
      "239/239 [==============================] - 0s 938us/step - loss: 0.6297 - accuracy: 0.7527 - val_loss: 0.5833 - val_accuracy: 0.7714\n",
      "Epoch 422/1000\n",
      "239/239 [==============================] - 0s 931us/step - loss: 0.6308 - accuracy: 0.7523 - val_loss: 0.5831 - val_accuracy: 0.7701\n",
      "Epoch 423/1000\n",
      "239/239 [==============================] - 0s 929us/step - loss: 0.6305 - accuracy: 0.7529 - val_loss: 0.5799 - val_accuracy: 0.7706\n",
      "Epoch 424/1000\n",
      "239/239 [==============================] - 0s 920us/step - loss: 0.6293 - accuracy: 0.7540 - val_loss: 0.5817 - val_accuracy: 0.7695\n",
      "Epoch 425/1000\n",
      "239/239 [==============================] - 0s 927us/step - loss: 0.6301 - accuracy: 0.7528 - val_loss: 0.5810 - val_accuracy: 0.7719\n",
      "Epoch 426/1000\n",
      "239/239 [==============================] - 0s 958us/step - loss: 0.6298 - accuracy: 0.7520 - val_loss: 0.5820 - val_accuracy: 0.7705\n",
      "Epoch 427/1000\n",
      "239/239 [==============================] - 0s 907us/step - loss: 0.6292 - accuracy: 0.7535 - val_loss: 0.5808 - val_accuracy: 0.7705\n",
      "Epoch 428/1000\n",
      "239/239 [==============================] - 0s 919us/step - loss: 0.6302 - accuracy: 0.7517 - val_loss: 0.5812 - val_accuracy: 0.7699\n",
      "Epoch 429/1000\n",
      "239/239 [==============================] - 0s 906us/step - loss: 0.6310 - accuracy: 0.7518 - val_loss: 0.5821 - val_accuracy: 0.7711\n",
      "Epoch 430/1000\n",
      "239/239 [==============================] - 0s 865us/step - loss: 0.6277 - accuracy: 0.7526 - val_loss: 0.5834 - val_accuracy: 0.7693\n",
      "Epoch 431/1000\n",
      "239/239 [==============================] - 0s 864us/step - loss: 0.6293 - accuracy: 0.7527 - val_loss: 0.5814 - val_accuracy: 0.7702\n",
      "Epoch 432/1000\n",
      "239/239 [==============================] - 0s 936us/step - loss: 0.6310 - accuracy: 0.7514 - val_loss: 0.5814 - val_accuracy: 0.7705\n",
      "Epoch 433/1000\n",
      "239/239 [==============================] - 0s 885us/step - loss: 0.6307 - accuracy: 0.7518 - val_loss: 0.5812 - val_accuracy: 0.7706\n",
      "Epoch 434/1000\n",
      "239/239 [==============================] - 0s 972us/step - loss: 0.6300 - accuracy: 0.7526 - val_loss: 0.5834 - val_accuracy: 0.7680\n",
      "Epoch 435/1000\n",
      "239/239 [==============================] - 0s 1ms/step - loss: 0.6310 - accuracy: 0.7521 - val_loss: 0.5818 - val_accuracy: 0.7715\n",
      "Epoch 436/1000\n",
      "239/239 [==============================] - 0s 1ms/step - loss: 0.6303 - accuracy: 0.7536 - val_loss: 0.5806 - val_accuracy: 0.7702\n",
      "Epoch 437/1000\n",
      "239/239 [==============================] - 0s 882us/step - loss: 0.6302 - accuracy: 0.7531 - val_loss: 0.5796 - val_accuracy: 0.7710\n",
      "Epoch 438/1000\n",
      "239/239 [==============================] - 0s 1ms/step - loss: 0.6284 - accuracy: 0.7529 - val_loss: 0.5824 - val_accuracy: 0.7715\n",
      "Epoch 439/1000\n",
      "239/239 [==============================] - 0s 940us/step - loss: 0.6311 - accuracy: 0.7515 - val_loss: 0.5807 - val_accuracy: 0.7708\n",
      "Epoch 440/1000\n",
      "239/239 [==============================] - 0s 970us/step - loss: 0.6299 - accuracy: 0.7516 - val_loss: 0.5812 - val_accuracy: 0.7707\n",
      "Epoch 441/1000\n",
      "239/239 [==============================] - 0s 969us/step - loss: 0.6307 - accuracy: 0.7516 - val_loss: 0.5820 - val_accuracy: 0.7702\n",
      "Epoch 442/1000\n",
      "239/239 [==============================] - 0s 929us/step - loss: 0.6298 - accuracy: 0.7520 - val_loss: 0.5821 - val_accuracy: 0.7743\n",
      "Epoch 443/1000\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "239/239 [==============================] - 0s 985us/step - loss: 0.6306 - accuracy: 0.7521 - val_loss: 0.5810 - val_accuracy: 0.7689\n",
      "Epoch 444/1000\n",
      "239/239 [==============================] - 0s 933us/step - loss: 0.6293 - accuracy: 0.7521 - val_loss: 0.5822 - val_accuracy: 0.7696\n",
      "Epoch 445/1000\n",
      "239/239 [==============================] - 0s 974us/step - loss: 0.6304 - accuracy: 0.7516 - val_loss: 0.5823 - val_accuracy: 0.7691\n",
      "Epoch 446/1000\n",
      "239/239 [==============================] - 0s 954us/step - loss: 0.6292 - accuracy: 0.7529 - val_loss: 0.5818 - val_accuracy: 0.7699\n",
      "Epoch 447/1000\n",
      "239/239 [==============================] - 0s 951us/step - loss: 0.6284 - accuracy: 0.7536 - val_loss: 0.5837 - val_accuracy: 0.7691\n",
      "Epoch 448/1000\n",
      "239/239 [==============================] - 0s 933us/step - loss: 0.6303 - accuracy: 0.7521 - val_loss: 0.5812 - val_accuracy: 0.7713\n",
      "Epoch 449/1000\n",
      "239/239 [==============================] - 0s 978us/step - loss: 0.6293 - accuracy: 0.7526 - val_loss: 0.5821 - val_accuracy: 0.7710\n",
      "Epoch 450/1000\n",
      "239/239 [==============================] - 0s 934us/step - loss: 0.6290 - accuracy: 0.7530 - val_loss: 0.5812 - val_accuracy: 0.7689\n",
      "Epoch 451/1000\n",
      "239/239 [==============================] - 0s 930us/step - loss: 0.6311 - accuracy: 0.7522 - val_loss: 0.5815 - val_accuracy: 0.7716\n",
      "Epoch 452/1000\n",
      "239/239 [==============================] - 0s 958us/step - loss: 0.6286 - accuracy: 0.7523 - val_loss: 0.5811 - val_accuracy: 0.7693\n",
      "Epoch 453/1000\n",
      "239/239 [==============================] - 0s 962us/step - loss: 0.6304 - accuracy: 0.7520 - val_loss: 0.5821 - val_accuracy: 0.7698\n",
      "Epoch 454/1000\n",
      "239/239 [==============================] - 0s 933us/step - loss: 0.6285 - accuracy: 0.7535 - val_loss: 0.5814 - val_accuracy: 0.7714\n",
      "Epoch 455/1000\n",
      "239/239 [==============================] - 0s 963us/step - loss: 0.6281 - accuracy: 0.7530 - val_loss: 0.5818 - val_accuracy: 0.7718\n",
      "Epoch 456/1000\n",
      "239/239 [==============================] - 0s 938us/step - loss: 0.6280 - accuracy: 0.7534 - val_loss: 0.5802 - val_accuracy: 0.7713\n",
      "Epoch 457/1000\n",
      "239/239 [==============================] - 0s 920us/step - loss: 0.6286 - accuracy: 0.7534 - val_loss: 0.5812 - val_accuracy: 0.7702\n",
      "Epoch 458/1000\n",
      "239/239 [==============================] - 0s 906us/step - loss: 0.6297 - accuracy: 0.7519 - val_loss: 0.5801 - val_accuracy: 0.7719\n",
      "Epoch 459/1000\n",
      "239/239 [==============================] - 0s 861us/step - loss: 0.6272 - accuracy: 0.7538 - val_loss: 0.5838 - val_accuracy: 0.7696\n",
      "Epoch 460/1000\n",
      "239/239 [==============================] - 0s 856us/step - loss: 0.6294 - accuracy: 0.7525 - val_loss: 0.5808 - val_accuracy: 0.7716\n",
      "Epoch 461/1000\n",
      "239/239 [==============================] - 0s 953us/step - loss: 0.6281 - accuracy: 0.7537 - val_loss: 0.5837 - val_accuracy: 0.7688\n",
      "Epoch 462/1000\n",
      "239/239 [==============================] - 0s 961us/step - loss: 0.6290 - accuracy: 0.7529 - val_loss: 0.5813 - val_accuracy: 0.7693\n",
      "Epoch 463/1000\n",
      "239/239 [==============================] - 0s 934us/step - loss: 0.6293 - accuracy: 0.7532 - val_loss: 0.5806 - val_accuracy: 0.7715\n",
      "Epoch 464/1000\n",
      "239/239 [==============================] - 0s 918us/step - loss: 0.6287 - accuracy: 0.7526 - val_loss: 0.5806 - val_accuracy: 0.7709\n",
      "Epoch 465/1000\n",
      "239/239 [==============================] - 0s 907us/step - loss: 0.6294 - accuracy: 0.7527 - val_loss: 0.5806 - val_accuracy: 0.7721\n",
      "Epoch 466/1000\n",
      "239/239 [==============================] - 0s 945us/step - loss: 0.6292 - accuracy: 0.7533 - val_loss: 0.5812 - val_accuracy: 0.7691\n",
      "Epoch 467/1000\n",
      "239/239 [==============================] - 0s 951us/step - loss: 0.6288 - accuracy: 0.7523 - val_loss: 0.5816 - val_accuracy: 0.7719\n",
      "Epoch 468/1000\n",
      "239/239 [==============================] - 0s 974us/step - loss: 0.6289 - accuracy: 0.7528 - val_loss: 0.5807 - val_accuracy: 0.7714\n",
      "Epoch 469/1000\n",
      "239/239 [==============================] - 0s 991us/step - loss: 0.6296 - accuracy: 0.7525 - val_loss: 0.5803 - val_accuracy: 0.7708\n",
      "Epoch 470/1000\n",
      "239/239 [==============================] - 0s 1ms/step - loss: 0.6308 - accuracy: 0.7526 - val_loss: 0.5801 - val_accuracy: 0.7707\n",
      "Epoch 471/1000\n",
      "239/239 [==============================] - 0s 1ms/step - loss: 0.6291 - accuracy: 0.7517 - val_loss: 0.5800 - val_accuracy: 0.7699\n",
      "Epoch 472/1000\n",
      "239/239 [==============================] - 0s 946us/step - loss: 0.6289 - accuracy: 0.7522 - val_loss: 0.5803 - val_accuracy: 0.7700\n",
      "Epoch 473/1000\n",
      "239/239 [==============================] - 0s 1ms/step - loss: 0.6303 - accuracy: 0.7528 - val_loss: 0.5794 - val_accuracy: 0.7705\n",
      "Epoch 474/1000\n",
      "239/239 [==============================] - 0s 1ms/step - loss: 0.6297 - accuracy: 0.7522 - val_loss: 0.5803 - val_accuracy: 0.7682\n",
      "Epoch 475/1000\n",
      "239/239 [==============================] - 0s 1ms/step - loss: 0.6270 - accuracy: 0.7533 - val_loss: 0.5807 - val_accuracy: 0.7680\n",
      "Epoch 476/1000\n",
      "239/239 [==============================] - 0s 1ms/step - loss: 0.6289 - accuracy: 0.7530 - val_loss: 0.5802 - val_accuracy: 0.7710\n",
      "Epoch 477/1000\n",
      "239/239 [==============================] - 0s 1000us/step - loss: 0.6280 - accuracy: 0.7540 - val_loss: 0.5798 - val_accuracy: 0.7719\n",
      "Epoch 478/1000\n",
      "239/239 [==============================] - 0s 865us/step - loss: 0.6272 - accuracy: 0.7545 - val_loss: 0.5801 - val_accuracy: 0.7722\n",
      "Epoch 479/1000\n",
      "239/239 [==============================] - 0s 1ms/step - loss: 0.6286 - accuracy: 0.7542 - val_loss: 0.5805 - val_accuracy: 0.7696\n",
      "Epoch 480/1000\n",
      "239/239 [==============================] - 0s 921us/step - loss: 0.6281 - accuracy: 0.7526 - val_loss: 0.5813 - val_accuracy: 0.7699\n",
      "Epoch 481/1000\n",
      "239/239 [==============================] - 0s 928us/step - loss: 0.6284 - accuracy: 0.7534 - val_loss: 0.5789 - val_accuracy: 0.7710\n",
      "Epoch 482/1000\n",
      "239/239 [==============================] - 0s 936us/step - loss: 0.6298 - accuracy: 0.7523 - val_loss: 0.5811 - val_accuracy: 0.7707\n",
      "Epoch 483/1000\n",
      "239/239 [==============================] - 0s 953us/step - loss: 0.6294 - accuracy: 0.7527 - val_loss: 0.5814 - val_accuracy: 0.7708\n",
      "Epoch 484/1000\n",
      "239/239 [==============================] - 0s 891us/step - loss: 0.6297 - accuracy: 0.7532 - val_loss: 0.5791 - val_accuracy: 0.7724\n",
      "Epoch 485/1000\n",
      "239/239 [==============================] - 0s 902us/step - loss: 0.6292 - accuracy: 0.7525 - val_loss: 0.5786 - val_accuracy: 0.7720\n",
      "Epoch 486/1000\n",
      "239/239 [==============================] - 0s 1ms/step - loss: 0.6286 - accuracy: 0.7535 - val_loss: 0.5799 - val_accuracy: 0.7703\n",
      "Epoch 487/1000\n",
      "239/239 [==============================] - 0s 1ms/step - loss: 0.6285 - accuracy: 0.7528 - val_loss: 0.5805 - val_accuracy: 0.7707\n",
      "Epoch 488/1000\n",
      "239/239 [==============================] - 0s 1ms/step - loss: 0.6282 - accuracy: 0.7531 - val_loss: 0.5792 - val_accuracy: 0.7714\n",
      "Epoch 489/1000\n",
      "239/239 [==============================] - 0s 945us/step - loss: 0.6296 - accuracy: 0.7529 - val_loss: 0.5803 - val_accuracy: 0.7701\n",
      "Epoch 490/1000\n",
      "239/239 [==============================] - 0s 929us/step - loss: 0.6271 - accuracy: 0.7525 - val_loss: 0.5796 - val_accuracy: 0.7715\n",
      "Epoch 491/1000\n",
      "239/239 [==============================] - 0s 942us/step - loss: 0.6294 - accuracy: 0.7535 - val_loss: 0.5813 - val_accuracy: 0.7705\n",
      "Epoch 492/1000\n",
      "239/239 [==============================] - 0s 953us/step - loss: 0.6296 - accuracy: 0.7520 - val_loss: 0.5814 - val_accuracy: 0.7705\n",
      "Epoch 493/1000\n",
      "239/239 [==============================] - 0s 977us/step - loss: 0.6284 - accuracy: 0.7535 - val_loss: 0.5808 - val_accuracy: 0.7693\n",
      "Epoch 494/1000\n",
      "239/239 [==============================] - 0s 978us/step - loss: 0.6294 - accuracy: 0.7537 - val_loss: 0.5804 - val_accuracy: 0.7697\n",
      "Epoch 495/1000\n",
      "239/239 [==============================] - 0s 936us/step - loss: 0.6284 - accuracy: 0.7533 - val_loss: 0.5794 - val_accuracy: 0.7715\n",
      "Epoch 496/1000\n",
      "239/239 [==============================] - 0s 961us/step - loss: 0.6297 - accuracy: 0.7526 - val_loss: 0.5808 - val_accuracy: 0.7699\n",
      "Epoch 497/1000\n",
      "239/239 [==============================] - 0s 948us/step - loss: 0.6290 - accuracy: 0.7524 - val_loss: 0.5795 - val_accuracy: 0.7714\n",
      "Epoch 498/1000\n",
      "239/239 [==============================] - 0s 935us/step - loss: 0.6281 - accuracy: 0.7536 - val_loss: 0.5811 - val_accuracy: 0.7713\n",
      "Epoch 499/1000\n",
      "239/239 [==============================] - 0s 937us/step - loss: 0.6278 - accuracy: 0.7529 - val_loss: 0.5806 - val_accuracy: 0.7699\n",
      "Epoch 500/1000\n",
      "239/239 [==============================] - 0s 981us/step - loss: 0.6278 - accuracy: 0.7538 - val_loss: 0.5814 - val_accuracy: 0.7698\n",
      "Epoch 501/1000\n",
      "239/239 [==============================] - 0s 959us/step - loss: 0.6286 - accuracy: 0.7517 - val_loss: 0.5816 - val_accuracy: 0.7706\n",
      "Epoch 502/1000\n",
      "239/239 [==============================] - 0s 912us/step - loss: 0.6276 - accuracy: 0.7530 - val_loss: 0.5798 - val_accuracy: 0.7713\n",
      "Epoch 503/1000\n",
      "239/239 [==============================] - 0s 1ms/step - loss: 0.6275 - accuracy: 0.7530 - val_loss: 0.5802 - val_accuracy: 0.7700\n",
      "Epoch 504/1000\n",
      "239/239 [==============================] - 0s 947us/step - loss: 0.6291 - accuracy: 0.7532 - val_loss: 0.5800 - val_accuracy: 0.7704\n",
      "Epoch 505/1000\n",
      "239/239 [==============================] - 0s 979us/step - loss: 0.6278 - accuracy: 0.7536 - val_loss: 0.5790 - val_accuracy: 0.7719\n",
      "Epoch 506/1000\n",
      "239/239 [==============================] - 0s 929us/step - loss: 0.6281 - accuracy: 0.7528 - val_loss: 0.5806 - val_accuracy: 0.7706\n",
      "Epoch 507/1000\n",
      "239/239 [==============================] - 0s 929us/step - loss: 0.6274 - accuracy: 0.7526 - val_loss: 0.5802 - val_accuracy: 0.7706\n",
      "Epoch 508/1000\n",
      "239/239 [==============================] - 0s 910us/step - loss: 0.6285 - accuracy: 0.7518 - val_loss: 0.5801 - val_accuracy: 0.7724\n",
      "Epoch 509/1000\n",
      "239/239 [==============================] - 0s 1ms/step - loss: 0.6297 - accuracy: 0.7537 - val_loss: 0.5804 - val_accuracy: 0.7714\n",
      "Epoch 510/1000\n",
      "239/239 [==============================] - 0s 949us/step - loss: 0.6291 - accuracy: 0.7528 - val_loss: 0.5800 - val_accuracy: 0.7718\n",
      "Epoch 511/1000\n",
      "239/239 [==============================] - 0s 928us/step - loss: 0.6279 - accuracy: 0.7535 - val_loss: 0.5811 - val_accuracy: 0.7693\n",
      "Epoch 512/1000\n",
      "239/239 [==============================] - 0s 919us/step - loss: 0.6281 - accuracy: 0.7528 - val_loss: 0.5795 - val_accuracy: 0.7701\n",
      "Epoch 513/1000\n",
      "239/239 [==============================] - 0s 985us/step - loss: 0.6280 - accuracy: 0.7538 - val_loss: 0.5788 - val_accuracy: 0.7709\n",
      "Epoch 514/1000\n",
      "239/239 [==============================] - 0s 1ms/step - loss: 0.6267 - accuracy: 0.7533 - val_loss: 0.5774 - val_accuracy: 0.7714\n",
      "Epoch 515/1000\n",
      "239/239 [==============================] - 0s 1ms/step - loss: 0.6280 - accuracy: 0.7534 - val_loss: 0.5793 - val_accuracy: 0.7714\n",
      "Epoch 516/1000\n",
      "239/239 [==============================] - 0s 1ms/step - loss: 0.6281 - accuracy: 0.7532 - val_loss: 0.5791 - val_accuracy: 0.7710\n",
      "Epoch 517/1000\n",
      "239/239 [==============================] - 0s 948us/step - loss: 0.6276 - accuracy: 0.7542 - val_loss: 0.5800 - val_accuracy: 0.7729\n",
      "Epoch 518/1000\n",
      "239/239 [==============================] - 0s 954us/step - loss: 0.6270 - accuracy: 0.7541 - val_loss: 0.5826 - val_accuracy: 0.7693\n",
      "Epoch 519/1000\n",
      "239/239 [==============================] - 0s 931us/step - loss: 0.6277 - accuracy: 0.7534 - val_loss: 0.5780 - val_accuracy: 0.7729\n",
      "Epoch 520/1000\n",
      "239/239 [==============================] - 0s 1ms/step - loss: 0.6295 - accuracy: 0.7538 - val_loss: 0.5771 - val_accuracy: 0.7727\n",
      "Epoch 521/1000\n",
      "239/239 [==============================] - 0s 974us/step - loss: 0.6273 - accuracy: 0.7535 - val_loss: 0.5791 - val_accuracy: 0.7712\n",
      "Epoch 522/1000\n",
      "239/239 [==============================] - 0s 1ms/step - loss: 0.6264 - accuracy: 0.7522 - val_loss: 0.5787 - val_accuracy: 0.7727\n",
      "Epoch 523/1000\n",
      "239/239 [==============================] - 0s 930us/step - loss: 0.6272 - accuracy: 0.7542 - val_loss: 0.5806 - val_accuracy: 0.7722\n",
      "Epoch 524/1000\n",
      "239/239 [==============================] - 0s 945us/step - loss: 0.6288 - accuracy: 0.7533 - val_loss: 0.5809 - val_accuracy: 0.7697\n",
      "Epoch 525/1000\n",
      "239/239 [==============================] - 0s 912us/step - loss: 0.6275 - accuracy: 0.7533 - val_loss: 0.5782 - val_accuracy: 0.7708\n",
      "Epoch 526/1000\n",
      "239/239 [==============================] - 0s 936us/step - loss: 0.6288 - accuracy: 0.7532 - val_loss: 0.5801 - val_accuracy: 0.7693\n",
      "Epoch 527/1000\n",
      "239/239 [==============================] - 0s 986us/step - loss: 0.6282 - accuracy: 0.7528 - val_loss: 0.5808 - val_accuracy: 0.7711\n",
      "Epoch 528/1000\n",
      "239/239 [==============================] - 0s 870us/step - loss: 0.6284 - accuracy: 0.7522 - val_loss: 0.5797 - val_accuracy: 0.7708\n",
      "Epoch 529/1000\n",
      "239/239 [==============================] - 0s 922us/step - loss: 0.6268 - accuracy: 0.7545 - val_loss: 0.5795 - val_accuracy: 0.7705\n",
      "Epoch 530/1000\n",
      "239/239 [==============================] - 0s 891us/step - loss: 0.6268 - accuracy: 0.7532 - val_loss: 0.5789 - val_accuracy: 0.7699\n",
      "Epoch 531/1000\n",
      "239/239 [==============================] - 0s 950us/step - loss: 0.6259 - accuracy: 0.7537 - val_loss: 0.5811 - val_accuracy: 0.7689\n",
      "Epoch 532/1000\n",
      "239/239 [==============================] - 0s 891us/step - loss: 0.6275 - accuracy: 0.7534 - val_loss: 0.5777 - val_accuracy: 0.7716\n",
      "Epoch 533/1000\n",
      "239/239 [==============================] - 0s 864us/step - loss: 0.6270 - accuracy: 0.7538 - val_loss: 0.5789 - val_accuracy: 0.7714\n",
      "Epoch 534/1000\n",
      "239/239 [==============================] - 0s 965us/step - loss: 0.6290 - accuracy: 0.7529 - val_loss: 0.5798 - val_accuracy: 0.7703\n",
      "Epoch 535/1000\n",
      "239/239 [==============================] - 0s 973us/step - loss: 0.6273 - accuracy: 0.7538 - val_loss: 0.5806 - val_accuracy: 0.7710\n",
      "Epoch 536/1000\n",
      "239/239 [==============================] - 0s 947us/step - loss: 0.6269 - accuracy: 0.7527 - val_loss: 0.5796 - val_accuracy: 0.7705\n",
      "Epoch 537/1000\n",
      "239/239 [==============================] - 0s 1ms/step - loss: 0.6288 - accuracy: 0.7538 - val_loss: 0.5800 - val_accuracy: 0.7708\n",
      "Epoch 538/1000\n",
      "239/239 [==============================] - 0s 926us/step - loss: 0.6260 - accuracy: 0.7541 - val_loss: 0.5779 - val_accuracy: 0.7705\n",
      "Epoch 539/1000\n",
      "239/239 [==============================] - 0s 1ms/step - loss: 0.6274 - accuracy: 0.7532 - val_loss: 0.5804 - val_accuracy: 0.7710\n",
      "Epoch 540/1000\n",
      "239/239 [==============================] - 0s 1ms/step - loss: 0.6268 - accuracy: 0.7538 - val_loss: 0.5816 - val_accuracy: 0.7714\n",
      "Epoch 541/1000\n",
      "239/239 [==============================] - 0s 912us/step - loss: 0.6283 - accuracy: 0.7538 - val_loss: 0.5810 - val_accuracy: 0.7702\n",
      "Epoch 542/1000\n",
      "239/239 [==============================] - 0s 1ms/step - loss: 0.6275 - accuracy: 0.7539 - val_loss: 0.5770 - val_accuracy: 0.7730\n",
      "Epoch 543/1000\n",
      "239/239 [==============================] - 0s 994us/step - loss: 0.6281 - accuracy: 0.7535 - val_loss: 0.5763 - val_accuracy: 0.7714\n",
      "Epoch 544/1000\n",
      "239/239 [==============================] - 0s 932us/step - loss: 0.6262 - accuracy: 0.7546 - val_loss: 0.5813 - val_accuracy: 0.7691\n",
      "Epoch 545/1000\n",
      "239/239 [==============================] - 0s 918us/step - loss: 0.6269 - accuracy: 0.7540 - val_loss: 0.5806 - val_accuracy: 0.7706\n",
      "Epoch 546/1000\n",
      "239/239 [==============================] - 0s 867us/step - loss: 0.6274 - accuracy: 0.7522 - val_loss: 0.5785 - val_accuracy: 0.7714\n",
      "Epoch 547/1000\n",
      "239/239 [==============================] - 0s 883us/step - loss: 0.6256 - accuracy: 0.7547 - val_loss: 0.5801 - val_accuracy: 0.7701\n",
      "Epoch 548/1000\n",
      "239/239 [==============================] - 0s 1ms/step - loss: 0.6283 - accuracy: 0.7542 - val_loss: 0.5807 - val_accuracy: 0.7691\n",
      "Epoch 549/1000\n",
      "239/239 [==============================] - 0s 1ms/step - loss: 0.6278 - accuracy: 0.7538 - val_loss: 0.5806 - val_accuracy: 0.7705\n",
      "Epoch 550/1000\n",
      "239/239 [==============================] - 0s 1ms/step - loss: 0.6279 - accuracy: 0.7531 - val_loss: 0.5790 - val_accuracy: 0.7710\n",
      "Epoch 551/1000\n",
      "239/239 [==============================] - 0s 1ms/step - loss: 0.6276 - accuracy: 0.7527 - val_loss: 0.5781 - val_accuracy: 0.7720\n",
      "Epoch 552/1000\n",
      "239/239 [==============================] - 0s 968us/step - loss: 0.6281 - accuracy: 0.7537 - val_loss: 0.5832 - val_accuracy: 0.7708\n",
      "Epoch 553/1000\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "239/239 [==============================] - 0s 989us/step - loss: 0.6260 - accuracy: 0.7543 - val_loss: 0.5801 - val_accuracy: 0.7693\n",
      "Epoch 554/1000\n",
      "239/239 [==============================] - 0s 1ms/step - loss: 0.6267 - accuracy: 0.7524 - val_loss: 0.5791 - val_accuracy: 0.7704\n",
      "Epoch 555/1000\n",
      "239/239 [==============================] - 0s 1ms/step - loss: 0.6288 - accuracy: 0.7525 - val_loss: 0.5782 - val_accuracy: 0.7712\n",
      "Epoch 556/1000\n",
      "239/239 [==============================] - 0s 1ms/step - loss: 0.6278 - accuracy: 0.7536 - val_loss: 0.5794 - val_accuracy: 0.7698\n",
      "Epoch 557/1000\n",
      "239/239 [==============================] - 0s 1ms/step - loss: 0.6273 - accuracy: 0.7535 - val_loss: 0.5810 - val_accuracy: 0.7693\n",
      "Epoch 558/1000\n",
      "239/239 [==============================] - 0s 982us/step - loss: 0.6262 - accuracy: 0.7530 - val_loss: 0.5802 - val_accuracy: 0.7691\n",
      "Epoch 559/1000\n",
      "239/239 [==============================] - 0s 909us/step - loss: 0.6265 - accuracy: 0.7538 - val_loss: 0.5789 - val_accuracy: 0.7704\n",
      "Epoch 560/1000\n",
      "239/239 [==============================] - 0s 981us/step - loss: 0.6281 - accuracy: 0.7534 - val_loss: 0.5776 - val_accuracy: 0.7691\n",
      "Epoch 561/1000\n",
      "239/239 [==============================] - 0s 886us/step - loss: 0.6259 - accuracy: 0.7530 - val_loss: 0.5803 - val_accuracy: 0.7701\n",
      "Epoch 562/1000\n",
      "239/239 [==============================] - 0s 853us/step - loss: 0.6263 - accuracy: 0.7547 - val_loss: 0.5790 - val_accuracy: 0.7696\n",
      "Epoch 563/1000\n",
      "239/239 [==============================] - 0s 866us/step - loss: 0.6262 - accuracy: 0.7540 - val_loss: 0.5787 - val_accuracy: 0.7714\n",
      "Epoch 564/1000\n",
      "239/239 [==============================] - 0s 1ms/step - loss: 0.6284 - accuracy: 0.7531 - val_loss: 0.5780 - val_accuracy: 0.7716\n",
      "Epoch 565/1000\n",
      "239/239 [==============================] - 0s 1ms/step - loss: 0.6278 - accuracy: 0.7529 - val_loss: 0.5776 - val_accuracy: 0.7693\n",
      "Epoch 566/1000\n",
      "239/239 [==============================] - 0s 934us/step - loss: 0.6269 - accuracy: 0.7540 - val_loss: 0.5795 - val_accuracy: 0.7710\n",
      "Epoch 567/1000\n",
      "239/239 [==============================] - 0s 898us/step - loss: 0.6269 - accuracy: 0.7532 - val_loss: 0.5775 - val_accuracy: 0.7714\n",
      "Epoch 568/1000\n",
      "239/239 [==============================] - 0s 909us/step - loss: 0.6270 - accuracy: 0.7545 - val_loss: 0.5769 - val_accuracy: 0.7715\n",
      "Epoch 569/1000\n",
      "239/239 [==============================] - 0s 898us/step - loss: 0.6281 - accuracy: 0.7531 - val_loss: 0.5785 - val_accuracy: 0.7704\n",
      "Epoch 570/1000\n",
      "239/239 [==============================] - 0s 903us/step - loss: 0.6282 - accuracy: 0.7535 - val_loss: 0.5796 - val_accuracy: 0.7706\n",
      "Epoch 571/1000\n",
      "239/239 [==============================] - 0s 918us/step - loss: 0.6271 - accuracy: 0.7537 - val_loss: 0.5787 - val_accuracy: 0.7720\n",
      "Epoch 572/1000\n",
      "239/239 [==============================] - 0s 915us/step - loss: 0.6269 - accuracy: 0.7543 - val_loss: 0.5781 - val_accuracy: 0.7714\n",
      "Epoch 573/1000\n",
      "239/239 [==============================] - 0s 977us/step - loss: 0.6272 - accuracy: 0.7544 - val_loss: 0.5773 - val_accuracy: 0.7722\n",
      "Epoch 574/1000\n",
      "239/239 [==============================] - 0s 911us/step - loss: 0.6278 - accuracy: 0.7533 - val_loss: 0.5805 - val_accuracy: 0.7700\n",
      "Epoch 575/1000\n",
      "239/239 [==============================] - 0s 903us/step - loss: 0.6270 - accuracy: 0.7533 - val_loss: 0.5791 - val_accuracy: 0.7710\n",
      "Epoch 576/1000\n",
      "239/239 [==============================] - 0s 922us/step - loss: 0.6266 - accuracy: 0.7549 - val_loss: 0.5784 - val_accuracy: 0.7708\n",
      "Epoch 577/1000\n",
      "239/239 [==============================] - 0s 921us/step - loss: 0.6279 - accuracy: 0.7531 - val_loss: 0.5778 - val_accuracy: 0.7709\n",
      "Epoch 578/1000\n",
      "239/239 [==============================] - 0s 943us/step - loss: 0.6274 - accuracy: 0.7540 - val_loss: 0.5795 - val_accuracy: 0.7702\n",
      "Epoch 579/1000\n",
      "239/239 [==============================] - 0s 928us/step - loss: 0.6278 - accuracy: 0.7525 - val_loss: 0.5777 - val_accuracy: 0.7708\n",
      "Epoch 580/1000\n",
      "239/239 [==============================] - 0s 895us/step - loss: 0.6275 - accuracy: 0.7528 - val_loss: 0.5782 - val_accuracy: 0.7710\n",
      "Epoch 581/1000\n",
      "239/239 [==============================] - 0s 889us/step - loss: 0.6279 - accuracy: 0.7538 - val_loss: 0.5798 - val_accuracy: 0.7712\n",
      "Epoch 582/1000\n",
      "239/239 [==============================] - 0s 890us/step - loss: 0.6278 - accuracy: 0.7544 - val_loss: 0.5793 - val_accuracy: 0.7705\n",
      "Epoch 583/1000\n",
      "239/239 [==============================] - 0s 936us/step - loss: 0.6264 - accuracy: 0.7535 - val_loss: 0.5784 - val_accuracy: 0.7719\n",
      "Epoch 584/1000\n",
      "239/239 [==============================] - 0s 906us/step - loss: 0.6260 - accuracy: 0.7539 - val_loss: 0.5761 - val_accuracy: 0.7716\n",
      "Epoch 585/1000\n",
      "239/239 [==============================] - 0s 889us/step - loss: 0.6275 - accuracy: 0.7539 - val_loss: 0.5792 - val_accuracy: 0.7696\n",
      "Epoch 586/1000\n",
      "239/239 [==============================] - 0s 909us/step - loss: 0.6257 - accuracy: 0.7541 - val_loss: 0.5777 - val_accuracy: 0.7713\n",
      "Epoch 587/1000\n",
      "239/239 [==============================] - 0s 926us/step - loss: 0.6266 - accuracy: 0.7545 - val_loss: 0.5775 - val_accuracy: 0.7723\n",
      "Epoch 588/1000\n",
      "239/239 [==============================] - 0s 917us/step - loss: 0.6277 - accuracy: 0.7545 - val_loss: 0.5785 - val_accuracy: 0.7709\n",
      "Epoch 589/1000\n",
      "239/239 [==============================] - 0s 927us/step - loss: 0.6285 - accuracy: 0.7535 - val_loss: 0.5777 - val_accuracy: 0.7705\n",
      "Epoch 590/1000\n",
      "239/239 [==============================] - 0s 900us/step - loss: 0.6281 - accuracy: 0.7535 - val_loss: 0.5807 - val_accuracy: 0.7708\n",
      "Epoch 591/1000\n",
      "239/239 [==============================] - 0s 894us/step - loss: 0.6277 - accuracy: 0.7535 - val_loss: 0.5773 - val_accuracy: 0.7718\n",
      "Epoch 592/1000\n",
      "239/239 [==============================] - 0s 848us/step - loss: 0.6268 - accuracy: 0.7545 - val_loss: 0.5782 - val_accuracy: 0.7706\n",
      "Epoch 593/1000\n",
      "239/239 [==============================] - 0s 901us/step - loss: 0.6278 - accuracy: 0.7531 - val_loss: 0.5794 - val_accuracy: 0.7702\n",
      "Epoch 594/1000\n",
      "239/239 [==============================] - 0s 904us/step - loss: 0.6264 - accuracy: 0.7537 - val_loss: 0.5803 - val_accuracy: 0.7702\n",
      "Epoch 595/1000\n",
      "239/239 [==============================] - 0s 912us/step - loss: 0.6274 - accuracy: 0.7541 - val_loss: 0.5778 - val_accuracy: 0.7707\n",
      "Epoch 596/1000\n",
      "239/239 [==============================] - 0s 928us/step - loss: 0.6284 - accuracy: 0.7532 - val_loss: 0.5781 - val_accuracy: 0.7724\n",
      "Epoch 597/1000\n",
      "239/239 [==============================] - 0s 951us/step - loss: 0.6254 - accuracy: 0.7540 - val_loss: 0.5790 - val_accuracy: 0.7714\n",
      "Epoch 598/1000\n",
      "239/239 [==============================] - 0s 917us/step - loss: 0.6271 - accuracy: 0.7534 - val_loss: 0.5760 - val_accuracy: 0.7710\n",
      "Epoch 599/1000\n",
      "239/239 [==============================] - 0s 905us/step - loss: 0.6258 - accuracy: 0.7535 - val_loss: 0.5779 - val_accuracy: 0.7714\n",
      "Epoch 600/1000\n",
      "239/239 [==============================] - 0s 883us/step - loss: 0.6258 - accuracy: 0.7531 - val_loss: 0.5779 - val_accuracy: 0.7709\n",
      "Epoch 601/1000\n",
      "239/239 [==============================] - 0s 922us/step - loss: 0.6254 - accuracy: 0.7534 - val_loss: 0.5815 - val_accuracy: 0.7681\n",
      "Epoch 602/1000\n",
      "239/239 [==============================] - 0s 917us/step - loss: 0.6277 - accuracy: 0.7542 - val_loss: 0.5787 - val_accuracy: 0.7715\n",
      "Epoch 603/1000\n",
      "239/239 [==============================] - 0s 932us/step - loss: 0.6260 - accuracy: 0.7536 - val_loss: 0.5794 - val_accuracy: 0.7694\n",
      "Epoch 604/1000\n",
      "239/239 [==============================] - 0s 932us/step - loss: 0.6252 - accuracy: 0.7555 - val_loss: 0.5792 - val_accuracy: 0.7699\n",
      "Epoch 605/1000\n",
      "239/239 [==============================] - 0s 935us/step - loss: 0.6283 - accuracy: 0.7531 - val_loss: 0.5792 - val_accuracy: 0.7688\n",
      "Epoch 606/1000\n",
      "239/239 [==============================] - 0s 893us/step - loss: 0.6276 - accuracy: 0.7543 - val_loss: 0.5799 - val_accuracy: 0.7704\n",
      "Epoch 607/1000\n",
      "239/239 [==============================] - 0s 886us/step - loss: 0.6252 - accuracy: 0.7547 - val_loss: 0.5798 - val_accuracy: 0.7700\n",
      "Epoch 608/1000\n",
      "239/239 [==============================] - 0s 1ms/step - loss: 0.6269 - accuracy: 0.7528 - val_loss: 0.5790 - val_accuracy: 0.7696\n",
      "Epoch 609/1000\n",
      "239/239 [==============================] - 0s 946us/step - loss: 0.6268 - accuracy: 0.7538 - val_loss: 0.5781 - val_accuracy: 0.7707\n",
      "Epoch 610/1000\n",
      "239/239 [==============================] - 0s 942us/step - loss: 0.6258 - accuracy: 0.7547 - val_loss: 0.5773 - val_accuracy: 0.7695\n",
      "Epoch 611/1000\n",
      "239/239 [==============================] - 0s 924us/step - loss: 0.6261 - accuracy: 0.7535 - val_loss: 0.5788 - val_accuracy: 0.7691\n",
      "Epoch 612/1000\n",
      "239/239 [==============================] - 0s 905us/step - loss: 0.6250 - accuracy: 0.7546 - val_loss: 0.5784 - val_accuracy: 0.7710\n",
      "Epoch 613/1000\n",
      "239/239 [==============================] - 0s 889us/step - loss: 0.6253 - accuracy: 0.7551 - val_loss: 0.5773 - val_accuracy: 0.7719\n",
      "Epoch 614/1000\n",
      "239/239 [==============================] - 0s 917us/step - loss: 0.6258 - accuracy: 0.7548 - val_loss: 0.5790 - val_accuracy: 0.7705\n",
      "Epoch 615/1000\n",
      "239/239 [==============================] - 0s 873us/step - loss: 0.6262 - accuracy: 0.7547 - val_loss: 0.5766 - val_accuracy: 0.7714\n",
      "Epoch 616/1000\n",
      "239/239 [==============================] - 0s 873us/step - loss: 0.6281 - accuracy: 0.7532 - val_loss: 0.5787 - val_accuracy: 0.7706\n",
      "Epoch 617/1000\n",
      "239/239 [==============================] - 0s 902us/step - loss: 0.6267 - accuracy: 0.7545 - val_loss: 0.5802 - val_accuracy: 0.7704\n",
      "Epoch 618/1000\n",
      "239/239 [==============================] - 0s 891us/step - loss: 0.6268 - accuracy: 0.7540 - val_loss: 0.5794 - val_accuracy: 0.7702\n",
      "Epoch 619/1000\n",
      "239/239 [==============================] - 0s 910us/step - loss: 0.6263 - accuracy: 0.7531 - val_loss: 0.5769 - val_accuracy: 0.7710\n",
      "Epoch 620/1000\n",
      "239/239 [==============================] - 0s 907us/step - loss: 0.6270 - accuracy: 0.7530 - val_loss: 0.5773 - val_accuracy: 0.7709\n",
      "Epoch 621/1000\n",
      "239/239 [==============================] - 0s 904us/step - loss: 0.6277 - accuracy: 0.7544 - val_loss: 0.5774 - val_accuracy: 0.7707\n",
      "Epoch 622/1000\n",
      "239/239 [==============================] - 0s 916us/step - loss: 0.6265 - accuracy: 0.7539 - val_loss: 0.5774 - val_accuracy: 0.7705\n",
      "Epoch 623/1000\n",
      "239/239 [==============================] - 0s 907us/step - loss: 0.6263 - accuracy: 0.7533 - val_loss: 0.5779 - val_accuracy: 0.7695\n",
      "Epoch 624/1000\n",
      "239/239 [==============================] - 0s 929us/step - loss: 0.6268 - accuracy: 0.7543 - val_loss: 0.5775 - val_accuracy: 0.7701\n",
      "Epoch 625/1000\n",
      "239/239 [==============================] - 0s 882us/step - loss: 0.6250 - accuracy: 0.7548 - val_loss: 0.5769 - val_accuracy: 0.7726\n",
      "Epoch 626/1000\n",
      "239/239 [==============================] - 0s 870us/step - loss: 0.6251 - accuracy: 0.7524 - val_loss: 0.5762 - val_accuracy: 0.7716\n",
      "Epoch 627/1000\n",
      "239/239 [==============================] - 0s 910us/step - loss: 0.6274 - accuracy: 0.7531 - val_loss: 0.5787 - val_accuracy: 0.7703\n",
      "Epoch 628/1000\n",
      "239/239 [==============================] - 0s 913us/step - loss: 0.6259 - accuracy: 0.7545 - val_loss: 0.5796 - val_accuracy: 0.7696\n",
      "Epoch 629/1000\n",
      "239/239 [==============================] - 0s 925us/step - loss: 0.6263 - accuracy: 0.7544 - val_loss: 0.5781 - val_accuracy: 0.7711\n",
      "Epoch 630/1000\n",
      "239/239 [==============================] - 0s 920us/step - loss: 0.6266 - accuracy: 0.7532 - val_loss: 0.5788 - val_accuracy: 0.7707\n",
      "Epoch 631/1000\n",
      "239/239 [==============================] - 0s 927us/step - loss: 0.6260 - accuracy: 0.7533 - val_loss: 0.5775 - val_accuracy: 0.7721\n",
      "Epoch 632/1000\n",
      "239/239 [==============================] - 0s 921us/step - loss: 0.6259 - accuracy: 0.7553 - val_loss: 0.5767 - val_accuracy: 0.7708\n",
      "Epoch 633/1000\n",
      "239/239 [==============================] - 0s 939us/step - loss: 0.6272 - accuracy: 0.7530 - val_loss: 0.5758 - val_accuracy: 0.7715\n",
      "Epoch 634/1000\n",
      "239/239 [==============================] - 0s 916us/step - loss: 0.6263 - accuracy: 0.7541 - val_loss: 0.5757 - val_accuracy: 0.7712\n",
      "Epoch 635/1000\n",
      "239/239 [==============================] - 0s 897us/step - loss: 0.6263 - accuracy: 0.7540 - val_loss: 0.5762 - val_accuracy: 0.7738\n",
      "Epoch 636/1000\n",
      "239/239 [==============================] - 0s 936us/step - loss: 0.6261 - accuracy: 0.7538 - val_loss: 0.5790 - val_accuracy: 0.7707\n",
      "Epoch 637/1000\n",
      "239/239 [==============================] - 0s 922us/step - loss: 0.6262 - accuracy: 0.7549 - val_loss: 0.5778 - val_accuracy: 0.7718\n",
      "Epoch 638/1000\n",
      "239/239 [==============================] - 0s 911us/step - loss: 0.6266 - accuracy: 0.7540 - val_loss: 0.5759 - val_accuracy: 0.7706\n",
      "Epoch 639/1000\n",
      "239/239 [==============================] - 0s 921us/step - loss: 0.6267 - accuracy: 0.7533 - val_loss: 0.5771 - val_accuracy: 0.7696\n",
      "Epoch 640/1000\n",
      "239/239 [==============================] - 0s 903us/step - loss: 0.6257 - accuracy: 0.7533 - val_loss: 0.5773 - val_accuracy: 0.7706\n",
      "Epoch 641/1000\n",
      "239/239 [==============================] - 0s 911us/step - loss: 0.6266 - accuracy: 0.7549 - val_loss: 0.5768 - val_accuracy: 0.7710\n",
      "Epoch 642/1000\n",
      "239/239 [==============================] - 0s 920us/step - loss: 0.6255 - accuracy: 0.7547 - val_loss: 0.5777 - val_accuracy: 0.7697\n",
      "Epoch 643/1000\n",
      "239/239 [==============================] - 0s 910us/step - loss: 0.6264 - accuracy: 0.7536 - val_loss: 0.5771 - val_accuracy: 0.7702\n",
      "Epoch 644/1000\n",
      "239/239 [==============================] - 0s 896us/step - loss: 0.6263 - accuracy: 0.7545 - val_loss: 0.5780 - val_accuracy: 0.7704\n",
      "Epoch 645/1000\n",
      "239/239 [==============================] - 0s 912us/step - loss: 0.6276 - accuracy: 0.7533 - val_loss: 0.5792 - val_accuracy: 0.7699\n",
      "Epoch 646/1000\n",
      "239/239 [==============================] - 0s 911us/step - loss: 0.6258 - accuracy: 0.7548 - val_loss: 0.5787 - val_accuracy: 0.7710\n",
      "Epoch 647/1000\n",
      "239/239 [==============================] - 0s 925us/step - loss: 0.6257 - accuracy: 0.7548 - val_loss: 0.5784 - val_accuracy: 0.7719\n",
      "Epoch 648/1000\n",
      "239/239 [==============================] - 0s 930us/step - loss: 0.6255 - accuracy: 0.7535 - val_loss: 0.5773 - val_accuracy: 0.7708\n",
      "Epoch 649/1000\n",
      "239/239 [==============================] - 0s 907us/step - loss: 0.6270 - accuracy: 0.7539 - val_loss: 0.5774 - val_accuracy: 0.7707\n",
      "Epoch 650/1000\n",
      "239/239 [==============================] - 0s 903us/step - loss: 0.6262 - accuracy: 0.7545 - val_loss: 0.5764 - val_accuracy: 0.7708\n",
      "Epoch 651/1000\n",
      "239/239 [==============================] - 0s 1ms/step - loss: 0.6236 - accuracy: 0.7553 - val_loss: 0.5762 - val_accuracy: 0.7711\n",
      "Epoch 652/1000\n",
      "239/239 [==============================] - 0s 987us/step - loss: 0.6254 - accuracy: 0.7545 - val_loss: 0.5765 - val_accuracy: 0.7720\n",
      "Epoch 653/1000\n",
      "239/239 [==============================] - 0s 1ms/step - loss: 0.6247 - accuracy: 0.7541 - val_loss: 0.5775 - val_accuracy: 0.7710\n",
      "Epoch 654/1000\n",
      "239/239 [==============================] - 0s 934us/step - loss: 0.6267 - accuracy: 0.7540 - val_loss: 0.5766 - val_accuracy: 0.7716\n",
      "Epoch 655/1000\n",
      "239/239 [==============================] - 0s 989us/step - loss: 0.6258 - accuracy: 0.7541 - val_loss: 0.5780 - val_accuracy: 0.7704\n",
      "Epoch 656/1000\n",
      "239/239 [==============================] - 0s 1000us/step - loss: 0.6249 - accuracy: 0.7553 - val_loss: 0.5770 - val_accuracy: 0.7718\n",
      "Epoch 657/1000\n",
      "239/239 [==============================] - 0s 910us/step - loss: 0.6275 - accuracy: 0.7538 - val_loss: 0.5782 - val_accuracy: 0.7723\n",
      "Epoch 658/1000\n",
      "239/239 [==============================] - 0s 905us/step - loss: 0.6252 - accuracy: 0.7544 - val_loss: 0.5780 - val_accuracy: 0.7695\n",
      "Epoch 659/1000\n",
      "239/239 [==============================] - 0s 1ms/step - loss: 0.6265 - accuracy: 0.7539 - val_loss: 0.5803 - val_accuracy: 0.7716\n",
      "Epoch 660/1000\n",
      "239/239 [==============================] - 0s 1ms/step - loss: 0.6278 - accuracy: 0.7538 - val_loss: 0.5789 - val_accuracy: 0.7697\n",
      "Epoch 661/1000\n",
      "239/239 [==============================] - 0s 1ms/step - loss: 0.6237 - accuracy: 0.7545 - val_loss: 0.5759 - val_accuracy: 0.7713\n",
      "Epoch 662/1000\n",
      "239/239 [==============================] - 0s 1ms/step - loss: 0.6281 - accuracy: 0.7533 - val_loss: 0.5763 - val_accuracy: 0.7710\n",
      "Epoch 663/1000\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "239/239 [==============================] - 0s 1ms/step - loss: 0.6256 - accuracy: 0.7555 - val_loss: 0.5779 - val_accuracy: 0.7714\n",
      "Epoch 664/1000\n",
      "239/239 [==============================] - 0s 1ms/step - loss: 0.6267 - accuracy: 0.7535 - val_loss: 0.5771 - val_accuracy: 0.7717\n",
      "Epoch 665/1000\n",
      "239/239 [==============================] - 0s 931us/step - loss: 0.6241 - accuracy: 0.7545 - val_loss: 0.5781 - val_accuracy: 0.7708\n",
      "Epoch 666/1000\n",
      "239/239 [==============================] - 0s 909us/step - loss: 0.6248 - accuracy: 0.7545 - val_loss: 0.5775 - val_accuracy: 0.7708\n",
      "Epoch 667/1000\n",
      "239/239 [==============================] - 0s 939us/step - loss: 0.6253 - accuracy: 0.7544 - val_loss: 0.5771 - val_accuracy: 0.7724\n",
      "Epoch 668/1000\n",
      "239/239 [==============================] - 0s 945us/step - loss: 0.6246 - accuracy: 0.7554 - val_loss: 0.5780 - val_accuracy: 0.7707\n",
      "Epoch 669/1000\n",
      "239/239 [==============================] - 0s 858us/step - loss: 0.6266 - accuracy: 0.7540 - val_loss: 0.5790 - val_accuracy: 0.7701\n",
      "Epoch 670/1000\n",
      "239/239 [==============================] - 0s 853us/step - loss: 0.6254 - accuracy: 0.7538 - val_loss: 0.5784 - val_accuracy: 0.7694\n",
      "Epoch 671/1000\n",
      "239/239 [==============================] - 0s 854us/step - loss: 0.6267 - accuracy: 0.7537 - val_loss: 0.5773 - val_accuracy: 0.7716\n",
      "Epoch 672/1000\n",
      "239/239 [==============================] - 0s 879us/step - loss: 0.6245 - accuracy: 0.7541 - val_loss: 0.5768 - val_accuracy: 0.7707\n",
      "Epoch 673/1000\n",
      "239/239 [==============================] - 0s 866us/step - loss: 0.6259 - accuracy: 0.7544 - val_loss: 0.5778 - val_accuracy: 0.7705\n",
      "Epoch 674/1000\n",
      "239/239 [==============================] - 0s 871us/step - loss: 0.6271 - accuracy: 0.7547 - val_loss: 0.5780 - val_accuracy: 0.7716\n",
      "Epoch 675/1000\n",
      "239/239 [==============================] - 0s 911us/step - loss: 0.6237 - accuracy: 0.7551 - val_loss: 0.5762 - val_accuracy: 0.7708\n",
      "Epoch 676/1000\n",
      "239/239 [==============================] - 0s 907us/step - loss: 0.6254 - accuracy: 0.7541 - val_loss: 0.5762 - val_accuracy: 0.7708\n",
      "Epoch 677/1000\n",
      "239/239 [==============================] - 0s 935us/step - loss: 0.6269 - accuracy: 0.7529 - val_loss: 0.5776 - val_accuracy: 0.7702\n",
      "Epoch 678/1000\n",
      "239/239 [==============================] - 0s 1ms/step - loss: 0.6267 - accuracy: 0.7541 - val_loss: 0.5777 - val_accuracy: 0.7700\n",
      "Epoch 679/1000\n",
      "239/239 [==============================] - 0s 1ms/step - loss: 0.6259 - accuracy: 0.7546 - val_loss: 0.5772 - val_accuracy: 0.7705\n",
      "Epoch 680/1000\n",
      "239/239 [==============================] - 0s 921us/step - loss: 0.6256 - accuracy: 0.7529 - val_loss: 0.5772 - val_accuracy: 0.7720\n",
      "Epoch 681/1000\n",
      "239/239 [==============================] - 0s 917us/step - loss: 0.6263 - accuracy: 0.7539 - val_loss: 0.5774 - val_accuracy: 0.7727\n",
      "Epoch 682/1000\n",
      "239/239 [==============================] - 0s 897us/step - loss: 0.6262 - accuracy: 0.7549 - val_loss: 0.5755 - val_accuracy: 0.7731\n",
      "Epoch 683/1000\n",
      "239/239 [==============================] - 0s 907us/step - loss: 0.6242 - accuracy: 0.7535 - val_loss: 0.5770 - val_accuracy: 0.7705\n",
      "Epoch 684/1000\n",
      "239/239 [==============================] - 0s 916us/step - loss: 0.6254 - accuracy: 0.7540 - val_loss: 0.5778 - val_accuracy: 0.7714\n",
      "Epoch 685/1000\n",
      "239/239 [==============================] - 0s 990us/step - loss: 0.6244 - accuracy: 0.7534 - val_loss: 0.5771 - val_accuracy: 0.7719\n",
      "Epoch 686/1000\n",
      "239/239 [==============================] - 0s 1ms/step - loss: 0.6249 - accuracy: 0.7552 - val_loss: 0.5776 - val_accuracy: 0.7705\n",
      "Epoch 687/1000\n",
      "239/239 [==============================] - 0s 1ms/step - loss: 0.6245 - accuracy: 0.7554 - val_loss: 0.5764 - val_accuracy: 0.7709\n",
      "Epoch 688/1000\n",
      "239/239 [==============================] - 0s 1000us/step - loss: 0.6242 - accuracy: 0.7543 - val_loss: 0.5756 - val_accuracy: 0.7722\n",
      "Epoch 689/1000\n",
      "239/239 [==============================] - 0s 999us/step - loss: 0.6255 - accuracy: 0.7544 - val_loss: 0.5772 - val_accuracy: 0.7696\n",
      "Epoch 690/1000\n",
      "239/239 [==============================] - 0s 990us/step - loss: 0.6246 - accuracy: 0.7553 - val_loss: 0.5787 - val_accuracy: 0.7711\n",
      "Epoch 691/1000\n",
      "239/239 [==============================] - 0s 1ms/step - loss: 0.6240 - accuracy: 0.7549 - val_loss: 0.5768 - val_accuracy: 0.7714\n",
      "Epoch 692/1000\n",
      "239/239 [==============================] - 0s 990us/step - loss: 0.6248 - accuracy: 0.7540 - val_loss: 0.5761 - val_accuracy: 0.7709\n",
      "Epoch 693/1000\n",
      "239/239 [==============================] - 0s 985us/step - loss: 0.6243 - accuracy: 0.7545 - val_loss: 0.5757 - val_accuracy: 0.7722\n",
      "Epoch 694/1000\n",
      "239/239 [==============================] - 0s 934us/step - loss: 0.6258 - accuracy: 0.7543 - val_loss: 0.5767 - val_accuracy: 0.7714\n",
      "Epoch 695/1000\n",
      "239/239 [==============================] - 0s 911us/step - loss: 0.6278 - accuracy: 0.7530 - val_loss: 0.5799 - val_accuracy: 0.7699\n",
      "Epoch 696/1000\n",
      "239/239 [==============================] - 0s 931us/step - loss: 0.6242 - accuracy: 0.7552 - val_loss: 0.5762 - val_accuracy: 0.7718\n",
      "Epoch 697/1000\n",
      "239/239 [==============================] - 0s 926us/step - loss: 0.6251 - accuracy: 0.7539 - val_loss: 0.5776 - val_accuracy: 0.7693\n",
      "Epoch 698/1000\n",
      "239/239 [==============================] - 0s 924us/step - loss: 0.6259 - accuracy: 0.7537 - val_loss: 0.5777 - val_accuracy: 0.7703\n",
      "Epoch 699/1000\n",
      "239/239 [==============================] - 0s 913us/step - loss: 0.6249 - accuracy: 0.7541 - val_loss: 0.5760 - val_accuracy: 0.7724\n",
      "Epoch 700/1000\n",
      "239/239 [==============================] - 0s 905us/step - loss: 0.6267 - accuracy: 0.7536 - val_loss: 0.5759 - val_accuracy: 0.7725\n",
      "Epoch 701/1000\n",
      "239/239 [==============================] - 0s 973us/step - loss: 0.6257 - accuracy: 0.7548 - val_loss: 0.5780 - val_accuracy: 0.7705\n",
      "Epoch 702/1000\n",
      "239/239 [==============================] - 0s 949us/step - loss: 0.6244 - accuracy: 0.7555 - val_loss: 0.5769 - val_accuracy: 0.7719\n",
      "Epoch 703/1000\n",
      "239/239 [==============================] - 0s 914us/step - loss: 0.6247 - accuracy: 0.7544 - val_loss: 0.5774 - val_accuracy: 0.7723\n",
      "Epoch 704/1000\n",
      "239/239 [==============================] - 0s 901us/step - loss: 0.6253 - accuracy: 0.7557 - val_loss: 0.5780 - val_accuracy: 0.7721\n",
      "Epoch 705/1000\n",
      "239/239 [==============================] - 0s 927us/step - loss: 0.6263 - accuracy: 0.7531 - val_loss: 0.5776 - val_accuracy: 0.7697\n",
      "Epoch 706/1000\n",
      "239/239 [==============================] - 0s 924us/step - loss: 0.6235 - accuracy: 0.7543 - val_loss: 0.5779 - val_accuracy: 0.7702\n",
      "Epoch 707/1000\n",
      "239/239 [==============================] - 0s 931us/step - loss: 0.6232 - accuracy: 0.7544 - val_loss: 0.5774 - val_accuracy: 0.7717\n",
      "Epoch 708/1000\n",
      "239/239 [==============================] - 0s 911us/step - loss: 0.6266 - accuracy: 0.7534 - val_loss: 0.5774 - val_accuracy: 0.7702\n",
      "Epoch 709/1000\n",
      "239/239 [==============================] - 0s 866us/step - loss: 0.6242 - accuracy: 0.7554 - val_loss: 0.5781 - val_accuracy: 0.7716\n",
      "Epoch 710/1000\n",
      "239/239 [==============================] - 0s 869us/step - loss: 0.6253 - accuracy: 0.7530 - val_loss: 0.5805 - val_accuracy: 0.7705\n",
      "Epoch 711/1000\n",
      "239/239 [==============================] - 0s 904us/step - loss: 0.6247 - accuracy: 0.7543 - val_loss: 0.5781 - val_accuracy: 0.7713\n",
      "Epoch 712/1000\n",
      "239/239 [==============================] - 0s 911us/step - loss: 0.6254 - accuracy: 0.7550 - val_loss: 0.5777 - val_accuracy: 0.7722\n",
      "Epoch 713/1000\n",
      "239/239 [==============================] - 0s 906us/step - loss: 0.6235 - accuracy: 0.7555 - val_loss: 0.5766 - val_accuracy: 0.7712\n",
      "Epoch 714/1000\n",
      "239/239 [==============================] - 0s 878us/step - loss: 0.6258 - accuracy: 0.7535 - val_loss: 0.5771 - val_accuracy: 0.7716\n",
      "Epoch 715/1000\n",
      "239/239 [==============================] - 0s 864us/step - loss: 0.6256 - accuracy: 0.7547 - val_loss: 0.5742 - val_accuracy: 0.7719\n",
      "Epoch 716/1000\n",
      "239/239 [==============================] - 0s 1ms/step - loss: 0.6264 - accuracy: 0.7535 - val_loss: 0.5755 - val_accuracy: 0.7723\n",
      "Epoch 717/1000\n",
      "239/239 [==============================] - 0s 918us/step - loss: 0.6242 - accuracy: 0.7549 - val_loss: 0.5755 - val_accuracy: 0.7722\n",
      "Epoch 718/1000\n",
      "239/239 [==============================] - 0s 918us/step - loss: 0.6251 - accuracy: 0.7545 - val_loss: 0.5761 - val_accuracy: 0.7721\n",
      "Epoch 719/1000\n",
      "239/239 [==============================] - 0s 928us/step - loss: 0.6257 - accuracy: 0.7554 - val_loss: 0.5782 - val_accuracy: 0.7712\n",
      "Epoch 720/1000\n",
      "239/239 [==============================] - 0s 916us/step - loss: 0.6254 - accuracy: 0.7532 - val_loss: 0.5770 - val_accuracy: 0.7708\n",
      "Epoch 721/1000\n",
      "239/239 [==============================] - 0s 950us/step - loss: 0.6255 - accuracy: 0.7544 - val_loss: 0.5777 - val_accuracy: 0.7718\n",
      "Epoch 722/1000\n",
      "239/239 [==============================] - 0s 915us/step - loss: 0.6263 - accuracy: 0.7537 - val_loss: 0.5767 - val_accuracy: 0.7711\n",
      "Epoch 723/1000\n",
      "239/239 [==============================] - 0s 906us/step - loss: 0.6254 - accuracy: 0.7540 - val_loss: 0.5764 - val_accuracy: 0.7722\n",
      "Epoch 724/1000\n",
      "239/239 [==============================] - 0s 904us/step - loss: 0.6253 - accuracy: 0.7540 - val_loss: 0.5763 - val_accuracy: 0.7715\n",
      "Epoch 725/1000\n",
      "239/239 [==============================] - 0s 922us/step - loss: 0.6266 - accuracy: 0.7538 - val_loss: 0.5765 - val_accuracy: 0.7695\n",
      "Epoch 726/1000\n",
      "239/239 [==============================] - 0s 960us/step - loss: 0.6244 - accuracy: 0.7544 - val_loss: 0.5749 - val_accuracy: 0.7711\n",
      "Epoch 727/1000\n",
      "239/239 [==============================] - 0s 916us/step - loss: 0.6264 - accuracy: 0.7539 - val_loss: 0.5763 - val_accuracy: 0.7733\n",
      "Epoch 728/1000\n",
      "239/239 [==============================] - 0s 898us/step - loss: 0.6255 - accuracy: 0.7548 - val_loss: 0.5767 - val_accuracy: 0.7724\n",
      "Epoch 729/1000\n",
      "239/239 [==============================] - 0s 905us/step - loss: 0.6264 - accuracy: 0.7539 - val_loss: 0.5761 - val_accuracy: 0.7712\n",
      "Epoch 730/1000\n",
      "239/239 [==============================] - 0s 928us/step - loss: 0.6246 - accuracy: 0.7541 - val_loss: 0.5772 - val_accuracy: 0.7723\n",
      "Epoch 731/1000\n",
      "239/239 [==============================] - 0s 923us/step - loss: 0.6255 - accuracy: 0.7552 - val_loss: 0.5760 - val_accuracy: 0.7721\n",
      "Epoch 732/1000\n",
      "239/239 [==============================] - 0s 925us/step - loss: 0.6229 - accuracy: 0.7556 - val_loss: 0.5785 - val_accuracy: 0.7710\n",
      "Epoch 733/1000\n",
      "239/239 [==============================] - 0s 906us/step - loss: 0.6248 - accuracy: 0.7533 - val_loss: 0.5776 - val_accuracy: 0.7686\n",
      "Epoch 734/1000\n",
      "239/239 [==============================] - 0s 954us/step - loss: 0.6242 - accuracy: 0.7544 - val_loss: 0.5771 - val_accuracy: 0.7724\n",
      "Epoch 735/1000\n",
      "239/239 [==============================] - 0s 1ms/step - loss: 0.6262 - accuracy: 0.7537 - val_loss: 0.5761 - val_accuracy: 0.7718\n",
      "Epoch 736/1000\n",
      "239/239 [==============================] - 0s 996us/step - loss: 0.6240 - accuracy: 0.7541 - val_loss: 0.5760 - val_accuracy: 0.7712\n",
      "Epoch 737/1000\n",
      "239/239 [==============================] - 0s 910us/step - loss: 0.6256 - accuracy: 0.7536 - val_loss: 0.5762 - val_accuracy: 0.7708\n",
      "Epoch 738/1000\n",
      "239/239 [==============================] - 0s 904us/step - loss: 0.6247 - accuracy: 0.7537 - val_loss: 0.5790 - val_accuracy: 0.7710\n",
      "Epoch 739/1000\n",
      "239/239 [==============================] - 0s 944us/step - loss: 0.6259 - accuracy: 0.7542 - val_loss: 0.5758 - val_accuracy: 0.7713\n",
      "Epoch 740/1000\n",
      "239/239 [==============================] - 0s 922us/step - loss: 0.6245 - accuracy: 0.7536 - val_loss: 0.5765 - val_accuracy: 0.7710\n",
      "Epoch 741/1000\n",
      "239/239 [==============================] - 0s 903us/step - loss: 0.6257 - accuracy: 0.7533 - val_loss: 0.5774 - val_accuracy: 0.7722\n",
      "Epoch 742/1000\n",
      "239/239 [==============================] - 0s 916us/step - loss: 0.6260 - accuracy: 0.7547 - val_loss: 0.5776 - val_accuracy: 0.7710\n",
      "Epoch 743/1000\n",
      "239/239 [==============================] - 0s 921us/step - loss: 0.6252 - accuracy: 0.7539 - val_loss: 0.5762 - val_accuracy: 0.7707\n",
      "Epoch 744/1000\n",
      "239/239 [==============================] - 0s 924us/step - loss: 0.6273 - accuracy: 0.7535 - val_loss: 0.5788 - val_accuracy: 0.7697\n",
      "Epoch 745/1000\n",
      "239/239 [==============================] - 0s 905us/step - loss: 0.6260 - accuracy: 0.7540 - val_loss: 0.5784 - val_accuracy: 0.7720\n",
      "Epoch 746/1000\n",
      "239/239 [==============================] - 0s 910us/step - loss: 0.6245 - accuracy: 0.7546 - val_loss: 0.5756 - val_accuracy: 0.7710\n",
      "Epoch 747/1000\n",
      "239/239 [==============================] - 0s 890us/step - loss: 0.6244 - accuracy: 0.7542 - val_loss: 0.5742 - val_accuracy: 0.7733\n",
      "Epoch 748/1000\n",
      "239/239 [==============================] - 0s 930us/step - loss: 0.6244 - accuracy: 0.7552 - val_loss: 0.5775 - val_accuracy: 0.7719\n",
      "Epoch 749/1000\n",
      "239/239 [==============================] - 0s 886us/step - loss: 0.6259 - accuracy: 0.7547 - val_loss: 0.5764 - val_accuracy: 0.7705\n",
      "Epoch 750/1000\n",
      "239/239 [==============================] - 0s 989us/step - loss: 0.6252 - accuracy: 0.7546 - val_loss: 0.5763 - val_accuracy: 0.7715\n",
      "Epoch 751/1000\n",
      "239/239 [==============================] - 0s 864us/step - loss: 0.6257 - accuracy: 0.7542 - val_loss: 0.5771 - val_accuracy: 0.7738\n",
      "Epoch 752/1000\n",
      "239/239 [==============================] - 0s 860us/step - loss: 0.6239 - accuracy: 0.7542 - val_loss: 0.5769 - val_accuracy: 0.7729\n",
      "Epoch 753/1000\n",
      "239/239 [==============================] - 0s 1ms/step - loss: 0.6234 - accuracy: 0.7552 - val_loss: 0.5771 - val_accuracy: 0.7717\n",
      "Epoch 754/1000\n",
      "239/239 [==============================] - 0s 927us/step - loss: 0.6248 - accuracy: 0.7535 - val_loss: 0.5777 - val_accuracy: 0.7711\n",
      "Epoch 755/1000\n",
      "239/239 [==============================] - 0s 931us/step - loss: 0.6250 - accuracy: 0.7553 - val_loss: 0.5765 - val_accuracy: 0.7713\n",
      "Epoch 756/1000\n",
      "239/239 [==============================] - 0s 922us/step - loss: 0.6258 - accuracy: 0.7556 - val_loss: 0.5746 - val_accuracy: 0.7720\n",
      "Epoch 757/1000\n",
      "239/239 [==============================] - 0s 924us/step - loss: 0.6265 - accuracy: 0.7554 - val_loss: 0.5765 - val_accuracy: 0.7708\n",
      "Epoch 758/1000\n",
      "239/239 [==============================] - 0s 896us/step - loss: 0.6245 - accuracy: 0.7551 - val_loss: 0.5764 - val_accuracy: 0.7723\n",
      "Epoch 759/1000\n",
      "239/239 [==============================] - 0s 902us/step - loss: 0.6249 - accuracy: 0.7543 - val_loss: 0.5759 - val_accuracy: 0.7716\n",
      "Epoch 760/1000\n",
      "239/239 [==============================] - 0s 904us/step - loss: 0.6249 - accuracy: 0.7544 - val_loss: 0.5769 - val_accuracy: 0.7694\n",
      "Epoch 761/1000\n",
      "239/239 [==============================] - 0s 903us/step - loss: 0.6247 - accuracy: 0.7542 - val_loss: 0.5753 - val_accuracy: 0.7724\n",
      "Epoch 762/1000\n",
      "239/239 [==============================] - 0s 948us/step - loss: 0.6251 - accuracy: 0.7546 - val_loss: 0.5748 - val_accuracy: 0.7714\n",
      "Epoch 763/1000\n",
      "239/239 [==============================] - 0s 908us/step - loss: 0.6252 - accuracy: 0.7546 - val_loss: 0.5760 - val_accuracy: 0.7718\n",
      "Epoch 764/1000\n",
      "239/239 [==============================] - 0s 903us/step - loss: 0.6248 - accuracy: 0.7545 - val_loss: 0.5760 - val_accuracy: 0.7706\n",
      "Epoch 765/1000\n",
      "239/239 [==============================] - 0s 903us/step - loss: 0.6257 - accuracy: 0.7550 - val_loss: 0.5759 - val_accuracy: 0.7719\n",
      "Epoch 765: early stopping\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "<keras.src.callbacks.History at 0x144f0c8e0>"
      ]
     },
     "execution_count": 78,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# 4 hidden layer\n",
    "model=Sequential()\n",
    "\n",
    "model.add(Dense(64, activation=\"relu\"))\n",
    "model.add(Dropout(0.2))\n",
    "model.add(Dense(32, activation=\"relu\"))\n",
    "model.add(Dense(16, activation=\"relu\"))\n",
    "model.add(Dropout(0.2))\n",
    "model.add(Dense(8, activation=\"relu\"))\n",
    "model.add(Dropout(0.2))\n",
    "model.add(Dense(3, activation=\"softmax\"))\n",
    "\n",
    "model.compile(loss='categorical_crossentropy', optimizer=Adam(learning_rate=0.001), metrics=['accuracy'])\n",
    "\n",
    "es=EarlyStopping(monitor=\"val_loss\",patience=50,mode=\"auto\",verbose=1)\n",
    "\n",
    "model.fit(X_train,\n",
    "          y_train,\n",
    "          epochs=1000,\n",
    "               batch_size=512,\n",
    "               validation_split=0.1,\n",
    "               verbose=1,callbacks=[es])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 79,
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "748/748 [==============================] - 0s 225us/step\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0       0.76      0.88      0.82      7973\n",
      "           1       0.77      0.82      0.79      7973\n",
      "           2       0.75      0.58      0.66      7972\n",
      "\n",
      "    accuracy                           0.76     23918\n",
      "   macro avg       0.76      0.76      0.76     23918\n",
      "weighted avg       0.76      0.76      0.76     23918\n",
      "\n"
     ]
    }
   ],
   "source": [
    "y_pred = model.predict(X_test)\n",
    "y_pred_classes = np.argmax(y_pred, axis=1)\n",
    "y_true = np.argmax(y_test, axis=1)\n",
    "print(classification_report(y_true, y_pred_classes))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 80,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "4236/4236 [==============================] - 1s 220us/step\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0       0.77      0.89      0.83     45176\n",
      "           1       0.78      0.83      0.80     45176\n",
      "           2       0.77      0.60      0.68     45177\n",
      "\n",
      "    accuracy                           0.77    135529\n",
      "   macro avg       0.77      0.77      0.77    135529\n",
      "weighted avg       0.77      0.77      0.77    135529\n",
      "\n"
     ]
    }
   ],
   "source": [
    "y_t_pred = model.predict(X_train)\n",
    "y_t_pred_classes = np.argmax(y_t_pred, axis=1)\n",
    "y_t_true = np.argmax(y_train, axis=1)\n",
    "print(classification_report(y_t_true, y_t_pred_classes))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 81,
   "metadata": {},
   "outputs": [],
   "source": [
    "model=Sequential()\n",
    "model.add(Dense(128, input_dim=X_train.shape[1], activation=\"relu\"))\n",
    "model.add(Dropout(0.8))\n",
    "model.add(Dense(128, activation=\"relu\"))\n",
    "\n",
    "model.add(Dense(64, activation=\"relu\"))\n",
    "model.add(Dropout(0.2))\n",
    "model.add(Dense(64, activation=\"relu\"))\n",
    "\n",
    "model.add(Dense(32, activation=\"relu\"))\n",
    "model.add(Dropout(0.2))\n",
    "model.add(Dense(16, activation=\"relu\"))\n",
    "model.add(Dropout(0.2))\n",
    "model.add(Dense(3, activation=\"softmax\"))\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 82,
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 1/1000\n",
      "239/239 [==============================] - 1s 2ms/step - loss: 0.8659 - accuracy: 0.6326 - val_loss: 0.7521 - val_accuracy: 0.7195\n",
      "Epoch 2/1000\n",
      "239/239 [==============================] - 1s 3ms/step - loss: 0.7805 - accuracy: 0.7000 - val_loss: 0.7082 - val_accuracy: 0.7255\n",
      "Epoch 3/1000\n",
      "239/239 [==============================] - 1s 2ms/step - loss: 0.7532 - accuracy: 0.7131 - val_loss: 0.7007 - val_accuracy: 0.7294\n",
      "Epoch 4/1000\n",
      "239/239 [==============================] - 0s 2ms/step - loss: 0.7412 - accuracy: 0.7170 - val_loss: 0.6914 - val_accuracy: 0.7302\n",
      "Epoch 5/1000\n",
      "239/239 [==============================] - 0s 2ms/step - loss: 0.7337 - accuracy: 0.7189 - val_loss: 0.6926 - val_accuracy: 0.7370\n",
      "Epoch 6/1000\n",
      "239/239 [==============================] - 0s 2ms/step - loss: 0.7269 - accuracy: 0.7210 - val_loss: 0.6891 - val_accuracy: 0.7366\n",
      "Epoch 7/1000\n",
      "239/239 [==============================] - 0s 2ms/step - loss: 0.7216 - accuracy: 0.7245 - val_loss: 0.6783 - val_accuracy: 0.7376\n",
      "Epoch 8/1000\n",
      "239/239 [==============================] - 0s 2ms/step - loss: 0.7185 - accuracy: 0.7254 - val_loss: 0.6815 - val_accuracy: 0.7387\n",
      "Epoch 9/1000\n",
      "239/239 [==============================] - 0s 2ms/step - loss: 0.7156 - accuracy: 0.7260 - val_loss: 0.6799 - val_accuracy: 0.7404\n",
      "Epoch 10/1000\n",
      "239/239 [==============================] - 0s 2ms/step - loss: 0.7132 - accuracy: 0.7259 - val_loss: 0.6790 - val_accuracy: 0.7409\n",
      "Epoch 11/1000\n",
      "239/239 [==============================] - 0s 2ms/step - loss: 0.7110 - accuracy: 0.7277 - val_loss: 0.6819 - val_accuracy: 0.7412\n",
      "Epoch 12/1000\n",
      "239/239 [==============================] - 0s 2ms/step - loss: 0.7101 - accuracy: 0.7275 - val_loss: 0.6831 - val_accuracy: 0.7407\n",
      "Epoch 13/1000\n",
      "239/239 [==============================] - 0s 2ms/step - loss: 0.7070 - accuracy: 0.7280 - val_loss: 0.6752 - val_accuracy: 0.7411\n",
      "Epoch 14/1000\n",
      "239/239 [==============================] - 0s 2ms/step - loss: 0.7066 - accuracy: 0.7288 - val_loss: 0.6766 - val_accuracy: 0.7423\n",
      "Epoch 15/1000\n",
      "239/239 [==============================] - 0s 2ms/step - loss: 0.7063 - accuracy: 0.7282 - val_loss: 0.6725 - val_accuracy: 0.7404\n",
      "Epoch 16/1000\n",
      "239/239 [==============================] - 1s 2ms/step - loss: 0.7054 - accuracy: 0.7290 - val_loss: 0.6757 - val_accuracy: 0.7412\n",
      "Epoch 17/1000\n",
      "239/239 [==============================] - 0s 2ms/step - loss: 0.7037 - accuracy: 0.7296 - val_loss: 0.6761 - val_accuracy: 0.7409\n",
      "Epoch 18/1000\n",
      "239/239 [==============================] - 0s 2ms/step - loss: 0.7026 - accuracy: 0.7296 - val_loss: 0.6808 - val_accuracy: 0.7412\n",
      "Epoch 19/1000\n",
      "239/239 [==============================] - 0s 2ms/step - loss: 0.7025 - accuracy: 0.7301 - val_loss: 0.6721 - val_accuracy: 0.7414\n",
      "Epoch 20/1000\n",
      "239/239 [==============================] - 0s 2ms/step - loss: 0.7017 - accuracy: 0.7298 - val_loss: 0.6749 - val_accuracy: 0.7425\n",
      "Epoch 21/1000\n",
      "239/239 [==============================] - 0s 2ms/step - loss: 0.7011 - accuracy: 0.7306 - val_loss: 0.6767 - val_accuracy: 0.7415\n",
      "Epoch 22/1000\n",
      "239/239 [==============================] - 1s 2ms/step - loss: 0.6995 - accuracy: 0.7308 - val_loss: 0.6701 - val_accuracy: 0.7419\n",
      "Epoch 23/1000\n",
      "239/239 [==============================] - 1s 2ms/step - loss: 0.6991 - accuracy: 0.7308 - val_loss: 0.6732 - val_accuracy: 0.7401\n",
      "Epoch 24/1000\n",
      "239/239 [==============================] - 0s 2ms/step - loss: 0.6986 - accuracy: 0.7307 - val_loss: 0.6711 - val_accuracy: 0.7407\n",
      "Epoch 25/1000\n",
      "239/239 [==============================] - 0s 2ms/step - loss: 0.6972 - accuracy: 0.7309 - val_loss: 0.6790 - val_accuracy: 0.7415\n",
      "Epoch 26/1000\n",
      "239/239 [==============================] - 0s 2ms/step - loss: 0.6979 - accuracy: 0.7304 - val_loss: 0.6719 - val_accuracy: 0.7435\n",
      "Epoch 27/1000\n",
      "239/239 [==============================] - 0s 2ms/step - loss: 0.6965 - accuracy: 0.7312 - val_loss: 0.6701 - val_accuracy: 0.7440\n",
      "Epoch 28/1000\n",
      "239/239 [==============================] - 1s 2ms/step - loss: 0.6974 - accuracy: 0.7320 - val_loss: 0.6791 - val_accuracy: 0.7434\n",
      "Epoch 29/1000\n",
      "239/239 [==============================] - 1s 2ms/step - loss: 0.6973 - accuracy: 0.7320 - val_loss: 0.6752 - val_accuracy: 0.7426\n",
      "Epoch 30/1000\n",
      "239/239 [==============================] - 1s 2ms/step - loss: 0.6969 - accuracy: 0.7313 - val_loss: 0.6763 - val_accuracy: 0.7435\n",
      "Epoch 31/1000\n",
      "239/239 [==============================] - 1s 2ms/step - loss: 0.6949 - accuracy: 0.7319 - val_loss: 0.6788 - val_accuracy: 0.7427\n",
      "Epoch 32/1000\n",
      "239/239 [==============================] - 0s 2ms/step - loss: 0.6957 - accuracy: 0.7315 - val_loss: 0.6721 - val_accuracy: 0.7435\n",
      "Epoch 33/1000\n",
      "239/239 [==============================] - 0s 2ms/step - loss: 0.6958 - accuracy: 0.7317 - val_loss: 0.6716 - val_accuracy: 0.7435\n",
      "Epoch 34/1000\n",
      "239/239 [==============================] - 1s 2ms/step - loss: 0.6951 - accuracy: 0.7314 - val_loss: 0.6706 - val_accuracy: 0.7449\n",
      "Epoch 35/1000\n",
      "239/239 [==============================] - 0s 2ms/step - loss: 0.6946 - accuracy: 0.7320 - val_loss: 0.6703 - val_accuracy: 0.7446\n",
      "Epoch 36/1000\n",
      "239/239 [==============================] - 0s 2ms/step - loss: 0.6941 - accuracy: 0.7321 - val_loss: 0.6702 - val_accuracy: 0.7432\n",
      "Epoch 37/1000\n",
      "239/239 [==============================] - 0s 2ms/step - loss: 0.6948 - accuracy: 0.7321 - val_loss: 0.6689 - val_accuracy: 0.7432\n",
      "Epoch 38/1000\n",
      "239/239 [==============================] - 0s 2ms/step - loss: 0.6942 - accuracy: 0.7322 - val_loss: 0.6685 - val_accuracy: 0.7437\n",
      "Epoch 39/1000\n",
      "239/239 [==============================] - 0s 2ms/step - loss: 0.6939 - accuracy: 0.7323 - val_loss: 0.6730 - val_accuracy: 0.7426\n",
      "Epoch 40/1000\n",
      "239/239 [==============================] - 0s 2ms/step - loss: 0.6941 - accuracy: 0.7325 - val_loss: 0.6757 - val_accuracy: 0.7429\n",
      "Epoch 41/1000\n",
      "239/239 [==============================] - 0s 2ms/step - loss: 0.6928 - accuracy: 0.7327 - val_loss: 0.6699 - val_accuracy: 0.7419\n",
      "Epoch 42/1000\n",
      "239/239 [==============================] - 0s 2ms/step - loss: 0.6925 - accuracy: 0.7325 - val_loss: 0.6716 - val_accuracy: 0.7436\n",
      "Epoch 43/1000\n",
      "239/239 [==============================] - 0s 2ms/step - loss: 0.6917 - accuracy: 0.7321 - val_loss: 0.6687 - val_accuracy: 0.7404\n",
      "Epoch 44/1000\n",
      "239/239 [==============================] - 0s 2ms/step - loss: 0.6929 - accuracy: 0.7317 - val_loss: 0.6755 - val_accuracy: 0.7437\n",
      "Epoch 45/1000\n",
      "239/239 [==============================] - 1s 2ms/step - loss: 0.6929 - accuracy: 0.7320 - val_loss: 0.6629 - val_accuracy: 0.7437\n",
      "Epoch 46/1000\n",
      "239/239 [==============================] - 0s 2ms/step - loss: 0.6926 - accuracy: 0.7325 - val_loss: 0.6666 - val_accuracy: 0.7382\n",
      "Epoch 47/1000\n",
      "239/239 [==============================] - 1s 2ms/step - loss: 0.6936 - accuracy: 0.7319 - val_loss: 0.6693 - val_accuracy: 0.7432\n",
      "Epoch 48/1000\n",
      "239/239 [==============================] - 0s 2ms/step - loss: 0.6939 - accuracy: 0.7319 - val_loss: 0.6719 - val_accuracy: 0.7426\n",
      "Epoch 49/1000\n",
      "239/239 [==============================] - 0s 2ms/step - loss: 0.6920 - accuracy: 0.7328 - val_loss: 0.6651 - val_accuracy: 0.7457\n",
      "Epoch 50/1000\n",
      "239/239 [==============================] - 1s 3ms/step - loss: 0.6925 - accuracy: 0.7331 - val_loss: 0.6662 - val_accuracy: 0.7456\n",
      "Epoch 51/1000\n",
      "239/239 [==============================] - 0s 2ms/step - loss: 0.6932 - accuracy: 0.7330 - val_loss: 0.6660 - val_accuracy: 0.7411\n",
      "Epoch 52/1000\n",
      "239/239 [==============================] - 0s 2ms/step - loss: 0.6917 - accuracy: 0.7330 - val_loss: 0.6662 - val_accuracy: 0.7435\n",
      "Epoch 53/1000\n",
      "239/239 [==============================] - 0s 2ms/step - loss: 0.6921 - accuracy: 0.7329 - val_loss: 0.6698 - val_accuracy: 0.7427\n",
      "Epoch 54/1000\n",
      "239/239 [==============================] - 0s 2ms/step - loss: 0.6905 - accuracy: 0.7338 - val_loss: 0.6660 - val_accuracy: 0.7419\n",
      "Epoch 55/1000\n",
      "239/239 [==============================] - 1s 2ms/step - loss: 0.6910 - accuracy: 0.7331 - val_loss: 0.6638 - val_accuracy: 0.7457\n",
      "Epoch 56/1000\n",
      "239/239 [==============================] - 0s 2ms/step - loss: 0.6919 - accuracy: 0.7335 - val_loss: 0.6623 - val_accuracy: 0.7437\n",
      "Epoch 57/1000\n",
      "239/239 [==============================] - 0s 2ms/step - loss: 0.6941 - accuracy: 0.7329 - val_loss: 0.6644 - val_accuracy: 0.7436\n",
      "Epoch 58/1000\n",
      "239/239 [==============================] - 0s 2ms/step - loss: 0.6905 - accuracy: 0.7344 - val_loss: 0.6637 - val_accuracy: 0.7455\n",
      "Epoch 59/1000\n",
      "239/239 [==============================] - 0s 2ms/step - loss: 0.6917 - accuracy: 0.7343 - val_loss: 0.6621 - val_accuracy: 0.7444\n",
      "Epoch 60/1000\n",
      "239/239 [==============================] - 0s 2ms/step - loss: 0.6910 - accuracy: 0.7333 - val_loss: 0.6629 - val_accuracy: 0.7438\n",
      "Epoch 61/1000\n",
      "239/239 [==============================] - 0s 2ms/step - loss: 0.6918 - accuracy: 0.7340 - val_loss: 0.6641 - val_accuracy: 0.7436\n",
      "Epoch 62/1000\n",
      "239/239 [==============================] - 0s 2ms/step - loss: 0.6913 - accuracy: 0.7335 - val_loss: 0.6635 - val_accuracy: 0.7428\n",
      "Epoch 63/1000\n",
      "239/239 [==============================] - 0s 2ms/step - loss: 0.6912 - accuracy: 0.7324 - val_loss: 0.6642 - val_accuracy: 0.7429\n",
      "Epoch 64/1000\n",
      "239/239 [==============================] - 0s 2ms/step - loss: 0.6907 - accuracy: 0.7336 - val_loss: 0.6642 - val_accuracy: 0.7450\n",
      "Epoch 65/1000\n",
      "239/239 [==============================] - 0s 2ms/step - loss: 0.6907 - accuracy: 0.7346 - val_loss: 0.6682 - val_accuracy: 0.7443\n",
      "Epoch 66/1000\n",
      "239/239 [==============================] - 0s 2ms/step - loss: 0.6911 - accuracy: 0.7336 - val_loss: 0.6611 - val_accuracy: 0.7438\n",
      "Epoch 67/1000\n",
      "239/239 [==============================] - 0s 2ms/step - loss: 0.6915 - accuracy: 0.7328 - val_loss: 0.6636 - val_accuracy: 0.7426\n",
      "Epoch 68/1000\n",
      "239/239 [==============================] - 0s 2ms/step - loss: 0.6913 - accuracy: 0.7334 - val_loss: 0.6629 - val_accuracy: 0.7440\n",
      "Epoch 69/1000\n",
      "239/239 [==============================] - 1s 2ms/step - loss: 0.6904 - accuracy: 0.7339 - val_loss: 0.6670 - val_accuracy: 0.7436\n",
      "Epoch 70/1000\n",
      "239/239 [==============================] - 0s 2ms/step - loss: 0.6910 - accuracy: 0.7337 - val_loss: 0.6634 - val_accuracy: 0.7434\n",
      "Epoch 71/1000\n",
      "239/239 [==============================] - 0s 2ms/step - loss: 0.6905 - accuracy: 0.7340 - val_loss: 0.6637 - val_accuracy: 0.7441\n",
      "Epoch 72/1000\n",
      "239/239 [==============================] - 0s 2ms/step - loss: 0.6909 - accuracy: 0.7335 - val_loss: 0.6633 - val_accuracy: 0.7435\n",
      "Epoch 73/1000\n",
      "239/239 [==============================] - 0s 2ms/step - loss: 0.6904 - accuracy: 0.7332 - val_loss: 0.6637 - val_accuracy: 0.7443\n",
      "Epoch 74/1000\n",
      "239/239 [==============================] - 0s 2ms/step - loss: 0.6902 - accuracy: 0.7344 - val_loss: 0.6626 - val_accuracy: 0.7435\n",
      "Epoch 75/1000\n",
      "239/239 [==============================] - 0s 2ms/step - loss: 0.6907 - accuracy: 0.7349 - val_loss: 0.6638 - val_accuracy: 0.7426\n",
      "Epoch 76/1000\n",
      "239/239 [==============================] - 1s 2ms/step - loss: 0.6892 - accuracy: 0.7335 - val_loss: 0.6646 - val_accuracy: 0.7420\n",
      "Epoch 77/1000\n",
      "239/239 [==============================] - 0s 2ms/step - loss: 0.6901 - accuracy: 0.7337 - val_loss: 0.6628 - val_accuracy: 0.7430\n",
      "Epoch 78/1000\n",
      "239/239 [==============================] - 0s 2ms/step - loss: 0.6888 - accuracy: 0.7345 - val_loss: 0.6642 - val_accuracy: 0.7410\n",
      "Epoch 79/1000\n",
      "239/239 [==============================] - 0s 2ms/step - loss: 0.6889 - accuracy: 0.7339 - val_loss: 0.6658 - val_accuracy: 0.7403\n",
      "Epoch 80/1000\n",
      "239/239 [==============================] - 0s 2ms/step - loss: 0.6897 - accuracy: 0.7334 - val_loss: 0.6611 - val_accuracy: 0.7407\n",
      "Epoch 81/1000\n",
      "239/239 [==============================] - 0s 2ms/step - loss: 0.6899 - accuracy: 0.7331 - val_loss: 0.6630 - val_accuracy: 0.7429\n",
      "Epoch 82/1000\n",
      "239/239 [==============================] - 0s 2ms/step - loss: 0.6903 - accuracy: 0.7333 - val_loss: 0.6611 - val_accuracy: 0.7446\n",
      "Epoch 83/1000\n",
      "239/239 [==============================] - 0s 2ms/step - loss: 0.6905 - accuracy: 0.7337 - val_loss: 0.6609 - val_accuracy: 0.7422\n",
      "Epoch 84/1000\n",
      "239/239 [==============================] - 0s 2ms/step - loss: 0.6908 - accuracy: 0.7348 - val_loss: 0.6610 - val_accuracy: 0.7420\n",
      "Epoch 85/1000\n",
      "239/239 [==============================] - 0s 2ms/step - loss: 0.6898 - accuracy: 0.7346 - val_loss: 0.6622 - val_accuracy: 0.7455\n",
      "Epoch 86/1000\n",
      "239/239 [==============================] - 0s 2ms/step - loss: 0.6901 - accuracy: 0.7333 - val_loss: 0.6609 - val_accuracy: 0.7409\n",
      "Epoch 87/1000\n",
      "239/239 [==============================] - 0s 2ms/step - loss: 0.6897 - accuracy: 0.7342 - val_loss: 0.6626 - val_accuracy: 0.7424\n",
      "Epoch 88/1000\n",
      "239/239 [==============================] - 0s 2ms/step - loss: 0.6908 - accuracy: 0.7346 - val_loss: 0.6589 - val_accuracy: 0.7446\n",
      "Epoch 89/1000\n",
      "239/239 [==============================] - 0s 2ms/step - loss: 0.6889 - accuracy: 0.7342 - val_loss: 0.6624 - val_accuracy: 0.7415\n",
      "Epoch 90/1000\n",
      "239/239 [==============================] - 0s 2ms/step - loss: 0.6907 - accuracy: 0.7346 - val_loss: 0.6660 - val_accuracy: 0.7414\n",
      "Epoch 91/1000\n",
      "239/239 [==============================] - 0s 2ms/step - loss: 0.6902 - accuracy: 0.7345 - val_loss: 0.6592 - val_accuracy: 0.7440\n",
      "Epoch 92/1000\n",
      "239/239 [==============================] - 0s 2ms/step - loss: 0.6889 - accuracy: 0.7341 - val_loss: 0.6629 - val_accuracy: 0.7429\n",
      "Epoch 93/1000\n",
      "239/239 [==============================] - 0s 2ms/step - loss: 0.6896 - accuracy: 0.7339 - val_loss: 0.6655 - val_accuracy: 0.7426\n",
      "Epoch 94/1000\n",
      "239/239 [==============================] - 0s 2ms/step - loss: 0.6910 - accuracy: 0.7335 - val_loss: 0.6627 - val_accuracy: 0.7420\n",
      "Epoch 95/1000\n",
      "239/239 [==============================] - 0s 2ms/step - loss: 0.6896 - accuracy: 0.7343 - val_loss: 0.6643 - val_accuracy: 0.7412\n",
      "Epoch 96/1000\n",
      "239/239 [==============================] - 1s 2ms/step - loss: 0.6899 - accuracy: 0.7338 - val_loss: 0.6610 - val_accuracy: 0.7406\n",
      "Epoch 97/1000\n",
      "239/239 [==============================] - 0s 2ms/step - loss: 0.6887 - accuracy: 0.7339 - val_loss: 0.6622 - val_accuracy: 0.7392\n",
      "Epoch 98/1000\n",
      "239/239 [==============================] - 0s 2ms/step - loss: 0.6896 - accuracy: 0.7344 - val_loss: 0.6612 - val_accuracy: 0.7411\n",
      "Epoch 99/1000\n",
      "239/239 [==============================] - 0s 2ms/step - loss: 0.6889 - accuracy: 0.7343 - val_loss: 0.6646 - val_accuracy: 0.7408\n",
      "Epoch 100/1000\n",
      "239/239 [==============================] - 0s 2ms/step - loss: 0.6894 - accuracy: 0.7344 - val_loss: 0.6609 - val_accuracy: 0.7437\n",
      "Epoch 101/1000\n",
      "239/239 [==============================] - 0s 2ms/step - loss: 0.6889 - accuracy: 0.7341 - val_loss: 0.6601 - val_accuracy: 0.7455\n",
      "Epoch 102/1000\n",
      "239/239 [==============================] - 0s 2ms/step - loss: 0.6896 - accuracy: 0.7346 - val_loss: 0.6611 - val_accuracy: 0.7415\n",
      "Epoch 103/1000\n",
      "239/239 [==============================] - 0s 2ms/step - loss: 0.6891 - accuracy: 0.7348 - val_loss: 0.6619 - val_accuracy: 0.7418\n",
      "Epoch 104/1000\n",
      "239/239 [==============================] - 0s 2ms/step - loss: 0.6896 - accuracy: 0.7348 - val_loss: 0.6618 - val_accuracy: 0.7402\n",
      "Epoch 105/1000\n",
      "239/239 [==============================] - 0s 2ms/step - loss: 0.6896 - accuracy: 0.7346 - val_loss: 0.6599 - val_accuracy: 0.7423\n",
      "Epoch 106/1000\n",
      "239/239 [==============================] - 0s 2ms/step - loss: 0.6897 - accuracy: 0.7347 - val_loss: 0.6641 - val_accuracy: 0.7406\n",
      "Epoch 107/1000\n",
      "239/239 [==============================] - 0s 2ms/step - loss: 0.6911 - accuracy: 0.7338 - val_loss: 0.6599 - val_accuracy: 0.7433\n",
      "Epoch 108/1000\n",
      "239/239 [==============================] - 0s 2ms/step - loss: 0.6902 - accuracy: 0.7348 - val_loss: 0.6617 - val_accuracy: 0.7414\n",
      "Epoch 109/1000\n",
      "239/239 [==============================] - 0s 2ms/step - loss: 0.6893 - accuracy: 0.7351 - val_loss: 0.6648 - val_accuracy: 0.7403\n",
      "Epoch 110/1000\n",
      "239/239 [==============================] - 0s 2ms/step - loss: 0.6898 - accuracy: 0.7340 - val_loss: 0.6638 - val_accuracy: 0.7387\n",
      "Epoch 111/1000\n",
      "239/239 [==============================] - 0s 2ms/step - loss: 0.6888 - accuracy: 0.7349 - val_loss: 0.6642 - val_accuracy: 0.7420\n",
      "Epoch 112/1000\n",
      "239/239 [==============================] - 0s 2ms/step - loss: 0.6883 - accuracy: 0.7351 - val_loss: 0.6624 - val_accuracy: 0.7399\n",
      "Epoch 113/1000\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "239/239 [==============================] - 0s 2ms/step - loss: 0.6896 - accuracy: 0.7342 - val_loss: 0.6606 - val_accuracy: 0.7427\n",
      "Epoch 114/1000\n",
      "239/239 [==============================] - 0s 2ms/step - loss: 0.6885 - accuracy: 0.7346 - val_loss: 0.6612 - val_accuracy: 0.7415\n",
      "Epoch 115/1000\n",
      "239/239 [==============================] - 0s 2ms/step - loss: 0.6896 - accuracy: 0.7337 - val_loss: 0.6618 - val_accuracy: 0.7420\n",
      "Epoch 116/1000\n",
      "239/239 [==============================] - 0s 2ms/step - loss: 0.6888 - accuracy: 0.7349 - val_loss: 0.6618 - val_accuracy: 0.7415\n",
      "Epoch 117/1000\n",
      "239/239 [==============================] - 0s 2ms/step - loss: 0.6892 - accuracy: 0.7351 - val_loss: 0.6598 - val_accuracy: 0.7424\n",
      "Epoch 118/1000\n",
      "239/239 [==============================] - 0s 2ms/step - loss: 0.6890 - accuracy: 0.7346 - val_loss: 0.6633 - val_accuracy: 0.7368\n",
      "Epoch 119/1000\n",
      "239/239 [==============================] - 0s 2ms/step - loss: 0.6899 - accuracy: 0.7337 - val_loss: 0.6623 - val_accuracy: 0.7412\n",
      "Epoch 120/1000\n",
      "239/239 [==============================] - 0s 2ms/step - loss: 0.6892 - accuracy: 0.7342 - val_loss: 0.6612 - val_accuracy: 0.7390\n",
      "Epoch 121/1000\n",
      "239/239 [==============================] - 0s 2ms/step - loss: 0.6895 - accuracy: 0.7347 - val_loss: 0.6630 - val_accuracy: 0.7373\n",
      "Epoch 122/1000\n",
      "239/239 [==============================] - 0s 2ms/step - loss: 0.6897 - accuracy: 0.7345 - val_loss: 0.6625 - val_accuracy: 0.7380\n",
      "Epoch 123/1000\n",
      "239/239 [==============================] - 0s 2ms/step - loss: 0.6893 - accuracy: 0.7351 - val_loss: 0.6615 - val_accuracy: 0.7411\n",
      "Epoch 124/1000\n",
      "239/239 [==============================] - 0s 2ms/step - loss: 0.6906 - accuracy: 0.7344 - val_loss: 0.6629 - val_accuracy: 0.7390\n",
      "Epoch 125/1000\n",
      "239/239 [==============================] - 0s 2ms/step - loss: 0.6891 - accuracy: 0.7349 - val_loss: 0.6666 - val_accuracy: 0.7356\n",
      "Epoch 126/1000\n",
      "239/239 [==============================] - 0s 2ms/step - loss: 0.6900 - accuracy: 0.7343 - val_loss: 0.6624 - val_accuracy: 0.7390\n",
      "Epoch 127/1000\n",
      "239/239 [==============================] - 0s 2ms/step - loss: 0.6892 - accuracy: 0.7343 - val_loss: 0.6636 - val_accuracy: 0.7366\n",
      "Epoch 128/1000\n",
      "239/239 [==============================] - 0s 2ms/step - loss: 0.6899 - accuracy: 0.7350 - val_loss: 0.6640 - val_accuracy: 0.7362\n",
      "Epoch 129/1000\n",
      "239/239 [==============================] - 0s 2ms/step - loss: 0.6899 - accuracy: 0.7350 - val_loss: 0.6617 - val_accuracy: 0.7436\n",
      "Epoch 130/1000\n",
      "239/239 [==============================] - 0s 2ms/step - loss: 0.6880 - accuracy: 0.7348 - val_loss: 0.6631 - val_accuracy: 0.7365\n",
      "Epoch 131/1000\n",
      "239/239 [==============================] - 0s 2ms/step - loss: 0.6895 - accuracy: 0.7343 - val_loss: 0.6623 - val_accuracy: 0.7398\n",
      "Epoch 132/1000\n",
      "239/239 [==============================] - 0s 2ms/step - loss: 0.6896 - accuracy: 0.7345 - val_loss: 0.6620 - val_accuracy: 0.7378\n",
      "Epoch 133/1000\n",
      "239/239 [==============================] - 0s 2ms/step - loss: 0.6893 - accuracy: 0.7347 - val_loss: 0.6628 - val_accuracy: 0.7380\n",
      "Epoch 134/1000\n",
      "239/239 [==============================] - 0s 2ms/step - loss: 0.6907 - accuracy: 0.7339 - val_loss: 0.6649 - val_accuracy: 0.7350\n",
      "Epoch 135/1000\n",
      "239/239 [==============================] - 0s 2ms/step - loss: 0.6878 - accuracy: 0.7350 - val_loss: 0.6638 - val_accuracy: 0.7365\n",
      "Epoch 136/1000\n",
      "239/239 [==============================] - 0s 2ms/step - loss: 0.6897 - accuracy: 0.7342 - val_loss: 0.6627 - val_accuracy: 0.7376\n",
      "Epoch 137/1000\n",
      "239/239 [==============================] - 0s 2ms/step - loss: 0.6898 - accuracy: 0.7343 - val_loss: 0.6613 - val_accuracy: 0.7368\n",
      "Epoch 138/1000\n",
      "239/239 [==============================] - 1s 2ms/step - loss: 0.6889 - accuracy: 0.7346 - val_loss: 0.6607 - val_accuracy: 0.7362\n",
      "Epoch 138: early stopping\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "<keras.src.callbacks.History at 0x17c8c97b0>"
      ]
     },
     "execution_count": 82,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# optimizer='rmsprop'\n",
    "model.compile(loss='categorical_crossentropy', optimizer='rmsprop', metrics=['accuracy'])\n",
    "\n",
    "es=EarlyStopping(monitor=\"val_loss\",patience=50,mode=\"auto\",verbose=1)\n",
    "\n",
    "model.fit(X_train,\n",
    "          y_train,\n",
    "          epochs=1000,\n",
    "               batch_size=512,\n",
    "               validation_split=0.1,\n",
    "               verbose=1,callbacks=[es])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 83,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "748/748 [==============================] - 0s 256us/step\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0       0.70      0.88      0.78      7973\n",
      "           1       0.74      0.78      0.76      7973\n",
      "           2       0.77      0.54      0.63      7972\n",
      "\n",
      "    accuracy                           0.73     23918\n",
      "   macro avg       0.74      0.73      0.72     23918\n",
      "weighted avg       0.74      0.73      0.72     23918\n",
      "\n"
     ]
    }
   ],
   "source": [
    "y_pred = model.predict(X_test)\n",
    "y_pred_classes = np.argmax(y_pred, axis=1)\n",
    "y_true = np.argmax(y_test, axis=1)\n",
    "print(classification_report(y_true, y_pred_classes))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 84,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "4236/4236 [==============================] - 1s 266us/step\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0       0.71      0.88      0.78     45176\n",
      "           1       0.74      0.77      0.76     45176\n",
      "           2       0.77      0.55      0.65     45177\n",
      "\n",
      "    accuracy                           0.74    135529\n",
      "   macro avg       0.74      0.74      0.73    135529\n",
      "weighted avg       0.74      0.74      0.73    135529\n",
      "\n"
     ]
    }
   ],
   "source": [
    "y_t_pred = model.predict(X_train)\n",
    "y_t_pred_classes = np.argmax(y_t_pred, axis=1)\n",
    "y_t_true = np.argmax(y_train, axis=1)\n",
    "print(classification_report(y_t_true, y_t_pred_classes))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 85,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 1/1000\n",
      "239/239 [==============================] - 1s 2ms/step - loss: 0.8494 - accuracy: 0.6440 - val_loss: 0.7213 - val_accuracy: 0.7243\n",
      "Epoch 2/1000\n",
      "239/239 [==============================] - 1s 3ms/step - loss: 0.7677 - accuracy: 0.7062 - val_loss: 0.6979 - val_accuracy: 0.7244\n",
      "Epoch 3/1000\n",
      "239/239 [==============================] - 1s 2ms/step - loss: 0.7454 - accuracy: 0.7144 - val_loss: 0.6903 - val_accuracy: 0.7266\n",
      "Epoch 4/1000\n",
      "239/239 [==============================] - 0s 2ms/step - loss: 0.7355 - accuracy: 0.7170 - val_loss: 0.6874 - val_accuracy: 0.7278\n",
      "Epoch 5/1000\n",
      "239/239 [==============================] - 0s 2ms/step - loss: 0.7303 - accuracy: 0.7195 - val_loss: 0.6842 - val_accuracy: 0.7339\n",
      "Epoch 6/1000\n",
      "239/239 [==============================] - 1s 2ms/step - loss: 0.7262 - accuracy: 0.7215 - val_loss: 0.6789 - val_accuracy: 0.7356\n",
      "Epoch 7/1000\n",
      "239/239 [==============================] - 1s 2ms/step - loss: 0.7202 - accuracy: 0.7237 - val_loss: 0.6792 - val_accuracy: 0.7377\n",
      "Epoch 8/1000\n",
      "239/239 [==============================] - 0s 2ms/step - loss: 0.7176 - accuracy: 0.7241 - val_loss: 0.6757 - val_accuracy: 0.7392\n",
      "Epoch 9/1000\n",
      "239/239 [==============================] - 1s 2ms/step - loss: 0.7152 - accuracy: 0.7260 - val_loss: 0.6758 - val_accuracy: 0.7383\n",
      "Epoch 10/1000\n",
      "239/239 [==============================] - 1s 2ms/step - loss: 0.7126 - accuracy: 0.7278 - val_loss: 0.6721 - val_accuracy: 0.7392\n",
      "Epoch 11/1000\n",
      "239/239 [==============================] - 1s 3ms/step - loss: 0.7116 - accuracy: 0.7281 - val_loss: 0.6725 - val_accuracy: 0.7387\n",
      "Epoch 12/1000\n",
      "239/239 [==============================] - 1s 2ms/step - loss: 0.7092 - accuracy: 0.7292 - val_loss: 0.6695 - val_accuracy: 0.7397\n",
      "Epoch 13/1000\n",
      "239/239 [==============================] - 1s 2ms/step - loss: 0.7094 - accuracy: 0.7284 - val_loss: 0.6707 - val_accuracy: 0.7406\n",
      "Epoch 14/1000\n",
      "239/239 [==============================] - 1s 2ms/step - loss: 0.7074 - accuracy: 0.7283 - val_loss: 0.6687 - val_accuracy: 0.7407\n",
      "Epoch 15/1000\n",
      "239/239 [==============================] - 0s 2ms/step - loss: 0.7060 - accuracy: 0.7295 - val_loss: 0.6692 - val_accuracy: 0.7404\n",
      "Epoch 16/1000\n",
      "239/239 [==============================] - 1s 2ms/step - loss: 0.7051 - accuracy: 0.7297 - val_loss: 0.6671 - val_accuracy: 0.7415\n",
      "Epoch 17/1000\n",
      "239/239 [==============================] - 1s 2ms/step - loss: 0.7030 - accuracy: 0.7318 - val_loss: 0.6666 - val_accuracy: 0.7411\n",
      "Epoch 18/1000\n",
      "239/239 [==============================] - 1s 2ms/step - loss: 0.7036 - accuracy: 0.7309 - val_loss: 0.6658 - val_accuracy: 0.7419\n",
      "Epoch 19/1000\n",
      "239/239 [==============================] - 0s 2ms/step - loss: 0.7044 - accuracy: 0.7307 - val_loss: 0.6662 - val_accuracy: 0.7411\n",
      "Epoch 20/1000\n",
      "239/239 [==============================] - 1s 2ms/step - loss: 0.7028 - accuracy: 0.7308 - val_loss: 0.6655 - val_accuracy: 0.7422\n",
      "Epoch 21/1000\n",
      "239/239 [==============================] - 0s 2ms/step - loss: 0.7009 - accuracy: 0.7318 - val_loss: 0.6642 - val_accuracy: 0.7439\n",
      "Epoch 22/1000\n",
      "239/239 [==============================] - 0s 2ms/step - loss: 0.7004 - accuracy: 0.7307 - val_loss: 0.6634 - val_accuracy: 0.7435\n",
      "Epoch 23/1000\n",
      "239/239 [==============================] - 0s 2ms/step - loss: 0.7001 - accuracy: 0.7316 - val_loss: 0.6666 - val_accuracy: 0.7420\n",
      "Epoch 24/1000\n",
      "239/239 [==============================] - 0s 2ms/step - loss: 0.6991 - accuracy: 0.7300 - val_loss: 0.6636 - val_accuracy: 0.7431\n",
      "Epoch 25/1000\n",
      "239/239 [==============================] - 1s 2ms/step - loss: 0.6992 - accuracy: 0.7309 - val_loss: 0.6624 - val_accuracy: 0.7432\n",
      "Epoch 26/1000\n",
      "239/239 [==============================] - 1s 2ms/step - loss: 0.6976 - accuracy: 0.7315 - val_loss: 0.6638 - val_accuracy: 0.7409\n",
      "Epoch 27/1000\n",
      "239/239 [==============================] - 0s 2ms/step - loss: 0.6976 - accuracy: 0.7313 - val_loss: 0.6630 - val_accuracy: 0.7432\n",
      "Epoch 28/1000\n",
      "239/239 [==============================] - 0s 2ms/step - loss: 0.6969 - accuracy: 0.7315 - val_loss: 0.6620 - val_accuracy: 0.7423\n",
      "Epoch 29/1000\n",
      "239/239 [==============================] - 0s 2ms/step - loss: 0.6968 - accuracy: 0.7307 - val_loss: 0.6637 - val_accuracy: 0.7413\n",
      "Epoch 30/1000\n",
      "239/239 [==============================] - 0s 2ms/step - loss: 0.6959 - accuracy: 0.7323 - val_loss: 0.6607 - val_accuracy: 0.7440\n",
      "Epoch 31/1000\n",
      "239/239 [==============================] - 0s 2ms/step - loss: 0.6955 - accuracy: 0.7312 - val_loss: 0.6613 - val_accuracy: 0.7423\n",
      "Epoch 32/1000\n",
      "239/239 [==============================] - 0s 2ms/step - loss: 0.6949 - accuracy: 0.7327 - val_loss: 0.6613 - val_accuracy: 0.7429\n",
      "Epoch 33/1000\n",
      "239/239 [==============================] - 0s 2ms/step - loss: 0.6956 - accuracy: 0.7306 - val_loss: 0.6618 - val_accuracy: 0.7423\n",
      "Epoch 34/1000\n",
      "239/239 [==============================] - 0s 2ms/step - loss: 0.6960 - accuracy: 0.7311 - val_loss: 0.6597 - val_accuracy: 0.7422\n",
      "Epoch 35/1000\n",
      "239/239 [==============================] - 1s 2ms/step - loss: 0.6945 - accuracy: 0.7323 - val_loss: 0.6604 - val_accuracy: 0.7421\n",
      "Epoch 36/1000\n",
      "239/239 [==============================] - 1s 2ms/step - loss: 0.6938 - accuracy: 0.7325 - val_loss: 0.6634 - val_accuracy: 0.7426\n",
      "Epoch 37/1000\n",
      "239/239 [==============================] - 1s 2ms/step - loss: 0.6950 - accuracy: 0.7314 - val_loss: 0.6596 - val_accuracy: 0.7428\n",
      "Epoch 38/1000\n",
      "239/239 [==============================] - 1s 2ms/step - loss: 0.6928 - accuracy: 0.7325 - val_loss: 0.6599 - val_accuracy: 0.7428\n",
      "Epoch 39/1000\n",
      "239/239 [==============================] - 1s 2ms/step - loss: 0.6930 - accuracy: 0.7333 - val_loss: 0.6590 - val_accuracy: 0.7437\n",
      "Epoch 40/1000\n",
      "239/239 [==============================] - 1s 2ms/step - loss: 0.6923 - accuracy: 0.7325 - val_loss: 0.6593 - val_accuracy: 0.7431\n",
      "Epoch 41/1000\n",
      "239/239 [==============================] - 1s 2ms/step - loss: 0.6928 - accuracy: 0.7324 - val_loss: 0.6576 - val_accuracy: 0.7439\n",
      "Epoch 42/1000\n",
      "239/239 [==============================] - 0s 2ms/step - loss: 0.6934 - accuracy: 0.7323 - val_loss: 0.6585 - val_accuracy: 0.7439\n",
      "Epoch 43/1000\n",
      "239/239 [==============================] - 1s 2ms/step - loss: 0.6928 - accuracy: 0.7320 - val_loss: 0.6601 - val_accuracy: 0.7431\n",
      "Epoch 44/1000\n",
      "239/239 [==============================] - 1s 2ms/step - loss: 0.6910 - accuracy: 0.7332 - val_loss: 0.6586 - val_accuracy: 0.7434\n",
      "Epoch 45/1000\n",
      "239/239 [==============================] - 1s 2ms/step - loss: 0.6918 - accuracy: 0.7331 - val_loss: 0.6593 - val_accuracy: 0.7437\n",
      "Epoch 46/1000\n",
      "239/239 [==============================] - 0s 2ms/step - loss: 0.6925 - accuracy: 0.7330 - val_loss: 0.6604 - val_accuracy: 0.7432\n",
      "Epoch 47/1000\n",
      "239/239 [==============================] - 0s 2ms/step - loss: 0.6914 - accuracy: 0.7343 - val_loss: 0.6599 - val_accuracy: 0.7418\n",
      "Epoch 48/1000\n",
      "239/239 [==============================] - 0s 2ms/step - loss: 0.6907 - accuracy: 0.7336 - val_loss: 0.6580 - val_accuracy: 0.7438\n",
      "Epoch 49/1000\n",
      "239/239 [==============================] - 1s 2ms/step - loss: 0.6919 - accuracy: 0.7330 - val_loss: 0.6571 - val_accuracy: 0.7451\n",
      "Epoch 50/1000\n",
      "239/239 [==============================] - 1s 2ms/step - loss: 0.6909 - accuracy: 0.7334 - val_loss: 0.6600 - val_accuracy: 0.7435\n",
      "Epoch 51/1000\n",
      "239/239 [==============================] - 1s 2ms/step - loss: 0.6896 - accuracy: 0.7342 - val_loss: 0.6574 - val_accuracy: 0.7435\n",
      "Epoch 52/1000\n",
      "239/239 [==============================] - 1s 2ms/step - loss: 0.6909 - accuracy: 0.7329 - val_loss: 0.6592 - val_accuracy: 0.7430\n",
      "Epoch 53/1000\n",
      "239/239 [==============================] - 1s 2ms/step - loss: 0.6899 - accuracy: 0.7336 - val_loss: 0.6574 - val_accuracy: 0.7439\n",
      "Epoch 54/1000\n",
      "239/239 [==============================] - 1s 2ms/step - loss: 0.6901 - accuracy: 0.7338 - val_loss: 0.6584 - val_accuracy: 0.7436\n",
      "Epoch 55/1000\n",
      "239/239 [==============================] - 1s 2ms/step - loss: 0.6897 - accuracy: 0.7335 - val_loss: 0.6579 - val_accuracy: 0.7451\n",
      "Epoch 56/1000\n",
      "239/239 [==============================] - 0s 2ms/step - loss: 0.6897 - accuracy: 0.7337 - val_loss: 0.6599 - val_accuracy: 0.7433\n",
      "Epoch 57/1000\n",
      "239/239 [==============================] - 0s 2ms/step - loss: 0.6898 - accuracy: 0.7343 - val_loss: 0.6571 - val_accuracy: 0.7436\n",
      "Epoch 58/1000\n",
      "239/239 [==============================] - 1s 2ms/step - loss: 0.6879 - accuracy: 0.7341 - val_loss: 0.6561 - val_accuracy: 0.7442\n",
      "Epoch 59/1000\n",
      "239/239 [==============================] - 1s 2ms/step - loss: 0.6899 - accuracy: 0.7340 - val_loss: 0.6573 - val_accuracy: 0.7447\n",
      "Epoch 60/1000\n",
      "239/239 [==============================] - 0s 2ms/step - loss: 0.6894 - accuracy: 0.7340 - val_loss: 0.6580 - val_accuracy: 0.7435\n",
      "Epoch 61/1000\n",
      "239/239 [==============================] - 0s 2ms/step - loss: 0.6890 - accuracy: 0.7339 - val_loss: 0.6557 - val_accuracy: 0.7443\n",
      "Epoch 62/1000\n",
      "239/239 [==============================] - 1s 2ms/step - loss: 0.6883 - accuracy: 0.7342 - val_loss: 0.6550 - val_accuracy: 0.7436\n",
      "Epoch 63/1000\n",
      "239/239 [==============================] - 1s 2ms/step - loss: 0.6888 - accuracy: 0.7345 - val_loss: 0.6589 - val_accuracy: 0.7434\n",
      "Epoch 64/1000\n",
      "239/239 [==============================] - 1s 2ms/step - loss: 0.6897 - accuracy: 0.7340 - val_loss: 0.6581 - val_accuracy: 0.7456\n",
      "Epoch 65/1000\n",
      "239/239 [==============================] - 1s 2ms/step - loss: 0.6894 - accuracy: 0.7335 - val_loss: 0.6565 - val_accuracy: 0.7434\n",
      "Epoch 66/1000\n",
      "239/239 [==============================] - 0s 2ms/step - loss: 0.6868 - accuracy: 0.7348 - val_loss: 0.6570 - val_accuracy: 0.7449\n",
      "Epoch 67/1000\n",
      "239/239 [==============================] - 0s 2ms/step - loss: 0.6899 - accuracy: 0.7338 - val_loss: 0.6573 - val_accuracy: 0.7439\n",
      "Epoch 68/1000\n",
      "239/239 [==============================] - 0s 2ms/step - loss: 0.6883 - accuracy: 0.7343 - val_loss: 0.6590 - val_accuracy: 0.7423\n",
      "Epoch 69/1000\n",
      "239/239 [==============================] - 0s 2ms/step - loss: 0.6879 - accuracy: 0.7343 - val_loss: 0.6575 - val_accuracy: 0.7450\n",
      "Epoch 70/1000\n",
      "239/239 [==============================] - 1s 2ms/step - loss: 0.6875 - accuracy: 0.7351 - val_loss: 0.6565 - val_accuracy: 0.7439\n",
      "Epoch 71/1000\n",
      "239/239 [==============================] - 1s 2ms/step - loss: 0.6869 - accuracy: 0.7347 - val_loss: 0.6582 - val_accuracy: 0.7422\n",
      "Epoch 72/1000\n",
      "239/239 [==============================] - 1s 2ms/step - loss: 0.6882 - accuracy: 0.7348 - val_loss: 0.6570 - val_accuracy: 0.7456\n",
      "Epoch 73/1000\n",
      "239/239 [==============================] - 1s 2ms/step - loss: 0.6882 - accuracy: 0.7338 - val_loss: 0.6578 - val_accuracy: 0.7440\n",
      "Epoch 74/1000\n",
      "239/239 [==============================] - 1s 2ms/step - loss: 0.6881 - accuracy: 0.7346 - val_loss: 0.6581 - val_accuracy: 0.7440\n",
      "Epoch 75/1000\n",
      "239/239 [==============================] - 1s 2ms/step - loss: 0.6892 - accuracy: 0.7340 - val_loss: 0.6579 - val_accuracy: 0.7454\n",
      "Epoch 76/1000\n",
      "239/239 [==============================] - 1s 2ms/step - loss: 0.6866 - accuracy: 0.7342 - val_loss: 0.6571 - val_accuracy: 0.7449\n",
      "Epoch 77/1000\n",
      "239/239 [==============================] - 1s 2ms/step - loss: 0.6867 - accuracy: 0.7341 - val_loss: 0.6573 - val_accuracy: 0.7437\n",
      "Epoch 78/1000\n",
      "239/239 [==============================] - 1s 2ms/step - loss: 0.6876 - accuracy: 0.7343 - val_loss: 0.6556 - val_accuracy: 0.7450\n",
      "Epoch 79/1000\n",
      "239/239 [==============================] - 1s 2ms/step - loss: 0.6884 - accuracy: 0.7351 - val_loss: 0.6556 - val_accuracy: 0.7449\n",
      "Epoch 80/1000\n",
      "239/239 [==============================] - 0s 2ms/step - loss: 0.6873 - accuracy: 0.7344 - val_loss: 0.6568 - val_accuracy: 0.7437\n",
      "Epoch 81/1000\n",
      "239/239 [==============================] - 0s 2ms/step - loss: 0.6860 - accuracy: 0.7351 - val_loss: 0.6569 - val_accuracy: 0.7447\n",
      "Epoch 82/1000\n",
      "239/239 [==============================] - 0s 2ms/step - loss: 0.6864 - accuracy: 0.7346 - val_loss: 0.6571 - val_accuracy: 0.7439\n",
      "Epoch 83/1000\n",
      "239/239 [==============================] - 1s 2ms/step - loss: 0.6887 - accuracy: 0.7337 - val_loss: 0.6586 - val_accuracy: 0.7436\n",
      "Epoch 84/1000\n",
      "239/239 [==============================] - 1s 2ms/step - loss: 0.6860 - accuracy: 0.7347 - val_loss: 0.6561 - val_accuracy: 0.7433\n",
      "Epoch 85/1000\n",
      "239/239 [==============================] - 0s 2ms/step - loss: 0.6881 - accuracy: 0.7348 - val_loss: 0.6563 - val_accuracy: 0.7449\n",
      "Epoch 86/1000\n",
      "239/239 [==============================] - 0s 2ms/step - loss: 0.6865 - accuracy: 0.7355 - val_loss: 0.6568 - val_accuracy: 0.7446\n",
      "Epoch 87/1000\n",
      "239/239 [==============================] - 1s 2ms/step - loss: 0.6873 - accuracy: 0.7348 - val_loss: 0.6595 - val_accuracy: 0.7446\n",
      "Epoch 88/1000\n",
      "239/239 [==============================] - 1s 2ms/step - loss: 0.6874 - accuracy: 0.7351 - val_loss: 0.6586 - val_accuracy: 0.7443\n",
      "Epoch 89/1000\n",
      "239/239 [==============================] - 1s 2ms/step - loss: 0.6862 - accuracy: 0.7356 - val_loss: 0.6563 - val_accuracy: 0.7452\n",
      "Epoch 90/1000\n",
      "239/239 [==============================] - 1s 2ms/step - loss: 0.6867 - accuracy: 0.7348 - val_loss: 0.6579 - val_accuracy: 0.7429\n",
      "Epoch 91/1000\n",
      "239/239 [==============================] - 0s 2ms/step - loss: 0.6849 - accuracy: 0.7351 - val_loss: 0.6551 - val_accuracy: 0.7456\n",
      "Epoch 92/1000\n",
      "239/239 [==============================] - 0s 2ms/step - loss: 0.6866 - accuracy: 0.7348 - val_loss: 0.6608 - val_accuracy: 0.7437\n",
      "Epoch 93/1000\n",
      "239/239 [==============================] - 1s 2ms/step - loss: 0.6851 - accuracy: 0.7365 - val_loss: 0.6571 - val_accuracy: 0.7432\n",
      "Epoch 94/1000\n",
      "239/239 [==============================] - 0s 2ms/step - loss: 0.6860 - accuracy: 0.7352 - val_loss: 0.6552 - val_accuracy: 0.7456\n",
      "Epoch 95/1000\n",
      "239/239 [==============================] - 0s 2ms/step - loss: 0.6853 - accuracy: 0.7356 - val_loss: 0.6556 - val_accuracy: 0.7450\n",
      "Epoch 96/1000\n",
      "239/239 [==============================] - 0s 2ms/step - loss: 0.6869 - accuracy: 0.7355 - val_loss: 0.6576 - val_accuracy: 0.7454\n",
      "Epoch 97/1000\n",
      "239/239 [==============================] - 0s 2ms/step - loss: 0.6858 - accuracy: 0.7355 - val_loss: 0.6578 - val_accuracy: 0.7435\n",
      "Epoch 98/1000\n",
      "239/239 [==============================] - 0s 2ms/step - loss: 0.6861 - accuracy: 0.7348 - val_loss: 0.6539 - val_accuracy: 0.7457\n",
      "Epoch 99/1000\n",
      "239/239 [==============================] - 0s 2ms/step - loss: 0.6868 - accuracy: 0.7352 - val_loss: 0.6553 - val_accuracy: 0.7457\n",
      "Epoch 100/1000\n",
      "239/239 [==============================] - 0s 2ms/step - loss: 0.6846 - accuracy: 0.7360 - val_loss: 0.6535 - val_accuracy: 0.7453\n",
      "Epoch 101/1000\n",
      "239/239 [==============================] - 1s 2ms/step - loss: 0.6845 - accuracy: 0.7355 - val_loss: 0.6563 - val_accuracy: 0.7436\n",
      "Epoch 102/1000\n",
      "239/239 [==============================] - 1s 2ms/step - loss: 0.6861 - accuracy: 0.7353 - val_loss: 0.6556 - val_accuracy: 0.7435\n",
      "Epoch 103/1000\n",
      "239/239 [==============================] - 0s 2ms/step - loss: 0.6853 - accuracy: 0.7354 - val_loss: 0.6542 - val_accuracy: 0.7459\n",
      "Epoch 104/1000\n",
      "239/239 [==============================] - 0s 2ms/step - loss: 0.6848 - accuracy: 0.7352 - val_loss: 0.6535 - val_accuracy: 0.7456\n",
      "Epoch 105/1000\n",
      "239/239 [==============================] - 0s 2ms/step - loss: 0.6855 - accuracy: 0.7352 - val_loss: 0.6565 - val_accuracy: 0.7449\n",
      "Epoch 106/1000\n",
      "239/239 [==============================] - 0s 2ms/step - loss: 0.6853 - accuracy: 0.7355 - val_loss: 0.6554 - val_accuracy: 0.7452\n",
      "Epoch 107/1000\n",
      "239/239 [==============================] - 0s 2ms/step - loss: 0.6851 - accuracy: 0.7357 - val_loss: 0.6557 - val_accuracy: 0.7452\n",
      "Epoch 108/1000\n",
      "239/239 [==============================] - 1s 2ms/step - loss: 0.6847 - accuracy: 0.7350 - val_loss: 0.6547 - val_accuracy: 0.7449\n",
      "Epoch 109/1000\n",
      "239/239 [==============================] - 1s 2ms/step - loss: 0.6859 - accuracy: 0.7349 - val_loss: 0.6577 - val_accuracy: 0.7453\n",
      "Epoch 110/1000\n",
      "239/239 [==============================] - 1s 2ms/step - loss: 0.6851 - accuracy: 0.7353 - val_loss: 0.6543 - val_accuracy: 0.7452\n",
      "Epoch 111/1000\n",
      "239/239 [==============================] - 1s 2ms/step - loss: 0.6844 - accuracy: 0.7355 - val_loss: 0.6559 - val_accuracy: 0.7446\n",
      "Epoch 112/1000\n",
      "239/239 [==============================] - 1s 2ms/step - loss: 0.6842 - accuracy: 0.7355 - val_loss: 0.6558 - val_accuracy: 0.7456\n",
      "Epoch 113/1000\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "239/239 [==============================] - 1s 3ms/step - loss: 0.6846 - accuracy: 0.7351 - val_loss: 0.6554 - val_accuracy: 0.7437\n",
      "Epoch 114/1000\n",
      "239/239 [==============================] - 0s 2ms/step - loss: 0.6859 - accuracy: 0.7358 - val_loss: 0.6585 - val_accuracy: 0.7434\n",
      "Epoch 115/1000\n",
      "239/239 [==============================] - 0s 2ms/step - loss: 0.6851 - accuracy: 0.7353 - val_loss: 0.6560 - val_accuracy: 0.7445\n",
      "Epoch 116/1000\n",
      "239/239 [==============================] - 1s 2ms/step - loss: 0.6849 - accuracy: 0.7356 - val_loss: 0.6575 - val_accuracy: 0.7459\n",
      "Epoch 117/1000\n",
      "239/239 [==============================] - 1s 2ms/step - loss: 0.6842 - accuracy: 0.7357 - val_loss: 0.6563 - val_accuracy: 0.7454\n",
      "Epoch 118/1000\n",
      "239/239 [==============================] - 1s 2ms/step - loss: 0.6854 - accuracy: 0.7356 - val_loss: 0.6536 - val_accuracy: 0.7449\n",
      "Epoch 119/1000\n",
      "239/239 [==============================] - 1s 2ms/step - loss: 0.6849 - accuracy: 0.7362 - val_loss: 0.6566 - val_accuracy: 0.7442\n",
      "Epoch 120/1000\n",
      "239/239 [==============================] - 1s 3ms/step - loss: 0.6829 - accuracy: 0.7360 - val_loss: 0.6545 - val_accuracy: 0.7453\n",
      "Epoch 121/1000\n",
      "239/239 [==============================] - 1s 2ms/step - loss: 0.6837 - accuracy: 0.7356 - val_loss: 0.6549 - val_accuracy: 0.7442\n",
      "Epoch 122/1000\n",
      "239/239 [==============================] - 1s 2ms/step - loss: 0.6855 - accuracy: 0.7349 - val_loss: 0.6559 - val_accuracy: 0.7443\n",
      "Epoch 123/1000\n",
      "239/239 [==============================] - 0s 2ms/step - loss: 0.6853 - accuracy: 0.7356 - val_loss: 0.6557 - val_accuracy: 0.7443\n",
      "Epoch 124/1000\n",
      "239/239 [==============================] - 0s 2ms/step - loss: 0.6836 - accuracy: 0.7349 - val_loss: 0.6557 - val_accuracy: 0.7437\n",
      "Epoch 125/1000\n",
      "239/239 [==============================] - 0s 2ms/step - loss: 0.6846 - accuracy: 0.7347 - val_loss: 0.6545 - val_accuracy: 0.7453\n",
      "Epoch 126/1000\n",
      "239/239 [==============================] - 1s 2ms/step - loss: 0.6843 - accuracy: 0.7351 - val_loss: 0.6553 - val_accuracy: 0.7457\n",
      "Epoch 127/1000\n",
      "239/239 [==============================] - 1s 2ms/step - loss: 0.6844 - accuracy: 0.7357 - val_loss: 0.6561 - val_accuracy: 0.7443\n",
      "Epoch 128/1000\n",
      "239/239 [==============================] - 1s 2ms/step - loss: 0.6837 - accuracy: 0.7352 - val_loss: 0.6550 - val_accuracy: 0.7452\n",
      "Epoch 129/1000\n",
      "239/239 [==============================] - 1s 2ms/step - loss: 0.6847 - accuracy: 0.7357 - val_loss: 0.6551 - val_accuracy: 0.7457\n",
      "Epoch 130/1000\n",
      "239/239 [==============================] - 0s 2ms/step - loss: 0.6849 - accuracy: 0.7355 - val_loss: 0.6542 - val_accuracy: 0.7450\n",
      "Epoch 131/1000\n",
      "239/239 [==============================] - 0s 2ms/step - loss: 0.6840 - accuracy: 0.7355 - val_loss: 0.6541 - val_accuracy: 0.7452\n",
      "Epoch 132/1000\n",
      "239/239 [==============================] - 1s 2ms/step - loss: 0.6846 - accuracy: 0.7360 - val_loss: 0.6556 - val_accuracy: 0.7443\n",
      "Epoch 133/1000\n",
      "239/239 [==============================] - 1s 2ms/step - loss: 0.6863 - accuracy: 0.7347 - val_loss: 0.6551 - val_accuracy: 0.7440\n",
      "Epoch 134/1000\n",
      "239/239 [==============================] - 1s 2ms/step - loss: 0.6843 - accuracy: 0.7361 - val_loss: 0.6553 - val_accuracy: 0.7450\n",
      "Epoch 135/1000\n",
      "239/239 [==============================] - 0s 2ms/step - loss: 0.6839 - accuracy: 0.7357 - val_loss: 0.6566 - val_accuracy: 0.7451\n",
      "Epoch 136/1000\n",
      "239/239 [==============================] - 0s 2ms/step - loss: 0.6845 - accuracy: 0.7349 - val_loss: 0.6542 - val_accuracy: 0.7450\n",
      "Epoch 137/1000\n",
      "239/239 [==============================] - 1s 2ms/step - loss: 0.6838 - accuracy: 0.7347 - val_loss: 0.6538 - val_accuracy: 0.7449\n",
      "Epoch 138/1000\n",
      "239/239 [==============================] - 1s 2ms/step - loss: 0.6850 - accuracy: 0.7354 - val_loss: 0.6546 - val_accuracy: 0.7441\n",
      "Epoch 139/1000\n",
      "239/239 [==============================] - 1s 2ms/step - loss: 0.6830 - accuracy: 0.7361 - val_loss: 0.6555 - val_accuracy: 0.7436\n",
      "Epoch 140/1000\n",
      "239/239 [==============================] - 1s 2ms/step - loss: 0.6840 - accuracy: 0.7355 - val_loss: 0.6551 - val_accuracy: 0.7450\n",
      "Epoch 141/1000\n",
      "239/239 [==============================] - 1s 3ms/step - loss: 0.6832 - accuracy: 0.7362 - val_loss: 0.6544 - val_accuracy: 0.7447\n",
      "Epoch 142/1000\n",
      "239/239 [==============================] - 1s 2ms/step - loss: 0.6843 - accuracy: 0.7366 - val_loss: 0.6549 - val_accuracy: 0.7444\n",
      "Epoch 143/1000\n",
      "239/239 [==============================] - 1s 2ms/step - loss: 0.6837 - accuracy: 0.7354 - val_loss: 0.6548 - val_accuracy: 0.7445\n",
      "Epoch 144/1000\n",
      "239/239 [==============================] - 1s 2ms/step - loss: 0.6845 - accuracy: 0.7356 - val_loss: 0.6558 - val_accuracy: 0.7448\n",
      "Epoch 145/1000\n",
      "239/239 [==============================] - 1s 2ms/step - loss: 0.6839 - accuracy: 0.7353 - val_loss: 0.6580 - val_accuracy: 0.7439\n",
      "Epoch 146/1000\n",
      "239/239 [==============================] - 0s 2ms/step - loss: 0.6837 - accuracy: 0.7362 - val_loss: 0.6575 - val_accuracy: 0.7456\n",
      "Epoch 147/1000\n",
      "239/239 [==============================] - 0s 2ms/step - loss: 0.6823 - accuracy: 0.7362 - val_loss: 0.6548 - val_accuracy: 0.7438\n",
      "Epoch 148/1000\n",
      "239/239 [==============================] - 0s 2ms/step - loss: 0.6827 - accuracy: 0.7361 - val_loss: 0.6553 - val_accuracy: 0.7456\n",
      "Epoch 149/1000\n",
      "239/239 [==============================] - 0s 2ms/step - loss: 0.6830 - accuracy: 0.7355 - val_loss: 0.6559 - val_accuracy: 0.7435\n",
      "Epoch 150/1000\n",
      "239/239 [==============================] - 1s 2ms/step - loss: 0.6835 - accuracy: 0.7362 - val_loss: 0.6547 - val_accuracy: 0.7436\n",
      "Epoch 150: early stopping\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "<keras.src.callbacks.History at 0x2a33c2770>"
      ]
     },
     "execution_count": 85,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# activation=Tanh\n",
    "model=Sequential()\n",
    "model.add(Dense(128, activation=\"relu\"))\n",
    "model.add(Dropout(0.8))\n",
    "model.add(Dense(128, activation=\"tanh\"))\n",
    "\n",
    "model.add(Dense(64, activation=\"relu\"))\n",
    "model.add(Dropout(0.2))\n",
    "model.add(Dense(64, activation=\"tanh\"))\n",
    "\n",
    "model.add(Dense(32, activation=\"relu\"))\n",
    "model.add(Dropout(0.2))\n",
    "model.add(Dense(16, activation=\"relu\"))\n",
    "model.add(Dropout(0.2))\n",
    "model.add(Dense(3, activation=\"softmax\"))\n",
    "\n",
    "model.compile(loss='categorical_crossentropy', optimizer=Adam(learning_rate=0.001), metrics=['accuracy'])\n",
    "\n",
    "es=EarlyStopping(monitor=\"val_loss\",patience=50,mode=\"auto\",verbose=1)\n",
    "\n",
    "model.fit(X_train,\n",
    "          y_train,\n",
    "          epochs=1000,\n",
    "               batch_size=512,\n",
    "               validation_split=0.1,\n",
    "               verbose=1,callbacks=[es])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 86,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "748/748 [==============================] - 0s 258us/step\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0       0.72      0.87      0.79      7973\n",
      "           1       0.74      0.80      0.77      7973\n",
      "           2       0.77      0.54      0.63      7972\n",
      "\n",
      "    accuracy                           0.74     23918\n",
      "   macro avg       0.74      0.74      0.73     23918\n",
      "weighted avg       0.74      0.74      0.73     23918\n",
      "\n"
     ]
    }
   ],
   "source": [
    "y_pred = model.predict(X_test)\n",
    "y_pred_classes = np.argmax(y_pred, axis=1)\n",
    "y_true = np.argmax(y_test, axis=1)\n",
    "print(classification_report(y_true, y_pred_classes))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 87,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "4236/4236 [==============================] - 1s 267us/step\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0       0.73      0.87      0.79     45176\n",
      "           1       0.74      0.80      0.77     45176\n",
      "           2       0.77      0.55      0.64     45177\n",
      "\n",
      "    accuracy                           0.74    135529\n",
      "   macro avg       0.75      0.74      0.74    135529\n",
      "weighted avg       0.75      0.74      0.74    135529\n",
      "\n"
     ]
    }
   ],
   "source": [
    "y_t_pred = model.predict(X_train)\n",
    "y_t_pred_classes = np.argmax(y_t_pred, axis=1)\n",
    "y_t_true = np.argmax(y_train, axis=1)\n",
    "print(classification_report(y_t_true, y_t_pred_classes))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 107,
   "metadata": {},
   "outputs": [],
   "source": [
    "model=Sequential()\n",
    "model.add(Dense(128, input_dim=X_train.shape[1], activation=\"relu\"))\n",
    "model.add(Dropout(0.2))\n",
    "model.add(Dense(128, activation=\"relu\"))\n",
    "\n",
    "model.add(Dense(64, activation=\"relu\"))\n",
    "model.add(Dropout(0.2))\n",
    "model.add(Dense(64, activation=\"relu\"))\n",
    "\n",
    "model.add(Dense(32, activation=\"relu\"))\n",
    "model.add(Dropout(0.2))\n",
    "model.add(Dense(16, activation=\"relu\"))\n",
    "model.add(Dropout(0.2))\n",
    "model.add(Dense(3, activation=\"softmax\"))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 125,
   "metadata": {
    "scrolled": false
   },
   "outputs": [
    {
     "ename": "TypeError",
     "evalue": "unhashable type: 'numpy.ndarray'",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mTypeError\u001b[0m                                 Traceback (most recent call last)",
      "Cell \u001b[0;32mIn[125], line 3\u001b[0m\n\u001b[1;32m      1\u001b[0m \u001b[38;5;28;01mfrom\u001b[39;00m \u001b[38;5;21;01msklearn\u001b[39;00m\u001b[38;5;21;01m.\u001b[39;00m\u001b[38;5;21;01mutils\u001b[39;00m\u001b[38;5;21;01m.\u001b[39;00m\u001b[38;5;21;01mclass_weight\u001b[39;00m \u001b[38;5;28;01mimport\u001b[39;00m compute_class_weight\n\u001b[0;32m----> 3\u001b[0m class_weights \u001b[38;5;241m=\u001b[39m \u001b[43mcompute_class_weight\u001b[49m\u001b[43m(\u001b[49m\u001b[38;5;124;43m'\u001b[39;49m\u001b[38;5;124;43mbalanced\u001b[39;49m\u001b[38;5;124;43m'\u001b[39;49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mclasses\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mnp\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43munique\u001b[49m\u001b[43m(\u001b[49m\u001b[43my_train\u001b[49m\u001b[43m)\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43my\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43my_train\u001b[49m\u001b[43m)\u001b[49m\n",
      "File \u001b[0;32m~/anaconda3/envs/yeni_ortam/lib/python3.10/site-packages/sklearn/utils/class_weight.py:42\u001b[0m, in \u001b[0;36mcompute_class_weight\u001b[0;34m(class_weight, classes, y)\u001b[0m\n\u001b[1;32m     39\u001b[0m \u001b[38;5;66;03m# Import error caused by circular imports.\u001b[39;00m\n\u001b[1;32m     40\u001b[0m \u001b[38;5;28;01mfrom\u001b[39;00m \u001b[38;5;21;01m.\u001b[39;00m\u001b[38;5;21;01m.\u001b[39;00m\u001b[38;5;21;01mpreprocessing\u001b[39;00m \u001b[38;5;28;01mimport\u001b[39;00m LabelEncoder\n\u001b[0;32m---> 42\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m \u001b[38;5;28;43mset\u001b[39;49m\u001b[43m(\u001b[49m\u001b[43my\u001b[49m\u001b[43m)\u001b[49m \u001b[38;5;241m-\u001b[39m \u001b[38;5;28mset\u001b[39m(classes):\n\u001b[1;32m     43\u001b[0m     \u001b[38;5;28;01mraise\u001b[39;00m \u001b[38;5;167;01mValueError\u001b[39;00m(\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mclasses should include all valid labels that can be in y\u001b[39m\u001b[38;5;124m\"\u001b[39m)\n\u001b[1;32m     44\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m class_weight \u001b[38;5;129;01mis\u001b[39;00m \u001b[38;5;28;01mNone\u001b[39;00m \u001b[38;5;129;01mor\u001b[39;00m \u001b[38;5;28mlen\u001b[39m(class_weight) \u001b[38;5;241m==\u001b[39m \u001b[38;5;241m0\u001b[39m:\n\u001b[1;32m     45\u001b[0m     \u001b[38;5;66;03m# uniform class weights\u001b[39;00m\n",
      "\u001b[0;31mTypeError\u001b[0m: unhashable type: 'numpy.ndarray'"
     ]
    }
   ],
   "source": [
    "from sklearn.utils.class_weight import compute_class_weight\n",
    "\n",
    "class_weights = compute_class_weight('balanced', classes=np.unique(y_train), y=y_train)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 105,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([[0., 0., 1.],\n",
       "       [0., 0., 1.],\n",
       "       [1., 0., 0.],\n",
       "       ...,\n",
       "       [0., 1., 0.],\n",
       "       [1., 0., 0.],\n",
       "       [0., 1., 0.]], dtype=float32)"
      ]
     },
     "execution_count": 105,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "y_train"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 92,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>0</th>\n",
       "      <th>1</th>\n",
       "      <th>2</th>\n",
       "      <th>3</th>\n",
       "      <th>4</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>Delay_from_due_date</th>\n",
       "      <td>3.000</td>\n",
       "      <td>3.000</td>\n",
       "      <td>3.000</td>\n",
       "      <td>5.000</td>\n",
       "      <td>6.000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>Num_of_Delayed_Payment</th>\n",
       "      <td>7.000</td>\n",
       "      <td>7.000</td>\n",
       "      <td>7.000</td>\n",
       "      <td>4.000</td>\n",
       "      <td>4.000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>Num_Credit_Inquiries</th>\n",
       "      <td>4.000</td>\n",
       "      <td>4.000</td>\n",
       "      <td>4.000</td>\n",
       "      <td>4.000</td>\n",
       "      <td>4.000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>Credit_Utilization_Ratio</th>\n",
       "      <td>26.823</td>\n",
       "      <td>31.945</td>\n",
       "      <td>28.609</td>\n",
       "      <td>31.378</td>\n",
       "      <td>24.797</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>Credit_History_Age</th>\n",
       "      <td>265.000</td>\n",
       "      <td>265.000</td>\n",
       "      <td>267.000</td>\n",
       "      <td>268.000</td>\n",
       "      <td>269.000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>Payment_of_Min_Amount</th>\n",
       "      <td>1.099</td>\n",
       "      <td>1.099</td>\n",
       "      <td>1.099</td>\n",
       "      <td>1.099</td>\n",
       "      <td>1.099</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>Amount_invested_monthly</th>\n",
       "      <td>80.415</td>\n",
       "      <td>118.280</td>\n",
       "      <td>81.700</td>\n",
       "      <td>199.458</td>\n",
       "      <td>41.420</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>Monthly_Balance</th>\n",
       "      <td>312.494</td>\n",
       "      <td>284.629</td>\n",
       "      <td>331.210</td>\n",
       "      <td>223.451</td>\n",
       "      <td>341.489</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>Credit_Score</th>\n",
       "      <td>0.000</td>\n",
       "      <td>0.000</td>\n",
       "      <td>0.000</td>\n",
       "      <td>0.000</td>\n",
       "      <td>0.000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>Credit_Mix</th>\n",
       "      <td>0.863</td>\n",
       "      <td>0.863</td>\n",
       "      <td>0.863</td>\n",
       "      <td>0.863</td>\n",
       "      <td>0.863</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>Payment_Behaviour</th>\n",
       "      <td>1.348</td>\n",
       "      <td>1.348</td>\n",
       "      <td>1.348</td>\n",
       "      <td>1.348</td>\n",
       "      <td>1.348</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>Age</th>\n",
       "      <td>23.000</td>\n",
       "      <td>23.000</td>\n",
       "      <td>23.000</td>\n",
       "      <td>23.000</td>\n",
       "      <td>23.000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>Num_Bank_Accounts</th>\n",
       "      <td>3.000</td>\n",
       "      <td>3.000</td>\n",
       "      <td>3.000</td>\n",
       "      <td>3.000</td>\n",
       "      <td>3.000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>Num_Credit_Card</th>\n",
       "      <td>4.000</td>\n",
       "      <td>4.000</td>\n",
       "      <td>4.000</td>\n",
       "      <td>4.000</td>\n",
       "      <td>4.000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>Interest_Rate</th>\n",
       "      <td>3.000</td>\n",
       "      <td>3.000</td>\n",
       "      <td>3.000</td>\n",
       "      <td>3.000</td>\n",
       "      <td>3.000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>Num_of_Loan</th>\n",
       "      <td>4.000</td>\n",
       "      <td>4.000</td>\n",
       "      <td>4.000</td>\n",
       "      <td>4.000</td>\n",
       "      <td>4.000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>Monthly_Inhand_Salary</th>\n",
       "      <td>1824.843</td>\n",
       "      <td>1824.843</td>\n",
       "      <td>1824.843</td>\n",
       "      <td>1824.843</td>\n",
       "      <td>1824.843</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>Changed_Credit_Limit</th>\n",
       "      <td>11.270</td>\n",
       "      <td>11.270</td>\n",
       "      <td>11.270</td>\n",
       "      <td>11.270</td>\n",
       "      <td>11.270</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>Outstanding_Debt</th>\n",
       "      <td>809.980</td>\n",
       "      <td>809.980</td>\n",
       "      <td>809.980</td>\n",
       "      <td>809.980</td>\n",
       "      <td>809.980</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>Total_EMI_per_month</th>\n",
       "      <td>49.575</td>\n",
       "      <td>49.575</td>\n",
       "      <td>49.575</td>\n",
       "      <td>49.575</td>\n",
       "      <td>49.575</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "                                0        1        2        3        4\n",
       "Delay_from_due_date         3.000    3.000    3.000    5.000    6.000\n",
       "Num_of_Delayed_Payment      7.000    7.000    7.000    4.000    4.000\n",
       "Num_Credit_Inquiries        4.000    4.000    4.000    4.000    4.000\n",
       "Credit_Utilization_Ratio   26.823   31.945   28.609   31.378   24.797\n",
       "Credit_History_Age        265.000  265.000  267.000  268.000  269.000\n",
       "Payment_of_Min_Amount       1.099    1.099    1.099    1.099    1.099\n",
       "Amount_invested_monthly    80.415  118.280   81.700  199.458   41.420\n",
       "Monthly_Balance           312.494  284.629  331.210  223.451  341.489\n",
       "Credit_Score                0.000    0.000    0.000    0.000    0.000\n",
       "Credit_Mix                  0.863    0.863    0.863    0.863    0.863\n",
       "Payment_Behaviour           1.348    1.348    1.348    1.348    1.348\n",
       "Age                        23.000   23.000   23.000   23.000   23.000\n",
       "Num_Bank_Accounts           3.000    3.000    3.000    3.000    3.000\n",
       "Num_Credit_Card             4.000    4.000    4.000    4.000    4.000\n",
       "Interest_Rate               3.000    3.000    3.000    3.000    3.000\n",
       "Num_of_Loan                 4.000    4.000    4.000    4.000    4.000\n",
       "Monthly_Inhand_Salary    1824.843 1824.843 1824.843 1824.843 1824.843\n",
       "Changed_Credit_Limit       11.270   11.270   11.270   11.270   11.270\n",
       "Outstanding_Debt          809.980  809.980  809.980  809.980  809.980\n",
       "Total_EMI_per_month        49.575   49.575   49.575   49.575   49.575"
      ]
     },
     "execution_count": 92,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df.head().T"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "model.fit(x=X_train,\n",
    "          y=y_train,\n",
    "          validation_split=.1,\n",
    "          batch_size=32,\n",
    "          epochs=500,\n",
    "          verbose=1,\n",
    "          callbacks=[early_stop],\n",
    "          class_weight=class_weights)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## CyclicLR ile"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 106,
   "metadata": {},
   "outputs": [],
   "source": [
    "from tensorflow.keras.callbacks import *\n",
    "from tensorflow.keras import backend as K\n",
    "import numpy as np\n",
    "\n",
    "class CyclicLR(Callback):\n",
    "   \n",
    "    def __init__(self, base_lr=0.001, max_lr=0.006, step_size=2000., mode='triangular',\n",
    "                 gamma=1., scale_fn=None, scale_mode='cycle'):\n",
    "        super(CyclicLR, self).__init__()\n",
    "\n",
    "        self.base_lr = base_lr\n",
    "        self.max_lr = max_lr\n",
    "        self.step_size = step_size\n",
    "        self.mode = mode\n",
    "        self.gamma = gamma\n",
    "        if scale_fn == None:\n",
    "            if self.mode == 'triangular':\n",
    "                self.scale_fn = lambda x: 1.\n",
    "                self.scale_mode = 'cycle'\n",
    "            elif self.mode == 'triangular2':\n",
    "                self.scale_fn = lambda x: 1/(2.**(x-1))\n",
    "                self.scale_mode = 'cycle'\n",
    "            elif self.mode == 'exp_range':\n",
    "                self.scale_fn = lambda x: gamma**(x)\n",
    "                self.scale_mode = 'iterations'\n",
    "        else:\n",
    "            self.scale_fn = scale_fn\n",
    "            self.scale_mode = scale_mode\n",
    "        self.clr_iterations = 0.\n",
    "        self.trn_iterations = 0.\n",
    "        self.history = {}\n",
    "\n",
    "        self._reset()\n",
    "\n",
    "    def _reset(self, new_base_lr=None, new_max_lr=None,\n",
    "               new_step_size=None):\n",
    "        \"\"\"Resets cycle iterations.\n",
    "        Optional boundary/step size adjustment.\n",
    "        \"\"\"\n",
    "        if new_base_lr != None:\n",
    "            self.base_lr = new_base_lr\n",
    "        if new_max_lr != None:\n",
    "            self.max_lr = new_max_lr\n",
    "        if new_step_size != None:\n",
    "            self.step_size = new_step_size\n",
    "        self.clr_iterations = 0.\n",
    "        \n",
    "    def clr(self):\n",
    "        cycle = np.floor(1+self.clr_iterations/(2*self.step_size))\n",
    "        x = np.abs(self.clr_iterations/self.step_size - 2*cycle + 1)\n",
    "        if self.scale_mode == 'cycle':\n",
    "            return self.base_lr + (self.max_lr-self.base_lr)*np.maximum(0, (1-x))*self.scale_fn(cycle)\n",
    "        else:\n",
    "            return self.base_lr + (self.max_lr-self.base_lr)*np.maximum(0, (1-x))*self.scale_fn(self.clr_iterations)\n",
    "        \n",
    "    def on_train_begin(self, logs={}):\n",
    "        logs = logs or {}\n",
    "\n",
    "        if self.clr_iterations == 0:\n",
    "            K.set_value(self.model.optimizer.lr, self.base_lr)\n",
    "        else:\n",
    "            K.set_value(self.model.optimizer.lr, self.clr())        \n",
    "            \n",
    "    def on_batch_end(self, epoch, logs=None):\n",
    "        \n",
    "        logs = logs or {}\n",
    "        self.trn_iterations += 1\n",
    "        self.clr_iterations += 1\n",
    "\n",
    "        self.history.setdefault('lr', []).append(K.get_value(self.model.optimizer.lr))\n",
    "        self.history.setdefault('iterations', []).append(self.trn_iterations)\n",
    "\n",
    "        for k, v in logs.items():\n",
    "            self.history.setdefault(k, []).append(v)\n",
    "        \n",
    "        K.set_value(self.model.optimizer.lr, self.clr())"
   ]
  },
  {
   "cell_type": "raw",
   "metadata": {},
   "source": [
    " ''' This callback implements a cyclical learning rate policy (CLR).\n",
    "    The method cycles the learning rate between two boundaries with\n",
    "    some constant frequency, as detailed in this paper (https://arxiv.org/abs/1506.01186).\n",
    "    The amplitude of the cycle can be scaled on a per-iteration or \n",
    "    per-cycle basis.\n",
    "    This class has three built-in policies, as put forth in the paper.\n",
    "    \"triangular\":\n",
    "        A basic triangular cycle w/ no amplitude scaling.\n",
    "    \"triangular2\":\n",
    "        A basic triangular cycle that scales initial amplitude by half each cycle.\n",
    "    \"exp_range\":\n",
    "        A cycle that scales initial amplitude by gamma**(cycle iterations) at each \n",
    "        cycle iteration.\n",
    "    For more detail, please see paper.'''\n",
    "    \n",
    "    # Example\n",
    "        ```python\n",
    "            clr = CyclicLR(base_lr=0.001, max_lr=0.006,\n",
    "                                step_size=2000., mode='triangular')\n",
    "            model.fit(X_train, Y_train, callbacks=[clr])\n",
    "        ```\n",
    "    \n",
    "    Class also supports custom scaling functions:\n",
    "        ```python\n",
    "            clr_fn = lambda x: 0.5*(1+np.sin(x*np.pi/2.))\n",
    "            clr = CyclicLR(base_lr=0.001, max_lr=0.006,\n",
    "                                step_size=2000., scale_fn=clr_fn,\n",
    "                                scale_mode='cycle')\n",
    "            model.fit(X_train, Y_train, callbacks=[clr])\n",
    "        ```    \n",
    "    # Arguments\n",
    "        base_lr: initial learning rate which is the\n",
    "            lower boundary in the cycle.\n",
    "        max_lr: upper boundary in the cycle. Functionally,\n",
    "            it defines the cycle amplitude (max_lr - base_lr).\n",
    "            The lr at any cycle is the sum of base_lr\n",
    "            and some scaling of the amplitude; therefore \n",
    "            max_lr may not actually be reached depending on\n",
    "            scaling function.\n",
    "        step_size: number of training iterations per\n",
    "            half cycle. Authors suggest setting step_size\n",
    "            2-8 x training iterations in epoch.\n",
    "        mode: one of {triangular, triangular2, exp_range}.\n",
    "            Default 'triangular'.\n",
    "            Values correspond to policies detailed above.\n",
    "            If scale_fn is not None, this argument is ignored.\n",
    "        gamma: constant in 'exp_range' scaling function:\n",
    "            gamma**(cycle iterations)\n",
    "        scale_fn: Custom scaling policy defined by a single\n",
    "            argument lambda function, where \n",
    "            0 <= scale_fn(x) <= 1 for all x >= 0.\n",
    "            mode paramater is ignored \n",
    "        scale_mode: {'cycle', 'iterations'}.\n",
    "            Defines whether scale_fn is evaluated on \n",
    "            cycle number or cycle iterations (training\n",
    "            iterations since start of cycle). Default is 'cycle'."
   ]
  },
  {
   "cell_type": "raw",
   "metadata": {},
   "source": [
    "clr = CyclicLR(base_lr=0.001, max_lr=0.006,\n",
    "                                step_size=2000., mode='triangular')\n",
    "model.fit(X_train, Y_train, callbacks=[clr])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 108,
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 1/1000\n",
      "239/239 [==============================] - 1s 2ms/step - loss: 0.7857 - accuracy: 0.6841 - val_loss: 0.6831 - val_accuracy: 0.7374\n",
      "Epoch 2/1000\n",
      "239/239 [==============================] - 1s 2ms/step - loss: 0.7118 - accuracy: 0.7283 - val_loss: 0.6707 - val_accuracy: 0.7427\n",
      "Epoch 3/1000\n",
      "239/239 [==============================] - 0s 2ms/step - loss: 0.6939 - accuracy: 0.7337 - val_loss: 0.6597 - val_accuracy: 0.7463\n",
      "Epoch 4/1000\n",
      "239/239 [==============================] - 0s 2ms/step - loss: 0.6858 - accuracy: 0.7356 - val_loss: 0.6550 - val_accuracy: 0.7468\n",
      "Epoch 5/1000\n",
      "239/239 [==============================] - 1s 2ms/step - loss: 0.6784 - accuracy: 0.7391 - val_loss: 0.6493 - val_accuracy: 0.7460\n",
      "Epoch 6/1000\n",
      "239/239 [==============================] - 0s 2ms/step - loss: 0.6756 - accuracy: 0.7384 - val_loss: 0.6426 - val_accuracy: 0.7482\n",
      "Epoch 7/1000\n",
      "239/239 [==============================] - 0s 2ms/step - loss: 0.6687 - accuracy: 0.7418 - val_loss: 0.6426 - val_accuracy: 0.7483\n",
      "Epoch 8/1000\n",
      "239/239 [==============================] - 0s 2ms/step - loss: 0.6665 - accuracy: 0.7425 - val_loss: 0.6419 - val_accuracy: 0.7466\n",
      "Epoch 9/1000\n",
      "239/239 [==============================] - 0s 2ms/step - loss: 0.6620 - accuracy: 0.7429 - val_loss: 0.6278 - val_accuracy: 0.7536\n",
      "Epoch 10/1000\n",
      "239/239 [==============================] - 0s 2ms/step - loss: 0.6562 - accuracy: 0.7457 - val_loss: 0.6299 - val_accuracy: 0.7564\n",
      "Epoch 11/1000\n",
      "239/239 [==============================] - 0s 2ms/step - loss: 0.6495 - accuracy: 0.7472 - val_loss: 0.6174 - val_accuracy: 0.7581\n",
      "Epoch 12/1000\n",
      "239/239 [==============================] - 0s 2ms/step - loss: 0.6420 - accuracy: 0.7494 - val_loss: 0.6116 - val_accuracy: 0.7618\n",
      "Epoch 13/1000\n",
      "239/239 [==============================] - 0s 2ms/step - loss: 0.6331 - accuracy: 0.7518 - val_loss: 0.6012 - val_accuracy: 0.7639\n",
      "Epoch 14/1000\n",
      "239/239 [==============================] - 0s 2ms/step - loss: 0.6239 - accuracy: 0.7562 - val_loss: 0.5917 - val_accuracy: 0.7679\n",
      "Epoch 15/1000\n",
      "239/239 [==============================] - 0s 2ms/step - loss: 0.6162 - accuracy: 0.7588 - val_loss: 0.5816 - val_accuracy: 0.7702\n",
      "Epoch 16/1000\n",
      "239/239 [==============================] - 0s 2ms/step - loss: 0.6080 - accuracy: 0.7617 - val_loss: 0.5739 - val_accuracy: 0.7745\n",
      "Epoch 17/1000\n",
      "239/239 [==============================] - 0s 2ms/step - loss: 0.6004 - accuracy: 0.7644 - val_loss: 0.5700 - val_accuracy: 0.7746\n",
      "Epoch 18/1000\n",
      "239/239 [==============================] - 0s 2ms/step - loss: 0.5984 - accuracy: 0.7648 - val_loss: 0.5700 - val_accuracy: 0.7747\n",
      "Epoch 19/1000\n",
      "239/239 [==============================] - 0s 2ms/step - loss: 0.6007 - accuracy: 0.7634 - val_loss: 0.5672 - val_accuracy: 0.7753\n",
      "Epoch 20/1000\n",
      "239/239 [==============================] - 0s 2ms/step - loss: 0.6010 - accuracy: 0.7635 - val_loss: 0.5681 - val_accuracy: 0.7775\n",
      "Epoch 21/1000\n",
      "239/239 [==============================] - 0s 2ms/step - loss: 0.6040 - accuracy: 0.7631 - val_loss: 0.5758 - val_accuracy: 0.7716\n",
      "Epoch 22/1000\n",
      "239/239 [==============================] - 0s 2ms/step - loss: 0.6061 - accuracy: 0.7618 - val_loss: 0.5712 - val_accuracy: 0.7740\n",
      "Epoch 23/1000\n",
      "239/239 [==============================] - 0s 2ms/step - loss: 0.6070 - accuracy: 0.7610 - val_loss: 0.5778 - val_accuracy: 0.7732\n",
      "Epoch 24/1000\n",
      "239/239 [==============================] - 0s 2ms/step - loss: 0.6092 - accuracy: 0.7600 - val_loss: 0.5822 - val_accuracy: 0.7666\n",
      "Epoch 25/1000\n",
      "239/239 [==============================] - 0s 2ms/step - loss: 0.6103 - accuracy: 0.7602 - val_loss: 0.5790 - val_accuracy: 0.7627\n",
      "Epoch 26/1000\n",
      "239/239 [==============================] - 0s 2ms/step - loss: 0.6101 - accuracy: 0.7582 - val_loss: 0.5762 - val_accuracy: 0.7713\n",
      "Epoch 27/1000\n",
      "239/239 [==============================] - 1s 2ms/step - loss: 0.6052 - accuracy: 0.7611 - val_loss: 0.5665 - val_accuracy: 0.7741\n",
      "Epoch 28/1000\n",
      "239/239 [==============================] - 0s 2ms/step - loss: 0.5985 - accuracy: 0.7631 - val_loss: 0.5549 - val_accuracy: 0.7784\n",
      "Epoch 29/1000\n",
      "239/239 [==============================] - 0s 2ms/step - loss: 0.5921 - accuracy: 0.7653 - val_loss: 0.5525 - val_accuracy: 0.7808\n",
      "Epoch 30/1000\n",
      "239/239 [==============================] - 0s 2ms/step - loss: 0.5830 - accuracy: 0.7677 - val_loss: 0.5524 - val_accuracy: 0.7826\n",
      "Epoch 31/1000\n",
      "239/239 [==============================] - 0s 2ms/step - loss: 0.5752 - accuracy: 0.7721 - val_loss: 0.5386 - val_accuracy: 0.7861\n",
      "Epoch 32/1000\n",
      "239/239 [==============================] - 0s 2ms/step - loss: 0.5664 - accuracy: 0.7758 - val_loss: 0.5340 - val_accuracy: 0.7868\n",
      "Epoch 33/1000\n",
      "239/239 [==============================] - 0s 2ms/step - loss: 0.5613 - accuracy: 0.7783 - val_loss: 0.5263 - val_accuracy: 0.7915\n",
      "Epoch 34/1000\n",
      "239/239 [==============================] - 0s 2ms/step - loss: 0.5558 - accuracy: 0.7796 - val_loss: 0.5235 - val_accuracy: 0.7909\n",
      "Epoch 35/1000\n",
      "239/239 [==============================] - 0s 2ms/step - loss: 0.5549 - accuracy: 0.7800 - val_loss: 0.5262 - val_accuracy: 0.7908\n",
      "Epoch 36/1000\n",
      "239/239 [==============================] - 0s 2ms/step - loss: 0.5566 - accuracy: 0.7783 - val_loss: 0.5274 - val_accuracy: 0.7924\n",
      "Epoch 37/1000\n",
      "239/239 [==============================] - 0s 2ms/step - loss: 0.5640 - accuracy: 0.7773 - val_loss: 0.5337 - val_accuracy: 0.7885\n",
      "Epoch 38/1000\n",
      "239/239 [==============================] - 0s 2ms/step - loss: 0.5654 - accuracy: 0.7747 - val_loss: 0.5367 - val_accuracy: 0.7887\n",
      "Epoch 39/1000\n",
      "239/239 [==============================] - 0s 2ms/step - loss: 0.5699 - accuracy: 0.7751 - val_loss: 0.5398 - val_accuracy: 0.7857\n",
      "Epoch 40/1000\n",
      "239/239 [==============================] - 0s 2ms/step - loss: 0.5752 - accuracy: 0.7740 - val_loss: 0.5419 - val_accuracy: 0.7829\n",
      "Epoch 41/1000\n",
      "239/239 [==============================] - 1s 2ms/step - loss: 0.5787 - accuracy: 0.7718 - val_loss: 0.5469 - val_accuracy: 0.7835\n",
      "Epoch 42/1000\n",
      "239/239 [==============================] - 0s 2ms/step - loss: 0.5827 - accuracy: 0.7700 - val_loss: 0.5457 - val_accuracy: 0.7813\n",
      "Epoch 43/1000\n",
      "239/239 [==============================] - 0s 2ms/step - loss: 0.5820 - accuracy: 0.7696 - val_loss: 0.5434 - val_accuracy: 0.7848\n",
      "Epoch 44/1000\n",
      "239/239 [==============================] - 0s 2ms/step - loss: 0.5734 - accuracy: 0.7731 - val_loss: 0.5485 - val_accuracy: 0.7807\n",
      "Epoch 45/1000\n",
      "239/239 [==============================] - 0s 2ms/step - loss: 0.5693 - accuracy: 0.7741 - val_loss: 0.5303 - val_accuracy: 0.7873\n",
      "Epoch 46/1000\n",
      "239/239 [==============================] - 0s 2ms/step - loss: 0.5626 - accuracy: 0.7769 - val_loss: 0.5237 - val_accuracy: 0.7898\n",
      "Epoch 47/1000\n",
      "239/239 [==============================] - 0s 2ms/step - loss: 0.5557 - accuracy: 0.7801 - val_loss: 0.5215 - val_accuracy: 0.7907\n",
      "Epoch 48/1000\n",
      "239/239 [==============================] - 0s 2ms/step - loss: 0.5497 - accuracy: 0.7816 - val_loss: 0.5162 - val_accuracy: 0.7932\n",
      "Epoch 49/1000\n",
      "239/239 [==============================] - 0s 2ms/step - loss: 0.5421 - accuracy: 0.7848 - val_loss: 0.5088 - val_accuracy: 0.7989\n",
      "Epoch 50/1000\n",
      "239/239 [==============================] - 0s 2ms/step - loss: 0.5365 - accuracy: 0.7864 - val_loss: 0.5059 - val_accuracy: 0.7974\n",
      "Epoch 51/1000\n",
      "239/239 [==============================] - 0s 2ms/step - loss: 0.5304 - accuracy: 0.7887 - val_loss: 0.5079 - val_accuracy: 0.7953\n",
      "Epoch 52/1000\n",
      "239/239 [==============================] - 0s 2ms/step - loss: 0.5338 - accuracy: 0.7884 - val_loss: 0.5042 - val_accuracy: 0.7986\n",
      "Epoch 53/1000\n",
      "239/239 [==============================] - 0s 2ms/step - loss: 0.5359 - accuracy: 0.7864 - val_loss: 0.5055 - val_accuracy: 0.7993\n",
      "Epoch 54/1000\n",
      "239/239 [==============================] - 0s 2ms/step - loss: 0.5443 - accuracy: 0.7835 - val_loss: 0.5139 - val_accuracy: 0.7966\n",
      "Epoch 55/1000\n",
      "239/239 [==============================] - 1s 2ms/step - loss: 0.5460 - accuracy: 0.7828 - val_loss: 0.5140 - val_accuracy: 0.7941\n",
      "Epoch 56/1000\n",
      "239/239 [==============================] - 0s 2ms/step - loss: 0.5520 - accuracy: 0.7804 - val_loss: 0.5245 - val_accuracy: 0.7909\n",
      "Epoch 57/1000\n",
      "239/239 [==============================] - 0s 2ms/step - loss: 0.5555 - accuracy: 0.7797 - val_loss: 0.5196 - val_accuracy: 0.7934\n",
      "Epoch 58/1000\n",
      "239/239 [==============================] - 1s 2ms/step - loss: 0.5618 - accuracy: 0.7774 - val_loss: 0.5286 - val_accuracy: 0.7919\n",
      "Epoch 59/1000\n",
      "239/239 [==============================] - 0s 2ms/step - loss: 0.5662 - accuracy: 0.7763 - val_loss: 0.5332 - val_accuracy: 0.7857\n",
      "Epoch 60/1000\n",
      "239/239 [==============================] - 0s 2ms/step - loss: 0.5672 - accuracy: 0.7752 - val_loss: 0.5273 - val_accuracy: 0.7901\n",
      "Epoch 61/1000\n",
      "239/239 [==============================] - 0s 2ms/step - loss: 0.5592 - accuracy: 0.7770 - val_loss: 0.5192 - val_accuracy: 0.7926\n",
      "Epoch 62/1000\n",
      "239/239 [==============================] - 0s 2ms/step - loss: 0.5512 - accuracy: 0.7818 - val_loss: 0.5205 - val_accuracy: 0.7955\n",
      "Epoch 63/1000\n",
      "239/239 [==============================] - 0s 2ms/step - loss: 0.5467 - accuracy: 0.7835 - val_loss: 0.5121 - val_accuracy: 0.7939\n",
      "Epoch 64/1000\n",
      "239/239 [==============================] - 0s 2ms/step - loss: 0.5381 - accuracy: 0.7857 - val_loss: 0.5058 - val_accuracy: 0.7981\n",
      "Epoch 65/1000\n",
      "239/239 [==============================] - 0s 2ms/step - loss: 0.5328 - accuracy: 0.7887 - val_loss: 0.4981 - val_accuracy: 0.8024\n",
      "Epoch 66/1000\n",
      "239/239 [==============================] - 0s 2ms/step - loss: 0.5287 - accuracy: 0.7907 - val_loss: 0.4910 - val_accuracy: 0.8051\n",
      "Epoch 67/1000\n",
      "239/239 [==============================] - 0s 2ms/step - loss: 0.5223 - accuracy: 0.7930 - val_loss: 0.4891 - val_accuracy: 0.8052\n",
      "Epoch 68/1000\n",
      "239/239 [==============================] - 0s 2ms/step - loss: 0.5188 - accuracy: 0.7936 - val_loss: 0.4881 - val_accuracy: 0.8051\n",
      "Epoch 69/1000\n",
      "239/239 [==============================] - 0s 2ms/step - loss: 0.5202 - accuracy: 0.7939 - val_loss: 0.4917 - val_accuracy: 0.8028\n",
      "Epoch 70/1000\n",
      "239/239 [==============================] - 0s 2ms/step - loss: 0.5265 - accuracy: 0.7903 - val_loss: 0.4911 - val_accuracy: 0.8071\n",
      "Epoch 71/1000\n",
      "239/239 [==============================] - 0s 2ms/step - loss: 0.5298 - accuracy: 0.7899 - val_loss: 0.4954 - val_accuracy: 0.8023\n",
      "Epoch 72/1000\n",
      "239/239 [==============================] - 0s 2ms/step - loss: 0.5365 - accuracy: 0.7873 - val_loss: 0.4974 - val_accuracy: 0.8027\n",
      "Epoch 73/1000\n",
      "239/239 [==============================] - 0s 2ms/step - loss: 0.5384 - accuracy: 0.7854 - val_loss: 0.5051 - val_accuracy: 0.7978\n",
      "Epoch 74/1000\n",
      "239/239 [==============================] - 0s 2ms/step - loss: 0.5472 - accuracy: 0.7817 - val_loss: 0.5191 - val_accuracy: 0.7933\n",
      "Epoch 75/1000\n",
      "239/239 [==============================] - 0s 2ms/step - loss: 0.5524 - accuracy: 0.7807 - val_loss: 0.5168 - val_accuracy: 0.8003\n",
      "Epoch 76/1000\n",
      "239/239 [==============================] - 0s 2ms/step - loss: 0.5584 - accuracy: 0.7775 - val_loss: 0.5212 - val_accuracy: 0.7933\n",
      "Epoch 77/1000\n",
      "239/239 [==============================] - 0s 2ms/step - loss: 0.5546 - accuracy: 0.7799 - val_loss: 0.5144 - val_accuracy: 0.7977\n",
      "Epoch 78/1000\n",
      "239/239 [==============================] - 0s 2ms/step - loss: 0.5469 - accuracy: 0.7818 - val_loss: 0.5097 - val_accuracy: 0.7985\n",
      "Epoch 79/1000\n",
      "239/239 [==============================] - 0s 2ms/step - loss: 0.5410 - accuracy: 0.7852 - val_loss: 0.5042 - val_accuracy: 0.7981\n",
      "Epoch 80/1000\n",
      "239/239 [==============================] - 0s 2ms/step - loss: 0.5335 - accuracy: 0.7883 - val_loss: 0.4948 - val_accuracy: 0.8011\n",
      "Epoch 81/1000\n",
      "239/239 [==============================] - 0s 2ms/step - loss: 0.5307 - accuracy: 0.7892 - val_loss: 0.4952 - val_accuracy: 0.8019\n",
      "Epoch 82/1000\n",
      "239/239 [==============================] - 0s 2ms/step - loss: 0.5225 - accuracy: 0.7923 - val_loss: 0.4895 - val_accuracy: 0.8016\n",
      "Epoch 83/1000\n",
      "239/239 [==============================] - 0s 2ms/step - loss: 0.5174 - accuracy: 0.7943 - val_loss: 0.4829 - val_accuracy: 0.8069\n",
      "Epoch 84/1000\n",
      "239/239 [==============================] - 0s 2ms/step - loss: 0.5117 - accuracy: 0.7971 - val_loss: 0.4799 - val_accuracy: 0.8074\n",
      "Epoch 85/1000\n",
      "239/239 [==============================] - 0s 2ms/step - loss: 0.5101 - accuracy: 0.7980 - val_loss: 0.4827 - val_accuracy: 0.8067\n",
      "Epoch 86/1000\n",
      "239/239 [==============================] - 0s 2ms/step - loss: 0.5118 - accuracy: 0.7963 - val_loss: 0.4811 - val_accuracy: 0.8079\n",
      "Epoch 87/1000\n",
      "239/239 [==============================] - 0s 2ms/step - loss: 0.5174 - accuracy: 0.7950 - val_loss: 0.4829 - val_accuracy: 0.8074\n",
      "Epoch 88/1000\n",
      "239/239 [==============================] - 0s 2ms/step - loss: 0.5213 - accuracy: 0.7931 - val_loss: 0.4878 - val_accuracy: 0.8074\n",
      "Epoch 89/1000\n",
      "239/239 [==============================] - 0s 2ms/step - loss: 0.5282 - accuracy: 0.7898 - val_loss: 0.4900 - val_accuracy: 0.8045\n",
      "Epoch 90/1000\n",
      "239/239 [==============================] - 1s 2ms/step - loss: 0.5358 - accuracy: 0.7893 - val_loss: 0.4986 - val_accuracy: 0.8030\n",
      "Epoch 91/1000\n",
      "239/239 [==============================] - 1s 2ms/step - loss: 0.5412 - accuracy: 0.7846 - val_loss: 0.5059 - val_accuracy: 0.7986\n",
      "Epoch 92/1000\n",
      "239/239 [==============================] - 0s 2ms/step - loss: 0.5483 - accuracy: 0.7838 - val_loss: 0.5050 - val_accuracy: 0.7986\n",
      "Epoch 93/1000\n",
      "239/239 [==============================] - 1s 2ms/step - loss: 0.5479 - accuracy: 0.7830 - val_loss: 0.5075 - val_accuracy: 0.7958\n",
      "Epoch 94/1000\n",
      "239/239 [==============================] - 0s 2ms/step - loss: 0.5451 - accuracy: 0.7837 - val_loss: 0.5007 - val_accuracy: 0.7986\n",
      "Epoch 95/1000\n",
      "239/239 [==============================] - 0s 2ms/step - loss: 0.5370 - accuracy: 0.7861 - val_loss: 0.4975 - val_accuracy: 0.8014\n",
      "Epoch 96/1000\n",
      "239/239 [==============================] - 0s 2ms/step - loss: 0.5324 - accuracy: 0.7893 - val_loss: 0.4934 - val_accuracy: 0.8000\n",
      "Epoch 97/1000\n",
      "239/239 [==============================] - 0s 2ms/step - loss: 0.5292 - accuracy: 0.7898 - val_loss: 0.4897 - val_accuracy: 0.8040\n",
      "Epoch 98/1000\n",
      "239/239 [==============================] - 0s 2ms/step - loss: 0.5203 - accuracy: 0.7928 - val_loss: 0.4851 - val_accuracy: 0.8068\n",
      "Epoch 99/1000\n",
      "239/239 [==============================] - 0s 2ms/step - loss: 0.5130 - accuracy: 0.7971 - val_loss: 0.4798 - val_accuracy: 0.8088\n",
      "Epoch 100/1000\n",
      "239/239 [==============================] - 0s 2ms/step - loss: 0.5057 - accuracy: 0.7990 - val_loss: 0.4754 - val_accuracy: 0.8105\n",
      "Epoch 101/1000\n",
      "239/239 [==============================] - 0s 2ms/step - loss: 0.5052 - accuracy: 0.7990 - val_loss: 0.4732 - val_accuracy: 0.8120\n",
      "Epoch 102/1000\n",
      "239/239 [==============================] - 0s 2ms/step - loss: 0.5050 - accuracy: 0.7989 - val_loss: 0.4743 - val_accuracy: 0.8108\n",
      "Epoch 103/1000\n",
      "239/239 [==============================] - 0s 2ms/step - loss: 0.5103 - accuracy: 0.7981 - val_loss: 0.4791 - val_accuracy: 0.8085\n",
      "Epoch 104/1000\n",
      "239/239 [==============================] - 0s 2ms/step - loss: 0.5125 - accuracy: 0.7961 - val_loss: 0.4805 - val_accuracy: 0.8074\n",
      "Epoch 105/1000\n",
      "239/239 [==============================] - 0s 2ms/step - loss: 0.5172 - accuracy: 0.7955 - val_loss: 0.4884 - val_accuracy: 0.8067\n",
      "Epoch 106/1000\n",
      "239/239 [==============================] - 0s 2ms/step - loss: 0.5225 - accuracy: 0.7910 - val_loss: 0.4899 - val_accuracy: 0.8028\n",
      "Epoch 107/1000\n",
      "239/239 [==============================] - 0s 2ms/step - loss: 0.5291 - accuracy: 0.7894 - val_loss: 0.4919 - val_accuracy: 0.8014\n",
      "Epoch 108/1000\n",
      "239/239 [==============================] - 1s 2ms/step - loss: 0.5361 - accuracy: 0.7877 - val_loss: 0.4981 - val_accuracy: 0.8017\n",
      "Epoch 109/1000\n",
      "239/239 [==============================] - 0s 2ms/step - loss: 0.5437 - accuracy: 0.7845 - val_loss: 0.5074 - val_accuracy: 0.7992\n",
      "Epoch 110/1000\n",
      "239/239 [==============================] - 0s 2ms/step - loss: 0.5402 - accuracy: 0.7863 - val_loss: 0.5038 - val_accuracy: 0.7986\n",
      "Epoch 111/1000\n",
      "239/239 [==============================] - 0s 2ms/step - loss: 0.5356 - accuracy: 0.7865 - val_loss: 0.4937 - val_accuracy: 0.8016\n",
      "Epoch 112/1000\n",
      "239/239 [==============================] - 0s 2ms/step - loss: 0.5304 - accuracy: 0.7881 - val_loss: 0.4865 - val_accuracy: 0.8070\n",
      "Epoch 113/1000\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "239/239 [==============================] - 0s 2ms/step - loss: 0.5268 - accuracy: 0.7910 - val_loss: 0.4844 - val_accuracy: 0.8071\n",
      "Epoch 114/1000\n",
      "239/239 [==============================] - 0s 2ms/step - loss: 0.5218 - accuracy: 0.7923 - val_loss: 0.4778 - val_accuracy: 0.8102\n",
      "Epoch 115/1000\n",
      "239/239 [==============================] - 0s 2ms/step - loss: 0.5110 - accuracy: 0.7959 - val_loss: 0.4736 - val_accuracy: 0.8132\n",
      "Epoch 116/1000\n",
      "239/239 [==============================] - 0s 2ms/step - loss: 0.5097 - accuracy: 0.7981 - val_loss: 0.4709 - val_accuracy: 0.8123\n",
      "Epoch 117/1000\n",
      "239/239 [==============================] - 0s 2ms/step - loss: 0.5035 - accuracy: 0.7998 - val_loss: 0.4683 - val_accuracy: 0.8128\n",
      "Epoch 118/1000\n",
      "239/239 [==============================] - 0s 2ms/step - loss: 0.4982 - accuracy: 0.8030 - val_loss: 0.4661 - val_accuracy: 0.8128\n",
      "Epoch 119/1000\n",
      "239/239 [==============================] - 0s 2ms/step - loss: 0.5010 - accuracy: 0.8011 - val_loss: 0.4645 - val_accuracy: 0.8149\n",
      "Epoch 120/1000\n",
      "239/239 [==============================] - 0s 2ms/step - loss: 0.5034 - accuracy: 0.8013 - val_loss: 0.4703 - val_accuracy: 0.8118\n",
      "Epoch 121/1000\n",
      "239/239 [==============================] - 0s 2ms/step - loss: 0.5094 - accuracy: 0.7980 - val_loss: 0.4742 - val_accuracy: 0.8112\n",
      "Epoch 122/1000\n",
      "239/239 [==============================] - 0s 2ms/step - loss: 0.5156 - accuracy: 0.7957 - val_loss: 0.4770 - val_accuracy: 0.8089\n",
      "Epoch 123/1000\n",
      "239/239 [==============================] - 1s 2ms/step - loss: 0.5181 - accuracy: 0.7943 - val_loss: 0.4786 - val_accuracy: 0.8104\n",
      "Epoch 124/1000\n",
      "239/239 [==============================] - 0s 2ms/step - loss: 0.5256 - accuracy: 0.7918 - val_loss: 0.4894 - val_accuracy: 0.8058\n",
      "Epoch 125/1000\n",
      "239/239 [==============================] - 0s 2ms/step - loss: 0.5305 - accuracy: 0.7891 - val_loss: 0.4921 - val_accuracy: 0.8023\n",
      "Epoch 126/1000\n",
      "239/239 [==============================] - 0s 2ms/step - loss: 0.5376 - accuracy: 0.7882 - val_loss: 0.5006 - val_accuracy: 0.8016\n",
      "Epoch 127/1000\n",
      "239/239 [==============================] - 0s 2ms/step - loss: 0.5368 - accuracy: 0.7875 - val_loss: 0.4958 - val_accuracy: 0.8046\n",
      "Epoch 128/1000\n",
      "239/239 [==============================] - 0s 2ms/step - loss: 0.5314 - accuracy: 0.7903 - val_loss: 0.4898 - val_accuracy: 0.8062\n",
      "Epoch 129/1000\n",
      "239/239 [==============================] - 1s 2ms/step - loss: 0.5265 - accuracy: 0.7920 - val_loss: 0.4880 - val_accuracy: 0.8076\n",
      "Epoch 130/1000\n",
      "239/239 [==============================] - 0s 2ms/step - loss: 0.5213 - accuracy: 0.7932 - val_loss: 0.4815 - val_accuracy: 0.8094\n",
      "Epoch 131/1000\n",
      "239/239 [==============================] - 0s 2ms/step - loss: 0.5148 - accuracy: 0.7969 - val_loss: 0.4751 - val_accuracy: 0.8104\n",
      "Epoch 132/1000\n",
      "239/239 [==============================] - 0s 2ms/step - loss: 0.5092 - accuracy: 0.7989 - val_loss: 0.4747 - val_accuracy: 0.8105\n",
      "Epoch 133/1000\n",
      "239/239 [==============================] - 0s 2ms/step - loss: 0.5027 - accuracy: 0.8011 - val_loss: 0.4682 - val_accuracy: 0.8135\n",
      "Epoch 134/1000\n",
      "239/239 [==============================] - 0s 2ms/step - loss: 0.4978 - accuracy: 0.8023 - val_loss: 0.4659 - val_accuracy: 0.8166\n",
      "Epoch 135/1000\n",
      "239/239 [==============================] - 0s 2ms/step - loss: 0.4968 - accuracy: 0.8033 - val_loss: 0.4651 - val_accuracy: 0.8169\n",
      "Epoch 136/1000\n",
      "239/239 [==============================] - 0s 2ms/step - loss: 0.4971 - accuracy: 0.8035 - val_loss: 0.4673 - val_accuracy: 0.8172\n",
      "Epoch 137/1000\n",
      "239/239 [==============================] - 0s 2ms/step - loss: 0.5008 - accuracy: 0.8022 - val_loss: 0.4682 - val_accuracy: 0.8156\n",
      "Epoch 138/1000\n",
      "239/239 [==============================] - 0s 2ms/step - loss: 0.5059 - accuracy: 0.7980 - val_loss: 0.4719 - val_accuracy: 0.8157\n",
      "Epoch 139/1000\n",
      "239/239 [==============================] - 0s 2ms/step - loss: 0.5111 - accuracy: 0.7967 - val_loss: 0.4788 - val_accuracy: 0.8083\n",
      "Epoch 140/1000\n",
      "239/239 [==============================] - 0s 2ms/step - loss: 0.5201 - accuracy: 0.7929 - val_loss: 0.4813 - val_accuracy: 0.8098\n",
      "Epoch 141/1000\n",
      "239/239 [==============================] - 0s 2ms/step - loss: 0.5242 - accuracy: 0.7933 - val_loss: 0.4904 - val_accuracy: 0.8073\n",
      "Epoch 142/1000\n",
      "239/239 [==============================] - 0s 2ms/step - loss: 0.5325 - accuracy: 0.7900 - val_loss: 0.4919 - val_accuracy: 0.8034\n",
      "Epoch 143/1000\n",
      "239/239 [==============================] - 0s 2ms/step - loss: 0.5404 - accuracy: 0.7862 - val_loss: 0.4954 - val_accuracy: 0.8073\n",
      "Epoch 144/1000\n",
      "239/239 [==============================] - 0s 2ms/step - loss: 0.5362 - accuracy: 0.7883 - val_loss: 0.5002 - val_accuracy: 0.8050\n",
      "Epoch 145/1000\n",
      "239/239 [==============================] - 0s 2ms/step - loss: 0.5302 - accuracy: 0.7897 - val_loss: 0.4856 - val_accuracy: 0.8051\n",
      "Epoch 146/1000\n",
      "239/239 [==============================] - 0s 2ms/step - loss: 0.5218 - accuracy: 0.7932 - val_loss: 0.4823 - val_accuracy: 0.8113\n",
      "Epoch 147/1000\n",
      "239/239 [==============================] - 0s 2ms/step - loss: 0.5177 - accuracy: 0.7955 - val_loss: 0.4779 - val_accuracy: 0.8100\n",
      "Epoch 148/1000\n",
      "239/239 [==============================] - 0s 2ms/step - loss: 0.5122 - accuracy: 0.7985 - val_loss: 0.4757 - val_accuracy: 0.8127\n",
      "Epoch 149/1000\n",
      "239/239 [==============================] - 0s 2ms/step - loss: 0.5046 - accuracy: 0.8010 - val_loss: 0.4714 - val_accuracy: 0.8130\n",
      "Epoch 150/1000\n",
      "239/239 [==============================] - 0s 2ms/step - loss: 0.5003 - accuracy: 0.8019 - val_loss: 0.4661 - val_accuracy: 0.8167\n",
      "Epoch 151/1000\n",
      "239/239 [==============================] - 1s 2ms/step - loss: 0.4961 - accuracy: 0.8045 - val_loss: 0.4645 - val_accuracy: 0.8167\n",
      "Epoch 152/1000\n",
      "239/239 [==============================] - 1s 2ms/step - loss: 0.4972 - accuracy: 0.8042 - val_loss: 0.4633 - val_accuracy: 0.8175\n",
      "Epoch 153/1000\n",
      "239/239 [==============================] - 0s 2ms/step - loss: 0.4977 - accuracy: 0.8028 - val_loss: 0.4659 - val_accuracy: 0.8178\n",
      "Epoch 154/1000\n",
      "239/239 [==============================] - 0s 2ms/step - loss: 0.5036 - accuracy: 0.8012 - val_loss: 0.4663 - val_accuracy: 0.8163\n",
      "Epoch 155/1000\n",
      "239/239 [==============================] - 0s 2ms/step - loss: 0.5050 - accuracy: 0.8010 - val_loss: 0.4722 - val_accuracy: 0.8111\n",
      "Epoch 156/1000\n",
      "239/239 [==============================] - 0s 2ms/step - loss: 0.5117 - accuracy: 0.7980 - val_loss: 0.4804 - val_accuracy: 0.8099\n",
      "Epoch 157/1000\n",
      "239/239 [==============================] - 1s 2ms/step - loss: 0.5152 - accuracy: 0.7964 - val_loss: 0.4820 - val_accuracy: 0.8093\n",
      "Epoch 158/1000\n",
      "239/239 [==============================] - 0s 2ms/step - loss: 0.5192 - accuracy: 0.7944 - val_loss: 0.4826 - val_accuracy: 0.8090\n",
      "Epoch 159/1000\n",
      "239/239 [==============================] - 0s 2ms/step - loss: 0.5227 - accuracy: 0.7914 - val_loss: 0.4904 - val_accuracy: 0.8050\n",
      "Epoch 160/1000\n",
      "239/239 [==============================] - 0s 2ms/step - loss: 0.5310 - accuracy: 0.7911 - val_loss: 0.4853 - val_accuracy: 0.8091\n",
      "Epoch 161/1000\n",
      "239/239 [==============================] - 0s 2ms/step - loss: 0.5284 - accuracy: 0.7902 - val_loss: 0.4885 - val_accuracy: 0.8056\n",
      "Epoch 162/1000\n",
      "239/239 [==============================] - 0s 2ms/step - loss: 0.5292 - accuracy: 0.7909 - val_loss: 0.4827 - val_accuracy: 0.8083\n",
      "Epoch 163/1000\n",
      "239/239 [==============================] - 0s 2ms/step - loss: 0.5215 - accuracy: 0.7937 - val_loss: 0.4785 - val_accuracy: 0.8125\n",
      "Epoch 164/1000\n",
      "239/239 [==============================] - 0s 2ms/step - loss: 0.5132 - accuracy: 0.7966 - val_loss: 0.4693 - val_accuracy: 0.8139\n",
      "Epoch 165/1000\n",
      "239/239 [==============================] - 0s 2ms/step - loss: 0.5067 - accuracy: 0.7998 - val_loss: 0.4702 - val_accuracy: 0.8169\n",
      "Epoch 166/1000\n",
      "239/239 [==============================] - 0s 2ms/step - loss: 0.5025 - accuracy: 0.8014 - val_loss: 0.4623 - val_accuracy: 0.8181\n",
      "Epoch 167/1000\n",
      "239/239 [==============================] - 0s 2ms/step - loss: 0.4951 - accuracy: 0.8043 - val_loss: 0.4587 - val_accuracy: 0.8195\n",
      "Epoch 168/1000\n",
      "239/239 [==============================] - 0s 2ms/step - loss: 0.4904 - accuracy: 0.8075 - val_loss: 0.4571 - val_accuracy: 0.8203\n",
      "Epoch 169/1000\n",
      "239/239 [==============================] - 0s 2ms/step - loss: 0.4895 - accuracy: 0.8065 - val_loss: 0.4583 - val_accuracy: 0.8212\n",
      "Epoch 170/1000\n",
      "239/239 [==============================] - 0s 2ms/step - loss: 0.4948 - accuracy: 0.8050 - val_loss: 0.4659 - val_accuracy: 0.8180\n",
      "Epoch 171/1000\n",
      "239/239 [==============================] - 0s 2ms/step - loss: 0.4976 - accuracy: 0.8037 - val_loss: 0.4631 - val_accuracy: 0.8166\n",
      "Epoch 172/1000\n",
      "239/239 [==============================] - 0s 2ms/step - loss: 0.5044 - accuracy: 0.8013 - val_loss: 0.4664 - val_accuracy: 0.8164\n",
      "Epoch 173/1000\n",
      "239/239 [==============================] - 0s 2ms/step - loss: 0.5117 - accuracy: 0.7976 - val_loss: 0.4743 - val_accuracy: 0.8127\n",
      "Epoch 174/1000\n",
      "239/239 [==============================] - 0s 2ms/step - loss: 0.5178 - accuracy: 0.7947 - val_loss: 0.4753 - val_accuracy: 0.8132\n",
      "Epoch 175/1000\n",
      "239/239 [==============================] - 0s 2ms/step - loss: 0.5226 - accuracy: 0.7945 - val_loss: 0.4828 - val_accuracy: 0.8104\n",
      "Epoch 176/1000\n",
      "239/239 [==============================] - 0s 2ms/step - loss: 0.5256 - accuracy: 0.7922 - val_loss: 0.4882 - val_accuracy: 0.8073\n",
      "Epoch 177/1000\n",
      "239/239 [==============================] - 0s 2ms/step - loss: 0.5275 - accuracy: 0.7917 - val_loss: 0.4835 - val_accuracy: 0.8089\n",
      "Epoch 178/1000\n",
      "239/239 [==============================] - 0s 2ms/step - loss: 0.5224 - accuracy: 0.7925 - val_loss: 0.4800 - val_accuracy: 0.8109\n",
      "Epoch 179/1000\n",
      "239/239 [==============================] - 0s 2ms/step - loss: 0.5176 - accuracy: 0.7959 - val_loss: 0.4758 - val_accuracy: 0.8118\n",
      "Epoch 180/1000\n",
      "239/239 [==============================] - 0s 2ms/step - loss: 0.5168 - accuracy: 0.7956 - val_loss: 0.4719 - val_accuracy: 0.8166\n",
      "Epoch 181/1000\n",
      "239/239 [==============================] - 0s 2ms/step - loss: 0.5081 - accuracy: 0.7987 - val_loss: 0.4688 - val_accuracy: 0.8181\n",
      "Epoch 182/1000\n",
      "239/239 [==============================] - 0s 2ms/step - loss: 0.5030 - accuracy: 0.8023 - val_loss: 0.4639 - val_accuracy: 0.8181\n",
      "Epoch 183/1000\n",
      "239/239 [==============================] - 1s 2ms/step - loss: 0.4993 - accuracy: 0.8041 - val_loss: 0.4624 - val_accuracy: 0.8180\n",
      "Epoch 184/1000\n",
      "239/239 [==============================] - 0s 2ms/step - loss: 0.4923 - accuracy: 0.8058 - val_loss: 0.4558 - val_accuracy: 0.8215\n",
      "Epoch 185/1000\n",
      "239/239 [==============================] - 0s 2ms/step - loss: 0.4878 - accuracy: 0.8079 - val_loss: 0.4546 - val_accuracy: 0.8226\n",
      "Epoch 186/1000\n",
      "239/239 [==============================] - 0s 2ms/step - loss: 0.4896 - accuracy: 0.8075 - val_loss: 0.4572 - val_accuracy: 0.8209\n",
      "Epoch 187/1000\n",
      "239/239 [==============================] - 0s 2ms/step - loss: 0.4927 - accuracy: 0.8053 - val_loss: 0.4618 - val_accuracy: 0.8182\n",
      "Epoch 188/1000\n",
      "239/239 [==============================] - 0s 2ms/step - loss: 0.4969 - accuracy: 0.8049 - val_loss: 0.4656 - val_accuracy: 0.8163\n",
      "Epoch 189/1000\n",
      "239/239 [==============================] - 0s 2ms/step - loss: 0.5037 - accuracy: 0.8016 - val_loss: 0.4730 - val_accuracy: 0.8149\n",
      "Epoch 190/1000\n",
      "239/239 [==============================] - 0s 2ms/step - loss: 0.5092 - accuracy: 0.7992 - val_loss: 0.4686 - val_accuracy: 0.8155\n",
      "Epoch 191/1000\n",
      "239/239 [==============================] - 1s 2ms/step - loss: 0.5152 - accuracy: 0.7968 - val_loss: 0.4785 - val_accuracy: 0.8140\n",
      "Epoch 192/1000\n",
      "239/239 [==============================] - 0s 2ms/step - loss: 0.5210 - accuracy: 0.7948 - val_loss: 0.4857 - val_accuracy: 0.8116\n",
      "Epoch 193/1000\n",
      "239/239 [==============================] - 0s 2ms/step - loss: 0.5277 - accuracy: 0.7925 - val_loss: 0.4874 - val_accuracy: 0.8090\n",
      "Epoch 194/1000\n",
      "239/239 [==============================] - 0s 2ms/step - loss: 0.5263 - accuracy: 0.7930 - val_loss: 0.4874 - val_accuracy: 0.8094\n",
      "Epoch 195/1000\n",
      "239/239 [==============================] - 0s 2ms/step - loss: 0.5204 - accuracy: 0.7960 - val_loss: 0.4807 - val_accuracy: 0.8110\n",
      "Epoch 196/1000\n",
      "239/239 [==============================] - 0s 2ms/step - loss: 0.5135 - accuracy: 0.7974 - val_loss: 0.4709 - val_accuracy: 0.8164\n",
      "Epoch 197/1000\n",
      "239/239 [==============================] - 0s 2ms/step - loss: 0.5068 - accuracy: 0.8014 - val_loss: 0.4701 - val_accuracy: 0.8146\n",
      "Epoch 198/1000\n",
      "239/239 [==============================] - 0s 2ms/step - loss: 0.5039 - accuracy: 0.8024 - val_loss: 0.4620 - val_accuracy: 0.8183\n",
      "Epoch 199/1000\n",
      "239/239 [==============================] - 0s 2ms/step - loss: 0.4979 - accuracy: 0.8046 - val_loss: 0.4604 - val_accuracy: 0.8194\n",
      "Epoch 200/1000\n",
      "239/239 [==============================] - 0s 2ms/step - loss: 0.4944 - accuracy: 0.8045 - val_loss: 0.4587 - val_accuracy: 0.8203\n",
      "Epoch 201/1000\n",
      "239/239 [==============================] - 0s 2ms/step - loss: 0.4891 - accuracy: 0.8074 - val_loss: 0.4571 - val_accuracy: 0.8193\n",
      "Epoch 202/1000\n",
      "239/239 [==============================] - 0s 2ms/step - loss: 0.4859 - accuracy: 0.8088 - val_loss: 0.4542 - val_accuracy: 0.8213\n",
      "Epoch 203/1000\n",
      "239/239 [==============================] - 0s 2ms/step - loss: 0.4881 - accuracy: 0.8077 - val_loss: 0.4581 - val_accuracy: 0.8222\n",
      "Epoch 204/1000\n",
      "239/239 [==============================] - 0s 2ms/step - loss: 0.4937 - accuracy: 0.8066 - val_loss: 0.4604 - val_accuracy: 0.8197\n",
      "Epoch 205/1000\n",
      "239/239 [==============================] - 0s 2ms/step - loss: 0.4988 - accuracy: 0.8039 - val_loss: 0.4691 - val_accuracy: 0.8149\n",
      "Epoch 206/1000\n",
      "239/239 [==============================] - 0s 2ms/step - loss: 0.5055 - accuracy: 0.7999 - val_loss: 0.4707 - val_accuracy: 0.8152\n",
      "Epoch 207/1000\n",
      "239/239 [==============================] - 0s 2ms/step - loss: 0.5108 - accuracy: 0.7989 - val_loss: 0.4697 - val_accuracy: 0.8189\n",
      "Epoch 208/1000\n",
      "239/239 [==============================] - 0s 2ms/step - loss: 0.5114 - accuracy: 0.7985 - val_loss: 0.4731 - val_accuracy: 0.8128\n",
      "Epoch 209/1000\n",
      "239/239 [==============================] - 1s 2ms/step - loss: 0.5209 - accuracy: 0.7955 - val_loss: 0.4832 - val_accuracy: 0.8084\n",
      "Epoch 210/1000\n",
      "239/239 [==============================] - 0s 2ms/step - loss: 0.5276 - accuracy: 0.7907 - val_loss: 0.4872 - val_accuracy: 0.8065\n",
      "Epoch 211/1000\n",
      "239/239 [==============================] - 0s 2ms/step - loss: 0.5232 - accuracy: 0.7931 - val_loss: 0.4838 - val_accuracy: 0.8097\n",
      "Epoch 212/1000\n",
      "239/239 [==============================] - 0s 2ms/step - loss: 0.5151 - accuracy: 0.7958 - val_loss: 0.4795 - val_accuracy: 0.8126\n",
      "Epoch 213/1000\n",
      "239/239 [==============================] - 0s 2ms/step - loss: 0.5124 - accuracy: 0.7979 - val_loss: 0.4705 - val_accuracy: 0.8149\n",
      "Epoch 214/1000\n",
      "239/239 [==============================] - 0s 2ms/step - loss: 0.5123 - accuracy: 0.7968 - val_loss: 0.4697 - val_accuracy: 0.8132\n",
      "Epoch 215/1000\n",
      "239/239 [==============================] - 0s 2ms/step - loss: 0.5037 - accuracy: 0.8014 - val_loss: 0.4678 - val_accuracy: 0.8177\n",
      "Epoch 216/1000\n",
      "239/239 [==============================] - 0s 2ms/step - loss: 0.4986 - accuracy: 0.8042 - val_loss: 0.4619 - val_accuracy: 0.8169\n",
      "Epoch 217/1000\n",
      "239/239 [==============================] - 0s 2ms/step - loss: 0.4947 - accuracy: 0.8047 - val_loss: 0.4564 - val_accuracy: 0.8212\n",
      "Epoch 218/1000\n",
      "239/239 [==============================] - 0s 2ms/step - loss: 0.4884 - accuracy: 0.8077 - val_loss: 0.4563 - val_accuracy: 0.8206\n",
      "Epoch 219/1000\n",
      "239/239 [==============================] - 0s 2ms/step - loss: 0.4889 - accuracy: 0.8075 - val_loss: 0.4544 - val_accuracy: 0.8240\n",
      "Epoch 220/1000\n",
      "239/239 [==============================] - 0s 2ms/step - loss: 0.4909 - accuracy: 0.8066 - val_loss: 0.4575 - val_accuracy: 0.8208\n",
      "Epoch 221/1000\n",
      "239/239 [==============================] - 0s 2ms/step - loss: 0.4931 - accuracy: 0.8053 - val_loss: 0.4602 - val_accuracy: 0.8198\n",
      "Epoch 222/1000\n",
      "239/239 [==============================] - 0s 2ms/step - loss: 0.5004 - accuracy: 0.8022 - val_loss: 0.4663 - val_accuracy: 0.8152\n",
      "Epoch 223/1000\n",
      "239/239 [==============================] - 0s 2ms/step - loss: 0.5001 - accuracy: 0.8023 - val_loss: 0.4702 - val_accuracy: 0.8137\n",
      "Epoch 224/1000\n",
      "239/239 [==============================] - 1s 2ms/step - loss: 0.5049 - accuracy: 0.8010 - val_loss: 0.4678 - val_accuracy: 0.8178\n",
      "Epoch 225/1000\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "239/239 [==============================] - 0s 2ms/step - loss: 0.5133 - accuracy: 0.7975 - val_loss: 0.4740 - val_accuracy: 0.8141\n",
      "Epoch 226/1000\n",
      "239/239 [==============================] - 0s 2ms/step - loss: 0.5233 - accuracy: 0.7939 - val_loss: 0.4868 - val_accuracy: 0.8085\n",
      "Epoch 227/1000\n",
      "239/239 [==============================] - 0s 2ms/step - loss: 0.5250 - accuracy: 0.7931 - val_loss: 0.4821 - val_accuracy: 0.8113\n",
      "Epoch 228/1000\n",
      "239/239 [==============================] - 0s 2ms/step - loss: 0.5177 - accuracy: 0.7957 - val_loss: 0.4770 - val_accuracy: 0.8156\n",
      "Epoch 229/1000\n",
      "239/239 [==============================] - 0s 2ms/step - loss: 0.5101 - accuracy: 0.7984 - val_loss: 0.4714 - val_accuracy: 0.8147\n",
      "Epoch 230/1000\n",
      "239/239 [==============================] - 0s 2ms/step - loss: 0.5078 - accuracy: 0.8000 - val_loss: 0.4640 - val_accuracy: 0.8182\n",
      "Epoch 231/1000\n",
      "239/239 [==============================] - 0s 2ms/step - loss: 0.5019 - accuracy: 0.8017 - val_loss: 0.4623 - val_accuracy: 0.8180\n",
      "Epoch 232/1000\n",
      "239/239 [==============================] - 0s 2ms/step - loss: 0.4961 - accuracy: 0.8048 - val_loss: 0.4606 - val_accuracy: 0.8189\n",
      "Epoch 233/1000\n",
      "239/239 [==============================] - 0s 2ms/step - loss: 0.4950 - accuracy: 0.8056 - val_loss: 0.4547 - val_accuracy: 0.8225\n",
      "Epoch 234/1000\n",
      "239/239 [==============================] - 0s 2ms/step - loss: 0.4863 - accuracy: 0.8086 - val_loss: 0.4570 - val_accuracy: 0.8210\n",
      "Epoch 235/1000\n",
      "239/239 [==============================] - 0s 2ms/step - loss: 0.4862 - accuracy: 0.8092 - val_loss: 0.4528 - val_accuracy: 0.8230\n",
      "Epoch 236/1000\n",
      "239/239 [==============================] - 0s 2ms/step - loss: 0.4862 - accuracy: 0.8080 - val_loss: 0.4574 - val_accuracy: 0.8223\n",
      "Epoch 237/1000\n",
      "239/239 [==============================] - 0s 2ms/step - loss: 0.4877 - accuracy: 0.8076 - val_loss: 0.4601 - val_accuracy: 0.8223\n",
      "Epoch 238/1000\n",
      "239/239 [==============================] - 0s 2ms/step - loss: 0.4931 - accuracy: 0.8064 - val_loss: 0.4666 - val_accuracy: 0.8196\n",
      "Epoch 239/1000\n",
      "239/239 [==============================] - 0s 2ms/step - loss: 0.4967 - accuracy: 0.8039 - val_loss: 0.4631 - val_accuracy: 0.8212\n",
      "Epoch 240/1000\n",
      "239/239 [==============================] - 0s 2ms/step - loss: 0.5027 - accuracy: 0.8021 - val_loss: 0.4703 - val_accuracy: 0.8155\n",
      "Epoch 241/1000\n",
      "239/239 [==============================] - 0s 2ms/step - loss: 0.5084 - accuracy: 0.7991 - val_loss: 0.4748 - val_accuracy: 0.8132\n",
      "Epoch 242/1000\n",
      "239/239 [==============================] - 0s 2ms/step - loss: 0.5178 - accuracy: 0.7956 - val_loss: 0.4740 - val_accuracy: 0.8142\n",
      "Epoch 243/1000\n",
      "239/239 [==============================] - 0s 2ms/step - loss: 0.5270 - accuracy: 0.7913 - val_loss: 0.4886 - val_accuracy: 0.8079\n",
      "Epoch 244/1000\n",
      "239/239 [==============================] - 0s 2ms/step - loss: 0.5243 - accuracy: 0.7927 - val_loss: 0.4811 - val_accuracy: 0.8139\n",
      "Epoch 245/1000\n",
      "239/239 [==============================] - 0s 2ms/step - loss: 0.5170 - accuracy: 0.7965 - val_loss: 0.4739 - val_accuracy: 0.8133\n",
      "Epoch 246/1000\n",
      "239/239 [==============================] - 0s 2ms/step - loss: 0.5154 - accuracy: 0.7970 - val_loss: 0.4748 - val_accuracy: 0.8149\n",
      "Epoch 247/1000\n",
      "239/239 [==============================] - 0s 2ms/step - loss: 0.5088 - accuracy: 0.7997 - val_loss: 0.4664 - val_accuracy: 0.8166\n",
      "Epoch 248/1000\n",
      "239/239 [==============================] - 1s 2ms/step - loss: 0.5042 - accuracy: 0.8021 - val_loss: 0.4628 - val_accuracy: 0.8196\n",
      "Epoch 249/1000\n",
      "239/239 [==============================] - 0s 2ms/step - loss: 0.4975 - accuracy: 0.8030 - val_loss: 0.4614 - val_accuracy: 0.8183\n",
      "Epoch 250/1000\n",
      "239/239 [==============================] - 0s 2ms/step - loss: 0.4920 - accuracy: 0.8061 - val_loss: 0.4575 - val_accuracy: 0.8201\n",
      "Epoch 251/1000\n",
      "239/239 [==============================] - 0s 2ms/step - loss: 0.4874 - accuracy: 0.8071 - val_loss: 0.4529 - val_accuracy: 0.8231\n",
      "Epoch 252/1000\n",
      "239/239 [==============================] - 0s 2ms/step - loss: 0.4848 - accuracy: 0.8093 - val_loss: 0.4535 - val_accuracy: 0.8232\n",
      "Epoch 253/1000\n",
      "239/239 [==============================] - 0s 2ms/step - loss: 0.4868 - accuracy: 0.8087 - val_loss: 0.4555 - val_accuracy: 0.8213\n",
      "Epoch 254/1000\n",
      "239/239 [==============================] - 0s 2ms/step - loss: 0.4894 - accuracy: 0.8073 - val_loss: 0.4553 - val_accuracy: 0.8201\n",
      "Epoch 255/1000\n",
      "239/239 [==============================] - 0s 2ms/step - loss: 0.4918 - accuracy: 0.8067 - val_loss: 0.4560 - val_accuracy: 0.8206\n",
      "Epoch 256/1000\n",
      "239/239 [==============================] - 0s 2ms/step - loss: 0.4997 - accuracy: 0.8034 - val_loss: 0.4622 - val_accuracy: 0.8197\n",
      "Epoch 257/1000\n",
      "239/239 [==============================] - 0s 2ms/step - loss: 0.5014 - accuracy: 0.8021 - val_loss: 0.4686 - val_accuracy: 0.8163\n",
      "Epoch 258/1000\n",
      "239/239 [==============================] - 0s 2ms/step - loss: 0.5069 - accuracy: 0.8010 - val_loss: 0.4757 - val_accuracy: 0.8182\n",
      "Epoch 259/1000\n",
      "239/239 [==============================] - 0s 2ms/step - loss: 0.5101 - accuracy: 0.7994 - val_loss: 0.4660 - val_accuracy: 0.8149\n",
      "Epoch 260/1000\n",
      "239/239 [==============================] - 0s 2ms/step - loss: 0.5208 - accuracy: 0.7940 - val_loss: 0.4807 - val_accuracy: 0.8129\n",
      "Epoch 261/1000\n",
      "239/239 [==============================] - 0s 2ms/step - loss: 0.5239 - accuracy: 0.7923 - val_loss: 0.4866 - val_accuracy: 0.8121\n",
      "Epoch 262/1000\n",
      "239/239 [==============================] - 0s 2ms/step - loss: 0.5195 - accuracy: 0.7945 - val_loss: 0.4776 - val_accuracy: 0.8101\n",
      "Epoch 263/1000\n",
      "239/239 [==============================] - 0s 2ms/step - loss: 0.5134 - accuracy: 0.7987 - val_loss: 0.4721 - val_accuracy: 0.8180\n",
      "Epoch 264/1000\n",
      "239/239 [==============================] - 0s 2ms/step - loss: 0.5063 - accuracy: 0.8011 - val_loss: 0.4665 - val_accuracy: 0.8156\n",
      "Epoch 265/1000\n",
      "239/239 [==============================] - 0s 2ms/step - loss: 0.4990 - accuracy: 0.8040 - val_loss: 0.4583 - val_accuracy: 0.8214\n",
      "Epoch 266/1000\n",
      "239/239 [==============================] - 0s 2ms/step - loss: 0.4963 - accuracy: 0.8042 - val_loss: 0.4603 - val_accuracy: 0.8200\n",
      "Epoch 267/1000\n",
      "239/239 [==============================] - 0s 2ms/step - loss: 0.4892 - accuracy: 0.8072 - val_loss: 0.4540 - val_accuracy: 0.8220\n",
      "Epoch 268/1000\n",
      "239/239 [==============================] - 0s 2ms/step - loss: 0.4842 - accuracy: 0.8089 - val_loss: 0.4527 - val_accuracy: 0.8220\n",
      "Epoch 269/1000\n",
      "239/239 [==============================] - 0s 2ms/step - loss: 0.4845 - accuracy: 0.8097 - val_loss: 0.4514 - val_accuracy: 0.8246\n",
      "Epoch 270/1000\n",
      "239/239 [==============================] - 0s 2ms/step - loss: 0.4853 - accuracy: 0.8091 - val_loss: 0.4550 - val_accuracy: 0.8213\n",
      "Epoch 271/1000\n",
      "239/239 [==============================] - 0s 2ms/step - loss: 0.4877 - accuracy: 0.8088 - val_loss: 0.4560 - val_accuracy: 0.8225\n",
      "Epoch 272/1000\n",
      "239/239 [==============================] - 0s 2ms/step - loss: 0.4925 - accuracy: 0.8053 - val_loss: 0.4576 - val_accuracy: 0.8217\n",
      "Epoch 273/1000\n",
      "239/239 [==============================] - 0s 2ms/step - loss: 0.4993 - accuracy: 0.8033 - val_loss: 0.4668 - val_accuracy: 0.8182\n",
      "Epoch 274/1000\n",
      "239/239 [==============================] - 0s 2ms/step - loss: 0.5058 - accuracy: 0.8020 - val_loss: 0.4691 - val_accuracy: 0.8193\n",
      "Epoch 275/1000\n",
      "239/239 [==============================] - 1s 2ms/step - loss: 0.5059 - accuracy: 0.8001 - val_loss: 0.4733 - val_accuracy: 0.8173\n",
      "Epoch 276/1000\n",
      "239/239 [==============================] - 0s 2ms/step - loss: 0.5144 - accuracy: 0.7974 - val_loss: 0.4806 - val_accuracy: 0.8132\n",
      "Epoch 277/1000\n",
      "239/239 [==============================] - 0s 2ms/step - loss: 0.5185 - accuracy: 0.7956 - val_loss: 0.4756 - val_accuracy: 0.8124\n",
      "Epoch 278/1000\n",
      "239/239 [==============================] - 0s 2ms/step - loss: 0.5188 - accuracy: 0.7970 - val_loss: 0.4801 - val_accuracy: 0.8110\n",
      "Epoch 279/1000\n",
      "239/239 [==============================] - 0s 2ms/step - loss: 0.5145 - accuracy: 0.7977 - val_loss: 0.4709 - val_accuracy: 0.8174\n",
      "Epoch 280/1000\n",
      "239/239 [==============================] - 0s 2ms/step - loss: 0.5109 - accuracy: 0.7993 - val_loss: 0.4644 - val_accuracy: 0.8201\n",
      "Epoch 281/1000\n",
      "239/239 [==============================] - 0s 2ms/step - loss: 0.5053 - accuracy: 0.8014 - val_loss: 0.4629 - val_accuracy: 0.8198\n",
      "Epoch 282/1000\n",
      "239/239 [==============================] - 0s 2ms/step - loss: 0.4991 - accuracy: 0.8038 - val_loss: 0.4561 - val_accuracy: 0.8214\n",
      "Epoch 283/1000\n",
      "239/239 [==============================] - 0s 2ms/step - loss: 0.4943 - accuracy: 0.8062 - val_loss: 0.4532 - val_accuracy: 0.8228\n",
      "Epoch 284/1000\n",
      "239/239 [==============================] - 0s 2ms/step - loss: 0.4884 - accuracy: 0.8079 - val_loss: 0.4508 - val_accuracy: 0.8245\n",
      "Epoch 285/1000\n",
      "239/239 [==============================] - 0s 2ms/step - loss: 0.4819 - accuracy: 0.8096 - val_loss: 0.4492 - val_accuracy: 0.8242\n",
      "Epoch 286/1000\n",
      "239/239 [==============================] - 0s 2ms/step - loss: 0.4816 - accuracy: 0.8102 - val_loss: 0.4519 - val_accuracy: 0.8225\n",
      "Epoch 287/1000\n",
      "239/239 [==============================] - 0s 2ms/step - loss: 0.4851 - accuracy: 0.8101 - val_loss: 0.4542 - val_accuracy: 0.8234\n",
      "Epoch 288/1000\n",
      "239/239 [==============================] - 0s 2ms/step - loss: 0.4902 - accuracy: 0.8091 - val_loss: 0.4577 - val_accuracy: 0.8223\n",
      "Epoch 289/1000\n",
      "239/239 [==============================] - 0s 2ms/step - loss: 0.4927 - accuracy: 0.8075 - val_loss: 0.4584 - val_accuracy: 0.8216\n",
      "Epoch 290/1000\n",
      "239/239 [==============================] - 0s 2ms/step - loss: 0.4956 - accuracy: 0.8048 - val_loss: 0.4601 - val_accuracy: 0.8225\n",
      "Epoch 291/1000\n",
      "239/239 [==============================] - 1s 2ms/step - loss: 0.5026 - accuracy: 0.8027 - val_loss: 0.4686 - val_accuracy: 0.8164\n",
      "Epoch 292/1000\n",
      "239/239 [==============================] - 0s 2ms/step - loss: 0.5135 - accuracy: 0.7985 - val_loss: 0.4751 - val_accuracy: 0.8156\n",
      "Epoch 293/1000\n",
      "239/239 [==============================] - 0s 2ms/step - loss: 0.5250 - accuracy: 0.7921 - val_loss: 0.4795 - val_accuracy: 0.8152\n",
      "Epoch 294/1000\n",
      "239/239 [==============================] - 0s 2ms/step - loss: 0.5192 - accuracy: 0.7967 - val_loss: 0.4752 - val_accuracy: 0.8118\n",
      "Epoch 295/1000\n",
      "239/239 [==============================] - 0s 2ms/step - loss: 0.5196 - accuracy: 0.7955 - val_loss: 0.4790 - val_accuracy: 0.8149\n",
      "Epoch 296/1000\n",
      "239/239 [==============================] - 1s 2ms/step - loss: 0.5174 - accuracy: 0.7968 - val_loss: 0.4767 - val_accuracy: 0.8166\n",
      "Epoch 297/1000\n",
      "239/239 [==============================] - 0s 2ms/step - loss: 0.5128 - accuracy: 0.7981 - val_loss: 0.4670 - val_accuracy: 0.8179\n",
      "Epoch 298/1000\n",
      "239/239 [==============================] - 0s 2ms/step - loss: 0.5038 - accuracy: 0.8023 - val_loss: 0.4633 - val_accuracy: 0.8207\n",
      "Epoch 299/1000\n",
      "239/239 [==============================] - 0s 2ms/step - loss: 0.4945 - accuracy: 0.8059 - val_loss: 0.4598 - val_accuracy: 0.8231\n",
      "Epoch 300/1000\n",
      "239/239 [==============================] - 0s 2ms/step - loss: 0.4910 - accuracy: 0.8080 - val_loss: 0.4535 - val_accuracy: 0.8260\n",
      "Epoch 301/1000\n",
      "239/239 [==============================] - 0s 2ms/step - loss: 0.4849 - accuracy: 0.8101 - val_loss: 0.4521 - val_accuracy: 0.8256\n",
      "Epoch 302/1000\n",
      "239/239 [==============================] - 0s 2ms/step - loss: 0.4817 - accuracy: 0.8121 - val_loss: 0.4508 - val_accuracy: 0.8257\n",
      "Epoch 303/1000\n",
      "239/239 [==============================] - 0s 2ms/step - loss: 0.4805 - accuracy: 0.8115 - val_loss: 0.4533 - val_accuracy: 0.8238\n",
      "Epoch 304/1000\n",
      "239/239 [==============================] - 0s 2ms/step - loss: 0.4854 - accuracy: 0.8093 - val_loss: 0.4538 - val_accuracy: 0.8240\n",
      "Epoch 305/1000\n",
      "239/239 [==============================] - 0s 2ms/step - loss: 0.4888 - accuracy: 0.8082 - val_loss: 0.4550 - val_accuracy: 0.8251\n",
      "Epoch 306/1000\n",
      "239/239 [==============================] - 0s 2ms/step - loss: 0.4907 - accuracy: 0.8070 - val_loss: 0.4567 - val_accuracy: 0.8235\n",
      "Epoch 307/1000\n",
      "239/239 [==============================] - 0s 2ms/step - loss: 0.5009 - accuracy: 0.8022 - val_loss: 0.4677 - val_accuracy: 0.8180\n",
      "Epoch 308/1000\n",
      "239/239 [==============================] - 0s 2ms/step - loss: 0.5041 - accuracy: 0.8013 - val_loss: 0.4758 - val_accuracy: 0.8170\n",
      "Epoch 309/1000\n",
      "239/239 [==============================] - 0s 2ms/step - loss: 0.5113 - accuracy: 0.7989 - val_loss: 0.4803 - val_accuracy: 0.8135\n",
      "Epoch 310/1000\n",
      "239/239 [==============================] - 0s 2ms/step - loss: 0.5240 - accuracy: 0.7936 - val_loss: 0.4749 - val_accuracy: 0.8133\n",
      "Epoch 311/1000\n",
      "239/239 [==============================] - 0s 2ms/step - loss: 0.5170 - accuracy: 0.7964 - val_loss: 0.4788 - val_accuracy: 0.8172\n",
      "Epoch 312/1000\n",
      "239/239 [==============================] - 0s 2ms/step - loss: 0.5179 - accuracy: 0.7956 - val_loss: 0.4808 - val_accuracy: 0.8129\n",
      "Epoch 313/1000\n",
      "239/239 [==============================] - 0s 2ms/step - loss: 0.5106 - accuracy: 0.8001 - val_loss: 0.4666 - val_accuracy: 0.8199\n",
      "Epoch 314/1000\n",
      "239/239 [==============================] - 0s 2ms/step - loss: 0.5045 - accuracy: 0.8018 - val_loss: 0.4672 - val_accuracy: 0.8177\n",
      "Epoch 315/1000\n",
      "239/239 [==============================] - 0s 2ms/step - loss: 0.5036 - accuracy: 0.8023 - val_loss: 0.4614 - val_accuracy: 0.8223\n",
      "Epoch 316/1000\n",
      "239/239 [==============================] - 0s 2ms/step - loss: 0.4966 - accuracy: 0.8039 - val_loss: 0.4579 - val_accuracy: 0.8205\n",
      "Epoch 317/1000\n",
      "239/239 [==============================] - 0s 2ms/step - loss: 0.4920 - accuracy: 0.8071 - val_loss: 0.4523 - val_accuracy: 0.8250\n",
      "Epoch 318/1000\n",
      "239/239 [==============================] - 0s 2ms/step - loss: 0.4862 - accuracy: 0.8080 - val_loss: 0.4490 - val_accuracy: 0.8258\n",
      "Epoch 319/1000\n",
      "239/239 [==============================] - 0s 2ms/step - loss: 0.4836 - accuracy: 0.8099 - val_loss: 0.4481 - val_accuracy: 0.8258\n",
      "Epoch 320/1000\n",
      "239/239 [==============================] - 1s 2ms/step - loss: 0.4838 - accuracy: 0.8096 - val_loss: 0.4507 - val_accuracy: 0.8245\n",
      "Epoch 321/1000\n",
      "239/239 [==============================] - 0s 2ms/step - loss: 0.4866 - accuracy: 0.8099 - val_loss: 0.4525 - val_accuracy: 0.8243\n",
      "Epoch 322/1000\n",
      "239/239 [==============================] - 0s 2ms/step - loss: 0.4907 - accuracy: 0.8070 - val_loss: 0.4569 - val_accuracy: 0.8217\n",
      "Epoch 323/1000\n",
      "239/239 [==============================] - 0s 2ms/step - loss: 0.4961 - accuracy: 0.8056 - val_loss: 0.4641 - val_accuracy: 0.8183\n",
      "Epoch 324/1000\n",
      "239/239 [==============================] - 0s 2ms/step - loss: 0.5021 - accuracy: 0.8033 - val_loss: 0.4661 - val_accuracy: 0.8191\n",
      "Epoch 325/1000\n",
      "239/239 [==============================] - 0s 2ms/step - loss: 0.5061 - accuracy: 0.8010 - val_loss: 0.4730 - val_accuracy: 0.8169\n",
      "Epoch 326/1000\n",
      "239/239 [==============================] - 0s 2ms/step - loss: 0.5126 - accuracy: 0.7986 - val_loss: 0.4741 - val_accuracy: 0.8122\n",
      "Epoch 327/1000\n",
      "239/239 [==============================] - 0s 2ms/step - loss: 0.5181 - accuracy: 0.7964 - val_loss: 0.4775 - val_accuracy: 0.8172\n",
      "Epoch 328/1000\n",
      "239/239 [==============================] - 0s 2ms/step - loss: 0.5181 - accuracy: 0.7972 - val_loss: 0.4774 - val_accuracy: 0.8099\n",
      "Epoch 329/1000\n",
      "239/239 [==============================] - 0s 2ms/step - loss: 0.5163 - accuracy: 0.7967 - val_loss: 0.4826 - val_accuracy: 0.8117\n",
      "Epoch 330/1000\n",
      "239/239 [==============================] - 0s 2ms/step - loss: 0.5076 - accuracy: 0.7990 - val_loss: 0.4688 - val_accuracy: 0.8161\n",
      "Epoch 331/1000\n",
      "239/239 [==============================] - 0s 2ms/step - loss: 0.5036 - accuracy: 0.8018 - val_loss: 0.4583 - val_accuracy: 0.8212\n",
      "Epoch 332/1000\n",
      "239/239 [==============================] - 0s 2ms/step - loss: 0.4976 - accuracy: 0.8045 - val_loss: 0.4607 - val_accuracy: 0.8194\n",
      "Epoch 333/1000\n",
      "239/239 [==============================] - 0s 2ms/step - loss: 0.4923 - accuracy: 0.8055 - val_loss: 0.4536 - val_accuracy: 0.8215\n",
      "Epoch 334/1000\n",
      "239/239 [==============================] - 0s 2ms/step - loss: 0.4856 - accuracy: 0.8082 - val_loss: 0.4506 - val_accuracy: 0.8219\n",
      "Epoch 335/1000\n",
      "239/239 [==============================] - 0s 2ms/step - loss: 0.4805 - accuracy: 0.8110 - val_loss: 0.4481 - val_accuracy: 0.8245\n",
      "Epoch 336/1000\n",
      "239/239 [==============================] - 0s 2ms/step - loss: 0.4812 - accuracy: 0.8107 - val_loss: 0.4472 - val_accuracy: 0.8264\n",
      "Epoch 337/1000\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "239/239 [==============================] - 0s 2ms/step - loss: 0.4805 - accuracy: 0.8117 - val_loss: 0.4512 - val_accuracy: 0.8250\n",
      "Epoch 338/1000\n",
      "239/239 [==============================] - 0s 2ms/step - loss: 0.4850 - accuracy: 0.8105 - val_loss: 0.4518 - val_accuracy: 0.8260\n",
      "Epoch 339/1000\n",
      "239/239 [==============================] - 0s 2ms/step - loss: 0.4914 - accuracy: 0.8070 - val_loss: 0.4531 - val_accuracy: 0.8246\n",
      "Epoch 340/1000\n",
      "239/239 [==============================] - 0s 2ms/step - loss: 0.4969 - accuracy: 0.8064 - val_loss: 0.4654 - val_accuracy: 0.8178\n",
      "Epoch 341/1000\n",
      "239/239 [==============================] - 0s 2ms/step - loss: 0.5036 - accuracy: 0.8038 - val_loss: 0.4664 - val_accuracy: 0.8183\n",
      "Epoch 342/1000\n",
      "239/239 [==============================] - 0s 2ms/step - loss: 0.5078 - accuracy: 0.8018 - val_loss: 0.4718 - val_accuracy: 0.8157\n",
      "Epoch 343/1000\n",
      "239/239 [==============================] - 0s 2ms/step - loss: 0.5122 - accuracy: 0.7987 - val_loss: 0.4756 - val_accuracy: 0.8149\n",
      "Epoch 344/1000\n",
      "239/239 [==============================] - 0s 2ms/step - loss: 0.5134 - accuracy: 0.7991 - val_loss: 0.4774 - val_accuracy: 0.8111\n",
      "Epoch 345/1000\n",
      "239/239 [==============================] - 0s 2ms/step - loss: 0.5135 - accuracy: 0.7987 - val_loss: 0.4753 - val_accuracy: 0.8163\n",
      "Epoch 346/1000\n",
      "239/239 [==============================] - 0s 2ms/step - loss: 0.5135 - accuracy: 0.7985 - val_loss: 0.4634 - val_accuracy: 0.8205\n",
      "Epoch 347/1000\n",
      "239/239 [==============================] - 0s 2ms/step - loss: 0.5043 - accuracy: 0.8015 - val_loss: 0.4675 - val_accuracy: 0.8183\n",
      "Epoch 348/1000\n",
      "239/239 [==============================] - 0s 2ms/step - loss: 0.5000 - accuracy: 0.8034 - val_loss: 0.4547 - val_accuracy: 0.8226\n",
      "Epoch 349/1000\n",
      "239/239 [==============================] - 0s 2ms/step - loss: 0.4946 - accuracy: 0.8062 - val_loss: 0.4567 - val_accuracy: 0.8220\n",
      "Epoch 350/1000\n",
      "239/239 [==============================] - 0s 2ms/step - loss: 0.4905 - accuracy: 0.8081 - val_loss: 0.4545 - val_accuracy: 0.8258\n",
      "Epoch 351/1000\n",
      "239/239 [==============================] - 0s 2ms/step - loss: 0.4855 - accuracy: 0.8089 - val_loss: 0.4500 - val_accuracy: 0.8279\n",
      "Epoch 352/1000\n",
      "239/239 [==============================] - 1s 2ms/step - loss: 0.4819 - accuracy: 0.8107 - val_loss: 0.4477 - val_accuracy: 0.8270\n",
      "Epoch 353/1000\n",
      "239/239 [==============================] - 0s 2ms/step - loss: 0.4815 - accuracy: 0.8123 - val_loss: 0.4503 - val_accuracy: 0.8260\n",
      "Epoch 354/1000\n",
      "239/239 [==============================] - 0s 2ms/step - loss: 0.4833 - accuracy: 0.8112 - val_loss: 0.4492 - val_accuracy: 0.8273\n",
      "Epoch 355/1000\n",
      "239/239 [==============================] - 0s 2ms/step - loss: 0.4856 - accuracy: 0.8099 - val_loss: 0.4522 - val_accuracy: 0.8233\n",
      "Epoch 356/1000\n",
      "239/239 [==============================] - 0s 2ms/step - loss: 0.4909 - accuracy: 0.8079 - val_loss: 0.4616 - val_accuracy: 0.8159\n",
      "Epoch 357/1000\n",
      "239/239 [==============================] - 1s 2ms/step - loss: 0.4949 - accuracy: 0.8064 - val_loss: 0.4681 - val_accuracy: 0.8197\n",
      "Epoch 358/1000\n",
      "239/239 [==============================] - 0s 2ms/step - loss: 0.5004 - accuracy: 0.8033 - val_loss: 0.4653 - val_accuracy: 0.8192\n",
      "Epoch 359/1000\n",
      "239/239 [==============================] - 0s 2ms/step - loss: 0.5064 - accuracy: 0.8005 - val_loss: 0.4640 - val_accuracy: 0.8178\n",
      "Epoch 360/1000\n",
      "239/239 [==============================] - 0s 2ms/step - loss: 0.5166 - accuracy: 0.7963 - val_loss: 0.4762 - val_accuracy: 0.8137\n",
      "Epoch 361/1000\n",
      "239/239 [==============================] - 0s 2ms/step - loss: 0.5223 - accuracy: 0.7936 - val_loss: 0.4767 - val_accuracy: 0.8122\n",
      "Epoch 362/1000\n",
      "239/239 [==============================] - 0s 2ms/step - loss: 0.5160 - accuracy: 0.7962 - val_loss: 0.4765 - val_accuracy: 0.8134\n",
      "Epoch 363/1000\n",
      "239/239 [==============================] - 0s 2ms/step - loss: 0.5127 - accuracy: 0.7987 - val_loss: 0.4706 - val_accuracy: 0.8201\n",
      "Epoch 364/1000\n",
      "239/239 [==============================] - 0s 2ms/step - loss: 0.5070 - accuracy: 0.8023 - val_loss: 0.4651 - val_accuracy: 0.8214\n",
      "Epoch 365/1000\n",
      "239/239 [==============================] - 0s 2ms/step - loss: 0.5014 - accuracy: 0.8042 - val_loss: 0.4657 - val_accuracy: 0.8189\n",
      "Epoch 366/1000\n",
      "239/239 [==============================] - 0s 2ms/step - loss: 0.4952 - accuracy: 0.8068 - val_loss: 0.4588 - val_accuracy: 0.8210\n",
      "Epoch 367/1000\n",
      "239/239 [==============================] - 0s 2ms/step - loss: 0.4889 - accuracy: 0.8086 - val_loss: 0.4573 - val_accuracy: 0.8235\n",
      "Epoch 368/1000\n",
      "239/239 [==============================] - 0s 2ms/step - loss: 0.4860 - accuracy: 0.8106 - val_loss: 0.4511 - val_accuracy: 0.8258\n",
      "Epoch 369/1000\n",
      "239/239 [==============================] - 0s 2ms/step - loss: 0.4842 - accuracy: 0.8110 - val_loss: 0.4522 - val_accuracy: 0.8254\n",
      "Epoch 370/1000\n",
      "239/239 [==============================] - 0s 2ms/step - loss: 0.4840 - accuracy: 0.8117 - val_loss: 0.4540 - val_accuracy: 0.8228\n",
      "Epoch 371/1000\n",
      "239/239 [==============================] - 0s 2ms/step - loss: 0.4840 - accuracy: 0.8111 - val_loss: 0.4537 - val_accuracy: 0.8231\n",
      "Epoch 372/1000\n",
      "239/239 [==============================] - 0s 2ms/step - loss: 0.4852 - accuracy: 0.8108 - val_loss: 0.4525 - val_accuracy: 0.8242\n",
      "Epoch 373/1000\n",
      "239/239 [==============================] - 0s 2ms/step - loss: 0.4883 - accuracy: 0.8093 - val_loss: 0.4559 - val_accuracy: 0.8253\n",
      "Epoch 374/1000\n",
      "239/239 [==============================] - 0s 2ms/step - loss: 0.4954 - accuracy: 0.8070 - val_loss: 0.4635 - val_accuracy: 0.8192\n",
      "Epoch 375/1000\n",
      "239/239 [==============================] - 0s 2ms/step - loss: 0.5066 - accuracy: 0.8016 - val_loss: 0.4700 - val_accuracy: 0.8172\n",
      "Epoch 376/1000\n",
      "239/239 [==============================] - 0s 2ms/step - loss: 0.5123 - accuracy: 0.8001 - val_loss: 0.4689 - val_accuracy: 0.8204\n",
      "Epoch 377/1000\n",
      "239/239 [==============================] - 0s 2ms/step - loss: 0.5138 - accuracy: 0.7988 - val_loss: 0.4755 - val_accuracy: 0.8118\n",
      "Epoch 378/1000\n",
      "239/239 [==============================] - 1s 2ms/step - loss: 0.5126 - accuracy: 0.7984 - val_loss: 0.4683 - val_accuracy: 0.8189\n",
      "Epoch 379/1000\n",
      "239/239 [==============================] - 0s 2ms/step - loss: 0.5129 - accuracy: 0.7992 - val_loss: 0.4762 - val_accuracy: 0.8127\n",
      "Epoch 380/1000\n",
      "239/239 [==============================] - 0s 2ms/step - loss: 0.5090 - accuracy: 0.8007 - val_loss: 0.4771 - val_accuracy: 0.8132\n",
      "Epoch 381/1000\n",
      "239/239 [==============================] - 0s 2ms/step - loss: 0.5054 - accuracy: 0.8017 - val_loss: 0.4674 - val_accuracy: 0.8149\n",
      "Epoch 382/1000\n",
      "239/239 [==============================] - 1s 2ms/step - loss: 0.4995 - accuracy: 0.8038 - val_loss: 0.4691 - val_accuracy: 0.8201\n",
      "Epoch 383/1000\n",
      "239/239 [==============================] - 1s 2ms/step - loss: 0.4940 - accuracy: 0.8048 - val_loss: 0.4602 - val_accuracy: 0.8210\n",
      "Epoch 384/1000\n",
      "239/239 [==============================] - 1s 2ms/step - loss: 0.4872 - accuracy: 0.8087 - val_loss: 0.4544 - val_accuracy: 0.8235\n",
      "Epoch 385/1000\n",
      "239/239 [==============================] - 1s 2ms/step - loss: 0.4821 - accuracy: 0.8118 - val_loss: 0.4493 - val_accuracy: 0.8262\n",
      "Epoch 386/1000\n",
      "239/239 [==============================] - 1s 2ms/step - loss: 0.4799 - accuracy: 0.8102 - val_loss: 0.4498 - val_accuracy: 0.8265\n",
      "Epoch 386: early stopping\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "<keras.src.callbacks.History at 0x17dfbb880>"
      ]
     },
     "execution_count": 108,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# CyclicLR ile\n",
    "model.compile(loss='categorical_crossentropy', optimizer=Adam(), metrics=['accuracy'])\n",
    "\n",
    "es=EarlyStopping(monitor=\"val_loss\",patience=50,verbose=1)\n",
    "clr = CyclicLR(base_lr=0.001, max_lr=0.006,\n",
    "                                step_size=2000., mode='triangular')\n",
    "\n",
    "model.fit(X_train,\n",
    "          y_train,\n",
    "          epochs=1000,\n",
    "               batch_size=512,\n",
    "               validation_split=0.1,\n",
    "               verbose=1,callbacks=[es, clr])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 109,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "748/748 [==============================] - 0s 259us/step\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0       0.85      0.93      0.89      7973\n",
      "           1       0.81      0.89      0.85      7973\n",
      "           2       0.80      0.65      0.72      7972\n",
      "\n",
      "    accuracy                           0.82     23918\n",
      "   macro avg       0.82      0.82      0.82     23918\n",
      "weighted avg       0.82      0.82      0.82     23918\n",
      "\n"
     ]
    }
   ],
   "source": [
    "y_pred = model.predict(X_test)\n",
    "y_pred_classes = np.argmax(y_pred, axis=1)\n",
    "y_true = np.argmax(y_test, axis=1)\n",
    "print(classification_report(y_true, y_pred_classes))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 110,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "4236/4236 [==============================] - 1s 254us/step\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0       0.87      0.95      0.91     45176\n",
      "           1       0.83      0.91      0.87     45176\n",
      "           2       0.85      0.69      0.76     45177\n",
      "\n",
      "    accuracy                           0.85    135529\n",
      "   macro avg       0.85      0.85      0.85    135529\n",
      "weighted avg       0.85      0.85      0.85    135529\n",
      "\n"
     ]
    }
   ],
   "source": [
    "y_t_pred = model.predict(X_train)\n",
    "y_t_pred_classes = np.argmax(y_t_pred, axis=1)\n",
    "y_t_true = np.argmax(y_train, axis=1)\n",
    "print(classification_report(y_t_true, y_t_pred_classes))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "**_____________________________________________________________________________________________________**"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## SMOTE olmadan CyclicLR ile"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 112,
   "metadata": {},
   "outputs": [],
   "source": [
    "X=df.drop('Credit_Score',axis=1)\n",
    "y = df.Credit_Score"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 113,
   "metadata": {},
   "outputs": [],
   "source": [
    "y=to_categorical(y, num_classes=3)\n",
    "\n",
    "X_train, X_test, y_train, y_test = train_test_split(X,y,test_size=0.15,shuffle=True,stratify=y,random_state=42)\n",
    "\n",
    "scaler = RobustScaler()\n",
    "X_train = scaler.fit_transform(X_train)\n",
    "X_test = scaler.transform(X_test)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 118,
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "2    53149\n",
       "1    28988\n",
       "0    17823\n",
       "Name: Credit_Score, dtype: int64"
      ]
     },
     "execution_count": 118,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df.Credit_Score.value_counts()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 121,
   "metadata": {},
   "outputs": [],
   "source": [
    "model=Sequential()\n",
    "model.add(Dense(128, activation=\"relu\"))\n",
    "model.add(Dropout(0.8))\n",
    "model.add(Dense(128, activation=\"relu\"))\n",
    "\n",
    "model.add(Dense(64, activation=\"relu\"))\n",
    "model.add(Dropout(0.2))\n",
    "model.add(Dense(64, activation=\"relu\"))\n",
    "\n",
    "model.add(Dense(32, activation=\"relu\"))\n",
    "model.add(Dropout(0.2))\n",
    "model.add(Dense(16, activation=\"relu\"))\n",
    "model.add(Dropout(0.2))\n",
    "model.add(Dense(3, activation=\"softmax\"))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 122,
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 1/1000\n",
      "150/150 [==============================] - 1s 2ms/step - loss: 0.8817 - accuracy: 0.5773 - val_loss: 0.7353 - val_accuracy: 0.6682\n",
      "Epoch 2/1000\n",
      "150/150 [==============================] - 0s 2ms/step - loss: 0.7772 - accuracy: 0.6381 - val_loss: 0.7161 - val_accuracy: 0.6804\n",
      "Epoch 3/1000\n",
      "150/150 [==============================] - 0s 2ms/step - loss: 0.7499 - accuracy: 0.6511 - val_loss: 0.7010 - val_accuracy: 0.6998\n",
      "Epoch 4/1000\n",
      "150/150 [==============================] - 0s 2ms/step - loss: 0.7344 - accuracy: 0.6646 - val_loss: 0.6896 - val_accuracy: 0.7011\n",
      "Epoch 5/1000\n",
      "150/150 [==============================] - 0s 2ms/step - loss: 0.7276 - accuracy: 0.6716 - val_loss: 0.6873 - val_accuracy: 0.6954\n",
      "Epoch 6/1000\n",
      "150/150 [==============================] - 0s 2ms/step - loss: 0.7220 - accuracy: 0.6756 - val_loss: 0.6877 - val_accuracy: 0.6953\n",
      "Epoch 7/1000\n",
      "150/150 [==============================] - 0s 2ms/step - loss: 0.7164 - accuracy: 0.6812 - val_loss: 0.6832 - val_accuracy: 0.7025\n",
      "Epoch 8/1000\n",
      "150/150 [==============================] - 0s 2ms/step - loss: 0.7146 - accuracy: 0.6809 - val_loss: 0.6793 - val_accuracy: 0.7046\n",
      "Epoch 9/1000\n",
      "150/150 [==============================] - 0s 2ms/step - loss: 0.7120 - accuracy: 0.6849 - val_loss: 0.6858 - val_accuracy: 0.7004\n",
      "Epoch 10/1000\n",
      "150/150 [==============================] - 0s 2ms/step - loss: 0.7123 - accuracy: 0.6844 - val_loss: 0.6875 - val_accuracy: 0.6972\n",
      "Epoch 11/1000\n",
      "150/150 [==============================] - 0s 2ms/step - loss: 0.7121 - accuracy: 0.6820 - val_loss: 0.6837 - val_accuracy: 0.6995\n",
      "Epoch 12/1000\n",
      "150/150 [==============================] - 0s 2ms/step - loss: 0.7117 - accuracy: 0.6817 - val_loss: 0.6801 - val_accuracy: 0.7000\n",
      "Epoch 13/1000\n",
      "150/150 [==============================] - 0s 2ms/step - loss: 0.7114 - accuracy: 0.6848 - val_loss: 0.6865 - val_accuracy: 0.7005\n",
      "Epoch 14/1000\n",
      "150/150 [==============================] - 0s 2ms/step - loss: 0.7099 - accuracy: 0.6835 - val_loss: 0.6887 - val_accuracy: 0.7032\n",
      "Epoch 15/1000\n",
      "150/150 [==============================] - 0s 2ms/step - loss: 0.7079 - accuracy: 0.6863 - val_loss: 0.6810 - val_accuracy: 0.7050\n",
      "Epoch 16/1000\n",
      "150/150 [==============================] - 0s 2ms/step - loss: 0.7072 - accuracy: 0.6858 - val_loss: 0.6871 - val_accuracy: 0.7017\n",
      "Epoch 17/1000\n",
      "150/150 [==============================] - 0s 2ms/step - loss: 0.7065 - accuracy: 0.6866 - val_loss: 0.6841 - val_accuracy: 0.7008\n",
      "Epoch 18/1000\n",
      "150/150 [==============================] - 0s 2ms/step - loss: 0.7044 - accuracy: 0.6869 - val_loss: 0.6901 - val_accuracy: 0.6952\n",
      "Epoch 19/1000\n",
      "150/150 [==============================] - 0s 2ms/step - loss: 0.7034 - accuracy: 0.6880 - val_loss: 0.6829 - val_accuracy: 0.6988\n",
      "Epoch 20/1000\n",
      "150/150 [==============================] - 0s 2ms/step - loss: 0.7022 - accuracy: 0.6883 - val_loss: 0.6810 - val_accuracy: 0.7025\n",
      "Epoch 21/1000\n",
      "150/150 [==============================] - 0s 2ms/step - loss: 0.7003 - accuracy: 0.6900 - val_loss: 0.6771 - val_accuracy: 0.7034\n",
      "Epoch 22/1000\n",
      "150/150 [==============================] - 0s 2ms/step - loss: 0.6991 - accuracy: 0.6900 - val_loss: 0.6799 - val_accuracy: 0.7002\n",
      "Epoch 23/1000\n",
      "150/150 [==============================] - 0s 2ms/step - loss: 0.6974 - accuracy: 0.6927 - val_loss: 0.6827 - val_accuracy: 0.7026\n",
      "Epoch 24/1000\n",
      "150/150 [==============================] - 0s 2ms/step - loss: 0.6963 - accuracy: 0.6929 - val_loss: 0.6775 - val_accuracy: 0.7067\n",
      "Epoch 25/1000\n",
      "150/150 [==============================] - 0s 2ms/step - loss: 0.6954 - accuracy: 0.6934 - val_loss: 0.6872 - val_accuracy: 0.6945\n",
      "Epoch 26/1000\n",
      "150/150 [==============================] - 0s 2ms/step - loss: 0.6945 - accuracy: 0.6939 - val_loss: 0.6812 - val_accuracy: 0.6978\n",
      "Epoch 27/1000\n",
      "150/150 [==============================] - 0s 2ms/step - loss: 0.6933 - accuracy: 0.6942 - val_loss: 0.6856 - val_accuracy: 0.6964\n",
      "Epoch 28/1000\n",
      "150/150 [==============================] - 0s 2ms/step - loss: 0.6928 - accuracy: 0.6933 - val_loss: 0.6824 - val_accuracy: 0.6944\n",
      "Epoch 29/1000\n",
      "150/150 [==============================] - 0s 2ms/step - loss: 0.6932 - accuracy: 0.6943 - val_loss: 0.6821 - val_accuracy: 0.6987\n",
      "Epoch 30/1000\n",
      "150/150 [==============================] - 0s 2ms/step - loss: 0.6927 - accuracy: 0.6949 - val_loss: 0.6872 - val_accuracy: 0.6938\n",
      "Epoch 31/1000\n",
      "150/150 [==============================] - 0s 2ms/step - loss: 0.6954 - accuracy: 0.6924 - val_loss: 0.6830 - val_accuracy: 0.6981\n",
      "Epoch 32/1000\n",
      "150/150 [==============================] - 0s 2ms/step - loss: 0.6952 - accuracy: 0.6920 - val_loss: 0.6791 - val_accuracy: 0.7025\n",
      "Epoch 33/1000\n",
      "150/150 [==============================] - 0s 2ms/step - loss: 0.6959 - accuracy: 0.6929 - val_loss: 0.6856 - val_accuracy: 0.6900\n",
      "Epoch 34/1000\n",
      "150/150 [==============================] - 0s 2ms/step - loss: 0.6981 - accuracy: 0.6909 - val_loss: 0.6799 - val_accuracy: 0.7005\n",
      "Epoch 35/1000\n",
      "150/150 [==============================] - 0s 2ms/step - loss: 0.6997 - accuracy: 0.6897 - val_loss: 0.6823 - val_accuracy: 0.7041\n",
      "Epoch 36/1000\n",
      "150/150 [==============================] - 0s 2ms/step - loss: 0.7005 - accuracy: 0.6888 - val_loss: 0.6875 - val_accuracy: 0.6966\n",
      "Epoch 37/1000\n",
      "150/150 [==============================] - 0s 2ms/step - loss: 0.7018 - accuracy: 0.6885 - val_loss: 0.6886 - val_accuracy: 0.6965\n",
      "Epoch 38/1000\n",
      "150/150 [==============================] - 0s 2ms/step - loss: 0.7007 - accuracy: 0.6897 - val_loss: 0.6825 - val_accuracy: 0.7054\n",
      "Epoch 39/1000\n",
      "150/150 [==============================] - 0s 2ms/step - loss: 0.7029 - accuracy: 0.6887 - val_loss: 0.6776 - val_accuracy: 0.7041\n",
      "Epoch 40/1000\n",
      "150/150 [==============================] - 0s 2ms/step - loss: 0.7036 - accuracy: 0.6887 - val_loss: 0.6838 - val_accuracy: 0.6992\n",
      "Epoch 41/1000\n",
      "150/150 [==============================] - 0s 2ms/step - loss: 0.7047 - accuracy: 0.6870 - val_loss: 0.6798 - val_accuracy: 0.6992\n",
      "Epoch 42/1000\n",
      "150/150 [==============================] - 0s 2ms/step - loss: 0.7061 - accuracy: 0.6882 - val_loss: 0.6805 - val_accuracy: 0.7031\n",
      "Epoch 43/1000\n",
      "150/150 [==============================] - 0s 2ms/step - loss: 0.7049 - accuracy: 0.6878 - val_loss: 0.6827 - val_accuracy: 0.6948\n",
      "Epoch 44/1000\n",
      "150/150 [==============================] - 0s 2ms/step - loss: 0.7025 - accuracy: 0.6880 - val_loss: 0.6812 - val_accuracy: 0.6966\n",
      "Epoch 45/1000\n",
      "150/150 [==============================] - 0s 2ms/step - loss: 0.7007 - accuracy: 0.6878 - val_loss: 0.6762 - val_accuracy: 0.7034\n",
      "Epoch 46/1000\n",
      "150/150 [==============================] - 0s 2ms/step - loss: 0.6989 - accuracy: 0.6899 - val_loss: 0.6799 - val_accuracy: 0.6938\n",
      "Epoch 47/1000\n",
      "150/150 [==============================] - 0s 2ms/step - loss: 0.6986 - accuracy: 0.6897 - val_loss: 0.6815 - val_accuracy: 0.6928\n",
      "Epoch 48/1000\n",
      "150/150 [==============================] - 0s 2ms/step - loss: 0.6970 - accuracy: 0.6924 - val_loss: 0.6808 - val_accuracy: 0.6960\n",
      "Epoch 49/1000\n",
      "150/150 [==============================] - 0s 2ms/step - loss: 0.6967 - accuracy: 0.6909 - val_loss: 0.6838 - val_accuracy: 0.6930\n",
      "Epoch 50/1000\n",
      "150/150 [==============================] - 0s 2ms/step - loss: 0.6956 - accuracy: 0.6925 - val_loss: 0.6776 - val_accuracy: 0.6991\n",
      "Epoch 51/1000\n",
      "150/150 [==============================] - 0s 2ms/step - loss: 0.6941 - accuracy: 0.6939 - val_loss: 0.6769 - val_accuracy: 0.6999\n",
      "Epoch 52/1000\n",
      "150/150 [==============================] - 0s 2ms/step - loss: 0.6938 - accuracy: 0.6925 - val_loss: 0.6802 - val_accuracy: 0.6942\n",
      "Epoch 53/1000\n",
      "150/150 [==============================] - 0s 2ms/step - loss: 0.6930 - accuracy: 0.6938 - val_loss: 0.6784 - val_accuracy: 0.6955\n",
      "Epoch 54/1000\n",
      "150/150 [==============================] - 0s 2ms/step - loss: 0.6917 - accuracy: 0.6936 - val_loss: 0.6808 - val_accuracy: 0.6946\n",
      "Epoch 55/1000\n",
      "150/150 [==============================] - 0s 2ms/step - loss: 0.6900 - accuracy: 0.6959 - val_loss: 0.6829 - val_accuracy: 0.6886\n",
      "Epoch 56/1000\n",
      "150/150 [==============================] - 0s 2ms/step - loss: 0.6928 - accuracy: 0.6936 - val_loss: 0.6801 - val_accuracy: 0.6946\n",
      "Epoch 57/1000\n",
      "150/150 [==============================] - 0s 2ms/step - loss: 0.6933 - accuracy: 0.6934 - val_loss: 0.6785 - val_accuracy: 0.6958\n",
      "Epoch 58/1000\n",
      "150/150 [==============================] - 0s 2ms/step - loss: 0.6930 - accuracy: 0.6928 - val_loss: 0.6776 - val_accuracy: 0.7064\n",
      "Epoch 59/1000\n",
      "150/150 [==============================] - 0s 2ms/step - loss: 0.6936 - accuracy: 0.6938 - val_loss: 0.6848 - val_accuracy: 0.6961\n",
      "Epoch 60/1000\n",
      "150/150 [==============================] - 0s 2ms/step - loss: 0.6950 - accuracy: 0.6932 - val_loss: 0.6919 - val_accuracy: 0.6794\n",
      "Epoch 61/1000\n",
      "150/150 [==============================] - 0s 2ms/step - loss: 0.6952 - accuracy: 0.6926 - val_loss: 0.6815 - val_accuracy: 0.6932\n",
      "Epoch 62/1000\n",
      "150/150 [==============================] - 0s 2ms/step - loss: 0.6985 - accuracy: 0.6908 - val_loss: 0.6841 - val_accuracy: 0.6904\n",
      "Epoch 63/1000\n",
      "150/150 [==============================] - 0s 2ms/step - loss: 0.6989 - accuracy: 0.6901 - val_loss: 0.6803 - val_accuracy: 0.7006\n",
      "Epoch 64/1000\n",
      "150/150 [==============================] - 0s 2ms/step - loss: 0.6989 - accuracy: 0.6891 - val_loss: 0.6785 - val_accuracy: 0.6964\n",
      "Epoch 65/1000\n",
      "150/150 [==============================] - 0s 2ms/step - loss: 0.6993 - accuracy: 0.6893 - val_loss: 0.6808 - val_accuracy: 0.6934\n",
      "Epoch 66/1000\n",
      "150/150 [==============================] - 0s 2ms/step - loss: 0.7048 - accuracy: 0.6864 - val_loss: 0.6825 - val_accuracy: 0.7001\n",
      "Epoch 67/1000\n",
      "150/150 [==============================] - 0s 2ms/step - loss: 0.7047 - accuracy: 0.6866 - val_loss: 0.6841 - val_accuracy: 0.7033\n",
      "Epoch 68/1000\n",
      "150/150 [==============================] - 0s 2ms/step - loss: 0.7040 - accuracy: 0.6892 - val_loss: 0.6930 - val_accuracy: 0.6859\n",
      "Epoch 69/1000\n",
      "150/150 [==============================] - 0s 2ms/step - loss: 0.7031 - accuracy: 0.6870 - val_loss: 0.6802 - val_accuracy: 0.7025\n",
      "Epoch 70/1000\n",
      "150/150 [==============================] - 0s 2ms/step - loss: 0.7001 - accuracy: 0.6913 - val_loss: 0.6773 - val_accuracy: 0.7010\n",
      "Epoch 71/1000\n",
      "150/150 [==============================] - 0s 2ms/step - loss: 0.6996 - accuracy: 0.6908 - val_loss: 0.6839 - val_accuracy: 0.6895\n",
      "Epoch 72/1000\n",
      "150/150 [==============================] - 0s 2ms/step - loss: 0.6994 - accuracy: 0.6898 - val_loss: 0.6765 - val_accuracy: 0.7025\n",
      "Epoch 73/1000\n",
      "150/150 [==============================] - 0s 2ms/step - loss: 0.6986 - accuracy: 0.6887 - val_loss: 0.6817 - val_accuracy: 0.6947\n",
      "Epoch 74/1000\n",
      "150/150 [==============================] - 0s 2ms/step - loss: 0.6983 - accuracy: 0.6912 - val_loss: 0.6825 - val_accuracy: 0.6952\n",
      "Epoch 75/1000\n",
      "150/150 [==============================] - 0s 2ms/step - loss: 0.6954 - accuracy: 0.6931 - val_loss: 0.6842 - val_accuracy: 0.6920\n",
      "Epoch 76/1000\n",
      "150/150 [==============================] - 0s 2ms/step - loss: 0.6942 - accuracy: 0.6925 - val_loss: 0.6795 - val_accuracy: 0.7014\n",
      "Epoch 77/1000\n",
      "150/150 [==============================] - 0s 2ms/step - loss: 0.6942 - accuracy: 0.6933 - val_loss: 0.6813 - val_accuracy: 0.6895\n",
      "Epoch 78/1000\n",
      "150/150 [==============================] - 0s 2ms/step - loss: 0.6930 - accuracy: 0.6954 - val_loss: 0.6792 - val_accuracy: 0.6959\n",
      "Epoch 79/1000\n",
      "150/150 [==============================] - 0s 2ms/step - loss: 0.6917 - accuracy: 0.6958 - val_loss: 0.6808 - val_accuracy: 0.6933\n",
      "Epoch 80/1000\n",
      "150/150 [==============================] - 0s 2ms/step - loss: 0.6917 - accuracy: 0.6936 - val_loss: 0.6809 - val_accuracy: 0.6924\n",
      "Epoch 81/1000\n",
      "150/150 [==============================] - 0s 2ms/step - loss: 0.6922 - accuracy: 0.6958 - val_loss: 0.6780 - val_accuracy: 0.6966\n",
      "Epoch 82/1000\n",
      "150/150 [==============================] - 0s 2ms/step - loss: 0.6914 - accuracy: 0.6960 - val_loss: 0.6866 - val_accuracy: 0.6801\n",
      "Epoch 83/1000\n",
      "150/150 [==============================] - 0s 2ms/step - loss: 0.6909 - accuracy: 0.6965 - val_loss: 0.6806 - val_accuracy: 0.6966\n",
      "Epoch 84/1000\n",
      "150/150 [==============================] - 0s 2ms/step - loss: 0.6923 - accuracy: 0.6946 - val_loss: 0.6804 - val_accuracy: 0.6986\n",
      "Epoch 85/1000\n",
      "150/150 [==============================] - 0s 2ms/step - loss: 0.6928 - accuracy: 0.6939 - val_loss: 0.6834 - val_accuracy: 0.6900\n",
      "Epoch 86/1000\n",
      "150/150 [==============================] - 0s 2ms/step - loss: 0.6933 - accuracy: 0.6946 - val_loss: 0.6779 - val_accuracy: 0.6941\n",
      "Epoch 87/1000\n",
      "150/150 [==============================] - 0s 2ms/step - loss: 0.6940 - accuracy: 0.6934 - val_loss: 0.6861 - val_accuracy: 0.6919\n",
      "Epoch 88/1000\n",
      "150/150 [==============================] - 0s 2ms/step - loss: 0.6958 - accuracy: 0.6913 - val_loss: 0.6847 - val_accuracy: 0.7051\n",
      "Epoch 89/1000\n",
      "150/150 [==============================] - 0s 2ms/step - loss: 0.6953 - accuracy: 0.6923 - val_loss: 0.6868 - val_accuracy: 0.7014\n",
      "Epoch 90/1000\n",
      "150/150 [==============================] - 0s 2ms/step - loss: 0.6978 - accuracy: 0.6913 - val_loss: 0.6797 - val_accuracy: 0.6967\n",
      "Epoch 91/1000\n",
      "150/150 [==============================] - 0s 2ms/step - loss: 0.6966 - accuracy: 0.6915 - val_loss: 0.6816 - val_accuracy: 0.7035\n",
      "Epoch 92/1000\n",
      "150/150 [==============================] - 0s 2ms/step - loss: 0.6995 - accuracy: 0.6897 - val_loss: 0.6762 - val_accuracy: 0.7040\n",
      "Epoch 93/1000\n",
      "150/150 [==============================] - 0s 2ms/step - loss: 0.6998 - accuracy: 0.6904 - val_loss: 0.6985 - val_accuracy: 0.6839\n",
      "Epoch 94/1000\n",
      "150/150 [==============================] - 0s 2ms/step - loss: 0.7013 - accuracy: 0.6883 - val_loss: 0.6827 - val_accuracy: 0.6914\n",
      "Epoch 95/1000\n",
      "150/150 [==============================] - 0s 2ms/step - loss: 0.7017 - accuracy: 0.6879 - val_loss: 0.6806 - val_accuracy: 0.7054\n",
      "Epoch 96/1000\n",
      "150/150 [==============================] - 0s 2ms/step - loss: 0.7022 - accuracy: 0.6874 - val_loss: 0.6828 - val_accuracy: 0.6907\n",
      "Epoch 97/1000\n",
      "150/150 [==============================] - 0s 2ms/step - loss: 0.7012 - accuracy: 0.6894 - val_loss: 0.6787 - val_accuracy: 0.7004\n",
      "Epoch 98/1000\n",
      "150/150 [==============================] - 0s 2ms/step - loss: 0.6992 - accuracy: 0.6897 - val_loss: 0.6793 - val_accuracy: 0.7000\n",
      "Epoch 99/1000\n",
      "150/150 [==============================] - 0s 2ms/step - loss: 0.7008 - accuracy: 0.6901 - val_loss: 0.6904 - val_accuracy: 0.6884\n",
      "Epoch 100/1000\n",
      "150/150 [==============================] - 0s 2ms/step - loss: 0.6972 - accuracy: 0.6922 - val_loss: 0.6794 - val_accuracy: 0.7040\n",
      "Epoch 101/1000\n",
      "150/150 [==============================] - 0s 2ms/step - loss: 0.6970 - accuracy: 0.6922 - val_loss: 0.6860 - val_accuracy: 0.6944\n",
      "Epoch 102/1000\n",
      "150/150 [==============================] - 0s 2ms/step - loss: 0.6950 - accuracy: 0.6917 - val_loss: 0.6767 - val_accuracy: 0.7026\n",
      "Epoch 103/1000\n",
      "150/150 [==============================] - 0s 2ms/step - loss: 0.6947 - accuracy: 0.6928 - val_loss: 0.6816 - val_accuracy: 0.6984\n",
      "Epoch 104/1000\n",
      "150/150 [==============================] - 0s 2ms/step - loss: 0.6948 - accuracy: 0.6924 - val_loss: 0.6794 - val_accuracy: 0.7021\n",
      "Epoch 105/1000\n",
      "150/150 [==============================] - 0s 2ms/step - loss: 0.6947 - accuracy: 0.6926 - val_loss: 0.6781 - val_accuracy: 0.7039\n",
      "Epoch 106/1000\n",
      "150/150 [==============================] - 0s 2ms/step - loss: 0.6926 - accuracy: 0.6940 - val_loss: 0.6785 - val_accuracy: 0.7030\n",
      "Epoch 107/1000\n",
      "150/150 [==============================] - 0s 2ms/step - loss: 0.6921 - accuracy: 0.6952 - val_loss: 0.6786 - val_accuracy: 0.7021\n",
      "Epoch 108/1000\n",
      "150/150 [==============================] - 0s 2ms/step - loss: 0.6932 - accuracy: 0.6952 - val_loss: 0.6794 - val_accuracy: 0.7024\n",
      "Epoch 109/1000\n",
      "150/150 [==============================] - 0s 2ms/step - loss: 0.6916 - accuracy: 0.6945 - val_loss: 0.6818 - val_accuracy: 0.6953\n",
      "Epoch 110/1000\n",
      "150/150 [==============================] - 0s 2ms/step - loss: 0.6920 - accuracy: 0.6946 - val_loss: 0.6825 - val_accuracy: 0.6981\n",
      "Epoch 111/1000\n",
      "150/150 [==============================] - 0s 2ms/step - loss: 0.6923 - accuracy: 0.6943 - val_loss: 0.6829 - val_accuracy: 0.6962\n",
      "Epoch 112/1000\n",
      "150/150 [==============================] - 0s 2ms/step - loss: 0.6943 - accuracy: 0.6937 - val_loss: 0.6791 - val_accuracy: 0.6977\n",
      "Epoch 113/1000\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "150/150 [==============================] - 0s 2ms/step - loss: 0.6934 - accuracy: 0.6937 - val_loss: 0.6753 - val_accuracy: 0.7045\n",
      "Epoch 114/1000\n",
      "150/150 [==============================] - 0s 2ms/step - loss: 0.6966 - accuracy: 0.6920 - val_loss: 0.6772 - val_accuracy: 0.7042\n",
      "Epoch 115/1000\n",
      "150/150 [==============================] - 0s 2ms/step - loss: 0.6993 - accuracy: 0.6905 - val_loss: 0.6791 - val_accuracy: 0.7068\n",
      "Epoch 116/1000\n",
      "150/150 [==============================] - 0s 2ms/step - loss: 0.6959 - accuracy: 0.6934 - val_loss: 0.6760 - val_accuracy: 0.7045\n",
      "Epoch 117/1000\n",
      "150/150 [==============================] - 0s 2ms/step - loss: 0.6971 - accuracy: 0.6925 - val_loss: 0.6776 - val_accuracy: 0.7079\n",
      "Epoch 118/1000\n",
      "150/150 [==============================] - 0s 2ms/step - loss: 0.7001 - accuracy: 0.6909 - val_loss: 0.6810 - val_accuracy: 0.7037\n",
      "Epoch 119/1000\n",
      "150/150 [==============================] - 0s 2ms/step - loss: 0.6995 - accuracy: 0.6899 - val_loss: 0.6825 - val_accuracy: 0.6900\n",
      "Epoch 120/1000\n",
      "150/150 [==============================] - 0s 2ms/step - loss: 0.7007 - accuracy: 0.6903 - val_loss: 0.6779 - val_accuracy: 0.6995\n",
      "Epoch 121/1000\n",
      "150/150 [==============================] - 0s 2ms/step - loss: 0.7014 - accuracy: 0.6894 - val_loss: 0.6861 - val_accuracy: 0.6954\n",
      "Epoch 122/1000\n",
      "150/150 [==============================] - 0s 2ms/step - loss: 0.7018 - accuracy: 0.6916 - val_loss: 0.6768 - val_accuracy: 0.7002\n",
      "Epoch 123/1000\n",
      "150/150 [==============================] - 0s 2ms/step - loss: 0.7017 - accuracy: 0.6888 - val_loss: 0.6888 - val_accuracy: 0.6965\n",
      "Epoch 124/1000\n",
      "150/150 [==============================] - 0s 2ms/step - loss: 0.6997 - accuracy: 0.6888 - val_loss: 0.6920 - val_accuracy: 0.6849\n",
      "Epoch 125/1000\n",
      "150/150 [==============================] - 0s 2ms/step - loss: 0.7000 - accuracy: 0.6906 - val_loss: 0.6811 - val_accuracy: 0.7030\n",
      "Epoch 126/1000\n",
      "150/150 [==============================] - 0s 2ms/step - loss: 0.6981 - accuracy: 0.6916 - val_loss: 0.6763 - val_accuracy: 0.7039\n",
      "Epoch 127/1000\n",
      "150/150 [==============================] - 0s 2ms/step - loss: 0.6958 - accuracy: 0.6926 - val_loss: 0.6815 - val_accuracy: 0.6932\n",
      "Epoch 128/1000\n",
      "150/150 [==============================] - 0s 2ms/step - loss: 0.6956 - accuracy: 0.6927 - val_loss: 0.6783 - val_accuracy: 0.6973\n",
      "Epoch 129/1000\n",
      "150/150 [==============================] - 0s 2ms/step - loss: 0.6944 - accuracy: 0.6936 - val_loss: 0.6800 - val_accuracy: 0.7044\n",
      "Epoch 130/1000\n",
      "150/150 [==============================] - 0s 2ms/step - loss: 0.6940 - accuracy: 0.6926 - val_loss: 0.6812 - val_accuracy: 0.6958\n",
      "Epoch 131/1000\n",
      "150/150 [==============================] - 0s 2ms/step - loss: 0.6932 - accuracy: 0.6931 - val_loss: 0.6818 - val_accuracy: 0.6924\n",
      "Epoch 132/1000\n",
      "150/150 [==============================] - 0s 2ms/step - loss: 0.6923 - accuracy: 0.6953 - val_loss: 0.6797 - val_accuracy: 0.6964\n",
      "Epoch 133/1000\n",
      "150/150 [==============================] - 0s 2ms/step - loss: 0.6920 - accuracy: 0.6951 - val_loss: 0.6783 - val_accuracy: 0.6988\n",
      "Epoch 134/1000\n",
      "150/150 [==============================] - 0s 2ms/step - loss: 0.6913 - accuracy: 0.6954 - val_loss: 0.6810 - val_accuracy: 0.6992\n",
      "Epoch 135/1000\n",
      "150/150 [==============================] - 0s 2ms/step - loss: 0.6918 - accuracy: 0.6963 - val_loss: 0.6773 - val_accuracy: 0.7014\n",
      "Epoch 136/1000\n",
      "150/150 [==============================] - 0s 2ms/step - loss: 0.6915 - accuracy: 0.6961 - val_loss: 0.6780 - val_accuracy: 0.6998\n",
      "Epoch 137/1000\n",
      "150/150 [==============================] - 0s 2ms/step - loss: 0.6925 - accuracy: 0.6944 - val_loss: 0.6749 - val_accuracy: 0.7030\n",
      "Epoch 138/1000\n",
      "150/150 [==============================] - 0s 2ms/step - loss: 0.6923 - accuracy: 0.6942 - val_loss: 0.6797 - val_accuracy: 0.7113\n",
      "Epoch 139/1000\n",
      "150/150 [==============================] - 0s 2ms/step - loss: 0.6933 - accuracy: 0.6955 - val_loss: 0.6802 - val_accuracy: 0.6953\n",
      "Epoch 140/1000\n",
      "150/150 [==============================] - 0s 2ms/step - loss: 0.6942 - accuracy: 0.6942 - val_loss: 0.6872 - val_accuracy: 0.6945\n",
      "Epoch 141/1000\n",
      "150/150 [==============================] - 0s 2ms/step - loss: 0.6949 - accuracy: 0.6955 - val_loss: 0.6924 - val_accuracy: 0.6881\n",
      "Epoch 142/1000\n",
      "150/150 [==============================] - 0s 2ms/step - loss: 0.6952 - accuracy: 0.6941 - val_loss: 0.6820 - val_accuracy: 0.6960\n",
      "Epoch 143/1000\n",
      "150/150 [==============================] - 0s 2ms/step - loss: 0.6959 - accuracy: 0.6920 - val_loss: 0.6807 - val_accuracy: 0.7000\n",
      "Epoch 144/1000\n",
      "150/150 [==============================] - 0s 2ms/step - loss: 0.6961 - accuracy: 0.6917 - val_loss: 0.6762 - val_accuracy: 0.7031\n",
      "Epoch 145/1000\n",
      "150/150 [==============================] - 0s 2ms/step - loss: 0.6983 - accuracy: 0.6902 - val_loss: 0.6716 - val_accuracy: 0.7081\n",
      "Epoch 146/1000\n",
      "150/150 [==============================] - 0s 2ms/step - loss: 0.6989 - accuracy: 0.6902 - val_loss: 0.6801 - val_accuracy: 0.6991\n",
      "Epoch 147/1000\n",
      "150/150 [==============================] - 0s 2ms/step - loss: 0.7023 - accuracy: 0.6878 - val_loss: 0.6804 - val_accuracy: 0.6998\n",
      "Epoch 148/1000\n",
      "150/150 [==============================] - 0s 2ms/step - loss: 0.7067 - accuracy: 0.6839 - val_loss: 0.6796 - val_accuracy: 0.7053\n",
      "Epoch 149/1000\n",
      "150/150 [==============================] - 0s 2ms/step - loss: 0.7109 - accuracy: 0.6829 - val_loss: 0.6910 - val_accuracy: 0.6998\n",
      "Epoch 150/1000\n",
      "150/150 [==============================] - 0s 2ms/step - loss: 0.7074 - accuracy: 0.6865 - val_loss: 0.6824 - val_accuracy: 0.6844\n",
      "Epoch 151/1000\n",
      "150/150 [==============================] - 0s 2ms/step - loss: 0.7043 - accuracy: 0.6854 - val_loss: 0.6808 - val_accuracy: 0.7004\n",
      "Epoch 152/1000\n",
      "150/150 [==============================] - 0s 2ms/step - loss: 0.7035 - accuracy: 0.6876 - val_loss: 0.6788 - val_accuracy: 0.6940\n",
      "Epoch 153/1000\n",
      "150/150 [==============================] - 0s 2ms/step - loss: 0.7000 - accuracy: 0.6905 - val_loss: 0.6819 - val_accuracy: 0.6990\n",
      "Epoch 154/1000\n",
      "150/150 [==============================] - 0s 2ms/step - loss: 0.6991 - accuracy: 0.6895 - val_loss: 0.6801 - val_accuracy: 0.7039\n",
      "Epoch 155/1000\n",
      "150/150 [==============================] - 0s 2ms/step - loss: 0.6989 - accuracy: 0.6912 - val_loss: 0.6720 - val_accuracy: 0.7054\n",
      "Epoch 156/1000\n",
      "150/150 [==============================] - 0s 2ms/step - loss: 0.6965 - accuracy: 0.6916 - val_loss: 0.6787 - val_accuracy: 0.7039\n",
      "Epoch 157/1000\n",
      "150/150 [==============================] - 0s 2ms/step - loss: 0.6966 - accuracy: 0.6927 - val_loss: 0.6754 - val_accuracy: 0.7001\n",
      "Epoch 158/1000\n",
      "150/150 [==============================] - 0s 2ms/step - loss: 0.6970 - accuracy: 0.6916 - val_loss: 0.6793 - val_accuracy: 0.7017\n",
      "Epoch 159/1000\n",
      "150/150 [==============================] - 0s 2ms/step - loss: 0.6950 - accuracy: 0.6934 - val_loss: 0.6745 - val_accuracy: 0.7025\n",
      "Epoch 160/1000\n",
      "150/150 [==============================] - 0s 2ms/step - loss: 0.6962 - accuracy: 0.6923 - val_loss: 0.6762 - val_accuracy: 0.6958\n",
      "Epoch 161/1000\n",
      "150/150 [==============================] - 0s 2ms/step - loss: 0.6936 - accuracy: 0.6932 - val_loss: 0.6765 - val_accuracy: 0.6998\n",
      "Epoch 162/1000\n",
      "150/150 [==============================] - 0s 2ms/step - loss: 0.6935 - accuracy: 0.6940 - val_loss: 0.6732 - val_accuracy: 0.7051\n",
      "Epoch 163/1000\n",
      "150/150 [==============================] - 0s 2ms/step - loss: 0.6939 - accuracy: 0.6931 - val_loss: 0.6774 - val_accuracy: 0.6927\n",
      "Epoch 164/1000\n",
      "150/150 [==============================] - 0s 2ms/step - loss: 0.6955 - accuracy: 0.6926 - val_loss: 0.6760 - val_accuracy: 0.7057\n",
      "Epoch 165/1000\n",
      "150/150 [==============================] - 0s 2ms/step - loss: 0.6929 - accuracy: 0.6937 - val_loss: 0.6749 - val_accuracy: 0.7047\n",
      "Epoch 166/1000\n",
      "150/150 [==============================] - 0s 2ms/step - loss: 0.6936 - accuracy: 0.6937 - val_loss: 0.6756 - val_accuracy: 0.7044\n",
      "Epoch 167/1000\n",
      "150/150 [==============================] - 0s 2ms/step - loss: 0.6940 - accuracy: 0.6917 - val_loss: 0.6754 - val_accuracy: 0.6938\n",
      "Epoch 168/1000\n",
      "150/150 [==============================] - 0s 2ms/step - loss: 0.6971 - accuracy: 0.6924 - val_loss: 0.6769 - val_accuracy: 0.7051\n",
      "Epoch 169/1000\n",
      "150/150 [==============================] - 0s 2ms/step - loss: 0.6968 - accuracy: 0.6925 - val_loss: 0.6888 - val_accuracy: 0.6880\n",
      "Epoch 170/1000\n",
      "150/150 [==============================] - 0s 2ms/step - loss: 0.7000 - accuracy: 0.6905 - val_loss: 0.6754 - val_accuracy: 0.7062\n",
      "Epoch 171/1000\n",
      "150/150 [==============================] - 0s 2ms/step - loss: 0.6994 - accuracy: 0.6898 - val_loss: 0.6837 - val_accuracy: 0.6995\n",
      "Epoch 172/1000\n",
      "150/150 [==============================] - 0s 2ms/step - loss: 0.7022 - accuracy: 0.6892 - val_loss: 0.6836 - val_accuracy: 0.6948\n",
      "Epoch 173/1000\n",
      "150/150 [==============================] - 0s 2ms/step - loss: 0.7027 - accuracy: 0.6877 - val_loss: 0.6947 - val_accuracy: 0.6762\n",
      "Epoch 174/1000\n",
      "150/150 [==============================] - 0s 2ms/step - loss: 0.7030 - accuracy: 0.6889 - val_loss: 0.6869 - val_accuracy: 0.6795\n",
      "Epoch 175/1000\n",
      "150/150 [==============================] - 0s 2ms/step - loss: 0.7055 - accuracy: 0.6866 - val_loss: 0.6841 - val_accuracy: 0.6925\n",
      "Epoch 176/1000\n",
      "150/150 [==============================] - 0s 2ms/step - loss: 0.7038 - accuracy: 0.6870 - val_loss: 0.6856 - val_accuracy: 0.6930\n",
      "Epoch 177/1000\n",
      "150/150 [==============================] - 0s 2ms/step - loss: 0.7023 - accuracy: 0.6873 - val_loss: 0.6863 - val_accuracy: 0.6911\n",
      "Epoch 178/1000\n",
      "150/150 [==============================] - 0s 2ms/step - loss: 0.7006 - accuracy: 0.6878 - val_loss: 0.6840 - val_accuracy: 0.6957\n",
      "Epoch 179/1000\n",
      "150/150 [==============================] - 0s 2ms/step - loss: 0.7000 - accuracy: 0.6892 - val_loss: 0.6847 - val_accuracy: 0.6912\n",
      "Epoch 180/1000\n",
      "150/150 [==============================] - 0s 2ms/step - loss: 0.6995 - accuracy: 0.6905 - val_loss: 0.6781 - val_accuracy: 0.6988\n",
      "Epoch 181/1000\n",
      "150/150 [==============================] - 0s 2ms/step - loss: 0.6981 - accuracy: 0.6905 - val_loss: 0.6772 - val_accuracy: 0.7012\n",
      "Epoch 182/1000\n",
      "150/150 [==============================] - 0s 2ms/step - loss: 0.6988 - accuracy: 0.6900 - val_loss: 0.6766 - val_accuracy: 0.7048\n",
      "Epoch 183/1000\n",
      "150/150 [==============================] - 0s 2ms/step - loss: 0.6974 - accuracy: 0.6896 - val_loss: 0.6819 - val_accuracy: 0.6904\n",
      "Epoch 184/1000\n",
      "150/150 [==============================] - 0s 2ms/step - loss: 0.6966 - accuracy: 0.6918 - val_loss: 0.6824 - val_accuracy: 0.6906\n",
      "Epoch 185/1000\n",
      "150/150 [==============================] - 0s 2ms/step - loss: 0.6957 - accuracy: 0.6910 - val_loss: 0.6767 - val_accuracy: 0.6999\n",
      "Epoch 186/1000\n",
      "150/150 [==============================] - 0s 2ms/step - loss: 0.6944 - accuracy: 0.6926 - val_loss: 0.6756 - val_accuracy: 0.7011\n",
      "Epoch 187/1000\n",
      "150/150 [==============================] - 0s 2ms/step - loss: 0.6946 - accuracy: 0.6922 - val_loss: 0.6763 - val_accuracy: 0.6964\n",
      "Epoch 188/1000\n",
      "150/150 [==============================] - 0s 2ms/step - loss: 0.6944 - accuracy: 0.6934 - val_loss: 0.6758 - val_accuracy: 0.6977\n",
      "Epoch 189/1000\n",
      "150/150 [==============================] - 0s 2ms/step - loss: 0.6944 - accuracy: 0.6933 - val_loss: 0.6757 - val_accuracy: 0.6992\n",
      "Epoch 190/1000\n",
      "150/150 [==============================] - 0s 2ms/step - loss: 0.6941 - accuracy: 0.6931 - val_loss: 0.6782 - val_accuracy: 0.6984\n",
      "Epoch 191/1000\n",
      "150/150 [==============================] - 0s 2ms/step - loss: 0.6944 - accuracy: 0.6933 - val_loss: 0.6807 - val_accuracy: 0.6957\n",
      "Epoch 192/1000\n",
      "150/150 [==============================] - 0s 2ms/step - loss: 0.6940 - accuracy: 0.6924 - val_loss: 0.6737 - val_accuracy: 0.7039\n",
      "Epoch 193/1000\n",
      "150/150 [==============================] - 0s 2ms/step - loss: 0.6960 - accuracy: 0.6925 - val_loss: 0.6787 - val_accuracy: 0.6982\n",
      "Epoch 194/1000\n",
      "150/150 [==============================] - 0s 2ms/step - loss: 0.6975 - accuracy: 0.6928 - val_loss: 0.6813 - val_accuracy: 0.6935\n",
      "Epoch 195/1000\n",
      "150/150 [==============================] - 0s 2ms/step - loss: 0.6969 - accuracy: 0.6918 - val_loss: 0.6803 - val_accuracy: 0.6937\n",
      "Epoch 195: early stopping\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "<keras.src.callbacks.History at 0x144f98ee0>"
      ]
     },
     "execution_count": 122,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "model=Sequential()\n",
    "model.add(Dense(128, activation=\"relu\"))\n",
    "model.add(Dropout(0.8))\n",
    "model.add(Dense(128, activation=\"relu\"))\n",
    "\n",
    "model.add(Dense(64, activation=\"relu\"))\n",
    "model.add(Dropout(0.2))\n",
    "model.add(Dense(64, activation=\"relu\"))\n",
    "\n",
    "model.add(Dense(32, activation=\"relu\"))\n",
    "model.add(Dropout(0.2))\n",
    "model.add(Dense(16, activation=\"relu\"))\n",
    "model.add(Dropout(0.2))\n",
    "model.add(Dense(3, activation=\"softmax\"))\n",
    "\n",
    "model.compile(loss='categorical_crossentropy', optimizer=Adam(), metrics=['accuracy'])\n",
    "\n",
    "es=EarlyStopping(monitor=\"val_loss\",patience=50,verbose=1)\n",
    "clr = CyclicLR(base_lr=0.001, max_lr=0.006,\n",
    "                                step_size=2000., mode='triangular')\n",
    "\n",
    "model.fit(X_train,\n",
    "          y_train,\n",
    "          epochs=1000,\n",
    "               batch_size=512,\n",
    "               validation_split=0.1,\n",
    "               verbose=1,callbacks=[es, clr])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 123,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "469/469 [==============================] - 0s 270us/step\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0       0.56      0.64      0.60      2674\n",
      "           1       0.67      0.71      0.69      4348\n",
      "           2       0.74      0.68      0.71      7972\n",
      "\n",
      "    accuracy                           0.68     14994\n",
      "   macro avg       0.66      0.68      0.67     14994\n",
      "weighted avg       0.69      0.68      0.68     14994\n",
      "\n"
     ]
    }
   ],
   "source": [
    "y_pred = model.predict(X_test)\n",
    "y_pred_classes = np.argmax(y_pred, axis=1)\n",
    "y_true = np.argmax(y_test, axis=1)\n",
    "print(classification_report(y_true, y_pred_classes))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 124,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "2656/2656 [==============================] - 1s 251us/step\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0       0.57      0.65      0.61     15149\n",
      "           1       0.68      0.71      0.69     24640\n",
      "           2       0.75      0.69      0.72     45177\n",
      "\n",
      "    accuracy                           0.69     84966\n",
      "   macro avg       0.67      0.68      0.67     84966\n",
      "weighted avg       0.70      0.69      0.69     84966\n",
      "\n"
     ]
    }
   ],
   "source": [
    "y_t_pred = model.predict(X_train)\n",
    "y_t_pred_classes = np.argmax(y_t_pred, axis=1)\n",
    "y_t_true = np.argmax(y_train, axis=1)\n",
    "print(classification_report(y_t_true, y_t_pred_classes))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 129,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[<matplotlib.lines.Line2D at 0x141ff2530>]"
      ]
     },
     "execution_count": 129,
     "metadata": {},
     "output_type": "execute_result"
    },
    {
     "data": {
      "image/png": "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",
      "text/plain": [
       "<Figure size 1200x600 with 1 Axes>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "plt.xlabel('Training Iterations')\n",
    "plt.ylabel('Learning Rate')\n",
    "plt.title(\"'triangular2' Policy Reset at 20000 Iterations\")\n",
    "plt.plot(clr.history['iterations'], clr.history['lr'])"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "**_______________________________________________________________________________________________________**"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## With Class Weight"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 133,
   "metadata": {},
   "outputs": [],
   "source": [
    "X=df.drop('Credit_Score',axis=1)\n",
    "y = df.Credit_Score\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 134,
   "metadata": {},
   "outputs": [],
   "source": [
    "y=to_categorical(y, num_classes=3)\n",
    "\n",
    "X_train, X_test, y_train, y_test = train_test_split(X,y,test_size=0.15,shuffle=True,stratify=y,random_state=42)\n",
    "\n",
    "scaler = RobustScaler()\n",
    "X_train = scaler.fit_transform(X_train)\n",
    "X_test = scaler.transform(X_test)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 135,
   "metadata": {},
   "outputs": [],
   "source": [
    "class_weights = {}\n",
    "for i in range(3):\n",
    "    class_weights[i] = len(X_train) / (3 * np.sum(y_train[:, i]))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 137,
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 1/1000\n",
      "150/150 [==============================] - 1s 2ms/step - loss: 0.9525 - accuracy: 0.4372 - val_loss: 0.8921 - val_accuracy: 0.5626\n",
      "Epoch 2/1000\n",
      "150/150 [==============================] - 0s 2ms/step - loss: 0.8401 - accuracy: 0.5890 - val_loss: 0.7619 - val_accuracy: 0.6711\n",
      "Epoch 3/1000\n",
      "150/150 [==============================] - 0s 3ms/step - loss: 0.7893 - accuracy: 0.6374 - val_loss: 0.7375 - val_accuracy: 0.6755\n",
      "Epoch 4/1000\n",
      "150/150 [==============================] - 0s 2ms/step - loss: 0.7667 - accuracy: 0.6526 - val_loss: 0.7335 - val_accuracy: 0.6778\n",
      "Epoch 5/1000\n",
      "150/150 [==============================] - 0s 2ms/step - loss: 0.7601 - accuracy: 0.6562 - val_loss: 0.7280 - val_accuracy: 0.6812\n",
      "Epoch 6/1000\n",
      "150/150 [==============================] - 0s 2ms/step - loss: 0.7538 - accuracy: 0.6580 - val_loss: 0.7456 - val_accuracy: 0.6826\n",
      "Epoch 7/1000\n",
      "150/150 [==============================] - 0s 2ms/step - loss: 0.7494 - accuracy: 0.6588 - val_loss: 0.7285 - val_accuracy: 0.6842\n",
      "Epoch 8/1000\n",
      "150/150 [==============================] - 0s 2ms/step - loss: 0.7465 - accuracy: 0.6611 - val_loss: 0.7286 - val_accuracy: 0.6868\n",
      "Epoch 9/1000\n",
      "150/150 [==============================] - 0s 2ms/step - loss: 0.7419 - accuracy: 0.6636 - val_loss: 0.7320 - val_accuracy: 0.6835\n",
      "Epoch 10/1000\n",
      "150/150 [==============================] - 0s 3ms/step - loss: 0.7408 - accuracy: 0.6645 - val_loss: 0.7478 - val_accuracy: 0.6869\n",
      "Epoch 11/1000\n",
      "150/150 [==============================] - 0s 2ms/step - loss: 0.7396 - accuracy: 0.6658 - val_loss: 0.7152 - val_accuracy: 0.6880\n",
      "Epoch 12/1000\n",
      "150/150 [==============================] - 0s 2ms/step - loss: 0.7388 - accuracy: 0.6648 - val_loss: 0.7405 - val_accuracy: 0.6872\n",
      "Epoch 13/1000\n",
      "150/150 [==============================] - 0s 2ms/step - loss: 0.7391 - accuracy: 0.6623 - val_loss: 0.7226 - val_accuracy: 0.6851\n",
      "Epoch 14/1000\n",
      "150/150 [==============================] - 0s 2ms/step - loss: 0.7405 - accuracy: 0.6628 - val_loss: 0.7393 - val_accuracy: 0.6844\n",
      "Epoch 15/1000\n",
      "150/150 [==============================] - 0s 2ms/step - loss: 0.7397 - accuracy: 0.6635 - val_loss: 0.7194 - val_accuracy: 0.6845\n",
      "Epoch 16/1000\n",
      "150/150 [==============================] - 0s 2ms/step - loss: 0.7343 - accuracy: 0.6641 - val_loss: 0.7443 - val_accuracy: 0.6831\n",
      "Epoch 17/1000\n",
      "150/150 [==============================] - 0s 2ms/step - loss: 0.7350 - accuracy: 0.6651 - val_loss: 0.7300 - val_accuracy: 0.6847\n",
      "Epoch 18/1000\n",
      "150/150 [==============================] - 0s 2ms/step - loss: 0.7309 - accuracy: 0.6671 - val_loss: 0.7399 - val_accuracy: 0.6755\n",
      "Epoch 19/1000\n",
      "150/150 [==============================] - 0s 2ms/step - loss: 0.7287 - accuracy: 0.6681 - val_loss: 0.7375 - val_accuracy: 0.6846\n",
      "Epoch 20/1000\n",
      "150/150 [==============================] - 0s 2ms/step - loss: 0.7273 - accuracy: 0.6675 - val_loss: 0.7363 - val_accuracy: 0.6858\n",
      "Epoch 21/1000\n",
      "150/150 [==============================] - 0s 2ms/step - loss: 0.7249 - accuracy: 0.6697 - val_loss: 0.7363 - val_accuracy: 0.6842\n",
      "Epoch 22/1000\n",
      "150/150 [==============================] - 0s 2ms/step - loss: 0.7240 - accuracy: 0.6681 - val_loss: 0.7484 - val_accuracy: 0.6824\n",
      "Epoch 23/1000\n",
      "150/150 [==============================] - 0s 2ms/step - loss: 0.7215 - accuracy: 0.6688 - val_loss: 0.7457 - val_accuracy: 0.6821\n",
      "Epoch 24/1000\n",
      "150/150 [==============================] - 0s 2ms/step - loss: 0.7204 - accuracy: 0.6702 - val_loss: 0.7486 - val_accuracy: 0.6854\n",
      "Epoch 25/1000\n",
      "150/150 [==============================] - 0s 2ms/step - loss: 0.7170 - accuracy: 0.6717 - val_loss: 0.7388 - val_accuracy: 0.6804\n",
      "Epoch 26/1000\n",
      "150/150 [==============================] - 0s 2ms/step - loss: 0.7165 - accuracy: 0.6718 - val_loss: 0.7358 - val_accuracy: 0.6821\n",
      "Epoch 27/1000\n",
      "150/150 [==============================] - 0s 2ms/step - loss: 0.7158 - accuracy: 0.6718 - val_loss: 0.7349 - val_accuracy: 0.6821\n",
      "Epoch 28/1000\n",
      "150/150 [==============================] - 0s 2ms/step - loss: 0.7150 - accuracy: 0.6718 - val_loss: 0.7420 - val_accuracy: 0.6785\n",
      "Epoch 29/1000\n",
      "150/150 [==============================] - 0s 2ms/step - loss: 0.7145 - accuracy: 0.6726 - val_loss: 0.7430 - val_accuracy: 0.6814\n",
      "Epoch 30/1000\n",
      "150/150 [==============================] - 0s 2ms/step - loss: 0.7148 - accuracy: 0.6717 - val_loss: 0.7294 - val_accuracy: 0.6815\n",
      "Epoch 31/1000\n",
      "150/150 [==============================] - 0s 3ms/step - loss: 0.7161 - accuracy: 0.6723 - val_loss: 0.7542 - val_accuracy: 0.6820\n",
      "Epoch 32/1000\n",
      "150/150 [==============================] - 0s 2ms/step - loss: 0.7171 - accuracy: 0.6699 - val_loss: 0.7513 - val_accuracy: 0.6834\n",
      "Epoch 33/1000\n",
      "150/150 [==============================] - 0s 2ms/step - loss: 0.7198 - accuracy: 0.6712 - val_loss: 0.7405 - val_accuracy: 0.6855\n",
      "Epoch 34/1000\n",
      "150/150 [==============================] - 0s 2ms/step - loss: 0.7220 - accuracy: 0.6702 - val_loss: 0.7445 - val_accuracy: 0.6854\n",
      "Epoch 35/1000\n",
      "150/150 [==============================] - 0s 2ms/step - loss: 0.7203 - accuracy: 0.6690 - val_loss: 0.7592 - val_accuracy: 0.6819\n",
      "Epoch 36/1000\n",
      "150/150 [==============================] - 0s 2ms/step - loss: 0.7227 - accuracy: 0.6689 - val_loss: 0.7368 - val_accuracy: 0.6820\n",
      "Epoch 37/1000\n",
      "150/150 [==============================] - 0s 2ms/step - loss: 0.7255 - accuracy: 0.6687 - val_loss: 0.7322 - val_accuracy: 0.6860\n",
      "Epoch 38/1000\n",
      "150/150 [==============================] - 0s 2ms/step - loss: 0.7260 - accuracy: 0.6673 - val_loss: 0.7361 - val_accuracy: 0.6821\n",
      "Epoch 39/1000\n",
      "150/150 [==============================] - 0s 2ms/step - loss: 0.7265 - accuracy: 0.6662 - val_loss: 0.7327 - val_accuracy: 0.6785\n",
      "Epoch 40/1000\n",
      "150/150 [==============================] - 0s 2ms/step - loss: 0.7276 - accuracy: 0.6674 - val_loss: 0.7342 - val_accuracy: 0.6736\n",
      "Epoch 41/1000\n",
      "150/150 [==============================] - 0s 2ms/step - loss: 0.7299 - accuracy: 0.6664 - val_loss: 0.7252 - val_accuracy: 0.6858\n",
      "Epoch 42/1000\n",
      "150/150 [==============================] - 0s 2ms/step - loss: 0.7278 - accuracy: 0.6665 - val_loss: 0.7218 - val_accuracy: 0.6859\n",
      "Epoch 43/1000\n",
      "150/150 [==============================] - 0s 2ms/step - loss: 0.7253 - accuracy: 0.6660 - val_loss: 0.7444 - val_accuracy: 0.6847\n",
      "Epoch 44/1000\n",
      "150/150 [==============================] - 0s 2ms/step - loss: 0.7251 - accuracy: 0.6664 - val_loss: 0.7293 - val_accuracy: 0.6873\n",
      "Epoch 45/1000\n",
      "150/150 [==============================] - 0s 2ms/step - loss: 0.7239 - accuracy: 0.6681 - val_loss: 0.7361 - val_accuracy: 0.6869\n",
      "Epoch 46/1000\n",
      "150/150 [==============================] - 0s 2ms/step - loss: 0.7211 - accuracy: 0.6693 - val_loss: 0.7382 - val_accuracy: 0.6829\n",
      "Epoch 47/1000\n",
      "150/150 [==============================] - 0s 2ms/step - loss: 0.7187 - accuracy: 0.6693 - val_loss: 0.7395 - val_accuracy: 0.6874\n",
      "Epoch 48/1000\n",
      "150/150 [==============================] - 0s 2ms/step - loss: 0.7190 - accuracy: 0.6712 - val_loss: 0.7435 - val_accuracy: 0.6857\n",
      "Epoch 49/1000\n",
      "150/150 [==============================] - 0s 2ms/step - loss: 0.7178 - accuracy: 0.6697 - val_loss: 0.7311 - val_accuracy: 0.6875\n",
      "Epoch 50/1000\n",
      "150/150 [==============================] - 0s 2ms/step - loss: 0.7150 - accuracy: 0.6709 - val_loss: 0.7382 - val_accuracy: 0.6862\n",
      "Epoch 51/1000\n",
      "150/150 [==============================] - 0s 2ms/step - loss: 0.7139 - accuracy: 0.6714 - val_loss: 0.7488 - val_accuracy: 0.6854\n",
      "Epoch 52/1000\n",
      "150/150 [==============================] - 0s 2ms/step - loss: 0.7135 - accuracy: 0.6728 - val_loss: 0.7340 - val_accuracy: 0.6866\n",
      "Epoch 53/1000\n",
      "150/150 [==============================] - 0s 2ms/step - loss: 0.7118 - accuracy: 0.6717 - val_loss: 0.7316 - val_accuracy: 0.6860\n",
      "Epoch 54/1000\n",
      "150/150 [==============================] - 0s 3ms/step - loss: 0.7086 - accuracy: 0.6716 - val_loss: 0.7330 - val_accuracy: 0.6884\n",
      "Epoch 55/1000\n",
      "150/150 [==============================] - 0s 2ms/step - loss: 0.7114 - accuracy: 0.6717 - val_loss: 0.7295 - val_accuracy: 0.6867\n",
      "Epoch 56/1000\n",
      "150/150 [==============================] - 0s 2ms/step - loss: 0.7098 - accuracy: 0.6721 - val_loss: 0.7282 - val_accuracy: 0.6867\n",
      "Epoch 57/1000\n",
      "150/150 [==============================] - 0s 2ms/step - loss: 0.7126 - accuracy: 0.6718 - val_loss: 0.7353 - val_accuracy: 0.6866\n",
      "Epoch 58/1000\n",
      "150/150 [==============================] - 0s 2ms/step - loss: 0.7110 - accuracy: 0.6721 - val_loss: 0.7364 - val_accuracy: 0.6853\n",
      "Epoch 59/1000\n",
      "150/150 [==============================] - 0s 2ms/step - loss: 0.7125 - accuracy: 0.6728 - val_loss: 0.7335 - val_accuracy: 0.6859\n",
      "Epoch 60/1000\n",
      "150/150 [==============================] - 0s 2ms/step - loss: 0.7132 - accuracy: 0.6729 - val_loss: 0.7226 - val_accuracy: 0.6873\n",
      "Epoch 61/1000\n",
      "150/150 [==============================] - 0s 2ms/step - loss: 0.7177 - accuracy: 0.6708 - val_loss: 0.7337 - val_accuracy: 0.6865\n",
      "Epoch 61: early stopping\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "<keras.src.callbacks.History at 0x1425c7670>"
      ]
     },
     "execution_count": 137,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "model=Sequential()\n",
    "model.add(Dense(128, activation=\"relu\"))\n",
    "model.add(Dropout(0.8))\n",
    "model.add(Dense(128, activation=\"relu\"))\n",
    "\n",
    "model.add(Dense(64, activation=\"relu\"))\n",
    "model.add(Dropout(0.2))\n",
    "model.add(Dense(64, activation=\"relu\"))\n",
    "\n",
    "model.add(Dense(32, activation=\"relu\"))\n",
    "model.add(Dropout(0.2))\n",
    "model.add(Dense(16, activation=\"relu\"))\n",
    "model.add(Dropout(0.2))\n",
    "model.add(Dense(3, activation=\"softmax\"))\n",
    "\n",
    "model.compile(loss='categorical_crossentropy', optimizer=Adam(), metrics=['accuracy'])\n",
    "\n",
    "es=EarlyStopping(monitor=\"val_loss\",patience=50,mode=\"auto\",verbose=1)\n",
    "clr = CyclicLR(base_lr=0.0005, max_lr=0.006,\n",
    "                                step_size=2000., mode='triangular')\n",
    "\n",
    "model.fit(X_train,\n",
    "          y_train,\n",
    "          epochs=1000,\n",
    "          batch_size=512,\n",
    "          validation_split=0.1,\n",
    "          verbose=1,callbacks=[es, clr],\n",
    "          class_weight=class_weights)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 138,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "469/469 [==============================] - 0s 269us/step\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0       0.51      0.83      0.63      2674\n",
      "           1       0.62      0.80      0.70      4348\n",
      "           2       0.86      0.54      0.67      7972\n",
      "\n",
      "    accuracy                           0.67     14994\n",
      "   macro avg       0.66      0.72      0.67     14994\n",
      "weighted avg       0.73      0.67      0.67     14994\n",
      "\n"
     ]
    }
   ],
   "source": [
    "y_pred = model.predict(X_test)\n",
    "y_pred_classes = np.argmax(y_pred, axis=1)\n",
    "y_true = np.argmax(y_test, axis=1)\n",
    "print(classification_report(y_true, y_pred_classes))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 139,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "2656/2656 [==============================] - 1s 269us/step\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0       0.51      0.83      0.64     15149\n",
      "           1       0.62      0.79      0.70     24640\n",
      "           2       0.87      0.56      0.68     45177\n",
      "\n",
      "    accuracy                           0.68     84966\n",
      "   macro avg       0.67      0.73      0.67     84966\n",
      "weighted avg       0.73      0.68      0.68     84966\n",
      "\n"
     ]
    }
   ],
   "source": [
    "y_t_pred = model.predict(X_train)\n",
    "y_t_pred_classes = np.argmax(y_t_pred, axis=1)\n",
    "y_t_true = np.argmax(y_train, axis=1)\n",
    "print(classification_report(y_t_true, y_t_pred_classes))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "**____________________________________________________________________________________________________**"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 140,
   "metadata": {},
   "outputs": [],
   "source": [
    "X=df.drop('Credit_Score',axis=1)\n",
    "y = df.Credit_Score\n",
    "\n",
    "smote = SMOTE() \n",
    "X, y = smote.fit_resample(X,y)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 141,
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "y=to_categorical(y, num_classes=3)\n",
    "\n",
    "X_train, X_test, y_train, y_test = train_test_split(X,y,test_size=0.15,shuffle=True,stratify=y,random_state=42)\n",
    "\n",
    "scaler = RobustScaler()\n",
    "X_train = scaler.fit_transform(X_train)\n",
    "X_test = scaler.transform(X_test)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 142,
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 1/1000\n",
      "239/239 [==============================] - 1s 3ms/step - loss: 1.0549 - accuracy: 0.5083 - val_loss: 0.8613 - val_accuracy: 0.5731\n",
      "Epoch 2/1000\n",
      "239/239 [==============================] - 1s 2ms/step - loss: 0.8590 - accuracy: 0.5868 - val_loss: 0.8031 - val_accuracy: 0.6220\n",
      "Epoch 3/1000\n",
      "239/239 [==============================] - 0s 2ms/step - loss: 0.8055 - accuracy: 0.6628 - val_loss: 0.7610 - val_accuracy: 0.7239\n",
      "Epoch 4/1000\n",
      "239/239 [==============================] - 1s 2ms/step - loss: 0.7770 - accuracy: 0.6849 - val_loss: 0.7464 - val_accuracy: 0.7308\n",
      "Epoch 5/1000\n",
      "239/239 [==============================] - 1s 2ms/step - loss: 0.7636 - accuracy: 0.6992 - val_loss: 0.7442 - val_accuracy: 0.7294\n",
      "Epoch 6/1000\n",
      "239/239 [==============================] - 0s 2ms/step - loss: 0.7576 - accuracy: 0.7044 - val_loss: 0.7403 - val_accuracy: 0.7375\n",
      "Epoch 7/1000\n",
      "239/239 [==============================] - 1s 2ms/step - loss: 0.7538 - accuracy: 0.7035 - val_loss: 0.7485 - val_accuracy: 0.7373\n",
      "Epoch 8/1000\n",
      "239/239 [==============================] - 0s 2ms/step - loss: 0.7510 - accuracy: 0.7036 - val_loss: 0.7429 - val_accuracy: 0.7305\n",
      "Epoch 9/1000\n",
      "239/239 [==============================] - 1s 2ms/step - loss: 0.7476 - accuracy: 0.7048 - val_loss: 0.7555 - val_accuracy: 0.7332\n",
      "Epoch 10/1000\n",
      "239/239 [==============================] - 1s 2ms/step - loss: 0.7432 - accuracy: 0.7079 - val_loss: 0.7493 - val_accuracy: 0.7354\n",
      "Epoch 11/1000\n",
      "239/239 [==============================] - 0s 2ms/step - loss: 0.7375 - accuracy: 0.7109 - val_loss: 0.7325 - val_accuracy: 0.7376\n",
      "Epoch 12/1000\n",
      "239/239 [==============================] - 1s 2ms/step - loss: 0.7325 - accuracy: 0.7121 - val_loss: 0.7530 - val_accuracy: 0.7354\n",
      "Epoch 13/1000\n",
      "239/239 [==============================] - 0s 2ms/step - loss: 0.7281 - accuracy: 0.7128 - val_loss: 0.7414 - val_accuracy: 0.7378\n",
      "Epoch 14/1000\n",
      "239/239 [==============================] - 1s 2ms/step - loss: 0.7242 - accuracy: 0.7152 - val_loss: 0.7293 - val_accuracy: 0.7415\n",
      "Epoch 15/1000\n",
      "239/239 [==============================] - 0s 2ms/step - loss: 0.7190 - accuracy: 0.7176 - val_loss: 0.7331 - val_accuracy: 0.7394\n",
      "Epoch 16/1000\n",
      "239/239 [==============================] - 1s 2ms/step - loss: 0.7172 - accuracy: 0.7191 - val_loss: 0.7282 - val_accuracy: 0.7404\n",
      "Epoch 17/1000\n",
      "239/239 [==============================] - 1s 2ms/step - loss: 0.7133 - accuracy: 0.7212 - val_loss: 0.7286 - val_accuracy: 0.7403\n",
      "Epoch 18/1000\n",
      "239/239 [==============================] - 1s 2ms/step - loss: 0.7139 - accuracy: 0.7210 - val_loss: 0.7287 - val_accuracy: 0.7402\n",
      "Epoch 19/1000\n",
      "239/239 [==============================] - 1s 2ms/step - loss: 0.7148 - accuracy: 0.7199 - val_loss: 0.7247 - val_accuracy: 0.7412\n",
      "Epoch 20/1000\n",
      "239/239 [==============================] - 1s 2ms/step - loss: 0.7164 - accuracy: 0.7194 - val_loss: 0.7270 - val_accuracy: 0.7393\n",
      "Epoch 21/1000\n",
      "239/239 [==============================] - 1s 2ms/step - loss: 0.7210 - accuracy: 0.7179 - val_loss: 0.7281 - val_accuracy: 0.7389\n",
      "Epoch 22/1000\n",
      "239/239 [==============================] - 0s 2ms/step - loss: 0.7230 - accuracy: 0.7156 - val_loss: 0.7238 - val_accuracy: 0.7396\n",
      "Epoch 23/1000\n",
      "239/239 [==============================] - 1s 2ms/step - loss: 0.7251 - accuracy: 0.7152 - val_loss: 0.7389 - val_accuracy: 0.7363\n",
      "Epoch 24/1000\n",
      "239/239 [==============================] - 1s 2ms/step - loss: 0.7296 - accuracy: 0.7131 - val_loss: 0.7453 - val_accuracy: 0.7375\n",
      "Epoch 25/1000\n",
      "239/239 [==============================] - 1s 2ms/step - loss: 0.7315 - accuracy: 0.7116 - val_loss: 0.7303 - val_accuracy: 0.7440\n",
      "Epoch 26/1000\n",
      "239/239 [==============================] - 1s 2ms/step - loss: 0.7329 - accuracy: 0.7111 - val_loss: 0.7347 - val_accuracy: 0.7399\n",
      "Epoch 27/1000\n",
      "239/239 [==============================] - 1s 2ms/step - loss: 0.7279 - accuracy: 0.7143 - val_loss: 0.7322 - val_accuracy: 0.7390\n",
      "Epoch 28/1000\n",
      "239/239 [==============================] - 1s 2ms/step - loss: 0.7249 - accuracy: 0.7130 - val_loss: 0.7374 - val_accuracy: 0.7390\n",
      "Epoch 29/1000\n",
      "239/239 [==============================] - 1s 2ms/step - loss: 0.7260 - accuracy: 0.7129 - val_loss: 0.7376 - val_accuracy: 0.7387\n",
      "Epoch 30/1000\n",
      "239/239 [==============================] - 1s 2ms/step - loss: 0.7223 - accuracy: 0.7148 - val_loss: 0.7278 - val_accuracy: 0.7379\n",
      "Epoch 31/1000\n",
      "239/239 [==============================] - 1s 2ms/step - loss: 0.7187 - accuracy: 0.7180 - val_loss: 0.7270 - val_accuracy: 0.7387\n",
      "Epoch 32/1000\n",
      "239/239 [==============================] - 1s 2ms/step - loss: 0.7156 - accuracy: 0.7179 - val_loss: 0.7212 - val_accuracy: 0.7390\n",
      "Epoch 33/1000\n",
      "239/239 [==============================] - 0s 2ms/step - loss: 0.7138 - accuracy: 0.7190 - val_loss: 0.7254 - val_accuracy: 0.7390\n",
      "Epoch 34/1000\n",
      "239/239 [==============================] - 0s 2ms/step - loss: 0.7119 - accuracy: 0.7204 - val_loss: 0.7267 - val_accuracy: 0.7398\n",
      "Epoch 35/1000\n",
      "239/239 [==============================] - 1s 2ms/step - loss: 0.7113 - accuracy: 0.7199 - val_loss: 0.7311 - val_accuracy: 0.7410\n",
      "Epoch 36/1000\n",
      "239/239 [==============================] - 1s 2ms/step - loss: 0.7128 - accuracy: 0.7193 - val_loss: 0.7310 - val_accuracy: 0.7379\n",
      "Epoch 37/1000\n",
      "239/239 [==============================] - 1s 2ms/step - loss: 0.7132 - accuracy: 0.7196 - val_loss: 0.7286 - val_accuracy: 0.7384\n",
      "Epoch 38/1000\n",
      "239/239 [==============================] - 1s 2ms/step - loss: 0.7164 - accuracy: 0.7178 - val_loss: 0.7280 - val_accuracy: 0.7385\n",
      "Epoch 39/1000\n",
      "239/239 [==============================] - 0s 2ms/step - loss: 0.7189 - accuracy: 0.7169 - val_loss: 0.7266 - val_accuracy: 0.7409\n",
      "Epoch 40/1000\n",
      "239/239 [==============================] - 1s 2ms/step - loss: 0.7231 - accuracy: 0.7167 - val_loss: 0.7263 - val_accuracy: 0.7357\n",
      "Epoch 41/1000\n",
      "239/239 [==============================] - 0s 2ms/step - loss: 0.7256 - accuracy: 0.7148 - val_loss: 0.7277 - val_accuracy: 0.7379\n",
      "Epoch 42/1000\n",
      "239/239 [==============================] - 0s 2ms/step - loss: 0.7288 - accuracy: 0.7132 - val_loss: 0.7344 - val_accuracy: 0.7403\n",
      "Epoch 43/1000\n",
      "239/239 [==============================] - 0s 2ms/step - loss: 0.7269 - accuracy: 0.7130 - val_loss: 0.7219 - val_accuracy: 0.7375\n",
      "Epoch 44/1000\n",
      "239/239 [==============================] - 0s 2ms/step - loss: 0.7260 - accuracy: 0.7148 - val_loss: 0.7364 - val_accuracy: 0.7392\n",
      "Epoch 45/1000\n",
      "239/239 [==============================] - 0s 2ms/step - loss: 0.7238 - accuracy: 0.7164 - val_loss: 0.7272 - val_accuracy: 0.7392\n",
      "Epoch 46/1000\n",
      "239/239 [==============================] - 0s 2ms/step - loss: 0.7229 - accuracy: 0.7157 - val_loss: 0.7259 - val_accuracy: 0.7397\n",
      "Epoch 47/1000\n",
      "239/239 [==============================] - 0s 2ms/step - loss: 0.7184 - accuracy: 0.7170 - val_loss: 0.7213 - val_accuracy: 0.7401\n",
      "Epoch 48/1000\n",
      "239/239 [==============================] - 0s 2ms/step - loss: 0.7152 - accuracy: 0.7175 - val_loss: 0.7174 - val_accuracy: 0.7401\n",
      "Epoch 49/1000\n",
      "239/239 [==============================] - 0s 2ms/step - loss: 0.7126 - accuracy: 0.7194 - val_loss: 0.7250 - val_accuracy: 0.7404\n",
      "Epoch 50/1000\n",
      "239/239 [==============================] - 1s 2ms/step - loss: 0.7107 - accuracy: 0.7201 - val_loss: 0.7196 - val_accuracy: 0.7407\n",
      "Epoch 51/1000\n",
      "239/239 [==============================] - 0s 2ms/step - loss: 0.7099 - accuracy: 0.7213 - val_loss: 0.7212 - val_accuracy: 0.7418\n",
      "Epoch 52/1000\n",
      "239/239 [==============================] - 1s 2ms/step - loss: 0.7125 - accuracy: 0.7219 - val_loss: 0.7232 - val_accuracy: 0.7406\n",
      "Epoch 53/1000\n",
      "239/239 [==============================] - 1s 2ms/step - loss: 0.7107 - accuracy: 0.7220 - val_loss: 0.7298 - val_accuracy: 0.7409\n",
      "Epoch 54/1000\n",
      "239/239 [==============================] - 1s 2ms/step - loss: 0.7126 - accuracy: 0.7198 - val_loss: 0.7272 - val_accuracy: 0.7395\n",
      "Epoch 55/1000\n",
      "239/239 [==============================] - 1s 2ms/step - loss: 0.7173 - accuracy: 0.7196 - val_loss: 0.7124 - val_accuracy: 0.7411\n",
      "Epoch 56/1000\n",
      "239/239 [==============================] - 1s 2ms/step - loss: 0.7188 - accuracy: 0.7181 - val_loss: 0.7316 - val_accuracy: 0.7411\n",
      "Epoch 57/1000\n",
      "239/239 [==============================] - 0s 2ms/step - loss: 0.7216 - accuracy: 0.7171 - val_loss: 0.7365 - val_accuracy: 0.7404\n",
      "Epoch 58/1000\n",
      "239/239 [==============================] - 1s 2ms/step - loss: 0.7248 - accuracy: 0.7145 - val_loss: 0.7408 - val_accuracy: 0.7401\n",
      "Epoch 59/1000\n",
      "239/239 [==============================] - 1s 2ms/step - loss: 0.7305 - accuracy: 0.7124 - val_loss: 0.7328 - val_accuracy: 0.7350\n",
      "Epoch 60/1000\n",
      "239/239 [==============================] - 1s 2ms/step - loss: 0.7298 - accuracy: 0.7104 - val_loss: 0.7259 - val_accuracy: 0.7373\n",
      "Epoch 61/1000\n",
      "239/239 [==============================] - 0s 2ms/step - loss: 0.7271 - accuracy: 0.7140 - val_loss: 0.7230 - val_accuracy: 0.7383\n",
      "Epoch 62/1000\n",
      "239/239 [==============================] - 0s 2ms/step - loss: 0.7232 - accuracy: 0.7144 - val_loss: 0.7272 - val_accuracy: 0.7404\n",
      "Epoch 63/1000\n",
      "239/239 [==============================] - 0s 2ms/step - loss: 0.7209 - accuracy: 0.7156 - val_loss: 0.7304 - val_accuracy: 0.7395\n",
      "Epoch 64/1000\n",
      "239/239 [==============================] - 1s 2ms/step - loss: 0.7175 - accuracy: 0.7186 - val_loss: 0.7323 - val_accuracy: 0.7395\n",
      "Epoch 65/1000\n",
      "239/239 [==============================] - 0s 2ms/step - loss: 0.7162 - accuracy: 0.7186 - val_loss: 0.7181 - val_accuracy: 0.7401\n",
      "Epoch 66/1000\n",
      "239/239 [==============================] - 0s 2ms/step - loss: 0.7120 - accuracy: 0.7207 - val_loss: 0.7249 - val_accuracy: 0.7409\n",
      "Epoch 67/1000\n",
      "239/239 [==============================] - 0s 2ms/step - loss: 0.7119 - accuracy: 0.7200 - val_loss: 0.7238 - val_accuracy: 0.7411\n",
      "Epoch 68/1000\n",
      "239/239 [==============================] - 1s 2ms/step - loss: 0.7102 - accuracy: 0.7210 - val_loss: 0.7223 - val_accuracy: 0.7410\n",
      "Epoch 69/1000\n",
      "239/239 [==============================] - 1s 2ms/step - loss: 0.7116 - accuracy: 0.7206 - val_loss: 0.7314 - val_accuracy: 0.7398\n",
      "Epoch 70/1000\n",
      "239/239 [==============================] - 1s 2ms/step - loss: 0.7123 - accuracy: 0.7220 - val_loss: 0.7289 - val_accuracy: 0.7397\n",
      "Epoch 71/1000\n",
      "239/239 [==============================] - 1s 2ms/step - loss: 0.7137 - accuracy: 0.7202 - val_loss: 0.7309 - val_accuracy: 0.7398\n",
      "Epoch 72/1000\n",
      "239/239 [==============================] - 1s 2ms/step - loss: 0.7145 - accuracy: 0.7176 - val_loss: 0.7464 - val_accuracy: 0.7401\n",
      "Epoch 73/1000\n",
      "239/239 [==============================] - 0s 2ms/step - loss: 0.7186 - accuracy: 0.7186 - val_loss: 0.7305 - val_accuracy: 0.7395\n",
      "Epoch 74/1000\n",
      "239/239 [==============================] - 0s 2ms/step - loss: 0.7203 - accuracy: 0.7162 - val_loss: 0.7471 - val_accuracy: 0.7296\n",
      "Epoch 75/1000\n",
      "239/239 [==============================] - 0s 2ms/step - loss: 0.7265 - accuracy: 0.7138 - val_loss: 0.7747 - val_accuracy: 0.7370\n",
      "Epoch 76/1000\n",
      "239/239 [==============================] - 0s 2ms/step - loss: 0.7333 - accuracy: 0.7101 - val_loss: 0.7514 - val_accuracy: 0.7390\n",
      "Epoch 77/1000\n",
      "239/239 [==============================] - 0s 2ms/step - loss: 0.7283 - accuracy: 0.7116 - val_loss: 0.7268 - val_accuracy: 0.7386\n",
      "Epoch 78/1000\n",
      "239/239 [==============================] - 0s 2ms/step - loss: 0.7260 - accuracy: 0.7122 - val_loss: 0.7308 - val_accuracy: 0.7356\n",
      "Epoch 79/1000\n",
      "239/239 [==============================] - 0s 2ms/step - loss: 0.7230 - accuracy: 0.7139 - val_loss: 0.7320 - val_accuracy: 0.7342\n",
      "Epoch 80/1000\n",
      "239/239 [==============================] - 0s 2ms/step - loss: 0.7195 - accuracy: 0.7150 - val_loss: 0.7361 - val_accuracy: 0.7384\n",
      "Epoch 81/1000\n",
      "239/239 [==============================] - 0s 2ms/step - loss: 0.7171 - accuracy: 0.7160 - val_loss: 0.7295 - val_accuracy: 0.7372\n",
      "Epoch 82/1000\n",
      "239/239 [==============================] - 0s 2ms/step - loss: 0.7138 - accuracy: 0.7172 - val_loss: 0.7238 - val_accuracy: 0.7374\n",
      "Epoch 83/1000\n",
      "239/239 [==============================] - 0s 2ms/step - loss: 0.7123 - accuracy: 0.7186 - val_loss: 0.7218 - val_accuracy: 0.7384\n",
      "Epoch 84/1000\n",
      "239/239 [==============================] - 0s 2ms/step - loss: 0.7105 - accuracy: 0.7197 - val_loss: 0.7266 - val_accuracy: 0.7381\n",
      "Epoch 85/1000\n",
      "239/239 [==============================] - 0s 2ms/step - loss: 0.7092 - accuracy: 0.7193 - val_loss: 0.7207 - val_accuracy: 0.7386\n",
      "Epoch 86/1000\n",
      "239/239 [==============================] - 1s 2ms/step - loss: 0.7118 - accuracy: 0.7193 - val_loss: 0.7244 - val_accuracy: 0.7367\n",
      "Epoch 87/1000\n",
      "239/239 [==============================] - 1s 2ms/step - loss: 0.7126 - accuracy: 0.7187 - val_loss: 0.7304 - val_accuracy: 0.7380\n",
      "Epoch 88/1000\n",
      "239/239 [==============================] - 0s 2ms/step - loss: 0.7121 - accuracy: 0.7192 - val_loss: 0.7360 - val_accuracy: 0.7369\n",
      "Epoch 89/1000\n",
      "239/239 [==============================] - 0s 2ms/step - loss: 0.7142 - accuracy: 0.7189 - val_loss: 0.7250 - val_accuracy: 0.7381\n",
      "Epoch 90/1000\n",
      "239/239 [==============================] - 0s 2ms/step - loss: 0.7164 - accuracy: 0.7180 - val_loss: 0.7296 - val_accuracy: 0.7359\n",
      "Epoch 91/1000\n",
      "239/239 [==============================] - 0s 2ms/step - loss: 0.7205 - accuracy: 0.7152 - val_loss: 0.7164 - val_accuracy: 0.7386\n",
      "Epoch 92/1000\n",
      "239/239 [==============================] - 1s 2ms/step - loss: 0.7261 - accuracy: 0.7128 - val_loss: 0.7266 - val_accuracy: 0.7392\n",
      "Epoch 93/1000\n",
      "239/239 [==============================] - 0s 2ms/step - loss: 0.7293 - accuracy: 0.7129 - val_loss: 0.7223 - val_accuracy: 0.7331\n",
      "Epoch 94/1000\n",
      "239/239 [==============================] - 0s 2ms/step - loss: 0.7288 - accuracy: 0.7110 - val_loss: 0.7503 - val_accuracy: 0.7372\n",
      "Epoch 95/1000\n",
      "239/239 [==============================] - 1s 2ms/step - loss: 0.7242 - accuracy: 0.7135 - val_loss: 0.7302 - val_accuracy: 0.7347\n",
      "Epoch 96/1000\n",
      "239/239 [==============================] - 1s 2ms/step - loss: 0.7226 - accuracy: 0.7145 - val_loss: 0.7358 - val_accuracy: 0.7400\n",
      "Epoch 97/1000\n",
      "239/239 [==============================] - 1s 2ms/step - loss: 0.7189 - accuracy: 0.7155 - val_loss: 0.7251 - val_accuracy: 0.7365\n",
      "Epoch 98/1000\n",
      "239/239 [==============================] - 1s 2ms/step - loss: 0.7176 - accuracy: 0.7168 - val_loss: 0.7202 - val_accuracy: 0.7380\n",
      "Epoch 99/1000\n",
      "239/239 [==============================] - 0s 2ms/step - loss: 0.7144 - accuracy: 0.7182 - val_loss: 0.7271 - val_accuracy: 0.7396\n",
      "Epoch 100/1000\n",
      "239/239 [==============================] - 0s 2ms/step - loss: 0.7125 - accuracy: 0.7175 - val_loss: 0.7216 - val_accuracy: 0.7390\n",
      "Epoch 101/1000\n",
      "239/239 [==============================] - 0s 2ms/step - loss: 0.7121 - accuracy: 0.7195 - val_loss: 0.7244 - val_accuracy: 0.7393\n",
      "Epoch 102/1000\n",
      "239/239 [==============================] - 0s 2ms/step - loss: 0.7117 - accuracy: 0.7200 - val_loss: 0.7258 - val_accuracy: 0.7377\n",
      "Epoch 103/1000\n",
      "239/239 [==============================] - 0s 2ms/step - loss: 0.7107 - accuracy: 0.7193 - val_loss: 0.7240 - val_accuracy: 0.7388\n",
      "Epoch 104/1000\n",
      "239/239 [==============================] - 0s 2ms/step - loss: 0.7102 - accuracy: 0.7193 - val_loss: 0.7278 - val_accuracy: 0.7396\n",
      "Epoch 105/1000\n",
      "239/239 [==============================] - 0s 2ms/step - loss: 0.7135 - accuracy: 0.7180 - val_loss: 0.7300 - val_accuracy: 0.7374\n",
      "Epoch 105: early stopping\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "<keras.src.callbacks.History at 0x1421f41f0>"
      ]
     },
     "execution_count": 142,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "model=Sequential()\n",
    "model.add(Dense(128, activation=\"relu\"))\n",
    "model.add(Dropout(0.8))\n",
    "model.add(Dense(128, activation=\"relu\"))\n",
    "\n",
    "model.add(Dense(64, activation=\"relu\"))\n",
    "model.add(Dropout(0.2))\n",
    "model.add(Dense(64, activation=\"relu\"))\n",
    "\n",
    "model.add(Dense(32, activation=\"relu\"))\n",
    "model.add(Dropout(0.2))\n",
    "model.add(Dense(16, activation=\"relu\"))\n",
    "model.add(Dropout(0.2))\n",
    "model.add(Dense(3, activation=\"softmax\"))\n",
    "\n",
    "model.compile(loss='categorical_crossentropy', optimizer=Adam(), metrics=['accuracy'])\n",
    "\n",
    "es=EarlyStopping(monitor=\"val_loss\",patience=50,mode=\"auto\",verbose=1)\n",
    "clr = CyclicLR(base_lr=0.0001, max_lr=0.006,\n",
    "                                step_size=2000., mode='triangular')\n",
    "\n",
    "model.fit(X_train,\n",
    "          y_train,\n",
    "          epochs=1000,\n",
    "          batch_size=512,\n",
    "          validation_split=0.1,\n",
    "          verbose=1,callbacks=[es, clr],\n",
    "          class_weight=class_weights)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 143,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "748/748 [==============================] - 0s 258us/step\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0       0.70      0.88      0.78      7973\n",
      "           1       0.74      0.77      0.76      7973\n",
      "           2       0.78      0.54      0.64      7972\n",
      "\n",
      "    accuracy                           0.73     23918\n",
      "   macro avg       0.74      0.73      0.73     23918\n",
      "weighted avg       0.74      0.73      0.73     23918\n",
      "\n"
     ]
    }
   ],
   "source": [
    "y_pred = model.predict(X_test)\n",
    "y_pred_classes = np.argmax(y_pred, axis=1)\n",
    "y_true = np.argmax(y_test, axis=1)\n",
    "print(classification_report(y_true, y_pred_classes))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 144,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "4236/4236 [==============================] - 1s 251us/step\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0       0.71      0.89      0.79     45176\n",
      "           1       0.74      0.78      0.76     45176\n",
      "           2       0.78      0.55      0.65     45177\n",
      "\n",
      "    accuracy                           0.74    135529\n",
      "   macro avg       0.75      0.74      0.73    135529\n",
      "weighted avg       0.75      0.74      0.73    135529\n",
      "\n"
     ]
    }
   ],
   "source": [
    "y_t_pred = model.predict(X_train)\n",
    "y_t_pred_classes = np.argmax(y_t_pred, axis=1)\n",
    "y_t_true = np.argmax(y_train, axis=1)\n",
    "print(classification_report(y_t_true, y_t_pred_classes))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 145,
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 1/1000\n",
      "3812/3812 [==============================] - 3s 776us/step - loss: 0.8551 - accuracy: 0.6264 - val_loss: 0.7706 - val_accuracy: 0.7273\n",
      "Epoch 2/1000\n",
      "3812/3812 [==============================] - 3s 753us/step - loss: 0.7925 - accuracy: 0.6808 - val_loss: 0.7603 - val_accuracy: 0.7249\n",
      "Epoch 3/1000\n",
      "3812/3812 [==============================] - 3s 752us/step - loss: 0.7869 - accuracy: 0.6845 - val_loss: 0.7666 - val_accuracy: 0.7219\n",
      "Epoch 4/1000\n",
      "3812/3812 [==============================] - 3s 753us/step - loss: 0.7932 - accuracy: 0.6795 - val_loss: 0.7701 - val_accuracy: 0.7221\n",
      "Epoch 5/1000\n",
      "3812/3812 [==============================] - 3s 766us/step - loss: 0.8025 - accuracy: 0.6690 - val_loss: 0.7805 - val_accuracy: 0.7237\n",
      "Epoch 6/1000\n",
      "3812/3812 [==============================] - 3s 761us/step - loss: 0.8020 - accuracy: 0.6777 - val_loss: 0.7870 - val_accuracy: 0.7233\n",
      "Epoch 7/1000\n",
      "3812/3812 [==============================] - 3s 776us/step - loss: 0.7995 - accuracy: 0.6807 - val_loss: 0.8280 - val_accuracy: 0.7235\n",
      "Epoch 8/1000\n",
      "3812/3812 [==============================] - 3s 762us/step - loss: 0.8059 - accuracy: 0.6738 - val_loss: 0.7918 - val_accuracy: 0.7260\n",
      "Epoch 9/1000\n",
      "3812/3812 [==============================] - 3s 759us/step - loss: 0.8146 - accuracy: 0.6759 - val_loss: 0.8007 - val_accuracy: 0.7235\n",
      "Epoch 10/1000\n",
      "3812/3812 [==============================] - 3s 762us/step - loss: 0.8314 - accuracy: 0.6450 - val_loss: 0.8253 - val_accuracy: 0.7229\n",
      "Epoch 11/1000\n",
      "3812/3812 [==============================] - 3s 756us/step - loss: 0.8268 - accuracy: 0.6427 - val_loss: 0.7948 - val_accuracy: 0.7187\n",
      "Epoch 12/1000\n",
      "3812/3812 [==============================] - 3s 755us/step - loss: 0.8347 - accuracy: 0.6291 - val_loss: 0.7968 - val_accuracy: 0.7236\n",
      "Epoch 13/1000\n",
      "3812/3812 [==============================] - 3s 753us/step - loss: 0.8210 - accuracy: 0.6548 - val_loss: 0.8080 - val_accuracy: 0.7203\n",
      "Epoch 14/1000\n",
      "3812/3812 [==============================] - 3s 754us/step - loss: 0.8143 - accuracy: 0.6620 - val_loss: 0.8318 - val_accuracy: 0.5688\n",
      "Epoch 15/1000\n",
      "3812/3812 [==============================] - 3s 768us/step - loss: 0.8374 - accuracy: 0.6111 - val_loss: 0.8416 - val_accuracy: 0.5726\n",
      "Epoch 16/1000\n",
      "3812/3812 [==============================] - 3s 760us/step - loss: 0.8287 - accuracy: 0.6300 - val_loss: 0.8122 - val_accuracy: 0.7227\n",
      "Epoch 17/1000\n",
      "3812/3812 [==============================] - 3s 754us/step - loss: 0.8262 - accuracy: 0.6491 - val_loss: 0.8413 - val_accuracy: 0.5743\n",
      "Epoch 18/1000\n",
      "3812/3812 [==============================] - 3s 754us/step - loss: 0.8338 - accuracy: 0.6437 - val_loss: 0.8005 - val_accuracy: 0.7201\n",
      "Epoch 19/1000\n",
      "3812/3812 [==============================] - 3s 754us/step - loss: 0.8299 - accuracy: 0.6322 - val_loss: 0.8257 - val_accuracy: 0.5740\n",
      "Epoch 20/1000\n",
      "3812/3812 [==============================] - 3s 754us/step - loss: 0.8414 - accuracy: 0.6168 - val_loss: 0.8404 - val_accuracy: 0.5745\n",
      "Epoch 21/1000\n",
      "3812/3812 [==============================] - 3s 760us/step - loss: 0.8299 - accuracy: 0.6347 - val_loss: 0.8091 - val_accuracy: 0.7201\n",
      "Epoch 22/1000\n",
      "3812/3812 [==============================] - 3s 755us/step - loss: 0.8305 - accuracy: 0.6382 - val_loss: 0.8280 - val_accuracy: 0.5754\n",
      "Epoch 23/1000\n",
      "3812/3812 [==============================] - 3s 753us/step - loss: 0.8332 - accuracy: 0.6176 - val_loss: 0.8269 - val_accuracy: 0.5723\n",
      "Epoch 24/1000\n",
      "3812/3812 [==============================] - 3s 769us/step - loss: 0.8210 - accuracy: 0.6336 - val_loss: 0.8173 - val_accuracy: 0.5743\n",
      "Epoch 25/1000\n",
      "3812/3812 [==============================] - 3s 755us/step - loss: 0.8252 - accuracy: 0.6346 - val_loss: 0.8123 - val_accuracy: 0.7215\n",
      "Epoch 26/1000\n",
      "3812/3812 [==============================] - 3s 754us/step - loss: 0.8289 - accuracy: 0.6182 - val_loss: 0.8200 - val_accuracy: 0.7178\n",
      "Epoch 27/1000\n",
      "3812/3812 [==============================] - 3s 762us/step - loss: 0.8240 - accuracy: 0.6302 - val_loss: 0.8488 - val_accuracy: 0.5710\n",
      "Epoch 28/1000\n",
      "3812/3812 [==============================] - 3s 754us/step - loss: 0.8242 - accuracy: 0.6287 - val_loss: 0.8191 - val_accuracy: 0.7209\n",
      "Epoch 29/1000\n",
      "3812/3812 [==============================] - 3s 754us/step - loss: 0.8275 - accuracy: 0.6112 - val_loss: 0.8573 - val_accuracy: 0.5723\n",
      "Epoch 30/1000\n",
      "3812/3812 [==============================] - 3s 754us/step - loss: 0.8336 - accuracy: 0.5910 - val_loss: 0.8628 - val_accuracy: 0.5751\n",
      "Epoch 31/1000\n",
      "3812/3812 [==============================] - 3s 755us/step - loss: 0.8345 - accuracy: 0.5901 - val_loss: 0.9203 - val_accuracy: 0.5721\n",
      "Epoch 32/1000\n",
      "3812/3812 [==============================] - 3s 776us/step - loss: 0.8784 - accuracy: 0.5716 - val_loss: 0.9352 - val_accuracy: 0.5763\n",
      "Epoch 33/1000\n",
      "3812/3812 [==============================] - 3s 755us/step - loss: 0.8935 - accuracy: 0.5712 - val_loss: 0.9598 - val_accuracy: 0.5729\n",
      "Epoch 34/1000\n",
      "3812/3812 [==============================] - 3s 753us/step - loss: 0.8713 - accuracy: 0.5738 - val_loss: 0.9495 - val_accuracy: 0.5731\n",
      "Epoch 35/1000\n",
      "3812/3812 [==============================] - 3s 755us/step - loss: 0.8670 - accuracy: 0.6072 - val_loss: 0.9293 - val_accuracy: 0.5698\n",
      "Epoch 36/1000\n",
      "3812/3812 [==============================] - 3s 755us/step - loss: 0.8594 - accuracy: 0.6217 - val_loss: 0.8917 - val_accuracy: 0.6692\n",
      "Epoch 37/1000\n",
      "3812/3812 [==============================] - 3s 755us/step - loss: 0.8554 - accuracy: 0.6231 - val_loss: 0.8879 - val_accuracy: 0.6570\n",
      "Epoch 38/1000\n",
      "3812/3812 [==============================] - 3s 761us/step - loss: 0.8478 - accuracy: 0.6289 - val_loss: 0.8699 - val_accuracy: 0.6987\n",
      "Epoch 39/1000\n",
      "3812/3812 [==============================] - 3s 755us/step - loss: 0.8348 - accuracy: 0.6463 - val_loss: 0.8484 - val_accuracy: 0.7052\n",
      "Epoch 40/1000\n",
      "3812/3812 [==============================] - 3s 768us/step - loss: 0.8323 - accuracy: 0.6488 - val_loss: 0.8116 - val_accuracy: 0.7223\n",
      "Epoch 41/1000\n",
      "3812/3812 [==============================] - 3s 753us/step - loss: 0.8385 - accuracy: 0.6534 - val_loss: 0.8182 - val_accuracy: 0.7179\n",
      "Epoch 42/1000\n",
      "3812/3812 [==============================] - 3s 753us/step - loss: 0.8370 - accuracy: 0.6545 - val_loss: 0.8260 - val_accuracy: 0.7231\n",
      "Epoch 43/1000\n",
      "3812/3812 [==============================] - 3s 754us/step - loss: 0.8302 - accuracy: 0.6537 - val_loss: 0.8785 - val_accuracy: 0.6877\n",
      "Epoch 44/1000\n",
      "3812/3812 [==============================] - 3s 757us/step - loss: 0.8278 - accuracy: 0.6545 - val_loss: 0.8401 - val_accuracy: 0.7119\n",
      "Epoch 45/1000\n",
      "3812/3812 [==============================] - 3s 753us/step - loss: 0.8267 - accuracy: 0.6624 - val_loss: 0.8290 - val_accuracy: 0.7176\n",
      "Epoch 46/1000\n",
      "3812/3812 [==============================] - 3s 753us/step - loss: 0.8265 - accuracy: 0.6568 - val_loss: 0.8370 - val_accuracy: 0.7250\n",
      "Epoch 47/1000\n",
      "3812/3812 [==============================] - 3s 754us/step - loss: 0.8119 - accuracy: 0.6715 - val_loss: 0.8194 - val_accuracy: 0.7263\n",
      "Epoch 48/1000\n",
      "3812/3812 [==============================] - 3s 755us/step - loss: 0.8252 - accuracy: 0.6643 - val_loss: 0.7996 - val_accuracy: 0.7243\n",
      "Epoch 49/1000\n",
      "3812/3812 [==============================] - 3s 774us/step - loss: 0.8273 - accuracy: 0.6587 - val_loss: 0.8325 - val_accuracy: 0.7168\n",
      "Epoch 50/1000\n",
      "3812/3812 [==============================] - 3s 755us/step - loss: 0.8353 - accuracy: 0.6579 - val_loss: 0.8006 - val_accuracy: 0.7260\n",
      "Epoch 51/1000\n",
      "3812/3812 [==============================] - 3s 780us/step - loss: 0.8150 - accuracy: 0.6697 - val_loss: 0.8041 - val_accuracy: 0.7232\n",
      "Epoch 52/1000\n",
      "3812/3812 [==============================] - 3s 757us/step - loss: 0.8348 - accuracy: 0.6593 - val_loss: 0.8005 - val_accuracy: 0.7217\n",
      "Epoch 52: early stopping\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "<keras.src.callbacks.History at 0x145eeabc0>"
      ]
     },
     "execution_count": 145,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "model=Sequential()\n",
    "model.add(Dense(128, activation=\"relu\"))\n",
    "model.add(Dropout(0.8))\n",
    "model.add(Dense(128, activation=\"relu\"))\n",
    "\n",
    "model.add(Dense(64, activation=\"relu\"))\n",
    "model.add(Dropout(0.2))\n",
    "model.add(Dense(64, activation=\"relu\"))\n",
    "\n",
    "model.add(Dense(32, activation=\"relu\"))\n",
    "model.add(Dropout(0.2))\n",
    "model.add(Dense(16, activation=\"relu\"))\n",
    "model.add(Dropout(0.2))\n",
    "model.add(Dense(3, activation=\"softmax\"))\n",
    "\n",
    "model.compile(loss='categorical_crossentropy', optimizer=Adam(), metrics=['accuracy'])\n",
    "\n",
    "es=EarlyStopping(monitor=\"val_loss\",patience=50,mode=\"auto\",verbose=1)\n",
    "clr = CyclicLR(base_lr=0.0001, max_lr=0.006,\n",
    "                                step_size=2000., mode='triangular')\n",
    "\n",
    "model.fit(X_train,\n",
    "          y_train,\n",
    "          epochs=1000,\n",
    "          batch_size=32,\n",
    "          validation_split=0.1,\n",
    "          verbose=1,callbacks=[es, clr],\n",
    "          class_weight=class_weights)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 146,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "748/748 [==============================] - 0s 256us/step\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0       0.68      0.87      0.76      7973\n",
      "           1       0.75      0.72      0.74      7973\n",
      "           2       0.73      0.55      0.63      7972\n",
      "\n",
      "    accuracy                           0.71     23918\n",
      "   macro avg       0.72      0.71      0.71     23918\n",
      "weighted avg       0.72      0.71      0.71     23918\n",
      "\n"
     ]
    }
   ],
   "source": [
    "y_pred = model.predict(X_test)\n",
    "y_pred_classes = np.argmax(y_pred, axis=1)\n",
    "y_true = np.argmax(y_test, axis=1)\n",
    "print(classification_report(y_true, y_pred_classes))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 147,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "4236/4236 [==============================] - 1s 250us/step\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0       0.69      0.87      0.77     45176\n",
      "           1       0.76      0.73      0.74     45176\n",
      "           2       0.73      0.57      0.64     45177\n",
      "\n",
      "    accuracy                           0.72    135529\n",
      "   macro avg       0.73      0.72      0.72    135529\n",
      "weighted avg       0.73      0.72      0.72    135529\n",
      "\n"
     ]
    }
   ],
   "source": [
    "y_t_pred = model.predict(X_train)\n",
    "y_t_pred_classes = np.argmax(y_t_pred, axis=1)\n",
    "y_t_true = np.argmax(y_train, axis=1)\n",
    "print(classification_report(y_t_true, y_t_pred_classes))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 148,
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 1/1000\n",
      "239/239 [==============================] - 1s 2ms/step - loss: 0.7171 - accuracy: 0.7156 - val_loss: 0.6886 - val_accuracy: 0.7361\n",
      "Epoch 2/1000\n",
      "239/239 [==============================] - 0s 1ms/step - loss: 0.6573 - accuracy: 0.7435 - val_loss: 0.6581 - val_accuracy: 0.7455\n",
      "Epoch 3/1000\n",
      "239/239 [==============================] - 0s 2ms/step - loss: 0.6400 - accuracy: 0.7496 - val_loss: 0.6427 - val_accuracy: 0.7488\n",
      "Epoch 4/1000\n",
      "239/239 [==============================] - 0s 1ms/step - loss: 0.6269 - accuracy: 0.7534 - val_loss: 0.6299 - val_accuracy: 0.7528\n",
      "Epoch 5/1000\n",
      "239/239 [==============================] - 0s 1ms/step - loss: 0.6127 - accuracy: 0.7596 - val_loss: 0.6173 - val_accuracy: 0.7585\n",
      "Epoch 6/1000\n",
      "239/239 [==============================] - 0s 1ms/step - loss: 0.6010 - accuracy: 0.7640 - val_loss: 0.6045 - val_accuracy: 0.7632\n",
      "Epoch 7/1000\n",
      "239/239 [==============================] - 0s 2ms/step - loss: 0.5860 - accuracy: 0.7695 - val_loss: 0.5996 - val_accuracy: 0.7634\n",
      "Epoch 8/1000\n",
      "239/239 [==============================] - 0s 1ms/step - loss: 0.5728 - accuracy: 0.7750 - val_loss: 0.5872 - val_accuracy: 0.7686\n",
      "Epoch 9/1000\n",
      "239/239 [==============================] - 0s 1ms/step - loss: 0.5586 - accuracy: 0.7807 - val_loss: 0.5824 - val_accuracy: 0.7713\n",
      "Epoch 10/1000\n",
      "239/239 [==============================] - 0s 2ms/step - loss: 0.5450 - accuracy: 0.7864 - val_loss: 0.5734 - val_accuracy: 0.7755\n",
      "Epoch 11/1000\n",
      "239/239 [==============================] - 0s 1ms/step - loss: 0.5313 - accuracy: 0.7914 - val_loss: 0.5650 - val_accuracy: 0.7757\n",
      "Epoch 12/1000\n",
      "239/239 [==============================] - 0s 2ms/step - loss: 0.5186 - accuracy: 0.7974 - val_loss: 0.5497 - val_accuracy: 0.7875\n",
      "Epoch 13/1000\n",
      "239/239 [==============================] - 0s 2ms/step - loss: 0.5055 - accuracy: 0.8033 - val_loss: 0.5472 - val_accuracy: 0.7926\n",
      "Epoch 14/1000\n",
      "239/239 [==============================] - 0s 2ms/step - loss: 0.4953 - accuracy: 0.8066 - val_loss: 0.5406 - val_accuracy: 0.7893\n",
      "Epoch 15/1000\n",
      "239/239 [==============================] - 0s 2ms/step - loss: 0.4835 - accuracy: 0.8126 - val_loss: 0.5455 - val_accuracy: 0.7865\n",
      "Epoch 16/1000\n",
      "239/239 [==============================] - 0s 1ms/step - loss: 0.4744 - accuracy: 0.8156 - val_loss: 0.5262 - val_accuracy: 0.7956\n",
      "Epoch 17/1000\n",
      "239/239 [==============================] - 0s 1ms/step - loss: 0.4628 - accuracy: 0.8214 - val_loss: 0.5214 - val_accuracy: 0.7995\n",
      "Epoch 18/1000\n",
      "239/239 [==============================] - 0s 1ms/step - loss: 0.4562 - accuracy: 0.8234 - val_loss: 0.5113 - val_accuracy: 0.8063\n",
      "Epoch 19/1000\n",
      "239/239 [==============================] - 0s 2ms/step - loss: 0.4467 - accuracy: 0.8275 - val_loss: 0.5219 - val_accuracy: 0.8021\n",
      "Epoch 20/1000\n",
      "239/239 [==============================] - 0s 1ms/step - loss: 0.4381 - accuracy: 0.8319 - val_loss: 0.5270 - val_accuracy: 0.8000\n",
      "Epoch 21/1000\n",
      "239/239 [==============================] - 0s 1ms/step - loss: 0.4320 - accuracy: 0.8337 - val_loss: 0.5043 - val_accuracy: 0.8079\n",
      "Epoch 22/1000\n",
      "239/239 [==============================] - 0s 1ms/step - loss: 0.4234 - accuracy: 0.8386 - val_loss: 0.5026 - val_accuracy: 0.8099\n",
      "Epoch 23/1000\n",
      "239/239 [==============================] - 0s 1ms/step - loss: 0.4160 - accuracy: 0.8404 - val_loss: 0.4906 - val_accuracy: 0.8164\n",
      "Epoch 24/1000\n",
      "239/239 [==============================] - 0s 1ms/step - loss: 0.4108 - accuracy: 0.8430 - val_loss: 0.4885 - val_accuracy: 0.8183\n",
      "Epoch 25/1000\n",
      "239/239 [==============================] - 0s 1ms/step - loss: 0.4020 - accuracy: 0.8464 - val_loss: 0.5007 - val_accuracy: 0.8134\n",
      "Epoch 26/1000\n",
      "239/239 [==============================] - 0s 1ms/step - loss: 0.3967 - accuracy: 0.8491 - val_loss: 0.4864 - val_accuracy: 0.8183\n",
      "Epoch 27/1000\n",
      "239/239 [==============================] - 0s 1ms/step - loss: 0.3911 - accuracy: 0.8516 - val_loss: 0.4884 - val_accuracy: 0.8176\n",
      "Epoch 28/1000\n",
      "239/239 [==============================] - 0s 1ms/step - loss: 0.3866 - accuracy: 0.8518 - val_loss: 0.5081 - val_accuracy: 0.8098\n",
      "Epoch 29/1000\n",
      "239/239 [==============================] - 0s 2ms/step - loss: 0.3806 - accuracy: 0.8551 - val_loss: 0.4890 - val_accuracy: 0.8149\n",
      "Epoch 30/1000\n",
      "239/239 [==============================] - 0s 2ms/step - loss: 0.3761 - accuracy: 0.8577 - val_loss: 0.4853 - val_accuracy: 0.8227\n",
      "Epoch 31/1000\n",
      "239/239 [==============================] - 0s 2ms/step - loss: 0.3707 - accuracy: 0.8587 - val_loss: 0.4769 - val_accuracy: 0.8231\n",
      "Epoch 32/1000\n",
      "239/239 [==============================] - 0s 2ms/step - loss: 0.3692 - accuracy: 0.8598 - val_loss: 0.4760 - val_accuracy: 0.8260\n",
      "Epoch 33/1000\n",
      "239/239 [==============================] - 0s 2ms/step - loss: 0.3614 - accuracy: 0.8629 - val_loss: 0.4781 - val_accuracy: 0.8217\n",
      "Epoch 34/1000\n",
      "239/239 [==============================] - 0s 1ms/step - loss: 0.3592 - accuracy: 0.8637 - val_loss: 0.4804 - val_accuracy: 0.8276\n",
      "Epoch 35/1000\n",
      "239/239 [==============================] - 0s 2ms/step - loss: 0.3550 - accuracy: 0.8652 - val_loss: 0.4719 - val_accuracy: 0.8259\n",
      "Epoch 36/1000\n",
      "239/239 [==============================] - 0s 2ms/step - loss: 0.3525 - accuracy: 0.8666 - val_loss: 0.4721 - val_accuracy: 0.8290\n",
      "Epoch 37/1000\n",
      "239/239 [==============================] - 0s 1ms/step - loss: 0.3467 - accuracy: 0.8693 - val_loss: 0.4771 - val_accuracy: 0.8259\n",
      "Epoch 38/1000\n",
      "239/239 [==============================] - 0s 2ms/step - loss: 0.3451 - accuracy: 0.8699 - val_loss: 0.4725 - val_accuracy: 0.8299\n",
      "Epoch 39/1000\n",
      "239/239 [==============================] - 0s 2ms/step - loss: 0.3414 - accuracy: 0.8708 - val_loss: 0.4691 - val_accuracy: 0.8307\n",
      "Epoch 40/1000\n",
      "239/239 [==============================] - 0s 1ms/step - loss: 0.3378 - accuracy: 0.8730 - val_loss: 0.4715 - val_accuracy: 0.8317\n",
      "Epoch 41/1000\n",
      "239/239 [==============================] - 0s 1ms/step - loss: 0.3358 - accuracy: 0.8736 - val_loss: 0.5024 - val_accuracy: 0.8222\n",
      "Epoch 42/1000\n",
      "239/239 [==============================] - 0s 1ms/step - loss: 0.3320 - accuracy: 0.8746 - val_loss: 0.4757 - val_accuracy: 0.8290\n",
      "Epoch 43/1000\n",
      "239/239 [==============================] - 0s 2ms/step - loss: 0.3295 - accuracy: 0.8758 - val_loss: 0.4693 - val_accuracy: 0.8329\n",
      "Epoch 44/1000\n",
      "239/239 [==============================] - 0s 2ms/step - loss: 0.3284 - accuracy: 0.8757 - val_loss: 0.4856 - val_accuracy: 0.8309\n",
      "Epoch 45/1000\n",
      "239/239 [==============================] - 0s 2ms/step - loss: 0.3242 - accuracy: 0.8779 - val_loss: 0.4853 - val_accuracy: 0.8298\n",
      "Epoch 46/1000\n",
      "239/239 [==============================] - 0s 2ms/step - loss: 0.3205 - accuracy: 0.8795 - val_loss: 0.4810 - val_accuracy: 0.8310\n",
      "Epoch 47/1000\n",
      "239/239 [==============================] - 0s 2ms/step - loss: 0.3198 - accuracy: 0.8798 - val_loss: 0.4752 - val_accuracy: 0.8337\n",
      "Epoch 48/1000\n",
      "239/239 [==============================] - 0s 2ms/step - loss: 0.3205 - accuracy: 0.8798 - val_loss: 0.4731 - val_accuracy: 0.8345\n",
      "Epoch 49/1000\n",
      "239/239 [==============================] - 0s 2ms/step - loss: 0.3147 - accuracy: 0.8815 - val_loss: 0.4819 - val_accuracy: 0.8330\n",
      "Epoch 50/1000\n",
      "239/239 [==============================] - 0s 1ms/step - loss: 0.3123 - accuracy: 0.8831 - val_loss: 0.4826 - val_accuracy: 0.8299\n",
      "Epoch 51/1000\n",
      "239/239 [==============================] - 0s 2ms/step - loss: 0.3090 - accuracy: 0.8835 - val_loss: 0.4803 - val_accuracy: 0.8310\n",
      "Epoch 52/1000\n",
      "239/239 [==============================] - 0s 1ms/step - loss: 0.3085 - accuracy: 0.8830 - val_loss: 0.4742 - val_accuracy: 0.8386\n",
      "Epoch 53/1000\n",
      "239/239 [==============================] - 0s 1ms/step - loss: 0.3061 - accuracy: 0.8854 - val_loss: 0.4743 - val_accuracy: 0.8361\n",
      "Epoch 54/1000\n",
      "239/239 [==============================] - 0s 1ms/step - loss: 0.3019 - accuracy: 0.8875 - val_loss: 0.4879 - val_accuracy: 0.8335\n",
      "Epoch 55/1000\n",
      "239/239 [==============================] - 0s 1ms/step - loss: 0.3041 - accuracy: 0.8859 - val_loss: 0.4792 - val_accuracy: 0.8364\n",
      "Epoch 56/1000\n",
      "239/239 [==============================] - 0s 2ms/step - loss: 0.3003 - accuracy: 0.8870 - val_loss: 0.4859 - val_accuracy: 0.8325\n",
      "Epoch 57/1000\n",
      "239/239 [==============================] - 0s 2ms/step - loss: 0.2998 - accuracy: 0.8874 - val_loss: 0.4891 - val_accuracy: 0.8293\n",
      "Epoch 58/1000\n",
      "239/239 [==============================] - 0s 1ms/step - loss: 0.2948 - accuracy: 0.8892 - val_loss: 0.4796 - val_accuracy: 0.8383\n",
      "Epoch 59/1000\n",
      "239/239 [==============================] - 0s 2ms/step - loss: 0.2947 - accuracy: 0.8897 - val_loss: 0.4901 - val_accuracy: 0.8364\n",
      "Epoch 60/1000\n",
      "239/239 [==============================] - 0s 2ms/step - loss: 0.2935 - accuracy: 0.8892 - val_loss: 0.4748 - val_accuracy: 0.8358\n",
      "Epoch 61/1000\n",
      "239/239 [==============================] - 0s 2ms/step - loss: 0.2930 - accuracy: 0.8897 - val_loss: 0.4823 - val_accuracy: 0.8354\n",
      "Epoch 62/1000\n",
      "239/239 [==============================] - 0s 2ms/step - loss: 0.2891 - accuracy: 0.8913 - val_loss: 0.5044 - val_accuracy: 0.8290\n",
      "Epoch 63/1000\n",
      "239/239 [==============================] - 0s 2ms/step - loss: 0.2874 - accuracy: 0.8919 - val_loss: 0.4798 - val_accuracy: 0.8383\n",
      "Epoch 64/1000\n",
      "239/239 [==============================] - 0s 2ms/step - loss: 0.2859 - accuracy: 0.8922 - val_loss: 0.4785 - val_accuracy: 0.8353\n",
      "Epoch 65/1000\n",
      "239/239 [==============================] - 0s 2ms/step - loss: 0.2871 - accuracy: 0.8915 - val_loss: 0.4894 - val_accuracy: 0.8345\n",
      "Epoch 66/1000\n",
      "239/239 [==============================] - 0s 1ms/step - loss: 0.2829 - accuracy: 0.8944 - val_loss: 0.4998 - val_accuracy: 0.8309\n",
      "Epoch 67/1000\n",
      "239/239 [==============================] - 0s 1ms/step - loss: 0.2833 - accuracy: 0.8930 - val_loss: 0.4822 - val_accuracy: 0.8375\n",
      "Epoch 68/1000\n",
      "239/239 [==============================] - 0s 1ms/step - loss: 0.2798 - accuracy: 0.8951 - val_loss: 0.4852 - val_accuracy: 0.8368\n",
      "Epoch 69/1000\n",
      "239/239 [==============================] - 0s 1ms/step - loss: 0.2789 - accuracy: 0.8951 - val_loss: 0.4942 - val_accuracy: 0.8328\n",
      "Epoch 70/1000\n",
      "239/239 [==============================] - 0s 1ms/step - loss: 0.2781 - accuracy: 0.8952 - val_loss: 0.4943 - val_accuracy: 0.8358\n",
      "Epoch 71/1000\n",
      "239/239 [==============================] - 0s 1ms/step - loss: 0.2779 - accuracy: 0.8952 - val_loss: 0.4814 - val_accuracy: 0.8393\n",
      "Epoch 72/1000\n",
      "239/239 [==============================] - 0s 2ms/step - loss: 0.2748 - accuracy: 0.8966 - val_loss: 0.4915 - val_accuracy: 0.8358\n",
      "Epoch 73/1000\n",
      "239/239 [==============================] - 0s 2ms/step - loss: 0.2743 - accuracy: 0.8963 - val_loss: 0.4926 - val_accuracy: 0.8355\n",
      "Epoch 74/1000\n",
      "239/239 [==============================] - 0s 1ms/step - loss: 0.2699 - accuracy: 0.8985 - val_loss: 0.4887 - val_accuracy: 0.8406\n",
      "Epoch 75/1000\n",
      "239/239 [==============================] - 0s 1ms/step - loss: 0.2727 - accuracy: 0.8975 - val_loss: 0.4883 - val_accuracy: 0.8411\n",
      "Epoch 76/1000\n",
      "239/239 [==============================] - 0s 2ms/step - loss: 0.2676 - accuracy: 0.9002 - val_loss: 0.5010 - val_accuracy: 0.8401\n",
      "Epoch 77/1000\n",
      "239/239 [==============================] - 0s 1ms/step - loss: 0.2681 - accuracy: 0.8992 - val_loss: 0.4968 - val_accuracy: 0.8364\n",
      "Epoch 78/1000\n",
      "239/239 [==============================] - 0s 2ms/step - loss: 0.2640 - accuracy: 0.9007 - val_loss: 0.5200 - val_accuracy: 0.8313\n",
      "Epoch 79/1000\n",
      "239/239 [==============================] - 0s 2ms/step - loss: 0.2669 - accuracy: 0.8987 - val_loss: 0.4892 - val_accuracy: 0.8397\n",
      "Epoch 80/1000\n",
      "239/239 [==============================] - 0s 2ms/step - loss: 0.2653 - accuracy: 0.9004 - val_loss: 0.4952 - val_accuracy: 0.8425\n",
      "Epoch 81/1000\n",
      "239/239 [==============================] - 0s 2ms/step - loss: 0.2635 - accuracy: 0.9004 - val_loss: 0.4878 - val_accuracy: 0.8432\n",
      "Epoch 82/1000\n",
      "239/239 [==============================] - 0s 2ms/step - loss: 0.2629 - accuracy: 0.9007 - val_loss: 0.4907 - val_accuracy: 0.8425\n",
      "Epoch 83/1000\n",
      "239/239 [==============================] - 0s 1ms/step - loss: 0.2615 - accuracy: 0.9019 - val_loss: 0.4960 - val_accuracy: 0.8448\n",
      "Epoch 84/1000\n",
      "239/239 [==============================] - 0s 1ms/step - loss: 0.2598 - accuracy: 0.9019 - val_loss: 0.5089 - val_accuracy: 0.8344\n",
      "Epoch 85/1000\n",
      "239/239 [==============================] - 0s 2ms/step - loss: 0.2588 - accuracy: 0.9026 - val_loss: 0.5023 - val_accuracy: 0.8421\n",
      "Epoch 86/1000\n",
      "239/239 [==============================] - 0s 2ms/step - loss: 0.2591 - accuracy: 0.9022 - val_loss: 0.4951 - val_accuracy: 0.8424\n",
      "Epoch 87/1000\n",
      "239/239 [==============================] - 0s 2ms/step - loss: 0.2561 - accuracy: 0.9036 - val_loss: 0.5230 - val_accuracy: 0.8363\n",
      "Epoch 88/1000\n",
      "239/239 [==============================] - 0s 2ms/step - loss: 0.2546 - accuracy: 0.9039 - val_loss: 0.4970 - val_accuracy: 0.8403\n",
      "Epoch 89/1000\n",
      "239/239 [==============================] - 0s 2ms/step - loss: 0.2579 - accuracy: 0.9036 - val_loss: 0.4805 - val_accuracy: 0.8462\n",
      "Epoch 89: early stopping\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "<keras.src.callbacks.History at 0x28e1fc9d0>"
      ]
     },
     "execution_count": 148,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# batch size=512 ve dropout yok\n",
    "model=Sequential()\n",
    "model.add(Dense(128, input_dim=X_train.shape[1], activation=\"relu\"))\n",
    "#model.add(Dropout(0.2))\n",
    "model.add(Dense(128, activation=\"relu\"))\n",
    "\n",
    "model.add(Dense(64, activation=\"relu\"))\n",
    "#model.add(Dropout(0.2))\n",
    "model.add(Dense(64, activation=\"relu\"))\n",
    "\n",
    "model.add(Dense(32, activation=\"relu\"))\n",
    "#model.add(Dropout(0.2))\n",
    "model.add(Dense(16, activation=\"relu\"))\n",
    "#model.add(Dropout(0.2))\n",
    "model.add(Dense(3, activation=\"softmax\"))\n",
    "\n",
    "model.compile(loss='categorical_crossentropy', optimizer=Adam(learning_rate=0.001), metrics=['accuracy'])\n",
    "\n",
    "es=EarlyStopping(monitor=\"val_loss\",patience=50,mode=\"auto\",verbose=1)\n",
    "\n",
    "model.fit(X_train,\n",
    "          y_train,\n",
    "          epochs=1000,\n",
    "               batch_size=512,\n",
    "               validation_split=0.1,\n",
    "               verbose=1,callbacks=[es])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 149,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "748/748 [==============================] - 0s 259us/step\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0       0.86      0.93      0.89      7973\n",
      "           1       0.83      0.91      0.87      7973\n",
      "           2       0.84      0.70      0.76      7972\n",
      "\n",
      "    accuracy                           0.84     23918\n",
      "   macro avg       0.84      0.84      0.84     23918\n",
      "weighted avg       0.84      0.84      0.84     23918\n",
      "\n"
     ]
    }
   ],
   "source": [
    "y_pred = model.predict(X_test)\n",
    "y_pred_classes = np.argmax(y_pred, axis=1)\n",
    "y_true = np.argmax(y_test, axis=1)\n",
    "print(classification_report(y_true, y_pred_classes))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 150,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "4236/4236 [==============================] - 1s 247us/step\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0       0.92      0.96      0.94     45176\n",
      "           1       0.88      0.96      0.92     45176\n",
      "           2       0.92      0.79      0.85     45177\n",
      "\n",
      "    accuracy                           0.91    135529\n",
      "   macro avg       0.91      0.91      0.90    135529\n",
      "weighted avg       0.91      0.91      0.90    135529\n",
      "\n"
     ]
    }
   ],
   "source": [
    "y_t_pred = model.predict(X_train)\n",
    "y_t_pred_classes = np.argmax(y_t_pred, axis=1)\n",
    "y_t_true = np.argmax(y_train, axis=1)\n",
    "print(classification_report(y_t_true, y_t_pred_classes))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 151,
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 1/1000\n",
      "239/239 [==============================] - 1s 2ms/step - loss: 0.9950 - accuracy: 0.5411 - val_loss: 0.8446 - val_accuracy: 0.6165\n",
      "Epoch 2/1000\n",
      "239/239 [==============================] - 1s 2ms/step - loss: 0.8107 - accuracy: 0.6579 - val_loss: 0.7609 - val_accuracy: 0.7230\n",
      "Epoch 3/1000\n",
      "239/239 [==============================] - 0s 2ms/step - loss: 0.7674 - accuracy: 0.7003 - val_loss: 0.7472 - val_accuracy: 0.7274\n",
      "Epoch 4/1000\n",
      "239/239 [==============================] - 0s 2ms/step - loss: 0.7456 - accuracy: 0.7103 - val_loss: 0.7277 - val_accuracy: 0.7355\n",
      "Epoch 5/1000\n",
      "239/239 [==============================] - 0s 2ms/step - loss: 0.7372 - accuracy: 0.7157 - val_loss: 0.7493 - val_accuracy: 0.7346\n",
      "Epoch 6/1000\n",
      "239/239 [==============================] - 0s 2ms/step - loss: 0.7310 - accuracy: 0.7182 - val_loss: 0.7315 - val_accuracy: 0.7387\n",
      "Epoch 7/1000\n",
      "239/239 [==============================] - 0s 2ms/step - loss: 0.7280 - accuracy: 0.7206 - val_loss: 0.7315 - val_accuracy: 0.7381\n",
      "Epoch 8/1000\n",
      "239/239 [==============================] - 0s 2ms/step - loss: 0.7268 - accuracy: 0.7207 - val_loss: 0.7434 - val_accuracy: 0.7373\n",
      "Epoch 9/1000\n",
      "239/239 [==============================] - 0s 2ms/step - loss: 0.7255 - accuracy: 0.7220 - val_loss: 0.7392 - val_accuracy: 0.7379\n",
      "Epoch 10/1000\n",
      "239/239 [==============================] - 1s 2ms/step - loss: 0.7179 - accuracy: 0.7234 - val_loss: 0.7390 - val_accuracy: 0.7375\n",
      "Epoch 11/1000\n",
      "239/239 [==============================] - 0s 2ms/step - loss: 0.7166 - accuracy: 0.7217 - val_loss: 0.7354 - val_accuracy: 0.7421\n",
      "Epoch 12/1000\n",
      "239/239 [==============================] - 0s 2ms/step - loss: 0.7114 - accuracy: 0.7257 - val_loss: 0.7356 - val_accuracy: 0.7392\n",
      "Epoch 13/1000\n",
      "239/239 [==============================] - 0s 2ms/step - loss: 0.7086 - accuracy: 0.7268 - val_loss: 0.7293 - val_accuracy: 0.7401\n",
      "Epoch 14/1000\n",
      "239/239 [==============================] - 0s 2ms/step - loss: 0.7045 - accuracy: 0.7277 - val_loss: 0.7313 - val_accuracy: 0.7411\n",
      "Epoch 15/1000\n",
      "239/239 [==============================] - 0s 2ms/step - loss: 0.7023 - accuracy: 0.7271 - val_loss: 0.7323 - val_accuracy: 0.7393\n",
      "Epoch 16/1000\n",
      "239/239 [==============================] - 1s 2ms/step - loss: 0.6994 - accuracy: 0.7296 - val_loss: 0.7354 - val_accuracy: 0.7412\n",
      "Epoch 17/1000\n",
      "239/239 [==============================] - 1s 2ms/step - loss: 0.6972 - accuracy: 0.7308 - val_loss: 0.7358 - val_accuracy: 0.7408\n",
      "Epoch 18/1000\n",
      "239/239 [==============================] - 0s 2ms/step - loss: 0.6979 - accuracy: 0.7292 - val_loss: 0.7332 - val_accuracy: 0.7426\n",
      "Epoch 19/1000\n",
      "239/239 [==============================] - 0s 2ms/step - loss: 0.6984 - accuracy: 0.7294 - val_loss: 0.7280 - val_accuracy: 0.7426\n",
      "Epoch 20/1000\n",
      "239/239 [==============================] - 0s 2ms/step - loss: 0.6993 - accuracy: 0.7310 - val_loss: 0.7439 - val_accuracy: 0.7406\n",
      "Epoch 21/1000\n",
      "239/239 [==============================] - 0s 2ms/step - loss: 0.7010 - accuracy: 0.7287 - val_loss: 0.7320 - val_accuracy: 0.7418\n",
      "Epoch 22/1000\n",
      "239/239 [==============================] - 0s 2ms/step - loss: 0.7039 - accuracy: 0.7291 - val_loss: 0.7384 - val_accuracy: 0.7372\n",
      "Epoch 23/1000\n",
      "239/239 [==============================] - 0s 2ms/step - loss: 0.7078 - accuracy: 0.7256 - val_loss: 0.7479 - val_accuracy: 0.7355\n",
      "Epoch 24/1000\n",
      "239/239 [==============================] - 0s 2ms/step - loss: 0.7102 - accuracy: 0.7261 - val_loss: 0.7425 - val_accuracy: 0.7371\n",
      "Epoch 25/1000\n",
      "239/239 [==============================] - 0s 2ms/step - loss: 0.7121 - accuracy: 0.7262 - val_loss: 0.7573 - val_accuracy: 0.7392\n",
      "Epoch 26/1000\n",
      "239/239 [==============================] - 0s 2ms/step - loss: 0.7117 - accuracy: 0.7249 - val_loss: 0.7413 - val_accuracy: 0.7415\n",
      "Epoch 27/1000\n",
      "239/239 [==============================] - 0s 2ms/step - loss: 0.7094 - accuracy: 0.7272 - val_loss: 0.7405 - val_accuracy: 0.7406\n",
      "Epoch 28/1000\n",
      "239/239 [==============================] - 0s 2ms/step - loss: 0.7063 - accuracy: 0.7282 - val_loss: 0.7317 - val_accuracy: 0.7433\n",
      "Epoch 29/1000\n",
      "239/239 [==============================] - 0s 2ms/step - loss: 0.7043 - accuracy: 0.7293 - val_loss: 0.7299 - val_accuracy: 0.7424\n",
      "Epoch 30/1000\n",
      "239/239 [==============================] - 0s 2ms/step - loss: 0.6993 - accuracy: 0.7295 - val_loss: 0.7374 - val_accuracy: 0.7418\n",
      "Epoch 31/1000\n",
      "239/239 [==============================] - 0s 2ms/step - loss: 0.6969 - accuracy: 0.7304 - val_loss: 0.7370 - val_accuracy: 0.7418\n",
      "Epoch 32/1000\n",
      "239/239 [==============================] - 0s 2ms/step - loss: 0.6943 - accuracy: 0.7319 - val_loss: 0.7349 - val_accuracy: 0.7418\n",
      "Epoch 33/1000\n",
      "239/239 [==============================] - 0s 2ms/step - loss: 0.6932 - accuracy: 0.7324 - val_loss: 0.7366 - val_accuracy: 0.7418\n",
      "Epoch 34/1000\n",
      "239/239 [==============================] - 0s 2ms/step - loss: 0.6914 - accuracy: 0.7321 - val_loss: 0.7395 - val_accuracy: 0.7426\n",
      "Epoch 35/1000\n",
      "239/239 [==============================] - 0s 2ms/step - loss: 0.6896 - accuracy: 0.7344 - val_loss: 0.7353 - val_accuracy: 0.7421\n",
      "Epoch 36/1000\n",
      "239/239 [==============================] - 0s 2ms/step - loss: 0.6906 - accuracy: 0.7337 - val_loss: 0.7374 - val_accuracy: 0.7426\n",
      "Epoch 37/1000\n",
      "239/239 [==============================] - 0s 2ms/step - loss: 0.6944 - accuracy: 0.7318 - val_loss: 0.7397 - val_accuracy: 0.7412\n",
      "Epoch 38/1000\n",
      "239/239 [==============================] - 0s 2ms/step - loss: 0.6949 - accuracy: 0.7320 - val_loss: 0.7358 - val_accuracy: 0.7451\n",
      "Epoch 39/1000\n",
      "239/239 [==============================] - 0s 2ms/step - loss: 0.6986 - accuracy: 0.7308 - val_loss: 0.7305 - val_accuracy: 0.7412\n",
      "Epoch 40/1000\n",
      "239/239 [==============================] - 0s 2ms/step - loss: 0.7011 - accuracy: 0.7307 - val_loss: 0.7442 - val_accuracy: 0.7397\n",
      "Epoch 41/1000\n",
      "239/239 [==============================] - 0s 2ms/step - loss: 0.7033 - accuracy: 0.7304 - val_loss: 0.7571 - val_accuracy: 0.7376\n",
      "Epoch 42/1000\n",
      "239/239 [==============================] - 0s 2ms/step - loss: 0.7047 - accuracy: 0.7291 - val_loss: 0.7354 - val_accuracy: 0.7420\n",
      "Epoch 43/1000\n",
      "239/239 [==============================] - 0s 2ms/step - loss: 0.7048 - accuracy: 0.7295 - val_loss: 0.7452 - val_accuracy: 0.7387\n",
      "Epoch 44/1000\n",
      "239/239 [==============================] - 0s 2ms/step - loss: 0.7041 - accuracy: 0.7290 - val_loss: 0.7467 - val_accuracy: 0.7423\n",
      "Epoch 45/1000\n",
      "239/239 [==============================] - 0s 2ms/step - loss: 0.7018 - accuracy: 0.7291 - val_loss: 0.7347 - val_accuracy: 0.7406\n",
      "Epoch 46/1000\n",
      "239/239 [==============================] - 0s 2ms/step - loss: 0.6999 - accuracy: 0.7312 - val_loss: 0.7382 - val_accuracy: 0.7426\n",
      "Epoch 47/1000\n",
      "239/239 [==============================] - 0s 2ms/step - loss: 0.6972 - accuracy: 0.7316 - val_loss: 0.7379 - val_accuracy: 0.7393\n",
      "Epoch 48/1000\n",
      "239/239 [==============================] - 0s 2ms/step - loss: 0.6955 - accuracy: 0.7320 - val_loss: 0.7376 - val_accuracy: 0.7414\n",
      "Epoch 49/1000\n",
      "239/239 [==============================] - 0s 2ms/step - loss: 0.6918 - accuracy: 0.7320 - val_loss: 0.7420 - val_accuracy: 0.7413\n",
      "Epoch 50/1000\n",
      "239/239 [==============================] - 0s 2ms/step - loss: 0.6906 - accuracy: 0.7333 - val_loss: 0.7357 - val_accuracy: 0.7426\n",
      "Epoch 51/1000\n",
      "239/239 [==============================] - 0s 2ms/step - loss: 0.6894 - accuracy: 0.7331 - val_loss: 0.7297 - val_accuracy: 0.7426\n",
      "Epoch 52/1000\n",
      "239/239 [==============================] - 0s 2ms/step - loss: 0.6887 - accuracy: 0.7342 - val_loss: 0.7324 - val_accuracy: 0.7420\n",
      "Epoch 53/1000\n",
      "239/239 [==============================] - 0s 2ms/step - loss: 0.6906 - accuracy: 0.7339 - val_loss: 0.7400 - val_accuracy: 0.7427\n",
      "Epoch 54/1000\n",
      "239/239 [==============================] - 0s 2ms/step - loss: 0.6916 - accuracy: 0.7350 - val_loss: 0.7329 - val_accuracy: 0.7409\n",
      "Epoch 54: early stopping\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "<keras.src.callbacks.History at 0x28e53be20>"
      ]
     },
     "execution_count": 151,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "model=Sequential()\n",
    "model.add(Dense(128, activation=\"relu\"))\n",
    "model.add(Dropout(0.8))\n",
    "model.add(Dense(128, activation=\"relu\"))\n",
    "\n",
    "model.add(Dense(64, activation=\"relu\"))\n",
    "#model.add(Dropout(0.2))\n",
    "model.add(Dense(64, activation=\"relu\"))\n",
    "\n",
    "model.add(Dense(32, activation=\"relu\"))\n",
    "model.add(Dropout(0.2))\n",
    "model.add(Dense(16, activation=\"relu\"))\n",
    "#model.add(Dropout(0.2))\n",
    "model.add(Dense(3, activation=\"softmax\"))\n",
    "\n",
    "model.compile(loss='categorical_crossentropy', optimizer=Adam(), metrics=['accuracy'])\n",
    "\n",
    "es=EarlyStopping(monitor=\"val_loss\",patience=50,mode=\"auto\",verbose=1)\n",
    "clr = CyclicLR(base_lr=0.0001, max_lr=0.006,\n",
    "                                step_size=2000., mode='triangular')\n",
    "\n",
    "model.fit(X_train,\n",
    "          y_train,\n",
    "          epochs=1000,\n",
    "          batch_size=512,\n",
    "          validation_split=0.1,\n",
    "          verbose=1,callbacks=[es, clr],\n",
    "          class_weight=class_weights)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 152,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "748/748 [==============================] - 0s 270us/step\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0       0.71      0.89      0.79      7973\n",
      "           1       0.74      0.79      0.76      7973\n",
      "           2       0.79      0.54      0.64      7972\n",
      "\n",
      "    accuracy                           0.74     23918\n",
      "   macro avg       0.74      0.74      0.73     23918\n",
      "weighted avg       0.74      0.74      0.73     23918\n",
      "\n"
     ]
    }
   ],
   "source": [
    "y_pred = model.predict(X_test)\n",
    "y_pred_classes = np.argmax(y_pred, axis=1)\n",
    "y_true = np.argmax(y_test, axis=1)\n",
    "print(classification_report(y_true, y_pred_classes))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 153,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "4236/4236 [==============================] - 1s 250us/step\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0       0.72      0.89      0.79     45176\n",
      "           1       0.74      0.79      0.77     45176\n",
      "           2       0.79      0.55      0.65     45177\n",
      "\n",
      "    accuracy                           0.74    135529\n",
      "   macro avg       0.75      0.74      0.74    135529\n",
      "weighted avg       0.75      0.74      0.74    135529\n",
      "\n"
     ]
    }
   ],
   "source": [
    "y_t_pred = model.predict(X_train)\n",
    "y_t_pred_classes = np.argmax(y_t_pred, axis=1)\n",
    "y_t_true = np.argmax(y_train, axis=1)\n",
    "print(classification_report(y_t_true, y_t_pred_classes))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 154,
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 1/1000\n",
      "239/239 [==============================] - 1s 2ms/step - loss: 0.8358 - accuracy: 0.6450 - val_loss: 0.7391 - val_accuracy: 0.7207\n",
      "Epoch 2/1000\n",
      "239/239 [==============================] - 0s 2ms/step - loss: 0.7496 - accuracy: 0.7084 - val_loss: 0.7289 - val_accuracy: 0.7226\n",
      "Epoch 3/1000\n",
      "239/239 [==============================] - 1s 2ms/step - loss: 0.7281 - accuracy: 0.7166 - val_loss: 0.7220 - val_accuracy: 0.7254\n",
      "Epoch 4/1000\n",
      "239/239 [==============================] - 0s 2ms/step - loss: 0.7174 - accuracy: 0.7202 - val_loss: 0.7117 - val_accuracy: 0.7292\n",
      "Epoch 5/1000\n",
      "239/239 [==============================] - 0s 2ms/step - loss: 0.7081 - accuracy: 0.7235 - val_loss: 0.7095 - val_accuracy: 0.7365\n",
      "Epoch 6/1000\n",
      "239/239 [==============================] - 0s 2ms/step - loss: 0.7028 - accuracy: 0.7259 - val_loss: 0.7013 - val_accuracy: 0.7364\n",
      "Epoch 7/1000\n",
      "239/239 [==============================] - 0s 2ms/step - loss: 0.6982 - accuracy: 0.7280 - val_loss: 0.7048 - val_accuracy: 0.7359\n",
      "Epoch 8/1000\n",
      "239/239 [==============================] - 0s 2ms/step - loss: 0.6950 - accuracy: 0.7290 - val_loss: 0.7000 - val_accuracy: 0.7397\n",
      "Epoch 9/1000\n",
      "239/239 [==============================] - 0s 2ms/step - loss: 0.6916 - accuracy: 0.7305 - val_loss: 0.6976 - val_accuracy: 0.7395\n",
      "Epoch 10/1000\n",
      "239/239 [==============================] - 0s 2ms/step - loss: 0.6902 - accuracy: 0.7316 - val_loss: 0.6977 - val_accuracy: 0.7427\n",
      "Epoch 11/1000\n",
      "239/239 [==============================] - 0s 2ms/step - loss: 0.6874 - accuracy: 0.7326 - val_loss: 0.6949 - val_accuracy: 0.7418\n",
      "Epoch 12/1000\n",
      "239/239 [==============================] - 0s 2ms/step - loss: 0.6853 - accuracy: 0.7338 - val_loss: 0.6922 - val_accuracy: 0.7445\n",
      "Epoch 13/1000\n",
      "239/239 [==============================] - 0s 2ms/step - loss: 0.6844 - accuracy: 0.7339 - val_loss: 0.6951 - val_accuracy: 0.7449\n",
      "Epoch 14/1000\n",
      "239/239 [==============================] - 0s 2ms/step - loss: 0.6838 - accuracy: 0.7344 - val_loss: 0.6997 - val_accuracy: 0.7444\n",
      "Epoch 15/1000\n",
      "239/239 [==============================] - 1s 2ms/step - loss: 0.6817 - accuracy: 0.7351 - val_loss: 0.7008 - val_accuracy: 0.7444\n",
      "Epoch 16/1000\n",
      "239/239 [==============================] - 0s 2ms/step - loss: 0.6806 - accuracy: 0.7351 - val_loss: 0.6949 - val_accuracy: 0.7464\n",
      "Epoch 17/1000\n",
      "239/239 [==============================] - 0s 2ms/step - loss: 0.6801 - accuracy: 0.7351 - val_loss: 0.6922 - val_accuracy: 0.7451\n",
      "Epoch 18/1000\n",
      "239/239 [==============================] - 0s 2ms/step - loss: 0.6797 - accuracy: 0.7357 - val_loss: 0.7041 - val_accuracy: 0.7436\n",
      "Epoch 19/1000\n",
      "239/239 [==============================] - 0s 2ms/step - loss: 0.6781 - accuracy: 0.7363 - val_loss: 0.6930 - val_accuracy: 0.7473\n",
      "Epoch 20/1000\n",
      "239/239 [==============================] - 0s 2ms/step - loss: 0.6780 - accuracy: 0.7361 - val_loss: 0.7064 - val_accuracy: 0.7471\n",
      "Epoch 21/1000\n",
      "239/239 [==============================] - 0s 2ms/step - loss: 0.6766 - accuracy: 0.7364 - val_loss: 0.6996 - val_accuracy: 0.7471\n",
      "Epoch 22/1000\n",
      "239/239 [==============================] - 0s 2ms/step - loss: 0.6755 - accuracy: 0.7370 - val_loss: 0.6976 - val_accuracy: 0.7481\n",
      "Epoch 23/1000\n",
      "239/239 [==============================] - 0s 2ms/step - loss: 0.6753 - accuracy: 0.7374 - val_loss: 0.7020 - val_accuracy: 0.7485\n",
      "Epoch 24/1000\n",
      "239/239 [==============================] - 0s 2ms/step - loss: 0.6746 - accuracy: 0.7377 - val_loss: 0.7064 - val_accuracy: 0.7482\n",
      "Epoch 25/1000\n",
      "239/239 [==============================] - 0s 2ms/step - loss: 0.6740 - accuracy: 0.7375 - val_loss: 0.7149 - val_accuracy: 0.7476\n",
      "Epoch 26/1000\n",
      "239/239 [==============================] - 0s 2ms/step - loss: 0.6736 - accuracy: 0.7367 - val_loss: 0.7178 - val_accuracy: 0.7466\n",
      "Epoch 27/1000\n",
      "239/239 [==============================] - 0s 2ms/step - loss: 0.6726 - accuracy: 0.7382 - val_loss: 0.7115 - val_accuracy: 0.7478\n",
      "Epoch 28/1000\n",
      "239/239 [==============================] - 0s 2ms/step - loss: 0.6728 - accuracy: 0.7382 - val_loss: 0.7172 - val_accuracy: 0.7467\n",
      "Epoch 29/1000\n",
      "239/239 [==============================] - 0s 2ms/step - loss: 0.6717 - accuracy: 0.7381 - val_loss: 0.7145 - val_accuracy: 0.7471\n",
      "Epoch 30/1000\n",
      "239/239 [==============================] - 0s 2ms/step - loss: 0.6722 - accuracy: 0.7379 - val_loss: 0.7010 - val_accuracy: 0.7468\n",
      "Epoch 31/1000\n",
      "239/239 [==============================] - 0s 2ms/step - loss: 0.6713 - accuracy: 0.7379 - val_loss: 0.7112 - val_accuracy: 0.7479\n",
      "Epoch 32/1000\n",
      "239/239 [==============================] - 0s 2ms/step - loss: 0.6712 - accuracy: 0.7379 - val_loss: 0.7053 - val_accuracy: 0.7476\n",
      "Epoch 33/1000\n",
      "239/239 [==============================] - 0s 2ms/step - loss: 0.6704 - accuracy: 0.7380 - val_loss: 0.7162 - val_accuracy: 0.7475\n",
      "Epoch 34/1000\n",
      "239/239 [==============================] - 0s 2ms/step - loss: 0.6708 - accuracy: 0.7380 - val_loss: 0.7229 - val_accuracy: 0.7452\n",
      "Epoch 35/1000\n",
      "239/239 [==============================] - 0s 2ms/step - loss: 0.6694 - accuracy: 0.7389 - val_loss: 0.7167 - val_accuracy: 0.7475\n",
      "Epoch 36/1000\n",
      "239/239 [==============================] - 0s 2ms/step - loss: 0.6699 - accuracy: 0.7389 - val_loss: 0.7268 - val_accuracy: 0.7466\n",
      "Epoch 37/1000\n",
      "239/239 [==============================] - 0s 2ms/step - loss: 0.6707 - accuracy: 0.7379 - val_loss: 0.7210 - val_accuracy: 0.7472\n",
      "Epoch 38/1000\n",
      "239/239 [==============================] - 0s 2ms/step - loss: 0.6683 - accuracy: 0.7387 - val_loss: 0.7190 - val_accuracy: 0.7474\n",
      "Epoch 39/1000\n",
      "239/239 [==============================] - 0s 2ms/step - loss: 0.6685 - accuracy: 0.7387 - val_loss: 0.7202 - val_accuracy: 0.7476\n",
      "Epoch 40/1000\n",
      "239/239 [==============================] - 0s 2ms/step - loss: 0.6693 - accuracy: 0.7387 - val_loss: 0.7289 - val_accuracy: 0.7464\n",
      "Epoch 41/1000\n",
      "239/239 [==============================] - 0s 2ms/step - loss: 0.6683 - accuracy: 0.7390 - val_loss: 0.7126 - val_accuracy: 0.7468\n",
      "Epoch 42/1000\n",
      "239/239 [==============================] - 0s 2ms/step - loss: 0.6682 - accuracy: 0.7391 - val_loss: 0.7201 - val_accuracy: 0.7471\n",
      "Epoch 43/1000\n",
      "239/239 [==============================] - 0s 2ms/step - loss: 0.6680 - accuracy: 0.7387 - val_loss: 0.7225 - val_accuracy: 0.7481\n",
      "Epoch 44/1000\n",
      "239/239 [==============================] - 0s 2ms/step - loss: 0.6676 - accuracy: 0.7398 - val_loss: 0.7102 - val_accuracy: 0.7471\n",
      "Epoch 45/1000\n",
      "239/239 [==============================] - 0s 2ms/step - loss: 0.6676 - accuracy: 0.7394 - val_loss: 0.7265 - val_accuracy: 0.7468\n",
      "Epoch 46/1000\n",
      "239/239 [==============================] - 0s 2ms/step - loss: 0.6668 - accuracy: 0.7396 - val_loss: 0.7279 - val_accuracy: 0.7478\n",
      "Epoch 47/1000\n",
      "239/239 [==============================] - 0s 2ms/step - loss: 0.6665 - accuracy: 0.7398 - val_loss: 0.7241 - val_accuracy: 0.7466\n",
      "Epoch 48/1000\n",
      "239/239 [==============================] - 0s 2ms/step - loss: 0.6675 - accuracy: 0.7384 - val_loss: 0.7297 - val_accuracy: 0.7467\n",
      "Epoch 49/1000\n",
      "239/239 [==============================] - 0s 2ms/step - loss: 0.6656 - accuracy: 0.7395 - val_loss: 0.7302 - val_accuracy: 0.7453\n",
      "Epoch 50/1000\n",
      "239/239 [==============================] - 0s 2ms/step - loss: 0.6660 - accuracy: 0.7408 - val_loss: 0.7336 - val_accuracy: 0.7471\n",
      "Epoch 51/1000\n",
      "239/239 [==============================] - 0s 2ms/step - loss: 0.6663 - accuracy: 0.7397 - val_loss: 0.7569 - val_accuracy: 0.7457\n",
      "Epoch 52/1000\n",
      "239/239 [==============================] - 0s 2ms/step - loss: 0.6657 - accuracy: 0.7397 - val_loss: 0.7412 - val_accuracy: 0.7451\n",
      "Epoch 53/1000\n",
      "239/239 [==============================] - 0s 2ms/step - loss: 0.6659 - accuracy: 0.7397 - val_loss: 0.7540 - val_accuracy: 0.7457\n",
      "Epoch 54/1000\n",
      "239/239 [==============================] - 0s 2ms/step - loss: 0.6656 - accuracy: 0.7404 - val_loss: 0.7568 - val_accuracy: 0.7471\n",
      "Epoch 55/1000\n",
      "239/239 [==============================] - 0s 2ms/step - loss: 0.6661 - accuracy: 0.7390 - val_loss: 0.7457 - val_accuracy: 0.7450\n",
      "Epoch 56/1000\n",
      "239/239 [==============================] - 0s 2ms/step - loss: 0.6655 - accuracy: 0.7396 - val_loss: 0.7576 - val_accuracy: 0.7468\n",
      "Epoch 57/1000\n",
      "239/239 [==============================] - 0s 2ms/step - loss: 0.6663 - accuracy: 0.7395 - val_loss: 0.7628 - val_accuracy: 0.7466\n",
      "Epoch 58/1000\n",
      "239/239 [==============================] - 0s 2ms/step - loss: 0.6655 - accuracy: 0.7393 - val_loss: 0.7519 - val_accuracy: 0.7463\n",
      "Epoch 59/1000\n",
      "239/239 [==============================] - 0s 2ms/step - loss: 0.6647 - accuracy: 0.7396 - val_loss: 0.7750 - val_accuracy: 0.7451\n",
      "Epoch 60/1000\n",
      "239/239 [==============================] - 0s 2ms/step - loss: 0.6644 - accuracy: 0.7408 - val_loss: 0.7552 - val_accuracy: 0.7476\n",
      "Epoch 61/1000\n",
      "239/239 [==============================] - 0s 2ms/step - loss: 0.6643 - accuracy: 0.7401 - val_loss: 0.7691 - val_accuracy: 0.7468\n",
      "Epoch 62/1000\n",
      "239/239 [==============================] - 0s 2ms/step - loss: 0.6647 - accuracy: 0.7390 - val_loss: 0.7489 - val_accuracy: 0.7463\n",
      "Epoch 63/1000\n",
      "239/239 [==============================] - 0s 2ms/step - loss: 0.6647 - accuracy: 0.7398 - val_loss: 0.7612 - val_accuracy: 0.7461\n",
      "Epoch 64/1000\n",
      "239/239 [==============================] - 0s 2ms/step - loss: 0.6647 - accuracy: 0.7398 - val_loss: 0.7536 - val_accuracy: 0.7471\n",
      "Epoch 65/1000\n",
      "239/239 [==============================] - 0s 2ms/step - loss: 0.6635 - accuracy: 0.7402 - val_loss: 0.7615 - val_accuracy: 0.7477\n",
      "Epoch 66/1000\n",
      "239/239 [==============================] - 0s 2ms/step - loss: 0.6637 - accuracy: 0.7404 - val_loss: 0.7485 - val_accuracy: 0.7469\n",
      "Epoch 67/1000\n",
      "239/239 [==============================] - 0s 2ms/step - loss: 0.6631 - accuracy: 0.7402 - val_loss: 0.7720 - val_accuracy: 0.7458\n",
      "Epoch 68/1000\n",
      "239/239 [==============================] - 0s 2ms/step - loss: 0.6634 - accuracy: 0.7401 - val_loss: 0.7686 - val_accuracy: 0.7450\n",
      "Epoch 69/1000\n",
      "239/239 [==============================] - 0s 2ms/step - loss: 0.6635 - accuracy: 0.7406 - val_loss: 0.7568 - val_accuracy: 0.7472\n",
      "Epoch 70/1000\n",
      "239/239 [==============================] - 0s 2ms/step - loss: 0.6629 - accuracy: 0.7404 - val_loss: 0.7826 - val_accuracy: 0.7463\n",
      "Epoch 71/1000\n",
      "239/239 [==============================] - 1s 2ms/step - loss: 0.6632 - accuracy: 0.7401 - val_loss: 0.7999 - val_accuracy: 0.7463\n",
      "Epoch 72/1000\n",
      "239/239 [==============================] - 0s 2ms/step - loss: 0.6633 - accuracy: 0.7403 - val_loss: 0.7782 - val_accuracy: 0.7469\n",
      "Epoch 73/1000\n",
      "239/239 [==============================] - 0s 2ms/step - loss: 0.6629 - accuracy: 0.7408 - val_loss: 0.7743 - val_accuracy: 0.7460\n",
      "Epoch 74/1000\n",
      "239/239 [==============================] - 0s 2ms/step - loss: 0.6624 - accuracy: 0.7414 - val_loss: 0.7709 - val_accuracy: 0.7480\n",
      "Epoch 75/1000\n",
      "239/239 [==============================] - 0s 2ms/step - loss: 0.6624 - accuracy: 0.7412 - val_loss: 0.7854 - val_accuracy: 0.7442\n",
      "Epoch 76/1000\n",
      "239/239 [==============================] - 0s 2ms/step - loss: 0.6632 - accuracy: 0.7406 - val_loss: 0.7792 - val_accuracy: 0.7458\n",
      "Epoch 77/1000\n",
      "239/239 [==============================] - 0s 2ms/step - loss: 0.6618 - accuracy: 0.7414 - val_loss: 0.7725 - val_accuracy: 0.7431\n",
      "Epoch 78/1000\n",
      "239/239 [==============================] - 0s 2ms/step - loss: 0.6620 - accuracy: 0.7405 - val_loss: 0.7778 - val_accuracy: 0.7468\n",
      "Epoch 79/1000\n",
      "239/239 [==============================] - 0s 2ms/step - loss: 0.6619 - accuracy: 0.7412 - val_loss: 0.7619 - val_accuracy: 0.7460\n",
      "Epoch 80/1000\n",
      "239/239 [==============================] - 0s 2ms/step - loss: 0.6622 - accuracy: 0.7413 - val_loss: 0.7879 - val_accuracy: 0.7465\n",
      "Epoch 81/1000\n",
      "239/239 [==============================] - 0s 2ms/step - loss: 0.6623 - accuracy: 0.7407 - val_loss: 0.7770 - val_accuracy: 0.7474\n",
      "Epoch 82/1000\n",
      "239/239 [==============================] - 0s 2ms/step - loss: 0.6622 - accuracy: 0.7415 - val_loss: 0.8119 - val_accuracy: 0.7460\n",
      "Epoch 83/1000\n",
      "239/239 [==============================] - 0s 2ms/step - loss: 0.6619 - accuracy: 0.7413 - val_loss: 0.8182 - val_accuracy: 0.7468\n",
      "Epoch 84/1000\n",
      "239/239 [==============================] - 0s 2ms/step - loss: 0.6614 - accuracy: 0.7412 - val_loss: 0.7901 - val_accuracy: 0.7470\n",
      "Epoch 85/1000\n",
      "239/239 [==============================] - 0s 2ms/step - loss: 0.6609 - accuracy: 0.7413 - val_loss: 0.7884 - val_accuracy: 0.7452\n",
      "Epoch 86/1000\n",
      "239/239 [==============================] - 0s 2ms/step - loss: 0.6616 - accuracy: 0.7407 - val_loss: 0.7879 - val_accuracy: 0.7415\n",
      "Epoch 87/1000\n",
      "239/239 [==============================] - 0s 2ms/step - loss: 0.6617 - accuracy: 0.7403 - val_loss: 0.7698 - val_accuracy: 0.7458\n",
      "Epoch 88/1000\n",
      "239/239 [==============================] - 0s 2ms/step - loss: 0.6622 - accuracy: 0.7404 - val_loss: 0.7556 - val_accuracy: 0.7464\n",
      "Epoch 89/1000\n",
      "239/239 [==============================] - 0s 2ms/step - loss: 0.6603 - accuracy: 0.7422 - val_loss: 0.7558 - val_accuracy: 0.7472\n",
      "Epoch 90/1000\n",
      "239/239 [==============================] - 0s 2ms/step - loss: 0.6612 - accuracy: 0.7412 - val_loss: 0.7687 - val_accuracy: 0.7421\n",
      "Epoch 91/1000\n",
      "239/239 [==============================] - 0s 2ms/step - loss: 0.6610 - accuracy: 0.7410 - val_loss: 0.7742 - val_accuracy: 0.7455\n",
      "Epoch 92/1000\n",
      "239/239 [==============================] - 0s 2ms/step - loss: 0.6605 - accuracy: 0.7411 - val_loss: 0.7801 - val_accuracy: 0.7470\n",
      "Epoch 93/1000\n",
      "239/239 [==============================] - 0s 2ms/step - loss: 0.6606 - accuracy: 0.7420 - val_loss: 0.8453 - val_accuracy: 0.7416\n",
      "Epoch 94/1000\n",
      "239/239 [==============================] - 0s 2ms/step - loss: 0.6598 - accuracy: 0.7419 - val_loss: 0.8368 - val_accuracy: 0.7441\n",
      "Epoch 95/1000\n",
      "239/239 [==============================] - 0s 2ms/step - loss: 0.6602 - accuracy: 0.7415 - val_loss: 0.8603 - val_accuracy: 0.7462\n",
      "Epoch 96/1000\n",
      "239/239 [==============================] - 0s 2ms/step - loss: 0.6601 - accuracy: 0.7410 - val_loss: 0.8419 - val_accuracy: 0.7453\n",
      "Epoch 97/1000\n",
      "239/239 [==============================] - 0s 2ms/step - loss: 0.6601 - accuracy: 0.7415 - val_loss: 0.8029 - val_accuracy: 0.7454\n",
      "Epoch 98/1000\n",
      "239/239 [==============================] - 0s 2ms/step - loss: 0.6602 - accuracy: 0.7421 - val_loss: 0.7743 - val_accuracy: 0.7465\n",
      "Epoch 99/1000\n",
      "239/239 [==============================] - 0s 2ms/step - loss: 0.6598 - accuracy: 0.7416 - val_loss: 0.8522 - val_accuracy: 0.7449\n",
      "Epoch 100/1000\n",
      "239/239 [==============================] - 0s 2ms/step - loss: 0.6600 - accuracy: 0.7419 - val_loss: 0.8186 - val_accuracy: 0.7418\n",
      "Epoch 101/1000\n",
      "239/239 [==============================] - 0s 2ms/step - loss: 0.6595 - accuracy: 0.7418 - val_loss: 0.8295 - val_accuracy: 0.7433\n",
      "Epoch 102/1000\n",
      "239/239 [==============================] - 0s 2ms/step - loss: 0.6598 - accuracy: 0.7419 - val_loss: 0.8288 - val_accuracy: 0.7433\n",
      "Epoch 103/1000\n",
      "239/239 [==============================] - 0s 2ms/step - loss: 0.6596 - accuracy: 0.7417 - val_loss: 0.8715 - val_accuracy: 0.7470\n",
      "Epoch 104/1000\n",
      "239/239 [==============================] - 0s 2ms/step - loss: 0.6589 - accuracy: 0.7421 - val_loss: 0.8262 - val_accuracy: 0.7440\n",
      "Epoch 105/1000\n",
      "239/239 [==============================] - 0s 2ms/step - loss: 0.6601 - accuracy: 0.7419 - val_loss: 0.8693 - val_accuracy: 0.7456\n",
      "Epoch 106/1000\n",
      "239/239 [==============================] - 0s 2ms/step - loss: 0.6597 - accuracy: 0.7418 - val_loss: 0.8221 - val_accuracy: 0.7485\n",
      "Epoch 107/1000\n",
      "239/239 [==============================] - 0s 2ms/step - loss: 0.6593 - accuracy: 0.7416 - val_loss: 0.8095 - val_accuracy: 0.7426\n",
      "Epoch 107: early stopping\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "<keras.src.callbacks.History at 0x303b91120>"
      ]
     },
     "execution_count": 154,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "model=Sequential()\n",
    "model.add(Dense(128, activation=\"relu\"))\n",
    "model.add(Dropout(0.8))\n",
    "model.add(Dense(128, activation=\"relu\"))\n",
    "\n",
    "model.add(Dense(64, activation=\"relu\"))\n",
    "#model.add(Dropout(0.2))\n",
    "model.add(Dense(64, activation=\"relu\"))\n",
    "\n",
    "model.add(Dense(32, activation=\"relu\"))\n",
    "model.add(Dropout(0.2))\n",
    "model.add(Dense(16, activation=\"relu\"))\n",
    "#model.add(Dropout(0.2))\n",
    "model.add(Dense(3, activation=\"softmax\"))\n",
    "\n",
    "model.compile(loss='categorical_crossentropy', optimizer=Adam(learning_rate=0.001), metrics=['accuracy'])\n",
    "\n",
    "es=EarlyStopping(monitor=\"val_loss\",patience=90,mode=\"auto\",verbose=1)\n",
    "\n",
    "model.fit(X_train,\n",
    "          y_train,\n",
    "          epochs=1000,\n",
    "          batch_size=512,\n",
    "          validation_split=0.1,\n",
    "          verbose=1,callbacks=[es])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 155,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "748/748 [==============================] - 0s 263us/step\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0       0.72      0.88      0.79      7973\n",
      "           1       0.75      0.75      0.75      7973\n",
      "           2       0.75      0.57      0.65      7972\n",
      "\n",
      "    accuracy                           0.74     23918\n",
      "   macro avg       0.74      0.74      0.73     23918\n",
      "weighted avg       0.74      0.74      0.73     23918\n",
      "\n"
     ]
    }
   ],
   "source": [
    "y_pred = model.predict(X_test)\n",
    "y_pred_classes = np.argmax(y_pred, axis=1)\n",
    "y_true = np.argmax(y_test, axis=1)\n",
    "print(classification_report(y_true, y_pred_classes))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 156,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "4236/4236 [==============================] - 1s 251us/step\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0       0.73      0.88      0.80     45176\n",
      "           1       0.75      0.75      0.75     45176\n",
      "           2       0.75      0.59      0.66     45177\n",
      "\n",
      "    accuracy                           0.74    135529\n",
      "   macro avg       0.74      0.74      0.74    135529\n",
      "weighted avg       0.74      0.74      0.74    135529\n",
      "\n"
     ]
    }
   ],
   "source": [
    "y_t_pred = model.predict(X_train)\n",
    "y_t_pred_classes = np.argmax(y_t_pred, axis=1)\n",
    "y_t_true = np.argmax(y_train, axis=1)\n",
    "print(classification_report(y_t_true, y_t_pred_classes))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 157,
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 1/1000\n",
      "120/120 [==============================] - 1s 3ms/step - loss: 0.8790 - accuracy: 0.6179 - val_loss: 0.7459 - val_accuracy: 0.7173\n",
      "Epoch 2/1000\n",
      "120/120 [==============================] - 0s 3ms/step - loss: 0.7664 - accuracy: 0.6998 - val_loss: 0.7244 - val_accuracy: 0.7218\n",
      "Epoch 3/1000\n",
      "120/120 [==============================] - 0s 3ms/step - loss: 0.7421 - accuracy: 0.7112 - val_loss: 0.7131 - val_accuracy: 0.7245\n",
      "Epoch 4/1000\n",
      "120/120 [==============================] - 0s 3ms/step - loss: 0.7264 - accuracy: 0.7172 - val_loss: 0.7059 - val_accuracy: 0.7292\n",
      "Epoch 5/1000\n",
      "120/120 [==============================] - 0s 3ms/step - loss: 0.7169 - accuracy: 0.7216 - val_loss: 0.6978 - val_accuracy: 0.7333\n",
      "Epoch 6/1000\n",
      "120/120 [==============================] - 1s 4ms/step - loss: 0.7114 - accuracy: 0.7234 - val_loss: 0.6911 - val_accuracy: 0.7359\n",
      "Epoch 7/1000\n",
      "120/120 [==============================] - 0s 3ms/step - loss: 0.7063 - accuracy: 0.7259 - val_loss: 0.6901 - val_accuracy: 0.7387\n",
      "Epoch 8/1000\n",
      "120/120 [==============================] - 0s 3ms/step - loss: 0.7017 - accuracy: 0.7278 - val_loss: 0.6853 - val_accuracy: 0.7391\n",
      "Epoch 9/1000\n",
      "120/120 [==============================] - 0s 3ms/step - loss: 0.6983 - accuracy: 0.7288 - val_loss: 0.6834 - val_accuracy: 0.7408\n",
      "Epoch 10/1000\n",
      "120/120 [==============================] - 0s 3ms/step - loss: 0.6957 - accuracy: 0.7311 - val_loss: 0.6818 - val_accuracy: 0.7415\n",
      "Epoch 11/1000\n",
      "120/120 [==============================] - 0s 3ms/step - loss: 0.6926 - accuracy: 0.7313 - val_loss: 0.6838 - val_accuracy: 0.7417\n",
      "Epoch 12/1000\n",
      "120/120 [==============================] - 0s 3ms/step - loss: 0.6911 - accuracy: 0.7320 - val_loss: 0.6818 - val_accuracy: 0.7435\n",
      "Epoch 13/1000\n",
      "120/120 [==============================] - 0s 3ms/step - loss: 0.6880 - accuracy: 0.7330 - val_loss: 0.6803 - val_accuracy: 0.7444\n",
      "Epoch 14/1000\n",
      "120/120 [==============================] - 0s 3ms/step - loss: 0.6871 - accuracy: 0.7333 - val_loss: 0.6827 - val_accuracy: 0.7442\n",
      "Epoch 15/1000\n",
      "120/120 [==============================] - 0s 3ms/step - loss: 0.6852 - accuracy: 0.7347 - val_loss: 0.6844 - val_accuracy: 0.7448\n",
      "Epoch 16/1000\n",
      "120/120 [==============================] - 0s 3ms/step - loss: 0.6849 - accuracy: 0.7334 - val_loss: 0.6769 - val_accuracy: 0.7450\n",
      "Epoch 17/1000\n",
      "120/120 [==============================] - 0s 3ms/step - loss: 0.6835 - accuracy: 0.7349 - val_loss: 0.6756 - val_accuracy: 0.7447\n",
      "Epoch 18/1000\n",
      "120/120 [==============================] - 0s 3ms/step - loss: 0.6812 - accuracy: 0.7354 - val_loss: 0.6784 - val_accuracy: 0.7454\n",
      "Epoch 19/1000\n",
      "120/120 [==============================] - 0s 3ms/step - loss: 0.6814 - accuracy: 0.7352 - val_loss: 0.6822 - val_accuracy: 0.7457\n",
      "Epoch 20/1000\n",
      "120/120 [==============================] - 0s 3ms/step - loss: 0.6801 - accuracy: 0.7362 - val_loss: 0.6860 - val_accuracy: 0.7454\n",
      "Epoch 21/1000\n",
      "120/120 [==============================] - 0s 3ms/step - loss: 0.6796 - accuracy: 0.7355 - val_loss: 0.6762 - val_accuracy: 0.7461\n",
      "Epoch 22/1000\n",
      "120/120 [==============================] - 0s 3ms/step - loss: 0.6785 - accuracy: 0.7368 - val_loss: 0.6810 - val_accuracy: 0.7457\n",
      "Epoch 23/1000\n",
      "120/120 [==============================] - 0s 3ms/step - loss: 0.6779 - accuracy: 0.7366 - val_loss: 0.6926 - val_accuracy: 0.7456\n",
      "Epoch 24/1000\n",
      "120/120 [==============================] - 0s 3ms/step - loss: 0.6773 - accuracy: 0.7371 - val_loss: 0.6974 - val_accuracy: 0.7457\n",
      "Epoch 25/1000\n",
      "120/120 [==============================] - 0s 3ms/step - loss: 0.6765 - accuracy: 0.7371 - val_loss: 0.6901 - val_accuracy: 0.7457\n",
      "Epoch 26/1000\n",
      "120/120 [==============================] - 0s 3ms/step - loss: 0.6747 - accuracy: 0.7375 - val_loss: 0.6965 - val_accuracy: 0.7443\n",
      "Epoch 27/1000\n",
      "120/120 [==============================] - 0s 3ms/step - loss: 0.6761 - accuracy: 0.7374 - val_loss: 0.6823 - val_accuracy: 0.7480\n",
      "Epoch 28/1000\n",
      "120/120 [==============================] - 0s 3ms/step - loss: 0.6746 - accuracy: 0.7378 - val_loss: 0.6877 - val_accuracy: 0.7458\n",
      "Epoch 29/1000\n",
      "120/120 [==============================] - 0s 3ms/step - loss: 0.6742 - accuracy: 0.7377 - val_loss: 0.6905 - val_accuracy: 0.7474\n",
      "Epoch 30/1000\n",
      "120/120 [==============================] - 0s 3ms/step - loss: 0.6739 - accuracy: 0.7377 - val_loss: 0.6871 - val_accuracy: 0.7471\n",
      "Epoch 31/1000\n",
      "120/120 [==============================] - 0s 3ms/step - loss: 0.6730 - accuracy: 0.7378 - val_loss: 0.6993 - val_accuracy: 0.7476\n",
      "Epoch 32/1000\n",
      "120/120 [==============================] - 0s 3ms/step - loss: 0.6730 - accuracy: 0.7386 - val_loss: 0.6931 - val_accuracy: 0.7475\n",
      "Epoch 33/1000\n",
      "120/120 [==============================] - 0s 3ms/step - loss: 0.6718 - accuracy: 0.7387 - val_loss: 0.6925 - val_accuracy: 0.7474\n",
      "Epoch 34/1000\n",
      "120/120 [==============================] - 0s 3ms/step - loss: 0.6715 - accuracy: 0.7390 - val_loss: 0.6998 - val_accuracy: 0.7480\n",
      "Epoch 35/1000\n",
      "120/120 [==============================] - 0s 3ms/step - loss: 0.6704 - accuracy: 0.7386 - val_loss: 0.6903 - val_accuracy: 0.7482\n",
      "Epoch 36/1000\n",
      "120/120 [==============================] - 0s 3ms/step - loss: 0.6718 - accuracy: 0.7390 - val_loss: 0.6871 - val_accuracy: 0.7486\n",
      "Epoch 37/1000\n",
      "120/120 [==============================] - 0s 3ms/step - loss: 0.6712 - accuracy: 0.7383 - val_loss: 0.6992 - val_accuracy: 0.7474\n",
      "Epoch 38/1000\n",
      "120/120 [==============================] - 0s 3ms/step - loss: 0.6708 - accuracy: 0.7394 - val_loss: 0.6993 - val_accuracy: 0.7479\n",
      "Epoch 39/1000\n",
      "120/120 [==============================] - 0s 3ms/step - loss: 0.6696 - accuracy: 0.7389 - val_loss: 0.6972 - val_accuracy: 0.7482\n",
      "Epoch 40/1000\n",
      "120/120 [==============================] - 0s 3ms/step - loss: 0.6699 - accuracy: 0.7392 - val_loss: 0.7019 - val_accuracy: 0.7468\n",
      "Epoch 41/1000\n",
      "120/120 [==============================] - 0s 3ms/step - loss: 0.6698 - accuracy: 0.7386 - val_loss: 0.6952 - val_accuracy: 0.7478\n",
      "Epoch 42/1000\n",
      "120/120 [==============================] - 0s 3ms/step - loss: 0.6693 - accuracy: 0.7396 - val_loss: 0.7001 - val_accuracy: 0.7480\n",
      "Epoch 43/1000\n",
      "120/120 [==============================] - 0s 3ms/step - loss: 0.6693 - accuracy: 0.7397 - val_loss: 0.6941 - val_accuracy: 0.7480\n",
      "Epoch 44/1000\n",
      "120/120 [==============================] - 0s 3ms/step - loss: 0.6682 - accuracy: 0.7393 - val_loss: 0.7014 - val_accuracy: 0.7484\n",
      "Epoch 45/1000\n",
      "120/120 [==============================] - 0s 3ms/step - loss: 0.6686 - accuracy: 0.7396 - val_loss: 0.7031 - val_accuracy: 0.7490\n",
      "Epoch 46/1000\n",
      "120/120 [==============================] - 0s 3ms/step - loss: 0.6682 - accuracy: 0.7397 - val_loss: 0.7024 - val_accuracy: 0.7476\n",
      "Epoch 47/1000\n",
      "120/120 [==============================] - 0s 3ms/step - loss: 0.6671 - accuracy: 0.7403 - val_loss: 0.7009 - val_accuracy: 0.7471\n",
      "Epoch 48/1000\n",
      "120/120 [==============================] - 0s 3ms/step - loss: 0.6683 - accuracy: 0.7394 - val_loss: 0.7040 - val_accuracy: 0.7479\n",
      "Epoch 49/1000\n",
      "120/120 [==============================] - 0s 3ms/step - loss: 0.6670 - accuracy: 0.7399 - val_loss: 0.7016 - val_accuracy: 0.7487\n",
      "Epoch 50/1000\n",
      "120/120 [==============================] - 0s 3ms/step - loss: 0.6668 - accuracy: 0.7405 - val_loss: 0.7093 - val_accuracy: 0.7477\n",
      "Epoch 51/1000\n",
      "120/120 [==============================] - 0s 3ms/step - loss: 0.6667 - accuracy: 0.7409 - val_loss: 0.7024 - val_accuracy: 0.7475\n",
      "Epoch 52/1000\n",
      "120/120 [==============================] - 0s 3ms/step - loss: 0.6662 - accuracy: 0.7409 - val_loss: 0.7044 - val_accuracy: 0.7488\n",
      "Epoch 53/1000\n",
      "120/120 [==============================] - 0s 3ms/step - loss: 0.6670 - accuracy: 0.7407 - val_loss: 0.7046 - val_accuracy: 0.7478\n",
      "Epoch 54/1000\n",
      "120/120 [==============================] - 0s 3ms/step - loss: 0.6660 - accuracy: 0.7409 - val_loss: 0.7078 - val_accuracy: 0.7485\n",
      "Epoch 55/1000\n",
      "120/120 [==============================] - 0s 3ms/step - loss: 0.6660 - accuracy: 0.7403 - val_loss: 0.7078 - val_accuracy: 0.7472\n",
      "Epoch 56/1000\n",
      "120/120 [==============================] - 0s 3ms/step - loss: 0.6662 - accuracy: 0.7404 - val_loss: 0.7025 - val_accuracy: 0.7482\n",
      "Epoch 57/1000\n",
      "120/120 [==============================] - 0s 3ms/step - loss: 0.6650 - accuracy: 0.7407 - val_loss: 0.7109 - val_accuracy: 0.7481\n",
      "Epoch 58/1000\n",
      "120/120 [==============================] - 0s 3ms/step - loss: 0.6656 - accuracy: 0.7402 - val_loss: 0.7019 - val_accuracy: 0.7475\n",
      "Epoch 59/1000\n",
      "120/120 [==============================] - 0s 3ms/step - loss: 0.6660 - accuracy: 0.7399 - val_loss: 0.7140 - val_accuracy: 0.7485\n",
      "Epoch 60/1000\n",
      "120/120 [==============================] - 0s 3ms/step - loss: 0.6652 - accuracy: 0.7398 - val_loss: 0.6954 - val_accuracy: 0.7480\n",
      "Epoch 61/1000\n",
      "120/120 [==============================] - 0s 3ms/step - loss: 0.6656 - accuracy: 0.7401 - val_loss: 0.7382 - val_accuracy: 0.7471\n",
      "Epoch 62/1000\n",
      "120/120 [==============================] - 0s 3ms/step - loss: 0.6647 - accuracy: 0.7414 - val_loss: 0.7324 - val_accuracy: 0.7475\n",
      "Epoch 63/1000\n",
      "120/120 [==============================] - 0s 3ms/step - loss: 0.6648 - accuracy: 0.7404 - val_loss: 0.7080 - val_accuracy: 0.7472\n",
      "Epoch 64/1000\n",
      "120/120 [==============================] - 0s 3ms/step - loss: 0.6645 - accuracy: 0.7410 - val_loss: 0.7275 - val_accuracy: 0.7471\n",
      "Epoch 65/1000\n",
      "120/120 [==============================] - 0s 3ms/step - loss: 0.6640 - accuracy: 0.7415 - val_loss: 0.7148 - val_accuracy: 0.7481\n",
      "Epoch 66/1000\n",
      "120/120 [==============================] - 0s 3ms/step - loss: 0.6632 - accuracy: 0.7411 - val_loss: 0.7272 - val_accuracy: 0.7474\n",
      "Epoch 67/1000\n",
      "120/120 [==============================] - 0s 3ms/step - loss: 0.6639 - accuracy: 0.7411 - val_loss: 0.7240 - val_accuracy: 0.7471\n",
      "Epoch 68/1000\n",
      "120/120 [==============================] - 0s 3ms/step - loss: 0.6649 - accuracy: 0.7403 - val_loss: 0.7387 - val_accuracy: 0.7478\n",
      "Epoch 69/1000\n",
      "120/120 [==============================] - 0s 3ms/step - loss: 0.6640 - accuracy: 0.7410 - val_loss: 0.7295 - val_accuracy: 0.7475\n",
      "Epoch 70/1000\n",
      "120/120 [==============================] - 0s 3ms/step - loss: 0.6633 - accuracy: 0.7415 - val_loss: 0.7350 - val_accuracy: 0.7485\n",
      "Epoch 71/1000\n",
      "120/120 [==============================] - 0s 3ms/step - loss: 0.6634 - accuracy: 0.7413 - val_loss: 0.7197 - val_accuracy: 0.7482\n",
      "Epoch 72/1000\n",
      "120/120 [==============================] - 0s 3ms/step - loss: 0.6637 - accuracy: 0.7414 - val_loss: 0.7506 - val_accuracy: 0.7482\n",
      "Epoch 73/1000\n",
      "120/120 [==============================] - 0s 3ms/step - loss: 0.6635 - accuracy: 0.7410 - val_loss: 0.7293 - val_accuracy: 0.7472\n",
      "Epoch 74/1000\n",
      "120/120 [==============================] - 0s 3ms/step - loss: 0.6632 - accuracy: 0.7414 - val_loss: 0.7271 - val_accuracy: 0.7474\n",
      "Epoch 75/1000\n",
      "120/120 [==============================] - 0s 3ms/step - loss: 0.6619 - accuracy: 0.7413 - val_loss: 0.7274 - val_accuracy: 0.7485\n",
      "Epoch 76/1000\n",
      "120/120 [==============================] - 0s 3ms/step - loss: 0.6633 - accuracy: 0.7413 - val_loss: 0.7577 - val_accuracy: 0.7486\n",
      "Epoch 77/1000\n",
      "120/120 [==============================] - 0s 3ms/step - loss: 0.6624 - accuracy: 0.7421 - val_loss: 0.7509 - val_accuracy: 0.7484\n",
      "Epoch 78/1000\n",
      "120/120 [==============================] - 0s 3ms/step - loss: 0.6633 - accuracy: 0.7408 - val_loss: 0.7151 - val_accuracy: 0.7485\n",
      "Epoch 79/1000\n",
      "120/120 [==============================] - 0s 3ms/step - loss: 0.6633 - accuracy: 0.7408 - val_loss: 0.7331 - val_accuracy: 0.7477\n",
      "Epoch 80/1000\n",
      "120/120 [==============================] - 0s 3ms/step - loss: 0.6625 - accuracy: 0.7419 - val_loss: 0.7623 - val_accuracy: 0.7477\n",
      "Epoch 81/1000\n",
      "120/120 [==============================] - 0s 3ms/step - loss: 0.6618 - accuracy: 0.7422 - val_loss: 0.7380 - val_accuracy: 0.7479\n",
      "Epoch 82/1000\n",
      "120/120 [==============================] - 0s 3ms/step - loss: 0.6613 - accuracy: 0.7421 - val_loss: 0.7504 - val_accuracy: 0.7485\n",
      "Epoch 83/1000\n",
      "120/120 [==============================] - 0s 3ms/step - loss: 0.6618 - accuracy: 0.7419 - val_loss: 0.7159 - val_accuracy: 0.7486\n",
      "Epoch 84/1000\n",
      "120/120 [==============================] - 0s 3ms/step - loss: 0.6620 - accuracy: 0.7418 - val_loss: 0.7649 - val_accuracy: 0.7474\n",
      "Epoch 85/1000\n",
      "120/120 [==============================] - 0s 3ms/step - loss: 0.6601 - accuracy: 0.7423 - val_loss: 0.7211 - val_accuracy: 0.7479\n",
      "Epoch 86/1000\n",
      "120/120 [==============================] - 0s 3ms/step - loss: 0.6612 - accuracy: 0.7416 - val_loss: 0.7508 - val_accuracy: 0.7476\n",
      "Epoch 87/1000\n",
      "120/120 [==============================] - 0s 3ms/step - loss: 0.6606 - accuracy: 0.7420 - val_loss: 0.7498 - val_accuracy: 0.7469\n",
      "Epoch 88/1000\n",
      "120/120 [==============================] - 0s 3ms/step - loss: 0.6617 - accuracy: 0.7422 - val_loss: 0.7675 - val_accuracy: 0.7485\n",
      "Epoch 89/1000\n",
      "120/120 [==============================] - 0s 3ms/step - loss: 0.6616 - accuracy: 0.7419 - val_loss: 0.7515 - val_accuracy: 0.7480\n",
      "Epoch 90/1000\n",
      "120/120 [==============================] - 0s 3ms/step - loss: 0.6612 - accuracy: 0.7421 - val_loss: 0.7924 - val_accuracy: 0.7480\n",
      "Epoch 91/1000\n",
      "120/120 [==============================] - 0s 3ms/step - loss: 0.6616 - accuracy: 0.7418 - val_loss: 0.7621 - val_accuracy: 0.7476\n",
      "Epoch 92/1000\n",
      "120/120 [==============================] - 0s 3ms/step - loss: 0.6612 - accuracy: 0.7418 - val_loss: 0.7411 - val_accuracy: 0.7478\n",
      "Epoch 93/1000\n",
      "120/120 [==============================] - 0s 3ms/step - loss: 0.6612 - accuracy: 0.7419 - val_loss: 0.7457 - val_accuracy: 0.7484\n",
      "Epoch 94/1000\n",
      "120/120 [==============================] - 0s 3ms/step - loss: 0.6600 - accuracy: 0.7425 - val_loss: 0.7800 - val_accuracy: 0.7467\n",
      "Epoch 95/1000\n",
      "120/120 [==============================] - 0s 3ms/step - loss: 0.6612 - accuracy: 0.7418 - val_loss: 0.7609 - val_accuracy: 0.7492\n",
      "Epoch 96/1000\n",
      "120/120 [==============================] - 0s 3ms/step - loss: 0.6611 - accuracy: 0.7422 - val_loss: 0.7628 - val_accuracy: 0.7467\n",
      "Epoch 97/1000\n",
      "120/120 [==============================] - 0s 3ms/step - loss: 0.6611 - accuracy: 0.7420 - val_loss: 0.7938 - val_accuracy: 0.7489\n",
      "Epoch 98/1000\n",
      "120/120 [==============================] - 0s 3ms/step - loss: 0.6599 - accuracy: 0.7427 - val_loss: 0.7887 - val_accuracy: 0.7473\n",
      "Epoch 99/1000\n",
      "120/120 [==============================] - 0s 3ms/step - loss: 0.6599 - accuracy: 0.7424 - val_loss: 0.7665 - val_accuracy: 0.7476\n",
      "Epoch 100/1000\n",
      "120/120 [==============================] - 0s 3ms/step - loss: 0.6586 - accuracy: 0.7428 - val_loss: 0.7796 - val_accuracy: 0.7468\n",
      "Epoch 101/1000\n",
      "120/120 [==============================] - 0s 3ms/step - loss: 0.6591 - accuracy: 0.7422 - val_loss: 0.8080 - val_accuracy: 0.7478\n",
      "Epoch 102/1000\n",
      "120/120 [==============================] - 0s 3ms/step - loss: 0.6593 - accuracy: 0.7426 - val_loss: 0.8022 - val_accuracy: 0.7482\n",
      "Epoch 103/1000\n",
      "120/120 [==============================] - 0s 3ms/step - loss: 0.6603 - accuracy: 0.7424 - val_loss: 0.7922 - val_accuracy: 0.7489\n",
      "Epoch 104/1000\n",
      "120/120 [==============================] - 0s 3ms/step - loss: 0.6598 - accuracy: 0.7428 - val_loss: 0.7910 - val_accuracy: 0.7488\n",
      "Epoch 105/1000\n",
      "120/120 [==============================] - 0s 3ms/step - loss: 0.6586 - accuracy: 0.7430 - val_loss: 0.7921 - val_accuracy: 0.7482\n",
      "Epoch 106/1000\n",
      "120/120 [==============================] - 0s 3ms/step - loss: 0.6596 - accuracy: 0.7428 - val_loss: 0.8127 - val_accuracy: 0.7491\n",
      "Epoch 107/1000\n",
      "120/120 [==============================] - 0s 3ms/step - loss: 0.6588 - accuracy: 0.7421 - val_loss: 0.8052 - val_accuracy: 0.7487\n",
      "Epoch 107: early stopping\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "<keras.src.callbacks.History at 0x142d5e770>"
      ]
     },
     "execution_count": 157,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "model=Sequential()\n",
    "model.add(Dense(128, activation=\"relu\"))\n",
    "model.add(Dropout(0.8))\n",
    "model.add(Dense(128, activation=\"relu\"))\n",
    "\n",
    "model.add(Dense(64, activation=\"relu\"))\n",
    "#model.add(Dropout(0.2))\n",
    "model.add(Dense(64, activation=\"relu\"))\n",
    "\n",
    "model.add(Dense(32, activation=\"relu\"))\n",
    "model.add(Dropout(0.2))\n",
    "model.add(Dense(16, activation=\"relu\"))\n",
    "#model.add(Dropout(0.2))\n",
    "model.add(Dense(3, activation=\"softmax\"))\n",
    "\n",
    "model.compile(loss='categorical_crossentropy', optimizer=Adam(learning_rate=0.001), metrics=['accuracy'])\n",
    "\n",
    "es=EarlyStopping(monitor=\"val_loss\",patience=90,mode=\"auto\",verbose=1)\n",
    "\n",
    "model.fit(X_train,\n",
    "          y_train,\n",
    "          epochs=1000,\n",
    "          batch_size=1024,\n",
    "          validation_split=0.1,\n",
    "          verbose=1,callbacks=[es])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 158,
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 1/512\n",
      "120/120 [==============================] - 1s 4ms/step - loss: 0.8628 - accuracy: 0.6305 - val_loss: 0.7536 - val_accuracy: 0.7066\n",
      "Epoch 2/512\n",
      "120/120 [==============================] - 0s 3ms/step - loss: 0.7695 - accuracy: 0.6976 - val_loss: 0.7166 - val_accuracy: 0.7240\n",
      "Epoch 3/512\n",
      "120/120 [==============================] - 0s 3ms/step - loss: 0.7420 - accuracy: 0.7115 - val_loss: 0.7103 - val_accuracy: 0.7258\n",
      "Epoch 4/512\n",
      "120/120 [==============================] - 0s 3ms/step - loss: 0.7294 - accuracy: 0.7175 - val_loss: 0.7034 - val_accuracy: 0.7277\n",
      "Epoch 5/512\n",
      "120/120 [==============================] - 0s 3ms/step - loss: 0.7208 - accuracy: 0.7204 - val_loss: 0.6983 - val_accuracy: 0.7283\n",
      "Epoch 6/512\n",
      "120/120 [==============================] - 0s 3ms/step - loss: 0.7138 - accuracy: 0.7227 - val_loss: 0.6924 - val_accuracy: 0.7330\n",
      "Epoch 7/512\n",
      "120/120 [==============================] - 0s 3ms/step - loss: 0.7091 - accuracy: 0.7252 - val_loss: 0.6863 - val_accuracy: 0.7366\n",
      "Epoch 8/512\n",
      "120/120 [==============================] - 0s 3ms/step - loss: 0.7030 - accuracy: 0.7279 - val_loss: 0.6881 - val_accuracy: 0.7383\n",
      "Epoch 9/512\n",
      "120/120 [==============================] - 0s 3ms/step - loss: 0.7008 - accuracy: 0.7284 - val_loss: 0.6872 - val_accuracy: 0.7397\n",
      "Epoch 10/512\n",
      "120/120 [==============================] - 0s 3ms/step - loss: 0.6976 - accuracy: 0.7289 - val_loss: 0.6842 - val_accuracy: 0.7404\n",
      "Epoch 11/512\n",
      "120/120 [==============================] - 0s 3ms/step - loss: 0.6936 - accuracy: 0.7308 - val_loss: 0.6831 - val_accuracy: 0.7412\n",
      "Epoch 12/512\n",
      "120/120 [==============================] - 0s 3ms/step - loss: 0.6918 - accuracy: 0.7322 - val_loss: 0.6788 - val_accuracy: 0.7420\n",
      "Epoch 13/512\n",
      "120/120 [==============================] - 0s 3ms/step - loss: 0.6902 - accuracy: 0.7326 - val_loss: 0.6785 - val_accuracy: 0.7426\n",
      "Epoch 14/512\n",
      "120/120 [==============================] - 0s 3ms/step - loss: 0.6879 - accuracy: 0.7335 - val_loss: 0.6859 - val_accuracy: 0.7421\n",
      "Epoch 15/512\n",
      "120/120 [==============================] - 0s 3ms/step - loss: 0.6854 - accuracy: 0.7345 - val_loss: 0.6816 - val_accuracy: 0.7426\n",
      "Epoch 16/512\n",
      "120/120 [==============================] - 0s 4ms/step - loss: 0.6849 - accuracy: 0.7344 - val_loss: 0.6847 - val_accuracy: 0.7437\n",
      "Epoch 17/512\n",
      "120/120 [==============================] - 1s 5ms/step - loss: 0.6830 - accuracy: 0.7350 - val_loss: 0.6775 - val_accuracy: 0.7437\n",
      "Epoch 18/512\n",
      "120/120 [==============================] - 0s 3ms/step - loss: 0.6828 - accuracy: 0.7355 - val_loss: 0.6834 - val_accuracy: 0.7438\n",
      "Epoch 19/512\n",
      "120/120 [==============================] - 0s 3ms/step - loss: 0.6810 - accuracy: 0.7356 - val_loss: 0.6870 - val_accuracy: 0.7445\n",
      "Epoch 20/512\n",
      "120/120 [==============================] - 0s 3ms/step - loss: 0.6798 - accuracy: 0.7361 - val_loss: 0.6953 - val_accuracy: 0.7442\n",
      "Epoch 21/512\n",
      "120/120 [==============================] - 0s 3ms/step - loss: 0.6796 - accuracy: 0.7364 - val_loss: 0.6814 - val_accuracy: 0.7453\n",
      "Epoch 22/512\n",
      "120/120 [==============================] - 0s 3ms/step - loss: 0.6793 - accuracy: 0.7368 - val_loss: 0.6842 - val_accuracy: 0.7446\n",
      "Epoch 23/512\n",
      "120/120 [==============================] - 0s 3ms/step - loss: 0.6767 - accuracy: 0.7378 - val_loss: 0.6876 - val_accuracy: 0.7443\n",
      "Epoch 24/512\n",
      "120/120 [==============================] - 0s 3ms/step - loss: 0.6765 - accuracy: 0.7379 - val_loss: 0.6788 - val_accuracy: 0.7468\n",
      "Epoch 25/512\n",
      "120/120 [==============================] - 0s 3ms/step - loss: 0.6775 - accuracy: 0.7377 - val_loss: 0.6735 - val_accuracy: 0.7466\n",
      "Epoch 26/512\n",
      "120/120 [==============================] - 0s 3ms/step - loss: 0.6756 - accuracy: 0.7386 - val_loss: 0.6757 - val_accuracy: 0.7454\n",
      "Epoch 27/512\n",
      "120/120 [==============================] - 0s 3ms/step - loss: 0.6744 - accuracy: 0.7381 - val_loss: 0.6794 - val_accuracy: 0.7461\n",
      "Epoch 28/512\n",
      "120/120 [==============================] - 0s 3ms/step - loss: 0.6742 - accuracy: 0.7389 - val_loss: 0.6796 - val_accuracy: 0.7468\n",
      "Epoch 29/512\n",
      "120/120 [==============================] - 0s 3ms/step - loss: 0.6738 - accuracy: 0.7390 - val_loss: 0.6775 - val_accuracy: 0.7459\n",
      "Epoch 30/512\n",
      "120/120 [==============================] - 0s 3ms/step - loss: 0.6747 - accuracy: 0.7380 - val_loss: 0.6839 - val_accuracy: 0.7461\n",
      "Epoch 31/512\n",
      "120/120 [==============================] - 0s 3ms/step - loss: 0.6726 - accuracy: 0.7392 - val_loss: 0.6802 - val_accuracy: 0.7482\n",
      "Epoch 32/512\n",
      "120/120 [==============================] - 0s 3ms/step - loss: 0.6708 - accuracy: 0.7396 - val_loss: 0.6775 - val_accuracy: 0.7481\n",
      "Epoch 33/512\n",
      "120/120 [==============================] - 0s 3ms/step - loss: 0.6723 - accuracy: 0.7390 - val_loss: 0.6799 - val_accuracy: 0.7478\n",
      "Epoch 34/512\n",
      "120/120 [==============================] - 0s 3ms/step - loss: 0.6721 - accuracy: 0.7387 - val_loss: 0.6884 - val_accuracy: 0.7491\n",
      "Epoch 35/512\n",
      "120/120 [==============================] - 0s 3ms/step - loss: 0.6707 - accuracy: 0.7392 - val_loss: 0.6831 - val_accuracy: 0.7476\n",
      "Epoch 36/512\n",
      "120/120 [==============================] - 0s 3ms/step - loss: 0.6701 - accuracy: 0.7402 - val_loss: 0.6822 - val_accuracy: 0.7496\n",
      "Epoch 37/512\n",
      "120/120 [==============================] - 0s 3ms/step - loss: 0.6697 - accuracy: 0.7403 - val_loss: 0.6813 - val_accuracy: 0.7473\n",
      "Epoch 38/512\n",
      "120/120 [==============================] - 0s 3ms/step - loss: 0.6693 - accuracy: 0.7395 - val_loss: 0.6810 - val_accuracy: 0.7446\n",
      "Epoch 39/512\n",
      "120/120 [==============================] - 0s 3ms/step - loss: 0.6685 - accuracy: 0.7403 - val_loss: 0.6788 - val_accuracy: 0.7482\n",
      "Epoch 40/512\n",
      "120/120 [==============================] - 0s 3ms/step - loss: 0.6698 - accuracy: 0.7397 - val_loss: 0.6792 - val_accuracy: 0.7480\n",
      "Epoch 41/512\n",
      "120/120 [==============================] - 0s 3ms/step - loss: 0.6683 - accuracy: 0.7409 - val_loss: 0.6878 - val_accuracy: 0.7477\n",
      "Epoch 42/512\n",
      "120/120 [==============================] - 0s 3ms/step - loss: 0.6681 - accuracy: 0.7396 - val_loss: 0.6844 - val_accuracy: 0.7488\n",
      "Epoch 43/512\n",
      "120/120 [==============================] - 0s 3ms/step - loss: 0.6678 - accuracy: 0.7405 - val_loss: 0.6925 - val_accuracy: 0.7481\n",
      "Epoch 44/512\n",
      "120/120 [==============================] - 0s 3ms/step - loss: 0.6678 - accuracy: 0.7403 - val_loss: 0.6755 - val_accuracy: 0.7492\n",
      "Epoch 45/512\n",
      "120/120 [==============================] - 0s 3ms/step - loss: 0.6674 - accuracy: 0.7404 - val_loss: 0.6859 - val_accuracy: 0.7467\n",
      "Epoch 46/512\n",
      "120/120 [==============================] - 0s 3ms/step - loss: 0.6668 - accuracy: 0.7406 - val_loss: 0.6913 - val_accuracy: 0.7491\n",
      "Epoch 47/512\n",
      "120/120 [==============================] - 0s 3ms/step - loss: 0.6661 - accuracy: 0.7413 - val_loss: 0.6796 - val_accuracy: 0.7498\n",
      "Epoch 48/512\n",
      "120/120 [==============================] - 0s 3ms/step - loss: 0.6667 - accuracy: 0.7407 - val_loss: 0.6885 - val_accuracy: 0.7480\n",
      "Epoch 49/512\n",
      "120/120 [==============================] - 0s 3ms/step - loss: 0.6662 - accuracy: 0.7410 - val_loss: 0.6925 - val_accuracy: 0.7486\n",
      "Epoch 50/512\n",
      "120/120 [==============================] - 0s 3ms/step - loss: 0.6655 - accuracy: 0.7413 - val_loss: 0.6875 - val_accuracy: 0.7484\n",
      "Epoch 51/512\n",
      "120/120 [==============================] - 0s 3ms/step - loss: 0.6652 - accuracy: 0.7410 - val_loss: 0.6823 - val_accuracy: 0.7489\n",
      "Epoch 52/512\n",
      "120/120 [==============================] - 0s 3ms/step - loss: 0.6647 - accuracy: 0.7411 - val_loss: 0.6878 - val_accuracy: 0.7481\n",
      "Epoch 53/512\n",
      "120/120 [==============================] - 0s 3ms/step - loss: 0.6645 - accuracy: 0.7421 - val_loss: 0.6990 - val_accuracy: 0.7490\n",
      "Epoch 54/512\n",
      "120/120 [==============================] - 0s 3ms/step - loss: 0.6642 - accuracy: 0.7419 - val_loss: 0.6870 - val_accuracy: 0.7480\n",
      "Epoch 55/512\n",
      "120/120 [==============================] - 0s 3ms/step - loss: 0.6647 - accuracy: 0.7413 - val_loss: 0.6946 - val_accuracy: 0.7488\n",
      "Epoch 56/512\n",
      "120/120 [==============================] - 0s 3ms/step - loss: 0.6642 - accuracy: 0.7411 - val_loss: 0.6916 - val_accuracy: 0.7492\n",
      "Epoch 57/512\n",
      "120/120 [==============================] - 0s 3ms/step - loss: 0.6638 - accuracy: 0.7419 - val_loss: 0.6909 - val_accuracy: 0.7483\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 58/512\n",
      "120/120 [==============================] - 0s 3ms/step - loss: 0.6634 - accuracy: 0.7414 - val_loss: 0.6978 - val_accuracy: 0.7487\n",
      "Epoch 59/512\n",
      "120/120 [==============================] - 0s 3ms/step - loss: 0.6646 - accuracy: 0.7414 - val_loss: 0.6917 - val_accuracy: 0.7491\n",
      "Epoch 60/512\n",
      "120/120 [==============================] - 0s 3ms/step - loss: 0.6630 - accuracy: 0.7414 - val_loss: 0.6949 - val_accuracy: 0.7488\n",
      "Epoch 61/512\n",
      "120/120 [==============================] - 0s 3ms/step - loss: 0.6641 - accuracy: 0.7407 - val_loss: 0.6981 - val_accuracy: 0.7483\n",
      "Epoch 62/512\n",
      "120/120 [==============================] - 0s 3ms/step - loss: 0.6628 - accuracy: 0.7419 - val_loss: 0.7202 - val_accuracy: 0.7483\n",
      "Epoch 63/512\n",
      "120/120 [==============================] - 0s 3ms/step - loss: 0.6621 - accuracy: 0.7423 - val_loss: 0.7067 - val_accuracy: 0.7477\n",
      "Epoch 64/512\n",
      "120/120 [==============================] - 0s 3ms/step - loss: 0.6616 - accuracy: 0.7427 - val_loss: 0.6977 - val_accuracy: 0.7499\n",
      "Epoch 65/512\n",
      "120/120 [==============================] - 0s 3ms/step - loss: 0.6620 - accuracy: 0.7414 - val_loss: 0.7088 - val_accuracy: 0.7503\n",
      "Epoch 66/512\n",
      "120/120 [==============================] - 0s 3ms/step - loss: 0.6616 - accuracy: 0.7418 - val_loss: 0.7120 - val_accuracy: 0.7488\n",
      "Epoch 67/512\n",
      "120/120 [==============================] - 0s 3ms/step - loss: 0.6627 - accuracy: 0.7421 - val_loss: 0.7261 - val_accuracy: 0.7501\n",
      "Epoch 68/512\n",
      "120/120 [==============================] - 0s 3ms/step - loss: 0.6617 - accuracy: 0.7433 - val_loss: 0.7014 - val_accuracy: 0.7508\n",
      "Epoch 69/512\n",
      "120/120 [==============================] - 0s 3ms/step - loss: 0.6621 - accuracy: 0.7424 - val_loss: 0.7228 - val_accuracy: 0.7494\n",
      "Epoch 70/512\n",
      "120/120 [==============================] - 0s 3ms/step - loss: 0.6617 - accuracy: 0.7418 - val_loss: 0.7150 - val_accuracy: 0.7492\n",
      "Epoch 71/512\n",
      "120/120 [==============================] - 0s 3ms/step - loss: 0.6609 - accuracy: 0.7421 - val_loss: 0.7096 - val_accuracy: 0.7487\n",
      "Epoch 72/512\n",
      "120/120 [==============================] - 0s 3ms/step - loss: 0.6611 - accuracy: 0.7423 - val_loss: 0.7102 - val_accuracy: 0.7499\n",
      "Epoch 73/512\n",
      "120/120 [==============================] - 0s 3ms/step - loss: 0.6613 - accuracy: 0.7423 - val_loss: 0.7270 - val_accuracy: 0.7508\n",
      "Epoch 74/512\n",
      "120/120 [==============================] - 0s 3ms/step - loss: 0.6613 - accuracy: 0.7426 - val_loss: 0.7033 - val_accuracy: 0.7510\n",
      "Epoch 75/512\n",
      "120/120 [==============================] - 0s 3ms/step - loss: 0.6608 - accuracy: 0.7425 - val_loss: 0.7171 - val_accuracy: 0.7485\n",
      "Epoch 76/512\n",
      "120/120 [==============================] - 0s 3ms/step - loss: 0.6603 - accuracy: 0.7428 - val_loss: 0.7456 - val_accuracy: 0.7510\n",
      "Epoch 77/512\n",
      "120/120 [==============================] - 0s 3ms/step - loss: 0.6616 - accuracy: 0.7423 - val_loss: 0.7210 - val_accuracy: 0.7494\n",
      "Epoch 78/512\n",
      "120/120 [==============================] - 0s 3ms/step - loss: 0.6605 - accuracy: 0.7435 - val_loss: 0.7288 - val_accuracy: 0.7493\n",
      "Epoch 79/512\n",
      "120/120 [==============================] - 0s 3ms/step - loss: 0.6610 - accuracy: 0.7424 - val_loss: 0.7247 - val_accuracy: 0.7494\n",
      "Epoch 80/512\n",
      "120/120 [==============================] - 0s 3ms/step - loss: 0.6609 - accuracy: 0.7422 - val_loss: 0.6970 - val_accuracy: 0.7507\n",
      "Epoch 81/512\n",
      "120/120 [==============================] - 0s 3ms/step - loss: 0.6608 - accuracy: 0.7421 - val_loss: 0.7340 - val_accuracy: 0.7506\n",
      "Epoch 82/512\n",
      "120/120 [==============================] - 0s 3ms/step - loss: 0.6601 - accuracy: 0.7427 - val_loss: 0.7280 - val_accuracy: 0.7496\n",
      "Epoch 83/512\n",
      "120/120 [==============================] - 0s 3ms/step - loss: 0.6605 - accuracy: 0.7429 - val_loss: 0.7446 - val_accuracy: 0.7494\n",
      "Epoch 84/512\n",
      "120/120 [==============================] - 0s 3ms/step - loss: 0.6595 - accuracy: 0.7429 - val_loss: 0.7262 - val_accuracy: 0.7490\n",
      "Epoch 85/512\n",
      "120/120 [==============================] - 0s 3ms/step - loss: 0.6600 - accuracy: 0.7424 - val_loss: 0.7227 - val_accuracy: 0.7483\n",
      "Epoch 86/512\n",
      "120/120 [==============================] - 0s 3ms/step - loss: 0.6596 - accuracy: 0.7422 - val_loss: 0.7157 - val_accuracy: 0.7499\n",
      "Epoch 87/512\n",
      "120/120 [==============================] - 0s 3ms/step - loss: 0.6598 - accuracy: 0.7421 - val_loss: 0.7221 - val_accuracy: 0.7502\n",
      "Epoch 88/512\n",
      "120/120 [==============================] - 0s 3ms/step - loss: 0.6590 - accuracy: 0.7429 - val_loss: 0.7321 - val_accuracy: 0.7486\n",
      "Epoch 89/512\n",
      "120/120 [==============================] - 0s 3ms/step - loss: 0.6605 - accuracy: 0.7423 - val_loss: 0.7530 - val_accuracy: 0.7485\n",
      "Epoch 90/512\n",
      "120/120 [==============================] - 0s 3ms/step - loss: 0.6603 - accuracy: 0.7424 - val_loss: 0.7238 - val_accuracy: 0.7491\n",
      "Epoch 91/512\n",
      "120/120 [==============================] - 0s 3ms/step - loss: 0.6585 - accuracy: 0.7432 - val_loss: 0.7112 - val_accuracy: 0.7503\n",
      "Epoch 92/512\n",
      "120/120 [==============================] - 0s 3ms/step - loss: 0.6595 - accuracy: 0.7433 - val_loss: 0.7449 - val_accuracy: 0.7508\n",
      "Epoch 93/512\n",
      "120/120 [==============================] - 0s 3ms/step - loss: 0.6582 - accuracy: 0.7433 - val_loss: 0.7151 - val_accuracy: 0.7508\n",
      "Epoch 94/512\n",
      "120/120 [==============================] - 0s 3ms/step - loss: 0.6585 - accuracy: 0.7428 - val_loss: 0.7288 - val_accuracy: 0.7514\n",
      "Epoch 95/512\n",
      "120/120 [==============================] - 0s 3ms/step - loss: 0.6589 - accuracy: 0.7427 - val_loss: 0.7233 - val_accuracy: 0.7494\n",
      "Epoch 96/512\n",
      "120/120 [==============================] - 0s 3ms/step - loss: 0.6581 - accuracy: 0.7434 - val_loss: 0.7285 - val_accuracy: 0.7511\n",
      "Epoch 97/512\n",
      "120/120 [==============================] - 0s 3ms/step - loss: 0.6586 - accuracy: 0.7434 - val_loss: 0.7043 - val_accuracy: 0.7506\n",
      "Epoch 98/512\n",
      "120/120 [==============================] - 0s 3ms/step - loss: 0.6580 - accuracy: 0.7432 - val_loss: 0.7155 - val_accuracy: 0.7499\n",
      "Epoch 99/512\n",
      "120/120 [==============================] - 0s 3ms/step - loss: 0.6587 - accuracy: 0.7424 - val_loss: 0.7472 - val_accuracy: 0.7502\n",
      "Epoch 100/512\n",
      "120/120 [==============================] - 0s 3ms/step - loss: 0.6580 - accuracy: 0.7429 - val_loss: 0.7289 - val_accuracy: 0.7493\n",
      "Epoch 101/512\n",
      "120/120 [==============================] - 0s 3ms/step - loss: 0.6580 - accuracy: 0.7429 - val_loss: 0.7517 - val_accuracy: 0.7480\n",
      "Epoch 102/512\n",
      "120/120 [==============================] - 0s 3ms/step - loss: 0.6592 - accuracy: 0.7424 - val_loss: 0.7731 - val_accuracy: 0.7488\n",
      "Epoch 103/512\n",
      "120/120 [==============================] - 0s 3ms/step - loss: 0.6586 - accuracy: 0.7428 - val_loss: 0.7680 - val_accuracy: 0.7486\n",
      "Epoch 104/512\n",
      "120/120 [==============================] - 0s 3ms/step - loss: 0.6582 - accuracy: 0.7434 - val_loss: 0.7356 - val_accuracy: 0.7490\n",
      "Epoch 105/512\n",
      "120/120 [==============================] - 0s 4ms/step - loss: 0.6577 - accuracy: 0.7432 - val_loss: 0.7394 - val_accuracy: 0.7479\n",
      "Epoch 106/512\n",
      "120/120 [==============================] - 0s 3ms/step - loss: 0.6580 - accuracy: 0.7437 - val_loss: 0.7670 - val_accuracy: 0.7479\n",
      "Epoch 107/512\n",
      "120/120 [==============================] - 0s 3ms/step - loss: 0.6579 - accuracy: 0.7439 - val_loss: 0.7358 - val_accuracy: 0.7493\n",
      "Epoch 108/512\n",
      "120/120 [==============================] - 0s 3ms/step - loss: 0.6580 - accuracy: 0.7430 - val_loss: 0.7590 - val_accuracy: 0.7489\n",
      "Epoch 109/512\n",
      "120/120 [==============================] - 0s 3ms/step - loss: 0.6579 - accuracy: 0.7436 - val_loss: 0.7597 - val_accuracy: 0.7499\n",
      "Epoch 110/512\n",
      "120/120 [==============================] - 0s 3ms/step - loss: 0.6569 - accuracy: 0.7434 - val_loss: 0.7785 - val_accuracy: 0.7486\n",
      "Epoch 111/512\n",
      "120/120 [==============================] - 0s 3ms/step - loss: 0.6579 - accuracy: 0.7432 - val_loss: 0.7544 - val_accuracy: 0.7478\n",
      "Epoch 112/512\n",
      "120/120 [==============================] - 0s 3ms/step - loss: 0.6572 - accuracy: 0.7429 - val_loss: 0.7725 - val_accuracy: 0.7493\n",
      "Epoch 113/512\n",
      "120/120 [==============================] - 0s 3ms/step - loss: 0.6578 - accuracy: 0.7432 - val_loss: 0.7868 - val_accuracy: 0.7485\n",
      "Epoch 114/512\n",
      "120/120 [==============================] - 0s 3ms/step - loss: 0.6572 - accuracy: 0.7432 - val_loss: 0.7528 - val_accuracy: 0.7474\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 115/512\n",
      "120/120 [==============================] - 0s 3ms/step - loss: 0.6563 - accuracy: 0.7432 - val_loss: 0.8096 - val_accuracy: 0.7492\n",
      "Epoch 115: early stopping\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "<keras.src.callbacks.History at 0x143035e70>"
      ]
     },
     "execution_count": 158,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "model=Sequential()\n",
    "model.add(Dense(128, activation=\"relu\"))\n",
    "model.add(Dropout(0.8))\n",
    "model.add(Dense(128, activation=\"relu\"))\n",
    "\n",
    "model.add(Dense(64, activation=\"relu\"))\n",
    "#model.add(Dropout(0.2))\n",
    "model.add(Dense(64, activation=\"relu\"))\n",
    "\n",
    "model.add(Dense(32, activation=\"relu\"))\n",
    "model.add(Dropout(0.2))\n",
    "model.add(Dense(16, activation=\"relu\"))\n",
    "#model.add(Dropout(0.2))\n",
    "model.add(Dense(3, activation=\"softmax\"))\n",
    "\n",
    "model.compile(loss='categorical_crossentropy', optimizer=Adam(learning_rate=0.001), metrics=['accuracy'])\n",
    "\n",
    "es=EarlyStopping(monitor=\"val_loss\",patience=90,mode=\"auto\",verbose=1)\n",
    "\n",
    "model.fit(X_train,\n",
    "          y_train,\n",
    "          epochs=512,\n",
    "          batch_size=1024,\n",
    "          validation_split=0.1,\n",
    "          verbose=1,callbacks=[es])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 159,
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 1/1000\n",
      "239/239 [==============================] - 1s 2ms/step - loss: 0.7453 - accuracy: 0.7064 - val_loss: 0.6792 - val_accuracy: 0.7344\n",
      "Epoch 2/1000\n",
      "239/239 [==============================] - 1s 2ms/step - loss: 0.6803 - accuracy: 0.7352 - val_loss: 0.6647 - val_accuracy: 0.7401\n",
      "Epoch 3/1000\n",
      "239/239 [==============================] - 0s 2ms/step - loss: 0.6659 - accuracy: 0.7404 - val_loss: 0.6562 - val_accuracy: 0.7449\n",
      "Epoch 4/1000\n",
      "239/239 [==============================] - 1s 3ms/step - loss: 0.6581 - accuracy: 0.7433 - val_loss: 0.6471 - val_accuracy: 0.7471\n",
      "Epoch 5/1000\n",
      "239/239 [==============================] - 0s 2ms/step - loss: 0.6502 - accuracy: 0.7457 - val_loss: 0.6424 - val_accuracy: 0.7494\n",
      "Epoch 6/1000\n",
      "239/239 [==============================] - 0s 2ms/step - loss: 0.6440 - accuracy: 0.7484 - val_loss: 0.6345 - val_accuracy: 0.7513\n",
      "Epoch 7/1000\n",
      "239/239 [==============================] - 1s 2ms/step - loss: 0.6384 - accuracy: 0.7492 - val_loss: 0.6307 - val_accuracy: 0.7525\n",
      "Epoch 8/1000\n",
      "239/239 [==============================] - 0s 2ms/step - loss: 0.6341 - accuracy: 0.7507 - val_loss: 0.6249 - val_accuracy: 0.7566\n",
      "Epoch 9/1000\n",
      "239/239 [==============================] - 0s 2ms/step - loss: 0.6294 - accuracy: 0.7518 - val_loss: 0.6181 - val_accuracy: 0.7574\n",
      "Epoch 10/1000\n",
      "239/239 [==============================] - 0s 2ms/step - loss: 0.6245 - accuracy: 0.7542 - val_loss: 0.6106 - val_accuracy: 0.7594\n",
      "Epoch 11/1000\n",
      "239/239 [==============================] - 1s 2ms/step - loss: 0.6195 - accuracy: 0.7557 - val_loss: 0.6064 - val_accuracy: 0.7625\n",
      "Epoch 12/1000\n",
      "239/239 [==============================] - 1s 2ms/step - loss: 0.6149 - accuracy: 0.7574 - val_loss: 0.6041 - val_accuracy: 0.7634\n",
      "Epoch 13/1000\n",
      "239/239 [==============================] - 0s 2ms/step - loss: 0.6102 - accuracy: 0.7598 - val_loss: 0.5963 - val_accuracy: 0.7661\n",
      "Epoch 14/1000\n",
      "239/239 [==============================] - 0s 2ms/step - loss: 0.6063 - accuracy: 0.7601 - val_loss: 0.5935 - val_accuracy: 0.7687\n",
      "Epoch 15/1000\n",
      "239/239 [==============================] - 0s 2ms/step - loss: 0.6025 - accuracy: 0.7630 - val_loss: 0.5885 - val_accuracy: 0.7717\n",
      "Epoch 16/1000\n",
      "239/239 [==============================] - 0s 2ms/step - loss: 0.5975 - accuracy: 0.7641 - val_loss: 0.5819 - val_accuracy: 0.7740\n",
      "Epoch 17/1000\n",
      "239/239 [==============================] - 0s 2ms/step - loss: 0.5938 - accuracy: 0.7652 - val_loss: 0.5797 - val_accuracy: 0.7728\n",
      "Epoch 18/1000\n",
      "239/239 [==============================] - 0s 2ms/step - loss: 0.5894 - accuracy: 0.7667 - val_loss: 0.5777 - val_accuracy: 0.7741\n",
      "Epoch 19/1000\n",
      "239/239 [==============================] - 0s 2ms/step - loss: 0.5868 - accuracy: 0.7674 - val_loss: 0.5718 - val_accuracy: 0.7776\n",
      "Epoch 20/1000\n",
      "239/239 [==============================] - 1s 2ms/step - loss: 0.5833 - accuracy: 0.7695 - val_loss: 0.5660 - val_accuracy: 0.7800\n",
      "Epoch 21/1000\n",
      "239/239 [==============================] - 1s 2ms/step - loss: 0.5799 - accuracy: 0.7706 - val_loss: 0.5661 - val_accuracy: 0.7786\n",
      "Epoch 22/1000\n",
      "239/239 [==============================] - 0s 2ms/step - loss: 0.5769 - accuracy: 0.7710 - val_loss: 0.5591 - val_accuracy: 0.7808\n",
      "Epoch 23/1000\n",
      "239/239 [==============================] - 1s 2ms/step - loss: 0.5726 - accuracy: 0.7725 - val_loss: 0.5582 - val_accuracy: 0.7834\n",
      "Epoch 24/1000\n",
      "239/239 [==============================] - 1s 2ms/step - loss: 0.5693 - accuracy: 0.7742 - val_loss: 0.5548 - val_accuracy: 0.7829\n",
      "Epoch 25/1000\n",
      "239/239 [==============================] - 1s 2ms/step - loss: 0.5666 - accuracy: 0.7761 - val_loss: 0.5543 - val_accuracy: 0.7820\n",
      "Epoch 26/1000\n",
      "239/239 [==============================] - 0s 2ms/step - loss: 0.5650 - accuracy: 0.7761 - val_loss: 0.5460 - val_accuracy: 0.7852\n",
      "Epoch 27/1000\n",
      "239/239 [==============================] - 1s 2ms/step - loss: 0.5607 - accuracy: 0.7763 - val_loss: 0.5417 - val_accuracy: 0.7887\n",
      "Epoch 28/1000\n",
      "239/239 [==============================] - 1s 2ms/step - loss: 0.5582 - accuracy: 0.7782 - val_loss: 0.5417 - val_accuracy: 0.7896\n",
      "Epoch 29/1000\n",
      "239/239 [==============================] - 1s 2ms/step - loss: 0.5561 - accuracy: 0.7783 - val_loss: 0.5400 - val_accuracy: 0.7907\n",
      "Epoch 30/1000\n",
      "239/239 [==============================] - 1s 2ms/step - loss: 0.5541 - accuracy: 0.7793 - val_loss: 0.5334 - val_accuracy: 0.7910\n",
      "Epoch 31/1000\n",
      "239/239 [==============================] - 1s 2ms/step - loss: 0.5531 - accuracy: 0.7807 - val_loss: 0.5341 - val_accuracy: 0.7919\n",
      "Epoch 32/1000\n",
      "239/239 [==============================] - 0s 2ms/step - loss: 0.5499 - accuracy: 0.7809 - val_loss: 0.5343 - val_accuracy: 0.7921\n",
      "Epoch 33/1000\n",
      "239/239 [==============================] - 0s 2ms/step - loss: 0.5474 - accuracy: 0.7828 - val_loss: 0.5285 - val_accuracy: 0.7929\n",
      "Epoch 34/1000\n",
      "239/239 [==============================] - 0s 2ms/step - loss: 0.5468 - accuracy: 0.7830 - val_loss: 0.5266 - val_accuracy: 0.7927\n",
      "Epoch 35/1000\n",
      "239/239 [==============================] - 0s 2ms/step - loss: 0.5443 - accuracy: 0.7831 - val_loss: 0.5254 - val_accuracy: 0.7956\n",
      "Epoch 36/1000\n",
      "239/239 [==============================] - 0s 2ms/step - loss: 0.5442 - accuracy: 0.7831 - val_loss: 0.5231 - val_accuracy: 0.7959\n",
      "Epoch 37/1000\n",
      "239/239 [==============================] - 0s 2ms/step - loss: 0.5419 - accuracy: 0.7836 - val_loss: 0.5262 - val_accuracy: 0.7960\n",
      "Epoch 38/1000\n",
      "239/239 [==============================] - 1s 2ms/step - loss: 0.5402 - accuracy: 0.7861 - val_loss: 0.5181 - val_accuracy: 0.7981\n",
      "Epoch 39/1000\n",
      "239/239 [==============================] - 1s 2ms/step - loss: 0.5365 - accuracy: 0.7868 - val_loss: 0.5182 - val_accuracy: 0.7970\n",
      "Epoch 40/1000\n",
      "239/239 [==============================] - 1s 2ms/step - loss: 0.5364 - accuracy: 0.7868 - val_loss: 0.5240 - val_accuracy: 0.7948\n",
      "Epoch 41/1000\n",
      "239/239 [==============================] - 1s 2ms/step - loss: 0.5351 - accuracy: 0.7879 - val_loss: 0.5135 - val_accuracy: 0.7985\n",
      "Epoch 42/1000\n",
      "239/239 [==============================] - 0s 2ms/step - loss: 0.5327 - accuracy: 0.7887 - val_loss: 0.5112 - val_accuracy: 0.8006\n",
      "Epoch 43/1000\n",
      "239/239 [==============================] - 0s 2ms/step - loss: 0.5322 - accuracy: 0.7891 - val_loss: 0.5106 - val_accuracy: 0.8021\n",
      "Epoch 44/1000\n",
      "239/239 [==============================] - 0s 2ms/step - loss: 0.5306 - accuracy: 0.7897 - val_loss: 0.5091 - val_accuracy: 0.8048\n",
      "Epoch 45/1000\n",
      "239/239 [==============================] - 0s 2ms/step - loss: 0.5279 - accuracy: 0.7900 - val_loss: 0.5117 - val_accuracy: 0.8023\n",
      "Epoch 46/1000\n",
      "239/239 [==============================] - 1s 2ms/step - loss: 0.5268 - accuracy: 0.7915 - val_loss: 0.5048 - val_accuracy: 0.8023\n",
      "Epoch 47/1000\n",
      "239/239 [==============================] - 1s 2ms/step - loss: 0.5270 - accuracy: 0.7905 - val_loss: 0.5054 - val_accuracy: 0.8043\n",
      "Epoch 48/1000\n",
      "239/239 [==============================] - 1s 2ms/step - loss: 0.5261 - accuracy: 0.7911 - val_loss: 0.5066 - val_accuracy: 0.8026\n",
      "Epoch 49/1000\n",
      "239/239 [==============================] - 1s 2ms/step - loss: 0.5232 - accuracy: 0.7918 - val_loss: 0.5032 - val_accuracy: 0.8028\n",
      "Epoch 50/1000\n",
      "239/239 [==============================] - 1s 2ms/step - loss: 0.5194 - accuracy: 0.7934 - val_loss: 0.4991 - val_accuracy: 0.8035\n",
      "Epoch 51/1000\n",
      "239/239 [==============================] - 0s 2ms/step - loss: 0.5199 - accuracy: 0.7925 - val_loss: 0.4988 - val_accuracy: 0.8050\n",
      "Epoch 52/1000\n",
      "239/239 [==============================] - 0s 2ms/step - loss: 0.5198 - accuracy: 0.7944 - val_loss: 0.4981 - val_accuracy: 0.8059\n",
      "Epoch 53/1000\n",
      "239/239 [==============================] - 0s 2ms/step - loss: 0.5174 - accuracy: 0.7948 - val_loss: 0.4977 - val_accuracy: 0.8079\n",
      "Epoch 54/1000\n",
      "239/239 [==============================] - 0s 2ms/step - loss: 0.5188 - accuracy: 0.7942 - val_loss: 0.4967 - val_accuracy: 0.8082\n",
      "Epoch 55/1000\n",
      "239/239 [==============================] - 0s 2ms/step - loss: 0.5158 - accuracy: 0.7949 - val_loss: 0.4969 - val_accuracy: 0.8086\n",
      "Epoch 56/1000\n",
      "239/239 [==============================] - 0s 2ms/step - loss: 0.5162 - accuracy: 0.7953 - val_loss: 0.4931 - val_accuracy: 0.8074\n",
      "Epoch 57/1000\n",
      "239/239 [==============================] - 0s 2ms/step - loss: 0.5140 - accuracy: 0.7956 - val_loss: 0.4933 - val_accuracy: 0.8085\n",
      "Epoch 58/1000\n",
      "239/239 [==============================] - 0s 2ms/step - loss: 0.5125 - accuracy: 0.7969 - val_loss: 0.4910 - val_accuracy: 0.8089\n",
      "Epoch 59/1000\n",
      "239/239 [==============================] - 0s 2ms/step - loss: 0.5121 - accuracy: 0.7969 - val_loss: 0.4908 - val_accuracy: 0.8091\n",
      "Epoch 60/1000\n",
      "239/239 [==============================] - 0s 2ms/step - loss: 0.5105 - accuracy: 0.7971 - val_loss: 0.4896 - val_accuracy: 0.8087\n",
      "Epoch 61/1000\n",
      "239/239 [==============================] - 0s 2ms/step - loss: 0.5109 - accuracy: 0.7969 - val_loss: 0.4849 - val_accuracy: 0.8112\n",
      "Epoch 62/1000\n",
      "239/239 [==============================] - 1s 3ms/step - loss: 0.5108 - accuracy: 0.7970 - val_loss: 0.4898 - val_accuracy: 0.8092\n",
      "Epoch 63/1000\n",
      "239/239 [==============================] - 1s 2ms/step - loss: 0.5099 - accuracy: 0.7975 - val_loss: 0.4855 - val_accuracy: 0.8113\n",
      "Epoch 64/1000\n",
      "239/239 [==============================] - 1s 2ms/step - loss: 0.5083 - accuracy: 0.7975 - val_loss: 0.4897 - val_accuracy: 0.8098\n",
      "Epoch 65/1000\n",
      "239/239 [==============================] - 0s 2ms/step - loss: 0.5076 - accuracy: 0.7984 - val_loss: 0.4861 - val_accuracy: 0.8121\n",
      "Epoch 66/1000\n",
      "239/239 [==============================] - 0s 2ms/step - loss: 0.5056 - accuracy: 0.7988 - val_loss: 0.4829 - val_accuracy: 0.8123\n",
      "Epoch 67/1000\n",
      "239/239 [==============================] - 1s 2ms/step - loss: 0.5068 - accuracy: 0.7991 - val_loss: 0.4835 - val_accuracy: 0.8150\n",
      "Epoch 68/1000\n",
      "239/239 [==============================] - 1s 2ms/step - loss: 0.5047 - accuracy: 0.8001 - val_loss: 0.4830 - val_accuracy: 0.8113\n",
      "Epoch 69/1000\n",
      "239/239 [==============================] - 0s 2ms/step - loss: 0.5049 - accuracy: 0.8005 - val_loss: 0.4819 - val_accuracy: 0.8131\n",
      "Epoch 70/1000\n",
      "239/239 [==============================] - 1s 2ms/step - loss: 0.5031 - accuracy: 0.8001 - val_loss: 0.4824 - val_accuracy: 0.8140\n",
      "Epoch 71/1000\n",
      "239/239 [==============================] - 1s 2ms/step - loss: 0.5024 - accuracy: 0.7998 - val_loss: 0.4797 - val_accuracy: 0.8144\n",
      "Epoch 72/1000\n",
      "239/239 [==============================] - 1s 2ms/step - loss: 0.5016 - accuracy: 0.8017 - val_loss: 0.4776 - val_accuracy: 0.8137\n",
      "Epoch 73/1000\n",
      "239/239 [==============================] - 0s 2ms/step - loss: 0.5003 - accuracy: 0.8006 - val_loss: 0.4834 - val_accuracy: 0.8123\n",
      "Epoch 74/1000\n",
      "239/239 [==============================] - 0s 2ms/step - loss: 0.5002 - accuracy: 0.8021 - val_loss: 0.4776 - val_accuracy: 0.8139\n",
      "Epoch 75/1000\n",
      "239/239 [==============================] - 0s 2ms/step - loss: 0.4998 - accuracy: 0.8006 - val_loss: 0.4789 - val_accuracy: 0.8146\n",
      "Epoch 76/1000\n",
      "239/239 [==============================] - 1s 2ms/step - loss: 0.4990 - accuracy: 0.8025 - val_loss: 0.4746 - val_accuracy: 0.8178\n",
      "Epoch 77/1000\n",
      "239/239 [==============================] - 0s 2ms/step - loss: 0.4993 - accuracy: 0.8033 - val_loss: 0.4774 - val_accuracy: 0.8144\n",
      "Epoch 78/1000\n",
      "239/239 [==============================] - 0s 2ms/step - loss: 0.4963 - accuracy: 0.8029 - val_loss: 0.4764 - val_accuracy: 0.8149\n",
      "Epoch 79/1000\n",
      "239/239 [==============================] - 1s 2ms/step - loss: 0.4971 - accuracy: 0.8033 - val_loss: 0.4751 - val_accuracy: 0.8174\n",
      "Epoch 80/1000\n",
      "239/239 [==============================] - 0s 2ms/step - loss: 0.4946 - accuracy: 0.8040 - val_loss: 0.4739 - val_accuracy: 0.8167\n",
      "Epoch 81/1000\n",
      "239/239 [==============================] - 0s 2ms/step - loss: 0.4946 - accuracy: 0.8042 - val_loss: 0.4754 - val_accuracy: 0.8155\n",
      "Epoch 82/1000\n",
      "239/239 [==============================] - 0s 2ms/step - loss: 0.4946 - accuracy: 0.8038 - val_loss: 0.4730 - val_accuracy: 0.8169\n",
      "Epoch 83/1000\n",
      "239/239 [==============================] - 1s 2ms/step - loss: 0.4964 - accuracy: 0.8040 - val_loss: 0.4724 - val_accuracy: 0.8143\n",
      "Epoch 84/1000\n",
      "239/239 [==============================] - 1s 2ms/step - loss: 0.4953 - accuracy: 0.8038 - val_loss: 0.4714 - val_accuracy: 0.8180\n",
      "Epoch 85/1000\n",
      "239/239 [==============================] - 1s 2ms/step - loss: 0.4940 - accuracy: 0.8043 - val_loss: 0.4682 - val_accuracy: 0.8180\n",
      "Epoch 86/1000\n",
      "239/239 [==============================] - 1s 2ms/step - loss: 0.4931 - accuracy: 0.8056 - val_loss: 0.4704 - val_accuracy: 0.8176\n",
      "Epoch 87/1000\n",
      "239/239 [==============================] - 0s 2ms/step - loss: 0.4913 - accuracy: 0.8065 - val_loss: 0.4726 - val_accuracy: 0.8158\n",
      "Epoch 88/1000\n",
      "239/239 [==============================] - 0s 2ms/step - loss: 0.4912 - accuracy: 0.8059 - val_loss: 0.4722 - val_accuracy: 0.8166\n",
      "Epoch 89/1000\n",
      "239/239 [==============================] - 0s 2ms/step - loss: 0.4911 - accuracy: 0.8062 - val_loss: 0.4689 - val_accuracy: 0.8165\n",
      "Epoch 90/1000\n",
      "239/239 [==============================] - 0s 2ms/step - loss: 0.4902 - accuracy: 0.8073 - val_loss: 0.4687 - val_accuracy: 0.8175\n",
      "Epoch 91/1000\n",
      "239/239 [==============================] - 0s 2ms/step - loss: 0.4884 - accuracy: 0.8060 - val_loss: 0.4659 - val_accuracy: 0.8192\n",
      "Epoch 92/1000\n",
      "239/239 [==============================] - 1s 2ms/step - loss: 0.4895 - accuracy: 0.8063 - val_loss: 0.4664 - val_accuracy: 0.8175\n",
      "Epoch 93/1000\n",
      "239/239 [==============================] - 1s 2ms/step - loss: 0.4899 - accuracy: 0.8059 - val_loss: 0.4666 - val_accuracy: 0.8180\n",
      "Epoch 94/1000\n",
      "239/239 [==============================] - 0s 2ms/step - loss: 0.4883 - accuracy: 0.8066 - val_loss: 0.4682 - val_accuracy: 0.8160\n",
      "Epoch 95/1000\n",
      "239/239 [==============================] - 0s 2ms/step - loss: 0.4901 - accuracy: 0.8065 - val_loss: 0.4667 - val_accuracy: 0.8171\n",
      "Epoch 96/1000\n",
      "239/239 [==============================] - 0s 2ms/step - loss: 0.4880 - accuracy: 0.8072 - val_loss: 0.4623 - val_accuracy: 0.8198\n",
      "Epoch 97/1000\n",
      "239/239 [==============================] - 1s 2ms/step - loss: 0.4888 - accuracy: 0.8066 - val_loss: 0.4638 - val_accuracy: 0.8206\n",
      "Epoch 98/1000\n",
      "239/239 [==============================] - 1s 2ms/step - loss: 0.4877 - accuracy: 0.8072 - val_loss: 0.4648 - val_accuracy: 0.8198\n",
      "Epoch 99/1000\n",
      "239/239 [==============================] - 0s 2ms/step - loss: 0.4863 - accuracy: 0.8079 - val_loss: 0.4625 - val_accuracy: 0.8212\n",
      "Epoch 100/1000\n",
      "239/239 [==============================] - 0s 2ms/step - loss: 0.4852 - accuracy: 0.8087 - val_loss: 0.4621 - val_accuracy: 0.8209\n",
      "Epoch 101/1000\n",
      "239/239 [==============================] - 0s 2ms/step - loss: 0.4857 - accuracy: 0.8080 - val_loss: 0.4638 - val_accuracy: 0.8189\n",
      "Epoch 102/1000\n",
      "239/239 [==============================] - 1s 2ms/step - loss: 0.4818 - accuracy: 0.8097 - val_loss: 0.4638 - val_accuracy: 0.8206\n",
      "Epoch 103/1000\n",
      "239/239 [==============================] - 1s 2ms/step - loss: 0.4856 - accuracy: 0.8069 - val_loss: 0.4606 - val_accuracy: 0.8200\n",
      "Epoch 104/1000\n",
      "239/239 [==============================] - 1s 2ms/step - loss: 0.4839 - accuracy: 0.8099 - val_loss: 0.4619 - val_accuracy: 0.8242\n",
      "Epoch 105/1000\n",
      "239/239 [==============================] - 0s 2ms/step - loss: 0.4855 - accuracy: 0.8080 - val_loss: 0.4579 - val_accuracy: 0.8246\n",
      "Epoch 106/1000\n",
      "239/239 [==============================] - 1s 2ms/step - loss: 0.4838 - accuracy: 0.8094 - val_loss: 0.4641 - val_accuracy: 0.8223\n",
      "Epoch 107/1000\n",
      "239/239 [==============================] - 0s 2ms/step - loss: 0.4830 - accuracy: 0.8104 - val_loss: 0.4596 - val_accuracy: 0.8233\n",
      "Epoch 108/1000\n",
      "239/239 [==============================] - 0s 2ms/step - loss: 0.4848 - accuracy: 0.8082 - val_loss: 0.4602 - val_accuracy: 0.8226\n",
      "Epoch 109/1000\n",
      "239/239 [==============================] - 0s 2ms/step - loss: 0.4834 - accuracy: 0.8088 - val_loss: 0.4600 - val_accuracy: 0.8239\n",
      "Epoch 110/1000\n",
      "239/239 [==============================] - 0s 2ms/step - loss: 0.4821 - accuracy: 0.8090 - val_loss: 0.4569 - val_accuracy: 0.8238\n",
      "Epoch 111/1000\n",
      "239/239 [==============================] - 1s 2ms/step - loss: 0.4818 - accuracy: 0.8101 - val_loss: 0.4579 - val_accuracy: 0.8251\n",
      "Epoch 112/1000\n",
      "239/239 [==============================] - 0s 2ms/step - loss: 0.4813 - accuracy: 0.8097 - val_loss: 0.4569 - val_accuracy: 0.8244\n",
      "Epoch 113/1000\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "239/239 [==============================] - 0s 2ms/step - loss: 0.4796 - accuracy: 0.8107 - val_loss: 0.4556 - val_accuracy: 0.8262\n",
      "Epoch 114/1000\n",
      "239/239 [==============================] - 1s 2ms/step - loss: 0.4788 - accuracy: 0.8102 - val_loss: 0.4573 - val_accuracy: 0.8242\n",
      "Epoch 115/1000\n",
      "239/239 [==============================] - 1s 2ms/step - loss: 0.4802 - accuracy: 0.8103 - val_loss: 0.4567 - val_accuracy: 0.8272\n",
      "Epoch 116/1000\n",
      "239/239 [==============================] - 1s 2ms/step - loss: 0.4801 - accuracy: 0.8114 - val_loss: 0.4587 - val_accuracy: 0.8228\n",
      "Epoch 117/1000\n",
      "239/239 [==============================] - 0s 2ms/step - loss: 0.4799 - accuracy: 0.8107 - val_loss: 0.4528 - val_accuracy: 0.8273\n",
      "Epoch 118/1000\n",
      "239/239 [==============================] - 0s 2ms/step - loss: 0.4809 - accuracy: 0.8095 - val_loss: 0.4557 - val_accuracy: 0.8255\n",
      "Epoch 119/1000\n",
      "239/239 [==============================] - 0s 2ms/step - loss: 0.4808 - accuracy: 0.8098 - val_loss: 0.4550 - val_accuracy: 0.8265\n",
      "Epoch 120/1000\n",
      "239/239 [==============================] - 0s 2ms/step - loss: 0.4783 - accuracy: 0.8111 - val_loss: 0.4535 - val_accuracy: 0.8279\n",
      "Epoch 121/1000\n",
      "239/239 [==============================] - 0s 2ms/step - loss: 0.4787 - accuracy: 0.8103 - val_loss: 0.4539 - val_accuracy: 0.8266\n",
      "Epoch 122/1000\n",
      "239/239 [==============================] - 0s 2ms/step - loss: 0.4798 - accuracy: 0.8104 - val_loss: 0.4525 - val_accuracy: 0.8273\n",
      "Epoch 123/1000\n",
      "239/239 [==============================] - 1s 2ms/step - loss: 0.4762 - accuracy: 0.8110 - val_loss: 0.4509 - val_accuracy: 0.8288\n",
      "Epoch 124/1000\n",
      "239/239 [==============================] - 1s 2ms/step - loss: 0.4767 - accuracy: 0.8122 - val_loss: 0.4529 - val_accuracy: 0.8252\n",
      "Epoch 125/1000\n",
      "239/239 [==============================] - 1s 3ms/step - loss: 0.4786 - accuracy: 0.8113 - val_loss: 0.4526 - val_accuracy: 0.8257\n",
      "Epoch 126/1000\n",
      "239/239 [==============================] - 1s 2ms/step - loss: 0.4760 - accuracy: 0.8112 - val_loss: 0.4496 - val_accuracy: 0.8279\n",
      "Epoch 127/1000\n",
      "239/239 [==============================] - 0s 2ms/step - loss: 0.4755 - accuracy: 0.8123 - val_loss: 0.4522 - val_accuracy: 0.8256\n",
      "Epoch 128/1000\n",
      "239/239 [==============================] - 1s 2ms/step - loss: 0.4776 - accuracy: 0.8119 - val_loss: 0.4503 - val_accuracy: 0.8287\n",
      "Epoch 129/1000\n",
      "239/239 [==============================] - 0s 2ms/step - loss: 0.4763 - accuracy: 0.8117 - val_loss: 0.4516 - val_accuracy: 0.8258\n",
      "Epoch 130/1000\n",
      "239/239 [==============================] - 0s 2ms/step - loss: 0.4766 - accuracy: 0.8120 - val_loss: 0.4541 - val_accuracy: 0.8259\n",
      "Epoch 131/1000\n",
      "239/239 [==============================] - 0s 2ms/step - loss: 0.4757 - accuracy: 0.8118 - val_loss: 0.4507 - val_accuracy: 0.8289\n",
      "Epoch 132/1000\n",
      "239/239 [==============================] - 0s 2ms/step - loss: 0.4753 - accuracy: 0.8123 - val_loss: 0.4511 - val_accuracy: 0.8272\n",
      "Epoch 133/1000\n",
      "239/239 [==============================] - 0s 2ms/step - loss: 0.4743 - accuracy: 0.8129 - val_loss: 0.4505 - val_accuracy: 0.8283\n",
      "Epoch 134/1000\n",
      "239/239 [==============================] - 0s 2ms/step - loss: 0.4746 - accuracy: 0.8126 - val_loss: 0.4487 - val_accuracy: 0.8287\n",
      "Epoch 135/1000\n",
      "239/239 [==============================] - 0s 2ms/step - loss: 0.4734 - accuracy: 0.8133 - val_loss: 0.4486 - val_accuracy: 0.8289\n",
      "Epoch 136/1000\n",
      "239/239 [==============================] - 0s 2ms/step - loss: 0.4754 - accuracy: 0.8118 - val_loss: 0.4498 - val_accuracy: 0.8286\n",
      "Epoch 137/1000\n",
      "239/239 [==============================] - 0s 2ms/step - loss: 0.4744 - accuracy: 0.8143 - val_loss: 0.4505 - val_accuracy: 0.8296\n",
      "Epoch 138/1000\n",
      "239/239 [==============================] - 0s 2ms/step - loss: 0.4729 - accuracy: 0.8136 - val_loss: 0.4467 - val_accuracy: 0.8295\n",
      "Epoch 139/1000\n",
      "239/239 [==============================] - 1s 2ms/step - loss: 0.4711 - accuracy: 0.8140 - val_loss: 0.4479 - val_accuracy: 0.8296\n",
      "Epoch 140/1000\n",
      "239/239 [==============================] - 1s 2ms/step - loss: 0.4724 - accuracy: 0.8138 - val_loss: 0.4465 - val_accuracy: 0.8317\n",
      "Epoch 141/1000\n",
      "239/239 [==============================] - 1s 2ms/step - loss: 0.4740 - accuracy: 0.8127 - val_loss: 0.4447 - val_accuracy: 0.8327\n",
      "Epoch 142/1000\n",
      "239/239 [==============================] - 1s 2ms/step - loss: 0.4722 - accuracy: 0.8135 - val_loss: 0.4426 - val_accuracy: 0.8316\n",
      "Epoch 143/1000\n",
      "239/239 [==============================] - 1s 2ms/step - loss: 0.4717 - accuracy: 0.8148 - val_loss: 0.4443 - val_accuracy: 0.8313\n",
      "Epoch 144/1000\n",
      "239/239 [==============================] - 1s 2ms/step - loss: 0.4729 - accuracy: 0.8141 - val_loss: 0.4475 - val_accuracy: 0.8307\n",
      "Epoch 145/1000\n",
      "239/239 [==============================] - 0s 2ms/step - loss: 0.4706 - accuracy: 0.8143 - val_loss: 0.4507 - val_accuracy: 0.8276\n",
      "Epoch 146/1000\n",
      "239/239 [==============================] - 1s 2ms/step - loss: 0.4705 - accuracy: 0.8146 - val_loss: 0.4461 - val_accuracy: 0.8297\n",
      "Epoch 147/1000\n",
      "239/239 [==============================] - 1s 2ms/step - loss: 0.4714 - accuracy: 0.8153 - val_loss: 0.4446 - val_accuracy: 0.8315\n",
      "Epoch 148/1000\n",
      "239/239 [==============================] - 0s 2ms/step - loss: 0.4705 - accuracy: 0.8137 - val_loss: 0.4463 - val_accuracy: 0.8316\n",
      "Epoch 149/1000\n",
      "239/239 [==============================] - 0s 2ms/step - loss: 0.4698 - accuracy: 0.8147 - val_loss: 0.4443 - val_accuracy: 0.8315\n",
      "Epoch 150/1000\n",
      "239/239 [==============================] - 1s 2ms/step - loss: 0.4702 - accuracy: 0.8151 - val_loss: 0.4452 - val_accuracy: 0.8316\n",
      "Epoch 151/1000\n",
      "239/239 [==============================] - 0s 2ms/step - loss: 0.4693 - accuracy: 0.8154 - val_loss: 0.4450 - val_accuracy: 0.8298\n",
      "Epoch 152/1000\n",
      "239/239 [==============================] - 0s 2ms/step - loss: 0.4700 - accuracy: 0.8153 - val_loss: 0.4457 - val_accuracy: 0.8313\n",
      "Epoch 153/1000\n",
      "239/239 [==============================] - 0s 2ms/step - loss: 0.4689 - accuracy: 0.8159 - val_loss: 0.4449 - val_accuracy: 0.8301\n",
      "Epoch 154/1000\n",
      "239/239 [==============================] - 1s 2ms/step - loss: 0.4697 - accuracy: 0.8154 - val_loss: 0.4473 - val_accuracy: 0.8290\n",
      "Epoch 155/1000\n",
      "239/239 [==============================] - 1s 2ms/step - loss: 0.4693 - accuracy: 0.8147 - val_loss: 0.4424 - val_accuracy: 0.8321\n",
      "Epoch 156/1000\n",
      "239/239 [==============================] - 1s 2ms/step - loss: 0.4686 - accuracy: 0.8162 - val_loss: 0.4424 - val_accuracy: 0.8315\n",
      "Epoch 157/1000\n",
      "239/239 [==============================] - 0s 2ms/step - loss: 0.4666 - accuracy: 0.8156 - val_loss: 0.4421 - val_accuracy: 0.8307\n",
      "Epoch 158/1000\n",
      "239/239 [==============================] - 1s 2ms/step - loss: 0.4700 - accuracy: 0.8145 - val_loss: 0.4440 - val_accuracy: 0.8299\n",
      "Epoch 159/1000\n",
      "239/239 [==============================] - 0s 2ms/step - loss: 0.4677 - accuracy: 0.8163 - val_loss: 0.4434 - val_accuracy: 0.8328\n",
      "Epoch 160/1000\n",
      "239/239 [==============================] - 1s 2ms/step - loss: 0.4671 - accuracy: 0.8165 - val_loss: 0.4404 - val_accuracy: 0.8330\n",
      "Epoch 161/1000\n",
      "239/239 [==============================] - 0s 2ms/step - loss: 0.4671 - accuracy: 0.8167 - val_loss: 0.4432 - val_accuracy: 0.8304\n",
      "Epoch 162/1000\n",
      "239/239 [==============================] - 0s 2ms/step - loss: 0.4680 - accuracy: 0.8167 - val_loss: 0.4423 - val_accuracy: 0.8330\n",
      "Epoch 163/1000\n",
      "239/239 [==============================] - 1s 2ms/step - loss: 0.4669 - accuracy: 0.8170 - val_loss: 0.4403 - val_accuracy: 0.8342\n",
      "Epoch 164/1000\n",
      "239/239 [==============================] - 1s 2ms/step - loss: 0.4675 - accuracy: 0.8164 - val_loss: 0.4400 - val_accuracy: 0.8335\n",
      "Epoch 165/1000\n",
      "239/239 [==============================] - 1s 2ms/step - loss: 0.4651 - accuracy: 0.8166 - val_loss: 0.4416 - val_accuracy: 0.8312\n",
      "Epoch 166/1000\n",
      "239/239 [==============================] - 1s 2ms/step - loss: 0.4657 - accuracy: 0.8176 - val_loss: 0.4376 - val_accuracy: 0.8330\n",
      "Epoch 167/1000\n",
      "239/239 [==============================] - 1s 2ms/step - loss: 0.4655 - accuracy: 0.8174 - val_loss: 0.4394 - val_accuracy: 0.8330\n",
      "Epoch 168/1000\n",
      "239/239 [==============================] - 1s 2ms/step - loss: 0.4661 - accuracy: 0.8173 - val_loss: 0.4395 - val_accuracy: 0.8344\n",
      "Epoch 169/1000\n",
      "239/239 [==============================] - 1s 2ms/step - loss: 0.4656 - accuracy: 0.8172 - val_loss: 0.4390 - val_accuracy: 0.8355\n",
      "Epoch 170/1000\n",
      "239/239 [==============================] - 1s 2ms/step - loss: 0.4654 - accuracy: 0.8169 - val_loss: 0.4418 - val_accuracy: 0.8315\n",
      "Epoch 171/1000\n",
      "239/239 [==============================] - 0s 2ms/step - loss: 0.4669 - accuracy: 0.8161 - val_loss: 0.4369 - val_accuracy: 0.8361\n",
      "Epoch 172/1000\n",
      "239/239 [==============================] - 1s 2ms/step - loss: 0.4663 - accuracy: 0.8166 - val_loss: 0.4389 - val_accuracy: 0.8332\n",
      "Epoch 173/1000\n",
      "239/239 [==============================] - 0s 2ms/step - loss: 0.4648 - accuracy: 0.8171 - val_loss: 0.4370 - val_accuracy: 0.8348\n",
      "Epoch 174/1000\n",
      "239/239 [==============================] - 1s 2ms/step - loss: 0.4648 - accuracy: 0.8176 - val_loss: 0.4392 - val_accuracy: 0.8334\n",
      "Epoch 175/1000\n",
      "239/239 [==============================] - 0s 2ms/step - loss: 0.4647 - accuracy: 0.8178 - val_loss: 0.4402 - val_accuracy: 0.8332\n",
      "Epoch 176/1000\n",
      "239/239 [==============================] - 1s 2ms/step - loss: 0.4647 - accuracy: 0.8184 - val_loss: 0.4363 - val_accuracy: 0.8360\n",
      "Epoch 177/1000\n",
      "239/239 [==============================] - 1s 2ms/step - loss: 0.4647 - accuracy: 0.8176 - val_loss: 0.4382 - val_accuracy: 0.8326\n",
      "Epoch 178/1000\n",
      "239/239 [==============================] - 0s 2ms/step - loss: 0.4639 - accuracy: 0.8181 - val_loss: 0.4419 - val_accuracy: 0.8316\n",
      "Epoch 179/1000\n",
      "239/239 [==============================] - 1s 2ms/step - loss: 0.4631 - accuracy: 0.8177 - val_loss: 0.4361 - val_accuracy: 0.8339\n",
      "Epoch 180/1000\n",
      "239/239 [==============================] - 1s 2ms/step - loss: 0.4637 - accuracy: 0.8185 - val_loss: 0.4361 - val_accuracy: 0.8338\n",
      "Epoch 181/1000\n",
      "239/239 [==============================] - 1s 2ms/step - loss: 0.4648 - accuracy: 0.8167 - val_loss: 0.4381 - val_accuracy: 0.8335\n",
      "Epoch 182/1000\n",
      "239/239 [==============================] - 1s 2ms/step - loss: 0.4623 - accuracy: 0.8186 - val_loss: 0.4362 - val_accuracy: 0.8344\n",
      "Epoch 183/1000\n",
      "239/239 [==============================] - 1s 2ms/step - loss: 0.4635 - accuracy: 0.8184 - val_loss: 0.4366 - val_accuracy: 0.8358\n",
      "Epoch 184/1000\n",
      "239/239 [==============================] - 1s 2ms/step - loss: 0.4640 - accuracy: 0.8173 - val_loss: 0.4351 - val_accuracy: 0.8362\n",
      "Epoch 185/1000\n",
      "239/239 [==============================] - 1s 2ms/step - loss: 0.4629 - accuracy: 0.8185 - val_loss: 0.4455 - val_accuracy: 0.8317\n",
      "Epoch 186/1000\n",
      "239/239 [==============================] - 1s 2ms/step - loss: 0.4634 - accuracy: 0.8176 - val_loss: 0.4360 - val_accuracy: 0.8346\n",
      "Epoch 187/1000\n",
      "239/239 [==============================] - 0s 2ms/step - loss: 0.4637 - accuracy: 0.8183 - val_loss: 0.4363 - val_accuracy: 0.8355\n",
      "Epoch 188/1000\n",
      "239/239 [==============================] - 1s 2ms/step - loss: 0.4635 - accuracy: 0.8188 - val_loss: 0.4362 - val_accuracy: 0.8352\n",
      "Epoch 189/1000\n",
      "239/239 [==============================] - 1s 2ms/step - loss: 0.4592 - accuracy: 0.8186 - val_loss: 0.4387 - val_accuracy: 0.8318\n",
      "Epoch 190/1000\n",
      "239/239 [==============================] - 1s 3ms/step - loss: 0.4615 - accuracy: 0.8186 - val_loss: 0.4365 - val_accuracy: 0.8343\n",
      "Epoch 191/1000\n",
      "239/239 [==============================] - 1s 2ms/step - loss: 0.4632 - accuracy: 0.8184 - val_loss: 0.4378 - val_accuracy: 0.8340\n",
      "Epoch 192/1000\n",
      "239/239 [==============================] - 0s 2ms/step - loss: 0.4614 - accuracy: 0.8192 - val_loss: 0.4356 - val_accuracy: 0.8327\n",
      "Epoch 193/1000\n",
      "239/239 [==============================] - 0s 2ms/step - loss: 0.4629 - accuracy: 0.8176 - val_loss: 0.4357 - val_accuracy: 0.8330\n",
      "Epoch 194/1000\n",
      "239/239 [==============================] - 1s 3ms/step - loss: 0.4613 - accuracy: 0.8191 - val_loss: 0.4351 - val_accuracy: 0.8355\n",
      "Epoch 195/1000\n",
      "239/239 [==============================] - 0s 2ms/step - loss: 0.4618 - accuracy: 0.8187 - val_loss: 0.4318 - val_accuracy: 0.8375\n",
      "Epoch 196/1000\n",
      "239/239 [==============================] - 0s 2ms/step - loss: 0.4617 - accuracy: 0.8190 - val_loss: 0.4358 - val_accuracy: 0.8341\n",
      "Epoch 197/1000\n",
      "239/239 [==============================] - 1s 2ms/step - loss: 0.4610 - accuracy: 0.8198 - val_loss: 0.4360 - val_accuracy: 0.8362\n",
      "Epoch 198/1000\n",
      "239/239 [==============================] - 1s 2ms/step - loss: 0.4605 - accuracy: 0.8202 - val_loss: 0.4363 - val_accuracy: 0.8344\n",
      "Epoch 199/1000\n",
      "239/239 [==============================] - 0s 2ms/step - loss: 0.4612 - accuracy: 0.8184 - val_loss: 0.4340 - val_accuracy: 0.8354\n",
      "Epoch 200/1000\n",
      "239/239 [==============================] - 0s 2ms/step - loss: 0.4606 - accuracy: 0.8189 - val_loss: 0.4347 - val_accuracy: 0.8355\n",
      "Epoch 201/1000\n",
      "239/239 [==============================] - 0s 2ms/step - loss: 0.4600 - accuracy: 0.8203 - val_loss: 0.4348 - val_accuracy: 0.8346\n",
      "Epoch 202/1000\n",
      "239/239 [==============================] - 1s 2ms/step - loss: 0.4605 - accuracy: 0.8204 - val_loss: 0.4348 - val_accuracy: 0.8352\n",
      "Epoch 203/1000\n",
      "239/239 [==============================] - 1s 2ms/step - loss: 0.4607 - accuracy: 0.8191 - val_loss: 0.4315 - val_accuracy: 0.8387\n",
      "Epoch 204/1000\n",
      "239/239 [==============================] - 0s 2ms/step - loss: 0.4605 - accuracy: 0.8198 - val_loss: 0.4339 - val_accuracy: 0.8360\n",
      "Epoch 205/1000\n",
      "239/239 [==============================] - 0s 2ms/step - loss: 0.4604 - accuracy: 0.8194 - val_loss: 0.4337 - val_accuracy: 0.8359\n",
      "Epoch 206/1000\n",
      "239/239 [==============================] - 1s 2ms/step - loss: 0.4609 - accuracy: 0.8186 - val_loss: 0.4333 - val_accuracy: 0.8338\n",
      "Epoch 207/1000\n",
      "239/239 [==============================] - 1s 2ms/step - loss: 0.4597 - accuracy: 0.8193 - val_loss: 0.4342 - val_accuracy: 0.8329\n",
      "Epoch 208/1000\n",
      "239/239 [==============================] - 0s 2ms/step - loss: 0.4564 - accuracy: 0.8207 - val_loss: 0.4324 - val_accuracy: 0.8370\n",
      "Epoch 209/1000\n",
      "239/239 [==============================] - 0s 2ms/step - loss: 0.4587 - accuracy: 0.8204 - val_loss: 0.4315 - val_accuracy: 0.8345\n",
      "Epoch 210/1000\n",
      "239/239 [==============================] - 0s 2ms/step - loss: 0.4597 - accuracy: 0.8194 - val_loss: 0.4331 - val_accuracy: 0.8369\n",
      "Epoch 211/1000\n",
      "239/239 [==============================] - 1s 2ms/step - loss: 0.4591 - accuracy: 0.8192 - val_loss: 0.4310 - val_accuracy: 0.8370\n",
      "Epoch 212/1000\n",
      "239/239 [==============================] - 1s 2ms/step - loss: 0.4594 - accuracy: 0.8203 - val_loss: 0.4341 - val_accuracy: 0.8355\n",
      "Epoch 213/1000\n",
      "239/239 [==============================] - 0s 2ms/step - loss: 0.4585 - accuracy: 0.8203 - val_loss: 0.4335 - val_accuracy: 0.8345\n",
      "Epoch 214/1000\n",
      "239/239 [==============================] - 0s 2ms/step - loss: 0.4585 - accuracy: 0.8196 - val_loss: 0.4333 - val_accuracy: 0.8349\n",
      "Epoch 215/1000\n",
      "239/239 [==============================] - 1s 2ms/step - loss: 0.4598 - accuracy: 0.8191 - val_loss: 0.4308 - val_accuracy: 0.8371\n",
      "Epoch 216/1000\n",
      "239/239 [==============================] - 1s 2ms/step - loss: 0.4605 - accuracy: 0.8198 - val_loss: 0.4319 - val_accuracy: 0.8363\n",
      "Epoch 217/1000\n",
      "239/239 [==============================] - 1s 2ms/step - loss: 0.4574 - accuracy: 0.8205 - val_loss: 0.4333 - val_accuracy: 0.8371\n",
      "Epoch 218/1000\n",
      "239/239 [==============================] - 1s 2ms/step - loss: 0.4568 - accuracy: 0.8210 - val_loss: 0.4304 - val_accuracy: 0.8383\n",
      "Epoch 219/1000\n",
      "239/239 [==============================] - 0s 2ms/step - loss: 0.4560 - accuracy: 0.8207 - val_loss: 0.4330 - val_accuracy: 0.8346\n",
      "Epoch 220/1000\n",
      "239/239 [==============================] - 0s 2ms/step - loss: 0.4562 - accuracy: 0.8204 - val_loss: 0.4289 - val_accuracy: 0.8370\n",
      "Epoch 221/1000\n",
      "239/239 [==============================] - 1s 2ms/step - loss: 0.4584 - accuracy: 0.8202 - val_loss: 0.4331 - val_accuracy: 0.8372\n",
      "Epoch 222/1000\n",
      "239/239 [==============================] - 1s 2ms/step - loss: 0.4573 - accuracy: 0.8205 - val_loss: 0.4331 - val_accuracy: 0.8363\n",
      "Epoch 223/1000\n",
      "239/239 [==============================] - 0s 2ms/step - loss: 0.4553 - accuracy: 0.8215 - val_loss: 0.4304 - val_accuracy: 0.8374\n",
      "Epoch 224/1000\n",
      "239/239 [==============================] - 0s 2ms/step - loss: 0.4580 - accuracy: 0.8206 - val_loss: 0.4304 - val_accuracy: 0.8378\n",
      "Epoch 225/1000\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "239/239 [==============================] - 0s 2ms/step - loss: 0.4566 - accuracy: 0.8211 - val_loss: 0.4301 - val_accuracy: 0.8375\n",
      "Epoch 226/1000\n",
      "239/239 [==============================] - 0s 2ms/step - loss: 0.4555 - accuracy: 0.8217 - val_loss: 0.4316 - val_accuracy: 0.8369\n",
      "Epoch 227/1000\n",
      "239/239 [==============================] - 1s 2ms/step - loss: 0.4572 - accuracy: 0.8208 - val_loss: 0.4301 - val_accuracy: 0.8367\n",
      "Epoch 228/1000\n",
      "239/239 [==============================] - 0s 2ms/step - loss: 0.4568 - accuracy: 0.8224 - val_loss: 0.4309 - val_accuracy: 0.8363\n",
      "Epoch 229/1000\n",
      "239/239 [==============================] - 1s 3ms/step - loss: 0.4556 - accuracy: 0.8216 - val_loss: 0.4303 - val_accuracy: 0.8381\n",
      "Epoch 230/1000\n",
      "239/239 [==============================] - 1s 2ms/step - loss: 0.4566 - accuracy: 0.8213 - val_loss: 0.4313 - val_accuracy: 0.8375\n",
      "Epoch 231/1000\n",
      "239/239 [==============================] - 0s 2ms/step - loss: 0.4551 - accuracy: 0.8220 - val_loss: 0.4257 - val_accuracy: 0.8382\n",
      "Epoch 232/1000\n",
      "239/239 [==============================] - 0s 2ms/step - loss: 0.4562 - accuracy: 0.8217 - val_loss: 0.4310 - val_accuracy: 0.8360\n",
      "Epoch 233/1000\n",
      "239/239 [==============================] - 0s 2ms/step - loss: 0.4550 - accuracy: 0.8221 - val_loss: 0.4268 - val_accuracy: 0.8381\n",
      "Epoch 234/1000\n",
      "239/239 [==============================] - 1s 3ms/step - loss: 0.4574 - accuracy: 0.8197 - val_loss: 0.4293 - val_accuracy: 0.8374\n",
      "Epoch 235/1000\n",
      "239/239 [==============================] - 1s 2ms/step - loss: 0.4555 - accuracy: 0.8217 - val_loss: 0.4280 - val_accuracy: 0.8383\n",
      "Epoch 236/1000\n",
      "239/239 [==============================] - 0s 2ms/step - loss: 0.4550 - accuracy: 0.8215 - val_loss: 0.4313 - val_accuracy: 0.8373\n",
      "Epoch 237/1000\n",
      "239/239 [==============================] - 1s 3ms/step - loss: 0.4562 - accuracy: 0.8212 - val_loss: 0.4297 - val_accuracy: 0.8375\n",
      "Epoch 238/1000\n",
      "239/239 [==============================] - 1s 2ms/step - loss: 0.4536 - accuracy: 0.8220 - val_loss: 0.4289 - val_accuracy: 0.8365\n",
      "Epoch 239/1000\n",
      "239/239 [==============================] - 0s 2ms/step - loss: 0.4549 - accuracy: 0.8222 - val_loss: 0.4288 - val_accuracy: 0.8401\n",
      "Epoch 240/1000\n",
      "239/239 [==============================] - 0s 2ms/step - loss: 0.4552 - accuracy: 0.8214 - val_loss: 0.4297 - val_accuracy: 0.8381\n",
      "Epoch 241/1000\n",
      "239/239 [==============================] - 1s 2ms/step - loss: 0.4555 - accuracy: 0.8220 - val_loss: 0.4291 - val_accuracy: 0.8380\n",
      "Epoch 242/1000\n",
      "239/239 [==============================] - 0s 2ms/step - loss: 0.4542 - accuracy: 0.8237 - val_loss: 0.4289 - val_accuracy: 0.8404\n",
      "Epoch 243/1000\n",
      "239/239 [==============================] - 0s 2ms/step - loss: 0.4537 - accuracy: 0.8229 - val_loss: 0.4265 - val_accuracy: 0.8402\n",
      "Epoch 244/1000\n",
      "239/239 [==============================] - 0s 2ms/step - loss: 0.4555 - accuracy: 0.8227 - val_loss: 0.4268 - val_accuracy: 0.8382\n",
      "Epoch 245/1000\n",
      "239/239 [==============================] - 0s 2ms/step - loss: 0.4534 - accuracy: 0.8225 - val_loss: 0.4266 - val_accuracy: 0.8398\n",
      "Epoch 246/1000\n",
      "239/239 [==============================] - 1s 2ms/step - loss: 0.4544 - accuracy: 0.8210 - val_loss: 0.4250 - val_accuracy: 0.8405\n",
      "Epoch 247/1000\n",
      "239/239 [==============================] - 0s 2ms/step - loss: 0.4538 - accuracy: 0.8224 - val_loss: 0.4264 - val_accuracy: 0.8400\n",
      "Epoch 248/1000\n",
      "239/239 [==============================] - 1s 2ms/step - loss: 0.4524 - accuracy: 0.8226 - val_loss: 0.4259 - val_accuracy: 0.8395\n",
      "Epoch 249/1000\n",
      "239/239 [==============================] - 1s 2ms/step - loss: 0.4534 - accuracy: 0.8231 - val_loss: 0.4283 - val_accuracy: 0.8366\n",
      "Epoch 250/1000\n",
      "239/239 [==============================] - 1s 2ms/step - loss: 0.4529 - accuracy: 0.8224 - val_loss: 0.4255 - val_accuracy: 0.8389\n",
      "Epoch 251/1000\n",
      "239/239 [==============================] - 0s 2ms/step - loss: 0.4541 - accuracy: 0.8218 - val_loss: 0.4274 - val_accuracy: 0.8382\n",
      "Epoch 252/1000\n",
      "239/239 [==============================] - 0s 2ms/step - loss: 0.4529 - accuracy: 0.8231 - val_loss: 0.4305 - val_accuracy: 0.8367\n",
      "Epoch 253/1000\n",
      "239/239 [==============================] - 0s 2ms/step - loss: 0.4527 - accuracy: 0.8228 - val_loss: 0.4284 - val_accuracy: 0.8370\n",
      "Epoch 254/1000\n",
      "239/239 [==============================] - 0s 2ms/step - loss: 0.4530 - accuracy: 0.8221 - val_loss: 0.4258 - val_accuracy: 0.8380\n",
      "Epoch 255/1000\n",
      "239/239 [==============================] - 0s 2ms/step - loss: 0.4513 - accuracy: 0.8234 - val_loss: 0.4248 - val_accuracy: 0.8393\n",
      "Epoch 256/1000\n",
      "239/239 [==============================] - 0s 2ms/step - loss: 0.4531 - accuracy: 0.8221 - val_loss: 0.4286 - val_accuracy: 0.8376\n",
      "Epoch 257/1000\n",
      "239/239 [==============================] - 0s 2ms/step - loss: 0.4520 - accuracy: 0.8227 - val_loss: 0.4255 - val_accuracy: 0.8393\n",
      "Epoch 258/1000\n",
      "239/239 [==============================] - 1s 2ms/step - loss: 0.4519 - accuracy: 0.8236 - val_loss: 0.4279 - val_accuracy: 0.8389\n",
      "Epoch 259/1000\n",
      "239/239 [==============================] - 1s 2ms/step - loss: 0.4525 - accuracy: 0.8233 - val_loss: 0.4274 - val_accuracy: 0.8393\n",
      "Epoch 260/1000\n",
      "239/239 [==============================] - 1s 3ms/step - loss: 0.4522 - accuracy: 0.8233 - val_loss: 0.4268 - val_accuracy: 0.8394\n",
      "Epoch 261/1000\n",
      "239/239 [==============================] - 1s 3ms/step - loss: 0.4506 - accuracy: 0.8241 - val_loss: 0.4269 - val_accuracy: 0.8376\n",
      "Epoch 262/1000\n",
      "239/239 [==============================] - 1s 2ms/step - loss: 0.4529 - accuracy: 0.8231 - val_loss: 0.4326 - val_accuracy: 0.8361\n",
      "Epoch 263/1000\n",
      "239/239 [==============================] - 1s 2ms/step - loss: 0.4515 - accuracy: 0.8232 - val_loss: 0.4267 - val_accuracy: 0.8384\n",
      "Epoch 264/1000\n",
      "239/239 [==============================] - 0s 2ms/step - loss: 0.4533 - accuracy: 0.8233 - val_loss: 0.4256 - val_accuracy: 0.8387\n",
      "Epoch 265/1000\n",
      "239/239 [==============================] - 0s 2ms/step - loss: 0.4505 - accuracy: 0.8233 - val_loss: 0.4260 - val_accuracy: 0.8390\n",
      "Epoch 266/1000\n",
      "239/239 [==============================] - 1s 2ms/step - loss: 0.4512 - accuracy: 0.8232 - val_loss: 0.4246 - val_accuracy: 0.8392\n",
      "Epoch 267/1000\n",
      "239/239 [==============================] - 1s 2ms/step - loss: 0.4512 - accuracy: 0.8236 - val_loss: 0.4269 - val_accuracy: 0.8389\n",
      "Epoch 268/1000\n",
      "239/239 [==============================] - 0s 2ms/step - loss: 0.4515 - accuracy: 0.8237 - val_loss: 0.4240 - val_accuracy: 0.8406\n",
      "Epoch 269/1000\n",
      "239/239 [==============================] - 0s 2ms/step - loss: 0.4521 - accuracy: 0.8235 - val_loss: 0.4286 - val_accuracy: 0.8389\n",
      "Epoch 270/1000\n",
      "239/239 [==============================] - 1s 3ms/step - loss: 0.4519 - accuracy: 0.8233 - val_loss: 0.4243 - val_accuracy: 0.8389\n",
      "Epoch 271/1000\n",
      "239/239 [==============================] - 1s 2ms/step - loss: 0.4515 - accuracy: 0.8236 - val_loss: 0.4263 - val_accuracy: 0.8389\n",
      "Epoch 272/1000\n",
      "239/239 [==============================] - 0s 2ms/step - loss: 0.4514 - accuracy: 0.8240 - val_loss: 0.4257 - val_accuracy: 0.8390\n",
      "Epoch 273/1000\n",
      "239/239 [==============================] - 0s 2ms/step - loss: 0.4512 - accuracy: 0.8230 - val_loss: 0.4216 - val_accuracy: 0.8393\n",
      "Epoch 274/1000\n",
      "239/239 [==============================] - 0s 2ms/step - loss: 0.4512 - accuracy: 0.8231 - val_loss: 0.4264 - val_accuracy: 0.8380\n",
      "Epoch 275/1000\n",
      "239/239 [==============================] - 1s 2ms/step - loss: 0.4513 - accuracy: 0.8225 - val_loss: 0.4239 - val_accuracy: 0.8410\n",
      "Epoch 276/1000\n",
      "239/239 [==============================] - 1s 2ms/step - loss: 0.4512 - accuracy: 0.8233 - val_loss: 0.4235 - val_accuracy: 0.8406\n",
      "Epoch 277/1000\n",
      "239/239 [==============================] - 1s 2ms/step - loss: 0.4491 - accuracy: 0.8236 - val_loss: 0.4245 - val_accuracy: 0.8402\n",
      "Epoch 278/1000\n",
      "239/239 [==============================] - 1s 2ms/step - loss: 0.4501 - accuracy: 0.8247 - val_loss: 0.4217 - val_accuracy: 0.8425\n",
      "Epoch 279/1000\n",
      "239/239 [==============================] - 1s 2ms/step - loss: 0.4486 - accuracy: 0.8245 - val_loss: 0.4237 - val_accuracy: 0.8392\n",
      "Epoch 280/1000\n",
      "239/239 [==============================] - 0s 2ms/step - loss: 0.4496 - accuracy: 0.8243 - val_loss: 0.4257 - val_accuracy: 0.8382\n",
      "Epoch 281/1000\n",
      "239/239 [==============================] - 0s 2ms/step - loss: 0.4488 - accuracy: 0.8245 - val_loss: 0.4237 - val_accuracy: 0.8409\n",
      "Epoch 282/1000\n",
      "239/239 [==============================] - 0s 2ms/step - loss: 0.4488 - accuracy: 0.8242 - val_loss: 0.4256 - val_accuracy: 0.8396\n",
      "Epoch 283/1000\n",
      "239/239 [==============================] - 0s 2ms/step - loss: 0.4496 - accuracy: 0.8239 - val_loss: 0.4232 - val_accuracy: 0.8400\n",
      "Epoch 284/1000\n",
      "239/239 [==============================] - 1s 2ms/step - loss: 0.4502 - accuracy: 0.8248 - val_loss: 0.4245 - val_accuracy: 0.8400\n",
      "Epoch 285/1000\n",
      "239/239 [==============================] - 1s 2ms/step - loss: 0.4491 - accuracy: 0.8251 - val_loss: 0.4270 - val_accuracy: 0.8379\n",
      "Epoch 286/1000\n",
      "239/239 [==============================] - 0s 2ms/step - loss: 0.4495 - accuracy: 0.8248 - val_loss: 0.4256 - val_accuracy: 0.8394\n",
      "Epoch 287/1000\n",
      "239/239 [==============================] - 0s 2ms/step - loss: 0.4492 - accuracy: 0.8241 - val_loss: 0.4251 - val_accuracy: 0.8397\n",
      "Epoch 288/1000\n",
      "239/239 [==============================] - 1s 2ms/step - loss: 0.4477 - accuracy: 0.8254 - val_loss: 0.4257 - val_accuracy: 0.8403\n",
      "Epoch 289/1000\n",
      "239/239 [==============================] - 0s 2ms/step - loss: 0.4505 - accuracy: 0.8237 - val_loss: 0.4243 - val_accuracy: 0.8406\n",
      "Epoch 290/1000\n",
      "239/239 [==============================] - 0s 2ms/step - loss: 0.4496 - accuracy: 0.8234 - val_loss: 0.4252 - val_accuracy: 0.8389\n",
      "Epoch 291/1000\n",
      "239/239 [==============================] - 1s 2ms/step - loss: 0.4484 - accuracy: 0.8257 - val_loss: 0.4260 - val_accuracy: 0.8403\n",
      "Epoch 292/1000\n",
      "239/239 [==============================] - 1s 2ms/step - loss: 0.4495 - accuracy: 0.8250 - val_loss: 0.4256 - val_accuracy: 0.8378\n",
      "Epoch 293/1000\n",
      "239/239 [==============================] - 1s 2ms/step - loss: 0.4509 - accuracy: 0.8232 - val_loss: 0.4234 - val_accuracy: 0.8394\n",
      "Epoch 294/1000\n",
      "239/239 [==============================] - 1s 2ms/step - loss: 0.4489 - accuracy: 0.8246 - val_loss: 0.4241 - val_accuracy: 0.8400\n",
      "Epoch 295/1000\n",
      "239/239 [==============================] - 0s 2ms/step - loss: 0.4489 - accuracy: 0.8255 - val_loss: 0.4232 - val_accuracy: 0.8405\n",
      "Epoch 296/1000\n",
      "239/239 [==============================] - 0s 2ms/step - loss: 0.4497 - accuracy: 0.8243 - val_loss: 0.4214 - val_accuracy: 0.8397\n",
      "Epoch 297/1000\n",
      "239/239 [==============================] - 1s 2ms/step - loss: 0.4493 - accuracy: 0.8248 - val_loss: 0.4219 - val_accuracy: 0.8404\n",
      "Epoch 298/1000\n",
      "239/239 [==============================] - 0s 2ms/step - loss: 0.4478 - accuracy: 0.8255 - val_loss: 0.4240 - val_accuracy: 0.8414\n",
      "Epoch 299/1000\n",
      "239/239 [==============================] - 1s 2ms/step - loss: 0.4471 - accuracy: 0.8252 - val_loss: 0.4196 - val_accuracy: 0.8418\n",
      "Epoch 300/1000\n",
      "239/239 [==============================] - 1s 2ms/step - loss: 0.4467 - accuracy: 0.8254 - val_loss: 0.4184 - val_accuracy: 0.8429\n",
      "Epoch 301/1000\n",
      "239/239 [==============================] - 1s 2ms/step - loss: 0.4478 - accuracy: 0.8249 - val_loss: 0.4238 - val_accuracy: 0.8408\n",
      "Epoch 302/1000\n",
      "239/239 [==============================] - 1s 2ms/step - loss: 0.4491 - accuracy: 0.8258 - val_loss: 0.4237 - val_accuracy: 0.8394\n",
      "Epoch 303/1000\n",
      "239/239 [==============================] - 0s 2ms/step - loss: 0.4477 - accuracy: 0.8254 - val_loss: 0.4244 - val_accuracy: 0.8398\n",
      "Epoch 304/1000\n",
      "239/239 [==============================] - 0s 2ms/step - loss: 0.4492 - accuracy: 0.8243 - val_loss: 0.4234 - val_accuracy: 0.8406\n",
      "Epoch 305/1000\n",
      "239/239 [==============================] - 1s 2ms/step - loss: 0.4469 - accuracy: 0.8252 - val_loss: 0.4234 - val_accuracy: 0.8396\n",
      "Epoch 306/1000\n",
      "239/239 [==============================] - 1s 2ms/step - loss: 0.4470 - accuracy: 0.8259 - val_loss: 0.4226 - val_accuracy: 0.8411\n",
      "Epoch 307/1000\n",
      "239/239 [==============================] - 1s 3ms/step - loss: 0.4476 - accuracy: 0.8248 - val_loss: 0.4220 - val_accuracy: 0.8396\n",
      "Epoch 308/1000\n",
      "239/239 [==============================] - 1s 2ms/step - loss: 0.4469 - accuracy: 0.8259 - val_loss: 0.4232 - val_accuracy: 0.8392\n",
      "Epoch 309/1000\n",
      "239/239 [==============================] - 1s 2ms/step - loss: 0.4451 - accuracy: 0.8278 - val_loss: 0.4213 - val_accuracy: 0.8425\n",
      "Epoch 310/1000\n",
      "239/239 [==============================] - 1s 2ms/step - loss: 0.4474 - accuracy: 0.8256 - val_loss: 0.4260 - val_accuracy: 0.8400\n",
      "Epoch 311/1000\n",
      "239/239 [==============================] - 1s 2ms/step - loss: 0.4458 - accuracy: 0.8255 - val_loss: 0.4222 - val_accuracy: 0.8409\n",
      "Epoch 312/1000\n",
      "239/239 [==============================] - 0s 2ms/step - loss: 0.4464 - accuracy: 0.8252 - val_loss: 0.4261 - val_accuracy: 0.8390\n",
      "Epoch 313/1000\n",
      "239/239 [==============================] - 0s 2ms/step - loss: 0.4470 - accuracy: 0.8258 - val_loss: 0.4247 - val_accuracy: 0.8406\n",
      "Epoch 314/1000\n",
      "239/239 [==============================] - 1s 3ms/step - loss: 0.4470 - accuracy: 0.8258 - val_loss: 0.4224 - val_accuracy: 0.8385\n",
      "Epoch 315/1000\n",
      "239/239 [==============================] - 1s 2ms/step - loss: 0.4453 - accuracy: 0.8265 - val_loss: 0.4234 - val_accuracy: 0.8397\n",
      "Epoch 316/1000\n",
      "239/239 [==============================] - 1s 2ms/step - loss: 0.4465 - accuracy: 0.8253 - val_loss: 0.4233 - val_accuracy: 0.8392\n",
      "Epoch 317/1000\n",
      "239/239 [==============================] - 0s 2ms/step - loss: 0.4453 - accuracy: 0.8266 - val_loss: 0.4194 - val_accuracy: 0.8411\n",
      "Epoch 318/1000\n",
      "239/239 [==============================] - 0s 2ms/step - loss: 0.4472 - accuracy: 0.8261 - val_loss: 0.4217 - val_accuracy: 0.8397\n",
      "Epoch 319/1000\n",
      "239/239 [==============================] - 0s 2ms/step - loss: 0.4462 - accuracy: 0.8259 - val_loss: 0.4213 - val_accuracy: 0.8403\n",
      "Epoch 320/1000\n",
      "239/239 [==============================] - 1s 2ms/step - loss: 0.4459 - accuracy: 0.8258 - val_loss: 0.4196 - val_accuracy: 0.8421\n",
      "Epoch 321/1000\n",
      "239/239 [==============================] - 0s 2ms/step - loss: 0.4475 - accuracy: 0.8256 - val_loss: 0.4195 - val_accuracy: 0.8430\n",
      "Epoch 322/1000\n",
      "239/239 [==============================] - 1s 2ms/step - loss: 0.4447 - accuracy: 0.8266 - val_loss: 0.4192 - val_accuracy: 0.8414\n",
      "Epoch 323/1000\n",
      "239/239 [==============================] - 1s 2ms/step - loss: 0.4453 - accuracy: 0.8266 - val_loss: 0.4175 - val_accuracy: 0.8422\n",
      "Epoch 324/1000\n",
      "239/239 [==============================] - 1s 2ms/step - loss: 0.4462 - accuracy: 0.8259 - val_loss: 0.4178 - val_accuracy: 0.8430\n",
      "Epoch 325/1000\n",
      "239/239 [==============================] - 1s 2ms/step - loss: 0.4468 - accuracy: 0.8265 - val_loss: 0.4237 - val_accuracy: 0.8390\n",
      "Epoch 326/1000\n",
      "239/239 [==============================] - 0s 2ms/step - loss: 0.4440 - accuracy: 0.8261 - val_loss: 0.4229 - val_accuracy: 0.8406\n",
      "Epoch 327/1000\n",
      "239/239 [==============================] - 1s 2ms/step - loss: 0.4429 - accuracy: 0.8275 - val_loss: 0.4219 - val_accuracy: 0.8408\n",
      "Epoch 328/1000\n",
      "239/239 [==============================] - 1s 2ms/step - loss: 0.4460 - accuracy: 0.8260 - val_loss: 0.4182 - val_accuracy: 0.8424\n",
      "Epoch 329/1000\n",
      "239/239 [==============================] - 1s 2ms/step - loss: 0.4476 - accuracy: 0.8250 - val_loss: 0.4208 - val_accuracy: 0.8418\n",
      "Epoch 330/1000\n",
      "239/239 [==============================] - 1s 3ms/step - loss: 0.4463 - accuracy: 0.8252 - val_loss: 0.4196 - val_accuracy: 0.8426\n",
      "Epoch 331/1000\n",
      "239/239 [==============================] - 1s 3ms/step - loss: 0.4438 - accuracy: 0.8269 - val_loss: 0.4221 - val_accuracy: 0.8422\n",
      "Epoch 332/1000\n",
      "239/239 [==============================] - 1s 2ms/step - loss: 0.4446 - accuracy: 0.8266 - val_loss: 0.4185 - val_accuracy: 0.8431\n",
      "Epoch 333/1000\n",
      "239/239 [==============================] - 1s 2ms/step - loss: 0.4444 - accuracy: 0.8264 - val_loss: 0.4214 - val_accuracy: 0.8431\n",
      "Epoch 334/1000\n",
      "239/239 [==============================] - 1s 2ms/step - loss: 0.4473 - accuracy: 0.8244 - val_loss: 0.4187 - val_accuracy: 0.8428\n",
      "Epoch 335/1000\n",
      "239/239 [==============================] - 0s 2ms/step - loss: 0.4482 - accuracy: 0.8247 - val_loss: 0.4227 - val_accuracy: 0.8403\n",
      "Epoch 336/1000\n",
      "239/239 [==============================] - 0s 2ms/step - loss: 0.4453 - accuracy: 0.8264 - val_loss: 0.4203 - val_accuracy: 0.8434\n",
      "Epoch 337/1000\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "239/239 [==============================] - 0s 2ms/step - loss: 0.4443 - accuracy: 0.8272 - val_loss: 0.4202 - val_accuracy: 0.8415\n",
      "Epoch 338/1000\n",
      "239/239 [==============================] - 0s 2ms/step - loss: 0.4447 - accuracy: 0.8269 - val_loss: 0.4193 - val_accuracy: 0.8434\n",
      "Epoch 339/1000\n",
      "239/239 [==============================] - 1s 2ms/step - loss: 0.4465 - accuracy: 0.8261 - val_loss: 0.4208 - val_accuracy: 0.8418\n",
      "Epoch 340/1000\n",
      "239/239 [==============================] - 0s 2ms/step - loss: 0.4443 - accuracy: 0.8274 - val_loss: 0.4199 - val_accuracy: 0.8422\n",
      "Epoch 341/1000\n",
      "239/239 [==============================] - 1s 2ms/step - loss: 0.4453 - accuracy: 0.8272 - val_loss: 0.4206 - val_accuracy: 0.8438\n",
      "Epoch 342/1000\n",
      "239/239 [==============================] - 1s 2ms/step - loss: 0.4463 - accuracy: 0.8251 - val_loss: 0.4209 - val_accuracy: 0.8436\n",
      "Epoch 343/1000\n",
      "239/239 [==============================] - 1s 2ms/step - loss: 0.4433 - accuracy: 0.8267 - val_loss: 0.4198 - val_accuracy: 0.8426\n",
      "Epoch 344/1000\n",
      "239/239 [==============================] - 1s 2ms/step - loss: 0.4452 - accuracy: 0.8261 - val_loss: 0.4193 - val_accuracy: 0.8419\n",
      "Epoch 345/1000\n",
      "239/239 [==============================] - 0s 2ms/step - loss: 0.4450 - accuracy: 0.8257 - val_loss: 0.4181 - val_accuracy: 0.8435\n",
      "Epoch 346/1000\n",
      "239/239 [==============================] - 1s 2ms/step - loss: 0.4455 - accuracy: 0.8256 - val_loss: 0.4192 - val_accuracy: 0.8439\n",
      "Epoch 347/1000\n",
      "239/239 [==============================] - 1s 2ms/step - loss: 0.4453 - accuracy: 0.8260 - val_loss: 0.4213 - val_accuracy: 0.8413\n",
      "Epoch 348/1000\n",
      "239/239 [==============================] - 1s 2ms/step - loss: 0.4440 - accuracy: 0.8272 - val_loss: 0.4205 - val_accuracy: 0.8441\n",
      "Epoch 349/1000\n",
      "239/239 [==============================] - 1s 2ms/step - loss: 0.4440 - accuracy: 0.8263 - val_loss: 0.4203 - val_accuracy: 0.8421\n",
      "Epoch 350/1000\n",
      "239/239 [==============================] - 1s 2ms/step - loss: 0.4440 - accuracy: 0.8273 - val_loss: 0.4226 - val_accuracy: 0.8400\n",
      "Epoch 351/1000\n",
      "239/239 [==============================] - 0s 2ms/step - loss: 0.4449 - accuracy: 0.8269 - val_loss: 0.4161 - val_accuracy: 0.8437\n",
      "Epoch 352/1000\n",
      "239/239 [==============================] - 1s 2ms/step - loss: 0.4440 - accuracy: 0.8264 - val_loss: 0.4180 - val_accuracy: 0.8414\n",
      "Epoch 353/1000\n",
      "239/239 [==============================] - 1s 2ms/step - loss: 0.4438 - accuracy: 0.8270 - val_loss: 0.4217 - val_accuracy: 0.8422\n",
      "Epoch 354/1000\n",
      "239/239 [==============================] - 0s 2ms/step - loss: 0.4463 - accuracy: 0.8264 - val_loss: 0.4221 - val_accuracy: 0.8414\n",
      "Epoch 355/1000\n",
      "239/239 [==============================] - 0s 2ms/step - loss: 0.4431 - accuracy: 0.8280 - val_loss: 0.4191 - val_accuracy: 0.8423\n",
      "Epoch 356/1000\n",
      "239/239 [==============================] - 0s 2ms/step - loss: 0.4434 - accuracy: 0.8267 - val_loss: 0.4190 - val_accuracy: 0.8421\n",
      "Epoch 357/1000\n",
      "239/239 [==============================] - 0s 2ms/step - loss: 0.4438 - accuracy: 0.8270 - val_loss: 0.4184 - val_accuracy: 0.8426\n",
      "Epoch 358/1000\n",
      "239/239 [==============================] - 0s 2ms/step - loss: 0.4434 - accuracy: 0.8280 - val_loss: 0.4167 - val_accuracy: 0.8439\n",
      "Epoch 359/1000\n",
      "239/239 [==============================] - 0s 2ms/step - loss: 0.4439 - accuracy: 0.8265 - val_loss: 0.4171 - val_accuracy: 0.8414\n",
      "Epoch 360/1000\n",
      "239/239 [==============================] - 0s 2ms/step - loss: 0.4449 - accuracy: 0.8264 - val_loss: 0.4175 - val_accuracy: 0.8418\n",
      "Epoch 361/1000\n",
      "239/239 [==============================] - 1s 2ms/step - loss: 0.4450 - accuracy: 0.8261 - val_loss: 0.4180 - val_accuracy: 0.8420\n",
      "Epoch 362/1000\n",
      "239/239 [==============================] - 1s 2ms/step - loss: 0.4430 - accuracy: 0.8265 - val_loss: 0.4164 - val_accuracy: 0.8429\n",
      "Epoch 363/1000\n",
      "239/239 [==============================] - 1s 2ms/step - loss: 0.4420 - accuracy: 0.8270 - val_loss: 0.4165 - val_accuracy: 0.8431\n",
      "Epoch 364/1000\n",
      "239/239 [==============================] - 0s 2ms/step - loss: 0.4418 - accuracy: 0.8274 - val_loss: 0.4179 - val_accuracy: 0.8412\n",
      "Epoch 365/1000\n",
      "239/239 [==============================] - 1s 2ms/step - loss: 0.4435 - accuracy: 0.8268 - val_loss: 0.4178 - val_accuracy: 0.8445\n",
      "Epoch 366/1000\n",
      "239/239 [==============================] - 1s 2ms/step - loss: 0.4436 - accuracy: 0.8265 - val_loss: 0.4191 - val_accuracy: 0.8428\n",
      "Epoch 367/1000\n",
      "239/239 [==============================] - 0s 2ms/step - loss: 0.4437 - accuracy: 0.8273 - val_loss: 0.4202 - val_accuracy: 0.8410\n",
      "Epoch 368/1000\n",
      "239/239 [==============================] - 0s 2ms/step - loss: 0.4430 - accuracy: 0.8273 - val_loss: 0.4182 - val_accuracy: 0.8434\n",
      "Epoch 369/1000\n",
      "239/239 [==============================] - 0s 2ms/step - loss: 0.4429 - accuracy: 0.8275 - val_loss: 0.4235 - val_accuracy: 0.8405\n",
      "Epoch 370/1000\n",
      "239/239 [==============================] - 0s 2ms/step - loss: 0.4443 - accuracy: 0.8267 - val_loss: 0.4176 - val_accuracy: 0.8421\n",
      "Epoch 371/1000\n",
      "239/239 [==============================] - 1s 2ms/step - loss: 0.4430 - accuracy: 0.8267 - val_loss: 0.4162 - val_accuracy: 0.8439\n",
      "Epoch 372/1000\n",
      "239/239 [==============================] - 1s 2ms/step - loss: 0.4429 - accuracy: 0.8270 - val_loss: 0.4165 - val_accuracy: 0.8425\n",
      "Epoch 373/1000\n",
      "239/239 [==============================] - 1s 2ms/step - loss: 0.4418 - accuracy: 0.8273 - val_loss: 0.4160 - val_accuracy: 0.8440\n",
      "Epoch 374/1000\n",
      "239/239 [==============================] - 1s 2ms/step - loss: 0.4416 - accuracy: 0.8279 - val_loss: 0.4167 - val_accuracy: 0.8454\n",
      "Epoch 375/1000\n",
      "239/239 [==============================] - 1s 2ms/step - loss: 0.4415 - accuracy: 0.8283 - val_loss: 0.4185 - val_accuracy: 0.8435\n",
      "Epoch 376/1000\n",
      "239/239 [==============================] - 1s 2ms/step - loss: 0.4433 - accuracy: 0.8276 - val_loss: 0.4169 - val_accuracy: 0.8431\n",
      "Epoch 377/1000\n",
      "239/239 [==============================] - 1s 2ms/step - loss: 0.4415 - accuracy: 0.8271 - val_loss: 0.4164 - val_accuracy: 0.8440\n",
      "Epoch 378/1000\n",
      "239/239 [==============================] - 1s 3ms/step - loss: 0.4409 - accuracy: 0.8276 - val_loss: 0.4239 - val_accuracy: 0.8387\n",
      "Epoch 379/1000\n",
      "239/239 [==============================] - 1s 3ms/step - loss: 0.4395 - accuracy: 0.8293 - val_loss: 0.4165 - val_accuracy: 0.8415\n",
      "Epoch 380/1000\n",
      "239/239 [==============================] - 0s 2ms/step - loss: 0.4408 - accuracy: 0.8283 - val_loss: 0.4199 - val_accuracy: 0.8431\n",
      "Epoch 381/1000\n",
      "239/239 [==============================] - 0s 2ms/step - loss: 0.4408 - accuracy: 0.8287 - val_loss: 0.4182 - val_accuracy: 0.8411\n",
      "Epoch 382/1000\n",
      "239/239 [==============================] - 0s 2ms/step - loss: 0.4409 - accuracy: 0.8283 - val_loss: 0.4174 - val_accuracy: 0.8425\n",
      "Epoch 383/1000\n",
      "239/239 [==============================] - 1s 2ms/step - loss: 0.4431 - accuracy: 0.8278 - val_loss: 0.4164 - val_accuracy: 0.8429\n",
      "Epoch 384/1000\n",
      "239/239 [==============================] - 1s 2ms/step - loss: 0.4413 - accuracy: 0.8285 - val_loss: 0.4160 - val_accuracy: 0.8445\n",
      "Epoch 385/1000\n",
      "239/239 [==============================] - 1s 2ms/step - loss: 0.4398 - accuracy: 0.8285 - val_loss: 0.4148 - val_accuracy: 0.8456\n",
      "Epoch 386/1000\n",
      "239/239 [==============================] - 0s 2ms/step - loss: 0.4411 - accuracy: 0.8284 - val_loss: 0.4192 - val_accuracy: 0.8425\n",
      "Epoch 387/1000\n",
      "239/239 [==============================] - 1s 2ms/step - loss: 0.4421 - accuracy: 0.8282 - val_loss: 0.4191 - val_accuracy: 0.8422\n",
      "Epoch 388/1000\n",
      "239/239 [==============================] - 1s 2ms/step - loss: 0.4420 - accuracy: 0.8272 - val_loss: 0.4167 - val_accuracy: 0.8432\n",
      "Epoch 389/1000\n",
      "239/239 [==============================] - 0s 2ms/step - loss: 0.4420 - accuracy: 0.8284 - val_loss: 0.4164 - val_accuracy: 0.8426\n",
      "Epoch 390/1000\n",
      "239/239 [==============================] - 0s 2ms/step - loss: 0.4409 - accuracy: 0.8278 - val_loss: 0.4153 - val_accuracy: 0.8437\n",
      "Epoch 391/1000\n",
      "239/239 [==============================] - 0s 2ms/step - loss: 0.4426 - accuracy: 0.8269 - val_loss: 0.4162 - val_accuracy: 0.8451\n",
      "Epoch 392/1000\n",
      "239/239 [==============================] - 0s 2ms/step - loss: 0.4406 - accuracy: 0.8284 - val_loss: 0.4149 - val_accuracy: 0.8431\n",
      "Epoch 393/1000\n",
      "239/239 [==============================] - 0s 2ms/step - loss: 0.4406 - accuracy: 0.8282 - val_loss: 0.4174 - val_accuracy: 0.8445\n",
      "Epoch 394/1000\n",
      "239/239 [==============================] - 1s 2ms/step - loss: 0.4411 - accuracy: 0.8279 - val_loss: 0.4178 - val_accuracy: 0.8428\n",
      "Epoch 395/1000\n",
      "239/239 [==============================] - 0s 2ms/step - loss: 0.4418 - accuracy: 0.8272 - val_loss: 0.4187 - val_accuracy: 0.8431\n",
      "Epoch 396/1000\n",
      "239/239 [==============================] - 1s 2ms/step - loss: 0.4408 - accuracy: 0.8284 - val_loss: 0.4167 - val_accuracy: 0.8451\n",
      "Epoch 397/1000\n",
      "239/239 [==============================] - 1s 2ms/step - loss: 0.4402 - accuracy: 0.8289 - val_loss: 0.4178 - val_accuracy: 0.8428\n",
      "Epoch 398/1000\n",
      "239/239 [==============================] - 0s 2ms/step - loss: 0.4403 - accuracy: 0.8278 - val_loss: 0.4174 - val_accuracy: 0.8440\n",
      "Epoch 399/1000\n",
      "239/239 [==============================] - 0s 2ms/step - loss: 0.4427 - accuracy: 0.8284 - val_loss: 0.4170 - val_accuracy: 0.8434\n",
      "Epoch 400/1000\n",
      "239/239 [==============================] - 0s 2ms/step - loss: 0.4409 - accuracy: 0.8277 - val_loss: 0.4172 - val_accuracy: 0.8445\n",
      "Epoch 401/1000\n",
      "239/239 [==============================] - 0s 2ms/step - loss: 0.4411 - accuracy: 0.8281 - val_loss: 0.4162 - val_accuracy: 0.8436\n",
      "Epoch 402/1000\n",
      "239/239 [==============================] - 0s 2ms/step - loss: 0.4403 - accuracy: 0.8286 - val_loss: 0.4159 - val_accuracy: 0.8434\n",
      "Epoch 403/1000\n",
      "239/239 [==============================] - 0s 2ms/step - loss: 0.4409 - accuracy: 0.8289 - val_loss: 0.4168 - val_accuracy: 0.8452\n",
      "Epoch 404/1000\n",
      "239/239 [==============================] - 0s 2ms/step - loss: 0.4414 - accuracy: 0.8278 - val_loss: 0.4195 - val_accuracy: 0.8428\n",
      "Epoch 405/1000\n",
      "239/239 [==============================] - 0s 2ms/step - loss: 0.4387 - accuracy: 0.8281 - val_loss: 0.4167 - val_accuracy: 0.8421\n",
      "Epoch 406/1000\n",
      "239/239 [==============================] - 0s 2ms/step - loss: 0.4403 - accuracy: 0.8282 - val_loss: 0.4174 - val_accuracy: 0.8436\n",
      "Epoch 407/1000\n",
      "239/239 [==============================] - 0s 2ms/step - loss: 0.4407 - accuracy: 0.8279 - val_loss: 0.4177 - val_accuracy: 0.8432\n",
      "Epoch 408/1000\n",
      "239/239 [==============================] - 0s 2ms/step - loss: 0.4392 - accuracy: 0.8288 - val_loss: 0.4181 - val_accuracy: 0.8440\n",
      "Epoch 409/1000\n",
      "239/239 [==============================] - 0s 2ms/step - loss: 0.4395 - accuracy: 0.8292 - val_loss: 0.4187 - val_accuracy: 0.8420\n",
      "Epoch 410/1000\n",
      "239/239 [==============================] - 1s 2ms/step - loss: 0.4380 - accuracy: 0.8293 - val_loss: 0.4178 - val_accuracy: 0.8425\n",
      "Epoch 411/1000\n",
      "239/239 [==============================] - 1s 2ms/step - loss: 0.4395 - accuracy: 0.8278 - val_loss: 0.4158 - val_accuracy: 0.8443\n",
      "Epoch 412/1000\n",
      "239/239 [==============================] - 0s 2ms/step - loss: 0.4403 - accuracy: 0.8278 - val_loss: 0.4195 - val_accuracy: 0.8422\n",
      "Epoch 413/1000\n",
      "239/239 [==============================] - 0s 2ms/step - loss: 0.4411 - accuracy: 0.8282 - val_loss: 0.4171 - val_accuracy: 0.8420\n",
      "Epoch 414/1000\n",
      "239/239 [==============================] - 1s 2ms/step - loss: 0.4387 - accuracy: 0.8290 - val_loss: 0.4141 - val_accuracy: 0.8449\n",
      "Epoch 415/1000\n",
      "239/239 [==============================] - 1s 3ms/step - loss: 0.4396 - accuracy: 0.8286 - val_loss: 0.4114 - val_accuracy: 0.8467\n",
      "Epoch 416/1000\n",
      "239/239 [==============================] - 1s 2ms/step - loss: 0.4395 - accuracy: 0.8293 - val_loss: 0.4163 - val_accuracy: 0.8431\n",
      "Epoch 417/1000\n",
      "239/239 [==============================] - 1s 2ms/step - loss: 0.4408 - accuracy: 0.8280 - val_loss: 0.4146 - val_accuracy: 0.8439\n",
      "Epoch 418/1000\n",
      "239/239 [==============================] - 0s 2ms/step - loss: 0.4379 - accuracy: 0.8290 - val_loss: 0.4134 - val_accuracy: 0.8462\n",
      "Epoch 419/1000\n",
      "239/239 [==============================] - 1s 2ms/step - loss: 0.4399 - accuracy: 0.8279 - val_loss: 0.4128 - val_accuracy: 0.8456\n",
      "Epoch 420/1000\n",
      "239/239 [==============================] - 0s 2ms/step - loss: 0.4389 - accuracy: 0.8289 - val_loss: 0.4166 - val_accuracy: 0.8412\n",
      "Epoch 421/1000\n",
      "239/239 [==============================] - 1s 2ms/step - loss: 0.4409 - accuracy: 0.8280 - val_loss: 0.4173 - val_accuracy: 0.8436\n",
      "Epoch 422/1000\n",
      "239/239 [==============================] - 0s 2ms/step - loss: 0.4390 - accuracy: 0.8294 - val_loss: 0.4165 - val_accuracy: 0.8439\n",
      "Epoch 423/1000\n",
      "239/239 [==============================] - 0s 2ms/step - loss: 0.4389 - accuracy: 0.8288 - val_loss: 0.4144 - val_accuracy: 0.8445\n",
      "Epoch 424/1000\n",
      "239/239 [==============================] - 0s 2ms/step - loss: 0.4397 - accuracy: 0.8290 - val_loss: 0.4129 - val_accuracy: 0.8455\n",
      "Epoch 425/1000\n",
      "239/239 [==============================] - 0s 2ms/step - loss: 0.4401 - accuracy: 0.8288 - val_loss: 0.4143 - val_accuracy: 0.8448\n",
      "Epoch 426/1000\n",
      "239/239 [==============================] - 0s 2ms/step - loss: 0.4379 - accuracy: 0.8302 - val_loss: 0.4119 - val_accuracy: 0.8462\n",
      "Epoch 427/1000\n",
      "239/239 [==============================] - 1s 2ms/step - loss: 0.4389 - accuracy: 0.8293 - val_loss: 0.4161 - val_accuracy: 0.8449\n",
      "Epoch 428/1000\n",
      "239/239 [==============================] - 1s 2ms/step - loss: 0.4396 - accuracy: 0.8290 - val_loss: 0.4143 - val_accuracy: 0.8444\n",
      "Epoch 429/1000\n",
      "239/239 [==============================] - 1s 2ms/step - loss: 0.4403 - accuracy: 0.8278 - val_loss: 0.4154 - val_accuracy: 0.8451\n",
      "Epoch 430/1000\n",
      "239/239 [==============================] - 1s 2ms/step - loss: 0.4397 - accuracy: 0.8297 - val_loss: 0.4146 - val_accuracy: 0.8459\n",
      "Epoch 431/1000\n",
      "239/239 [==============================] - 0s 2ms/step - loss: 0.4379 - accuracy: 0.8290 - val_loss: 0.4182 - val_accuracy: 0.8448\n",
      "Epoch 432/1000\n",
      "239/239 [==============================] - 1s 2ms/step - loss: 0.4395 - accuracy: 0.8288 - val_loss: 0.4147 - val_accuracy: 0.8454\n",
      "Epoch 433/1000\n",
      "239/239 [==============================] - 1s 2ms/step - loss: 0.4366 - accuracy: 0.8304 - val_loss: 0.4129 - val_accuracy: 0.8462\n",
      "Epoch 434/1000\n",
      "239/239 [==============================] - 0s 2ms/step - loss: 0.4398 - accuracy: 0.8277 - val_loss: 0.4143 - val_accuracy: 0.8452\n",
      "Epoch 435/1000\n",
      "239/239 [==============================] - 0s 2ms/step - loss: 0.4385 - accuracy: 0.8290 - val_loss: 0.4139 - val_accuracy: 0.8437\n",
      "Epoch 436/1000\n",
      "239/239 [==============================] - 0s 2ms/step - loss: 0.4388 - accuracy: 0.8296 - val_loss: 0.4122 - val_accuracy: 0.8457\n",
      "Epoch 437/1000\n",
      "239/239 [==============================] - 1s 2ms/step - loss: 0.4376 - accuracy: 0.8299 - val_loss: 0.4122 - val_accuracy: 0.8461\n",
      "Epoch 438/1000\n",
      "239/239 [==============================] - 0s 2ms/step - loss: 0.4387 - accuracy: 0.8298 - val_loss: 0.4132 - val_accuracy: 0.8456\n",
      "Epoch 439/1000\n",
      "239/239 [==============================] - 1s 3ms/step - loss: 0.4374 - accuracy: 0.8297 - val_loss: 0.4142 - val_accuracy: 0.8436\n",
      "Epoch 440/1000\n",
      "239/239 [==============================] - 0s 2ms/step - loss: 0.4384 - accuracy: 0.8292 - val_loss: 0.4116 - val_accuracy: 0.8467\n",
      "Epoch 441/1000\n",
      "239/239 [==============================] - 0s 2ms/step - loss: 0.4378 - accuracy: 0.8295 - val_loss: 0.4106 - val_accuracy: 0.8482\n",
      "Epoch 442/1000\n",
      "239/239 [==============================] - 1s 2ms/step - loss: 0.4364 - accuracy: 0.8303 - val_loss: 0.4127 - val_accuracy: 0.8461\n",
      "Epoch 443/1000\n",
      "239/239 [==============================] - 1s 2ms/step - loss: 0.4388 - accuracy: 0.8296 - val_loss: 0.4120 - val_accuracy: 0.8453\n",
      "Epoch 444/1000\n",
      "239/239 [==============================] - 1s 2ms/step - loss: 0.4400 - accuracy: 0.8287 - val_loss: 0.4136 - val_accuracy: 0.8467\n",
      "Epoch 445/1000\n",
      "239/239 [==============================] - 1s 2ms/step - loss: 0.4387 - accuracy: 0.8285 - val_loss: 0.4127 - val_accuracy: 0.8470\n",
      "Epoch 446/1000\n",
      "239/239 [==============================] - 1s 2ms/step - loss: 0.4396 - accuracy: 0.8289 - val_loss: 0.4128 - val_accuracy: 0.8446\n",
      "Epoch 447/1000\n",
      "239/239 [==============================] - 1s 2ms/step - loss: 0.4388 - accuracy: 0.8293 - val_loss: 0.4121 - val_accuracy: 0.8453\n",
      "Epoch 448/1000\n",
      "239/239 [==============================] - 1s 2ms/step - loss: 0.4384 - accuracy: 0.8295 - val_loss: 0.4088 - val_accuracy: 0.8466\n",
      "Epoch 449/1000\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "239/239 [==============================] - 0s 2ms/step - loss: 0.4362 - accuracy: 0.8303 - val_loss: 0.4109 - val_accuracy: 0.8473\n",
      "Epoch 450/1000\n",
      "239/239 [==============================] - 0s 2ms/step - loss: 0.4376 - accuracy: 0.8292 - val_loss: 0.4125 - val_accuracy: 0.8451\n",
      "Epoch 451/1000\n",
      "239/239 [==============================] - 0s 2ms/step - loss: 0.4368 - accuracy: 0.8297 - val_loss: 0.4135 - val_accuracy: 0.8465\n",
      "Epoch 452/1000\n",
      "239/239 [==============================] - 0s 2ms/step - loss: 0.4378 - accuracy: 0.8298 - val_loss: 0.4104 - val_accuracy: 0.8470\n",
      "Epoch 453/1000\n",
      "239/239 [==============================] - 0s 2ms/step - loss: 0.4372 - accuracy: 0.8298 - val_loss: 0.4108 - val_accuracy: 0.8480\n",
      "Epoch 454/1000\n",
      "239/239 [==============================] - 0s 2ms/step - loss: 0.4384 - accuracy: 0.8294 - val_loss: 0.4118 - val_accuracy: 0.8455\n",
      "Epoch 455/1000\n",
      "239/239 [==============================] - 1s 2ms/step - loss: 0.4362 - accuracy: 0.8307 - val_loss: 0.4123 - val_accuracy: 0.8467\n",
      "Epoch 456/1000\n",
      "239/239 [==============================] - 1s 2ms/step - loss: 0.4391 - accuracy: 0.8290 - val_loss: 0.4145 - val_accuracy: 0.8443\n",
      "Epoch 457/1000\n",
      "239/239 [==============================] - 1s 2ms/step - loss: 0.4365 - accuracy: 0.8302 - val_loss: 0.4097 - val_accuracy: 0.8469\n",
      "Epoch 458/1000\n",
      "239/239 [==============================] - 0s 2ms/step - loss: 0.4350 - accuracy: 0.8308 - val_loss: 0.4112 - val_accuracy: 0.8459\n",
      "Epoch 459/1000\n",
      "239/239 [==============================] - 0s 2ms/step - loss: 0.4378 - accuracy: 0.8302 - val_loss: 0.4107 - val_accuracy: 0.8453\n",
      "Epoch 460/1000\n",
      "239/239 [==============================] - 0s 2ms/step - loss: 0.4374 - accuracy: 0.8296 - val_loss: 0.4152 - val_accuracy: 0.8437\n",
      "Epoch 461/1000\n",
      "239/239 [==============================] - 1s 2ms/step - loss: 0.4372 - accuracy: 0.8300 - val_loss: 0.4115 - val_accuracy: 0.8449\n",
      "Epoch 462/1000\n",
      "239/239 [==============================] - 1s 2ms/step - loss: 0.4353 - accuracy: 0.8310 - val_loss: 0.4125 - val_accuracy: 0.8468\n",
      "Epoch 463/1000\n",
      "239/239 [==============================] - 0s 2ms/step - loss: 0.4374 - accuracy: 0.8311 - val_loss: 0.4112 - val_accuracy: 0.8466\n",
      "Epoch 464/1000\n",
      "239/239 [==============================] - 0s 2ms/step - loss: 0.4375 - accuracy: 0.8292 - val_loss: 0.4098 - val_accuracy: 0.8478\n",
      "Epoch 465/1000\n",
      "239/239 [==============================] - 0s 2ms/step - loss: 0.4370 - accuracy: 0.8300 - val_loss: 0.4138 - val_accuracy: 0.8467\n",
      "Epoch 466/1000\n",
      "239/239 [==============================] - 0s 2ms/step - loss: 0.4380 - accuracy: 0.8304 - val_loss: 0.4090 - val_accuracy: 0.8468\n",
      "Epoch 467/1000\n",
      "239/239 [==============================] - 1s 2ms/step - loss: 0.4357 - accuracy: 0.8298 - val_loss: 0.4119 - val_accuracy: 0.8445\n",
      "Epoch 468/1000\n",
      "239/239 [==============================] - 1s 2ms/step - loss: 0.4374 - accuracy: 0.8303 - val_loss: 0.4106 - val_accuracy: 0.8455\n",
      "Epoch 469/1000\n",
      "239/239 [==============================] - 0s 2ms/step - loss: 0.4371 - accuracy: 0.8298 - val_loss: 0.4112 - val_accuracy: 0.8459\n",
      "Epoch 470/1000\n",
      "239/239 [==============================] - 0s 2ms/step - loss: 0.4360 - accuracy: 0.8295 - val_loss: 0.4112 - val_accuracy: 0.8465\n",
      "Epoch 471/1000\n",
      "239/239 [==============================] - 1s 2ms/step - loss: 0.4363 - accuracy: 0.8302 - val_loss: 0.4127 - val_accuracy: 0.8453\n",
      "Epoch 472/1000\n",
      "239/239 [==============================] - 1s 2ms/step - loss: 0.4380 - accuracy: 0.8304 - val_loss: 0.4118 - val_accuracy: 0.8462\n",
      "Epoch 473/1000\n",
      "239/239 [==============================] - 0s 2ms/step - loss: 0.4372 - accuracy: 0.8304 - val_loss: 0.4176 - val_accuracy: 0.8451\n",
      "Epoch 474/1000\n",
      "239/239 [==============================] - 0s 2ms/step - loss: 0.4357 - accuracy: 0.8301 - val_loss: 0.4134 - val_accuracy: 0.8460\n",
      "Epoch 475/1000\n",
      "239/239 [==============================] - 0s 2ms/step - loss: 0.4368 - accuracy: 0.8304 - val_loss: 0.4126 - val_accuracy: 0.8455\n",
      "Epoch 476/1000\n",
      "239/239 [==============================] - 1s 2ms/step - loss: 0.4379 - accuracy: 0.8300 - val_loss: 0.4114 - val_accuracy: 0.8463\n",
      "Epoch 477/1000\n",
      "239/239 [==============================] - 1s 2ms/step - loss: 0.4376 - accuracy: 0.8306 - val_loss: 0.4116 - val_accuracy: 0.8480\n",
      "Epoch 478/1000\n",
      "239/239 [==============================] - 1s 2ms/step - loss: 0.4365 - accuracy: 0.8310 - val_loss: 0.4122 - val_accuracy: 0.8476\n",
      "Epoch 479/1000\n",
      "239/239 [==============================] - 1s 2ms/step - loss: 0.4373 - accuracy: 0.8293 - val_loss: 0.4147 - val_accuracy: 0.8445\n",
      "Epoch 480/1000\n",
      "239/239 [==============================] - 1s 2ms/step - loss: 0.4358 - accuracy: 0.8303 - val_loss: 0.4103 - val_accuracy: 0.8462\n",
      "Epoch 481/1000\n",
      "239/239 [==============================] - 0s 2ms/step - loss: 0.4361 - accuracy: 0.8304 - val_loss: 0.4122 - val_accuracy: 0.8453\n",
      "Epoch 482/1000\n",
      "239/239 [==============================] - 1s 2ms/step - loss: 0.4364 - accuracy: 0.8302 - val_loss: 0.4100 - val_accuracy: 0.8448\n",
      "Epoch 483/1000\n",
      "239/239 [==============================] - 1s 2ms/step - loss: 0.4363 - accuracy: 0.8300 - val_loss: 0.4092 - val_accuracy: 0.8473\n",
      "Epoch 484/1000\n",
      "239/239 [==============================] - 0s 2ms/step - loss: 0.4350 - accuracy: 0.8314 - val_loss: 0.4098 - val_accuracy: 0.8462\n",
      "Epoch 485/1000\n",
      "239/239 [==============================] - 0s 2ms/step - loss: 0.4355 - accuracy: 0.8305 - val_loss: 0.4121 - val_accuracy: 0.8465\n",
      "Epoch 486/1000\n",
      "239/239 [==============================] - 0s 2ms/step - loss: 0.4358 - accuracy: 0.8295 - val_loss: 0.4108 - val_accuracy: 0.8460\n",
      "Epoch 487/1000\n",
      "239/239 [==============================] - 1s 2ms/step - loss: 0.4348 - accuracy: 0.8305 - val_loss: 0.4101 - val_accuracy: 0.8470\n",
      "Epoch 488/1000\n",
      "239/239 [==============================] - 1s 2ms/step - loss: 0.4350 - accuracy: 0.8304 - val_loss: 0.4093 - val_accuracy: 0.8452\n",
      "Epoch 489/1000\n",
      "239/239 [==============================] - 0s 2ms/step - loss: 0.4345 - accuracy: 0.8311 - val_loss: 0.4101 - val_accuracy: 0.8459\n",
      "Epoch 490/1000\n",
      "239/239 [==============================] - 1s 2ms/step - loss: 0.4348 - accuracy: 0.8308 - val_loss: 0.4111 - val_accuracy: 0.8451\n",
      "Epoch 491/1000\n",
      "239/239 [==============================] - 1s 2ms/step - loss: 0.4374 - accuracy: 0.8290 - val_loss: 0.4133 - val_accuracy: 0.8476\n",
      "Epoch 492/1000\n",
      "239/239 [==============================] - 1s 2ms/step - loss: 0.4368 - accuracy: 0.8309 - val_loss: 0.4119 - val_accuracy: 0.8451\n",
      "Epoch 493/1000\n",
      "239/239 [==============================] - 1s 2ms/step - loss: 0.4359 - accuracy: 0.8308 - val_loss: 0.4116 - val_accuracy: 0.8462\n",
      "Epoch 494/1000\n",
      "239/239 [==============================] - 0s 2ms/step - loss: 0.4364 - accuracy: 0.8304 - val_loss: 0.4069 - val_accuracy: 0.8483\n",
      "Epoch 495/1000\n",
      "239/239 [==============================] - 0s 2ms/step - loss: 0.4341 - accuracy: 0.8310 - val_loss: 0.4109 - val_accuracy: 0.8467\n",
      "Epoch 496/1000\n",
      "239/239 [==============================] - 1s 2ms/step - loss: 0.4358 - accuracy: 0.8303 - val_loss: 0.4114 - val_accuracy: 0.8459\n",
      "Epoch 497/1000\n",
      "239/239 [==============================] - 1s 2ms/step - loss: 0.4357 - accuracy: 0.8314 - val_loss: 0.4111 - val_accuracy: 0.8470\n",
      "Epoch 498/1000\n",
      "239/239 [==============================] - 0s 2ms/step - loss: 0.4361 - accuracy: 0.8312 - val_loss: 0.4114 - val_accuracy: 0.8466\n",
      "Epoch 499/1000\n",
      "239/239 [==============================] - 1s 2ms/step - loss: 0.4373 - accuracy: 0.8289 - val_loss: 0.4127 - val_accuracy: 0.8455\n",
      "Epoch 500/1000\n",
      "239/239 [==============================] - 1s 2ms/step - loss: 0.4352 - accuracy: 0.8303 - val_loss: 0.4100 - val_accuracy: 0.8474\n",
      "Epoch 501/1000\n",
      "239/239 [==============================] - 0s 2ms/step - loss: 0.4348 - accuracy: 0.8312 - val_loss: 0.4086 - val_accuracy: 0.8479\n",
      "Epoch 502/1000\n",
      "239/239 [==============================] - 1s 2ms/step - loss: 0.4356 - accuracy: 0.8308 - val_loss: 0.4087 - val_accuracy: 0.8459\n",
      "Epoch 503/1000\n",
      "239/239 [==============================] - 1s 2ms/step - loss: 0.4342 - accuracy: 0.8317 - val_loss: 0.4099 - val_accuracy: 0.8459\n",
      "Epoch 504/1000\n",
      "239/239 [==============================] - 0s 2ms/step - loss: 0.4352 - accuracy: 0.8307 - val_loss: 0.4089 - val_accuracy: 0.8488\n",
      "Epoch 505/1000\n",
      "239/239 [==============================] - 1s 2ms/step - loss: 0.4362 - accuracy: 0.8304 - val_loss: 0.4073 - val_accuracy: 0.8491\n",
      "Epoch 506/1000\n",
      "239/239 [==============================] - 1s 2ms/step - loss: 0.4324 - accuracy: 0.8321 - val_loss: 0.4081 - val_accuracy: 0.8472\n",
      "Epoch 507/1000\n",
      "239/239 [==============================] - 1s 2ms/step - loss: 0.4346 - accuracy: 0.8312 - val_loss: 0.4094 - val_accuracy: 0.8487\n",
      "Epoch 508/1000\n",
      "239/239 [==============================] - 0s 2ms/step - loss: 0.4361 - accuracy: 0.8308 - val_loss: 0.4087 - val_accuracy: 0.8483\n",
      "Epoch 509/1000\n",
      "239/239 [==============================] - 1s 2ms/step - loss: 0.4341 - accuracy: 0.8307 - val_loss: 0.4120 - val_accuracy: 0.8476\n",
      "Epoch 510/1000\n",
      "239/239 [==============================] - 1s 2ms/step - loss: 0.4362 - accuracy: 0.8304 - val_loss: 0.4108 - val_accuracy: 0.8482\n",
      "Epoch 511/1000\n",
      "239/239 [==============================] - 1s 2ms/step - loss: 0.4353 - accuracy: 0.8300 - val_loss: 0.4100 - val_accuracy: 0.8475\n",
      "Epoch 512/1000\n",
      "239/239 [==============================] - 1s 2ms/step - loss: 0.4340 - accuracy: 0.8307 - val_loss: 0.4109 - val_accuracy: 0.8482\n",
      "Epoch 513/1000\n",
      "239/239 [==============================] - 1s 2ms/step - loss: 0.4340 - accuracy: 0.8315 - val_loss: 0.4064 - val_accuracy: 0.8487\n",
      "Epoch 514/1000\n",
      "239/239 [==============================] - 0s 2ms/step - loss: 0.4348 - accuracy: 0.8305 - val_loss: 0.4083 - val_accuracy: 0.8478\n",
      "Epoch 515/1000\n",
      "239/239 [==============================] - 1s 2ms/step - loss: 0.4336 - accuracy: 0.8312 - val_loss: 0.4116 - val_accuracy: 0.8475\n",
      "Epoch 516/1000\n",
      "239/239 [==============================] - 1s 2ms/step - loss: 0.4346 - accuracy: 0.8315 - val_loss: 0.4107 - val_accuracy: 0.8463\n",
      "Epoch 517/1000\n",
      "239/239 [==============================] - 0s 2ms/step - loss: 0.4358 - accuracy: 0.8311 - val_loss: 0.4099 - val_accuracy: 0.8485\n",
      "Epoch 518/1000\n",
      "239/239 [==============================] - 0s 2ms/step - loss: 0.4328 - accuracy: 0.8325 - val_loss: 0.4052 - val_accuracy: 0.8485\n",
      "Epoch 519/1000\n",
      "239/239 [==============================] - 1s 2ms/step - loss: 0.4341 - accuracy: 0.8306 - val_loss: 0.4105 - val_accuracy: 0.8467\n",
      "Epoch 520/1000\n",
      "239/239 [==============================] - 0s 2ms/step - loss: 0.4343 - accuracy: 0.8312 - val_loss: 0.4127 - val_accuracy: 0.8451\n",
      "Epoch 521/1000\n",
      "239/239 [==============================] - 0s 2ms/step - loss: 0.4357 - accuracy: 0.8308 - val_loss: 0.4106 - val_accuracy: 0.8481\n",
      "Epoch 522/1000\n",
      "239/239 [==============================] - 0s 2ms/step - loss: 0.4345 - accuracy: 0.8312 - val_loss: 0.4085 - val_accuracy: 0.8482\n",
      "Epoch 523/1000\n",
      "239/239 [==============================] - 1s 2ms/step - loss: 0.4344 - accuracy: 0.8311 - val_loss: 0.4097 - val_accuracy: 0.8476\n",
      "Epoch 524/1000\n",
      "239/239 [==============================] - 0s 2ms/step - loss: 0.4355 - accuracy: 0.8307 - val_loss: 0.4114 - val_accuracy: 0.8476\n",
      "Epoch 525/1000\n",
      "239/239 [==============================] - 0s 2ms/step - loss: 0.4346 - accuracy: 0.8311 - val_loss: 0.4078 - val_accuracy: 0.8469\n",
      "Epoch 526/1000\n",
      "239/239 [==============================] - 1s 2ms/step - loss: 0.4360 - accuracy: 0.8311 - val_loss: 0.4074 - val_accuracy: 0.8475\n",
      "Epoch 527/1000\n",
      "239/239 [==============================] - 0s 2ms/step - loss: 0.4336 - accuracy: 0.8320 - val_loss: 0.4100 - val_accuracy: 0.8459\n",
      "Epoch 528/1000\n",
      "239/239 [==============================] - 1s 2ms/step - loss: 0.4342 - accuracy: 0.8309 - val_loss: 0.4083 - val_accuracy: 0.8470\n",
      "Epoch 529/1000\n",
      "239/239 [==============================] - 1s 2ms/step - loss: 0.4361 - accuracy: 0.8299 - val_loss: 0.4095 - val_accuracy: 0.8473\n",
      "Epoch 530/1000\n",
      "239/239 [==============================] - 0s 2ms/step - loss: 0.4335 - accuracy: 0.8327 - val_loss: 0.4096 - val_accuracy: 0.8470\n",
      "Epoch 531/1000\n",
      "239/239 [==============================] - 0s 2ms/step - loss: 0.4349 - accuracy: 0.8314 - val_loss: 0.4086 - val_accuracy: 0.8476\n",
      "Epoch 532/1000\n",
      "239/239 [==============================] - 1s 2ms/step - loss: 0.4343 - accuracy: 0.8318 - val_loss: 0.4092 - val_accuracy: 0.8476\n",
      "Epoch 533/1000\n",
      "239/239 [==============================] - 1s 2ms/step - loss: 0.4334 - accuracy: 0.8310 - val_loss: 0.4098 - val_accuracy: 0.8473\n",
      "Epoch 534/1000\n",
      "239/239 [==============================] - 0s 2ms/step - loss: 0.4337 - accuracy: 0.8316 - val_loss: 0.4072 - val_accuracy: 0.8484\n",
      "Epoch 535/1000\n",
      "239/239 [==============================] - 0s 2ms/step - loss: 0.4321 - accuracy: 0.8320 - val_loss: 0.4110 - val_accuracy: 0.8476\n",
      "Epoch 536/1000\n",
      "239/239 [==============================] - 0s 2ms/step - loss: 0.4330 - accuracy: 0.8316 - val_loss: 0.4089 - val_accuracy: 0.8497\n",
      "Epoch 537/1000\n",
      "239/239 [==============================] - 0s 2ms/step - loss: 0.4334 - accuracy: 0.8320 - val_loss: 0.4088 - val_accuracy: 0.8486\n",
      "Epoch 538/1000\n",
      "239/239 [==============================] - 0s 2ms/step - loss: 0.4337 - accuracy: 0.8317 - val_loss: 0.4103 - val_accuracy: 0.8483\n",
      "Epoch 539/1000\n",
      "239/239 [==============================] - 0s 2ms/step - loss: 0.4330 - accuracy: 0.8320 - val_loss: 0.4097 - val_accuracy: 0.8470\n",
      "Epoch 540/1000\n",
      "239/239 [==============================] - 0s 2ms/step - loss: 0.4337 - accuracy: 0.8316 - val_loss: 0.4058 - val_accuracy: 0.8491\n",
      "Epoch 541/1000\n",
      "239/239 [==============================] - 1s 2ms/step - loss: 0.4328 - accuracy: 0.8318 - val_loss: 0.4047 - val_accuracy: 0.8513\n",
      "Epoch 542/1000\n",
      "239/239 [==============================] - 1s 2ms/step - loss: 0.4333 - accuracy: 0.8320 - val_loss: 0.4071 - val_accuracy: 0.8489\n",
      "Epoch 543/1000\n",
      "239/239 [==============================] - 1s 2ms/step - loss: 0.4347 - accuracy: 0.8308 - val_loss: 0.4090 - val_accuracy: 0.8472\n",
      "Epoch 544/1000\n",
      "239/239 [==============================] - 0s 2ms/step - loss: 0.4320 - accuracy: 0.8321 - val_loss: 0.4092 - val_accuracy: 0.8482\n",
      "Epoch 545/1000\n",
      "239/239 [==============================] - 0s 2ms/step - loss: 0.4339 - accuracy: 0.8310 - val_loss: 0.4088 - val_accuracy: 0.8480\n",
      "Epoch 546/1000\n",
      "239/239 [==============================] - 0s 2ms/step - loss: 0.4334 - accuracy: 0.8318 - val_loss: 0.4080 - val_accuracy: 0.8489\n",
      "Epoch 547/1000\n",
      "239/239 [==============================] - 1s 2ms/step - loss: 0.4338 - accuracy: 0.8310 - val_loss: 0.4100 - val_accuracy: 0.8479\n",
      "Epoch 548/1000\n",
      "239/239 [==============================] - 1s 2ms/step - loss: 0.4322 - accuracy: 0.8324 - val_loss: 0.4060 - val_accuracy: 0.8484\n",
      "Epoch 549/1000\n",
      "239/239 [==============================] - 0s 2ms/step - loss: 0.4343 - accuracy: 0.8307 - val_loss: 0.4109 - val_accuracy: 0.8459\n",
      "Epoch 550/1000\n",
      "239/239 [==============================] - 0s 2ms/step - loss: 0.4316 - accuracy: 0.8326 - val_loss: 0.4070 - val_accuracy: 0.8466\n",
      "Epoch 551/1000\n",
      "239/239 [==============================] - 0s 2ms/step - loss: 0.4323 - accuracy: 0.8316 - val_loss: 0.4059 - val_accuracy: 0.8488\n",
      "Epoch 552/1000\n",
      "239/239 [==============================] - 1s 2ms/step - loss: 0.4340 - accuracy: 0.8316 - val_loss: 0.4100 - val_accuracy: 0.8466\n",
      "Epoch 553/1000\n",
      "239/239 [==============================] - 1s 2ms/step - loss: 0.4330 - accuracy: 0.8323 - val_loss: 0.4068 - val_accuracy: 0.8493\n",
      "Epoch 554/1000\n",
      "239/239 [==============================] - 1s 2ms/step - loss: 0.4348 - accuracy: 0.8311 - val_loss: 0.4091 - val_accuracy: 0.8465\n",
      "Epoch 555/1000\n",
      "239/239 [==============================] - 1s 2ms/step - loss: 0.4311 - accuracy: 0.8320 - val_loss: 0.4049 - val_accuracy: 0.8481\n",
      "Epoch 556/1000\n",
      "239/239 [==============================] - 0s 2ms/step - loss: 0.4318 - accuracy: 0.8331 - val_loss: 0.4071 - val_accuracy: 0.8473\n",
      "Epoch 557/1000\n",
      "239/239 [==============================] - 0s 2ms/step - loss: 0.4327 - accuracy: 0.8314 - val_loss: 0.4074 - val_accuracy: 0.8470\n",
      "Epoch 558/1000\n",
      "239/239 [==============================] - 1s 2ms/step - loss: 0.4321 - accuracy: 0.8320 - val_loss: 0.4084 - val_accuracy: 0.8476\n",
      "Epoch 559/1000\n",
      "239/239 [==============================] - 1s 2ms/step - loss: 0.4351 - accuracy: 0.8306 - val_loss: 0.4069 - val_accuracy: 0.8481\n",
      "Epoch 560/1000\n",
      "239/239 [==============================] - 0s 2ms/step - loss: 0.4322 - accuracy: 0.8321 - val_loss: 0.4086 - val_accuracy: 0.8482\n",
      "Epoch 561/1000\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "239/239 [==============================] - 0s 2ms/step - loss: 0.4335 - accuracy: 0.8323 - val_loss: 0.4129 - val_accuracy: 0.8470\n",
      "Epoch 562/1000\n",
      "239/239 [==============================] - 0s 2ms/step - loss: 0.4333 - accuracy: 0.8319 - val_loss: 0.4080 - val_accuracy: 0.8486\n",
      "Epoch 563/1000\n",
      "239/239 [==============================] - 0s 2ms/step - loss: 0.4313 - accuracy: 0.8334 - val_loss: 0.4055 - val_accuracy: 0.8475\n",
      "Epoch 564/1000\n",
      "239/239 [==============================] - 1s 2ms/step - loss: 0.4307 - accuracy: 0.8336 - val_loss: 0.4115 - val_accuracy: 0.8462\n",
      "Epoch 565/1000\n",
      "239/239 [==============================] - 1s 2ms/step - loss: 0.4353 - accuracy: 0.8303 - val_loss: 0.4107 - val_accuracy: 0.8466\n",
      "Epoch 566/1000\n",
      "239/239 [==============================] - 1s 2ms/step - loss: 0.4321 - accuracy: 0.8323 - val_loss: 0.4068 - val_accuracy: 0.8482\n",
      "Epoch 567/1000\n",
      "239/239 [==============================] - 1s 2ms/step - loss: 0.4330 - accuracy: 0.8321 - val_loss: 0.4087 - val_accuracy: 0.8479\n",
      "Epoch 568/1000\n",
      "239/239 [==============================] - 0s 2ms/step - loss: 0.4314 - accuracy: 0.8328 - val_loss: 0.4080 - val_accuracy: 0.8470\n",
      "Epoch 569/1000\n",
      "239/239 [==============================] - 1s 2ms/step - loss: 0.4343 - accuracy: 0.8324 - val_loss: 0.4067 - val_accuracy: 0.8482\n",
      "Epoch 570/1000\n",
      "239/239 [==============================] - 1s 3ms/step - loss: 0.4355 - accuracy: 0.8305 - val_loss: 0.4082 - val_accuracy: 0.8472\n",
      "Epoch 571/1000\n",
      "239/239 [==============================] - 1s 2ms/step - loss: 0.4302 - accuracy: 0.8332 - val_loss: 0.4044 - val_accuracy: 0.8486\n",
      "Epoch 572/1000\n",
      "239/239 [==============================] - 0s 2ms/step - loss: 0.4301 - accuracy: 0.8325 - val_loss: 0.4070 - val_accuracy: 0.8487\n",
      "Epoch 573/1000\n",
      "239/239 [==============================] - 0s 2ms/step - loss: 0.4330 - accuracy: 0.8318 - val_loss: 0.4054 - val_accuracy: 0.8490\n",
      "Epoch 574/1000\n",
      "239/239 [==============================] - 0s 2ms/step - loss: 0.4337 - accuracy: 0.8303 - val_loss: 0.4058 - val_accuracy: 0.8490\n",
      "Epoch 575/1000\n",
      "239/239 [==============================] - 1s 2ms/step - loss: 0.4324 - accuracy: 0.8319 - val_loss: 0.4093 - val_accuracy: 0.8485\n",
      "Epoch 576/1000\n",
      "239/239 [==============================] - 1s 2ms/step - loss: 0.4332 - accuracy: 0.8322 - val_loss: 0.4060 - val_accuracy: 0.8494\n",
      "Epoch 577/1000\n",
      "239/239 [==============================] - 0s 2ms/step - loss: 0.4313 - accuracy: 0.8329 - val_loss: 0.4069 - val_accuracy: 0.8479\n",
      "Epoch 578/1000\n",
      "239/239 [==============================] - 0s 2ms/step - loss: 0.4319 - accuracy: 0.8321 - val_loss: 0.4072 - val_accuracy: 0.8470\n",
      "Epoch 579/1000\n",
      "239/239 [==============================] - 0s 2ms/step - loss: 0.4351 - accuracy: 0.8310 - val_loss: 0.4078 - val_accuracy: 0.8493\n",
      "Epoch 580/1000\n",
      "239/239 [==============================] - 0s 2ms/step - loss: 0.4318 - accuracy: 0.8308 - val_loss: 0.4080 - val_accuracy: 0.8496\n",
      "Epoch 581/1000\n",
      "239/239 [==============================] - 0s 2ms/step - loss: 0.4304 - accuracy: 0.8327 - val_loss: 0.4133 - val_accuracy: 0.8481\n",
      "Epoch 582/1000\n",
      "239/239 [==============================] - 1s 3ms/step - loss: 0.4304 - accuracy: 0.8324 - val_loss: 0.4070 - val_accuracy: 0.8482\n",
      "Epoch 583/1000\n",
      "239/239 [==============================] - 0s 2ms/step - loss: 0.4314 - accuracy: 0.8328 - val_loss: 0.4095 - val_accuracy: 0.8449\n",
      "Epoch 584/1000\n",
      "239/239 [==============================] - 1s 2ms/step - loss: 0.4299 - accuracy: 0.8330 - val_loss: 0.4067 - val_accuracy: 0.8479\n",
      "Epoch 585/1000\n",
      "239/239 [==============================] - 1s 2ms/step - loss: 0.4322 - accuracy: 0.8322 - val_loss: 0.4112 - val_accuracy: 0.8454\n",
      "Epoch 586/1000\n",
      "239/239 [==============================] - 1s 2ms/step - loss: 0.4338 - accuracy: 0.8306 - val_loss: 0.4058 - val_accuracy: 0.8477\n",
      "Epoch 587/1000\n",
      "239/239 [==============================] - 1s 2ms/step - loss: 0.4312 - accuracy: 0.8324 - val_loss: 0.4074 - val_accuracy: 0.8467\n",
      "Epoch 588/1000\n",
      "239/239 [==============================] - 0s 2ms/step - loss: 0.4301 - accuracy: 0.8326 - val_loss: 0.4065 - val_accuracy: 0.8506\n",
      "Epoch 589/1000\n",
      "239/239 [==============================] - 0s 2ms/step - loss: 0.4329 - accuracy: 0.8326 - val_loss: 0.4073 - val_accuracy: 0.8487\n",
      "Epoch 590/1000\n",
      "239/239 [==============================] - 1s 2ms/step - loss: 0.4318 - accuracy: 0.8324 - val_loss: 0.4068 - val_accuracy: 0.8490\n",
      "Epoch 591/1000\n",
      "239/239 [==============================] - 1s 2ms/step - loss: 0.4321 - accuracy: 0.8325 - val_loss: 0.4053 - val_accuracy: 0.8477\n",
      "Epoch 592/1000\n",
      "239/239 [==============================] - 1s 2ms/step - loss: 0.4301 - accuracy: 0.8333 - val_loss: 0.4064 - val_accuracy: 0.8500\n",
      "Epoch 593/1000\n",
      "239/239 [==============================] - 1s 2ms/step - loss: 0.4332 - accuracy: 0.8313 - val_loss: 0.4087 - val_accuracy: 0.8473\n",
      "Epoch 594/1000\n",
      "239/239 [==============================] - 1s 2ms/step - loss: 0.4340 - accuracy: 0.8320 - val_loss: 0.4080 - val_accuracy: 0.8493\n",
      "Epoch 595/1000\n",
      "239/239 [==============================] - 0s 2ms/step - loss: 0.4303 - accuracy: 0.8337 - val_loss: 0.4077 - val_accuracy: 0.8479\n",
      "Epoch 596/1000\n",
      "239/239 [==============================] - 0s 2ms/step - loss: 0.4319 - accuracy: 0.8325 - val_loss: 0.4090 - val_accuracy: 0.8459\n",
      "Epoch 597/1000\n",
      "239/239 [==============================] - 0s 2ms/step - loss: 0.4306 - accuracy: 0.8319 - val_loss: 0.4086 - val_accuracy: 0.8479\n",
      "Epoch 598/1000\n",
      "239/239 [==============================] - 0s 2ms/step - loss: 0.4314 - accuracy: 0.8331 - val_loss: 0.4066 - val_accuracy: 0.8481\n",
      "Epoch 599/1000\n",
      "239/239 [==============================] - 0s 2ms/step - loss: 0.4304 - accuracy: 0.8330 - val_loss: 0.4114 - val_accuracy: 0.8479\n",
      "Epoch 600/1000\n",
      "239/239 [==============================] - 0s 2ms/step - loss: 0.4310 - accuracy: 0.8332 - val_loss: 0.4102 - val_accuracy: 0.8484\n",
      "Epoch 601/1000\n",
      "239/239 [==============================] - 0s 2ms/step - loss: 0.4305 - accuracy: 0.8321 - val_loss: 0.4086 - val_accuracy: 0.8476\n",
      "Epoch 602/1000\n",
      "239/239 [==============================] - 1s 2ms/step - loss: 0.4302 - accuracy: 0.8322 - val_loss: 0.4073 - val_accuracy: 0.8476\n",
      "Epoch 603/1000\n",
      "239/239 [==============================] - 1s 2ms/step - loss: 0.4302 - accuracy: 0.8336 - val_loss: 0.4053 - val_accuracy: 0.8495\n",
      "Epoch 604/1000\n",
      "239/239 [==============================] - 0s 2ms/step - loss: 0.4322 - accuracy: 0.8324 - val_loss: 0.4065 - val_accuracy: 0.8488\n",
      "Epoch 605/1000\n",
      "239/239 [==============================] - 0s 2ms/step - loss: 0.4288 - accuracy: 0.8339 - val_loss: 0.4084 - val_accuracy: 0.8477\n",
      "Epoch 606/1000\n",
      "239/239 [==============================] - 1s 2ms/step - loss: 0.4325 - accuracy: 0.8320 - val_loss: 0.4084 - val_accuracy: 0.8465\n",
      "Epoch 607/1000\n",
      "239/239 [==============================] - 1s 2ms/step - loss: 0.4298 - accuracy: 0.8337 - val_loss: 0.4089 - val_accuracy: 0.8471\n",
      "Epoch 608/1000\n",
      "239/239 [==============================] - 1s 2ms/step - loss: 0.4304 - accuracy: 0.8328 - val_loss: 0.4103 - val_accuracy: 0.8458\n",
      "Epoch 609/1000\n",
      "239/239 [==============================] - 1s 2ms/step - loss: 0.4312 - accuracy: 0.8335 - val_loss: 0.4109 - val_accuracy: 0.8472\n",
      "Epoch 610/1000\n",
      "239/239 [==============================] - 0s 2ms/step - loss: 0.4316 - accuracy: 0.8334 - val_loss: 0.4064 - val_accuracy: 0.8485\n",
      "Epoch 611/1000\n",
      "239/239 [==============================] - 1s 2ms/step - loss: 0.4307 - accuracy: 0.8326 - val_loss: 0.4052 - val_accuracy: 0.8467\n",
      "Epoch 612/1000\n",
      "239/239 [==============================] - 1s 2ms/step - loss: 0.4313 - accuracy: 0.8322 - val_loss: 0.4073 - val_accuracy: 0.8507\n",
      "Epoch 613/1000\n",
      "239/239 [==============================] - 0s 2ms/step - loss: 0.4293 - accuracy: 0.8330 - val_loss: 0.4075 - val_accuracy: 0.8482\n",
      "Epoch 614/1000\n",
      "239/239 [==============================] - 0s 2ms/step - loss: 0.4301 - accuracy: 0.8343 - val_loss: 0.4112 - val_accuracy: 0.8482\n",
      "Epoch 615/1000\n",
      "239/239 [==============================] - 1s 2ms/step - loss: 0.4307 - accuracy: 0.8335 - val_loss: 0.4061 - val_accuracy: 0.8493\n",
      "Epoch 616/1000\n",
      "239/239 [==============================] - 1s 2ms/step - loss: 0.4306 - accuracy: 0.8327 - val_loss: 0.4074 - val_accuracy: 0.8493\n",
      "Epoch 617/1000\n",
      "239/239 [==============================] - 0s 2ms/step - loss: 0.4321 - accuracy: 0.8323 - val_loss: 0.4111 - val_accuracy: 0.8463\n",
      "Epoch 618/1000\n",
      "239/239 [==============================] - 0s 2ms/step - loss: 0.4299 - accuracy: 0.8333 - val_loss: 0.4096 - val_accuracy: 0.8462\n",
      "Epoch 619/1000\n",
      "239/239 [==============================] - 0s 2ms/step - loss: 0.4316 - accuracy: 0.8327 - val_loss: 0.4095 - val_accuracy: 0.8483\n",
      "Epoch 620/1000\n",
      "239/239 [==============================] - 1s 2ms/step - loss: 0.4304 - accuracy: 0.8324 - val_loss: 0.4067 - val_accuracy: 0.8496\n",
      "Epoch 621/1000\n",
      "239/239 [==============================] - 1s 2ms/step - loss: 0.4315 - accuracy: 0.8318 - val_loss: 0.4084 - val_accuracy: 0.8484\n",
      "Epoch 621: early stopping\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "<keras.src.callbacks.History at 0x14783aaa0>"
      ]
     },
     "execution_count": 159,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "\n",
    "model=Sequential()\n",
    "model.add(Dense(128, input_dim=X_train.shape[1], activation=\"relu\"))\n",
    "model.add(Dropout(0.2))\n",
    "model.add(Dense(128, activation=\"relu\"))\n",
    "\n",
    "model.add(Dense(64, activation=\"relu\"))\n",
    "model.add(Dropout(0.2))\n",
    "model.add(Dense(64, activation=\"relu\"))\n",
    "\n",
    "model.add(Dense(32, activation=\"relu\"))\n",
    "#model.add(Dropout(0.2))\n",
    "#model.add(Dense(16, activation=\"relu\"))\n",
    "#model.add(Dropout(0.2))\n",
    "model.add(Dense(3, activation=\"softmax\"))\n",
    "\n",
    "model.compile(loss='categorical_crossentropy', optimizer=Adam(learning_rate=0.001), metrics=['accuracy'])\n",
    "\n",
    "es=EarlyStopping(monitor=\"val_loss\",patience=50,mode=\"auto\",verbose=1)\n",
    "\n",
    "model.fit(X_train,\n",
    "          y_train,\n",
    "          epochs=1000,\n",
    "               batch_size=512,\n",
    "               validation_split=0.1,\n",
    "               verbose=1,callbacks=[es])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 160,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "748/748 [==============================] - 0s 255us/step\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0       0.86      0.94      0.90      7973\n",
      "           1       0.84      0.92      0.88      7973\n",
      "           2       0.86      0.69      0.77      7972\n",
      "\n",
      "    accuracy                           0.85     23918\n",
      "   macro avg       0.85      0.85      0.85     23918\n",
      "weighted avg       0.85      0.85      0.85     23918\n",
      "\n"
     ]
    }
   ],
   "source": [
    "y_pred = model.predict(X_test)\n",
    "y_pred_classes = np.argmax(y_pred, axis=1)\n",
    "y_true = np.argmax(y_test, axis=1)\n",
    "print(classification_report(y_true, y_pred_classes))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 161,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "4236/4236 [==============================] - 1s 251us/step\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0       0.89      0.96      0.92     45176\n",
      "           1       0.86      0.95      0.90     45176\n",
      "           2       0.90      0.73      0.81     45177\n",
      "\n",
      "    accuracy                           0.88    135529\n",
      "   macro avg       0.88      0.88      0.88    135529\n",
      "weighted avg       0.88      0.88      0.88    135529\n",
      "\n"
     ]
    }
   ],
   "source": [
    "y_t_pred = model.predict(X_train)\n",
    "y_t_pred_classes = np.argmax(y_t_pred, axis=1)\n",
    "y_t_true = np.argmax(y_train, axis=1)\n",
    "print(classification_report(y_t_true, y_t_pred_classes))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 162,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 1/1000\n",
      "239/239 [==============================] - 1s 2ms/step - loss: 0.8434 - accuracy: 0.6441 - val_loss: 0.7230 - val_accuracy: 0.7233\n",
      "Epoch 2/1000\n",
      "239/239 [==============================] - 1s 2ms/step - loss: 0.7392 - accuracy: 0.7169 - val_loss: 0.7089 - val_accuracy: 0.7328\n",
      "Epoch 3/1000\n",
      "239/239 [==============================] - 1s 2ms/step - loss: 0.7161 - accuracy: 0.7259 - val_loss: 0.6952 - val_accuracy: 0.7367\n",
      "Epoch 4/1000\n",
      "239/239 [==============================] - 1s 2ms/step - loss: 0.7046 - accuracy: 0.7309 - val_loss: 0.6870 - val_accuracy: 0.7393\n",
      "Epoch 5/1000\n",
      "239/239 [==============================] - 1s 2ms/step - loss: 0.6975 - accuracy: 0.7334 - val_loss: 0.6839 - val_accuracy: 0.7432\n",
      "Epoch 6/1000\n",
      "239/239 [==============================] - 1s 2ms/step - loss: 0.6900 - accuracy: 0.7367 - val_loss: 0.6771 - val_accuracy: 0.7444\n",
      "Epoch 7/1000\n",
      "239/239 [==============================] - 1s 2ms/step - loss: 0.6856 - accuracy: 0.7382 - val_loss: 0.6746 - val_accuracy: 0.7457\n",
      "Epoch 8/1000\n",
      "239/239 [==============================] - 1s 2ms/step - loss: 0.6817 - accuracy: 0.7386 - val_loss: 0.6704 - val_accuracy: 0.7464\n",
      "Epoch 9/1000\n",
      "239/239 [==============================] - 1s 2ms/step - loss: 0.6777 - accuracy: 0.7394 - val_loss: 0.6651 - val_accuracy: 0.7473\n",
      "Epoch 10/1000\n",
      "239/239 [==============================] - 0s 2ms/step - loss: 0.6736 - accuracy: 0.7417 - val_loss: 0.6632 - val_accuracy: 0.7482\n",
      "Epoch 11/1000\n",
      "239/239 [==============================] - 0s 2ms/step - loss: 0.6724 - accuracy: 0.7431 - val_loss: 0.6641 - val_accuracy: 0.7485\n",
      "Epoch 12/1000\n",
      "239/239 [==============================] - 1s 2ms/step - loss: 0.6694 - accuracy: 0.7435 - val_loss: 0.6561 - val_accuracy: 0.7494\n",
      "Epoch 13/1000\n",
      "239/239 [==============================] - 1s 2ms/step - loss: 0.6671 - accuracy: 0.7439 - val_loss: 0.6544 - val_accuracy: 0.7508\n",
      "Epoch 14/1000\n",
      "239/239 [==============================] - 1s 2ms/step - loss: 0.6660 - accuracy: 0.7451 - val_loss: 0.6539 - val_accuracy: 0.7509\n",
      "Epoch 15/1000\n",
      "239/239 [==============================] - 1s 2ms/step - loss: 0.6647 - accuracy: 0.7449 - val_loss: 0.6511 - val_accuracy: 0.7513\n",
      "Epoch 16/1000\n",
      "239/239 [==============================] - 1s 2ms/step - loss: 0.6619 - accuracy: 0.7454 - val_loss: 0.6507 - val_accuracy: 0.7519\n",
      "Epoch 17/1000\n",
      "239/239 [==============================] - 1s 2ms/step - loss: 0.6591 - accuracy: 0.7464 - val_loss: 0.6461 - val_accuracy: 0.7520\n",
      "Epoch 18/1000\n",
      "239/239 [==============================] - 1s 2ms/step - loss: 0.6588 - accuracy: 0.7459 - val_loss: 0.6461 - val_accuracy: 0.7538\n",
      "Epoch 19/1000\n",
      "239/239 [==============================] - 1s 2ms/step - loss: 0.6577 - accuracy: 0.7462 - val_loss: 0.6464 - val_accuracy: 0.7519\n",
      "Epoch 20/1000\n",
      "239/239 [==============================] - 1s 2ms/step - loss: 0.6553 - accuracy: 0.7480 - val_loss: 0.6426 - val_accuracy: 0.7523\n",
      "Epoch 21/1000\n",
      "239/239 [==============================] - 1s 3ms/step - loss: 0.6546 - accuracy: 0.7470 - val_loss: 0.6417 - val_accuracy: 0.7514\n",
      "Epoch 22/1000\n",
      "239/239 [==============================] - 1s 2ms/step - loss: 0.6538 - accuracy: 0.7474 - val_loss: 0.6428 - val_accuracy: 0.7541\n",
      "Epoch 23/1000\n",
      "239/239 [==============================] - 1s 2ms/step - loss: 0.6533 - accuracy: 0.7477 - val_loss: 0.6401 - val_accuracy: 0.7546\n",
      "Epoch 24/1000\n",
      "239/239 [==============================] - 1s 2ms/step - loss: 0.6523 - accuracy: 0.7479 - val_loss: 0.6374 - val_accuracy: 0.7536\n",
      "Epoch 25/1000\n",
      "239/239 [==============================] - 1s 2ms/step - loss: 0.6505 - accuracy: 0.7488 - val_loss: 0.6370 - val_accuracy: 0.7552\n",
      "Epoch 26/1000\n",
      "239/239 [==============================] - 1s 2ms/step - loss: 0.6496 - accuracy: 0.7491 - val_loss: 0.6378 - val_accuracy: 0.7546\n",
      "Epoch 27/1000\n",
      "239/239 [==============================] - 1s 3ms/step - loss: 0.6475 - accuracy: 0.7500 - val_loss: 0.6371 - val_accuracy: 0.7552\n",
      "Epoch 28/1000\n",
      "239/239 [==============================] - 1s 2ms/step - loss: 0.6469 - accuracy: 0.7499 - val_loss: 0.6347 - val_accuracy: 0.7542\n",
      "Epoch 29/1000\n",
      "239/239 [==============================] - 1s 2ms/step - loss: 0.6463 - accuracy: 0.7492 - val_loss: 0.6341 - val_accuracy: 0.7553\n",
      "Epoch 30/1000\n",
      "239/239 [==============================] - 1s 2ms/step - loss: 0.6457 - accuracy: 0.7498 - val_loss: 0.6322 - val_accuracy: 0.7557\n",
      "Epoch 31/1000\n",
      "239/239 [==============================] - 1s 2ms/step - loss: 0.6452 - accuracy: 0.7501 - val_loss: 0.6324 - val_accuracy: 0.7558\n",
      "Epoch 32/1000\n",
      "239/239 [==============================] - 1s 2ms/step - loss: 0.6438 - accuracy: 0.7506 - val_loss: 0.6342 - val_accuracy: 0.7549\n",
      "Epoch 33/1000\n",
      "239/239 [==============================] - 1s 2ms/step - loss: 0.6427 - accuracy: 0.7507 - val_loss: 0.6291 - val_accuracy: 0.7558\n",
      "Epoch 34/1000\n",
      "239/239 [==============================] - 0s 2ms/step - loss: 0.6420 - accuracy: 0.7512 - val_loss: 0.6289 - val_accuracy: 0.7560\n",
      "Epoch 35/1000\n",
      "239/239 [==============================] - 1s 2ms/step - loss: 0.6434 - accuracy: 0.7508 - val_loss: 0.6313 - val_accuracy: 0.7566\n",
      "Epoch 36/1000\n",
      "239/239 [==============================] - 1s 2ms/step - loss: 0.6409 - accuracy: 0.7525 - val_loss: 0.6293 - val_accuracy: 0.7568\n",
      "Epoch 37/1000\n",
      "239/239 [==============================] - 0s 2ms/step - loss: 0.6400 - accuracy: 0.7522 - val_loss: 0.6263 - val_accuracy: 0.7563\n",
      "Epoch 38/1000\n",
      "239/239 [==============================] - 1s 2ms/step - loss: 0.6404 - accuracy: 0.7515 - val_loss: 0.6280 - val_accuracy: 0.7570\n",
      "Epoch 39/1000\n",
      "239/239 [==============================] - 1s 2ms/step - loss: 0.6381 - accuracy: 0.7533 - val_loss: 0.6251 - val_accuracy: 0.7575\n",
      "Epoch 40/1000\n",
      "239/239 [==============================] - 1s 2ms/step - loss: 0.6393 - accuracy: 0.7526 - val_loss: 0.6242 - val_accuracy: 0.7583\n",
      "Epoch 41/1000\n",
      "239/239 [==============================] - 1s 3ms/step - loss: 0.6386 - accuracy: 0.7515 - val_loss: 0.6234 - val_accuracy: 0.7561\n",
      "Epoch 42/1000\n",
      "239/239 [==============================] - 1s 2ms/step - loss: 0.6377 - accuracy: 0.7532 - val_loss: 0.6218 - val_accuracy: 0.7569\n",
      "Epoch 43/1000\n",
      "239/239 [==============================] - 1s 2ms/step - loss: 0.6372 - accuracy: 0.7522 - val_loss: 0.6199 - val_accuracy: 0.7596\n",
      "Epoch 44/1000\n",
      "239/239 [==============================] - 1s 2ms/step - loss: 0.6356 - accuracy: 0.7531 - val_loss: 0.6221 - val_accuracy: 0.7575\n",
      "Epoch 45/1000\n",
      "239/239 [==============================] - 1s 2ms/step - loss: 0.6358 - accuracy: 0.7530 - val_loss: 0.6235 - val_accuracy: 0.7586\n",
      "Epoch 46/1000\n",
      "239/239 [==============================] - 1s 2ms/step - loss: 0.6368 - accuracy: 0.7529 - val_loss: 0.6178 - val_accuracy: 0.7594\n",
      "Epoch 47/1000\n",
      "239/239 [==============================] - 1s 2ms/step - loss: 0.6347 - accuracy: 0.7540 - val_loss: 0.6193 - val_accuracy: 0.7600\n",
      "Epoch 48/1000\n",
      "239/239 [==============================] - 1s 2ms/step - loss: 0.6348 - accuracy: 0.7545 - val_loss: 0.6191 - val_accuracy: 0.7604\n",
      "Epoch 49/1000\n",
      "239/239 [==============================] - 1s 2ms/step - loss: 0.6342 - accuracy: 0.7543 - val_loss: 0.6166 - val_accuracy: 0.7585\n",
      "Epoch 50/1000\n",
      "239/239 [==============================] - 1s 2ms/step - loss: 0.6321 - accuracy: 0.7543 - val_loss: 0.6154 - val_accuracy: 0.7599\n",
      "Epoch 51/1000\n",
      "239/239 [==============================] - 1s 2ms/step - loss: 0.6336 - accuracy: 0.7531 - val_loss: 0.6159 - val_accuracy: 0.7588\n",
      "Epoch 52/1000\n",
      "239/239 [==============================] - 1s 2ms/step - loss: 0.6338 - accuracy: 0.7529 - val_loss: 0.6185 - val_accuracy: 0.7585\n",
      "Epoch 53/1000\n",
      "239/239 [==============================] - 1s 3ms/step - loss: 0.6325 - accuracy: 0.7543 - val_loss: 0.6155 - val_accuracy: 0.7606\n",
      "Epoch 54/1000\n",
      "239/239 [==============================] - 1s 2ms/step - loss: 0.6318 - accuracy: 0.7537 - val_loss: 0.6139 - val_accuracy: 0.7604\n",
      "Epoch 55/1000\n",
      "239/239 [==============================] - 1s 2ms/step - loss: 0.6316 - accuracy: 0.7538 - val_loss: 0.6159 - val_accuracy: 0.7607\n",
      "Epoch 56/1000\n",
      "239/239 [==============================] - 1s 2ms/step - loss: 0.6306 - accuracy: 0.7539 - val_loss: 0.6135 - val_accuracy: 0.7612\n",
      "Epoch 57/1000\n",
      "239/239 [==============================] - 1s 2ms/step - loss: 0.6309 - accuracy: 0.7542 - val_loss: 0.6126 - val_accuracy: 0.7605\n",
      "Epoch 58/1000\n",
      "239/239 [==============================] - 1s 2ms/step - loss: 0.6285 - accuracy: 0.7559 - val_loss: 0.6137 - val_accuracy: 0.7610\n",
      "Epoch 59/1000\n",
      "239/239 [==============================] - 1s 2ms/step - loss: 0.6295 - accuracy: 0.7548 - val_loss: 0.6130 - val_accuracy: 0.7611\n",
      "Epoch 60/1000\n",
      "239/239 [==============================] - 0s 2ms/step - loss: 0.6288 - accuracy: 0.7547 - val_loss: 0.6117 - val_accuracy: 0.7612\n",
      "Epoch 61/1000\n",
      "239/239 [==============================] - 0s 2ms/step - loss: 0.6289 - accuracy: 0.7546 - val_loss: 0.6102 - val_accuracy: 0.7616\n",
      "Epoch 62/1000\n",
      "239/239 [==============================] - 1s 2ms/step - loss: 0.6284 - accuracy: 0.7550 - val_loss: 0.6113 - val_accuracy: 0.7605\n",
      "Epoch 63/1000\n",
      "239/239 [==============================] - 1s 2ms/step - loss: 0.6277 - accuracy: 0.7552 - val_loss: 0.6122 - val_accuracy: 0.7571\n",
      "Epoch 64/1000\n",
      "239/239 [==============================] - 1s 2ms/step - loss: 0.6279 - accuracy: 0.7554 - val_loss: 0.6135 - val_accuracy: 0.7593\n",
      "Epoch 65/1000\n",
      "239/239 [==============================] - 1s 2ms/step - loss: 0.6274 - accuracy: 0.7561 - val_loss: 0.6131 - val_accuracy: 0.7598\n",
      "Epoch 66/1000\n",
      "239/239 [==============================] - 1s 2ms/step - loss: 0.6281 - accuracy: 0.7552 - val_loss: 0.6104 - val_accuracy: 0.7602\n",
      "Epoch 67/1000\n",
      "239/239 [==============================] - 1s 2ms/step - loss: 0.6279 - accuracy: 0.7557 - val_loss: 0.6111 - val_accuracy: 0.7613\n",
      "Epoch 68/1000\n",
      "239/239 [==============================] - 1s 2ms/step - loss: 0.6258 - accuracy: 0.7559 - val_loss: 0.6104 - val_accuracy: 0.7593\n",
      "Epoch 69/1000\n",
      "239/239 [==============================] - 1s 2ms/step - loss: 0.6252 - accuracy: 0.7569 - val_loss: 0.6096 - val_accuracy: 0.7598\n",
      "Epoch 70/1000\n",
      "239/239 [==============================] - 1s 2ms/step - loss: 0.6263 - accuracy: 0.7558 - val_loss: 0.6110 - val_accuracy: 0.7621\n",
      "Epoch 71/1000\n",
      "239/239 [==============================] - 1s 2ms/step - loss: 0.6259 - accuracy: 0.7553 - val_loss: 0.6091 - val_accuracy: 0.7634\n",
      "Epoch 72/1000\n",
      "239/239 [==============================] - 0s 2ms/step - loss: 0.6255 - accuracy: 0.7564 - val_loss: 0.6084 - val_accuracy: 0.7615\n",
      "Epoch 73/1000\n",
      "239/239 [==============================] - 1s 2ms/step - loss: 0.6263 - accuracy: 0.7561 - val_loss: 0.6106 - val_accuracy: 0.7618\n",
      "Epoch 74/1000\n",
      "239/239 [==============================] - 1s 2ms/step - loss: 0.6249 - accuracy: 0.7557 - val_loss: 0.6078 - val_accuracy: 0.7608\n",
      "Epoch 75/1000\n",
      "239/239 [==============================] - 0s 2ms/step - loss: 0.6235 - accuracy: 0.7564 - val_loss: 0.6076 - val_accuracy: 0.7603\n",
      "Epoch 76/1000\n",
      "239/239 [==============================] - 0s 2ms/step - loss: 0.6254 - accuracy: 0.7560 - val_loss: 0.6110 - val_accuracy: 0.7614\n",
      "Epoch 77/1000\n",
      "239/239 [==============================] - 0s 2ms/step - loss: 0.6240 - accuracy: 0.7555 - val_loss: 0.6069 - val_accuracy: 0.7626\n",
      "Epoch 78/1000\n",
      "239/239 [==============================] - 1s 2ms/step - loss: 0.6250 - accuracy: 0.7559 - val_loss: 0.6070 - val_accuracy: 0.7606\n",
      "Epoch 79/1000\n",
      "239/239 [==============================] - 1s 2ms/step - loss: 0.6246 - accuracy: 0.7562 - val_loss: 0.6098 - val_accuracy: 0.7634\n",
      "Epoch 80/1000\n",
      "239/239 [==============================] - 1s 2ms/step - loss: 0.6240 - accuracy: 0.7569 - val_loss: 0.6061 - val_accuracy: 0.7618\n",
      "Epoch 81/1000\n",
      "239/239 [==============================] - 1s 2ms/step - loss: 0.6238 - accuracy: 0.7564 - val_loss: 0.6059 - val_accuracy: 0.7624\n",
      "Epoch 82/1000\n",
      "239/239 [==============================] - 0s 2ms/step - loss: 0.6235 - accuracy: 0.7559 - val_loss: 0.6047 - val_accuracy: 0.7646\n",
      "Epoch 83/1000\n",
      "239/239 [==============================] - 1s 2ms/step - loss: 0.6233 - accuracy: 0.7570 - val_loss: 0.6061 - val_accuracy: 0.7625\n",
      "Epoch 84/1000\n",
      "239/239 [==============================] - 1s 2ms/step - loss: 0.6221 - accuracy: 0.7578 - val_loss: 0.6066 - val_accuracy: 0.7629\n",
      "Epoch 85/1000\n",
      "239/239 [==============================] - 0s 2ms/step - loss: 0.6217 - accuracy: 0.7567 - val_loss: 0.6031 - val_accuracy: 0.7628\n",
      "Epoch 86/1000\n",
      "239/239 [==============================] - 1s 2ms/step - loss: 0.6225 - accuracy: 0.7571 - val_loss: 0.6039 - val_accuracy: 0.7640\n",
      "Epoch 87/1000\n",
      "239/239 [==============================] - 1s 2ms/step - loss: 0.6206 - accuracy: 0.7570 - val_loss: 0.6038 - val_accuracy: 0.7639\n",
      "Epoch 88/1000\n",
      "239/239 [==============================] - 1s 2ms/step - loss: 0.6222 - accuracy: 0.7566 - val_loss: 0.6065 - val_accuracy: 0.7619\n",
      "Epoch 89/1000\n",
      "239/239 [==============================] - 1s 2ms/step - loss: 0.6226 - accuracy: 0.7562 - val_loss: 0.6041 - val_accuracy: 0.7634\n",
      "Epoch 90/1000\n",
      "239/239 [==============================] - 1s 2ms/step - loss: 0.6219 - accuracy: 0.7570 - val_loss: 0.6010 - val_accuracy: 0.7620\n",
      "Epoch 91/1000\n",
      "239/239 [==============================] - 1s 2ms/step - loss: 0.6207 - accuracy: 0.7582 - val_loss: 0.6057 - val_accuracy: 0.7608\n",
      "Epoch 92/1000\n",
      "239/239 [==============================] - 0s 2ms/step - loss: 0.6210 - accuracy: 0.7574 - val_loss: 0.6041 - val_accuracy: 0.7648\n",
      "Epoch 93/1000\n",
      "239/239 [==============================] - 1s 2ms/step - loss: 0.6207 - accuracy: 0.7572 - val_loss: 0.6044 - val_accuracy: 0.7625\n",
      "Epoch 94/1000\n",
      "239/239 [==============================] - 1s 2ms/step - loss: 0.6201 - accuracy: 0.7576 - val_loss: 0.6037 - val_accuracy: 0.7629\n",
      "Epoch 95/1000\n",
      "239/239 [==============================] - 1s 2ms/step - loss: 0.6203 - accuracy: 0.7574 - val_loss: 0.6019 - val_accuracy: 0.7629\n",
      "Epoch 96/1000\n",
      "239/239 [==============================] - 0s 2ms/step - loss: 0.6204 - accuracy: 0.7575 - val_loss: 0.6027 - val_accuracy: 0.7614\n",
      "Epoch 97/1000\n",
      "239/239 [==============================] - 1s 2ms/step - loss: 0.6194 - accuracy: 0.7575 - val_loss: 0.6053 - val_accuracy: 0.7628\n",
      "Epoch 98/1000\n",
      "239/239 [==============================] - 1s 3ms/step - loss: 0.6204 - accuracy: 0.7565 - val_loss: 0.6062 - val_accuracy: 0.7645\n",
      "Epoch 99/1000\n",
      "239/239 [==============================] - 1s 2ms/step - loss: 0.6203 - accuracy: 0.7572 - val_loss: 0.6038 - val_accuracy: 0.7644\n",
      "Epoch 100/1000\n",
      "239/239 [==============================] - 1s 2ms/step - loss: 0.6207 - accuracy: 0.7575 - val_loss: 0.6027 - val_accuracy: 0.7632\n",
      "Epoch 101/1000\n",
      "239/239 [==============================] - 1s 2ms/step - loss: 0.6184 - accuracy: 0.7580 - val_loss: 0.6010 - val_accuracy: 0.7651\n",
      "Epoch 102/1000\n",
      "239/239 [==============================] - 0s 2ms/step - loss: 0.6198 - accuracy: 0.7583 - val_loss: 0.6016 - val_accuracy: 0.7652\n",
      "Epoch 103/1000\n",
      "239/239 [==============================] - 1s 2ms/step - loss: 0.6189 - accuracy: 0.7587 - val_loss: 0.6020 - val_accuracy: 0.7647\n",
      "Epoch 104/1000\n",
      "239/239 [==============================] - 1s 2ms/step - loss: 0.6192 - accuracy: 0.7580 - val_loss: 0.6069 - val_accuracy: 0.7646\n",
      "Epoch 105/1000\n",
      "239/239 [==============================] - 1s 2ms/step - loss: 0.6192 - accuracy: 0.7576 - val_loss: 0.6006 - val_accuracy: 0.7651\n",
      "Epoch 106/1000\n",
      "239/239 [==============================] - 1s 2ms/step - loss: 0.6197 - accuracy: 0.7579 - val_loss: 0.6012 - val_accuracy: 0.7637\n",
      "Epoch 107/1000\n",
      "239/239 [==============================] - 1s 2ms/step - loss: 0.6185 - accuracy: 0.7582 - val_loss: 0.6025 - val_accuracy: 0.7638\n",
      "Epoch 108/1000\n",
      "239/239 [==============================] - 1s 2ms/step - loss: 0.6184 - accuracy: 0.7570 - val_loss: 0.6017 - val_accuracy: 0.7640\n",
      "Epoch 109/1000\n",
      "239/239 [==============================] - 1s 2ms/step - loss: 0.6181 - accuracy: 0.7579 - val_loss: 0.5995 - val_accuracy: 0.7657\n",
      "Epoch 110/1000\n",
      "239/239 [==============================] - 1s 2ms/step - loss: 0.6169 - accuracy: 0.7595 - val_loss: 0.6036 - val_accuracy: 0.7651\n",
      "Epoch 111/1000\n",
      "239/239 [==============================] - 0s 2ms/step - loss: 0.6190 - accuracy: 0.7584 - val_loss: 0.6012 - val_accuracy: 0.7659\n",
      "Epoch 112/1000\n",
      "239/239 [==============================] - 1s 2ms/step - loss: 0.6175 - accuracy: 0.7579 - val_loss: 0.6009 - val_accuracy: 0.7665\n",
      "Epoch 113/1000\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "239/239 [==============================] - 1s 2ms/step - loss: 0.6181 - accuracy: 0.7582 - val_loss: 0.6001 - val_accuracy: 0.7668\n",
      "Epoch 114/1000\n",
      "239/239 [==============================] - 0s 2ms/step - loss: 0.6176 - accuracy: 0.7587 - val_loss: 0.6002 - val_accuracy: 0.7655\n",
      "Epoch 115/1000\n",
      "239/239 [==============================] - 0s 2ms/step - loss: 0.6175 - accuracy: 0.7586 - val_loss: 0.6027 - val_accuracy: 0.7657\n",
      "Epoch 116/1000\n",
      "239/239 [==============================] - 1s 2ms/step - loss: 0.6173 - accuracy: 0.7595 - val_loss: 0.5982 - val_accuracy: 0.7671\n",
      "Epoch 117/1000\n",
      "239/239 [==============================] - 0s 2ms/step - loss: 0.6161 - accuracy: 0.7595 - val_loss: 0.6009 - val_accuracy: 0.7643\n",
      "Epoch 118/1000\n",
      "239/239 [==============================] - 0s 2ms/step - loss: 0.6155 - accuracy: 0.7597 - val_loss: 0.5999 - val_accuracy: 0.7668\n",
      "Epoch 119/1000\n",
      "239/239 [==============================] - 1s 2ms/step - loss: 0.6168 - accuracy: 0.7583 - val_loss: 0.5978 - val_accuracy: 0.7654\n",
      "Epoch 120/1000\n",
      "239/239 [==============================] - 1s 2ms/step - loss: 0.6161 - accuracy: 0.7587 - val_loss: 0.5987 - val_accuracy: 0.7643\n",
      "Epoch 121/1000\n",
      "239/239 [==============================] - 1s 2ms/step - loss: 0.6156 - accuracy: 0.7596 - val_loss: 0.5986 - val_accuracy: 0.7659\n",
      "Epoch 122/1000\n",
      "239/239 [==============================] - 1s 2ms/step - loss: 0.6154 - accuracy: 0.7597 - val_loss: 0.5984 - val_accuracy: 0.7655\n",
      "Epoch 123/1000\n",
      "239/239 [==============================] - 1s 2ms/step - loss: 0.6175 - accuracy: 0.7597 - val_loss: 0.5979 - val_accuracy: 0.7655\n",
      "Epoch 124/1000\n",
      "239/239 [==============================] - 1s 2ms/step - loss: 0.6157 - accuracy: 0.7583 - val_loss: 0.6030 - val_accuracy: 0.7673\n",
      "Epoch 125/1000\n",
      "239/239 [==============================] - 1s 2ms/step - loss: 0.6150 - accuracy: 0.7594 - val_loss: 0.5992 - val_accuracy: 0.7673\n",
      "Epoch 126/1000\n",
      "239/239 [==============================] - 1s 2ms/step - loss: 0.6146 - accuracy: 0.7606 - val_loss: 0.6012 - val_accuracy: 0.7675\n",
      "Epoch 127/1000\n",
      "239/239 [==============================] - 1s 2ms/step - loss: 0.6168 - accuracy: 0.7585 - val_loss: 0.5982 - val_accuracy: 0.7655\n",
      "Epoch 128/1000\n",
      "239/239 [==============================] - 1s 2ms/step - loss: 0.6156 - accuracy: 0.7594 - val_loss: 0.5981 - val_accuracy: 0.7682\n",
      "Epoch 129/1000\n",
      "239/239 [==============================] - 0s 2ms/step - loss: 0.6148 - accuracy: 0.7595 - val_loss: 0.6012 - val_accuracy: 0.7662\n",
      "Epoch 130/1000\n",
      "239/239 [==============================] - 0s 2ms/step - loss: 0.6154 - accuracy: 0.7591 - val_loss: 0.5979 - val_accuracy: 0.7680\n",
      "Epoch 131/1000\n",
      "239/239 [==============================] - 1s 3ms/step - loss: 0.6154 - accuracy: 0.7595 - val_loss: 0.5985 - val_accuracy: 0.7678\n",
      "Epoch 132/1000\n",
      "239/239 [==============================] - 1s 2ms/step - loss: 0.6152 - accuracy: 0.7593 - val_loss: 0.5987 - val_accuracy: 0.7684\n",
      "Epoch 133/1000\n",
      "239/239 [==============================] - 1s 2ms/step - loss: 0.6144 - accuracy: 0.7603 - val_loss: 0.6002 - val_accuracy: 0.7666\n",
      "Epoch 134/1000\n",
      "239/239 [==============================] - 1s 2ms/step - loss: 0.6153 - accuracy: 0.7584 - val_loss: 0.6012 - val_accuracy: 0.7671\n",
      "Epoch 135/1000\n",
      "239/239 [==============================] - 1s 2ms/step - loss: 0.6144 - accuracy: 0.7596 - val_loss: 0.6014 - val_accuracy: 0.7665\n",
      "Epoch 136/1000\n",
      "239/239 [==============================] - 0s 2ms/step - loss: 0.6151 - accuracy: 0.7591 - val_loss: 0.5996 - val_accuracy: 0.7656\n",
      "Epoch 137/1000\n",
      "239/239 [==============================] - 1s 2ms/step - loss: 0.6152 - accuracy: 0.7591 - val_loss: 0.6024 - val_accuracy: 0.7675\n",
      "Epoch 138/1000\n",
      "239/239 [==============================] - 1s 3ms/step - loss: 0.6155 - accuracy: 0.7590 - val_loss: 0.5990 - val_accuracy: 0.7660\n",
      "Epoch 139/1000\n",
      "239/239 [==============================] - 1s 2ms/step - loss: 0.6149 - accuracy: 0.7587 - val_loss: 0.6017 - val_accuracy: 0.7667\n",
      "Epoch 140/1000\n",
      "239/239 [==============================] - 1s 2ms/step - loss: 0.6146 - accuracy: 0.7598 - val_loss: 0.5968 - val_accuracy: 0.7685\n",
      "Epoch 141/1000\n",
      "239/239 [==============================] - 1s 2ms/step - loss: 0.6131 - accuracy: 0.7600 - val_loss: 0.5970 - val_accuracy: 0.7668\n",
      "Epoch 142/1000\n",
      "239/239 [==============================] - 1s 2ms/step - loss: 0.6135 - accuracy: 0.7602 - val_loss: 0.5968 - val_accuracy: 0.7673\n",
      "Epoch 143/1000\n",
      "239/239 [==============================] - 1s 2ms/step - loss: 0.6140 - accuracy: 0.7599 - val_loss: 0.5976 - val_accuracy: 0.7677\n",
      "Epoch 144/1000\n",
      "239/239 [==============================] - 1s 2ms/step - loss: 0.6137 - accuracy: 0.7596 - val_loss: 0.5985 - val_accuracy: 0.7667\n",
      "Epoch 145/1000\n",
      "239/239 [==============================] - 1s 2ms/step - loss: 0.6125 - accuracy: 0.7605 - val_loss: 0.5998 - val_accuracy: 0.7660\n",
      "Epoch 146/1000\n",
      "239/239 [==============================] - 1s 2ms/step - loss: 0.6128 - accuracy: 0.7604 - val_loss: 0.5977 - val_accuracy: 0.7670\n",
      "Epoch 147/1000\n",
      "239/239 [==============================] - 1s 2ms/step - loss: 0.6145 - accuracy: 0.7602 - val_loss: 0.5978 - val_accuracy: 0.7686\n",
      "Epoch 148/1000\n",
      "239/239 [==============================] - 0s 2ms/step - loss: 0.6126 - accuracy: 0.7604 - val_loss: 0.5957 - val_accuracy: 0.7689\n",
      "Epoch 149/1000\n",
      "239/239 [==============================] - 0s 2ms/step - loss: 0.6126 - accuracy: 0.7596 - val_loss: 0.5960 - val_accuracy: 0.7673\n",
      "Epoch 150/1000\n",
      "239/239 [==============================] - 0s 2ms/step - loss: 0.6132 - accuracy: 0.7603 - val_loss: 0.5999 - val_accuracy: 0.7681\n",
      "Epoch 151/1000\n",
      "239/239 [==============================] - 1s 2ms/step - loss: 0.6118 - accuracy: 0.7605 - val_loss: 0.5933 - val_accuracy: 0.7674\n",
      "Epoch 152/1000\n",
      "239/239 [==============================] - 1s 2ms/step - loss: 0.6114 - accuracy: 0.7614 - val_loss: 0.6001 - val_accuracy: 0.7664\n",
      "Epoch 153/1000\n",
      "239/239 [==============================] - 1s 2ms/step - loss: 0.6126 - accuracy: 0.7609 - val_loss: 0.5935 - val_accuracy: 0.7668\n",
      "Epoch 154/1000\n",
      "239/239 [==============================] - 1s 2ms/step - loss: 0.6119 - accuracy: 0.7601 - val_loss: 0.5966 - val_accuracy: 0.7677\n",
      "Epoch 155/1000\n",
      "239/239 [==============================] - 1s 2ms/step - loss: 0.6135 - accuracy: 0.7602 - val_loss: 0.5972 - val_accuracy: 0.7688\n",
      "Epoch 156/1000\n",
      "239/239 [==============================] - 1s 2ms/step - loss: 0.6117 - accuracy: 0.7606 - val_loss: 0.5967 - val_accuracy: 0.7691\n",
      "Epoch 157/1000\n",
      "239/239 [==============================] - 1s 2ms/step - loss: 0.6116 - accuracy: 0.7609 - val_loss: 0.5932 - val_accuracy: 0.7696\n",
      "Epoch 158/1000\n",
      "239/239 [==============================] - 1s 3ms/step - loss: 0.6104 - accuracy: 0.7619 - val_loss: 0.5935 - val_accuracy: 0.7679\n",
      "Epoch 159/1000\n",
      "239/239 [==============================] - 1s 3ms/step - loss: 0.6125 - accuracy: 0.7601 - val_loss: 0.5954 - val_accuracy: 0.7687\n",
      "Epoch 160/1000\n",
      "239/239 [==============================] - 1s 2ms/step - loss: 0.6105 - accuracy: 0.7611 - val_loss: 0.5932 - val_accuracy: 0.7678\n",
      "Epoch 161/1000\n",
      "239/239 [==============================] - 1s 2ms/step - loss: 0.6112 - accuracy: 0.7598 - val_loss: 0.5941 - val_accuracy: 0.7677\n",
      "Epoch 162/1000\n",
      "239/239 [==============================] - 1s 2ms/step - loss: 0.6113 - accuracy: 0.7610 - val_loss: 0.5959 - val_accuracy: 0.7685\n",
      "Epoch 163/1000\n",
      "239/239 [==============================] - 1s 2ms/step - loss: 0.6115 - accuracy: 0.7605 - val_loss: 0.5949 - val_accuracy: 0.7691\n",
      "Epoch 164/1000\n",
      "239/239 [==============================] - 1s 2ms/step - loss: 0.6118 - accuracy: 0.7598 - val_loss: 0.5969 - val_accuracy: 0.7672\n",
      "Epoch 165/1000\n",
      "239/239 [==============================] - 1s 2ms/step - loss: 0.6102 - accuracy: 0.7614 - val_loss: 0.5933 - val_accuracy: 0.7685\n",
      "Epoch 166/1000\n",
      "239/239 [==============================] - 1s 2ms/step - loss: 0.6117 - accuracy: 0.7604 - val_loss: 0.5925 - val_accuracy: 0.7685\n",
      "Epoch 167/1000\n",
      "239/239 [==============================] - 1s 2ms/step - loss: 0.6104 - accuracy: 0.7615 - val_loss: 0.5944 - val_accuracy: 0.7677\n",
      "Epoch 168/1000\n",
      "239/239 [==============================] - 1s 2ms/step - loss: 0.6113 - accuracy: 0.7608 - val_loss: 0.5977 - val_accuracy: 0.7691\n",
      "Epoch 169/1000\n",
      "239/239 [==============================] - 1s 2ms/step - loss: 0.6125 - accuracy: 0.7602 - val_loss: 0.6009 - val_accuracy: 0.7677\n",
      "Epoch 170/1000\n",
      "239/239 [==============================] - 1s 2ms/step - loss: 0.6104 - accuracy: 0.7607 - val_loss: 0.5969 - val_accuracy: 0.7666\n",
      "Epoch 171/1000\n",
      "239/239 [==============================] - 1s 2ms/step - loss: 0.6106 - accuracy: 0.7617 - val_loss: 0.5967 - val_accuracy: 0.7672\n",
      "Epoch 172/1000\n",
      "239/239 [==============================] - 0s 2ms/step - loss: 0.6096 - accuracy: 0.7613 - val_loss: 0.5930 - val_accuracy: 0.7700\n",
      "Epoch 173/1000\n",
      "239/239 [==============================] - 0s 2ms/step - loss: 0.6092 - accuracy: 0.7626 - val_loss: 0.5922 - val_accuracy: 0.7681\n",
      "Epoch 174/1000\n",
      "239/239 [==============================] - 0s 2ms/step - loss: 0.6102 - accuracy: 0.7617 - val_loss: 0.5960 - val_accuracy: 0.7696\n",
      "Epoch 175/1000\n",
      "239/239 [==============================] - 0s 2ms/step - loss: 0.6110 - accuracy: 0.7618 - val_loss: 0.5945 - val_accuracy: 0.7682\n",
      "Epoch 176/1000\n",
      "239/239 [==============================] - 0s 2ms/step - loss: 0.6097 - accuracy: 0.7612 - val_loss: 0.5908 - val_accuracy: 0.7679\n",
      "Epoch 177/1000\n",
      "239/239 [==============================] - 1s 2ms/step - loss: 0.6104 - accuracy: 0.7620 - val_loss: 0.5960 - val_accuracy: 0.7674\n",
      "Epoch 178/1000\n",
      "239/239 [==============================] - 0s 2ms/step - loss: 0.6110 - accuracy: 0.7605 - val_loss: 0.5920 - val_accuracy: 0.7692\n",
      "Epoch 179/1000\n",
      "239/239 [==============================] - 1s 2ms/step - loss: 0.6090 - accuracy: 0.7622 - val_loss: 0.5985 - val_accuracy: 0.7684\n",
      "Epoch 180/1000\n",
      "239/239 [==============================] - 1s 2ms/step - loss: 0.6117 - accuracy: 0.7605 - val_loss: 0.5952 - val_accuracy: 0.7682\n",
      "Epoch 181/1000\n",
      "239/239 [==============================] - 1s 2ms/step - loss: 0.6098 - accuracy: 0.7615 - val_loss: 0.5945 - val_accuracy: 0.7699\n",
      "Epoch 182/1000\n",
      "239/239 [==============================] - 1s 2ms/step - loss: 0.6095 - accuracy: 0.7618 - val_loss: 0.5929 - val_accuracy: 0.7689\n",
      "Epoch 183/1000\n",
      "239/239 [==============================] - 1s 2ms/step - loss: 0.6112 - accuracy: 0.7610 - val_loss: 0.5955 - val_accuracy: 0.7696\n",
      "Epoch 184/1000\n",
      "239/239 [==============================] - 1s 2ms/step - loss: 0.6101 - accuracy: 0.7613 - val_loss: 0.5957 - val_accuracy: 0.7700\n",
      "Epoch 185/1000\n",
      "239/239 [==============================] - 0s 2ms/step - loss: 0.6077 - accuracy: 0.7620 - val_loss: 0.5944 - val_accuracy: 0.7700\n",
      "Epoch 186/1000\n",
      "239/239 [==============================] - 1s 2ms/step - loss: 0.6106 - accuracy: 0.7604 - val_loss: 0.5937 - val_accuracy: 0.7699\n",
      "Epoch 187/1000\n",
      "239/239 [==============================] - 1s 2ms/step - loss: 0.6079 - accuracy: 0.7622 - val_loss: 0.5926 - val_accuracy: 0.7682\n",
      "Epoch 188/1000\n",
      "239/239 [==============================] - 1s 2ms/step - loss: 0.6098 - accuracy: 0.7618 - val_loss: 0.5959 - val_accuracy: 0.7671\n",
      "Epoch 189/1000\n",
      "239/239 [==============================] - 1s 2ms/step - loss: 0.6082 - accuracy: 0.7614 - val_loss: 0.5953 - val_accuracy: 0.7672\n",
      "Epoch 190/1000\n",
      "239/239 [==============================] - 1s 2ms/step - loss: 0.6088 - accuracy: 0.7608 - val_loss: 0.5926 - val_accuracy: 0.7688\n",
      "Epoch 191/1000\n",
      "239/239 [==============================] - 1s 2ms/step - loss: 0.6107 - accuracy: 0.7610 - val_loss: 0.5943 - val_accuracy: 0.7690\n",
      "Epoch 192/1000\n",
      "239/239 [==============================] - 1s 2ms/step - loss: 0.6086 - accuracy: 0.7619 - val_loss: 0.5944 - val_accuracy: 0.7669\n",
      "Epoch 193/1000\n",
      "239/239 [==============================] - 1s 2ms/step - loss: 0.6079 - accuracy: 0.7612 - val_loss: 0.5951 - val_accuracy: 0.7686\n",
      "Epoch 194/1000\n",
      "239/239 [==============================] - 0s 2ms/step - loss: 0.6081 - accuracy: 0.7628 - val_loss: 0.5946 - val_accuracy: 0.7702\n",
      "Epoch 195/1000\n",
      "239/239 [==============================] - 1s 2ms/step - loss: 0.6087 - accuracy: 0.7615 - val_loss: 0.5935 - val_accuracy: 0.7703\n",
      "Epoch 196/1000\n",
      "239/239 [==============================] - 1s 2ms/step - loss: 0.6086 - accuracy: 0.7620 - val_loss: 0.5944 - val_accuracy: 0.7691\n",
      "Epoch 197/1000\n",
      "239/239 [==============================] - 1s 2ms/step - loss: 0.6085 - accuracy: 0.7618 - val_loss: 0.5948 - val_accuracy: 0.7699\n",
      "Epoch 198/1000\n",
      "239/239 [==============================] - 1s 2ms/step - loss: 0.6093 - accuracy: 0.7618 - val_loss: 0.5936 - val_accuracy: 0.7692\n",
      "Epoch 199/1000\n",
      "239/239 [==============================] - 0s 2ms/step - loss: 0.6087 - accuracy: 0.7617 - val_loss: 0.5938 - val_accuracy: 0.7688\n",
      "Epoch 200/1000\n",
      "239/239 [==============================] - 1s 2ms/step - loss: 0.6092 - accuracy: 0.7623 - val_loss: 0.5934 - val_accuracy: 0.7688\n",
      "Epoch 201/1000\n",
      "239/239 [==============================] - 1s 2ms/step - loss: 0.6094 - accuracy: 0.7622 - val_loss: 0.5939 - val_accuracy: 0.7676\n",
      "Epoch 202/1000\n",
      "239/239 [==============================] - 1s 2ms/step - loss: 0.6085 - accuracy: 0.7618 - val_loss: 0.5939 - val_accuracy: 0.7679\n",
      "Epoch 203/1000\n",
      "239/239 [==============================] - 0s 2ms/step - loss: 0.6074 - accuracy: 0.7617 - val_loss: 0.5926 - val_accuracy: 0.7685\n",
      "Epoch 204/1000\n",
      "239/239 [==============================] - 0s 2ms/step - loss: 0.6077 - accuracy: 0.7626 - val_loss: 0.5932 - val_accuracy: 0.7692\n",
      "Epoch 205/1000\n",
      "239/239 [==============================] - 0s 2ms/step - loss: 0.6084 - accuracy: 0.7617 - val_loss: 0.5940 - val_accuracy: 0.7687\n",
      "Epoch 206/1000\n",
      "239/239 [==============================] - 1s 2ms/step - loss: 0.6083 - accuracy: 0.7606 - val_loss: 0.5931 - val_accuracy: 0.7693\n",
      "Epoch 207/1000\n",
      "239/239 [==============================] - 1s 2ms/step - loss: 0.6069 - accuracy: 0.7626 - val_loss: 0.5950 - val_accuracy: 0.7688\n",
      "Epoch 208/1000\n",
      "239/239 [==============================] - 1s 2ms/step - loss: 0.6064 - accuracy: 0.7624 - val_loss: 0.5940 - val_accuracy: 0.7698\n",
      "Epoch 209/1000\n",
      "239/239 [==============================] - 1s 2ms/step - loss: 0.6079 - accuracy: 0.7623 - val_loss: 0.5911 - val_accuracy: 0.7678\n",
      "Epoch 210/1000\n",
      "239/239 [==============================] - 0s 2ms/step - loss: 0.6073 - accuracy: 0.7625 - val_loss: 0.5928 - val_accuracy: 0.7691\n",
      "Epoch 211/1000\n",
      "239/239 [==============================] - 0s 2ms/step - loss: 0.6078 - accuracy: 0.7624 - val_loss: 0.5911 - val_accuracy: 0.7679\n",
      "Epoch 212/1000\n",
      "239/239 [==============================] - 0s 2ms/step - loss: 0.6070 - accuracy: 0.7617 - val_loss: 0.5951 - val_accuracy: 0.7697\n",
      "Epoch 213/1000\n",
      "239/239 [==============================] - 0s 2ms/step - loss: 0.6067 - accuracy: 0.7621 - val_loss: 0.5920 - val_accuracy: 0.7694\n",
      "Epoch 214/1000\n",
      "239/239 [==============================] - 1s 2ms/step - loss: 0.6063 - accuracy: 0.7633 - val_loss: 0.5921 - val_accuracy: 0.7700\n",
      "Epoch 215/1000\n",
      "239/239 [==============================] - 1s 2ms/step - loss: 0.6074 - accuracy: 0.7617 - val_loss: 0.5909 - val_accuracy: 0.7701\n",
      "Epoch 216/1000\n",
      "239/239 [==============================] - 1s 2ms/step - loss: 0.6080 - accuracy: 0.7618 - val_loss: 0.5947 - val_accuracy: 0.7691\n",
      "Epoch 217/1000\n",
      "239/239 [==============================] - 1s 2ms/step - loss: 0.6077 - accuracy: 0.7629 - val_loss: 0.5944 - val_accuracy: 0.7688\n",
      "Epoch 218/1000\n",
      "239/239 [==============================] - 1s 2ms/step - loss: 0.6069 - accuracy: 0.7625 - val_loss: 0.5913 - val_accuracy: 0.7701\n",
      "Epoch 219/1000\n",
      "239/239 [==============================] - 1s 2ms/step - loss: 0.6087 - accuracy: 0.7613 - val_loss: 0.5917 - val_accuracy: 0.7697\n",
      "Epoch 220/1000\n",
      "239/239 [==============================] - 1s 2ms/step - loss: 0.6055 - accuracy: 0.7624 - val_loss: 0.5939 - val_accuracy: 0.7686\n",
      "Epoch 221/1000\n",
      "239/239 [==============================] - 0s 2ms/step - loss: 0.6071 - accuracy: 0.7625 - val_loss: 0.5953 - val_accuracy: 0.7705\n",
      "Epoch 222/1000\n",
      "239/239 [==============================] - 1s 2ms/step - loss: 0.6080 - accuracy: 0.7628 - val_loss: 0.5912 - val_accuracy: 0.7694\n",
      "Epoch 223/1000\n",
      "239/239 [==============================] - 1s 2ms/step - loss: 0.6069 - accuracy: 0.7626 - val_loss: 0.5953 - val_accuracy: 0.7699\n",
      "Epoch 224/1000\n",
      "239/239 [==============================] - 0s 2ms/step - loss: 0.6075 - accuracy: 0.7619 - val_loss: 0.5920 - val_accuracy: 0.7685\n",
      "Epoch 225/1000\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "239/239 [==============================] - 1s 2ms/step - loss: 0.6061 - accuracy: 0.7631 - val_loss: 0.5929 - val_accuracy: 0.7704\n",
      "Epoch 226/1000\n",
      "239/239 [==============================] - 1s 2ms/step - loss: 0.6064 - accuracy: 0.7626 - val_loss: 0.5904 - val_accuracy: 0.7699\n",
      "Epoch 227/1000\n",
      "239/239 [==============================] - 1s 2ms/step - loss: 0.6076 - accuracy: 0.7624 - val_loss: 0.5945 - val_accuracy: 0.7701\n",
      "Epoch 228/1000\n",
      "239/239 [==============================] - 1s 2ms/step - loss: 0.6055 - accuracy: 0.7623 - val_loss: 0.5926 - val_accuracy: 0.7705\n",
      "Epoch 229/1000\n",
      "239/239 [==============================] - 1s 2ms/step - loss: 0.6061 - accuracy: 0.7635 - val_loss: 0.5917 - val_accuracy: 0.7710\n",
      "Epoch 230/1000\n",
      "239/239 [==============================] - 1s 2ms/step - loss: 0.6075 - accuracy: 0.7618 - val_loss: 0.5898 - val_accuracy: 0.7702\n",
      "Epoch 231/1000\n",
      "239/239 [==============================] - 1s 2ms/step - loss: 0.6068 - accuracy: 0.7628 - val_loss: 0.5921 - val_accuracy: 0.7688\n",
      "Epoch 232/1000\n",
      "239/239 [==============================] - 1s 3ms/step - loss: 0.6065 - accuracy: 0.7620 - val_loss: 0.5952 - val_accuracy: 0.7703\n",
      "Epoch 233/1000\n",
      "239/239 [==============================] - 0s 2ms/step - loss: 0.6074 - accuracy: 0.7625 - val_loss: 0.5933 - val_accuracy: 0.7710\n",
      "Epoch 234/1000\n",
      "239/239 [==============================] - 1s 2ms/step - loss: 0.6061 - accuracy: 0.7630 - val_loss: 0.5883 - val_accuracy: 0.7702\n",
      "Epoch 235/1000\n",
      "239/239 [==============================] - 1s 2ms/step - loss: 0.6055 - accuracy: 0.7638 - val_loss: 0.5886 - val_accuracy: 0.7710\n",
      "Epoch 236/1000\n",
      "239/239 [==============================] - 1s 2ms/step - loss: 0.6075 - accuracy: 0.7617 - val_loss: 0.5927 - val_accuracy: 0.7713\n",
      "Epoch 237/1000\n",
      "239/239 [==============================] - 1s 2ms/step - loss: 0.6056 - accuracy: 0.7627 - val_loss: 0.5904 - val_accuracy: 0.7678\n",
      "Epoch 238/1000\n",
      "239/239 [==============================] - 1s 2ms/step - loss: 0.6060 - accuracy: 0.7633 - val_loss: 0.5904 - val_accuracy: 0.7689\n",
      "Epoch 239/1000\n",
      "239/239 [==============================] - 1s 2ms/step - loss: 0.6071 - accuracy: 0.7629 - val_loss: 0.5925 - val_accuracy: 0.7699\n",
      "Epoch 240/1000\n",
      "239/239 [==============================] - 1s 2ms/step - loss: 0.6056 - accuracy: 0.7625 - val_loss: 0.5927 - val_accuracy: 0.7696\n",
      "Epoch 241/1000\n",
      "239/239 [==============================] - 1s 2ms/step - loss: 0.6065 - accuracy: 0.7621 - val_loss: 0.5887 - val_accuracy: 0.7699\n",
      "Epoch 242/1000\n",
      "239/239 [==============================] - 1s 2ms/step - loss: 0.6067 - accuracy: 0.7617 - val_loss: 0.5915 - val_accuracy: 0.7693\n",
      "Epoch 243/1000\n",
      "239/239 [==============================] - 0s 2ms/step - loss: 0.6071 - accuracy: 0.7623 - val_loss: 0.5935 - val_accuracy: 0.7705\n",
      "Epoch 244/1000\n",
      "239/239 [==============================] - 1s 2ms/step - loss: 0.6054 - accuracy: 0.7626 - val_loss: 0.5924 - val_accuracy: 0.7693\n",
      "Epoch 245/1000\n",
      "239/239 [==============================] - 1s 2ms/step - loss: 0.6066 - accuracy: 0.7629 - val_loss: 0.5924 - val_accuracy: 0.7704\n",
      "Epoch 246/1000\n",
      "239/239 [==============================] - 1s 2ms/step - loss: 0.6051 - accuracy: 0.7631 - val_loss: 0.5877 - val_accuracy: 0.7716\n",
      "Epoch 247/1000\n",
      "239/239 [==============================] - 1s 2ms/step - loss: 0.6063 - accuracy: 0.7623 - val_loss: 0.5900 - val_accuracy: 0.7720\n",
      "Epoch 248/1000\n",
      "239/239 [==============================] - 1s 2ms/step - loss: 0.6049 - accuracy: 0.7629 - val_loss: 0.5950 - val_accuracy: 0.7705\n",
      "Epoch 249/1000\n",
      "239/239 [==============================] - 1s 2ms/step - loss: 0.6057 - accuracy: 0.7631 - val_loss: 0.5940 - val_accuracy: 0.7707\n",
      "Epoch 250/1000\n",
      "239/239 [==============================] - 1s 3ms/step - loss: 0.6055 - accuracy: 0.7629 - val_loss: 0.5914 - val_accuracy: 0.7703\n",
      "Epoch 251/1000\n",
      "239/239 [==============================] - 1s 3ms/step - loss: 0.6059 - accuracy: 0.7625 - val_loss: 0.5925 - val_accuracy: 0.7691\n",
      "Epoch 252/1000\n",
      "239/239 [==============================] - 1s 2ms/step - loss: 0.6052 - accuracy: 0.7630 - val_loss: 0.5928 - val_accuracy: 0.7698\n",
      "Epoch 253/1000\n",
      "239/239 [==============================] - 1s 2ms/step - loss: 0.6070 - accuracy: 0.7620 - val_loss: 0.5870 - val_accuracy: 0.7716\n",
      "Epoch 254/1000\n",
      "239/239 [==============================] - 1s 2ms/step - loss: 0.6062 - accuracy: 0.7625 - val_loss: 0.5931 - val_accuracy: 0.7702\n",
      "Epoch 255/1000\n",
      "239/239 [==============================] - 1s 2ms/step - loss: 0.6038 - accuracy: 0.7637 - val_loss: 0.5939 - val_accuracy: 0.7702\n",
      "Epoch 256/1000\n",
      "239/239 [==============================] - 1s 2ms/step - loss: 0.6054 - accuracy: 0.7631 - val_loss: 0.5886 - val_accuracy: 0.7709\n",
      "Epoch 257/1000\n",
      "239/239 [==============================] - 1s 2ms/step - loss: 0.6056 - accuracy: 0.7619 - val_loss: 0.5931 - val_accuracy: 0.7696\n",
      "Epoch 258/1000\n",
      "239/239 [==============================] - 1s 2ms/step - loss: 0.6050 - accuracy: 0.7630 - val_loss: 0.5897 - val_accuracy: 0.7693\n",
      "Epoch 259/1000\n",
      "239/239 [==============================] - 1s 2ms/step - loss: 0.6058 - accuracy: 0.7624 - val_loss: 0.5918 - val_accuracy: 0.7692\n",
      "Epoch 260/1000\n",
      "239/239 [==============================] - 1s 2ms/step - loss: 0.6049 - accuracy: 0.7636 - val_loss: 0.5932 - val_accuracy: 0.7696\n",
      "Epoch 261/1000\n",
      "239/239 [==============================] - 1s 2ms/step - loss: 0.6040 - accuracy: 0.7622 - val_loss: 0.5974 - val_accuracy: 0.7705\n",
      "Epoch 262/1000\n",
      "239/239 [==============================] - 1s 2ms/step - loss: 0.6050 - accuracy: 0.7631 - val_loss: 0.5903 - val_accuracy: 0.7697\n",
      "Epoch 263/1000\n",
      "239/239 [==============================] - 1s 2ms/step - loss: 0.6043 - accuracy: 0.7630 - val_loss: 0.5899 - val_accuracy: 0.7719\n",
      "Epoch 264/1000\n",
      "239/239 [==============================] - 1s 2ms/step - loss: 0.6046 - accuracy: 0.7630 - val_loss: 0.5875 - val_accuracy: 0.7703\n",
      "Epoch 265/1000\n",
      "239/239 [==============================] - 1s 2ms/step - loss: 0.6042 - accuracy: 0.7623 - val_loss: 0.5928 - val_accuracy: 0.7716\n",
      "Epoch 266/1000\n",
      "239/239 [==============================] - 1s 2ms/step - loss: 0.6039 - accuracy: 0.7631 - val_loss: 0.5862 - val_accuracy: 0.7719\n",
      "Epoch 267/1000\n",
      "239/239 [==============================] - 1s 2ms/step - loss: 0.6050 - accuracy: 0.7626 - val_loss: 0.5885 - val_accuracy: 0.7690\n",
      "Epoch 268/1000\n",
      "239/239 [==============================] - 1s 2ms/step - loss: 0.6049 - accuracy: 0.7630 - val_loss: 0.5922 - val_accuracy: 0.7702\n",
      "Epoch 269/1000\n",
      "239/239 [==============================] - 1s 2ms/step - loss: 0.6057 - accuracy: 0.7630 - val_loss: 0.5954 - val_accuracy: 0.7724\n",
      "Epoch 270/1000\n",
      "239/239 [==============================] - 1s 3ms/step - loss: 0.6035 - accuracy: 0.7633 - val_loss: 0.5928 - val_accuracy: 0.7718\n",
      "Epoch 271/1000\n",
      "239/239 [==============================] - 1s 2ms/step - loss: 0.6037 - accuracy: 0.7640 - val_loss: 0.5913 - val_accuracy: 0.7704\n",
      "Epoch 272/1000\n",
      "239/239 [==============================] - 1s 2ms/step - loss: 0.6039 - accuracy: 0.7639 - val_loss: 0.5921 - val_accuracy: 0.7705\n",
      "Epoch 273/1000\n",
      "239/239 [==============================] - 1s 2ms/step - loss: 0.6050 - accuracy: 0.7630 - val_loss: 0.5888 - val_accuracy: 0.7721\n",
      "Epoch 274/1000\n",
      "239/239 [==============================] - 1s 2ms/step - loss: 0.6042 - accuracy: 0.7639 - val_loss: 0.5899 - val_accuracy: 0.7719\n",
      "Epoch 275/1000\n",
      "239/239 [==============================] - 1s 2ms/step - loss: 0.6029 - accuracy: 0.7633 - val_loss: 0.5895 - val_accuracy: 0.7711\n",
      "Epoch 276/1000\n",
      "239/239 [==============================] - 1s 2ms/step - loss: 0.6048 - accuracy: 0.7631 - val_loss: 0.5894 - val_accuracy: 0.7710\n",
      "Epoch 277/1000\n",
      "239/239 [==============================] - 1s 2ms/step - loss: 0.6058 - accuracy: 0.7638 - val_loss: 0.5905 - val_accuracy: 0.7723\n",
      "Epoch 278/1000\n",
      "239/239 [==============================] - 1s 2ms/step - loss: 0.6038 - accuracy: 0.7630 - val_loss: 0.5882 - val_accuracy: 0.7705\n",
      "Epoch 279/1000\n",
      "239/239 [==============================] - 1s 2ms/step - loss: 0.6037 - accuracy: 0.7629 - val_loss: 0.5884 - val_accuracy: 0.7710\n",
      "Epoch 280/1000\n",
      "239/239 [==============================] - 1s 2ms/step - loss: 0.6033 - accuracy: 0.7635 - val_loss: 0.5911 - val_accuracy: 0.7722\n",
      "Epoch 281/1000\n",
      "239/239 [==============================] - 1s 3ms/step - loss: 0.6041 - accuracy: 0.7636 - val_loss: 0.5908 - val_accuracy: 0.7713\n",
      "Epoch 282/1000\n",
      "239/239 [==============================] - 1s 2ms/step - loss: 0.6031 - accuracy: 0.7639 - val_loss: 0.5918 - val_accuracy: 0.7694\n",
      "Epoch 283/1000\n",
      "239/239 [==============================] - 0s 2ms/step - loss: 0.6047 - accuracy: 0.7630 - val_loss: 0.5937 - val_accuracy: 0.7696\n",
      "Epoch 284/1000\n",
      "239/239 [==============================] - 1s 2ms/step - loss: 0.6040 - accuracy: 0.7642 - val_loss: 0.5913 - val_accuracy: 0.7722\n",
      "Epoch 285/1000\n",
      "239/239 [==============================] - 1s 2ms/step - loss: 0.6031 - accuracy: 0.7636 - val_loss: 0.5897 - val_accuracy: 0.7696\n",
      "Epoch 286/1000\n",
      "239/239 [==============================] - 1s 2ms/step - loss: 0.6035 - accuracy: 0.7632 - val_loss: 0.5894 - val_accuracy: 0.7722\n",
      "Epoch 287/1000\n",
      "239/239 [==============================] - 1s 2ms/step - loss: 0.6046 - accuracy: 0.7627 - val_loss: 0.5941 - val_accuracy: 0.7708\n",
      "Epoch 288/1000\n",
      "239/239 [==============================] - 1s 2ms/step - loss: 0.6041 - accuracy: 0.7632 - val_loss: 0.5886 - val_accuracy: 0.7710\n",
      "Epoch 289/1000\n",
      "239/239 [==============================] - 1s 2ms/step - loss: 0.6037 - accuracy: 0.7627 - val_loss: 0.5871 - val_accuracy: 0.7696\n",
      "Epoch 290/1000\n",
      "239/239 [==============================] - 1s 2ms/step - loss: 0.6031 - accuracy: 0.7630 - val_loss: 0.5886 - val_accuracy: 0.7722\n",
      "Epoch 291/1000\n",
      "239/239 [==============================] - 1s 2ms/step - loss: 0.6030 - accuracy: 0.7636 - val_loss: 0.5892 - val_accuracy: 0.7709\n",
      "Epoch 292/1000\n",
      "239/239 [==============================] - 1s 2ms/step - loss: 0.6040 - accuracy: 0.7645 - val_loss: 0.5897 - val_accuracy: 0.7724\n",
      "Epoch 293/1000\n",
      "239/239 [==============================] - 1s 2ms/step - loss: 0.6032 - accuracy: 0.7640 - val_loss: 0.5891 - val_accuracy: 0.7722\n",
      "Epoch 294/1000\n",
      "239/239 [==============================] - 1s 2ms/step - loss: 0.6039 - accuracy: 0.7634 - val_loss: 0.5897 - val_accuracy: 0.7695\n",
      "Epoch 295/1000\n",
      "239/239 [==============================] - 1s 2ms/step - loss: 0.6028 - accuracy: 0.7635 - val_loss: 0.5873 - val_accuracy: 0.7699\n",
      "Epoch 296/1000\n",
      "239/239 [==============================] - 1s 2ms/step - loss: 0.6032 - accuracy: 0.7633 - val_loss: 0.5914 - val_accuracy: 0.7711\n",
      "Epoch 297/1000\n",
      "239/239 [==============================] - 1s 2ms/step - loss: 0.6029 - accuracy: 0.7646 - val_loss: 0.5898 - val_accuracy: 0.7704\n",
      "Epoch 298/1000\n",
      "239/239 [==============================] - 0s 2ms/step - loss: 0.6041 - accuracy: 0.7644 - val_loss: 0.5889 - val_accuracy: 0.7713\n",
      "Epoch 299/1000\n",
      "239/239 [==============================] - 0s 2ms/step - loss: 0.6045 - accuracy: 0.7635 - val_loss: 0.5889 - val_accuracy: 0.7711\n",
      "Epoch 300/1000\n",
      "239/239 [==============================] - 1s 2ms/step - loss: 0.6017 - accuracy: 0.7633 - val_loss: 0.5877 - val_accuracy: 0.7720\n",
      "Epoch 301/1000\n",
      "239/239 [==============================] - 1s 3ms/step - loss: 0.6019 - accuracy: 0.7640 - val_loss: 0.5871 - val_accuracy: 0.7706\n",
      "Epoch 302/1000\n",
      "239/239 [==============================] - 1s 2ms/step - loss: 0.6036 - accuracy: 0.7630 - val_loss: 0.5888 - val_accuracy: 0.7713\n",
      "Epoch 303/1000\n",
      "239/239 [==============================] - 0s 2ms/step - loss: 0.6031 - accuracy: 0.7633 - val_loss: 0.5915 - val_accuracy: 0.7695\n",
      "Epoch 304/1000\n",
      "239/239 [==============================] - 1s 2ms/step - loss: 0.6038 - accuracy: 0.7631 - val_loss: 0.5853 - val_accuracy: 0.7723\n",
      "Epoch 305/1000\n",
      "239/239 [==============================] - 0s 2ms/step - loss: 0.6025 - accuracy: 0.7649 - val_loss: 0.5880 - val_accuracy: 0.7728\n",
      "Epoch 306/1000\n",
      "239/239 [==============================] - 1s 2ms/step - loss: 0.6031 - accuracy: 0.7617 - val_loss: 0.5870 - val_accuracy: 0.7705\n",
      "Epoch 307/1000\n",
      "239/239 [==============================] - 1s 2ms/step - loss: 0.6038 - accuracy: 0.7633 - val_loss: 0.5888 - val_accuracy: 0.7724\n",
      "Epoch 308/1000\n",
      "239/239 [==============================] - 1s 2ms/step - loss: 0.6030 - accuracy: 0.7637 - val_loss: 0.5898 - val_accuracy: 0.7731\n",
      "Epoch 309/1000\n",
      "239/239 [==============================] - 1s 3ms/step - loss: 0.6018 - accuracy: 0.7649 - val_loss: 0.5894 - val_accuracy: 0.7724\n",
      "Epoch 310/1000\n",
      "239/239 [==============================] - 1s 2ms/step - loss: 0.6014 - accuracy: 0.7644 - val_loss: 0.5874 - val_accuracy: 0.7705\n",
      "Epoch 311/1000\n",
      "239/239 [==============================] - 1s 2ms/step - loss: 0.6022 - accuracy: 0.7640 - val_loss: 0.5892 - val_accuracy: 0.7719\n",
      "Epoch 312/1000\n",
      "239/239 [==============================] - 1s 2ms/step - loss: 0.6018 - accuracy: 0.7631 - val_loss: 0.5898 - val_accuracy: 0.7712\n",
      "Epoch 313/1000\n",
      "239/239 [==============================] - 1s 2ms/step - loss: 0.6042 - accuracy: 0.7631 - val_loss: 0.5910 - val_accuracy: 0.7719\n",
      "Epoch 314/1000\n",
      "239/239 [==============================] - 0s 2ms/step - loss: 0.6028 - accuracy: 0.7635 - val_loss: 0.5876 - val_accuracy: 0.7716\n",
      "Epoch 315/1000\n",
      "239/239 [==============================] - 1s 2ms/step - loss: 0.6018 - accuracy: 0.7635 - val_loss: 0.5880 - val_accuracy: 0.7705\n",
      "Epoch 316/1000\n",
      "239/239 [==============================] - 1s 2ms/step - loss: 0.6009 - accuracy: 0.7648 - val_loss: 0.5928 - val_accuracy: 0.7699\n",
      "Epoch 317/1000\n",
      "239/239 [==============================] - 1s 2ms/step - loss: 0.6034 - accuracy: 0.7639 - val_loss: 0.5935 - val_accuracy: 0.7726\n",
      "Epoch 318/1000\n",
      "239/239 [==============================] - 0s 2ms/step - loss: 0.6035 - accuracy: 0.7642 - val_loss: 0.5894 - val_accuracy: 0.7699\n",
      "Epoch 319/1000\n",
      "239/239 [==============================] - 1s 3ms/step - loss: 0.6021 - accuracy: 0.7642 - val_loss: 0.5901 - val_accuracy: 0.7728\n",
      "Epoch 320/1000\n",
      "239/239 [==============================] - 1s 2ms/step - loss: 0.6032 - accuracy: 0.7632 - val_loss: 0.5893 - val_accuracy: 0.7732\n",
      "Epoch 321/1000\n",
      "239/239 [==============================] - 1s 2ms/step - loss: 0.6023 - accuracy: 0.7639 - val_loss: 0.5874 - val_accuracy: 0.7733\n",
      "Epoch 322/1000\n",
      "239/239 [==============================] - 1s 2ms/step - loss: 0.6022 - accuracy: 0.7644 - val_loss: 0.5873 - val_accuracy: 0.7736\n",
      "Epoch 323/1000\n",
      "239/239 [==============================] - 1s 2ms/step - loss: 0.6031 - accuracy: 0.7640 - val_loss: 0.5914 - val_accuracy: 0.7727\n",
      "Epoch 324/1000\n",
      "239/239 [==============================] - 1s 2ms/step - loss: 0.6038 - accuracy: 0.7640 - val_loss: 0.5852 - val_accuracy: 0.7730\n",
      "Epoch 325/1000\n",
      "239/239 [==============================] - 1s 2ms/step - loss: 0.6026 - accuracy: 0.7639 - val_loss: 0.5864 - val_accuracy: 0.7729\n",
      "Epoch 326/1000\n",
      "239/239 [==============================] - 1s 2ms/step - loss: 0.6008 - accuracy: 0.7649 - val_loss: 0.5880 - val_accuracy: 0.7724\n",
      "Epoch 327/1000\n",
      "239/239 [==============================] - 1s 3ms/step - loss: 0.6013 - accuracy: 0.7646 - val_loss: 0.5885 - val_accuracy: 0.7717\n",
      "Epoch 328/1000\n",
      "239/239 [==============================] - 1s 3ms/step - loss: 0.6021 - accuracy: 0.7641 - val_loss: 0.5885 - val_accuracy: 0.7723\n",
      "Epoch 329/1000\n",
      "239/239 [==============================] - 1s 3ms/step - loss: 0.6014 - accuracy: 0.7649 - val_loss: 0.5863 - val_accuracy: 0.7714\n",
      "Epoch 330/1000\n",
      "239/239 [==============================] - 1s 2ms/step - loss: 0.6024 - accuracy: 0.7642 - val_loss: 0.5898 - val_accuracy: 0.7711\n",
      "Epoch 331/1000\n",
      "239/239 [==============================] - 1s 2ms/step - loss: 0.6015 - accuracy: 0.7644 - val_loss: 0.5887 - val_accuracy: 0.7716\n",
      "Epoch 332/1000\n",
      "239/239 [==============================] - 1s 2ms/step - loss: 0.6006 - accuracy: 0.7646 - val_loss: 0.5864 - val_accuracy: 0.7731\n",
      "Epoch 333/1000\n",
      "239/239 [==============================] - 1s 2ms/step - loss: 0.6019 - accuracy: 0.7641 - val_loss: 0.5874 - val_accuracy: 0.7707\n",
      "Epoch 334/1000\n",
      "239/239 [==============================] - 1s 2ms/step - loss: 0.6022 - accuracy: 0.7639 - val_loss: 0.5884 - val_accuracy: 0.7716\n",
      "Epoch 335/1000\n",
      "239/239 [==============================] - 0s 2ms/step - loss: 0.6027 - accuracy: 0.7636 - val_loss: 0.5859 - val_accuracy: 0.7713\n",
      "Epoch 336/1000\n",
      "239/239 [==============================] - 0s 2ms/step - loss: 0.6020 - accuracy: 0.7644 - val_loss: 0.5897 - val_accuracy: 0.7723\n",
      "Epoch 337/1000\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "239/239 [==============================] - 1s 2ms/step - loss: 0.6004 - accuracy: 0.7654 - val_loss: 0.5861 - val_accuracy: 0.7734\n",
      "Epoch 338/1000\n",
      "239/239 [==============================] - 1s 2ms/step - loss: 0.6007 - accuracy: 0.7640 - val_loss: 0.5886 - val_accuracy: 0.7723\n",
      "Epoch 339/1000\n",
      "239/239 [==============================] - 1s 2ms/step - loss: 0.6028 - accuracy: 0.7640 - val_loss: 0.5865 - val_accuracy: 0.7733\n",
      "Epoch 340/1000\n",
      "239/239 [==============================] - 1s 2ms/step - loss: 0.6030 - accuracy: 0.7639 - val_loss: 0.5879 - val_accuracy: 0.7724\n",
      "Epoch 341/1000\n",
      "239/239 [==============================] - 1s 2ms/step - loss: 0.6021 - accuracy: 0.7631 - val_loss: 0.5858 - val_accuracy: 0.7702\n",
      "Epoch 342/1000\n",
      "239/239 [==============================] - 0s 2ms/step - loss: 0.6017 - accuracy: 0.7643 - val_loss: 0.5859 - val_accuracy: 0.7727\n",
      "Epoch 343/1000\n",
      "239/239 [==============================] - 0s 2ms/step - loss: 0.6008 - accuracy: 0.7650 - val_loss: 0.5853 - val_accuracy: 0.7713\n",
      "Epoch 344/1000\n",
      "239/239 [==============================] - 0s 2ms/step - loss: 0.6030 - accuracy: 0.7634 - val_loss: 0.5875 - val_accuracy: 0.7710\n",
      "Epoch 345/1000\n",
      "239/239 [==============================] - 1s 2ms/step - loss: 0.6004 - accuracy: 0.7640 - val_loss: 0.5872 - val_accuracy: 0.7730\n",
      "Epoch 346/1000\n",
      "239/239 [==============================] - 1s 2ms/step - loss: 0.6016 - accuracy: 0.7640 - val_loss: 0.5859 - val_accuracy: 0.7741\n",
      "Epoch 347/1000\n",
      "239/239 [==============================] - 1s 2ms/step - loss: 0.6008 - accuracy: 0.7637 - val_loss: 0.5880 - val_accuracy: 0.7721\n",
      "Epoch 348/1000\n",
      "239/239 [==============================] - 1s 2ms/step - loss: 0.6012 - accuracy: 0.7631 - val_loss: 0.5901 - val_accuracy: 0.7713\n",
      "Epoch 349/1000\n",
      "239/239 [==============================] - 1s 3ms/step - loss: 0.6023 - accuracy: 0.7638 - val_loss: 0.5904 - val_accuracy: 0.7741\n",
      "Epoch 350/1000\n",
      "239/239 [==============================] - 1s 2ms/step - loss: 0.6006 - accuracy: 0.7648 - val_loss: 0.5859 - val_accuracy: 0.7725\n",
      "Epoch 351/1000\n",
      "239/239 [==============================] - 1s 2ms/step - loss: 0.6015 - accuracy: 0.7639 - val_loss: 0.5893 - val_accuracy: 0.7729\n",
      "Epoch 352/1000\n",
      "239/239 [==============================] - 1s 2ms/step - loss: 0.6000 - accuracy: 0.7648 - val_loss: 0.5857 - val_accuracy: 0.7735\n",
      "Epoch 353/1000\n",
      "239/239 [==============================] - 1s 2ms/step - loss: 0.6007 - accuracy: 0.7644 - val_loss: 0.5879 - val_accuracy: 0.7740\n",
      "Epoch 354/1000\n",
      "239/239 [==============================] - 1s 2ms/step - loss: 0.6011 - accuracy: 0.7643 - val_loss: 0.5865 - val_accuracy: 0.7718\n",
      "Epoch 355/1000\n",
      "239/239 [==============================] - 1s 2ms/step - loss: 0.6007 - accuracy: 0.7634 - val_loss: 0.5909 - val_accuracy: 0.7741\n",
      "Epoch 356/1000\n",
      "239/239 [==============================] - 1s 2ms/step - loss: 0.6011 - accuracy: 0.7647 - val_loss: 0.5859 - val_accuracy: 0.7729\n",
      "Epoch 357/1000\n",
      "239/239 [==============================] - 1s 3ms/step - loss: 0.6010 - accuracy: 0.7643 - val_loss: 0.5840 - val_accuracy: 0.7740\n",
      "Epoch 358/1000\n",
      "239/239 [==============================] - 1s 2ms/step - loss: 0.6000 - accuracy: 0.7648 - val_loss: 0.5845 - val_accuracy: 0.7731\n",
      "Epoch 359/1000\n",
      "239/239 [==============================] - 1s 2ms/step - loss: 0.6021 - accuracy: 0.7640 - val_loss: 0.5854 - val_accuracy: 0.7726\n",
      "Epoch 360/1000\n",
      "239/239 [==============================] - 1s 2ms/step - loss: 0.6010 - accuracy: 0.7640 - val_loss: 0.5858 - val_accuracy: 0.7724\n",
      "Epoch 361/1000\n",
      "239/239 [==============================] - 1s 2ms/step - loss: 0.6016 - accuracy: 0.7646 - val_loss: 0.5864 - val_accuracy: 0.7750\n",
      "Epoch 362/1000\n",
      "239/239 [==============================] - 1s 2ms/step - loss: 0.5996 - accuracy: 0.7652 - val_loss: 0.5851 - val_accuracy: 0.7742\n",
      "Epoch 363/1000\n",
      "239/239 [==============================] - 1s 2ms/step - loss: 0.6005 - accuracy: 0.7648 - val_loss: 0.5899 - val_accuracy: 0.7735\n",
      "Epoch 364/1000\n",
      "239/239 [==============================] - 1s 2ms/step - loss: 0.6013 - accuracy: 0.7638 - val_loss: 0.5885 - val_accuracy: 0.7718\n",
      "Epoch 365/1000\n",
      "239/239 [==============================] - 0s 2ms/step - loss: 0.6010 - accuracy: 0.7638 - val_loss: 0.5888 - val_accuracy: 0.7730\n",
      "Epoch 366/1000\n",
      "239/239 [==============================] - 0s 2ms/step - loss: 0.5988 - accuracy: 0.7642 - val_loss: 0.5866 - val_accuracy: 0.7747\n",
      "Epoch 367/1000\n",
      "239/239 [==============================] - 1s 2ms/step - loss: 0.5997 - accuracy: 0.7640 - val_loss: 0.5858 - val_accuracy: 0.7729\n",
      "Epoch 368/1000\n",
      "239/239 [==============================] - 1s 2ms/step - loss: 0.6011 - accuracy: 0.7639 - val_loss: 0.5899 - val_accuracy: 0.7733\n",
      "Epoch 369/1000\n",
      "239/239 [==============================] - 0s 2ms/step - loss: 0.6012 - accuracy: 0.7638 - val_loss: 0.5861 - val_accuracy: 0.7721\n",
      "Epoch 370/1000\n",
      "239/239 [==============================] - 0s 2ms/step - loss: 0.6014 - accuracy: 0.7640 - val_loss: 0.5877 - val_accuracy: 0.7722\n",
      "Epoch 371/1000\n",
      "239/239 [==============================] - 0s 2ms/step - loss: 0.5994 - accuracy: 0.7652 - val_loss: 0.5872 - val_accuracy: 0.7735\n",
      "Epoch 372/1000\n",
      "239/239 [==============================] - 0s 2ms/step - loss: 0.5999 - accuracy: 0.7653 - val_loss: 0.5886 - val_accuracy: 0.7722\n",
      "Epoch 373/1000\n",
      "239/239 [==============================] - 0s 2ms/step - loss: 0.5988 - accuracy: 0.7655 - val_loss: 0.5888 - val_accuracy: 0.7726\n",
      "Epoch 374/1000\n",
      "239/239 [==============================] - 0s 2ms/step - loss: 0.6008 - accuracy: 0.7642 - val_loss: 0.5867 - val_accuracy: 0.7735\n",
      "Epoch 375/1000\n",
      "239/239 [==============================] - 1s 2ms/step - loss: 0.6002 - accuracy: 0.7654 - val_loss: 0.5866 - val_accuracy: 0.7708\n",
      "Epoch 376/1000\n",
      "239/239 [==============================] - 1s 2ms/step - loss: 0.5998 - accuracy: 0.7646 - val_loss: 0.5898 - val_accuracy: 0.7727\n",
      "Epoch 377/1000\n",
      "239/239 [==============================] - 1s 2ms/step - loss: 0.5991 - accuracy: 0.7647 - val_loss: 0.5879 - val_accuracy: 0.7717\n",
      "Epoch 378/1000\n",
      "239/239 [==============================] - 1s 2ms/step - loss: 0.6009 - accuracy: 0.7645 - val_loss: 0.5860 - val_accuracy: 0.7722\n",
      "Epoch 379/1000\n",
      "239/239 [==============================] - 1s 2ms/step - loss: 0.6017 - accuracy: 0.7639 - val_loss: 0.5861 - val_accuracy: 0.7729\n",
      "Epoch 380/1000\n",
      "239/239 [==============================] - 1s 3ms/step - loss: 0.6025 - accuracy: 0.7639 - val_loss: 0.5895 - val_accuracy: 0.7730\n",
      "Epoch 381/1000\n",
      "239/239 [==============================] - 1s 2ms/step - loss: 0.6013 - accuracy: 0.7647 - val_loss: 0.5905 - val_accuracy: 0.7730\n",
      "Epoch 382/1000\n",
      "239/239 [==============================] - 1s 3ms/step - loss: 0.6016 - accuracy: 0.7645 - val_loss: 0.5894 - val_accuracy: 0.7725\n",
      "Epoch 383/1000\n",
      "239/239 [==============================] - 1s 3ms/step - loss: 0.6028 - accuracy: 0.7644 - val_loss: 0.5853 - val_accuracy: 0.7717\n",
      "Epoch 384/1000\n",
      "239/239 [==============================] - 1s 2ms/step - loss: 0.5980 - accuracy: 0.7650 - val_loss: 0.5933 - val_accuracy: 0.7724\n",
      "Epoch 385/1000\n",
      "239/239 [==============================] - 1s 2ms/step - loss: 0.5997 - accuracy: 0.7649 - val_loss: 0.5910 - val_accuracy: 0.7740\n",
      "Epoch 386/1000\n",
      "239/239 [==============================] - 1s 2ms/step - loss: 0.6007 - accuracy: 0.7644 - val_loss: 0.5897 - val_accuracy: 0.7750\n",
      "Epoch 387/1000\n",
      "239/239 [==============================] - 1s 3ms/step - loss: 0.5979 - accuracy: 0.7655 - val_loss: 0.5857 - val_accuracy: 0.7744\n",
      "Epoch 388/1000\n",
      "239/239 [==============================] - 1s 2ms/step - loss: 0.5997 - accuracy: 0.7650 - val_loss: 0.5877 - val_accuracy: 0.7750\n",
      "Epoch 389/1000\n",
      "239/239 [==============================] - 1s 2ms/step - loss: 0.5987 - accuracy: 0.7654 - val_loss: 0.5850 - val_accuracy: 0.7713\n",
      "Epoch 390/1000\n",
      "239/239 [==============================] - 1s 2ms/step - loss: 0.5993 - accuracy: 0.7652 - val_loss: 0.5862 - val_accuracy: 0.7733\n",
      "Epoch 391/1000\n",
      "239/239 [==============================] - 1s 2ms/step - loss: 0.5998 - accuracy: 0.7649 - val_loss: 0.5845 - val_accuracy: 0.7747\n",
      "Epoch 392/1000\n",
      "239/239 [==============================] - 1s 2ms/step - loss: 0.5979 - accuracy: 0.7648 - val_loss: 0.5871 - val_accuracy: 0.7733\n",
      "Epoch 393/1000\n",
      "239/239 [==============================] - 1s 2ms/step - loss: 0.5993 - accuracy: 0.7648 - val_loss: 0.5817 - val_accuracy: 0.7717\n",
      "Epoch 394/1000\n",
      "239/239 [==============================] - 1s 2ms/step - loss: 0.6015 - accuracy: 0.7646 - val_loss: 0.5840 - val_accuracy: 0.7744\n",
      "Epoch 395/1000\n",
      "239/239 [==============================] - 1s 2ms/step - loss: 0.5995 - accuracy: 0.7652 - val_loss: 0.5821 - val_accuracy: 0.7732\n",
      "Epoch 396/1000\n",
      "239/239 [==============================] - 1s 3ms/step - loss: 0.5993 - accuracy: 0.7652 - val_loss: 0.5884 - val_accuracy: 0.7736\n",
      "Epoch 397/1000\n",
      "239/239 [==============================] - 1s 2ms/step - loss: 0.6010 - accuracy: 0.7642 - val_loss: 0.5853 - val_accuracy: 0.7730\n",
      "Epoch 398/1000\n",
      "239/239 [==============================] - 1s 2ms/step - loss: 0.5990 - accuracy: 0.7643 - val_loss: 0.5820 - val_accuracy: 0.7741\n",
      "Epoch 399/1000\n",
      "239/239 [==============================] - 1s 3ms/step - loss: 0.5995 - accuracy: 0.7652 - val_loss: 0.5865 - val_accuracy: 0.7722\n",
      "Epoch 400/1000\n",
      "239/239 [==============================] - 1s 2ms/step - loss: 0.6003 - accuracy: 0.7645 - val_loss: 0.5857 - val_accuracy: 0.7711\n",
      "Epoch 401/1000\n",
      "239/239 [==============================] - 1s 3ms/step - loss: 0.5968 - accuracy: 0.7661 - val_loss: 0.5835 - val_accuracy: 0.7752\n",
      "Epoch 402/1000\n",
      "239/239 [==============================] - 1s 2ms/step - loss: 0.5987 - accuracy: 0.7660 - val_loss: 0.5842 - val_accuracy: 0.7740\n",
      "Epoch 403/1000\n",
      "239/239 [==============================] - 1s 2ms/step - loss: 0.5984 - accuracy: 0.7651 - val_loss: 0.5849 - val_accuracy: 0.7742\n",
      "Epoch 404/1000\n",
      "239/239 [==============================] - 1s 2ms/step - loss: 0.5990 - accuracy: 0.7641 - val_loss: 0.5804 - val_accuracy: 0.7753\n",
      "Epoch 405/1000\n",
      "239/239 [==============================] - 1s 2ms/step - loss: 0.5984 - accuracy: 0.7657 - val_loss: 0.5858 - val_accuracy: 0.7716\n",
      "Epoch 406/1000\n",
      "239/239 [==============================] - 1s 3ms/step - loss: 0.6006 - accuracy: 0.7646 - val_loss: 0.5875 - val_accuracy: 0.7734\n",
      "Epoch 407/1000\n",
      "239/239 [==============================] - 1s 3ms/step - loss: 0.5988 - accuracy: 0.7653 - val_loss: 0.5844 - val_accuracy: 0.7729\n",
      "Epoch 408/1000\n",
      "239/239 [==============================] - 1s 2ms/step - loss: 0.5976 - accuracy: 0.7646 - val_loss: 0.5833 - val_accuracy: 0.7748\n",
      "Epoch 409/1000\n",
      "239/239 [==============================] - 1s 3ms/step - loss: 0.5991 - accuracy: 0.7657 - val_loss: 0.5820 - val_accuracy: 0.7738\n",
      "Epoch 410/1000\n",
      "239/239 [==============================] - 1s 2ms/step - loss: 0.5993 - accuracy: 0.7651 - val_loss: 0.5842 - val_accuracy: 0.7722\n",
      "Epoch 411/1000\n",
      "239/239 [==============================] - 0s 2ms/step - loss: 0.6003 - accuracy: 0.7651 - val_loss: 0.5835 - val_accuracy: 0.7723\n",
      "Epoch 412/1000\n",
      "239/239 [==============================] - 1s 2ms/step - loss: 0.6015 - accuracy: 0.7642 - val_loss: 0.5829 - val_accuracy: 0.7732\n",
      "Epoch 413/1000\n",
      "239/239 [==============================] - 1s 2ms/step - loss: 0.5982 - accuracy: 0.7652 - val_loss: 0.5825 - val_accuracy: 0.7755\n",
      "Epoch 414/1000\n",
      "239/239 [==============================] - 1s 2ms/step - loss: 0.5976 - accuracy: 0.7655 - val_loss: 0.5834 - val_accuracy: 0.7757\n",
      "Epoch 415/1000\n",
      "239/239 [==============================] - 1s 2ms/step - loss: 0.5996 - accuracy: 0.7643 - val_loss: 0.5832 - val_accuracy: 0.7741\n",
      "Epoch 416/1000\n",
      "239/239 [==============================] - 1s 2ms/step - loss: 0.5986 - accuracy: 0.7651 - val_loss: 0.5890 - val_accuracy: 0.7734\n",
      "Epoch 417/1000\n",
      "239/239 [==============================] - 1s 2ms/step - loss: 0.5989 - accuracy: 0.7642 - val_loss: 0.5864 - val_accuracy: 0.7760\n",
      "Epoch 418/1000\n",
      "239/239 [==============================] - 1s 2ms/step - loss: 0.5996 - accuracy: 0.7661 - val_loss: 0.5875 - val_accuracy: 0.7727\n",
      "Epoch 419/1000\n",
      "239/239 [==============================] - 1s 2ms/step - loss: 0.6014 - accuracy: 0.7645 - val_loss: 0.5878 - val_accuracy: 0.7750\n",
      "Epoch 420/1000\n",
      "239/239 [==============================] - 1s 2ms/step - loss: 0.5998 - accuracy: 0.7645 - val_loss: 0.5859 - val_accuracy: 0.7736\n",
      "Epoch 421/1000\n",
      "239/239 [==============================] - 0s 2ms/step - loss: 0.5983 - accuracy: 0.7659 - val_loss: 0.5853 - val_accuracy: 0.7737\n",
      "Epoch 422/1000\n",
      "239/239 [==============================] - 1s 2ms/step - loss: 0.5994 - accuracy: 0.7649 - val_loss: 0.5857 - val_accuracy: 0.7730\n",
      "Epoch 423/1000\n",
      "239/239 [==============================] - 1s 2ms/step - loss: 0.5988 - accuracy: 0.7653 - val_loss: 0.5859 - val_accuracy: 0.7741\n",
      "Epoch 424/1000\n",
      "239/239 [==============================] - 1s 2ms/step - loss: 0.5989 - accuracy: 0.7651 - val_loss: 0.5838 - val_accuracy: 0.7747\n",
      "Epoch 425/1000\n",
      "239/239 [==============================] - 1s 2ms/step - loss: 0.5991 - accuracy: 0.7646 - val_loss: 0.5826 - val_accuracy: 0.7752\n",
      "Epoch 426/1000\n",
      "239/239 [==============================] - 1s 2ms/step - loss: 0.6005 - accuracy: 0.7646 - val_loss: 0.5822 - val_accuracy: 0.7736\n",
      "Epoch 427/1000\n",
      "239/239 [==============================] - 1s 2ms/step - loss: 0.5985 - accuracy: 0.7647 - val_loss: 0.5864 - val_accuracy: 0.7736\n",
      "Epoch 428/1000\n",
      "239/239 [==============================] - 1s 2ms/step - loss: 0.5988 - accuracy: 0.7650 - val_loss: 0.5829 - val_accuracy: 0.7761\n",
      "Epoch 429/1000\n",
      "239/239 [==============================] - 0s 2ms/step - loss: 0.5972 - accuracy: 0.7657 - val_loss: 0.5833 - val_accuracy: 0.7752\n",
      "Epoch 430/1000\n",
      "239/239 [==============================] - 0s 2ms/step - loss: 0.5982 - accuracy: 0.7648 - val_loss: 0.5830 - val_accuracy: 0.7761\n",
      "Epoch 431/1000\n",
      "239/239 [==============================] - 0s 2ms/step - loss: 0.5985 - accuracy: 0.7651 - val_loss: 0.5828 - val_accuracy: 0.7736\n",
      "Epoch 432/1000\n",
      "239/239 [==============================] - 0s 2ms/step - loss: 0.5988 - accuracy: 0.7643 - val_loss: 0.5827 - val_accuracy: 0.7756\n",
      "Epoch 433/1000\n",
      "239/239 [==============================] - 0s 2ms/step - loss: 0.5983 - accuracy: 0.7648 - val_loss: 0.5848 - val_accuracy: 0.7741\n",
      "Epoch 434/1000\n",
      "239/239 [==============================] - 1s 2ms/step - loss: 0.6001 - accuracy: 0.7635 - val_loss: 0.5880 - val_accuracy: 0.7739\n",
      "Epoch 435/1000\n",
      "239/239 [==============================] - 1s 2ms/step - loss: 0.5986 - accuracy: 0.7655 - val_loss: 0.5838 - val_accuracy: 0.7754\n",
      "Epoch 436/1000\n",
      "239/239 [==============================] - 1s 2ms/step - loss: 0.5992 - accuracy: 0.7649 - val_loss: 0.5819 - val_accuracy: 0.7750\n",
      "Epoch 437/1000\n",
      "239/239 [==============================] - 1s 2ms/step - loss: 0.5984 - accuracy: 0.7655 - val_loss: 0.5803 - val_accuracy: 0.7758\n",
      "Epoch 438/1000\n",
      "239/239 [==============================] - 1s 2ms/step - loss: 0.5988 - accuracy: 0.7647 - val_loss: 0.5865 - val_accuracy: 0.7739\n",
      "Epoch 439/1000\n",
      "239/239 [==============================] - 0s 2ms/step - loss: 0.5977 - accuracy: 0.7657 - val_loss: 0.5819 - val_accuracy: 0.7741\n",
      "Epoch 440/1000\n",
      "239/239 [==============================] - 1s 2ms/step - loss: 0.5967 - accuracy: 0.7659 - val_loss: 0.5848 - val_accuracy: 0.7750\n",
      "Epoch 441/1000\n",
      "239/239 [==============================] - 1s 2ms/step - loss: 0.5986 - accuracy: 0.7651 - val_loss: 0.5805 - val_accuracy: 0.7742\n",
      "Epoch 442/1000\n",
      "239/239 [==============================] - 1s 2ms/step - loss: 0.5995 - accuracy: 0.7654 - val_loss: 0.5824 - val_accuracy: 0.7732\n",
      "Epoch 443/1000\n",
      "239/239 [==============================] - 1s 2ms/step - loss: 0.5990 - accuracy: 0.7648 - val_loss: 0.5839 - val_accuracy: 0.7746\n",
      "Epoch 444/1000\n",
      "239/239 [==============================] - 1s 2ms/step - loss: 0.5975 - accuracy: 0.7651 - val_loss: 0.5848 - val_accuracy: 0.7734\n",
      "Epoch 445/1000\n",
      "239/239 [==============================] - 1s 2ms/step - loss: 0.5996 - accuracy: 0.7648 - val_loss: 0.5861 - val_accuracy: 0.7733\n",
      "Epoch 446/1000\n",
      "239/239 [==============================] - 1s 2ms/step - loss: 0.5983 - accuracy: 0.7655 - val_loss: 0.5844 - val_accuracy: 0.7725\n",
      "Epoch 447/1000\n",
      "239/239 [==============================] - 1s 2ms/step - loss: 0.5990 - accuracy: 0.7650 - val_loss: 0.5803 - val_accuracy: 0.7730\n",
      "Epoch 448/1000\n",
      "239/239 [==============================] - 1s 2ms/step - loss: 0.5970 - accuracy: 0.7658 - val_loss: 0.5821 - val_accuracy: 0.7734\n",
      "Epoch 449/1000\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "239/239 [==============================] - 1s 2ms/step - loss: 0.5978 - accuracy: 0.7654 - val_loss: 0.5857 - val_accuracy: 0.7747\n",
      "Epoch 450/1000\n",
      "239/239 [==============================] - 1s 2ms/step - loss: 0.5981 - accuracy: 0.7652 - val_loss: 0.5821 - val_accuracy: 0.7754\n",
      "Epoch 451/1000\n",
      "239/239 [==============================] - 1s 2ms/step - loss: 0.5992 - accuracy: 0.7649 - val_loss: 0.5837 - val_accuracy: 0.7719\n",
      "Epoch 452/1000\n",
      "239/239 [==============================] - 1s 2ms/step - loss: 0.5988 - accuracy: 0.7646 - val_loss: 0.5823 - val_accuracy: 0.7742\n",
      "Epoch 453/1000\n",
      "239/239 [==============================] - 1s 2ms/step - loss: 0.5982 - accuracy: 0.7658 - val_loss: 0.5827 - val_accuracy: 0.7738\n",
      "Epoch 454/1000\n",
      "239/239 [==============================] - 1s 2ms/step - loss: 0.5991 - accuracy: 0.7651 - val_loss: 0.5834 - val_accuracy: 0.7739\n",
      "Epoch 455/1000\n",
      "239/239 [==============================] - 1s 2ms/step - loss: 0.5978 - accuracy: 0.7647 - val_loss: 0.5811 - val_accuracy: 0.7730\n",
      "Epoch 456/1000\n",
      "239/239 [==============================] - 1s 2ms/step - loss: 0.5980 - accuracy: 0.7657 - val_loss: 0.5846 - val_accuracy: 0.7715\n",
      "Epoch 457/1000\n",
      "239/239 [==============================] - 0s 2ms/step - loss: 0.5971 - accuracy: 0.7657 - val_loss: 0.5800 - val_accuracy: 0.7742\n",
      "Epoch 458/1000\n",
      "239/239 [==============================] - 1s 2ms/step - loss: 0.5971 - accuracy: 0.7668 - val_loss: 0.5824 - val_accuracy: 0.7753\n",
      "Epoch 459/1000\n",
      "239/239 [==============================] - 1s 2ms/step - loss: 0.5966 - accuracy: 0.7653 - val_loss: 0.5833 - val_accuracy: 0.7753\n",
      "Epoch 460/1000\n",
      "239/239 [==============================] - 1s 3ms/step - loss: 0.5977 - accuracy: 0.7653 - val_loss: 0.5817 - val_accuracy: 0.7744\n",
      "Epoch 461/1000\n",
      "239/239 [==============================] - 1s 2ms/step - loss: 0.5991 - accuracy: 0.7654 - val_loss: 0.5808 - val_accuracy: 0.7733\n",
      "Epoch 462/1000\n",
      "239/239 [==============================] - 1s 2ms/step - loss: 0.5985 - accuracy: 0.7649 - val_loss: 0.5806 - val_accuracy: 0.7737\n",
      "Epoch 463/1000\n",
      "239/239 [==============================] - 1s 2ms/step - loss: 0.5974 - accuracy: 0.7666 - val_loss: 0.5813 - val_accuracy: 0.7737\n",
      "Epoch 464/1000\n",
      "239/239 [==============================] - 1s 2ms/step - loss: 0.5980 - accuracy: 0.7648 - val_loss: 0.5809 - val_accuracy: 0.7744\n",
      "Epoch 465/1000\n",
      "239/239 [==============================] - 1s 2ms/step - loss: 0.5990 - accuracy: 0.7655 - val_loss: 0.5804 - val_accuracy: 0.7742\n",
      "Epoch 466/1000\n",
      "239/239 [==============================] - 1s 2ms/step - loss: 0.5996 - accuracy: 0.7651 - val_loss: 0.5814 - val_accuracy: 0.7741\n",
      "Epoch 467/1000\n",
      "239/239 [==============================] - 1s 2ms/step - loss: 0.5984 - accuracy: 0.7646 - val_loss: 0.5806 - val_accuracy: 0.7750\n",
      "Epoch 468/1000\n",
      "239/239 [==============================] - 1s 2ms/step - loss: 0.5976 - accuracy: 0.7648 - val_loss: 0.5803 - val_accuracy: 0.7733\n",
      "Epoch 469/1000\n",
      "239/239 [==============================] - 1s 2ms/step - loss: 0.5972 - accuracy: 0.7652 - val_loss: 0.5814 - val_accuracy: 0.7734\n",
      "Epoch 470/1000\n",
      "239/239 [==============================] - 1s 2ms/step - loss: 0.5974 - accuracy: 0.7654 - val_loss: 0.5801 - val_accuracy: 0.7741\n",
      "Epoch 471/1000\n",
      "239/239 [==============================] - 1s 2ms/step - loss: 0.5968 - accuracy: 0.7658 - val_loss: 0.5812 - val_accuracy: 0.7752\n",
      "Epoch 472/1000\n",
      "239/239 [==============================] - 1s 2ms/step - loss: 0.5994 - accuracy: 0.7637 - val_loss: 0.5842 - val_accuracy: 0.7746\n",
      "Epoch 473/1000\n",
      "239/239 [==============================] - 1s 2ms/step - loss: 0.5972 - accuracy: 0.7654 - val_loss: 0.5797 - val_accuracy: 0.7745\n",
      "Epoch 474/1000\n",
      "239/239 [==============================] - 0s 2ms/step - loss: 0.5983 - accuracy: 0.7652 - val_loss: 0.5825 - val_accuracy: 0.7743\n",
      "Epoch 475/1000\n",
      "239/239 [==============================] - 1s 2ms/step - loss: 0.5964 - accuracy: 0.7649 - val_loss: 0.5810 - val_accuracy: 0.7754\n",
      "Epoch 476/1000\n",
      "239/239 [==============================] - 1s 4ms/step - loss: 0.5969 - accuracy: 0.7667 - val_loss: 0.5820 - val_accuracy: 0.7753\n",
      "Epoch 477/1000\n",
      "239/239 [==============================] - 0s 2ms/step - loss: 0.5979 - accuracy: 0.7650 - val_loss: 0.5816 - val_accuracy: 0.7753\n",
      "Epoch 478/1000\n",
      "239/239 [==============================] - 0s 2ms/step - loss: 0.5975 - accuracy: 0.7656 - val_loss: 0.5834 - val_accuracy: 0.7741\n",
      "Epoch 479/1000\n",
      "239/239 [==============================] - 0s 2ms/step - loss: 0.5979 - accuracy: 0.7650 - val_loss: 0.5854 - val_accuracy: 0.7739\n",
      "Epoch 480/1000\n",
      "239/239 [==============================] - 1s 2ms/step - loss: 0.5973 - accuracy: 0.7654 - val_loss: 0.5882 - val_accuracy: 0.7753\n",
      "Epoch 481/1000\n",
      "239/239 [==============================] - 1s 2ms/step - loss: 0.5992 - accuracy: 0.7662 - val_loss: 0.5842 - val_accuracy: 0.7742\n",
      "Epoch 482/1000\n",
      "239/239 [==============================] - 1s 2ms/step - loss: 0.5968 - accuracy: 0.7661 - val_loss: 0.5829 - val_accuracy: 0.7739\n",
      "Epoch 483/1000\n",
      "239/239 [==============================] - 1s 2ms/step - loss: 0.5978 - accuracy: 0.7658 - val_loss: 0.5829 - val_accuracy: 0.7742\n",
      "Epoch 484/1000\n",
      "239/239 [==============================] - 1s 2ms/step - loss: 0.5976 - accuracy: 0.7659 - val_loss: 0.5814 - val_accuracy: 0.7742\n",
      "Epoch 485/1000\n",
      "239/239 [==============================] - 1s 2ms/step - loss: 0.5974 - accuracy: 0.7655 - val_loss: 0.5792 - val_accuracy: 0.7755\n",
      "Epoch 486/1000\n",
      "239/239 [==============================] - 1s 2ms/step - loss: 0.5968 - accuracy: 0.7661 - val_loss: 0.5803 - val_accuracy: 0.7732\n",
      "Epoch 487/1000\n",
      "239/239 [==============================] - 1s 2ms/step - loss: 0.5966 - accuracy: 0.7661 - val_loss: 0.5800 - val_accuracy: 0.7764\n",
      "Epoch 488/1000\n",
      "239/239 [==============================] - 1s 2ms/step - loss: 0.5975 - accuracy: 0.7658 - val_loss: 0.5781 - val_accuracy: 0.7744\n",
      "Epoch 489/1000\n",
      "239/239 [==============================] - 1s 2ms/step - loss: 0.5971 - accuracy: 0.7662 - val_loss: 0.5809 - val_accuracy: 0.7753\n",
      "Epoch 490/1000\n",
      "239/239 [==============================] - 1s 2ms/step - loss: 0.5975 - accuracy: 0.7664 - val_loss: 0.5785 - val_accuracy: 0.7744\n",
      "Epoch 491/1000\n",
      "239/239 [==============================] - 1s 2ms/step - loss: 0.5975 - accuracy: 0.7657 - val_loss: 0.5791 - val_accuracy: 0.7755\n",
      "Epoch 492/1000\n",
      "239/239 [==============================] - 1s 2ms/step - loss: 0.5969 - accuracy: 0.7662 - val_loss: 0.5815 - val_accuracy: 0.7742\n",
      "Epoch 493/1000\n",
      "239/239 [==============================] - 1s 2ms/step - loss: 0.5980 - accuracy: 0.7656 - val_loss: 0.5820 - val_accuracy: 0.7755\n",
      "Epoch 494/1000\n",
      "239/239 [==============================] - 1s 2ms/step - loss: 0.5971 - accuracy: 0.7664 - val_loss: 0.5812 - val_accuracy: 0.7743\n",
      "Epoch 495/1000\n",
      "239/239 [==============================] - 1s 2ms/step - loss: 0.5980 - accuracy: 0.7650 - val_loss: 0.5831 - val_accuracy: 0.7751\n",
      "Epoch 496/1000\n",
      "239/239 [==============================] - 1s 2ms/step - loss: 0.5971 - accuracy: 0.7655 - val_loss: 0.5802 - val_accuracy: 0.7728\n",
      "Epoch 497/1000\n",
      "239/239 [==============================] - 1s 2ms/step - loss: 0.5969 - accuracy: 0.7653 - val_loss: 0.5811 - val_accuracy: 0.7739\n",
      "Epoch 498/1000\n",
      "239/239 [==============================] - 1s 2ms/step - loss: 0.5963 - accuracy: 0.7663 - val_loss: 0.5813 - val_accuracy: 0.7748\n",
      "Epoch 499/1000\n",
      "239/239 [==============================] - 1s 2ms/step - loss: 0.5965 - accuracy: 0.7670 - val_loss: 0.5816 - val_accuracy: 0.7740\n",
      "Epoch 500/1000\n",
      "239/239 [==============================] - 1s 2ms/step - loss: 0.5977 - accuracy: 0.7653 - val_loss: 0.5833 - val_accuracy: 0.7736\n",
      "Epoch 501/1000\n",
      "239/239 [==============================] - 1s 2ms/step - loss: 0.5977 - accuracy: 0.7668 - val_loss: 0.5824 - val_accuracy: 0.7747\n",
      "Epoch 502/1000\n",
      "239/239 [==============================] - 1s 2ms/step - loss: 0.5977 - accuracy: 0.7655 - val_loss: 0.5867 - val_accuracy: 0.7740\n",
      "Epoch 503/1000\n",
      "239/239 [==============================] - 1s 2ms/step - loss: 0.5981 - accuracy: 0.7650 - val_loss: 0.5810 - val_accuracy: 0.7753\n",
      "Epoch 504/1000\n",
      "239/239 [==============================] - 1s 3ms/step - loss: 0.5970 - accuracy: 0.7654 - val_loss: 0.5781 - val_accuracy: 0.7742\n",
      "Epoch 505/1000\n",
      "239/239 [==============================] - 1s 2ms/step - loss: 0.5972 - accuracy: 0.7664 - val_loss: 0.5823 - val_accuracy: 0.7746\n",
      "Epoch 506/1000\n",
      "239/239 [==============================] - 1s 2ms/step - loss: 0.5953 - accuracy: 0.7668 - val_loss: 0.5804 - val_accuracy: 0.7755\n",
      "Epoch 507/1000\n",
      "239/239 [==============================] - 1s 2ms/step - loss: 0.5963 - accuracy: 0.7662 - val_loss: 0.5822 - val_accuracy: 0.7724\n",
      "Epoch 508/1000\n",
      "239/239 [==============================] - 1s 2ms/step - loss: 0.5960 - accuracy: 0.7658 - val_loss: 0.5809 - val_accuracy: 0.7738\n",
      "Epoch 509/1000\n",
      "239/239 [==============================] - 1s 4ms/step - loss: 0.5966 - accuracy: 0.7666 - val_loss: 0.5794 - val_accuracy: 0.7753\n",
      "Epoch 510/1000\n",
      "239/239 [==============================] - 1s 3ms/step - loss: 0.5978 - accuracy: 0.7662 - val_loss: 0.5821 - val_accuracy: 0.7748\n",
      "Epoch 511/1000\n",
      "239/239 [==============================] - 1s 3ms/step - loss: 0.5966 - accuracy: 0.7663 - val_loss: 0.5837 - val_accuracy: 0.7744\n",
      "Epoch 512/1000\n",
      "239/239 [==============================] - 1s 2ms/step - loss: 0.5966 - accuracy: 0.7667 - val_loss: 0.5820 - val_accuracy: 0.7743\n",
      "Epoch 513/1000\n",
      "239/239 [==============================] - 1s 2ms/step - loss: 0.5972 - accuracy: 0.7659 - val_loss: 0.5836 - val_accuracy: 0.7741\n",
      "Epoch 514/1000\n",
      "239/239 [==============================] - 1s 2ms/step - loss: 0.5953 - accuracy: 0.7675 - val_loss: 0.5856 - val_accuracy: 0.7751\n",
      "Epoch 515/1000\n",
      "239/239 [==============================] - 1s 2ms/step - loss: 0.5992 - accuracy: 0.7650 - val_loss: 0.5833 - val_accuracy: 0.7744\n",
      "Epoch 516/1000\n",
      "239/239 [==============================] - 1s 2ms/step - loss: 0.5961 - accuracy: 0.7662 - val_loss: 0.5794 - val_accuracy: 0.7736\n",
      "Epoch 517/1000\n",
      "239/239 [==============================] - 1s 2ms/step - loss: 0.5984 - accuracy: 0.7651 - val_loss: 0.5827 - val_accuracy: 0.7727\n",
      "Epoch 518/1000\n",
      "239/239 [==============================] - 1s 2ms/step - loss: 0.5979 - accuracy: 0.7662 - val_loss: 0.5839 - val_accuracy: 0.7740\n",
      "Epoch 519/1000\n",
      "239/239 [==============================] - 0s 2ms/step - loss: 0.5964 - accuracy: 0.7656 - val_loss: 0.5822 - val_accuracy: 0.7740\n",
      "Epoch 520/1000\n",
      "239/239 [==============================] - 1s 2ms/step - loss: 0.5968 - accuracy: 0.7662 - val_loss: 0.5813 - val_accuracy: 0.7738\n",
      "Epoch 521/1000\n",
      "239/239 [==============================] - 0s 2ms/step - loss: 0.5963 - accuracy: 0.7659 - val_loss: 0.5832 - val_accuracy: 0.7765\n",
      "Epoch 522/1000\n",
      "239/239 [==============================] - 0s 2ms/step - loss: 0.5976 - accuracy: 0.7663 - val_loss: 0.5827 - val_accuracy: 0.7739\n",
      "Epoch 523/1000\n",
      "239/239 [==============================] - 0s 2ms/step - loss: 0.5980 - accuracy: 0.7660 - val_loss: 0.5834 - val_accuracy: 0.7741\n",
      "Epoch 524/1000\n",
      "239/239 [==============================] - 0s 2ms/step - loss: 0.5968 - accuracy: 0.7651 - val_loss: 0.5824 - val_accuracy: 0.7748\n",
      "Epoch 525/1000\n",
      "239/239 [==============================] - 0s 2ms/step - loss: 0.5964 - accuracy: 0.7661 - val_loss: 0.5817 - val_accuracy: 0.7733\n",
      "Epoch 526/1000\n",
      "239/239 [==============================] - 0s 2ms/step - loss: 0.5973 - accuracy: 0.7661 - val_loss: 0.5828 - val_accuracy: 0.7743\n",
      "Epoch 527/1000\n",
      "239/239 [==============================] - 1s 2ms/step - loss: 0.5962 - accuracy: 0.7659 - val_loss: 0.5842 - val_accuracy: 0.7766\n",
      "Epoch 528/1000\n",
      "239/239 [==============================] - 1s 2ms/step - loss: 0.5954 - accuracy: 0.7656 - val_loss: 0.5813 - val_accuracy: 0.7746\n",
      "Epoch 529/1000\n",
      "239/239 [==============================] - 1s 2ms/step - loss: 0.5967 - accuracy: 0.7654 - val_loss: 0.5848 - val_accuracy: 0.7743\n",
      "Epoch 530/1000\n",
      "239/239 [==============================] - 1s 2ms/step - loss: 0.5981 - accuracy: 0.7658 - val_loss: 0.5827 - val_accuracy: 0.7745\n",
      "Epoch 531/1000\n",
      "239/239 [==============================] - 1s 2ms/step - loss: 0.5972 - accuracy: 0.7661 - val_loss: 0.5816 - val_accuracy: 0.7755\n",
      "Epoch 532/1000\n",
      "239/239 [==============================] - 1s 2ms/step - loss: 0.5952 - accuracy: 0.7666 - val_loss: 0.5828 - val_accuracy: 0.7733\n",
      "Epoch 533/1000\n",
      "239/239 [==============================] - 1s 2ms/step - loss: 0.5974 - accuracy: 0.7650 - val_loss: 0.5824 - val_accuracy: 0.7741\n",
      "Epoch 534/1000\n",
      "239/239 [==============================] - 1s 2ms/step - loss: 0.5973 - accuracy: 0.7669 - val_loss: 0.5824 - val_accuracy: 0.7753\n",
      "Epoch 535/1000\n",
      "239/239 [==============================] - 1s 2ms/step - loss: 0.5946 - accuracy: 0.7673 - val_loss: 0.5814 - val_accuracy: 0.7748\n",
      "Epoch 536/1000\n",
      "239/239 [==============================] - 1s 2ms/step - loss: 0.5957 - accuracy: 0.7666 - val_loss: 0.5799 - val_accuracy: 0.7739\n",
      "Epoch 537/1000\n",
      "239/239 [==============================] - 1s 2ms/step - loss: 0.5970 - accuracy: 0.7669 - val_loss: 0.5824 - val_accuracy: 0.7762\n",
      "Epoch 538/1000\n",
      "239/239 [==============================] - 0s 2ms/step - loss: 0.5965 - accuracy: 0.7655 - val_loss: 0.5852 - val_accuracy: 0.7751\n",
      "Epoch 539/1000\n",
      "239/239 [==============================] - 0s 2ms/step - loss: 0.5968 - accuracy: 0.7662 - val_loss: 0.5830 - val_accuracy: 0.7739\n",
      "Epoch 540/1000\n",
      "239/239 [==============================] - 0s 2ms/step - loss: 0.5979 - accuracy: 0.7657 - val_loss: 0.5813 - val_accuracy: 0.7747\n",
      "Epoch 541/1000\n",
      "239/239 [==============================] - 1s 2ms/step - loss: 0.5954 - accuracy: 0.7666 - val_loss: 0.5813 - val_accuracy: 0.7746\n",
      "Epoch 542/1000\n",
      "239/239 [==============================] - 1s 2ms/step - loss: 0.5965 - accuracy: 0.7663 - val_loss: 0.5845 - val_accuracy: 0.7747\n",
      "Epoch 543/1000\n",
      "239/239 [==============================] - 1s 2ms/step - loss: 0.5971 - accuracy: 0.7667 - val_loss: 0.5825 - val_accuracy: 0.7755\n",
      "Epoch 544/1000\n",
      "239/239 [==============================] - 1s 2ms/step - loss: 0.5960 - accuracy: 0.7665 - val_loss: 0.5814 - val_accuracy: 0.7746\n",
      "Epoch 545/1000\n",
      "239/239 [==============================] - 1s 2ms/step - loss: 0.5967 - accuracy: 0.7666 - val_loss: 0.5814 - val_accuracy: 0.7772\n",
      "Epoch 546/1000\n",
      "239/239 [==============================] - 1s 2ms/step - loss: 0.5954 - accuracy: 0.7674 - val_loss: 0.5785 - val_accuracy: 0.7774\n",
      "Epoch 547/1000\n",
      "239/239 [==============================] - 1s 2ms/step - loss: 0.5959 - accuracy: 0.7667 - val_loss: 0.5842 - val_accuracy: 0.7746\n",
      "Epoch 548/1000\n",
      "239/239 [==============================] - 1s 2ms/step - loss: 0.5950 - accuracy: 0.7675 - val_loss: 0.5838 - val_accuracy: 0.7749\n",
      "Epoch 549/1000\n",
      "239/239 [==============================] - 1s 2ms/step - loss: 0.5945 - accuracy: 0.7663 - val_loss: 0.5807 - val_accuracy: 0.7760\n",
      "Epoch 550/1000\n",
      "239/239 [==============================] - 1s 2ms/step - loss: 0.5967 - accuracy: 0.7663 - val_loss: 0.5823 - val_accuracy: 0.7762\n",
      "Epoch 551/1000\n",
      "239/239 [==============================] - 1s 2ms/step - loss: 0.5958 - accuracy: 0.7662 - val_loss: 0.5783 - val_accuracy: 0.7761\n",
      "Epoch 552/1000\n",
      "239/239 [==============================] - 0s 2ms/step - loss: 0.5942 - accuracy: 0.7672 - val_loss: 0.5810 - val_accuracy: 0.7753\n",
      "Epoch 553/1000\n",
      "239/239 [==============================] - 0s 2ms/step - loss: 0.5947 - accuracy: 0.7672 - val_loss: 0.5814 - val_accuracy: 0.7758\n",
      "Epoch 554/1000\n",
      "239/239 [==============================] - 0s 2ms/step - loss: 0.5959 - accuracy: 0.7661 - val_loss: 0.5801 - val_accuracy: 0.7751\n",
      "Epoch 555/1000\n",
      "239/239 [==============================] - 1s 2ms/step - loss: 0.5984 - accuracy: 0.7651 - val_loss: 0.5831 - val_accuracy: 0.7767\n",
      "Epoch 556/1000\n",
      "239/239 [==============================] - 0s 2ms/step - loss: 0.5957 - accuracy: 0.7662 - val_loss: 0.5811 - val_accuracy: 0.7762\n",
      "Epoch 557/1000\n",
      "239/239 [==============================] - 1s 2ms/step - loss: 0.5977 - accuracy: 0.7660 - val_loss: 0.5840 - val_accuracy: 0.7758\n",
      "Epoch 558/1000\n",
      "239/239 [==============================] - 1s 2ms/step - loss: 0.5970 - accuracy: 0.7657 - val_loss: 0.5801 - val_accuracy: 0.7764\n",
      "Epoch 559/1000\n",
      "239/239 [==============================] - 0s 2ms/step - loss: 0.5953 - accuracy: 0.7668 - val_loss: 0.5821 - val_accuracy: 0.7753\n",
      "Epoch 560/1000\n",
      "239/239 [==============================] - 1s 2ms/step - loss: 0.5956 - accuracy: 0.7668 - val_loss: 0.5840 - val_accuracy: 0.7758\n",
      "Epoch 561/1000\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "239/239 [==============================] - 1s 2ms/step - loss: 0.5963 - accuracy: 0.7675 - val_loss: 0.5850 - val_accuracy: 0.7756\n",
      "Epoch 562/1000\n",
      "239/239 [==============================] - 1s 2ms/step - loss: 0.5977 - accuracy: 0.7658 - val_loss: 0.5851 - val_accuracy: 0.7739\n",
      "Epoch 563/1000\n",
      "239/239 [==============================] - 1s 2ms/step - loss: 0.5979 - accuracy: 0.7661 - val_loss: 0.5813 - val_accuracy: 0.7760\n",
      "Epoch 564/1000\n",
      "239/239 [==============================] - 1s 2ms/step - loss: 0.5961 - accuracy: 0.7662 - val_loss: 0.5812 - val_accuracy: 0.7747\n",
      "Epoch 565/1000\n",
      "239/239 [==============================] - 1s 2ms/step - loss: 0.5967 - accuracy: 0.7651 - val_loss: 0.5817 - val_accuracy: 0.7751\n",
      "Epoch 566/1000\n",
      "239/239 [==============================] - 1s 2ms/step - loss: 0.5944 - accuracy: 0.7664 - val_loss: 0.5804 - val_accuracy: 0.7778\n",
      "Epoch 567/1000\n",
      "239/239 [==============================] - 1s 3ms/step - loss: 0.5967 - accuracy: 0.7662 - val_loss: 0.5840 - val_accuracy: 0.7766\n",
      "Epoch 568/1000\n",
      "239/239 [==============================] - 1s 2ms/step - loss: 0.5971 - accuracy: 0.7648 - val_loss: 0.5809 - val_accuracy: 0.7772\n",
      "Epoch 569/1000\n",
      "239/239 [==============================] - 0s 2ms/step - loss: 0.5959 - accuracy: 0.7655 - val_loss: 0.5844 - val_accuracy: 0.7755\n",
      "Epoch 570/1000\n",
      "239/239 [==============================] - 0s 2ms/step - loss: 0.5972 - accuracy: 0.7653 - val_loss: 0.5832 - val_accuracy: 0.7769\n",
      "Epoch 571/1000\n",
      "239/239 [==============================] - 0s 2ms/step - loss: 0.5954 - accuracy: 0.7665 - val_loss: 0.5817 - val_accuracy: 0.7752\n",
      "Epoch 572/1000\n",
      "239/239 [==============================] - 1s 2ms/step - loss: 0.5971 - accuracy: 0.7648 - val_loss: 0.5821 - val_accuracy: 0.7744\n",
      "Epoch 573/1000\n",
      "239/239 [==============================] - 1s 2ms/step - loss: 0.5951 - accuracy: 0.7661 - val_loss: 0.5824 - val_accuracy: 0.7750\n",
      "Epoch 574/1000\n",
      "239/239 [==============================] - 1s 2ms/step - loss: 0.5956 - accuracy: 0.7661 - val_loss: 0.5818 - val_accuracy: 0.7765\n",
      "Epoch 575/1000\n",
      "239/239 [==============================] - 1s 2ms/step - loss: 0.5954 - accuracy: 0.7666 - val_loss: 0.5801 - val_accuracy: 0.7761\n",
      "Epoch 576/1000\n",
      "239/239 [==============================] - 0s 2ms/step - loss: 0.5959 - accuracy: 0.7664 - val_loss: 0.5791 - val_accuracy: 0.7750\n",
      "Epoch 577/1000\n",
      "239/239 [==============================] - 1s 2ms/step - loss: 0.5978 - accuracy: 0.7656 - val_loss: 0.5856 - val_accuracy: 0.7732\n",
      "Epoch 578/1000\n",
      "239/239 [==============================] - 1s 2ms/step - loss: 0.5973 - accuracy: 0.7664 - val_loss: 0.5852 - val_accuracy: 0.7742\n",
      "Epoch 579/1000\n",
      "239/239 [==============================] - 1s 2ms/step - loss: 0.5973 - accuracy: 0.7664 - val_loss: 0.5823 - val_accuracy: 0.7743\n",
      "Epoch 580/1000\n",
      "239/239 [==============================] - 0s 2ms/step - loss: 0.5956 - accuracy: 0.7666 - val_loss: 0.5795 - val_accuracy: 0.7747\n",
      "Epoch 581/1000\n",
      "239/239 [==============================] - 0s 2ms/step - loss: 0.5955 - accuracy: 0.7665 - val_loss: 0.5779 - val_accuracy: 0.7758\n",
      "Epoch 582/1000\n",
      "239/239 [==============================] - 1s 2ms/step - loss: 0.5952 - accuracy: 0.7667 - val_loss: 0.5817 - val_accuracy: 0.7766\n",
      "Epoch 583/1000\n",
      "239/239 [==============================] - 1s 2ms/step - loss: 0.5936 - accuracy: 0.7674 - val_loss: 0.5789 - val_accuracy: 0.7769\n",
      "Epoch 584/1000\n",
      "239/239 [==============================] - 1s 2ms/step - loss: 0.5980 - accuracy: 0.7655 - val_loss: 0.5801 - val_accuracy: 0.7755\n",
      "Epoch 585/1000\n",
      "239/239 [==============================] - 1s 2ms/step - loss: 0.5965 - accuracy: 0.7649 - val_loss: 0.5792 - val_accuracy: 0.7753\n",
      "Epoch 586/1000\n",
      "239/239 [==============================] - 1s 2ms/step - loss: 0.5946 - accuracy: 0.7671 - val_loss: 0.5796 - val_accuracy: 0.7754\n",
      "Epoch 587/1000\n",
      "239/239 [==============================] - 1s 2ms/step - loss: 0.5957 - accuracy: 0.7667 - val_loss: 0.5771 - val_accuracy: 0.7757\n",
      "Epoch 588/1000\n",
      "239/239 [==============================] - 1s 2ms/step - loss: 0.5953 - accuracy: 0.7661 - val_loss: 0.5782 - val_accuracy: 0.7764\n",
      "Epoch 589/1000\n",
      "239/239 [==============================] - 1s 2ms/step - loss: 0.5950 - accuracy: 0.7680 - val_loss: 0.5797 - val_accuracy: 0.7756\n",
      "Epoch 590/1000\n",
      "239/239 [==============================] - 1s 2ms/step - loss: 0.5967 - accuracy: 0.7657 - val_loss: 0.5818 - val_accuracy: 0.7751\n",
      "Epoch 591/1000\n",
      "239/239 [==============================] - 1s 2ms/step - loss: 0.5962 - accuracy: 0.7660 - val_loss: 0.5789 - val_accuracy: 0.7775\n",
      "Epoch 592/1000\n",
      "239/239 [==============================] - 1s 2ms/step - loss: 0.5952 - accuracy: 0.7673 - val_loss: 0.5790 - val_accuracy: 0.7754\n",
      "Epoch 593/1000\n",
      "239/239 [==============================] - 1s 2ms/step - loss: 0.5964 - accuracy: 0.7663 - val_loss: 0.5803 - val_accuracy: 0.7743\n",
      "Epoch 594/1000\n",
      "239/239 [==============================] - 0s 2ms/step - loss: 0.5965 - accuracy: 0.7668 - val_loss: 0.5800 - val_accuracy: 0.7755\n",
      "Epoch 595/1000\n",
      "239/239 [==============================] - 0s 2ms/step - loss: 0.5928 - accuracy: 0.7678 - val_loss: 0.5810 - val_accuracy: 0.7760\n",
      "Epoch 596/1000\n",
      "239/239 [==============================] - 1s 2ms/step - loss: 0.5972 - accuracy: 0.7655 - val_loss: 0.5795 - val_accuracy: 0.7761\n",
      "Epoch 597/1000\n",
      "239/239 [==============================] - 1s 2ms/step - loss: 0.5939 - accuracy: 0.7676 - val_loss: 0.5803 - val_accuracy: 0.7751\n",
      "Epoch 598/1000\n",
      "239/239 [==============================] - 1s 2ms/step - loss: 0.5952 - accuracy: 0.7660 - val_loss: 0.5816 - val_accuracy: 0.7736\n",
      "Epoch 599/1000\n",
      "239/239 [==============================] - 1s 2ms/step - loss: 0.5954 - accuracy: 0.7659 - val_loss: 0.5796 - val_accuracy: 0.7763\n",
      "Epoch 600/1000\n",
      "239/239 [==============================] - 1s 2ms/step - loss: 0.5956 - accuracy: 0.7670 - val_loss: 0.5843 - val_accuracy: 0.7746\n",
      "Epoch 601/1000\n",
      "239/239 [==============================] - 1s 2ms/step - loss: 0.5954 - accuracy: 0.7660 - val_loss: 0.5857 - val_accuracy: 0.7724\n",
      "Epoch 602/1000\n",
      "239/239 [==============================] - 1s 2ms/step - loss: 0.5953 - accuracy: 0.7667 - val_loss: 0.5821 - val_accuracy: 0.7750\n",
      "Epoch 603/1000\n",
      "239/239 [==============================] - 1s 2ms/step - loss: 0.5966 - accuracy: 0.7665 - val_loss: 0.5793 - val_accuracy: 0.7760\n",
      "Epoch 604/1000\n",
      "239/239 [==============================] - 1s 2ms/step - loss: 0.5946 - accuracy: 0.7663 - val_loss: 0.5797 - val_accuracy: 0.7769\n",
      "Epoch 605/1000\n",
      "239/239 [==============================] - 1s 2ms/step - loss: 0.5963 - accuracy: 0.7653 - val_loss: 0.5836 - val_accuracy: 0.7749\n",
      "Epoch 606/1000\n",
      "239/239 [==============================] - 1s 2ms/step - loss: 0.5951 - accuracy: 0.7666 - val_loss: 0.5774 - val_accuracy: 0.7762\n",
      "Epoch 607/1000\n",
      "239/239 [==============================] - 1s 2ms/step - loss: 0.5954 - accuracy: 0.7663 - val_loss: 0.5820 - val_accuracy: 0.7762\n",
      "Epoch 608/1000\n",
      "239/239 [==============================] - 0s 2ms/step - loss: 0.5957 - accuracy: 0.7661 - val_loss: 0.5791 - val_accuracy: 0.7757\n",
      "Epoch 609/1000\n",
      "239/239 [==============================] - 0s 2ms/step - loss: 0.5943 - accuracy: 0.7668 - val_loss: 0.5792 - val_accuracy: 0.7769\n",
      "Epoch 610/1000\n",
      "239/239 [==============================] - 1s 2ms/step - loss: 0.5952 - accuracy: 0.7667 - val_loss: 0.5806 - val_accuracy: 0.7753\n",
      "Epoch 611/1000\n",
      "239/239 [==============================] - 1s 2ms/step - loss: 0.5944 - accuracy: 0.7666 - val_loss: 0.5838 - val_accuracy: 0.7758\n",
      "Epoch 612/1000\n",
      "239/239 [==============================] - 1s 2ms/step - loss: 0.5944 - accuracy: 0.7657 - val_loss: 0.5819 - val_accuracy: 0.7751\n",
      "Epoch 613/1000\n",
      "239/239 [==============================] - 0s 2ms/step - loss: 0.5954 - accuracy: 0.7661 - val_loss: 0.5791 - val_accuracy: 0.7762\n",
      "Epoch 614/1000\n",
      "239/239 [==============================] - 0s 2ms/step - loss: 0.5957 - accuracy: 0.7669 - val_loss: 0.5808 - val_accuracy: 0.7751\n",
      "Epoch 615/1000\n",
      "239/239 [==============================] - 1s 2ms/step - loss: 0.5954 - accuracy: 0.7661 - val_loss: 0.5793 - val_accuracy: 0.7741\n",
      "Epoch 616/1000\n",
      "239/239 [==============================] - 1s 2ms/step - loss: 0.5963 - accuracy: 0.7662 - val_loss: 0.5797 - val_accuracy: 0.7754\n",
      "Epoch 617/1000\n",
      "239/239 [==============================] - 1s 2ms/step - loss: 0.5949 - accuracy: 0.7668 - val_loss: 0.5791 - val_accuracy: 0.7749\n",
      "Epoch 618/1000\n",
      "239/239 [==============================] - 0s 2ms/step - loss: 0.5960 - accuracy: 0.7666 - val_loss: 0.5811 - val_accuracy: 0.7746\n",
      "Epoch 619/1000\n",
      "239/239 [==============================] - 0s 2ms/step - loss: 0.5954 - accuracy: 0.7648 - val_loss: 0.5786 - val_accuracy: 0.7763\n",
      "Epoch 620/1000\n",
      "239/239 [==============================] - 1s 2ms/step - loss: 0.5955 - accuracy: 0.7660 - val_loss: 0.5791 - val_accuracy: 0.7753\n",
      "Epoch 621/1000\n",
      "239/239 [==============================] - 1s 2ms/step - loss: 0.5953 - accuracy: 0.7663 - val_loss: 0.5807 - val_accuracy: 0.7750\n",
      "Epoch 622/1000\n",
      "239/239 [==============================] - 1s 2ms/step - loss: 0.5960 - accuracy: 0.7658 - val_loss: 0.5822 - val_accuracy: 0.7730\n",
      "Epoch 623/1000\n",
      "239/239 [==============================] - 1s 2ms/step - loss: 0.5942 - accuracy: 0.7664 - val_loss: 0.5798 - val_accuracy: 0.7752\n",
      "Epoch 624/1000\n",
      "239/239 [==============================] - 0s 2ms/step - loss: 0.5955 - accuracy: 0.7661 - val_loss: 0.5828 - val_accuracy: 0.7727\n",
      "Epoch 625/1000\n",
      "239/239 [==============================] - 0s 2ms/step - loss: 0.5946 - accuracy: 0.7671 - val_loss: 0.5807 - val_accuracy: 0.7760\n",
      "Epoch 626/1000\n",
      "239/239 [==============================] - 1s 2ms/step - loss: 0.5959 - accuracy: 0.7666 - val_loss: 0.5799 - val_accuracy: 0.7747\n",
      "Epoch 627/1000\n",
      "239/239 [==============================] - 1s 2ms/step - loss: 0.5943 - accuracy: 0.7668 - val_loss: 0.5775 - val_accuracy: 0.7765\n",
      "Epoch 628/1000\n",
      "239/239 [==============================] - 1s 2ms/step - loss: 0.5955 - accuracy: 0.7659 - val_loss: 0.5811 - val_accuracy: 0.7723\n",
      "Epoch 629/1000\n",
      "239/239 [==============================] - 1s 2ms/step - loss: 0.5949 - accuracy: 0.7668 - val_loss: 0.5814 - val_accuracy: 0.7753\n",
      "Epoch 630/1000\n",
      "239/239 [==============================] - 1s 2ms/step - loss: 0.5938 - accuracy: 0.7671 - val_loss: 0.5811 - val_accuracy: 0.7755\n",
      "Epoch 631/1000\n",
      "239/239 [==============================] - 1s 2ms/step - loss: 0.5948 - accuracy: 0.7668 - val_loss: 0.5779 - val_accuracy: 0.7759\n",
      "Epoch 632/1000\n",
      "239/239 [==============================] - 1s 2ms/step - loss: 0.5942 - accuracy: 0.7672 - val_loss: 0.5778 - val_accuracy: 0.7750\n",
      "Epoch 633/1000\n",
      "239/239 [==============================] - 1s 2ms/step - loss: 0.5938 - accuracy: 0.7680 - val_loss: 0.5787 - val_accuracy: 0.7745\n",
      "Epoch 634/1000\n",
      "239/239 [==============================] - 0s 2ms/step - loss: 0.5950 - accuracy: 0.7662 - val_loss: 0.5815 - val_accuracy: 0.7758\n",
      "Epoch 635/1000\n",
      "239/239 [==============================] - 0s 2ms/step - loss: 0.5941 - accuracy: 0.7668 - val_loss: 0.5791 - val_accuracy: 0.7744\n",
      "Epoch 636/1000\n",
      "239/239 [==============================] - 0s 2ms/step - loss: 0.5944 - accuracy: 0.7665 - val_loss: 0.5811 - val_accuracy: 0.7765\n",
      "Epoch 637/1000\n",
      "239/239 [==============================] - 0s 2ms/step - loss: 0.5975 - accuracy: 0.7661 - val_loss: 0.5814 - val_accuracy: 0.7739\n",
      "Epoch 638/1000\n",
      "239/239 [==============================] - 0s 2ms/step - loss: 0.5962 - accuracy: 0.7663 - val_loss: 0.5797 - val_accuracy: 0.7742\n",
      "Epoch 639/1000\n",
      "239/239 [==============================] - 0s 2ms/step - loss: 0.5949 - accuracy: 0.7666 - val_loss: 0.5777 - val_accuracy: 0.7748\n",
      "Epoch 640/1000\n",
      "239/239 [==============================] - 0s 2ms/step - loss: 0.5923 - accuracy: 0.7681 - val_loss: 0.5795 - val_accuracy: 0.7740\n",
      "Epoch 641/1000\n",
      "239/239 [==============================] - 1s 2ms/step - loss: 0.5940 - accuracy: 0.7679 - val_loss: 0.5801 - val_accuracy: 0.7760\n",
      "Epoch 642/1000\n",
      "239/239 [==============================] - 1s 2ms/step - loss: 0.5935 - accuracy: 0.7673 - val_loss: 0.5784 - val_accuracy: 0.7756\n",
      "Epoch 643/1000\n",
      "239/239 [==============================] - 1s 2ms/step - loss: 0.5947 - accuracy: 0.7664 - val_loss: 0.5776 - val_accuracy: 0.7753\n",
      "Epoch 644/1000\n",
      "239/239 [==============================] - 1s 2ms/step - loss: 0.5936 - accuracy: 0.7657 - val_loss: 0.5790 - val_accuracy: 0.7748\n",
      "Epoch 645/1000\n",
      "239/239 [==============================] - 0s 2ms/step - loss: 0.5936 - accuracy: 0.7667 - val_loss: 0.5784 - val_accuracy: 0.7755\n",
      "Epoch 646/1000\n",
      "239/239 [==============================] - 1s 2ms/step - loss: 0.5941 - accuracy: 0.7671 - val_loss: 0.5796 - val_accuracy: 0.7737\n",
      "Epoch 647/1000\n",
      "239/239 [==============================] - 1s 2ms/step - loss: 0.5941 - accuracy: 0.7671 - val_loss: 0.5824 - val_accuracy: 0.7767\n",
      "Epoch 648/1000\n",
      "239/239 [==============================] - 0s 2ms/step - loss: 0.5935 - accuracy: 0.7665 - val_loss: 0.5807 - val_accuracy: 0.7742\n",
      "Epoch 649/1000\n",
      "239/239 [==============================] - 0s 2ms/step - loss: 0.5946 - accuracy: 0.7662 - val_loss: 0.5841 - val_accuracy: 0.7767\n",
      "Epoch 650/1000\n",
      "239/239 [==============================] - 1s 2ms/step - loss: 0.5942 - accuracy: 0.7659 - val_loss: 0.5799 - val_accuracy: 0.7764\n",
      "Epoch 651/1000\n",
      "239/239 [==============================] - 1s 2ms/step - loss: 0.5952 - accuracy: 0.7666 - val_loss: 0.5865 - val_accuracy: 0.7761\n",
      "Epoch 652/1000\n",
      "239/239 [==============================] - 1s 2ms/step - loss: 0.5954 - accuracy: 0.7668 - val_loss: 0.5798 - val_accuracy: 0.7763\n",
      "Epoch 653/1000\n",
      "239/239 [==============================] - 1s 2ms/step - loss: 0.5952 - accuracy: 0.7671 - val_loss: 0.5799 - val_accuracy: 0.7731\n",
      "Epoch 654/1000\n",
      "239/239 [==============================] - 1s 2ms/step - loss: 0.5946 - accuracy: 0.7664 - val_loss: 0.5786 - val_accuracy: 0.7762\n",
      "Epoch 655/1000\n",
      "239/239 [==============================] - 1s 2ms/step - loss: 0.5939 - accuracy: 0.7676 - val_loss: 0.5778 - val_accuracy: 0.7747\n",
      "Epoch 656/1000\n",
      "239/239 [==============================] - 1s 2ms/step - loss: 0.5944 - accuracy: 0.7671 - val_loss: 0.5849 - val_accuracy: 0.7768\n",
      "Epoch 657/1000\n",
      "239/239 [==============================] - 0s 2ms/step - loss: 0.5954 - accuracy: 0.7664 - val_loss: 0.5788 - val_accuracy: 0.7772\n",
      "Epoch 658/1000\n",
      "239/239 [==============================] - 0s 2ms/step - loss: 0.5943 - accuracy: 0.7667 - val_loss: 0.5813 - val_accuracy: 0.7753\n",
      "Epoch 659/1000\n",
      "239/239 [==============================] - 0s 2ms/step - loss: 0.5952 - accuracy: 0.7663 - val_loss: 0.5804 - val_accuracy: 0.7758\n",
      "Epoch 660/1000\n",
      "239/239 [==============================] - 1s 2ms/step - loss: 0.5941 - accuracy: 0.7675 - val_loss: 0.5810 - val_accuracy: 0.7745\n",
      "Epoch 661/1000\n",
      "239/239 [==============================] - 1s 2ms/step - loss: 0.5938 - accuracy: 0.7669 - val_loss: 0.5782 - val_accuracy: 0.7767\n",
      "Epoch 662/1000\n",
      "239/239 [==============================] - 1s 2ms/step - loss: 0.5946 - accuracy: 0.7663 - val_loss: 0.5801 - val_accuracy: 0.7769\n",
      "Epoch 663/1000\n",
      "239/239 [==============================] - 0s 2ms/step - loss: 0.5950 - accuracy: 0.7658 - val_loss: 0.5860 - val_accuracy: 0.7747\n",
      "Epoch 664/1000\n",
      "239/239 [==============================] - 1s 2ms/step - loss: 0.5942 - accuracy: 0.7665 - val_loss: 0.5809 - val_accuracy: 0.7775\n",
      "Epoch 665/1000\n",
      "239/239 [==============================] - 1s 2ms/step - loss: 0.5947 - accuracy: 0.7671 - val_loss: 0.5795 - val_accuracy: 0.7763\n",
      "Epoch 666/1000\n",
      "239/239 [==============================] - 0s 2ms/step - loss: 0.5927 - accuracy: 0.7675 - val_loss: 0.5814 - val_accuracy: 0.7761\n",
      "Epoch 667/1000\n",
      "239/239 [==============================] - 0s 2ms/step - loss: 0.5937 - accuracy: 0.7677 - val_loss: 0.5811 - val_accuracy: 0.7772\n",
      "Epoch 668/1000\n",
      "239/239 [==============================] - 0s 2ms/step - loss: 0.5945 - accuracy: 0.7664 - val_loss: 0.5802 - val_accuracy: 0.7766\n",
      "Epoch 669/1000\n",
      "239/239 [==============================] - 0s 2ms/step - loss: 0.5949 - accuracy: 0.7664 - val_loss: 0.5815 - val_accuracy: 0.7765\n",
      "Epoch 670/1000\n",
      "239/239 [==============================] - 1s 2ms/step - loss: 0.5928 - accuracy: 0.7674 - val_loss: 0.5789 - val_accuracy: 0.7757\n",
      "Epoch 671/1000\n",
      "239/239 [==============================] - 1s 2ms/step - loss: 0.5939 - accuracy: 0.7669 - val_loss: 0.5836 - val_accuracy: 0.7737\n",
      "Epoch 672/1000\n",
      "239/239 [==============================] - 1s 2ms/step - loss: 0.5948 - accuracy: 0.7671 - val_loss: 0.5804 - val_accuracy: 0.7765\n",
      "Epoch 673/1000\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "239/239 [==============================] - 1s 2ms/step - loss: 0.5931 - accuracy: 0.7673 - val_loss: 0.5804 - val_accuracy: 0.7752\n",
      "Epoch 674/1000\n",
      "239/239 [==============================] - 1s 2ms/step - loss: 0.5936 - accuracy: 0.7667 - val_loss: 0.5818 - val_accuracy: 0.7734\n",
      "Epoch 675/1000\n",
      "239/239 [==============================] - 1s 2ms/step - loss: 0.5940 - accuracy: 0.7669 - val_loss: 0.5809 - val_accuracy: 0.7764\n",
      "Epoch 676/1000\n",
      "239/239 [==============================] - 1s 2ms/step - loss: 0.5960 - accuracy: 0.7665 - val_loss: 0.5812 - val_accuracy: 0.7739\n",
      "Epoch 677/1000\n",
      "239/239 [==============================] - 1s 2ms/step - loss: 0.5939 - accuracy: 0.7666 - val_loss: 0.5789 - val_accuracy: 0.7747\n",
      "Epoch 677: early stopping\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "<keras.src.callbacks.History at 0x141767a30>"
      ]
     },
     "execution_count": 162,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "model=Sequential()\n",
    "model.add(Dense(128, input_dim=X_train.shape[1], activation=\"relu\"))\n",
    "model.add(Dropout(0.2))\n",
    "model.add(Dense(128, activation=\"relu\"))\n",
    "model.add(Dropout(0.8))\n",
    "model.add(Dense(64, activation=\"relu\"))\n",
    "model.add(Dropout(0.2))\n",
    "model.add(Dense(64, activation=\"relu\"))\n",
    "\n",
    "model.add(Dense(32, activation=\"relu\"))\n",
    "model.add(Dropout(0.2))\n",
    "#model.add(Dense(16, activation=\"relu\"))\n",
    "#model.add(Dropout(0.2))\n",
    "model.add(Dense(3, activation=\"softmax\"))\n",
    "\n",
    "model.compile(loss='categorical_crossentropy', optimizer=Adam(learning_rate=0.001), metrics=['accuracy'])\n",
    "\n",
    "es=EarlyStopping(monitor=\"val_loss\",patience=90,mode=\"auto\",verbose=1)\n",
    "\n",
    "model.fit(X_train,\n",
    "          y_train,\n",
    "          epochs=1000,\n",
    "               batch_size=512,\n",
    "               validation_split=0.1,\n",
    "               verbose=1,callbacks=[es])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 172,
   "metadata": {},
   "outputs": [],
   "source": [
    "X=df.drop('Credit_Score',axis=1)\n",
    "y = df.Credit_Score\n",
    "\n",
    "smote = SMOTE() \n",
    "X, y = smote.fit_resample(X,y)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 173,
   "metadata": {},
   "outputs": [],
   "source": [
    "y=to_categorical(y, num_classes=3)\n",
    "\n",
    "X_train, X_test, y_train, y_test = train_test_split(X,y,test_size=0.15,shuffle=True,stratify=y,random_state=42)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 171,
   "metadata": {},
   "outputs": [],
   "source": [
    "X=df.drop('Credit_Score',axis=1)\n",
    "y = df.Credit_Score\n",
    "\n",
    "smote = SMOTE() \n",
    "X, y = smote.fit_resample(X,y)\n",
    "y=to_categorical(y, num_classes=3)\n",
    "\n",
    "X_train, X_test, y_train, y_test = train_test_split(X,y,test_size=0.2,random_state=42)\n",
    "\n",
    "from sklearn.preprocessing import MinMaxScaler\n",
    "scaler = MinMaxScaler()\n",
    "X_train = scaler.fit_transform(X_train)\n",
    "X_test = scaler.transform(X_test)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 165,
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.preprocessing import MinMaxScaler\n",
    "scaler = MinMaxScaler()\n",
    "X_train = scaler.fit_transform(X_train)\n",
    "X_test = scaler.transform(X_test)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 167,
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 1/1000\n",
      "239/239 [==============================] - 1s 2ms/step - loss: 0.8439 - accuracy: 0.6482 - val_loss: 0.7341 - val_accuracy: 0.7260\n",
      "Epoch 2/1000\n",
      "239/239 [==============================] - 1s 2ms/step - loss: 0.7412 - accuracy: 0.7181 - val_loss: 0.7004 - val_accuracy: 0.7345\n",
      "Epoch 3/1000\n",
      "239/239 [==============================] - 1s 2ms/step - loss: 0.7217 - accuracy: 0.7241 - val_loss: 0.6964 - val_accuracy: 0.7374\n",
      "Epoch 4/1000\n",
      "239/239 [==============================] - 1s 2ms/step - loss: 0.7119 - accuracy: 0.7280 - val_loss: 0.6881 - val_accuracy: 0.7395\n",
      "Epoch 5/1000\n",
      "239/239 [==============================] - 1s 2ms/step - loss: 0.7054 - accuracy: 0.7298 - val_loss: 0.6864 - val_accuracy: 0.7404\n",
      "Epoch 6/1000\n",
      "239/239 [==============================] - 1s 2ms/step - loss: 0.7017 - accuracy: 0.7320 - val_loss: 0.6809 - val_accuracy: 0.7387\n",
      "Epoch 7/1000\n",
      "239/239 [==============================] - 1s 2ms/step - loss: 0.6971 - accuracy: 0.7331 - val_loss: 0.6766 - val_accuracy: 0.7413\n",
      "Epoch 8/1000\n",
      "239/239 [==============================] - 1s 2ms/step - loss: 0.6944 - accuracy: 0.7329 - val_loss: 0.6748 - val_accuracy: 0.7385\n",
      "Epoch 9/1000\n",
      "239/239 [==============================] - 1s 2ms/step - loss: 0.6906 - accuracy: 0.7344 - val_loss: 0.6753 - val_accuracy: 0.7418\n",
      "Epoch 10/1000\n",
      "239/239 [==============================] - 1s 2ms/step - loss: 0.6885 - accuracy: 0.7347 - val_loss: 0.6661 - val_accuracy: 0.7447\n",
      "Epoch 11/1000\n",
      "239/239 [==============================] - 1s 2ms/step - loss: 0.6850 - accuracy: 0.7367 - val_loss: 0.6672 - val_accuracy: 0.7449\n",
      "Epoch 12/1000\n",
      "239/239 [==============================] - 1s 2ms/step - loss: 0.6838 - accuracy: 0.7368 - val_loss: 0.6652 - val_accuracy: 0.7454\n",
      "Epoch 13/1000\n",
      "239/239 [==============================] - 1s 2ms/step - loss: 0.6817 - accuracy: 0.7373 - val_loss: 0.6627 - val_accuracy: 0.7398\n",
      "Epoch 14/1000\n",
      "239/239 [==============================] - 0s 2ms/step - loss: 0.6785 - accuracy: 0.7388 - val_loss: 0.6632 - val_accuracy: 0.7449\n",
      "Epoch 15/1000\n",
      "239/239 [==============================] - 1s 2ms/step - loss: 0.6786 - accuracy: 0.7388 - val_loss: 0.6613 - val_accuracy: 0.7436\n",
      "Epoch 16/1000\n",
      "239/239 [==============================] - 1s 2ms/step - loss: 0.6763 - accuracy: 0.7396 - val_loss: 0.6586 - val_accuracy: 0.7466\n",
      "Epoch 17/1000\n",
      "239/239 [==============================] - 1s 2ms/step - loss: 0.6753 - accuracy: 0.7401 - val_loss: 0.6599 - val_accuracy: 0.7460\n",
      "Epoch 18/1000\n",
      "239/239 [==============================] - 1s 2ms/step - loss: 0.6736 - accuracy: 0.7407 - val_loss: 0.6538 - val_accuracy: 0.7477\n",
      "Epoch 19/1000\n",
      "239/239 [==============================] - 1s 2ms/step - loss: 0.6733 - accuracy: 0.7403 - val_loss: 0.6567 - val_accuracy: 0.7479\n",
      "Epoch 20/1000\n",
      "239/239 [==============================] - 1s 2ms/step - loss: 0.6715 - accuracy: 0.7420 - val_loss: 0.6541 - val_accuracy: 0.7485\n",
      "Epoch 21/1000\n",
      "239/239 [==============================] - 1s 2ms/step - loss: 0.6697 - accuracy: 0.7414 - val_loss: 0.6555 - val_accuracy: 0.7468\n",
      "Epoch 22/1000\n",
      "239/239 [==============================] - 1s 2ms/step - loss: 0.6700 - accuracy: 0.7420 - val_loss: 0.6512 - val_accuracy: 0.7485\n",
      "Epoch 23/1000\n",
      "239/239 [==============================] - 1s 2ms/step - loss: 0.6685 - accuracy: 0.7420 - val_loss: 0.6532 - val_accuracy: 0.7476\n",
      "Epoch 24/1000\n",
      "239/239 [==============================] - 1s 2ms/step - loss: 0.6681 - accuracy: 0.7428 - val_loss: 0.6551 - val_accuracy: 0.7492\n",
      "Epoch 25/1000\n",
      "239/239 [==============================] - 1s 2ms/step - loss: 0.6662 - accuracy: 0.7422 - val_loss: 0.6493 - val_accuracy: 0.7471\n",
      "Epoch 26/1000\n",
      "239/239 [==============================] - 0s 2ms/step - loss: 0.6645 - accuracy: 0.7436 - val_loss: 0.6500 - val_accuracy: 0.7493\n",
      "Epoch 27/1000\n",
      "239/239 [==============================] - 1s 2ms/step - loss: 0.6639 - accuracy: 0.7433 - val_loss: 0.6505 - val_accuracy: 0.7485\n",
      "Epoch 28/1000\n",
      "239/239 [==============================] - 1s 2ms/step - loss: 0.6643 - accuracy: 0.7438 - val_loss: 0.6478 - val_accuracy: 0.7504\n",
      "Epoch 29/1000\n",
      "239/239 [==============================] - 1s 2ms/step - loss: 0.6622 - accuracy: 0.7438 - val_loss: 0.6459 - val_accuracy: 0.7503\n",
      "Epoch 30/1000\n",
      "239/239 [==============================] - 1s 2ms/step - loss: 0.6616 - accuracy: 0.7439 - val_loss: 0.6495 - val_accuracy: 0.7501\n",
      "Epoch 31/1000\n",
      "239/239 [==============================] - 1s 2ms/step - loss: 0.6608 - accuracy: 0.7441 - val_loss: 0.6423 - val_accuracy: 0.7520\n",
      "Epoch 32/1000\n",
      "239/239 [==============================] - 1s 2ms/step - loss: 0.6604 - accuracy: 0.7440 - val_loss: 0.6469 - val_accuracy: 0.7499\n",
      "Epoch 33/1000\n",
      "239/239 [==============================] - 1s 2ms/step - loss: 0.6594 - accuracy: 0.7456 - val_loss: 0.6446 - val_accuracy: 0.7508\n",
      "Epoch 34/1000\n",
      "239/239 [==============================] - 1s 2ms/step - loss: 0.6585 - accuracy: 0.7458 - val_loss: 0.6457 - val_accuracy: 0.7505\n",
      "Epoch 35/1000\n",
      "239/239 [==============================] - 1s 2ms/step - loss: 0.6588 - accuracy: 0.7453 - val_loss: 0.6461 - val_accuracy: 0.7500\n",
      "Epoch 36/1000\n",
      "239/239 [==============================] - 1s 2ms/step - loss: 0.6587 - accuracy: 0.7448 - val_loss: 0.6426 - val_accuracy: 0.7519\n",
      "Epoch 37/1000\n",
      "239/239 [==============================] - 1s 2ms/step - loss: 0.6579 - accuracy: 0.7451 - val_loss: 0.6424 - val_accuracy: 0.7526\n",
      "Epoch 38/1000\n",
      "239/239 [==============================] - 1s 2ms/step - loss: 0.6562 - accuracy: 0.7455 - val_loss: 0.6432 - val_accuracy: 0.7507\n",
      "Epoch 39/1000\n",
      "239/239 [==============================] - 1s 2ms/step - loss: 0.6557 - accuracy: 0.7459 - val_loss: 0.6436 - val_accuracy: 0.7519\n",
      "Epoch 40/1000\n",
      "239/239 [==============================] - 1s 2ms/step - loss: 0.6553 - accuracy: 0.7454 - val_loss: 0.6424 - val_accuracy: 0.7508\n",
      "Epoch 41/1000\n",
      "239/239 [==============================] - 1s 2ms/step - loss: 0.6549 - accuracy: 0.7460 - val_loss: 0.6382 - val_accuracy: 0.7505\n",
      "Epoch 42/1000\n",
      "239/239 [==============================] - 1s 2ms/step - loss: 0.6549 - accuracy: 0.7454 - val_loss: 0.6382 - val_accuracy: 0.7520\n",
      "Epoch 43/1000\n",
      "239/239 [==============================] - 1s 2ms/step - loss: 0.6533 - accuracy: 0.7473 - val_loss: 0.6363 - val_accuracy: 0.7522\n",
      "Epoch 44/1000\n",
      "239/239 [==============================] - 1s 2ms/step - loss: 0.6527 - accuracy: 0.7468 - val_loss: 0.6439 - val_accuracy: 0.7505\n",
      "Epoch 45/1000\n",
      "239/239 [==============================] - 0s 2ms/step - loss: 0.6528 - accuracy: 0.7459 - val_loss: 0.6370 - val_accuracy: 0.7524\n",
      "Epoch 46/1000\n",
      "239/239 [==============================] - 0s 2ms/step - loss: 0.6530 - accuracy: 0.7462 - val_loss: 0.6402 - val_accuracy: 0.7518\n",
      "Epoch 47/1000\n",
      "239/239 [==============================] - 1s 2ms/step - loss: 0.6533 - accuracy: 0.7463 - val_loss: 0.6363 - val_accuracy: 0.7519\n",
      "Epoch 48/1000\n",
      "239/239 [==============================] - 1s 2ms/step - loss: 0.6519 - accuracy: 0.7471 - val_loss: 0.6373 - val_accuracy: 0.7517\n",
      "Epoch 49/1000\n",
      "239/239 [==============================] - 1s 2ms/step - loss: 0.6512 - accuracy: 0.7479 - val_loss: 0.6397 - val_accuracy: 0.7506\n",
      "Epoch 50/1000\n",
      "239/239 [==============================] - 1s 2ms/step - loss: 0.6502 - accuracy: 0.7478 - val_loss: 0.6353 - val_accuracy: 0.7527\n",
      "Epoch 51/1000\n",
      "239/239 [==============================] - 1s 2ms/step - loss: 0.6509 - accuracy: 0.7474 - val_loss: 0.6361 - val_accuracy: 0.7536\n",
      "Epoch 52/1000\n",
      "239/239 [==============================] - 1s 2ms/step - loss: 0.6506 - accuracy: 0.7474 - val_loss: 0.6381 - val_accuracy: 0.7518\n",
      "Epoch 53/1000\n",
      "239/239 [==============================] - 1s 2ms/step - loss: 0.6499 - accuracy: 0.7474 - val_loss: 0.6377 - val_accuracy: 0.7521\n",
      "Epoch 54/1000\n",
      "239/239 [==============================] - 1s 2ms/step - loss: 0.6500 - accuracy: 0.7481 - val_loss: 0.6352 - val_accuracy: 0.7516\n",
      "Epoch 55/1000\n",
      "239/239 [==============================] - 1s 2ms/step - loss: 0.6489 - accuracy: 0.7475 - val_loss: 0.6376 - val_accuracy: 0.7533\n",
      "Epoch 56/1000\n",
      "239/239 [==============================] - 1s 2ms/step - loss: 0.6487 - accuracy: 0.7477 - val_loss: 0.6352 - val_accuracy: 0.7536\n",
      "Epoch 57/1000\n",
      "239/239 [==============================] - 0s 2ms/step - loss: 0.6489 - accuracy: 0.7478 - val_loss: 0.6338 - val_accuracy: 0.7525\n",
      "Epoch 58/1000\n",
      "239/239 [==============================] - 1s 2ms/step - loss: 0.6477 - accuracy: 0.7480 - val_loss: 0.6361 - val_accuracy: 0.7536\n",
      "Epoch 59/1000\n",
      "239/239 [==============================] - 1s 2ms/step - loss: 0.6478 - accuracy: 0.7486 - val_loss: 0.6343 - val_accuracy: 0.7539\n",
      "Epoch 60/1000\n",
      "239/239 [==============================] - 1s 2ms/step - loss: 0.6480 - accuracy: 0.7481 - val_loss: 0.6308 - val_accuracy: 0.7536\n",
      "Epoch 61/1000\n",
      "239/239 [==============================] - 1s 2ms/step - loss: 0.6476 - accuracy: 0.7494 - val_loss: 0.6337 - val_accuracy: 0.7535\n",
      "Epoch 62/1000\n",
      "239/239 [==============================] - 1s 2ms/step - loss: 0.6465 - accuracy: 0.7490 - val_loss: 0.6331 - val_accuracy: 0.7521\n",
      "Epoch 63/1000\n",
      "239/239 [==============================] - 1s 2ms/step - loss: 0.6469 - accuracy: 0.7485 - val_loss: 0.6348 - val_accuracy: 0.7535\n",
      "Epoch 64/1000\n",
      "239/239 [==============================] - 1s 2ms/step - loss: 0.6462 - accuracy: 0.7493 - val_loss: 0.6349 - val_accuracy: 0.7525\n",
      "Epoch 65/1000\n",
      "239/239 [==============================] - 1s 2ms/step - loss: 0.6470 - accuracy: 0.7485 - val_loss: 0.6303 - val_accuracy: 0.7553\n",
      "Epoch 66/1000\n",
      "239/239 [==============================] - 0s 2ms/step - loss: 0.6438 - accuracy: 0.7499 - val_loss: 0.6333 - val_accuracy: 0.7543\n",
      "Epoch 67/1000\n",
      "239/239 [==============================] - 0s 2ms/step - loss: 0.6464 - accuracy: 0.7489 - val_loss: 0.6322 - val_accuracy: 0.7544\n",
      "Epoch 68/1000\n",
      "239/239 [==============================] - 1s 2ms/step - loss: 0.6438 - accuracy: 0.7493 - val_loss: 0.6317 - val_accuracy: 0.7535\n",
      "Epoch 69/1000\n",
      "239/239 [==============================] - 1s 2ms/step - loss: 0.6448 - accuracy: 0.7494 - val_loss: 0.6303 - val_accuracy: 0.7522\n",
      "Epoch 70/1000\n",
      "239/239 [==============================] - 0s 2ms/step - loss: 0.6434 - accuracy: 0.7497 - val_loss: 0.6311 - val_accuracy: 0.7539\n",
      "Epoch 71/1000\n",
      "239/239 [==============================] - 1s 2ms/step - loss: 0.6451 - accuracy: 0.7490 - val_loss: 0.6306 - val_accuracy: 0.7554\n",
      "Epoch 72/1000\n",
      "239/239 [==============================] - 1s 2ms/step - loss: 0.6447 - accuracy: 0.7498 - val_loss: 0.6274 - val_accuracy: 0.7554\n",
      "Epoch 73/1000\n",
      "239/239 [==============================] - 1s 2ms/step - loss: 0.6433 - accuracy: 0.7496 - val_loss: 0.6334 - val_accuracy: 0.7549\n",
      "Epoch 74/1000\n",
      "239/239 [==============================] - 1s 2ms/step - loss: 0.6426 - accuracy: 0.7508 - val_loss: 0.6259 - val_accuracy: 0.7567\n",
      "Epoch 75/1000\n",
      "239/239 [==============================] - 1s 2ms/step - loss: 0.6426 - accuracy: 0.7503 - val_loss: 0.6270 - val_accuracy: 0.7565\n",
      "Epoch 76/1000\n",
      "239/239 [==============================] - 0s 2ms/step - loss: 0.6430 - accuracy: 0.7496 - val_loss: 0.6326 - val_accuracy: 0.7524\n",
      "Epoch 77/1000\n",
      "239/239 [==============================] - 1s 2ms/step - loss: 0.6426 - accuracy: 0.7500 - val_loss: 0.6283 - val_accuracy: 0.7552\n",
      "Epoch 78/1000\n",
      "239/239 [==============================] - 1s 2ms/step - loss: 0.6422 - accuracy: 0.7505 - val_loss: 0.6278 - val_accuracy: 0.7564\n",
      "Epoch 79/1000\n",
      "239/239 [==============================] - 1s 2ms/step - loss: 0.6407 - accuracy: 0.7509 - val_loss: 0.6278 - val_accuracy: 0.7551\n",
      "Epoch 80/1000\n",
      "239/239 [==============================] - 0s 2ms/step - loss: 0.6409 - accuracy: 0.7511 - val_loss: 0.6247 - val_accuracy: 0.7558\n",
      "Epoch 81/1000\n",
      "239/239 [==============================] - 0s 2ms/step - loss: 0.6404 - accuracy: 0.7505 - val_loss: 0.6293 - val_accuracy: 0.7534\n",
      "Epoch 82/1000\n",
      "239/239 [==============================] - 1s 2ms/step - loss: 0.6412 - accuracy: 0.7505 - val_loss: 0.6256 - val_accuracy: 0.7570\n",
      "Epoch 83/1000\n",
      "239/239 [==============================] - 0s 2ms/step - loss: 0.6401 - accuracy: 0.7508 - val_loss: 0.6305 - val_accuracy: 0.7539\n",
      "Epoch 84/1000\n",
      "239/239 [==============================] - 0s 2ms/step - loss: 0.6389 - accuracy: 0.7508 - val_loss: 0.6247 - val_accuracy: 0.7572\n",
      "Epoch 85/1000\n",
      "239/239 [==============================] - 1s 2ms/step - loss: 0.6398 - accuracy: 0.7500 - val_loss: 0.6273 - val_accuracy: 0.7542\n",
      "Epoch 86/1000\n",
      "239/239 [==============================] - 1s 2ms/step - loss: 0.6394 - accuracy: 0.7503 - val_loss: 0.6257 - val_accuracy: 0.7557\n",
      "Epoch 87/1000\n",
      "239/239 [==============================] - 1s 2ms/step - loss: 0.6401 - accuracy: 0.7507 - val_loss: 0.6230 - val_accuracy: 0.7584\n",
      "Epoch 88/1000\n",
      "239/239 [==============================] - 1s 2ms/step - loss: 0.6400 - accuracy: 0.7514 - val_loss: 0.6280 - val_accuracy: 0.7556\n",
      "Epoch 89/1000\n",
      "239/239 [==============================] - 1s 2ms/step - loss: 0.6384 - accuracy: 0.7510 - val_loss: 0.6250 - val_accuracy: 0.7555\n",
      "Epoch 90/1000\n",
      "239/239 [==============================] - 1s 2ms/step - loss: 0.6391 - accuracy: 0.7508 - val_loss: 0.6289 - val_accuracy: 0.7530\n",
      "Epoch 91/1000\n",
      "239/239 [==============================] - 1s 2ms/step - loss: 0.6385 - accuracy: 0.7510 - val_loss: 0.6263 - val_accuracy: 0.7554\n",
      "Epoch 92/1000\n",
      "239/239 [==============================] - 1s 2ms/step - loss: 0.6371 - accuracy: 0.7513 - val_loss: 0.6280 - val_accuracy: 0.7555\n",
      "Epoch 93/1000\n",
      "239/239 [==============================] - 1s 2ms/step - loss: 0.6377 - accuracy: 0.7515 - val_loss: 0.6257 - val_accuracy: 0.7545\n",
      "Epoch 94/1000\n",
      "239/239 [==============================] - 1s 2ms/step - loss: 0.6373 - accuracy: 0.7521 - val_loss: 0.6227 - val_accuracy: 0.7561\n",
      "Epoch 95/1000\n",
      "239/239 [==============================] - 0s 2ms/step - loss: 0.6368 - accuracy: 0.7510 - val_loss: 0.6222 - val_accuracy: 0.7553\n",
      "Epoch 96/1000\n",
      "239/239 [==============================] - 0s 2ms/step - loss: 0.6372 - accuracy: 0.7504 - val_loss: 0.6226 - val_accuracy: 0.7555\n",
      "Epoch 97/1000\n",
      "239/239 [==============================] - 0s 2ms/step - loss: 0.6370 - accuracy: 0.7515 - val_loss: 0.6226 - val_accuracy: 0.7543\n",
      "Epoch 98/1000\n",
      "239/239 [==============================] - 1s 2ms/step - loss: 0.6367 - accuracy: 0.7518 - val_loss: 0.6250 - val_accuracy: 0.7544\n",
      "Epoch 99/1000\n",
      "239/239 [==============================] - 0s 2ms/step - loss: 0.6373 - accuracy: 0.7518 - val_loss: 0.6271 - val_accuracy: 0.7550\n",
      "Epoch 100/1000\n",
      "239/239 [==============================] - 0s 2ms/step - loss: 0.6359 - accuracy: 0.7521 - val_loss: 0.6244 - val_accuracy: 0.7564\n",
      "Epoch 101/1000\n",
      "239/239 [==============================] - 0s 2ms/step - loss: 0.6363 - accuracy: 0.7522 - val_loss: 0.6257 - val_accuracy: 0.7570\n",
      "Epoch 102/1000\n",
      "239/239 [==============================] - 0s 2ms/step - loss: 0.6355 - accuracy: 0.7523 - val_loss: 0.6216 - val_accuracy: 0.7564\n",
      "Epoch 103/1000\n",
      "239/239 [==============================] - 1s 2ms/step - loss: 0.6358 - accuracy: 0.7521 - val_loss: 0.6209 - val_accuracy: 0.7558\n",
      "Epoch 104/1000\n",
      "239/239 [==============================] - 1s 2ms/step - loss: 0.6359 - accuracy: 0.7518 - val_loss: 0.6225 - val_accuracy: 0.7555\n",
      "Epoch 105/1000\n",
      "239/239 [==============================] - 1s 2ms/step - loss: 0.6353 - accuracy: 0.7518 - val_loss: 0.6209 - val_accuracy: 0.7558\n",
      "Epoch 106/1000\n",
      "239/239 [==============================] - 1s 2ms/step - loss: 0.6351 - accuracy: 0.7526 - val_loss: 0.6205 - val_accuracy: 0.7594\n",
      "Epoch 107/1000\n",
      "239/239 [==============================] - 1s 2ms/step - loss: 0.6349 - accuracy: 0.7514 - val_loss: 0.6184 - val_accuracy: 0.7585\n",
      "Epoch 108/1000\n",
      "239/239 [==============================] - 1s 2ms/step - loss: 0.6354 - accuracy: 0.7524 - val_loss: 0.6234 - val_accuracy: 0.7555\n",
      "Epoch 109/1000\n",
      "239/239 [==============================] - 1s 2ms/step - loss: 0.6355 - accuracy: 0.7515 - val_loss: 0.6213 - val_accuracy: 0.7575\n",
      "Epoch 110/1000\n",
      "239/239 [==============================] - 1s 2ms/step - loss: 0.6347 - accuracy: 0.7521 - val_loss: 0.6206 - val_accuracy: 0.7579\n",
      "Epoch 111/1000\n",
      "239/239 [==============================] - 1s 2ms/step - loss: 0.6353 - accuracy: 0.7536 - val_loss: 0.6231 - val_accuracy: 0.7546\n",
      "Epoch 112/1000\n",
      "239/239 [==============================] - 1s 2ms/step - loss: 0.6345 - accuracy: 0.7530 - val_loss: 0.6204 - val_accuracy: 0.7586\n",
      "Epoch 113/1000\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "239/239 [==============================] - 1s 2ms/step - loss: 0.6338 - accuracy: 0.7525 - val_loss: 0.6263 - val_accuracy: 0.7553\n",
      "Epoch 114/1000\n",
      "239/239 [==============================] - 1s 2ms/step - loss: 0.6337 - accuracy: 0.7521 - val_loss: 0.6184 - val_accuracy: 0.7580\n",
      "Epoch 115/1000\n",
      "239/239 [==============================] - 0s 2ms/step - loss: 0.6330 - accuracy: 0.7525 - val_loss: 0.6217 - val_accuracy: 0.7550\n",
      "Epoch 116/1000\n",
      "239/239 [==============================] - 1s 2ms/step - loss: 0.6341 - accuracy: 0.7524 - val_loss: 0.6195 - val_accuracy: 0.7558\n",
      "Epoch 117/1000\n",
      "239/239 [==============================] - 0s 2ms/step - loss: 0.6335 - accuracy: 0.7531 - val_loss: 0.6180 - val_accuracy: 0.7594\n",
      "Epoch 118/1000\n",
      "239/239 [==============================] - 1s 2ms/step - loss: 0.6351 - accuracy: 0.7530 - val_loss: 0.6185 - val_accuracy: 0.7569\n",
      "Epoch 119/1000\n",
      "239/239 [==============================] - 0s 2ms/step - loss: 0.6324 - accuracy: 0.7530 - val_loss: 0.6191 - val_accuracy: 0.7574\n",
      "Epoch 120/1000\n",
      "239/239 [==============================] - 0s 2ms/step - loss: 0.6337 - accuracy: 0.7530 - val_loss: 0.6214 - val_accuracy: 0.7544\n",
      "Epoch 121/1000\n",
      "239/239 [==============================] - 1s 2ms/step - loss: 0.6320 - accuracy: 0.7532 - val_loss: 0.6206 - val_accuracy: 0.7558\n",
      "Epoch 122/1000\n",
      "239/239 [==============================] - 1s 2ms/step - loss: 0.6345 - accuracy: 0.7531 - val_loss: 0.6208 - val_accuracy: 0.7564\n",
      "Epoch 123/1000\n",
      "239/239 [==============================] - 1s 2ms/step - loss: 0.6311 - accuracy: 0.7539 - val_loss: 0.6172 - val_accuracy: 0.7585\n",
      "Epoch 124/1000\n",
      "239/239 [==============================] - 0s 2ms/step - loss: 0.6311 - accuracy: 0.7533 - val_loss: 0.6197 - val_accuracy: 0.7572\n",
      "Epoch 125/1000\n",
      "239/239 [==============================] - 1s 2ms/step - loss: 0.6327 - accuracy: 0.7539 - val_loss: 0.6191 - val_accuracy: 0.7584\n",
      "Epoch 126/1000\n",
      "239/239 [==============================] - 1s 2ms/step - loss: 0.6332 - accuracy: 0.7533 - val_loss: 0.6214 - val_accuracy: 0.7571\n",
      "Epoch 127/1000\n",
      "239/239 [==============================] - 1s 2ms/step - loss: 0.6310 - accuracy: 0.7546 - val_loss: 0.6183 - val_accuracy: 0.7583\n",
      "Epoch 128/1000\n",
      "239/239 [==============================] - 1s 2ms/step - loss: 0.6325 - accuracy: 0.7528 - val_loss: 0.6229 - val_accuracy: 0.7553\n",
      "Epoch 129/1000\n",
      "239/239 [==============================] - 0s 2ms/step - loss: 0.6316 - accuracy: 0.7537 - val_loss: 0.6203 - val_accuracy: 0.7586\n",
      "Epoch 130/1000\n",
      "239/239 [==============================] - 1s 2ms/step - loss: 0.6312 - accuracy: 0.7540 - val_loss: 0.6183 - val_accuracy: 0.7587\n",
      "Epoch 131/1000\n",
      "239/239 [==============================] - 1s 2ms/step - loss: 0.6316 - accuracy: 0.7532 - val_loss: 0.6194 - val_accuracy: 0.7566\n",
      "Epoch 132/1000\n",
      "239/239 [==============================] - 1s 2ms/step - loss: 0.6302 - accuracy: 0.7546 - val_loss: 0.6187 - val_accuracy: 0.7575\n",
      "Epoch 133/1000\n",
      "239/239 [==============================] - 0s 2ms/step - loss: 0.6305 - accuracy: 0.7538 - val_loss: 0.6219 - val_accuracy: 0.7577\n",
      "Epoch 134/1000\n",
      "239/239 [==============================] - 0s 2ms/step - loss: 0.6319 - accuracy: 0.7538 - val_loss: 0.6203 - val_accuracy: 0.7564\n",
      "Epoch 135/1000\n",
      "239/239 [==============================] - 1s 2ms/step - loss: 0.6302 - accuracy: 0.7547 - val_loss: 0.6159 - val_accuracy: 0.7594\n",
      "Epoch 136/1000\n",
      "239/239 [==============================] - 1s 2ms/step - loss: 0.6303 - accuracy: 0.7537 - val_loss: 0.6169 - val_accuracy: 0.7581\n",
      "Epoch 137/1000\n",
      "239/239 [==============================] - 1s 2ms/step - loss: 0.6291 - accuracy: 0.7551 - val_loss: 0.6161 - val_accuracy: 0.7623\n",
      "Epoch 138/1000\n",
      "239/239 [==============================] - 1s 2ms/step - loss: 0.6299 - accuracy: 0.7548 - val_loss: 0.6163 - val_accuracy: 0.7584\n",
      "Epoch 139/1000\n",
      "239/239 [==============================] - 1s 2ms/step - loss: 0.6293 - accuracy: 0.7556 - val_loss: 0.6140 - val_accuracy: 0.7621\n",
      "Epoch 140/1000\n",
      "239/239 [==============================] - 0s 2ms/step - loss: 0.6325 - accuracy: 0.7537 - val_loss: 0.6190 - val_accuracy: 0.7585\n",
      "Epoch 141/1000\n",
      "239/239 [==============================] - 1s 2ms/step - loss: 0.6294 - accuracy: 0.7548 - val_loss: 0.6167 - val_accuracy: 0.7604\n",
      "Epoch 142/1000\n",
      "239/239 [==============================] - 1s 2ms/step - loss: 0.6310 - accuracy: 0.7549 - val_loss: 0.6176 - val_accuracy: 0.7577\n",
      "Epoch 143/1000\n",
      "239/239 [==============================] - 0s 2ms/step - loss: 0.6302 - accuracy: 0.7548 - val_loss: 0.6160 - val_accuracy: 0.7607\n",
      "Epoch 144/1000\n",
      "239/239 [==============================] - 1s 2ms/step - loss: 0.6305 - accuracy: 0.7543 - val_loss: 0.6201 - val_accuracy: 0.7587\n",
      "Epoch 145/1000\n",
      "239/239 [==============================] - 1s 2ms/step - loss: 0.6305 - accuracy: 0.7541 - val_loss: 0.6189 - val_accuracy: 0.7581\n",
      "Epoch 146/1000\n",
      "239/239 [==============================] - 1s 2ms/step - loss: 0.6304 - accuracy: 0.7547 - val_loss: 0.6189 - val_accuracy: 0.7562\n",
      "Epoch 147/1000\n",
      "239/239 [==============================] - 1s 2ms/step - loss: 0.6289 - accuracy: 0.7549 - val_loss: 0.6198 - val_accuracy: 0.7581\n",
      "Epoch 148/1000\n",
      "239/239 [==============================] - 1s 2ms/step - loss: 0.6288 - accuracy: 0.7551 - val_loss: 0.6137 - val_accuracy: 0.7597\n",
      "Epoch 149/1000\n",
      "239/239 [==============================] - 1s 2ms/step - loss: 0.6300 - accuracy: 0.7544 - val_loss: 0.6170 - val_accuracy: 0.7603\n",
      "Epoch 150/1000\n",
      "239/239 [==============================] - 1s 2ms/step - loss: 0.6277 - accuracy: 0.7554 - val_loss: 0.6145 - val_accuracy: 0.7607\n",
      "Epoch 151/1000\n",
      "239/239 [==============================] - 1s 2ms/step - loss: 0.6297 - accuracy: 0.7547 - val_loss: 0.6161 - val_accuracy: 0.7578\n",
      "Epoch 152/1000\n",
      "239/239 [==============================] - 1s 2ms/step - loss: 0.6294 - accuracy: 0.7543 - val_loss: 0.6156 - val_accuracy: 0.7596\n",
      "Epoch 153/1000\n",
      "239/239 [==============================] - 1s 2ms/step - loss: 0.6290 - accuracy: 0.7542 - val_loss: 0.6152 - val_accuracy: 0.7608\n",
      "Epoch 154/1000\n",
      "239/239 [==============================] - 1s 2ms/step - loss: 0.6288 - accuracy: 0.7538 - val_loss: 0.6165 - val_accuracy: 0.7592\n",
      "Epoch 155/1000\n",
      "239/239 [==============================] - 1s 2ms/step - loss: 0.6280 - accuracy: 0.7553 - val_loss: 0.6174 - val_accuracy: 0.7592\n",
      "Epoch 156/1000\n",
      "239/239 [==============================] - 1s 2ms/step - loss: 0.6287 - accuracy: 0.7553 - val_loss: 0.6141 - val_accuracy: 0.7612\n",
      "Epoch 157/1000\n",
      "239/239 [==============================] - 1s 2ms/step - loss: 0.6279 - accuracy: 0.7551 - val_loss: 0.6141 - val_accuracy: 0.7605\n",
      "Epoch 158/1000\n",
      "239/239 [==============================] - 1s 2ms/step - loss: 0.6302 - accuracy: 0.7537 - val_loss: 0.6168 - val_accuracy: 0.7583\n",
      "Epoch 159/1000\n",
      "239/239 [==============================] - 1s 2ms/step - loss: 0.6288 - accuracy: 0.7547 - val_loss: 0.6189 - val_accuracy: 0.7594\n",
      "Epoch 160/1000\n",
      "239/239 [==============================] - 1s 2ms/step - loss: 0.6290 - accuracy: 0.7543 - val_loss: 0.6153 - val_accuracy: 0.7600\n",
      "Epoch 161/1000\n",
      "239/239 [==============================] - 1s 2ms/step - loss: 0.6282 - accuracy: 0.7548 - val_loss: 0.6151 - val_accuracy: 0.7591\n",
      "Epoch 162/1000\n",
      "239/239 [==============================] - 1s 2ms/step - loss: 0.6280 - accuracy: 0.7551 - val_loss: 0.6160 - val_accuracy: 0.7601\n",
      "Epoch 163/1000\n",
      "239/239 [==============================] - 0s 2ms/step - loss: 0.6292 - accuracy: 0.7555 - val_loss: 0.6184 - val_accuracy: 0.7578\n",
      "Epoch 164/1000\n",
      "239/239 [==============================] - 1s 2ms/step - loss: 0.6275 - accuracy: 0.7543 - val_loss: 0.6176 - val_accuracy: 0.7586\n",
      "Epoch 165/1000\n",
      "239/239 [==============================] - 1s 2ms/step - loss: 0.6287 - accuracy: 0.7549 - val_loss: 0.6169 - val_accuracy: 0.7571\n",
      "Epoch 166/1000\n",
      "239/239 [==============================] - 1s 2ms/step - loss: 0.6282 - accuracy: 0.7540 - val_loss: 0.6142 - val_accuracy: 0.7597\n",
      "Epoch 167/1000\n",
      "239/239 [==============================] - 1s 2ms/step - loss: 0.6284 - accuracy: 0.7549 - val_loss: 0.6176 - val_accuracy: 0.7592\n",
      "Epoch 168/1000\n",
      "239/239 [==============================] - 1s 2ms/step - loss: 0.6269 - accuracy: 0.7558 - val_loss: 0.6149 - val_accuracy: 0.7593\n",
      "Epoch 169/1000\n",
      "239/239 [==============================] - 1s 2ms/step - loss: 0.6270 - accuracy: 0.7551 - val_loss: 0.6135 - val_accuracy: 0.7606\n",
      "Epoch 170/1000\n",
      "239/239 [==============================] - 1s 2ms/step - loss: 0.6266 - accuracy: 0.7554 - val_loss: 0.6125 - val_accuracy: 0.7633\n",
      "Epoch 171/1000\n",
      "239/239 [==============================] - 1s 2ms/step - loss: 0.6280 - accuracy: 0.7547 - val_loss: 0.6137 - val_accuracy: 0.7590\n",
      "Epoch 172/1000\n",
      "239/239 [==============================] - 1s 2ms/step - loss: 0.6281 - accuracy: 0.7545 - val_loss: 0.6163 - val_accuracy: 0.7591\n",
      "Epoch 173/1000\n",
      "239/239 [==============================] - 1s 2ms/step - loss: 0.6287 - accuracy: 0.7542 - val_loss: 0.6172 - val_accuracy: 0.7560\n",
      "Epoch 174/1000\n",
      "239/239 [==============================] - 1s 2ms/step - loss: 0.6275 - accuracy: 0.7552 - val_loss: 0.6133 - val_accuracy: 0.7603\n",
      "Epoch 175/1000\n",
      "239/239 [==============================] - 0s 2ms/step - loss: 0.6286 - accuracy: 0.7545 - val_loss: 0.6179 - val_accuracy: 0.7564\n",
      "Epoch 176/1000\n",
      "239/239 [==============================] - 1s 2ms/step - loss: 0.6284 - accuracy: 0.7556 - val_loss: 0.6088 - val_accuracy: 0.7635\n",
      "Epoch 177/1000\n",
      "239/239 [==============================] - 1s 2ms/step - loss: 0.6268 - accuracy: 0.7556 - val_loss: 0.6116 - val_accuracy: 0.7609\n",
      "Epoch 178/1000\n",
      "239/239 [==============================] - 1s 2ms/step - loss: 0.6266 - accuracy: 0.7553 - val_loss: 0.6132 - val_accuracy: 0.7606\n",
      "Epoch 179/1000\n",
      "239/239 [==============================] - 0s 2ms/step - loss: 0.6271 - accuracy: 0.7553 - val_loss: 0.6124 - val_accuracy: 0.7602\n",
      "Epoch 180/1000\n",
      "239/239 [==============================] - 0s 2ms/step - loss: 0.6275 - accuracy: 0.7552 - val_loss: 0.6146 - val_accuracy: 0.7587\n",
      "Epoch 181/1000\n",
      "239/239 [==============================] - 1s 2ms/step - loss: 0.6263 - accuracy: 0.7554 - val_loss: 0.6146 - val_accuracy: 0.7598\n",
      "Epoch 182/1000\n",
      "239/239 [==============================] - 1s 2ms/step - loss: 0.6261 - accuracy: 0.7557 - val_loss: 0.6151 - val_accuracy: 0.7622\n",
      "Epoch 183/1000\n",
      "239/239 [==============================] - 1s 2ms/step - loss: 0.6270 - accuracy: 0.7553 - val_loss: 0.6146 - val_accuracy: 0.7601\n",
      "Epoch 184/1000\n",
      "239/239 [==============================] - 1s 2ms/step - loss: 0.6265 - accuracy: 0.7561 - val_loss: 0.6189 - val_accuracy: 0.7573\n",
      "Epoch 185/1000\n",
      "239/239 [==============================] - 1s 2ms/step - loss: 0.6271 - accuracy: 0.7549 - val_loss: 0.6144 - val_accuracy: 0.7604\n",
      "Epoch 186/1000\n",
      "239/239 [==============================] - 1s 2ms/step - loss: 0.6255 - accuracy: 0.7559 - val_loss: 0.6188 - val_accuracy: 0.7578\n",
      "Epoch 187/1000\n",
      "239/239 [==============================] - 1s 2ms/step - loss: 0.6251 - accuracy: 0.7568 - val_loss: 0.6097 - val_accuracy: 0.7608\n",
      "Epoch 188/1000\n",
      "239/239 [==============================] - 1s 2ms/step - loss: 0.6250 - accuracy: 0.7566 - val_loss: 0.6150 - val_accuracy: 0.7596\n",
      "Epoch 189/1000\n",
      "239/239 [==============================] - 1s 2ms/step - loss: 0.6255 - accuracy: 0.7558 - val_loss: 0.6176 - val_accuracy: 0.7607\n",
      "Epoch 190/1000\n",
      "239/239 [==============================] - 1s 2ms/step - loss: 0.6240 - accuracy: 0.7566 - val_loss: 0.6152 - val_accuracy: 0.7629\n",
      "Epoch 191/1000\n",
      "239/239 [==============================] - 1s 2ms/step - loss: 0.6255 - accuracy: 0.7556 - val_loss: 0.6164 - val_accuracy: 0.7605\n",
      "Epoch 192/1000\n",
      "239/239 [==============================] - 1s 2ms/step - loss: 0.6270 - accuracy: 0.7553 - val_loss: 0.6171 - val_accuracy: 0.7581\n",
      "Epoch 193/1000\n",
      "239/239 [==============================] - 1s 2ms/step - loss: 0.6273 - accuracy: 0.7552 - val_loss: 0.6177 - val_accuracy: 0.7580\n",
      "Epoch 194/1000\n",
      "239/239 [==============================] - 1s 2ms/step - loss: 0.6253 - accuracy: 0.7553 - val_loss: 0.6158 - val_accuracy: 0.7604\n",
      "Epoch 195/1000\n",
      "239/239 [==============================] - 1s 2ms/step - loss: 0.6259 - accuracy: 0.7550 - val_loss: 0.6141 - val_accuracy: 0.7595\n",
      "Epoch 196/1000\n",
      "239/239 [==============================] - 1s 2ms/step - loss: 0.6264 - accuracy: 0.7560 - val_loss: 0.6139 - val_accuracy: 0.7600\n",
      "Epoch 197/1000\n",
      "239/239 [==============================] - 1s 2ms/step - loss: 0.6268 - accuracy: 0.7553 - val_loss: 0.6186 - val_accuracy: 0.7591\n",
      "Epoch 198/1000\n",
      "239/239 [==============================] - 1s 2ms/step - loss: 0.6261 - accuracy: 0.7557 - val_loss: 0.6177 - val_accuracy: 0.7593\n",
      "Epoch 199/1000\n",
      "239/239 [==============================] - 1s 2ms/step - loss: 0.6261 - accuracy: 0.7559 - val_loss: 0.6097 - val_accuracy: 0.7615\n",
      "Epoch 200/1000\n",
      "239/239 [==============================] - 1s 2ms/step - loss: 0.6261 - accuracy: 0.7563 - val_loss: 0.6156 - val_accuracy: 0.7597\n",
      "Epoch 201/1000\n",
      "239/239 [==============================] - 1s 2ms/step - loss: 0.6273 - accuracy: 0.7545 - val_loss: 0.6171 - val_accuracy: 0.7598\n",
      "Epoch 202/1000\n",
      "239/239 [==============================] - 1s 2ms/step - loss: 0.6255 - accuracy: 0.7560 - val_loss: 0.6150 - val_accuracy: 0.7585\n",
      "Epoch 203/1000\n",
      "239/239 [==============================] - 1s 2ms/step - loss: 0.6250 - accuracy: 0.7557 - val_loss: 0.6098 - val_accuracy: 0.7608\n",
      "Epoch 204/1000\n",
      "239/239 [==============================] - 1s 2ms/step - loss: 0.6247 - accuracy: 0.7559 - val_loss: 0.6168 - val_accuracy: 0.7580\n",
      "Epoch 205/1000\n",
      "239/239 [==============================] - 1s 2ms/step - loss: 0.6254 - accuracy: 0.7558 - val_loss: 0.6126 - val_accuracy: 0.7604\n",
      "Epoch 206/1000\n",
      "239/239 [==============================] - 1s 2ms/step - loss: 0.6245 - accuracy: 0.7560 - val_loss: 0.6130 - val_accuracy: 0.7606\n",
      "Epoch 207/1000\n",
      "239/239 [==============================] - 0s 2ms/step - loss: 0.6254 - accuracy: 0.7555 - val_loss: 0.6160 - val_accuracy: 0.7593\n",
      "Epoch 208/1000\n",
      "239/239 [==============================] - 1s 2ms/step - loss: 0.6266 - accuracy: 0.7559 - val_loss: 0.6178 - val_accuracy: 0.7576\n",
      "Epoch 209/1000\n",
      "239/239 [==============================] - 1s 2ms/step - loss: 0.6257 - accuracy: 0.7568 - val_loss: 0.6128 - val_accuracy: 0.7601\n",
      "Epoch 210/1000\n",
      "239/239 [==============================] - 1s 2ms/step - loss: 0.6253 - accuracy: 0.7563 - val_loss: 0.6159 - val_accuracy: 0.7561\n",
      "Epoch 211/1000\n",
      "239/239 [==============================] - 1s 2ms/step - loss: 0.6237 - accuracy: 0.7556 - val_loss: 0.6173 - val_accuracy: 0.7598\n",
      "Epoch 212/1000\n",
      "239/239 [==============================] - 1s 2ms/step - loss: 0.6245 - accuracy: 0.7565 - val_loss: 0.6144 - val_accuracy: 0.7607\n",
      "Epoch 213/1000\n",
      "239/239 [==============================] - 1s 2ms/step - loss: 0.6244 - accuracy: 0.7562 - val_loss: 0.6178 - val_accuracy: 0.7595\n",
      "Epoch 214/1000\n",
      "239/239 [==============================] - 1s 2ms/step - loss: 0.6245 - accuracy: 0.7552 - val_loss: 0.6140 - val_accuracy: 0.7605\n",
      "Epoch 215/1000\n",
      "239/239 [==============================] - 1s 2ms/step - loss: 0.6245 - accuracy: 0.7566 - val_loss: 0.6141 - val_accuracy: 0.7601\n",
      "Epoch 216/1000\n",
      "239/239 [==============================] - 1s 2ms/step - loss: 0.6256 - accuracy: 0.7568 - val_loss: 0.6125 - val_accuracy: 0.7615\n",
      "Epoch 217/1000\n",
      "239/239 [==============================] - 1s 2ms/step - loss: 0.6250 - accuracy: 0.7566 - val_loss: 0.6131 - val_accuracy: 0.7598\n",
      "Epoch 218/1000\n",
      "239/239 [==============================] - 1s 2ms/step - loss: 0.6237 - accuracy: 0.7572 - val_loss: 0.6112 - val_accuracy: 0.7606\n",
      "Epoch 219/1000\n",
      "239/239 [==============================] - 1s 2ms/step - loss: 0.6243 - accuracy: 0.7569 - val_loss: 0.6131 - val_accuracy: 0.7618\n",
      "Epoch 220/1000\n",
      "239/239 [==============================] - 1s 2ms/step - loss: 0.6220 - accuracy: 0.7574 - val_loss: 0.6123 - val_accuracy: 0.7632\n",
      "Epoch 221/1000\n",
      "239/239 [==============================] - 1s 2ms/step - loss: 0.6245 - accuracy: 0.7562 - val_loss: 0.6135 - val_accuracy: 0.7607\n",
      "Epoch 222/1000\n",
      "239/239 [==============================] - 1s 2ms/step - loss: 0.6251 - accuracy: 0.7564 - val_loss: 0.6156 - val_accuracy: 0.7601\n",
      "Epoch 223/1000\n",
      "239/239 [==============================] - 1s 2ms/step - loss: 0.6248 - accuracy: 0.7559 - val_loss: 0.6119 - val_accuracy: 0.7596\n",
      "Epoch 224/1000\n",
      "239/239 [==============================] - 1s 2ms/step - loss: 0.6228 - accuracy: 0.7570 - val_loss: 0.6119 - val_accuracy: 0.7601\n",
      "Epoch 225/1000\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "239/239 [==============================] - 1s 2ms/step - loss: 0.6244 - accuracy: 0.7567 - val_loss: 0.6143 - val_accuracy: 0.7603\n",
      "Epoch 226/1000\n",
      "239/239 [==============================] - 1s 2ms/step - loss: 0.6239 - accuracy: 0.7570 - val_loss: 0.6104 - val_accuracy: 0.7613\n",
      "Epoch 227/1000\n",
      "239/239 [==============================] - 1s 2ms/step - loss: 0.6238 - accuracy: 0.7568 - val_loss: 0.6191 - val_accuracy: 0.7587\n",
      "Epoch 228/1000\n",
      "239/239 [==============================] - 1s 2ms/step - loss: 0.6240 - accuracy: 0.7564 - val_loss: 0.6105 - val_accuracy: 0.7627\n",
      "Epoch 229/1000\n",
      "239/239 [==============================] - 1s 2ms/step - loss: 0.6217 - accuracy: 0.7570 - val_loss: 0.6119 - val_accuracy: 0.7618\n",
      "Epoch 230/1000\n",
      "239/239 [==============================] - 1s 2ms/step - loss: 0.6245 - accuracy: 0.7571 - val_loss: 0.6099 - val_accuracy: 0.7626\n",
      "Epoch 231/1000\n",
      "239/239 [==============================] - 1s 2ms/step - loss: 0.6236 - accuracy: 0.7564 - val_loss: 0.6144 - val_accuracy: 0.7626\n",
      "Epoch 232/1000\n",
      "239/239 [==============================] - 1s 2ms/step - loss: 0.6230 - accuracy: 0.7576 - val_loss: 0.6071 - val_accuracy: 0.7640\n",
      "Epoch 233/1000\n",
      "239/239 [==============================] - 1s 2ms/step - loss: 0.6217 - accuracy: 0.7573 - val_loss: 0.6096 - val_accuracy: 0.7625\n",
      "Epoch 234/1000\n",
      "239/239 [==============================] - 1s 2ms/step - loss: 0.6231 - accuracy: 0.7569 - val_loss: 0.6099 - val_accuracy: 0.7636\n",
      "Epoch 235/1000\n",
      "239/239 [==============================] - 1s 2ms/step - loss: 0.6228 - accuracy: 0.7574 - val_loss: 0.6134 - val_accuracy: 0.7592\n",
      "Epoch 236/1000\n",
      "239/239 [==============================] - 1s 2ms/step - loss: 0.6229 - accuracy: 0.7571 - val_loss: 0.6092 - val_accuracy: 0.7623\n",
      "Epoch 237/1000\n",
      "239/239 [==============================] - 1s 2ms/step - loss: 0.6234 - accuracy: 0.7569 - val_loss: 0.6158 - val_accuracy: 0.7583\n",
      "Epoch 238/1000\n",
      "239/239 [==============================] - 1s 2ms/step - loss: 0.6232 - accuracy: 0.7567 - val_loss: 0.6131 - val_accuracy: 0.7608\n",
      "Epoch 239/1000\n",
      "239/239 [==============================] - 1s 2ms/step - loss: 0.6238 - accuracy: 0.7564 - val_loss: 0.6112 - val_accuracy: 0.7603\n",
      "Epoch 240/1000\n",
      "239/239 [==============================] - 1s 2ms/step - loss: 0.6243 - accuracy: 0.7564 - val_loss: 0.6176 - val_accuracy: 0.7572\n",
      "Epoch 241/1000\n",
      "239/239 [==============================] - 1s 2ms/step - loss: 0.6225 - accuracy: 0.7576 - val_loss: 0.6149 - val_accuracy: 0.7592\n",
      "Epoch 242/1000\n",
      "239/239 [==============================] - 1s 2ms/step - loss: 0.6233 - accuracy: 0.7566 - val_loss: 0.6116 - val_accuracy: 0.7592\n",
      "Epoch 243/1000\n",
      "239/239 [==============================] - 1s 2ms/step - loss: 0.6231 - accuracy: 0.7578 - val_loss: 0.6092 - val_accuracy: 0.7630\n",
      "Epoch 244/1000\n",
      "239/239 [==============================] - 1s 2ms/step - loss: 0.6220 - accuracy: 0.7574 - val_loss: 0.6172 - val_accuracy: 0.7587\n",
      "Epoch 245/1000\n",
      "239/239 [==============================] - 1s 2ms/step - loss: 0.6227 - accuracy: 0.7573 - val_loss: 0.6109 - val_accuracy: 0.7633\n",
      "Epoch 246/1000\n",
      "239/239 [==============================] - 1s 2ms/step - loss: 0.6221 - accuracy: 0.7573 - val_loss: 0.6088 - val_accuracy: 0.7626\n",
      "Epoch 247/1000\n",
      "239/239 [==============================] - 1s 2ms/step - loss: 0.6228 - accuracy: 0.7570 - val_loss: 0.6108 - val_accuracy: 0.7623\n",
      "Epoch 248/1000\n",
      "239/239 [==============================] - 1s 2ms/step - loss: 0.6222 - accuracy: 0.7568 - val_loss: 0.6091 - val_accuracy: 0.7618\n",
      "Epoch 249/1000\n",
      "239/239 [==============================] - 1s 2ms/step - loss: 0.6218 - accuracy: 0.7577 - val_loss: 0.6109 - val_accuracy: 0.7621\n",
      "Epoch 250/1000\n",
      "239/239 [==============================] - 1s 2ms/step - loss: 0.6218 - accuracy: 0.7581 - val_loss: 0.6164 - val_accuracy: 0.7594\n",
      "Epoch 251/1000\n",
      "239/239 [==============================] - 1s 2ms/step - loss: 0.6218 - accuracy: 0.7575 - val_loss: 0.6075 - val_accuracy: 0.7646\n",
      "Epoch 252/1000\n",
      "239/239 [==============================] - 1s 2ms/step - loss: 0.6232 - accuracy: 0.7569 - val_loss: 0.6155 - val_accuracy: 0.7606\n",
      "Epoch 253/1000\n",
      "239/239 [==============================] - 1s 2ms/step - loss: 0.6215 - accuracy: 0.7581 - val_loss: 0.6109 - val_accuracy: 0.7623\n",
      "Epoch 254/1000\n",
      "239/239 [==============================] - 0s 2ms/step - loss: 0.6217 - accuracy: 0.7569 - val_loss: 0.6097 - val_accuracy: 0.7615\n",
      "Epoch 255/1000\n",
      "239/239 [==============================] - 1s 2ms/step - loss: 0.6238 - accuracy: 0.7572 - val_loss: 0.6086 - val_accuracy: 0.7640\n",
      "Epoch 256/1000\n",
      "239/239 [==============================] - 1s 2ms/step - loss: 0.6228 - accuracy: 0.7575 - val_loss: 0.6157 - val_accuracy: 0.7615\n",
      "Epoch 257/1000\n",
      "239/239 [==============================] - 1s 2ms/step - loss: 0.6219 - accuracy: 0.7578 - val_loss: 0.6095 - val_accuracy: 0.7638\n",
      "Epoch 258/1000\n",
      "239/239 [==============================] - 1s 2ms/step - loss: 0.6218 - accuracy: 0.7581 - val_loss: 0.6145 - val_accuracy: 0.7620\n",
      "Epoch 259/1000\n",
      "239/239 [==============================] - 1s 2ms/step - loss: 0.6218 - accuracy: 0.7568 - val_loss: 0.6088 - val_accuracy: 0.7623\n",
      "Epoch 260/1000\n",
      "239/239 [==============================] - 1s 2ms/step - loss: 0.6233 - accuracy: 0.7566 - val_loss: 0.6140 - val_accuracy: 0.7599\n",
      "Epoch 261/1000\n",
      "239/239 [==============================] - 1s 2ms/step - loss: 0.6226 - accuracy: 0.7570 - val_loss: 0.6152 - val_accuracy: 0.7571\n",
      "Epoch 262/1000\n",
      "239/239 [==============================] - 1s 2ms/step - loss: 0.6241 - accuracy: 0.7568 - val_loss: 0.6186 - val_accuracy: 0.7574\n",
      "Epoch 263/1000\n",
      "239/239 [==============================] - 1s 2ms/step - loss: 0.6229 - accuracy: 0.7569 - val_loss: 0.6124 - val_accuracy: 0.7581\n",
      "Epoch 264/1000\n",
      "239/239 [==============================] - 1s 4ms/step - loss: 0.6222 - accuracy: 0.7570 - val_loss: 0.6118 - val_accuracy: 0.7612\n",
      "Epoch 265/1000\n",
      "239/239 [==============================] - 0s 2ms/step - loss: 0.6233 - accuracy: 0.7551 - val_loss: 0.6103 - val_accuracy: 0.7625\n",
      "Epoch 266/1000\n",
      "239/239 [==============================] - 1s 2ms/step - loss: 0.6222 - accuracy: 0.7574 - val_loss: 0.6117 - val_accuracy: 0.7615\n",
      "Epoch 267/1000\n",
      "239/239 [==============================] - 1s 2ms/step - loss: 0.6228 - accuracy: 0.7565 - val_loss: 0.6132 - val_accuracy: 0.7620\n",
      "Epoch 268/1000\n",
      "239/239 [==============================] - 1s 2ms/step - loss: 0.6224 - accuracy: 0.7574 - val_loss: 0.6107 - val_accuracy: 0.7610\n",
      "Epoch 269/1000\n",
      "239/239 [==============================] - 1s 2ms/step - loss: 0.6224 - accuracy: 0.7580 - val_loss: 0.6150 - val_accuracy: 0.7587\n",
      "Epoch 270/1000\n",
      "239/239 [==============================] - 1s 2ms/step - loss: 0.6233 - accuracy: 0.7571 - val_loss: 0.6100 - val_accuracy: 0.7634\n",
      "Epoch 271/1000\n",
      "239/239 [==============================] - 1s 2ms/step - loss: 0.6213 - accuracy: 0.7566 - val_loss: 0.6132 - val_accuracy: 0.7598\n",
      "Epoch 272/1000\n",
      "239/239 [==============================] - 1s 2ms/step - loss: 0.6220 - accuracy: 0.7575 - val_loss: 0.6121 - val_accuracy: 0.7606\n",
      "Epoch 273/1000\n",
      "239/239 [==============================] - 1s 2ms/step - loss: 0.6215 - accuracy: 0.7589 - val_loss: 0.6085 - val_accuracy: 0.7623\n",
      "Epoch 274/1000\n",
      "239/239 [==============================] - 1s 2ms/step - loss: 0.6219 - accuracy: 0.7576 - val_loss: 0.6123 - val_accuracy: 0.7601\n",
      "Epoch 275/1000\n",
      "239/239 [==============================] - 1s 2ms/step - loss: 0.6216 - accuracy: 0.7581 - val_loss: 0.6108 - val_accuracy: 0.7617\n",
      "Epoch 276/1000\n",
      "239/239 [==============================] - 1019s 4s/step - loss: 0.6211 - accuracy: 0.7579 - val_loss: 0.6125 - val_accuracy: 0.7601\n",
      "Epoch 277/1000\n",
      "239/239 [==============================] - 1s 2ms/step - loss: 0.6210 - accuracy: 0.7585 - val_loss: 0.6104 - val_accuracy: 0.7612\n",
      "Epoch 278/1000\n",
      "239/239 [==============================] - 1s 2ms/step - loss: 0.6212 - accuracy: 0.7579 - val_loss: 0.6095 - val_accuracy: 0.7621\n",
      "Epoch 279/1000\n",
      "239/239 [==============================] - 1s 2ms/step - loss: 0.6223 - accuracy: 0.7573 - val_loss: 0.6080 - val_accuracy: 0.7640\n",
      "Epoch 280/1000\n",
      "239/239 [==============================] - 1s 2ms/step - loss: 0.6214 - accuracy: 0.7574 - val_loss: 0.6067 - val_accuracy: 0.7620\n",
      "Epoch 281/1000\n",
      "239/239 [==============================] - 1s 2ms/step - loss: 0.6217 - accuracy: 0.7570 - val_loss: 0.6122 - val_accuracy: 0.7605\n",
      "Epoch 282/1000\n",
      "239/239 [==============================] - 1s 2ms/step - loss: 0.6194 - accuracy: 0.7586 - val_loss: 0.6090 - val_accuracy: 0.7629\n",
      "Epoch 283/1000\n",
      "239/239 [==============================] - 1s 2ms/step - loss: 0.6210 - accuracy: 0.7568 - val_loss: 0.6077 - val_accuracy: 0.7632\n",
      "Epoch 284/1000\n",
      "239/239 [==============================] - 1s 2ms/step - loss: 0.6215 - accuracy: 0.7585 - val_loss: 0.6133 - val_accuracy: 0.7614\n",
      "Epoch 285/1000\n",
      "239/239 [==============================] - 922s 4s/step - loss: 0.6199 - accuracy: 0.7585 - val_loss: 0.6104 - val_accuracy: 0.7612\n",
      "Epoch 286/1000\n",
      "239/239 [==============================] - 1s 3ms/step - loss: 0.6207 - accuracy: 0.7570 - val_loss: 0.6123 - val_accuracy: 0.7603\n",
      "Epoch 287/1000\n",
      "239/239 [==============================] - 1s 2ms/step - loss: 0.6215 - accuracy: 0.7578 - val_loss: 0.6102 - val_accuracy: 0.7630\n",
      "Epoch 288/1000\n",
      "239/239 [==============================] - 1s 2ms/step - loss: 0.6217 - accuracy: 0.7570 - val_loss: 0.6170 - val_accuracy: 0.7601\n",
      "Epoch 289/1000\n",
      "239/239 [==============================] - 1s 2ms/step - loss: 0.6209 - accuracy: 0.7578 - val_loss: 0.6081 - val_accuracy: 0.7599\n",
      "Epoch 290/1000\n",
      "239/239 [==============================] - 1s 4ms/step - loss: 0.6213 - accuracy: 0.7574 - val_loss: 0.6095 - val_accuracy: 0.7605\n",
      "Epoch 291/1000\n",
      "239/239 [==============================] - 1s 3ms/step - loss: 0.6215 - accuracy: 0.7585 - val_loss: 0.6127 - val_accuracy: 0.7601\n",
      "Epoch 292/1000\n",
      "239/239 [==============================] - 1s 2ms/step - loss: 0.6221 - accuracy: 0.7566 - val_loss: 0.6121 - val_accuracy: 0.7626\n",
      "Epoch 293/1000\n",
      "239/239 [==============================] - 1s 2ms/step - loss: 0.6205 - accuracy: 0.7583 - val_loss: 0.6109 - val_accuracy: 0.7638\n",
      "Epoch 294/1000\n",
      "239/239 [==============================] - 1s 2ms/step - loss: 0.6215 - accuracy: 0.7582 - val_loss: 0.6090 - val_accuracy: 0.7611\n",
      "Epoch 295/1000\n",
      "239/239 [==============================] - 1s 2ms/step - loss: 0.6207 - accuracy: 0.7583 - val_loss: 0.6106 - val_accuracy: 0.7626\n",
      "Epoch 296/1000\n",
      "239/239 [==============================] - 1s 2ms/step - loss: 0.6223 - accuracy: 0.7574 - val_loss: 0.6141 - val_accuracy: 0.7599\n",
      "Epoch 297/1000\n",
      "239/239 [==============================] - 1s 2ms/step - loss: 0.6211 - accuracy: 0.7573 - val_loss: 0.6107 - val_accuracy: 0.7602\n",
      "Epoch 298/1000\n",
      "239/239 [==============================] - 1s 2ms/step - loss: 0.6210 - accuracy: 0.7573 - val_loss: 0.6129 - val_accuracy: 0.7589\n",
      "Epoch 299/1000\n",
      "239/239 [==============================] - 1s 2ms/step - loss: 0.6217 - accuracy: 0.7576 - val_loss: 0.6096 - val_accuracy: 0.7615\n",
      "Epoch 300/1000\n",
      "239/239 [==============================] - 1s 2ms/step - loss: 0.6211 - accuracy: 0.7579 - val_loss: 0.6122 - val_accuracy: 0.7615\n",
      "Epoch 301/1000\n",
      "239/239 [==============================] - 1s 2ms/step - loss: 0.6192 - accuracy: 0.7591 - val_loss: 0.6091 - val_accuracy: 0.7620\n",
      "Epoch 302/1000\n",
      "239/239 [==============================] - 1s 2ms/step - loss: 0.6202 - accuracy: 0.7579 - val_loss: 0.6111 - val_accuracy: 0.7610\n",
      "Epoch 303/1000\n",
      "239/239 [==============================] - 1s 2ms/step - loss: 0.6227 - accuracy: 0.7575 - val_loss: 0.6122 - val_accuracy: 0.7590\n",
      "Epoch 304/1000\n",
      "239/239 [==============================] - 1s 2ms/step - loss: 0.6233 - accuracy: 0.7562 - val_loss: 0.6135 - val_accuracy: 0.7602\n",
      "Epoch 305/1000\n",
      "239/239 [==============================] - 1s 2ms/step - loss: 0.6212 - accuracy: 0.7570 - val_loss: 0.6121 - val_accuracy: 0.7606\n",
      "Epoch 306/1000\n",
      "239/239 [==============================] - 1s 2ms/step - loss: 0.6206 - accuracy: 0.7581 - val_loss: 0.6130 - val_accuracy: 0.7602\n",
      "Epoch 307/1000\n",
      "239/239 [==============================] - 1s 2ms/step - loss: 0.6208 - accuracy: 0.7570 - val_loss: 0.6143 - val_accuracy: 0.7620\n",
      "Epoch 308/1000\n",
      "239/239 [==============================] - 1s 2ms/step - loss: 0.6196 - accuracy: 0.7582 - val_loss: 0.6132 - val_accuracy: 0.7622\n",
      "Epoch 309/1000\n",
      "239/239 [==============================] - 1s 2ms/step - loss: 0.6224 - accuracy: 0.7571 - val_loss: 0.6149 - val_accuracy: 0.7609\n",
      "Epoch 310/1000\n",
      "239/239 [==============================] - 1s 2ms/step - loss: 0.6203 - accuracy: 0.7585 - val_loss: 0.6127 - val_accuracy: 0.7617\n",
      "Epoch 311/1000\n",
      "239/239 [==============================] - 1s 2ms/step - loss: 0.6214 - accuracy: 0.7574 - val_loss: 0.6097 - val_accuracy: 0.7631\n",
      "Epoch 312/1000\n",
      "239/239 [==============================] - 1s 2ms/step - loss: 0.6205 - accuracy: 0.7572 - val_loss: 0.6080 - val_accuracy: 0.7630\n",
      "Epoch 313/1000\n",
      "239/239 [==============================] - 1s 2ms/step - loss: 0.6207 - accuracy: 0.7585 - val_loss: 0.6084 - val_accuracy: 0.7657\n",
      "Epoch 314/1000\n",
      "239/239 [==============================] - 1s 2ms/step - loss: 0.6210 - accuracy: 0.7578 - val_loss: 0.6079 - val_accuracy: 0.7623\n",
      "Epoch 315/1000\n",
      "239/239 [==============================] - 1s 2ms/step - loss: 0.6205 - accuracy: 0.7579 - val_loss: 0.6156 - val_accuracy: 0.7603\n",
      "Epoch 316/1000\n",
      "239/239 [==============================] - 1s 2ms/step - loss: 0.6207 - accuracy: 0.7578 - val_loss: 0.6136 - val_accuracy: 0.7620\n",
      "Epoch 317/1000\n",
      "239/239 [==============================] - 1s 2ms/step - loss: 0.6202 - accuracy: 0.7581 - val_loss: 0.6178 - val_accuracy: 0.7610\n",
      "Epoch 318/1000\n",
      "239/239 [==============================] - 1s 2ms/step - loss: 0.6200 - accuracy: 0.7588 - val_loss: 0.6152 - val_accuracy: 0.7609\n",
      "Epoch 319/1000\n",
      "239/239 [==============================] - 1s 2ms/step - loss: 0.6206 - accuracy: 0.7575 - val_loss: 0.6119 - val_accuracy: 0.7612\n",
      "Epoch 320/1000\n",
      "239/239 [==============================] - 1s 2ms/step - loss: 0.6204 - accuracy: 0.7578 - val_loss: 0.6086 - val_accuracy: 0.7629\n",
      "Epoch 321/1000\n",
      "239/239 [==============================] - 1s 2ms/step - loss: 0.6222 - accuracy: 0.7572 - val_loss: 0.6139 - val_accuracy: 0.7622\n",
      "Epoch 322/1000\n",
      "239/239 [==============================] - 1s 2ms/step - loss: 0.6200 - accuracy: 0.7580 - val_loss: 0.6061 - val_accuracy: 0.7634\n",
      "Epoch 323/1000\n",
      "239/239 [==============================] - 1s 2ms/step - loss: 0.6213 - accuracy: 0.7581 - val_loss: 0.6094 - val_accuracy: 0.7622\n",
      "Epoch 324/1000\n",
      "239/239 [==============================] - 1s 2ms/step - loss: 0.6201 - accuracy: 0.7575 - val_loss: 0.6082 - val_accuracy: 0.7633\n",
      "Epoch 325/1000\n",
      "239/239 [==============================] - 1s 2ms/step - loss: 0.6209 - accuracy: 0.7583 - val_loss: 0.6147 - val_accuracy: 0.7600\n",
      "Epoch 326/1000\n",
      "239/239 [==============================] - 1s 2ms/step - loss: 0.6209 - accuracy: 0.7585 - val_loss: 0.6098 - val_accuracy: 0.7629\n",
      "Epoch 327/1000\n",
      "239/239 [==============================] - 1s 2ms/step - loss: 0.6202 - accuracy: 0.7587 - val_loss: 0.6125 - val_accuracy: 0.7603\n",
      "Epoch 328/1000\n",
      "239/239 [==============================] - 1s 2ms/step - loss: 0.6200 - accuracy: 0.7587 - val_loss: 0.6054 - val_accuracy: 0.7651\n",
      "Epoch 329/1000\n",
      "239/239 [==============================] - 1s 2ms/step - loss: 0.6186 - accuracy: 0.7586 - val_loss: 0.6098 - val_accuracy: 0.7618\n",
      "Epoch 330/1000\n",
      "239/239 [==============================] - 1s 2ms/step - loss: 0.6193 - accuracy: 0.7588 - val_loss: 0.6088 - val_accuracy: 0.7655\n",
      "Epoch 331/1000\n",
      "239/239 [==============================] - 1s 2ms/step - loss: 0.6199 - accuracy: 0.7583 - val_loss: 0.6105 - val_accuracy: 0.7614\n",
      "Epoch 332/1000\n",
      "239/239 [==============================] - 1s 2ms/step - loss: 0.6197 - accuracy: 0.7576 - val_loss: 0.6124 - val_accuracy: 0.7613\n",
      "Epoch 333/1000\n",
      "239/239 [==============================] - 1s 2ms/step - loss: 0.6211 - accuracy: 0.7589 - val_loss: 0.6126 - val_accuracy: 0.7601\n",
      "Epoch 334/1000\n",
      "239/239 [==============================] - 1s 2ms/step - loss: 0.6213 - accuracy: 0.7583 - val_loss: 0.6121 - val_accuracy: 0.7626\n",
      "Epoch 335/1000\n",
      "239/239 [==============================] - 1s 2ms/step - loss: 0.6188 - accuracy: 0.7586 - val_loss: 0.6120 - val_accuracy: 0.7604\n",
      "Epoch 336/1000\n",
      "239/239 [==============================] - 1s 2ms/step - loss: 0.6194 - accuracy: 0.7582 - val_loss: 0.6111 - val_accuracy: 0.7598\n",
      "Epoch 337/1000\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "239/239 [==============================] - 1s 2ms/step - loss: 0.6190 - accuracy: 0.7589 - val_loss: 0.6062 - val_accuracy: 0.7628\n",
      "Epoch 338/1000\n",
      "239/239 [==============================] - 1s 2ms/step - loss: 0.6187 - accuracy: 0.7588 - val_loss: 0.6096 - val_accuracy: 0.7626\n",
      "Epoch 339/1000\n",
      "239/239 [==============================] - 0s 2ms/step - loss: 0.6193 - accuracy: 0.7582 - val_loss: 0.6119 - val_accuracy: 0.7616\n",
      "Epoch 340/1000\n",
      "239/239 [==============================] - 1s 2ms/step - loss: 0.6196 - accuracy: 0.7579 - val_loss: 0.6092 - val_accuracy: 0.7612\n",
      "Epoch 341/1000\n",
      "239/239 [==============================] - 1s 2ms/step - loss: 0.6201 - accuracy: 0.7587 - val_loss: 0.6096 - val_accuracy: 0.7641\n",
      "Epoch 342/1000\n",
      "239/239 [==============================] - 1s 2ms/step - loss: 0.6198 - accuracy: 0.7587 - val_loss: 0.6163 - val_accuracy: 0.7623\n",
      "Epoch 343/1000\n",
      "239/239 [==============================] - 1s 2ms/step - loss: 0.6198 - accuracy: 0.7589 - val_loss: 0.6117 - val_accuracy: 0.7604\n",
      "Epoch 344/1000\n",
      "239/239 [==============================] - 1s 2ms/step - loss: 0.6193 - accuracy: 0.7589 - val_loss: 0.6122 - val_accuracy: 0.7597\n",
      "Epoch 345/1000\n",
      "239/239 [==============================] - 1s 2ms/step - loss: 0.6181 - accuracy: 0.7599 - val_loss: 0.6137 - val_accuracy: 0.7611\n",
      "Epoch 346/1000\n",
      "239/239 [==============================] - 1s 2ms/step - loss: 0.6192 - accuracy: 0.7591 - val_loss: 0.6081 - val_accuracy: 0.7639\n",
      "Epoch 347/1000\n",
      "239/239 [==============================] - 1s 2ms/step - loss: 0.6193 - accuracy: 0.7588 - val_loss: 0.6100 - val_accuracy: 0.7634\n",
      "Epoch 348/1000\n",
      "239/239 [==============================] - 1s 2ms/step - loss: 0.6190 - accuracy: 0.7591 - val_loss: 0.6107 - val_accuracy: 0.7638\n",
      "Epoch 349/1000\n",
      "239/239 [==============================] - 1s 2ms/step - loss: 0.6189 - accuracy: 0.7573 - val_loss: 0.6112 - val_accuracy: 0.7619\n",
      "Epoch 350/1000\n",
      "239/239 [==============================] - 1s 2ms/step - loss: 0.6186 - accuracy: 0.7578 - val_loss: 0.6138 - val_accuracy: 0.7635\n",
      "Epoch 351/1000\n",
      "239/239 [==============================] - 1s 2ms/step - loss: 0.6190 - accuracy: 0.7589 - val_loss: 0.6071 - val_accuracy: 0.7641\n",
      "Epoch 352/1000\n",
      "239/239 [==============================] - 1s 2ms/step - loss: 0.6193 - accuracy: 0.7586 - val_loss: 0.6049 - val_accuracy: 0.7666\n",
      "Epoch 353/1000\n",
      "239/239 [==============================] - 1s 3ms/step - loss: 0.6179 - accuracy: 0.7587 - val_loss: 0.6121 - val_accuracy: 0.7644\n",
      "Epoch 354/1000\n",
      "239/239 [==============================] - 1s 2ms/step - loss: 0.6184 - accuracy: 0.7580 - val_loss: 0.6075 - val_accuracy: 0.7626\n",
      "Epoch 355/1000\n",
      "239/239 [==============================] - 1s 2ms/step - loss: 0.6180 - accuracy: 0.7595 - val_loss: 0.6127 - val_accuracy: 0.7632\n",
      "Epoch 356/1000\n",
      "239/239 [==============================] - 1s 2ms/step - loss: 0.6177 - accuracy: 0.7593 - val_loss: 0.6124 - val_accuracy: 0.7619\n",
      "Epoch 357/1000\n",
      "239/239 [==============================] - 1s 2ms/step - loss: 0.6184 - accuracy: 0.7591 - val_loss: 0.6096 - val_accuracy: 0.7639\n",
      "Epoch 358/1000\n",
      "239/239 [==============================] - 1s 2ms/step - loss: 0.6192 - accuracy: 0.7587 - val_loss: 0.6125 - val_accuracy: 0.7636\n",
      "Epoch 359/1000\n",
      "239/239 [==============================] - 1s 2ms/step - loss: 0.6182 - accuracy: 0.7588 - val_loss: 0.6060 - val_accuracy: 0.7633\n",
      "Epoch 360/1000\n",
      "239/239 [==============================] - 1s 2ms/step - loss: 0.6177 - accuracy: 0.7581 - val_loss: 0.6065 - val_accuracy: 0.7634\n",
      "Epoch 361/1000\n",
      "239/239 [==============================] - 1s 2ms/step - loss: 0.6184 - accuracy: 0.7584 - val_loss: 0.6088 - val_accuracy: 0.7623\n",
      "Epoch 362/1000\n",
      "239/239 [==============================] - 1s 2ms/step - loss: 0.6190 - accuracy: 0.7594 - val_loss: 0.6074 - val_accuracy: 0.7641\n",
      "Epoch 363/1000\n",
      "239/239 [==============================] - 1s 2ms/step - loss: 0.6200 - accuracy: 0.7581 - val_loss: 0.6110 - val_accuracy: 0.7620\n",
      "Epoch 364/1000\n",
      "239/239 [==============================] - 1s 2ms/step - loss: 0.6182 - accuracy: 0.7594 - val_loss: 0.6110 - val_accuracy: 0.7637\n",
      "Epoch 365/1000\n",
      "239/239 [==============================] - 1s 2ms/step - loss: 0.6202 - accuracy: 0.7580 - val_loss: 0.6167 - val_accuracy: 0.7598\n",
      "Epoch 366/1000\n",
      "239/239 [==============================] - 1s 2ms/step - loss: 0.6191 - accuracy: 0.7592 - val_loss: 0.6164 - val_accuracy: 0.7601\n",
      "Epoch 367/1000\n",
      "239/239 [==============================] - 1s 2ms/step - loss: 0.6175 - accuracy: 0.7590 - val_loss: 0.6135 - val_accuracy: 0.7612\n",
      "Epoch 368/1000\n",
      "239/239 [==============================] - 1s 2ms/step - loss: 0.6178 - accuracy: 0.7595 - val_loss: 0.6137 - val_accuracy: 0.7611\n",
      "Epoch 369/1000\n",
      "239/239 [==============================] - 1s 2ms/step - loss: 0.6204 - accuracy: 0.7589 - val_loss: 0.6114 - val_accuracy: 0.7625\n",
      "Epoch 370/1000\n",
      "239/239 [==============================] - 1s 2ms/step - loss: 0.6174 - accuracy: 0.7588 - val_loss: 0.6113 - val_accuracy: 0.7615\n",
      "Epoch 371/1000\n",
      "239/239 [==============================] - 1s 2ms/step - loss: 0.6207 - accuracy: 0.7580 - val_loss: 0.6120 - val_accuracy: 0.7616\n",
      "Epoch 372/1000\n",
      "239/239 [==============================] - 1s 2ms/step - loss: 0.6181 - accuracy: 0.7590 - val_loss: 0.6095 - val_accuracy: 0.7643\n",
      "Epoch 373/1000\n",
      "239/239 [==============================] - 1s 2ms/step - loss: 0.6180 - accuracy: 0.7590 - val_loss: 0.6116 - val_accuracy: 0.7625\n",
      "Epoch 374/1000\n",
      "239/239 [==============================] - 1s 2ms/step - loss: 0.6174 - accuracy: 0.7596 - val_loss: 0.6102 - val_accuracy: 0.7637\n",
      "Epoch 375/1000\n",
      "239/239 [==============================] - 1s 2ms/step - loss: 0.6171 - accuracy: 0.7598 - val_loss: 0.6156 - val_accuracy: 0.7636\n",
      "Epoch 376/1000\n",
      "239/239 [==============================] - 1s 2ms/step - loss: 0.6189 - accuracy: 0.7585 - val_loss: 0.6104 - val_accuracy: 0.7629\n",
      "Epoch 377/1000\n",
      "239/239 [==============================] - 1s 2ms/step - loss: 0.6180 - accuracy: 0.7597 - val_loss: 0.6070 - val_accuracy: 0.7623\n",
      "Epoch 378/1000\n",
      "239/239 [==============================] - 1s 2ms/step - loss: 0.6187 - accuracy: 0.7592 - val_loss: 0.6067 - val_accuracy: 0.7643\n",
      "Epoch 379/1000\n",
      "239/239 [==============================] - 1s 2ms/step - loss: 0.6189 - accuracy: 0.7583 - val_loss: 0.6059 - val_accuracy: 0.7638\n",
      "Epoch 380/1000\n",
      "239/239 [==============================] - 1s 2ms/step - loss: 0.6180 - accuracy: 0.7594 - val_loss: 0.6144 - val_accuracy: 0.7612\n",
      "Epoch 381/1000\n",
      "239/239 [==============================] - 1s 2ms/step - loss: 0.6195 - accuracy: 0.7583 - val_loss: 0.6098 - val_accuracy: 0.7623\n",
      "Epoch 382/1000\n",
      "239/239 [==============================] - 1s 2ms/step - loss: 0.6168 - accuracy: 0.7602 - val_loss: 0.6107 - val_accuracy: 0.7642\n",
      "Epoch 383/1000\n",
      "239/239 [==============================] - 1s 2ms/step - loss: 0.6179 - accuracy: 0.7597 - val_loss: 0.6099 - val_accuracy: 0.7629\n",
      "Epoch 384/1000\n",
      "239/239 [==============================] - 1s 2ms/step - loss: 0.6180 - accuracy: 0.7591 - val_loss: 0.6096 - val_accuracy: 0.7640\n",
      "Epoch 385/1000\n",
      "239/239 [==============================] - 1s 2ms/step - loss: 0.6179 - accuracy: 0.7591 - val_loss: 0.6124 - val_accuracy: 0.7608\n",
      "Epoch 386/1000\n",
      "239/239 [==============================] - 1s 2ms/step - loss: 0.6165 - accuracy: 0.7595 - val_loss: 0.6090 - val_accuracy: 0.7626\n",
      "Epoch 387/1000\n",
      "239/239 [==============================] - 1s 2ms/step - loss: 0.6171 - accuracy: 0.7587 - val_loss: 0.6128 - val_accuracy: 0.7624\n",
      "Epoch 388/1000\n",
      "239/239 [==============================] - 1s 2ms/step - loss: 0.6198 - accuracy: 0.7579 - val_loss: 0.6134 - val_accuracy: 0.7634\n",
      "Epoch 389/1000\n",
      "239/239 [==============================] - 1s 2ms/step - loss: 0.6164 - accuracy: 0.7606 - val_loss: 0.6111 - val_accuracy: 0.7596\n",
      "Epoch 390/1000\n",
      "239/239 [==============================] - 1s 2ms/step - loss: 0.6161 - accuracy: 0.7596 - val_loss: 0.6120 - val_accuracy: 0.7606\n",
      "Epoch 391/1000\n",
      "239/239 [==============================] - 1s 2ms/step - loss: 0.6172 - accuracy: 0.7590 - val_loss: 0.6095 - val_accuracy: 0.7639\n",
      "Epoch 392/1000\n",
      "239/239 [==============================] - 1s 2ms/step - loss: 0.6188 - accuracy: 0.7580 - val_loss: 0.6119 - val_accuracy: 0.7631\n",
      "Epoch 393/1000\n",
      "239/239 [==============================] - 1s 2ms/step - loss: 0.6184 - accuracy: 0.7592 - val_loss: 0.6066 - val_accuracy: 0.7641\n",
      "Epoch 394/1000\n",
      "239/239 [==============================] - 1s 2ms/step - loss: 0.6168 - accuracy: 0.7599 - val_loss: 0.6100 - val_accuracy: 0.7609\n",
      "Epoch 395/1000\n",
      "239/239 [==============================] - 1s 2ms/step - loss: 0.6185 - accuracy: 0.7595 - val_loss: 0.6124 - val_accuracy: 0.7621\n",
      "Epoch 396/1000\n",
      "239/239 [==============================] - 1s 2ms/step - loss: 0.6175 - accuracy: 0.7584 - val_loss: 0.6053 - val_accuracy: 0.7644\n",
      "Epoch 397/1000\n",
      "239/239 [==============================] - 1s 2ms/step - loss: 0.6163 - accuracy: 0.7593 - val_loss: 0.6137 - val_accuracy: 0.7615\n",
      "Epoch 398/1000\n",
      "239/239 [==============================] - 1s 2ms/step - loss: 0.6174 - accuracy: 0.7601 - val_loss: 0.6169 - val_accuracy: 0.7598\n",
      "Epoch 399/1000\n",
      "239/239 [==============================] - 1s 2ms/step - loss: 0.6155 - accuracy: 0.7607 - val_loss: 0.6089 - val_accuracy: 0.7643\n",
      "Epoch 400/1000\n",
      "239/239 [==============================] - 1s 2ms/step - loss: 0.6178 - accuracy: 0.7586 - val_loss: 0.6103 - val_accuracy: 0.7590\n",
      "Epoch 401/1000\n",
      "239/239 [==============================] - 1s 2ms/step - loss: 0.6175 - accuracy: 0.7597 - val_loss: 0.6104 - val_accuracy: 0.7614\n",
      "Epoch 402/1000\n",
      "239/239 [==============================] - 1s 2ms/step - loss: 0.6173 - accuracy: 0.7583 - val_loss: 0.6164 - val_accuracy: 0.7601\n",
      "Epoch 403/1000\n",
      "239/239 [==============================] - 1s 2ms/step - loss: 0.6177 - accuracy: 0.7593 - val_loss: 0.6077 - val_accuracy: 0.7609\n",
      "Epoch 404/1000\n",
      "239/239 [==============================] - 1s 2ms/step - loss: 0.6168 - accuracy: 0.7601 - val_loss: 0.6089 - val_accuracy: 0.7609\n",
      "Epoch 405/1000\n",
      "239/239 [==============================] - 1s 2ms/step - loss: 0.6170 - accuracy: 0.7600 - val_loss: 0.6082 - val_accuracy: 0.7634\n",
      "Epoch 406/1000\n",
      "239/239 [==============================] - 1s 2ms/step - loss: 0.6151 - accuracy: 0.7607 - val_loss: 0.6070 - val_accuracy: 0.7665\n",
      "Epoch 407/1000\n",
      "239/239 [==============================] - 1s 2ms/step - loss: 0.6182 - accuracy: 0.7599 - val_loss: 0.6086 - val_accuracy: 0.7652\n",
      "Epoch 408/1000\n",
      "239/239 [==============================] - 1s 2ms/step - loss: 0.6179 - accuracy: 0.7598 - val_loss: 0.6071 - val_accuracy: 0.7639\n",
      "Epoch 409/1000\n",
      "239/239 [==============================] - 1s 2ms/step - loss: 0.6170 - accuracy: 0.7600 - val_loss: 0.6086 - val_accuracy: 0.7609\n",
      "Epoch 410/1000\n",
      "239/239 [==============================] - 1s 2ms/step - loss: 0.6167 - accuracy: 0.7599 - val_loss: 0.6066 - val_accuracy: 0.7643\n",
      "Epoch 411/1000\n",
      "239/239 [==============================] - 1s 2ms/step - loss: 0.6162 - accuracy: 0.7600 - val_loss: 0.6058 - val_accuracy: 0.7661\n",
      "Epoch 412/1000\n",
      "239/239 [==============================] - 1s 2ms/step - loss: 0.6177 - accuracy: 0.7601 - val_loss: 0.6075 - val_accuracy: 0.7632\n",
      "Epoch 413/1000\n",
      "239/239 [==============================] - 1s 2ms/step - loss: 0.6177 - accuracy: 0.7588 - val_loss: 0.6052 - val_accuracy: 0.7652\n",
      "Epoch 414/1000\n",
      "239/239 [==============================] - 1s 3ms/step - loss: 0.6181 - accuracy: 0.7591 - val_loss: 0.6099 - val_accuracy: 0.7635\n",
      "Epoch 415/1000\n",
      "239/239 [==============================] - 1s 2ms/step - loss: 0.6161 - accuracy: 0.7593 - val_loss: 0.6092 - val_accuracy: 0.7618\n",
      "Epoch 416/1000\n",
      "239/239 [==============================] - 1s 2ms/step - loss: 0.6173 - accuracy: 0.7594 - val_loss: 0.6086 - val_accuracy: 0.7641\n",
      "Epoch 417/1000\n",
      "239/239 [==============================] - 1s 3ms/step - loss: 0.6180 - accuracy: 0.7597 - val_loss: 0.6130 - val_accuracy: 0.7629\n",
      "Epoch 418/1000\n",
      "239/239 [==============================] - 1s 2ms/step - loss: 0.6169 - accuracy: 0.7600 - val_loss: 0.6162 - val_accuracy: 0.7607\n",
      "Epoch 419/1000\n",
      "239/239 [==============================] - 1s 2ms/step - loss: 0.6181 - accuracy: 0.7584 - val_loss: 0.6080 - val_accuracy: 0.7647\n",
      "Epoch 420/1000\n",
      "239/239 [==============================] - 1s 2ms/step - loss: 0.6168 - accuracy: 0.7603 - val_loss: 0.6098 - val_accuracy: 0.7599\n",
      "Epoch 421/1000\n",
      "239/239 [==============================] - 1s 2ms/step - loss: 0.6163 - accuracy: 0.7604 - val_loss: 0.6121 - val_accuracy: 0.7637\n",
      "Epoch 422/1000\n",
      "239/239 [==============================] - 0s 2ms/step - loss: 0.6171 - accuracy: 0.7599 - val_loss: 0.6082 - val_accuracy: 0.7655\n",
      "Epoch 423/1000\n",
      "239/239 [==============================] - 1s 2ms/step - loss: 0.6167 - accuracy: 0.7596 - val_loss: 0.6062 - val_accuracy: 0.7654\n",
      "Epoch 424/1000\n",
      "239/239 [==============================] - 1s 2ms/step - loss: 0.6157 - accuracy: 0.7601 - val_loss: 0.6053 - val_accuracy: 0.7660\n",
      "Epoch 425/1000\n",
      "239/239 [==============================] - 1s 2ms/step - loss: 0.6173 - accuracy: 0.7592 - val_loss: 0.6071 - val_accuracy: 0.7622\n",
      "Epoch 426/1000\n",
      "239/239 [==============================] - 1s 2ms/step - loss: 0.6146 - accuracy: 0.7604 - val_loss: 0.6080 - val_accuracy: 0.7618\n",
      "Epoch 427/1000\n",
      "239/239 [==============================] - 1s 2ms/step - loss: 0.6164 - accuracy: 0.7606 - val_loss: 0.6095 - val_accuracy: 0.7603\n",
      "Epoch 428/1000\n",
      "239/239 [==============================] - 1s 2ms/step - loss: 0.6171 - accuracy: 0.7601 - val_loss: 0.6085 - val_accuracy: 0.7623\n",
      "Epoch 429/1000\n",
      "239/239 [==============================] - 1s 2ms/step - loss: 0.6182 - accuracy: 0.7596 - val_loss: 0.6137 - val_accuracy: 0.7588\n",
      "Epoch 430/1000\n",
      "239/239 [==============================] - 1s 2ms/step - loss: 0.6150 - accuracy: 0.7616 - val_loss: 0.6086 - val_accuracy: 0.7625\n",
      "Epoch 431/1000\n",
      "239/239 [==============================] - 1s 2ms/step - loss: 0.6145 - accuracy: 0.7606 - val_loss: 0.6066 - val_accuracy: 0.7634\n",
      "Epoch 432/1000\n",
      "239/239 [==============================] - 1s 2ms/step - loss: 0.6157 - accuracy: 0.7605 - val_loss: 0.6149 - val_accuracy: 0.7590\n",
      "Epoch 433/1000\n",
      "239/239 [==============================] - 1s 2ms/step - loss: 0.6168 - accuracy: 0.7600 - val_loss: 0.6093 - val_accuracy: 0.7618\n",
      "Epoch 434/1000\n",
      "239/239 [==============================] - 1s 2ms/step - loss: 0.6183 - accuracy: 0.7585 - val_loss: 0.6115 - val_accuracy: 0.7637\n",
      "Epoch 435/1000\n",
      "239/239 [==============================] - 1s 2ms/step - loss: 0.6167 - accuracy: 0.7593 - val_loss: 0.6119 - val_accuracy: 0.7643\n",
      "Epoch 436/1000\n",
      "239/239 [==============================] - 1s 2ms/step - loss: 0.6171 - accuracy: 0.7594 - val_loss: 0.6075 - val_accuracy: 0.7636\n",
      "Epoch 437/1000\n",
      "239/239 [==============================] - 1s 2ms/step - loss: 0.6155 - accuracy: 0.7603 - val_loss: 0.6084 - val_accuracy: 0.7645\n",
      "Epoch 438/1000\n",
      "239/239 [==============================] - 1s 2ms/step - loss: 0.6159 - accuracy: 0.7604 - val_loss: 0.6092 - val_accuracy: 0.7634\n",
      "Epoch 439/1000\n",
      "239/239 [==============================] - 1s 2ms/step - loss: 0.6165 - accuracy: 0.7599 - val_loss: 0.6074 - val_accuracy: 0.7638\n",
      "Epoch 440/1000\n",
      "239/239 [==============================] - 1s 2ms/step - loss: 0.6158 - accuracy: 0.7611 - val_loss: 0.6090 - val_accuracy: 0.7646\n",
      "Epoch 441/1000\n",
      "239/239 [==============================] - 1s 2ms/step - loss: 0.6162 - accuracy: 0.7602 - val_loss: 0.6102 - val_accuracy: 0.7645\n",
      "Epoch 442/1000\n",
      "239/239 [==============================] - 1s 2ms/step - loss: 0.6159 - accuracy: 0.7611 - val_loss: 0.6097 - val_accuracy: 0.7634\n",
      "Epoch 442: early stopping\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "<keras.src.callbacks.History at 0x1419a0880>"
      ]
     },
     "execution_count": 167,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "model=Sequential()\n",
    "model.add(Dense(128, input_dim=X_train.shape[1], activation=\"relu\"))\n",
    "model.add(Dropout(0.2))\n",
    "model.add(Dense(128, activation=\"relu\"))\n",
    "model.add(Dropout(0.8))\n",
    "model.add(Dense(64, activation=\"relu\"))\n",
    "model.add(Dropout(0.2))\n",
    "model.add(Dense(64, activation=\"relu\"))\n",
    "\n",
    "model.add(Dense(32, activation=\"relu\"))\n",
    "model.add(Dropout(0.2))\n",
    "#model.add(Dense(16, activation=\"relu\"))\n",
    "#model.add(Dropout(0.2))\n",
    "model.add(Dense(3, activation=\"softmax\"))\n",
    "\n",
    "model.compile(loss='categorical_crossentropy', optimizer=Adam(learning_rate=0.001), metrics=['accuracy'])\n",
    "\n",
    "es=EarlyStopping(monitor=\"val_loss\",patience=90,mode=\"auto\",verbose=1)\n",
    "\n",
    "model.fit(X_train,\n",
    "          y_train,\n",
    "          epochs=1000,\n",
    "               batch_size=512,\n",
    "               validation_split=0.1,\n",
    "               verbose=1,callbacks=[es])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 168,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "748/748 [==============================] - 0s 254us/step\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0       0.74      0.90      0.81      7973\n",
      "           1       0.75      0.82      0.79      7973\n",
      "           2       0.80      0.56      0.66      7972\n",
      "\n",
      "    accuracy                           0.76     23918\n",
      "   macro avg       0.77      0.76      0.75     23918\n",
      "weighted avg       0.77      0.76      0.75     23918\n",
      "\n"
     ]
    }
   ],
   "source": [
    "y_pred = model.predict(X_test)\n",
    "y_pred_classes = np.argmax(y_pred, axis=1)\n",
    "y_true = np.argmax(y_test, axis=1)\n",
    "print(classification_report(y_true, y_pred_classes))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 169,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "4236/4236 [==============================] - 1s 247us/step\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0       0.75      0.90      0.82     45176\n",
      "           1       0.76      0.82      0.79     45176\n",
      "           2       0.80      0.58      0.67     45177\n",
      "\n",
      "    accuracy                           0.77    135529\n",
      "   macro avg       0.77      0.77      0.76    135529\n",
      "weighted avg       0.77      0.77      0.76    135529\n",
      "\n"
     ]
    }
   ],
   "source": [
    "y_t_pred = model.predict(X_train)\n",
    "y_t_pred_classes = np.argmax(y_t_pred, axis=1)\n",
    "y_t_true = np.argmax(y_train, axis=1)\n",
    "print(classification_report(y_t_true, y_t_pred_classes))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 174,
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.preprocessing import StandardScaler\n",
    "scaler = StandardScaler()\n",
    "X_train = scaler.fit_transform(X_train)\n",
    "X_test = scaler.transform(X_test)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 175,
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 1/1000\n",
      "239/239 [==============================] - 1s 2ms/step - loss: 0.8899 - accuracy: 0.6080 - val_loss: 0.7512 - val_accuracy: 0.7291\n",
      "Epoch 2/1000\n",
      "239/239 [==============================] - 1s 2ms/step - loss: 0.7530 - accuracy: 0.7128 - val_loss: 0.7238 - val_accuracy: 0.7349\n",
      "Epoch 3/1000\n",
      "239/239 [==============================] - 1s 2ms/step - loss: 0.7280 - accuracy: 0.7227 - val_loss: 0.7096 - val_accuracy: 0.7386\n",
      "Epoch 4/1000\n",
      "239/239 [==============================] - 1s 2ms/step - loss: 0.7179 - accuracy: 0.7257 - val_loss: 0.7011 - val_accuracy: 0.7403\n",
      "Epoch 5/1000\n",
      "239/239 [==============================] - 1s 2ms/step - loss: 0.7083 - accuracy: 0.7293 - val_loss: 0.6962 - val_accuracy: 0.7431\n",
      "Epoch 6/1000\n",
      "239/239 [==============================] - 1s 2ms/step - loss: 0.7007 - accuracy: 0.7317 - val_loss: 0.6922 - val_accuracy: 0.7451\n",
      "Epoch 7/1000\n",
      "239/239 [==============================] - 1s 3ms/step - loss: 0.6966 - accuracy: 0.7332 - val_loss: 0.6870 - val_accuracy: 0.7461\n",
      "Epoch 8/1000\n",
      "239/239 [==============================] - 1s 2ms/step - loss: 0.6935 - accuracy: 0.7336 - val_loss: 0.6730 - val_accuracy: 0.7463\n",
      "Epoch 9/1000\n",
      "239/239 [==============================] - 1s 2ms/step - loss: 0.6886 - accuracy: 0.7352 - val_loss: 0.6784 - val_accuracy: 0.7460\n",
      "Epoch 10/1000\n",
      "239/239 [==============================] - 1s 2ms/step - loss: 0.6854 - accuracy: 0.7356 - val_loss: 0.6721 - val_accuracy: 0.7480\n",
      "Epoch 11/1000\n",
      "239/239 [==============================] - 1s 2ms/step - loss: 0.6834 - accuracy: 0.7370 - val_loss: 0.6716 - val_accuracy: 0.7485\n",
      "Epoch 12/1000\n",
      "239/239 [==============================] - 1s 3ms/step - loss: 0.6808 - accuracy: 0.7387 - val_loss: 0.6665 - val_accuracy: 0.7500\n",
      "Epoch 13/1000\n",
      "239/239 [==============================] - 1s 2ms/step - loss: 0.6783 - accuracy: 0.7397 - val_loss: 0.6583 - val_accuracy: 0.7513\n",
      "Epoch 14/1000\n",
      "239/239 [==============================] - 1s 2ms/step - loss: 0.6753 - accuracy: 0.7393 - val_loss: 0.6561 - val_accuracy: 0.7522\n",
      "Epoch 15/1000\n",
      "239/239 [==============================] - 1s 2ms/step - loss: 0.6733 - accuracy: 0.7404 - val_loss: 0.6539 - val_accuracy: 0.7519\n",
      "Epoch 16/1000\n",
      "239/239 [==============================] - 1s 2ms/step - loss: 0.6723 - accuracy: 0.7403 - val_loss: 0.6565 - val_accuracy: 0.7521\n",
      "Epoch 17/1000\n",
      "239/239 [==============================] - 1s 2ms/step - loss: 0.6710 - accuracy: 0.7415 - val_loss: 0.6540 - val_accuracy: 0.7536\n",
      "Epoch 18/1000\n",
      "239/239 [==============================] - 1s 2ms/step - loss: 0.6690 - accuracy: 0.7418 - val_loss: 0.6499 - val_accuracy: 0.7536\n",
      "Epoch 19/1000\n",
      "239/239 [==============================] - 1s 2ms/step - loss: 0.6683 - accuracy: 0.7432 - val_loss: 0.6450 - val_accuracy: 0.7525\n",
      "Epoch 20/1000\n",
      "239/239 [==============================] - 1s 2ms/step - loss: 0.6665 - accuracy: 0.7429 - val_loss: 0.6457 - val_accuracy: 0.7536\n",
      "Epoch 21/1000\n",
      "239/239 [==============================] - 1s 2ms/step - loss: 0.6649 - accuracy: 0.7433 - val_loss: 0.6450 - val_accuracy: 0.7546\n",
      "Epoch 22/1000\n",
      "239/239 [==============================] - 1s 2ms/step - loss: 0.6637 - accuracy: 0.7446 - val_loss: 0.6420 - val_accuracy: 0.7555\n",
      "Epoch 23/1000\n",
      "239/239 [==============================] - 1s 2ms/step - loss: 0.6620 - accuracy: 0.7450 - val_loss: 0.6427 - val_accuracy: 0.7538\n",
      "Epoch 24/1000\n",
      "239/239 [==============================] - 1s 2ms/step - loss: 0.6605 - accuracy: 0.7449 - val_loss: 0.6405 - val_accuracy: 0.7553\n",
      "Epoch 25/1000\n",
      "239/239 [==============================] - 1s 2ms/step - loss: 0.6595 - accuracy: 0.7445 - val_loss: 0.6424 - val_accuracy: 0.7558\n",
      "Epoch 26/1000\n",
      "239/239 [==============================] - 1s 2ms/step - loss: 0.6593 - accuracy: 0.7454 - val_loss: 0.6414 - val_accuracy: 0.7549\n",
      "Epoch 27/1000\n",
      "239/239 [==============================] - 1s 2ms/step - loss: 0.6595 - accuracy: 0.7445 - val_loss: 0.6409 - val_accuracy: 0.7554\n",
      "Epoch 28/1000\n",
      "239/239 [==============================] - 1s 2ms/step - loss: 0.6575 - accuracy: 0.7458 - val_loss: 0.6413 - val_accuracy: 0.7545\n",
      "Epoch 29/1000\n",
      "239/239 [==============================] - 1s 2ms/step - loss: 0.6576 - accuracy: 0.7458 - val_loss: 0.6390 - val_accuracy: 0.7561\n",
      "Epoch 30/1000\n",
      "239/239 [==============================] - 1s 2ms/step - loss: 0.6558 - accuracy: 0.7461 - val_loss: 0.6379 - val_accuracy: 0.7558\n",
      "Epoch 31/1000\n",
      "239/239 [==============================] - 1s 2ms/step - loss: 0.6548 - accuracy: 0.7463 - val_loss: 0.6347 - val_accuracy: 0.7564\n",
      "Epoch 32/1000\n",
      "239/239 [==============================] - 1s 2ms/step - loss: 0.6554 - accuracy: 0.7464 - val_loss: 0.6353 - val_accuracy: 0.7580\n",
      "Epoch 33/1000\n",
      "239/239 [==============================] - 1s 2ms/step - loss: 0.6522 - accuracy: 0.7480 - val_loss: 0.6328 - val_accuracy: 0.7574\n",
      "Epoch 34/1000\n",
      "239/239 [==============================] - 1s 2ms/step - loss: 0.6520 - accuracy: 0.7477 - val_loss: 0.6335 - val_accuracy: 0.7561\n",
      "Epoch 35/1000\n",
      "239/239 [==============================] - 1s 2ms/step - loss: 0.6518 - accuracy: 0.7477 - val_loss: 0.6374 - val_accuracy: 0.7563\n",
      "Epoch 36/1000\n",
      "239/239 [==============================] - 1s 2ms/step - loss: 0.6522 - accuracy: 0.7469 - val_loss: 0.6316 - val_accuracy: 0.7569\n",
      "Epoch 37/1000\n",
      "239/239 [==============================] - 1s 2ms/step - loss: 0.6502 - accuracy: 0.7480 - val_loss: 0.6311 - val_accuracy: 0.7567\n",
      "Epoch 38/1000\n",
      "239/239 [==============================] - 1s 2ms/step - loss: 0.6505 - accuracy: 0.7477 - val_loss: 0.6303 - val_accuracy: 0.7582\n",
      "Epoch 39/1000\n",
      "239/239 [==============================] - 1s 2ms/step - loss: 0.6481 - accuracy: 0.7484 - val_loss: 0.6299 - val_accuracy: 0.7592\n",
      "Epoch 40/1000\n",
      "239/239 [==============================] - 1s 2ms/step - loss: 0.6481 - accuracy: 0.7479 - val_loss: 0.6317 - val_accuracy: 0.7577\n",
      "Epoch 41/1000\n",
      "239/239 [==============================] - 1s 3ms/step - loss: 0.6471 - accuracy: 0.7484 - val_loss: 0.6281 - val_accuracy: 0.7587\n",
      "Epoch 42/1000\n",
      "239/239 [==============================] - 1s 2ms/step - loss: 0.6466 - accuracy: 0.7479 - val_loss: 0.6285 - val_accuracy: 0.7571\n",
      "Epoch 43/1000\n",
      "239/239 [==============================] - 1s 2ms/step - loss: 0.6454 - accuracy: 0.7493 - val_loss: 0.6256 - val_accuracy: 0.7591\n",
      "Epoch 44/1000\n",
      "239/239 [==============================] - 1s 2ms/step - loss: 0.6470 - accuracy: 0.7486 - val_loss: 0.6276 - val_accuracy: 0.7585\n",
      "Epoch 45/1000\n",
      "239/239 [==============================] - 1s 2ms/step - loss: 0.6451 - accuracy: 0.7489 - val_loss: 0.6260 - val_accuracy: 0.7595\n",
      "Epoch 46/1000\n",
      "239/239 [==============================] - 1s 2ms/step - loss: 0.6453 - accuracy: 0.7489 - val_loss: 0.6277 - val_accuracy: 0.7575\n",
      "Epoch 47/1000\n",
      "239/239 [==============================] - 1s 2ms/step - loss: 0.6449 - accuracy: 0.7494 - val_loss: 0.6252 - val_accuracy: 0.7605\n",
      "Epoch 48/1000\n",
      "239/239 [==============================] - 1s 2ms/step - loss: 0.6439 - accuracy: 0.7491 - val_loss: 0.6264 - val_accuracy: 0.7598\n",
      "Epoch 49/1000\n",
      "239/239 [==============================] - 1s 2ms/step - loss: 0.6447 - accuracy: 0.7493 - val_loss: 0.6248 - val_accuracy: 0.7598\n",
      "Epoch 50/1000\n",
      "239/239 [==============================] - 1s 2ms/step - loss: 0.6425 - accuracy: 0.7493 - val_loss: 0.6271 - val_accuracy: 0.7598\n",
      "Epoch 51/1000\n",
      "239/239 [==============================] - 1s 2ms/step - loss: 0.6429 - accuracy: 0.7496 - val_loss: 0.6227 - val_accuracy: 0.7598\n",
      "Epoch 52/1000\n",
      "239/239 [==============================] - 1s 2ms/step - loss: 0.6413 - accuracy: 0.7502 - val_loss: 0.6234 - val_accuracy: 0.7605\n",
      "Epoch 53/1000\n",
      "239/239 [==============================] - 1s 2ms/step - loss: 0.6416 - accuracy: 0.7496 - val_loss: 0.6228 - val_accuracy: 0.7584\n",
      "Epoch 54/1000\n",
      "239/239 [==============================] - 1s 2ms/step - loss: 0.6414 - accuracy: 0.7504 - val_loss: 0.6192 - val_accuracy: 0.7592\n",
      "Epoch 55/1000\n",
      "239/239 [==============================] - 1s 2ms/step - loss: 0.6395 - accuracy: 0.7501 - val_loss: 0.6224 - val_accuracy: 0.7582\n",
      "Epoch 56/1000\n",
      "239/239 [==============================] - 1s 2ms/step - loss: 0.6416 - accuracy: 0.7494 - val_loss: 0.6224 - val_accuracy: 0.7595\n",
      "Epoch 57/1000\n",
      "239/239 [==============================] - 1s 2ms/step - loss: 0.6390 - accuracy: 0.7499 - val_loss: 0.6170 - val_accuracy: 0.7617\n",
      "Epoch 58/1000\n",
      "239/239 [==============================] - 1s 2ms/step - loss: 0.6403 - accuracy: 0.7500 - val_loss: 0.6232 - val_accuracy: 0.7603\n",
      "Epoch 59/1000\n",
      "239/239 [==============================] - 1s 2ms/step - loss: 0.6382 - accuracy: 0.7510 - val_loss: 0.6206 - val_accuracy: 0.7586\n",
      "Epoch 60/1000\n",
      "239/239 [==============================] - 1s 2ms/step - loss: 0.6391 - accuracy: 0.7504 - val_loss: 0.6217 - val_accuracy: 0.7611\n",
      "Epoch 61/1000\n",
      "239/239 [==============================] - 1s 2ms/step - loss: 0.6383 - accuracy: 0.7504 - val_loss: 0.6190 - val_accuracy: 0.7617\n",
      "Epoch 62/1000\n",
      "239/239 [==============================] - 1s 2ms/step - loss: 0.6375 - accuracy: 0.7519 - val_loss: 0.6203 - val_accuracy: 0.7609\n",
      "Epoch 63/1000\n",
      "239/239 [==============================] - 1s 2ms/step - loss: 0.6372 - accuracy: 0.7505 - val_loss: 0.6163 - val_accuracy: 0.7612\n",
      "Epoch 64/1000\n",
      "239/239 [==============================] - 1s 2ms/step - loss: 0.6363 - accuracy: 0.7513 - val_loss: 0.6185 - val_accuracy: 0.7603\n",
      "Epoch 65/1000\n",
      "239/239 [==============================] - 1s 2ms/step - loss: 0.6371 - accuracy: 0.7503 - val_loss: 0.6177 - val_accuracy: 0.7607\n",
      "Epoch 66/1000\n",
      "239/239 [==============================] - 1s 2ms/step - loss: 0.6359 - accuracy: 0.7515 - val_loss: 0.6205 - val_accuracy: 0.7616\n",
      "Epoch 67/1000\n",
      "239/239 [==============================] - 1s 2ms/step - loss: 0.6376 - accuracy: 0.7505 - val_loss: 0.6171 - val_accuracy: 0.7617\n",
      "Epoch 68/1000\n",
      "239/239 [==============================] - 1s 2ms/step - loss: 0.6354 - accuracy: 0.7512 - val_loss: 0.6166 - val_accuracy: 0.7588\n",
      "Epoch 69/1000\n",
      "239/239 [==============================] - 1s 2ms/step - loss: 0.6376 - accuracy: 0.7511 - val_loss: 0.6161 - val_accuracy: 0.7614\n",
      "Epoch 70/1000\n",
      "239/239 [==============================] - 1s 3ms/step - loss: 0.6354 - accuracy: 0.7517 - val_loss: 0.6162 - val_accuracy: 0.7623\n",
      "Epoch 71/1000\n",
      "239/239 [==============================] - 1s 2ms/step - loss: 0.6354 - accuracy: 0.7522 - val_loss: 0.6151 - val_accuracy: 0.7623\n",
      "Epoch 72/1000\n",
      "239/239 [==============================] - 1s 2ms/step - loss: 0.6335 - accuracy: 0.7519 - val_loss: 0.6169 - val_accuracy: 0.7632\n",
      "Epoch 73/1000\n",
      "239/239 [==============================] - 1s 2ms/step - loss: 0.6356 - accuracy: 0.7522 - val_loss: 0.6191 - val_accuracy: 0.7618\n",
      "Epoch 74/1000\n",
      "239/239 [==============================] - 1s 2ms/step - loss: 0.6341 - accuracy: 0.7512 - val_loss: 0.6173 - val_accuracy: 0.7613\n",
      "Epoch 75/1000\n",
      "239/239 [==============================] - 1s 2ms/step - loss: 0.6343 - accuracy: 0.7525 - val_loss: 0.6166 - val_accuracy: 0.7615\n",
      "Epoch 76/1000\n",
      "239/239 [==============================] - 1s 2ms/step - loss: 0.6339 - accuracy: 0.7522 - val_loss: 0.6123 - val_accuracy: 0.7632\n",
      "Epoch 77/1000\n",
      "239/239 [==============================] - 1s 2ms/step - loss: 0.6337 - accuracy: 0.7513 - val_loss: 0.6150 - val_accuracy: 0.7608\n",
      "Epoch 78/1000\n",
      "239/239 [==============================] - 1s 2ms/step - loss: 0.6335 - accuracy: 0.7518 - val_loss: 0.6147 - val_accuracy: 0.7610\n",
      "Epoch 79/1000\n",
      "239/239 [==============================] - 1s 2ms/step - loss: 0.6313 - accuracy: 0.7526 - val_loss: 0.6147 - val_accuracy: 0.7636\n",
      "Epoch 80/1000\n",
      "239/239 [==============================] - 1s 2ms/step - loss: 0.6324 - accuracy: 0.7526 - val_loss: 0.6139 - val_accuracy: 0.7641\n",
      "Epoch 81/1000\n",
      "239/239 [==============================] - 1s 2ms/step - loss: 0.6323 - accuracy: 0.7532 - val_loss: 0.6137 - val_accuracy: 0.7637\n",
      "Epoch 82/1000\n",
      "239/239 [==============================] - 1s 2ms/step - loss: 0.6328 - accuracy: 0.7523 - val_loss: 0.6114 - val_accuracy: 0.7610\n",
      "Epoch 83/1000\n",
      "239/239 [==============================] - 1s 2ms/step - loss: 0.6337 - accuracy: 0.7519 - val_loss: 0.6143 - val_accuracy: 0.7629\n",
      "Epoch 84/1000\n",
      "239/239 [==============================] - 1s 2ms/step - loss: 0.6325 - accuracy: 0.7528 - val_loss: 0.6167 - val_accuracy: 0.7628\n",
      "Epoch 85/1000\n",
      "239/239 [==============================] - 1s 2ms/step - loss: 0.6312 - accuracy: 0.7525 - val_loss: 0.6138 - val_accuracy: 0.7626\n",
      "Epoch 86/1000\n",
      "239/239 [==============================] - 1s 2ms/step - loss: 0.6320 - accuracy: 0.7532 - val_loss: 0.6127 - val_accuracy: 0.7621\n",
      "Epoch 87/1000\n",
      "239/239 [==============================] - 1s 2ms/step - loss: 0.6312 - accuracy: 0.7523 - val_loss: 0.6137 - val_accuracy: 0.7639\n",
      "Epoch 88/1000\n",
      "239/239 [==============================] - 1s 2ms/step - loss: 0.6323 - accuracy: 0.7522 - val_loss: 0.6165 - val_accuracy: 0.7636\n",
      "Epoch 89/1000\n",
      "239/239 [==============================] - 1s 2ms/step - loss: 0.6315 - accuracy: 0.7522 - val_loss: 0.6118 - val_accuracy: 0.7647\n",
      "Epoch 90/1000\n",
      "239/239 [==============================] - 1s 2ms/step - loss: 0.6297 - accuracy: 0.7540 - val_loss: 0.6150 - val_accuracy: 0.7629\n",
      "Epoch 91/1000\n",
      "239/239 [==============================] - 1s 2ms/step - loss: 0.6297 - accuracy: 0.7529 - val_loss: 0.6111 - val_accuracy: 0.7626\n",
      "Epoch 92/1000\n",
      "239/239 [==============================] - 1s 2ms/step - loss: 0.6312 - accuracy: 0.7530 - val_loss: 0.6130 - val_accuracy: 0.7632\n",
      "Epoch 93/1000\n",
      "239/239 [==============================] - 1s 2ms/step - loss: 0.6311 - accuracy: 0.7536 - val_loss: 0.6111 - val_accuracy: 0.7622\n",
      "Epoch 94/1000\n",
      "239/239 [==============================] - 1s 2ms/step - loss: 0.6309 - accuracy: 0.7530 - val_loss: 0.6125 - val_accuracy: 0.7640\n",
      "Epoch 95/1000\n",
      "239/239 [==============================] - 1s 2ms/step - loss: 0.6311 - accuracy: 0.7536 - val_loss: 0.6134 - val_accuracy: 0.7632\n",
      "Epoch 96/1000\n",
      "239/239 [==============================] - 1s 2ms/step - loss: 0.6289 - accuracy: 0.7531 - val_loss: 0.6112 - val_accuracy: 0.7634\n",
      "Epoch 97/1000\n",
      "239/239 [==============================] - 1s 2ms/step - loss: 0.6287 - accuracy: 0.7537 - val_loss: 0.6090 - val_accuracy: 0.7635\n",
      "Epoch 98/1000\n",
      "239/239 [==============================] - 1s 2ms/step - loss: 0.6296 - accuracy: 0.7531 - val_loss: 0.6087 - val_accuracy: 0.7646\n",
      "Epoch 99/1000\n",
      "239/239 [==============================] - 1s 2ms/step - loss: 0.6289 - accuracy: 0.7538 - val_loss: 0.6132 - val_accuracy: 0.7620\n",
      "Epoch 100/1000\n",
      "239/239 [==============================] - 1s 2ms/step - loss: 0.6292 - accuracy: 0.7539 - val_loss: 0.6098 - val_accuracy: 0.7632\n",
      "Epoch 101/1000\n",
      "239/239 [==============================] - 1s 2ms/step - loss: 0.6289 - accuracy: 0.7535 - val_loss: 0.6103 - val_accuracy: 0.7643\n",
      "Epoch 102/1000\n",
      "239/239 [==============================] - 1s 2ms/step - loss: 0.6279 - accuracy: 0.7538 - val_loss: 0.6116 - val_accuracy: 0.7639\n",
      "Epoch 103/1000\n",
      "239/239 [==============================] - 1s 2ms/step - loss: 0.6289 - accuracy: 0.7535 - val_loss: 0.6119 - val_accuracy: 0.7646\n",
      "Epoch 104/1000\n",
      "239/239 [==============================] - 1s 2ms/step - loss: 0.6289 - accuracy: 0.7536 - val_loss: 0.6105 - val_accuracy: 0.7654\n",
      "Epoch 105/1000\n",
      "239/239 [==============================] - 1s 2ms/step - loss: 0.6288 - accuracy: 0.7538 - val_loss: 0.6144 - val_accuracy: 0.7635\n",
      "Epoch 106/1000\n",
      "239/239 [==============================] - 1s 2ms/step - loss: 0.6295 - accuracy: 0.7527 - val_loss: 0.6127 - val_accuracy: 0.7627\n",
      "Epoch 107/1000\n",
      "239/239 [==============================] - 1s 2ms/step - loss: 0.6278 - accuracy: 0.7540 - val_loss: 0.6127 - val_accuracy: 0.7627\n",
      "Epoch 108/1000\n",
      "239/239 [==============================] - 1s 2ms/step - loss: 0.6290 - accuracy: 0.7533 - val_loss: 0.6091 - val_accuracy: 0.7626\n",
      "Epoch 109/1000\n",
      "239/239 [==============================] - 1s 2ms/step - loss: 0.6272 - accuracy: 0.7544 - val_loss: 0.6093 - val_accuracy: 0.7650\n",
      "Epoch 110/1000\n",
      "239/239 [==============================] - 1s 2ms/step - loss: 0.6269 - accuracy: 0.7546 - val_loss: 0.6100 - val_accuracy: 0.7642\n",
      "Epoch 111/1000\n",
      "239/239 [==============================] - 1s 2ms/step - loss: 0.6284 - accuracy: 0.7534 - val_loss: 0.6108 - val_accuracy: 0.7646\n",
      "Epoch 112/1000\n",
      "239/239 [==============================] - 1s 2ms/step - loss: 0.6273 - accuracy: 0.7534 - val_loss: 0.6134 - val_accuracy: 0.7640\n",
      "Epoch 113/1000\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "239/239 [==============================] - 1s 2ms/step - loss: 0.6263 - accuracy: 0.7545 - val_loss: 0.6139 - val_accuracy: 0.7654\n",
      "Epoch 114/1000\n",
      "239/239 [==============================] - 1s 2ms/step - loss: 0.6268 - accuracy: 0.7546 - val_loss: 0.6113 - val_accuracy: 0.7646\n",
      "Epoch 115/1000\n",
      "239/239 [==============================] - 1s 2ms/step - loss: 0.6261 - accuracy: 0.7547 - val_loss: 0.6087 - val_accuracy: 0.7649\n",
      "Epoch 116/1000\n",
      "239/239 [==============================] - 1s 2ms/step - loss: 0.6264 - accuracy: 0.7545 - val_loss: 0.6084 - val_accuracy: 0.7641\n",
      "Epoch 117/1000\n",
      "239/239 [==============================] - 1s 2ms/step - loss: 0.6269 - accuracy: 0.7544 - val_loss: 0.6080 - val_accuracy: 0.7646\n",
      "Epoch 118/1000\n",
      "239/239 [==============================] - 1s 2ms/step - loss: 0.6253 - accuracy: 0.7544 - val_loss: 0.6092 - val_accuracy: 0.7647\n",
      "Epoch 119/1000\n",
      "239/239 [==============================] - 1s 2ms/step - loss: 0.6252 - accuracy: 0.7550 - val_loss: 0.6074 - val_accuracy: 0.7665\n",
      "Epoch 120/1000\n",
      "239/239 [==============================] - 1s 2ms/step - loss: 0.6260 - accuracy: 0.7544 - val_loss: 0.6091 - val_accuracy: 0.7665\n",
      "Epoch 121/1000\n",
      "239/239 [==============================] - 1s 2ms/step - loss: 0.6273 - accuracy: 0.7550 - val_loss: 0.6069 - val_accuracy: 0.7654\n",
      "Epoch 122/1000\n",
      "239/239 [==============================] - 1s 2ms/step - loss: 0.6259 - accuracy: 0.7547 - val_loss: 0.6111 - val_accuracy: 0.7648\n",
      "Epoch 123/1000\n",
      "239/239 [==============================] - 1s 2ms/step - loss: 0.6273 - accuracy: 0.7536 - val_loss: 0.6106 - val_accuracy: 0.7637\n",
      "Epoch 124/1000\n",
      "239/239 [==============================] - 1s 2ms/step - loss: 0.6267 - accuracy: 0.7546 - val_loss: 0.6111 - val_accuracy: 0.7643\n",
      "Epoch 125/1000\n",
      "239/239 [==============================] - 1s 2ms/step - loss: 0.6262 - accuracy: 0.7551 - val_loss: 0.6090 - val_accuracy: 0.7656\n",
      "Epoch 126/1000\n",
      "239/239 [==============================] - 1s 2ms/step - loss: 0.6263 - accuracy: 0.7540 - val_loss: 0.6080 - val_accuracy: 0.7656\n",
      "Epoch 127/1000\n",
      "239/239 [==============================] - 1s 2ms/step - loss: 0.6243 - accuracy: 0.7550 - val_loss: 0.6083 - val_accuracy: 0.7649\n",
      "Epoch 128/1000\n",
      "239/239 [==============================] - 1s 2ms/step - loss: 0.6235 - accuracy: 0.7554 - val_loss: 0.6141 - val_accuracy: 0.7654\n",
      "Epoch 129/1000\n",
      "239/239 [==============================] - 1s 2ms/step - loss: 0.6243 - accuracy: 0.7542 - val_loss: 0.6104 - val_accuracy: 0.7654\n",
      "Epoch 130/1000\n",
      "239/239 [==============================] - 1s 2ms/step - loss: 0.6249 - accuracy: 0.7543 - val_loss: 0.6084 - val_accuracy: 0.7648\n",
      "Epoch 131/1000\n",
      "239/239 [==============================] - 1s 2ms/step - loss: 0.6244 - accuracy: 0.7545 - val_loss: 0.6101 - val_accuracy: 0.7663\n",
      "Epoch 132/1000\n",
      "239/239 [==============================] - 1s 2ms/step - loss: 0.6243 - accuracy: 0.7546 - val_loss: 0.6115 - val_accuracy: 0.7659\n",
      "Epoch 133/1000\n",
      "239/239 [==============================] - 1s 2ms/step - loss: 0.6244 - accuracy: 0.7554 - val_loss: 0.6087 - val_accuracy: 0.7650\n",
      "Epoch 134/1000\n",
      "239/239 [==============================] - 1s 2ms/step - loss: 0.6237 - accuracy: 0.7559 - val_loss: 0.6047 - val_accuracy: 0.7665\n",
      "Epoch 135/1000\n",
      "239/239 [==============================] - 1s 2ms/step - loss: 0.6242 - accuracy: 0.7558 - val_loss: 0.6056 - val_accuracy: 0.7651\n",
      "Epoch 136/1000\n",
      "239/239 [==============================] - 1s 2ms/step - loss: 0.6241 - accuracy: 0.7553 - val_loss: 0.6057 - val_accuracy: 0.7650\n",
      "Epoch 137/1000\n",
      "239/239 [==============================] - 1s 2ms/step - loss: 0.6251 - accuracy: 0.7559 - val_loss: 0.6113 - val_accuracy: 0.7668\n",
      "Epoch 138/1000\n",
      "239/239 [==============================] - 1s 2ms/step - loss: 0.6257 - accuracy: 0.7542 - val_loss: 0.6092 - val_accuracy: 0.7652\n",
      "Epoch 139/1000\n",
      "239/239 [==============================] - 1s 2ms/step - loss: 0.6251 - accuracy: 0.7553 - val_loss: 0.6101 - val_accuracy: 0.7665\n",
      "Epoch 140/1000\n",
      "239/239 [==============================] - 1s 2ms/step - loss: 0.6238 - accuracy: 0.7564 - val_loss: 0.6037 - val_accuracy: 0.7658\n",
      "Epoch 141/1000\n",
      "239/239 [==============================] - 1s 2ms/step - loss: 0.6236 - accuracy: 0.7559 - val_loss: 0.6070 - val_accuracy: 0.7658\n",
      "Epoch 142/1000\n",
      "239/239 [==============================] - 1s 2ms/step - loss: 0.6223 - accuracy: 0.7559 - val_loss: 0.6076 - val_accuracy: 0.7666\n",
      "Epoch 143/1000\n",
      "239/239 [==============================] - 1s 2ms/step - loss: 0.6236 - accuracy: 0.7552 - val_loss: 0.6084 - val_accuracy: 0.7657\n",
      "Epoch 144/1000\n",
      "239/239 [==============================] - 1s 2ms/step - loss: 0.6234 - accuracy: 0.7553 - val_loss: 0.6053 - val_accuracy: 0.7663\n",
      "Epoch 145/1000\n",
      "239/239 [==============================] - 1s 2ms/step - loss: 0.6247 - accuracy: 0.7549 - val_loss: 0.6057 - val_accuracy: 0.7646\n",
      "Epoch 146/1000\n",
      "239/239 [==============================] - 1s 2ms/step - loss: 0.6244 - accuracy: 0.7559 - val_loss: 0.6071 - val_accuracy: 0.7644\n",
      "Epoch 147/1000\n",
      "239/239 [==============================] - 1s 2ms/step - loss: 0.6236 - accuracy: 0.7548 - val_loss: 0.6079 - val_accuracy: 0.7644\n",
      "Epoch 148/1000\n",
      "239/239 [==============================] - 1s 2ms/step - loss: 0.6237 - accuracy: 0.7543 - val_loss: 0.6073 - val_accuracy: 0.7671\n",
      "Epoch 149/1000\n",
      "239/239 [==============================] - 1s 2ms/step - loss: 0.6221 - accuracy: 0.7552 - val_loss: 0.6083 - val_accuracy: 0.7677\n",
      "Epoch 150/1000\n",
      "239/239 [==============================] - 1s 2ms/step - loss: 0.6235 - accuracy: 0.7553 - val_loss: 0.6104 - val_accuracy: 0.7663\n",
      "Epoch 151/1000\n",
      "239/239 [==============================] - 1s 2ms/step - loss: 0.6231 - accuracy: 0.7549 - val_loss: 0.6077 - val_accuracy: 0.7668\n",
      "Epoch 152/1000\n",
      "239/239 [==============================] - 1s 2ms/step - loss: 0.6224 - accuracy: 0.7555 - val_loss: 0.6090 - val_accuracy: 0.7665\n",
      "Epoch 153/1000\n",
      "239/239 [==============================] - 1s 2ms/step - loss: 0.6223 - accuracy: 0.7551 - val_loss: 0.6095 - val_accuracy: 0.7664\n",
      "Epoch 154/1000\n",
      "239/239 [==============================] - 1s 2ms/step - loss: 0.6216 - accuracy: 0.7549 - val_loss: 0.6029 - val_accuracy: 0.7676\n",
      "Epoch 155/1000\n",
      "239/239 [==============================] - 1s 2ms/step - loss: 0.6192 - accuracy: 0.7553 - val_loss: 0.6094 - val_accuracy: 0.7668\n",
      "Epoch 156/1000\n",
      "239/239 [==============================] - 1s 2ms/step - loss: 0.6239 - accuracy: 0.7547 - val_loss: 0.6090 - val_accuracy: 0.7654\n",
      "Epoch 157/1000\n",
      "239/239 [==============================] - 1s 2ms/step - loss: 0.6224 - accuracy: 0.7554 - val_loss: 0.6065 - val_accuracy: 0.7657\n",
      "Epoch 158/1000\n",
      "239/239 [==============================] - 1s 2ms/step - loss: 0.6220 - accuracy: 0.7548 - val_loss: 0.6039 - val_accuracy: 0.7663\n",
      "Epoch 159/1000\n",
      "239/239 [==============================] - 1s 2ms/step - loss: 0.6217 - accuracy: 0.7560 - val_loss: 0.6083 - val_accuracy: 0.7656\n",
      "Epoch 160/1000\n",
      "239/239 [==============================] - 1s 2ms/step - loss: 0.6224 - accuracy: 0.7549 - val_loss: 0.6079 - val_accuracy: 0.7671\n",
      "Epoch 161/1000\n",
      "239/239 [==============================] - 1s 2ms/step - loss: 0.6216 - accuracy: 0.7559 - val_loss: 0.6056 - val_accuracy: 0.7670\n",
      "Epoch 162/1000\n",
      "239/239 [==============================] - 1s 2ms/step - loss: 0.6219 - accuracy: 0.7557 - val_loss: 0.6047 - val_accuracy: 0.7672\n",
      "Epoch 163/1000\n",
      "239/239 [==============================] - 1s 2ms/step - loss: 0.6221 - accuracy: 0.7554 - val_loss: 0.6091 - val_accuracy: 0.7668\n",
      "Epoch 164/1000\n",
      "239/239 [==============================] - 1s 2ms/step - loss: 0.6229 - accuracy: 0.7556 - val_loss: 0.6051 - val_accuracy: 0.7677\n",
      "Epoch 165/1000\n",
      "239/239 [==============================] - 1s 2ms/step - loss: 0.6223 - accuracy: 0.7550 - val_loss: 0.6048 - val_accuracy: 0.7674\n",
      "Epoch 166/1000\n",
      "239/239 [==============================] - 1s 2ms/step - loss: 0.6198 - accuracy: 0.7560 - val_loss: 0.6066 - val_accuracy: 0.7679\n",
      "Epoch 167/1000\n",
      "239/239 [==============================] - 1s 2ms/step - loss: 0.6210 - accuracy: 0.7554 - val_loss: 0.6038 - val_accuracy: 0.7659\n",
      "Epoch 168/1000\n",
      "239/239 [==============================] - 1s 2ms/step - loss: 0.6222 - accuracy: 0.7552 - val_loss: 0.6077 - val_accuracy: 0.7658\n",
      "Epoch 169/1000\n",
      "239/239 [==============================] - 1s 2ms/step - loss: 0.6216 - accuracy: 0.7556 - val_loss: 0.6086 - val_accuracy: 0.7657\n",
      "Epoch 170/1000\n",
      "239/239 [==============================] - 1s 2ms/step - loss: 0.6233 - accuracy: 0.7554 - val_loss: 0.6063 - val_accuracy: 0.7670\n",
      "Epoch 171/1000\n",
      "239/239 [==============================] - 1s 2ms/step - loss: 0.6218 - accuracy: 0.7559 - val_loss: 0.6104 - val_accuracy: 0.7651\n",
      "Epoch 172/1000\n",
      "239/239 [==============================] - 1s 2ms/step - loss: 0.6209 - accuracy: 0.7553 - val_loss: 0.6070 - val_accuracy: 0.7654\n",
      "Epoch 173/1000\n",
      "239/239 [==============================] - 1s 2ms/step - loss: 0.6223 - accuracy: 0.7558 - val_loss: 0.6046 - val_accuracy: 0.7661\n",
      "Epoch 174/1000\n",
      "239/239 [==============================] - 1s 2ms/step - loss: 0.6211 - accuracy: 0.7566 - val_loss: 0.6025 - val_accuracy: 0.7662\n",
      "Epoch 175/1000\n",
      "239/239 [==============================] - 1s 2ms/step - loss: 0.6189 - accuracy: 0.7554 - val_loss: 0.6049 - val_accuracy: 0.7652\n",
      "Epoch 176/1000\n",
      "239/239 [==============================] - 1s 2ms/step - loss: 0.6221 - accuracy: 0.7552 - val_loss: 0.6066 - val_accuracy: 0.7660\n",
      "Epoch 177/1000\n",
      "239/239 [==============================] - 1s 2ms/step - loss: 0.6202 - accuracy: 0.7557 - val_loss: 0.6037 - val_accuracy: 0.7663\n",
      "Epoch 178/1000\n",
      "239/239 [==============================] - 1s 2ms/step - loss: 0.6200 - accuracy: 0.7559 - val_loss: 0.6051 - val_accuracy: 0.7660\n",
      "Epoch 179/1000\n",
      "239/239 [==============================] - 1s 2ms/step - loss: 0.6193 - accuracy: 0.7565 - val_loss: 0.6102 - val_accuracy: 0.7677\n",
      "Epoch 180/1000\n",
      "239/239 [==============================] - 1s 2ms/step - loss: 0.6207 - accuracy: 0.7559 - val_loss: 0.6047 - val_accuracy: 0.7660\n",
      "Epoch 181/1000\n",
      "239/239 [==============================] - 1s 2ms/step - loss: 0.6206 - accuracy: 0.7554 - val_loss: 0.6052 - val_accuracy: 0.7659\n",
      "Epoch 182/1000\n",
      "239/239 [==============================] - 1s 2ms/step - loss: 0.6198 - accuracy: 0.7558 - val_loss: 0.6053 - val_accuracy: 0.7657\n",
      "Epoch 183/1000\n",
      "239/239 [==============================] - 1s 2ms/step - loss: 0.6203 - accuracy: 0.7562 - val_loss: 0.6067 - val_accuracy: 0.7665\n",
      "Epoch 184/1000\n",
      "239/239 [==============================] - 1s 2ms/step - loss: 0.6208 - accuracy: 0.7552 - val_loss: 0.6033 - val_accuracy: 0.7668\n",
      "Epoch 185/1000\n",
      "239/239 [==============================] - 1s 2ms/step - loss: 0.6218 - accuracy: 0.7559 - val_loss: 0.6055 - val_accuracy: 0.7671\n",
      "Epoch 186/1000\n",
      "239/239 [==============================] - 1s 2ms/step - loss: 0.6193 - accuracy: 0.7564 - val_loss: 0.6041 - val_accuracy: 0.7660\n",
      "Epoch 187/1000\n",
      "239/239 [==============================] - 1s 2ms/step - loss: 0.6193 - accuracy: 0.7562 - val_loss: 0.6021 - val_accuracy: 0.7669\n",
      "Epoch 188/1000\n",
      "239/239 [==============================] - 1s 2ms/step - loss: 0.6196 - accuracy: 0.7560 - val_loss: 0.6037 - val_accuracy: 0.7660\n",
      "Epoch 189/1000\n",
      "239/239 [==============================] - 1s 2ms/step - loss: 0.6182 - accuracy: 0.7560 - val_loss: 0.6044 - val_accuracy: 0.7647\n",
      "Epoch 190/1000\n",
      "239/239 [==============================] - 1s 2ms/step - loss: 0.6220 - accuracy: 0.7551 - val_loss: 0.6087 - val_accuracy: 0.7668\n",
      "Epoch 191/1000\n",
      "239/239 [==============================] - 1s 2ms/step - loss: 0.6195 - accuracy: 0.7562 - val_loss: 0.6057 - val_accuracy: 0.7667\n",
      "Epoch 192/1000\n",
      "239/239 [==============================] - 1s 2ms/step - loss: 0.6202 - accuracy: 0.7560 - val_loss: 0.6055 - val_accuracy: 0.7681\n",
      "Epoch 193/1000\n",
      "239/239 [==============================] - 1s 2ms/step - loss: 0.6197 - accuracy: 0.7555 - val_loss: 0.6079 - val_accuracy: 0.7675\n",
      "Epoch 194/1000\n",
      "239/239 [==============================] - 1s 2ms/step - loss: 0.6188 - accuracy: 0.7571 - val_loss: 0.6056 - val_accuracy: 0.7677\n",
      "Epoch 195/1000\n",
      "239/239 [==============================] - 1s 2ms/step - loss: 0.6174 - accuracy: 0.7566 - val_loss: 0.6042 - val_accuracy: 0.7659\n",
      "Epoch 196/1000\n",
      "239/239 [==============================] - 1s 2ms/step - loss: 0.6186 - accuracy: 0.7560 - val_loss: 0.6069 - val_accuracy: 0.7671\n",
      "Epoch 197/1000\n",
      "239/239 [==============================] - 1s 2ms/step - loss: 0.6215 - accuracy: 0.7548 - val_loss: 0.6067 - val_accuracy: 0.7669\n",
      "Epoch 198/1000\n",
      "239/239 [==============================] - 1s 2ms/step - loss: 0.6201 - accuracy: 0.7563 - val_loss: 0.6016 - val_accuracy: 0.7674\n",
      "Epoch 199/1000\n",
      "239/239 [==============================] - 1s 2ms/step - loss: 0.6188 - accuracy: 0.7557 - val_loss: 0.6034 - val_accuracy: 0.7683\n",
      "Epoch 200/1000\n",
      "239/239 [==============================] - 1s 2ms/step - loss: 0.6203 - accuracy: 0.7560 - val_loss: 0.6070 - val_accuracy: 0.7660\n",
      "Epoch 201/1000\n",
      "239/239 [==============================] - 1s 2ms/step - loss: 0.6192 - accuracy: 0.7552 - val_loss: 0.6057 - val_accuracy: 0.7681\n",
      "Epoch 202/1000\n",
      "239/239 [==============================] - 1s 2ms/step - loss: 0.6182 - accuracy: 0.7569 - val_loss: 0.6049 - val_accuracy: 0.7675\n",
      "Epoch 203/1000\n",
      "239/239 [==============================] - 1s 2ms/step - loss: 0.6184 - accuracy: 0.7569 - val_loss: 0.6067 - val_accuracy: 0.7645\n",
      "Epoch 204/1000\n",
      "239/239 [==============================] - 1s 2ms/step - loss: 0.6178 - accuracy: 0.7574 - val_loss: 0.6038 - val_accuracy: 0.7679\n",
      "Epoch 205/1000\n",
      "239/239 [==============================] - 1s 2ms/step - loss: 0.6175 - accuracy: 0.7564 - val_loss: 0.6068 - val_accuracy: 0.7673\n",
      "Epoch 206/1000\n",
      "239/239 [==============================] - 1s 2ms/step - loss: 0.6167 - accuracy: 0.7564 - val_loss: 0.6050 - val_accuracy: 0.7674\n",
      "Epoch 207/1000\n",
      "239/239 [==============================] - 1s 2ms/step - loss: 0.6168 - accuracy: 0.7573 - val_loss: 0.6004 - val_accuracy: 0.7670\n",
      "Epoch 208/1000\n",
      "239/239 [==============================] - 1s 2ms/step - loss: 0.6198 - accuracy: 0.7556 - val_loss: 0.6043 - val_accuracy: 0.7678\n",
      "Epoch 209/1000\n",
      "239/239 [==============================] - 1s 2ms/step - loss: 0.6179 - accuracy: 0.7576 - val_loss: 0.6048 - val_accuracy: 0.7660\n",
      "Epoch 210/1000\n",
      "239/239 [==============================] - 1s 2ms/step - loss: 0.6174 - accuracy: 0.7567 - val_loss: 0.6070 - val_accuracy: 0.7652\n",
      "Epoch 211/1000\n",
      "239/239 [==============================] - 1s 2ms/step - loss: 0.6175 - accuracy: 0.7566 - val_loss: 0.6051 - val_accuracy: 0.7673\n",
      "Epoch 212/1000\n",
      "239/239 [==============================] - 1s 2ms/step - loss: 0.6193 - accuracy: 0.7567 - val_loss: 0.6096 - val_accuracy: 0.7673\n",
      "Epoch 213/1000\n",
      "239/239 [==============================] - 1s 2ms/step - loss: 0.6174 - accuracy: 0.7574 - val_loss: 0.6027 - val_accuracy: 0.7669\n",
      "Epoch 214/1000\n",
      "239/239 [==============================] - 1s 2ms/step - loss: 0.6180 - accuracy: 0.7568 - val_loss: 0.6052 - val_accuracy: 0.7685\n",
      "Epoch 215/1000\n",
      "239/239 [==============================] - 1s 2ms/step - loss: 0.6189 - accuracy: 0.7560 - val_loss: 0.6044 - val_accuracy: 0.7671\n",
      "Epoch 216/1000\n",
      "239/239 [==============================] - 1s 2ms/step - loss: 0.6185 - accuracy: 0.7561 - val_loss: 0.6049 - val_accuracy: 0.7685\n",
      "Epoch 217/1000\n",
      "239/239 [==============================] - 1s 2ms/step - loss: 0.6171 - accuracy: 0.7564 - val_loss: 0.6049 - val_accuracy: 0.7665\n",
      "Epoch 218/1000\n",
      "239/239 [==============================] - 1s 3ms/step - loss: 0.6174 - accuracy: 0.7565 - val_loss: 0.6048 - val_accuracy: 0.7676\n",
      "Epoch 219/1000\n",
      "239/239 [==============================] - 1s 2ms/step - loss: 0.6170 - accuracy: 0.7564 - val_loss: 0.6039 - val_accuracy: 0.7674\n",
      "Epoch 220/1000\n",
      "239/239 [==============================] - 1s 2ms/step - loss: 0.6174 - accuracy: 0.7580 - val_loss: 0.6059 - val_accuracy: 0.7678\n",
      "Epoch 221/1000\n",
      "239/239 [==============================] - 1s 2ms/step - loss: 0.6178 - accuracy: 0.7572 - val_loss: 0.6039 - val_accuracy: 0.7673\n",
      "Epoch 222/1000\n",
      "239/239 [==============================] - 1s 2ms/step - loss: 0.6198 - accuracy: 0.7561 - val_loss: 0.6091 - val_accuracy: 0.7657\n",
      "Epoch 223/1000\n",
      "239/239 [==============================] - 1s 2ms/step - loss: 0.6165 - accuracy: 0.7569 - val_loss: 0.6074 - val_accuracy: 0.7680\n",
      "Epoch 224/1000\n",
      "239/239 [==============================] - 1s 2ms/step - loss: 0.6179 - accuracy: 0.7567 - val_loss: 0.6028 - val_accuracy: 0.7668\n",
      "Epoch 225/1000\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "239/239 [==============================] - 1s 2ms/step - loss: 0.6178 - accuracy: 0.7559 - val_loss: 0.6042 - val_accuracy: 0.7672\n",
      "Epoch 226/1000\n",
      "239/239 [==============================] - 1s 2ms/step - loss: 0.6179 - accuracy: 0.7560 - val_loss: 0.6023 - val_accuracy: 0.7682\n",
      "Epoch 227/1000\n",
      "239/239 [==============================] - 1s 2ms/step - loss: 0.6172 - accuracy: 0.7559 - val_loss: 0.6031 - val_accuracy: 0.7672\n",
      "Epoch 228/1000\n",
      "239/239 [==============================] - 1s 2ms/step - loss: 0.6158 - accuracy: 0.7574 - val_loss: 0.6025 - val_accuracy: 0.7681\n",
      "Epoch 229/1000\n",
      "239/239 [==============================] - 1s 2ms/step - loss: 0.6172 - accuracy: 0.7567 - val_loss: 0.6017 - val_accuracy: 0.7671\n",
      "Epoch 230/1000\n",
      "239/239 [==============================] - 1s 2ms/step - loss: 0.6157 - accuracy: 0.7562 - val_loss: 0.5990 - val_accuracy: 0.7688\n",
      "Epoch 231/1000\n",
      "239/239 [==============================] - 1s 2ms/step - loss: 0.6168 - accuracy: 0.7564 - val_loss: 0.6013 - val_accuracy: 0.7691\n",
      "Epoch 232/1000\n",
      "239/239 [==============================] - 1s 2ms/step - loss: 0.6170 - accuracy: 0.7569 - val_loss: 0.6014 - val_accuracy: 0.7679\n",
      "Epoch 233/1000\n",
      "239/239 [==============================] - 1s 2ms/step - loss: 0.6179 - accuracy: 0.7567 - val_loss: 0.6027 - val_accuracy: 0.7661\n",
      "Epoch 234/1000\n",
      "239/239 [==============================] - 1s 2ms/step - loss: 0.6167 - accuracy: 0.7558 - val_loss: 0.6050 - val_accuracy: 0.7678\n",
      "Epoch 235/1000\n",
      "239/239 [==============================] - 1s 2ms/step - loss: 0.6194 - accuracy: 0.7555 - val_loss: 0.6085 - val_accuracy: 0.7684\n",
      "Epoch 236/1000\n",
      "239/239 [==============================] - 1s 2ms/step - loss: 0.6189 - accuracy: 0.7559 - val_loss: 0.6033 - val_accuracy: 0.7685\n",
      "Epoch 237/1000\n",
      "239/239 [==============================] - 1s 2ms/step - loss: 0.6178 - accuracy: 0.7557 - val_loss: 0.6071 - val_accuracy: 0.7694\n",
      "Epoch 238/1000\n",
      "239/239 [==============================] - 1s 2ms/step - loss: 0.6185 - accuracy: 0.7558 - val_loss: 0.6083 - val_accuracy: 0.7691\n",
      "Epoch 239/1000\n",
      "239/239 [==============================] - 1s 2ms/step - loss: 0.6156 - accuracy: 0.7572 - val_loss: 0.6014 - val_accuracy: 0.7682\n",
      "Epoch 240/1000\n",
      "239/239 [==============================] - 1s 2ms/step - loss: 0.6167 - accuracy: 0.7577 - val_loss: 0.6003 - val_accuracy: 0.7691\n",
      "Epoch 241/1000\n",
      "239/239 [==============================] - 1s 2ms/step - loss: 0.6176 - accuracy: 0.7575 - val_loss: 0.6046 - val_accuracy: 0.7688\n",
      "Epoch 242/1000\n",
      "239/239 [==============================] - 1s 2ms/step - loss: 0.6156 - accuracy: 0.7573 - val_loss: 0.6002 - val_accuracy: 0.7698\n",
      "Epoch 243/1000\n",
      "239/239 [==============================] - 1s 2ms/step - loss: 0.6160 - accuracy: 0.7561 - val_loss: 0.5996 - val_accuracy: 0.7694\n",
      "Epoch 244/1000\n",
      "239/239 [==============================] - 1s 2ms/step - loss: 0.6165 - accuracy: 0.7565 - val_loss: 0.6050 - val_accuracy: 0.7684\n",
      "Epoch 245/1000\n",
      "239/239 [==============================] - 1s 2ms/step - loss: 0.6139 - accuracy: 0.7576 - val_loss: 0.5999 - val_accuracy: 0.7715\n",
      "Epoch 246/1000\n",
      "239/239 [==============================] - 1s 2ms/step - loss: 0.6176 - accuracy: 0.7567 - val_loss: 0.6004 - val_accuracy: 0.7691\n",
      "Epoch 247/1000\n",
      "239/239 [==============================] - 1s 2ms/step - loss: 0.6186 - accuracy: 0.7564 - val_loss: 0.5968 - val_accuracy: 0.7685\n",
      "Epoch 248/1000\n",
      "239/239 [==============================] - 1s 2ms/step - loss: 0.6171 - accuracy: 0.7563 - val_loss: 0.6022 - val_accuracy: 0.7678\n",
      "Epoch 249/1000\n",
      "239/239 [==============================] - 1s 2ms/step - loss: 0.6167 - accuracy: 0.7577 - val_loss: 0.5997 - val_accuracy: 0.7696\n",
      "Epoch 250/1000\n",
      "239/239 [==============================] - 1s 2ms/step - loss: 0.6173 - accuracy: 0.7575 - val_loss: 0.6019 - val_accuracy: 0.7685\n",
      "Epoch 251/1000\n",
      "239/239 [==============================] - 1s 2ms/step - loss: 0.6166 - accuracy: 0.7568 - val_loss: 0.6047 - val_accuracy: 0.7693\n",
      "Epoch 252/1000\n",
      "239/239 [==============================] - 1s 2ms/step - loss: 0.6169 - accuracy: 0.7570 - val_loss: 0.6018 - val_accuracy: 0.7696\n",
      "Epoch 253/1000\n",
      "239/239 [==============================] - 1s 2ms/step - loss: 0.6152 - accuracy: 0.7560 - val_loss: 0.6051 - val_accuracy: 0.7690\n",
      "Epoch 254/1000\n",
      "239/239 [==============================] - 1s 2ms/step - loss: 0.6174 - accuracy: 0.7555 - val_loss: 0.6048 - val_accuracy: 0.7683\n",
      "Epoch 255/1000\n",
      "239/239 [==============================] - 1s 2ms/step - loss: 0.6161 - accuracy: 0.7558 - val_loss: 0.6021 - val_accuracy: 0.7685\n",
      "Epoch 256/1000\n",
      "239/239 [==============================] - 1s 2ms/step - loss: 0.6162 - accuracy: 0.7562 - val_loss: 0.6019 - val_accuracy: 0.7696\n",
      "Epoch 257/1000\n",
      "239/239 [==============================] - 1s 3ms/step - loss: 0.6174 - accuracy: 0.7561 - val_loss: 0.6015 - val_accuracy: 0.7685\n",
      "Epoch 258/1000\n",
      "239/239 [==============================] - 1s 2ms/step - loss: 0.6165 - accuracy: 0.7568 - val_loss: 0.6058 - val_accuracy: 0.7681\n",
      "Epoch 259/1000\n",
      "239/239 [==============================] - 1s 2ms/step - loss: 0.6152 - accuracy: 0.7572 - val_loss: 0.6021 - val_accuracy: 0.7697\n",
      "Epoch 260/1000\n",
      "239/239 [==============================] - 1s 2ms/step - loss: 0.6149 - accuracy: 0.7577 - val_loss: 0.5999 - val_accuracy: 0.7689\n",
      "Epoch 261/1000\n",
      "239/239 [==============================] - 1s 2ms/step - loss: 0.6160 - accuracy: 0.7567 - val_loss: 0.5987 - val_accuracy: 0.7695\n",
      "Epoch 262/1000\n",
      "239/239 [==============================] - 1s 2ms/step - loss: 0.6145 - accuracy: 0.7573 - val_loss: 0.6016 - val_accuracy: 0.7696\n",
      "Epoch 263/1000\n",
      "239/239 [==============================] - 1s 2ms/step - loss: 0.6144 - accuracy: 0.7581 - val_loss: 0.6012 - val_accuracy: 0.7693\n",
      "Epoch 264/1000\n",
      "239/239 [==============================] - 1s 2ms/step - loss: 0.6162 - accuracy: 0.7577 - val_loss: 0.6024 - val_accuracy: 0.7700\n",
      "Epoch 265/1000\n",
      "239/239 [==============================] - 1s 2ms/step - loss: 0.6167 - accuracy: 0.7575 - val_loss: 0.6036 - val_accuracy: 0.7705\n",
      "Epoch 266/1000\n",
      "239/239 [==============================] - 1s 2ms/step - loss: 0.6159 - accuracy: 0.7576 - val_loss: 0.5985 - val_accuracy: 0.7719\n",
      "Epoch 267/1000\n",
      "239/239 [==============================] - 1s 2ms/step - loss: 0.6138 - accuracy: 0.7581 - val_loss: 0.6073 - val_accuracy: 0.7687\n",
      "Epoch 268/1000\n",
      "239/239 [==============================] - 1s 2ms/step - loss: 0.6141 - accuracy: 0.7574 - val_loss: 0.5988 - val_accuracy: 0.7702\n",
      "Epoch 269/1000\n",
      "239/239 [==============================] - 1s 2ms/step - loss: 0.6141 - accuracy: 0.7567 - val_loss: 0.5970 - val_accuracy: 0.7702\n",
      "Epoch 270/1000\n",
      "239/239 [==============================] - 1s 2ms/step - loss: 0.6146 - accuracy: 0.7565 - val_loss: 0.6013 - val_accuracy: 0.7678\n",
      "Epoch 271/1000\n",
      "239/239 [==============================] - 1s 2ms/step - loss: 0.6154 - accuracy: 0.7569 - val_loss: 0.6002 - val_accuracy: 0.7696\n",
      "Epoch 272/1000\n",
      "239/239 [==============================] - 1s 2ms/step - loss: 0.6145 - accuracy: 0.7568 - val_loss: 0.6066 - val_accuracy: 0.7683\n",
      "Epoch 273/1000\n",
      "239/239 [==============================] - 1s 3ms/step - loss: 0.6159 - accuracy: 0.7571 - val_loss: 0.5987 - val_accuracy: 0.7702\n",
      "Epoch 274/1000\n",
      "239/239 [==============================] - 1s 2ms/step - loss: 0.6163 - accuracy: 0.7574 - val_loss: 0.5993 - val_accuracy: 0.7693\n",
      "Epoch 275/1000\n",
      "239/239 [==============================] - 1s 2ms/step - loss: 0.6145 - accuracy: 0.7574 - val_loss: 0.6008 - val_accuracy: 0.7688\n",
      "Epoch 276/1000\n",
      "239/239 [==============================] - 1s 2ms/step - loss: 0.6143 - accuracy: 0.7574 - val_loss: 0.5980 - val_accuracy: 0.7703\n",
      "Epoch 277/1000\n",
      "239/239 [==============================] - 1s 2ms/step - loss: 0.6145 - accuracy: 0.7580 - val_loss: 0.5993 - val_accuracy: 0.7698\n",
      "Epoch 278/1000\n",
      "239/239 [==============================] - 1s 2ms/step - loss: 0.6143 - accuracy: 0.7588 - val_loss: 0.5974 - val_accuracy: 0.7699\n",
      "Epoch 279/1000\n",
      "239/239 [==============================] - 1s 2ms/step - loss: 0.6150 - accuracy: 0.7573 - val_loss: 0.6019 - val_accuracy: 0.7698\n",
      "Epoch 280/1000\n",
      "239/239 [==============================] - 1s 2ms/step - loss: 0.6139 - accuracy: 0.7573 - val_loss: 0.6021 - val_accuracy: 0.7696\n",
      "Epoch 281/1000\n",
      "239/239 [==============================] - 1s 2ms/step - loss: 0.6143 - accuracy: 0.7574 - val_loss: 0.5980 - val_accuracy: 0.7702\n",
      "Epoch 282/1000\n",
      "239/239 [==============================] - 1s 2ms/step - loss: 0.6129 - accuracy: 0.7583 - val_loss: 0.5991 - val_accuracy: 0.7704\n",
      "Epoch 283/1000\n",
      "239/239 [==============================] - 1s 2ms/step - loss: 0.6129 - accuracy: 0.7572 - val_loss: 0.5962 - val_accuracy: 0.7718\n",
      "Epoch 284/1000\n",
      "239/239 [==============================] - 1s 2ms/step - loss: 0.6134 - accuracy: 0.7573 - val_loss: 0.5963 - val_accuracy: 0.7702\n",
      "Epoch 285/1000\n",
      "239/239 [==============================] - 1s 2ms/step - loss: 0.6139 - accuracy: 0.7573 - val_loss: 0.5967 - val_accuracy: 0.7700\n",
      "Epoch 286/1000\n",
      "239/239 [==============================] - 1s 2ms/step - loss: 0.6139 - accuracy: 0.7572 - val_loss: 0.6057 - val_accuracy: 0.7704\n",
      "Epoch 287/1000\n",
      "239/239 [==============================] - 1s 2ms/step - loss: 0.6137 - accuracy: 0.7575 - val_loss: 0.6004 - val_accuracy: 0.7705\n",
      "Epoch 288/1000\n",
      "239/239 [==============================] - 1s 2ms/step - loss: 0.6137 - accuracy: 0.7577 - val_loss: 0.5942 - val_accuracy: 0.7707\n",
      "Epoch 289/1000\n",
      "239/239 [==============================] - 1s 2ms/step - loss: 0.6150 - accuracy: 0.7572 - val_loss: 0.5993 - val_accuracy: 0.7718\n",
      "Epoch 290/1000\n",
      "239/239 [==============================] - 1s 2ms/step - loss: 0.6153 - accuracy: 0.7568 - val_loss: 0.6035 - val_accuracy: 0.7685\n",
      "Epoch 291/1000\n",
      "239/239 [==============================] - 1s 2ms/step - loss: 0.6158 - accuracy: 0.7561 - val_loss: 0.5999 - val_accuracy: 0.7702\n",
      "Epoch 292/1000\n",
      "239/239 [==============================] - 1s 2ms/step - loss: 0.6154 - accuracy: 0.7568 - val_loss: 0.5973 - val_accuracy: 0.7722\n",
      "Epoch 293/1000\n",
      "239/239 [==============================] - 1s 2ms/step - loss: 0.6146 - accuracy: 0.7579 - val_loss: 0.6015 - val_accuracy: 0.7702\n",
      "Epoch 294/1000\n",
      "239/239 [==============================] - 1s 2ms/step - loss: 0.6133 - accuracy: 0.7572 - val_loss: 0.6038 - val_accuracy: 0.7708\n",
      "Epoch 295/1000\n",
      "239/239 [==============================] - 1s 2ms/step - loss: 0.6132 - accuracy: 0.7577 - val_loss: 0.6035 - val_accuracy: 0.7693\n",
      "Epoch 296/1000\n",
      "239/239 [==============================] - 1s 2ms/step - loss: 0.6145 - accuracy: 0.7574 - val_loss: 0.6068 - val_accuracy: 0.7690\n",
      "Epoch 297/1000\n",
      "239/239 [==============================] - 1s 2ms/step - loss: 0.6130 - accuracy: 0.7586 - val_loss: 0.6029 - val_accuracy: 0.7719\n",
      "Epoch 298/1000\n",
      "239/239 [==============================] - 1s 2ms/step - loss: 0.6150 - accuracy: 0.7570 - val_loss: 0.6067 - val_accuracy: 0.7704\n",
      "Epoch 299/1000\n",
      "239/239 [==============================] - 1s 2ms/step - loss: 0.6142 - accuracy: 0.7576 - val_loss: 0.6006 - val_accuracy: 0.7697\n",
      "Epoch 300/1000\n",
      "239/239 [==============================] - 1s 2ms/step - loss: 0.6130 - accuracy: 0.7575 - val_loss: 0.6004 - val_accuracy: 0.7688\n",
      "Epoch 301/1000\n",
      "239/239 [==============================] - 1s 2ms/step - loss: 0.6130 - accuracy: 0.7578 - val_loss: 0.5995 - val_accuracy: 0.7696\n",
      "Epoch 302/1000\n",
      "239/239 [==============================] - 1s 2ms/step - loss: 0.6156 - accuracy: 0.7575 - val_loss: 0.6004 - val_accuracy: 0.7699\n",
      "Epoch 303/1000\n",
      "239/239 [==============================] - 1s 2ms/step - loss: 0.6151 - accuracy: 0.7574 - val_loss: 0.6086 - val_accuracy: 0.7687\n",
      "Epoch 304/1000\n",
      "239/239 [==============================] - 1s 2ms/step - loss: 0.6142 - accuracy: 0.7572 - val_loss: 0.5977 - val_accuracy: 0.7713\n",
      "Epoch 305/1000\n",
      "239/239 [==============================] - 1s 2ms/step - loss: 0.6128 - accuracy: 0.7586 - val_loss: 0.5992 - val_accuracy: 0.7716\n",
      "Epoch 306/1000\n",
      "239/239 [==============================] - 1s 3ms/step - loss: 0.6139 - accuracy: 0.7572 - val_loss: 0.5988 - val_accuracy: 0.7705\n",
      "Epoch 307/1000\n",
      "239/239 [==============================] - 1s 2ms/step - loss: 0.6129 - accuracy: 0.7581 - val_loss: 0.5991 - val_accuracy: 0.7692\n",
      "Epoch 308/1000\n",
      "239/239 [==============================] - 1s 2ms/step - loss: 0.6129 - accuracy: 0.7586 - val_loss: 0.5997 - val_accuracy: 0.7699\n",
      "Epoch 309/1000\n",
      "239/239 [==============================] - 1s 2ms/step - loss: 0.6120 - accuracy: 0.7587 - val_loss: 0.5984 - val_accuracy: 0.7706\n",
      "Epoch 310/1000\n",
      "239/239 [==============================] - 1s 2ms/step - loss: 0.6135 - accuracy: 0.7585 - val_loss: 0.5990 - val_accuracy: 0.7709\n",
      "Epoch 311/1000\n",
      "239/239 [==============================] - 1s 2ms/step - loss: 0.6117 - accuracy: 0.7580 - val_loss: 0.5985 - val_accuracy: 0.7709\n",
      "Epoch 312/1000\n",
      "239/239 [==============================] - 1s 2ms/step - loss: 0.6140 - accuracy: 0.7583 - val_loss: 0.6000 - val_accuracy: 0.7696\n",
      "Epoch 313/1000\n",
      "239/239 [==============================] - 1s 2ms/step - loss: 0.6130 - accuracy: 0.7577 - val_loss: 0.6018 - val_accuracy: 0.7693\n",
      "Epoch 314/1000\n",
      "239/239 [==============================] - 1s 2ms/step - loss: 0.6129 - accuracy: 0.7578 - val_loss: 0.6018 - val_accuracy: 0.7696\n",
      "Epoch 315/1000\n",
      "239/239 [==============================] - 1s 2ms/step - loss: 0.6146 - accuracy: 0.7571 - val_loss: 0.5980 - val_accuracy: 0.7713\n",
      "Epoch 316/1000\n",
      "239/239 [==============================] - 1s 2ms/step - loss: 0.6115 - accuracy: 0.7591 - val_loss: 0.5979 - val_accuracy: 0.7696\n",
      "Epoch 317/1000\n",
      "239/239 [==============================] - 1s 2ms/step - loss: 0.6144 - accuracy: 0.7575 - val_loss: 0.6061 - val_accuracy: 0.7702\n",
      "Epoch 318/1000\n",
      "239/239 [==============================] - 1s 2ms/step - loss: 0.6127 - accuracy: 0.7571 - val_loss: 0.6044 - val_accuracy: 0.7701\n",
      "Epoch 319/1000\n",
      "239/239 [==============================] - 1s 2ms/step - loss: 0.6130 - accuracy: 0.7580 - val_loss: 0.6000 - val_accuracy: 0.7716\n",
      "Epoch 320/1000\n",
      "239/239 [==============================] - 1s 2ms/step - loss: 0.6116 - accuracy: 0.7581 - val_loss: 0.6021 - val_accuracy: 0.7701\n",
      "Epoch 321/1000\n",
      "239/239 [==============================] - 1s 2ms/step - loss: 0.6122 - accuracy: 0.7566 - val_loss: 0.5983 - val_accuracy: 0.7671\n",
      "Epoch 322/1000\n",
      "239/239 [==============================] - 1s 2ms/step - loss: 0.6146 - accuracy: 0.7572 - val_loss: 0.6055 - val_accuracy: 0.7645\n",
      "Epoch 323/1000\n",
      "239/239 [==============================] - 1s 2ms/step - loss: 0.6145 - accuracy: 0.7568 - val_loss: 0.6039 - val_accuracy: 0.7682\n",
      "Epoch 324/1000\n",
      "239/239 [==============================] - 1s 2ms/step - loss: 0.6138 - accuracy: 0.7571 - val_loss: 0.6076 - val_accuracy: 0.7673\n",
      "Epoch 325/1000\n",
      "239/239 [==============================] - 1s 2ms/step - loss: 0.6145 - accuracy: 0.7568 - val_loss: 0.6118 - val_accuracy: 0.7677\n",
      "Epoch 326/1000\n",
      "239/239 [==============================] - 1s 2ms/step - loss: 0.6120 - accuracy: 0.7579 - val_loss: 0.5998 - val_accuracy: 0.7708\n",
      "Epoch 327/1000\n",
      "239/239 [==============================] - 1s 2ms/step - loss: 0.6135 - accuracy: 0.7566 - val_loss: 0.6055 - val_accuracy: 0.7693\n",
      "Epoch 328/1000\n",
      "239/239 [==============================] - 1s 2ms/step - loss: 0.6126 - accuracy: 0.7572 - val_loss: 0.5988 - val_accuracy: 0.7698\n",
      "Epoch 329/1000\n",
      "239/239 [==============================] - 1s 2ms/step - loss: 0.6112 - accuracy: 0.7583 - val_loss: 0.6007 - val_accuracy: 0.7702\n",
      "Epoch 330/1000\n",
      "239/239 [==============================] - 1s 2ms/step - loss: 0.6113 - accuracy: 0.7583 - val_loss: 0.6017 - val_accuracy: 0.7707\n",
      "Epoch 331/1000\n",
      "239/239 [==============================] - 1s 2ms/step - loss: 0.6103 - accuracy: 0.7584 - val_loss: 0.5953 - val_accuracy: 0.7716\n",
      "Epoch 332/1000\n",
      "239/239 [==============================] - 1s 2ms/step - loss: 0.6108 - accuracy: 0.7579 - val_loss: 0.5998 - val_accuracy: 0.7705\n",
      "Epoch 333/1000\n",
      "239/239 [==============================] - 1s 3ms/step - loss: 0.6143 - accuracy: 0.7573 - val_loss: 0.6007 - val_accuracy: 0.7714\n",
      "Epoch 334/1000\n",
      "239/239 [==============================] - 1s 2ms/step - loss: 0.6121 - accuracy: 0.7573 - val_loss: 0.5953 - val_accuracy: 0.7694\n",
      "Epoch 335/1000\n",
      "239/239 [==============================] - 1s 2ms/step - loss: 0.6129 - accuracy: 0.7571 - val_loss: 0.6017 - val_accuracy: 0.7712\n",
      "Epoch 336/1000\n",
      "239/239 [==============================] - 1s 2ms/step - loss: 0.6127 - accuracy: 0.7573 - val_loss: 0.6004 - val_accuracy: 0.7702\n",
      "Epoch 337/1000\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "239/239 [==============================] - 1s 2ms/step - loss: 0.6128 - accuracy: 0.7577 - val_loss: 0.6020 - val_accuracy: 0.7722\n",
      "Epoch 338/1000\n",
      "239/239 [==============================] - 1s 2ms/step - loss: 0.6131 - accuracy: 0.7576 - val_loss: 0.5964 - val_accuracy: 0.7708\n",
      "Epoch 339/1000\n",
      "239/239 [==============================] - 1s 2ms/step - loss: 0.6124 - accuracy: 0.7576 - val_loss: 0.5986 - val_accuracy: 0.7716\n",
      "Epoch 340/1000\n",
      "239/239 [==============================] - 1s 2ms/step - loss: 0.6136 - accuracy: 0.7574 - val_loss: 0.6039 - val_accuracy: 0.7672\n",
      "Epoch 341/1000\n",
      "239/239 [==============================] - 1s 2ms/step - loss: 0.6136 - accuracy: 0.7578 - val_loss: 0.5992 - val_accuracy: 0.7699\n",
      "Epoch 342/1000\n",
      "239/239 [==============================] - 1s 2ms/step - loss: 0.6135 - accuracy: 0.7577 - val_loss: 0.6014 - val_accuracy: 0.7692\n",
      "Epoch 343/1000\n",
      "239/239 [==============================] - 1s 2ms/step - loss: 0.6111 - accuracy: 0.7585 - val_loss: 0.5979 - val_accuracy: 0.7696\n",
      "Epoch 344/1000\n",
      "239/239 [==============================] - 1s 2ms/step - loss: 0.6109 - accuracy: 0.7591 - val_loss: 0.5981 - val_accuracy: 0.7706\n",
      "Epoch 345/1000\n",
      "239/239 [==============================] - 1s 2ms/step - loss: 0.6112 - accuracy: 0.7580 - val_loss: 0.6009 - val_accuracy: 0.7697\n",
      "Epoch 346/1000\n",
      "239/239 [==============================] - 1s 2ms/step - loss: 0.6122 - accuracy: 0.7584 - val_loss: 0.5988 - val_accuracy: 0.7692\n",
      "Epoch 347/1000\n",
      "239/239 [==============================] - 1s 2ms/step - loss: 0.6111 - accuracy: 0.7582 - val_loss: 0.6002 - val_accuracy: 0.7706\n",
      "Epoch 348/1000\n",
      "239/239 [==============================] - 1s 2ms/step - loss: 0.6116 - accuracy: 0.7585 - val_loss: 0.6004 - val_accuracy: 0.7691\n",
      "Epoch 349/1000\n",
      "239/239 [==============================] - 1s 2ms/step - loss: 0.6115 - accuracy: 0.7582 - val_loss: 0.5967 - val_accuracy: 0.7696\n",
      "Epoch 350/1000\n",
      "239/239 [==============================] - 1s 2ms/step - loss: 0.6108 - accuracy: 0.7580 - val_loss: 0.5966 - val_accuracy: 0.7728\n",
      "Epoch 351/1000\n",
      "239/239 [==============================] - 1s 2ms/step - loss: 0.6128 - accuracy: 0.7584 - val_loss: 0.6012 - val_accuracy: 0.7716\n",
      "Epoch 352/1000\n",
      "239/239 [==============================] - 1s 2ms/step - loss: 0.6117 - accuracy: 0.7583 - val_loss: 0.6006 - val_accuracy: 0.7703\n",
      "Epoch 353/1000\n",
      "239/239 [==============================] - 1s 2ms/step - loss: 0.6134 - accuracy: 0.7572 - val_loss: 0.6057 - val_accuracy: 0.7696\n",
      "Epoch 354/1000\n",
      "239/239 [==============================] - 1s 2ms/step - loss: 0.6133 - accuracy: 0.7573 - val_loss: 0.6046 - val_accuracy: 0.7703\n",
      "Epoch 355/1000\n",
      "239/239 [==============================] - 1s 2ms/step - loss: 0.6108 - accuracy: 0.7586 - val_loss: 0.6030 - val_accuracy: 0.7681\n",
      "Epoch 356/1000\n",
      "239/239 [==============================] - 1s 2ms/step - loss: 0.6120 - accuracy: 0.7574 - val_loss: 0.5993 - val_accuracy: 0.7722\n",
      "Epoch 357/1000\n",
      "239/239 [==============================] - 1s 2ms/step - loss: 0.6101 - accuracy: 0.7581 - val_loss: 0.5961 - val_accuracy: 0.7734\n",
      "Epoch 358/1000\n",
      "239/239 [==============================] - 1s 2ms/step - loss: 0.6120 - accuracy: 0.7577 - val_loss: 0.6017 - val_accuracy: 0.7714\n",
      "Epoch 359/1000\n",
      "239/239 [==============================] - 1s 2ms/step - loss: 0.6122 - accuracy: 0.7583 - val_loss: 0.5979 - val_accuracy: 0.7717\n",
      "Epoch 360/1000\n",
      "239/239 [==============================] - 1s 2ms/step - loss: 0.6110 - accuracy: 0.7577 - val_loss: 0.5986 - val_accuracy: 0.7719\n",
      "Epoch 361/1000\n",
      "239/239 [==============================] - 1s 2ms/step - loss: 0.6114 - accuracy: 0.7579 - val_loss: 0.5980 - val_accuracy: 0.7707\n",
      "Epoch 362/1000\n",
      "239/239 [==============================] - 1s 2ms/step - loss: 0.6120 - accuracy: 0.7576 - val_loss: 0.6001 - val_accuracy: 0.7711\n",
      "Epoch 363/1000\n",
      "239/239 [==============================] - 1s 2ms/step - loss: 0.6129 - accuracy: 0.7574 - val_loss: 0.5982 - val_accuracy: 0.7706\n",
      "Epoch 364/1000\n",
      "239/239 [==============================] - 1s 2ms/step - loss: 0.6130 - accuracy: 0.7574 - val_loss: 0.6013 - val_accuracy: 0.7708\n",
      "Epoch 365/1000\n",
      "239/239 [==============================] - 1s 3ms/step - loss: 0.6109 - accuracy: 0.7576 - val_loss: 0.5975 - val_accuracy: 0.7722\n",
      "Epoch 366/1000\n",
      "239/239 [==============================] - 1s 2ms/step - loss: 0.6111 - accuracy: 0.7583 - val_loss: 0.6067 - val_accuracy: 0.7694\n",
      "Epoch 367/1000\n",
      "239/239 [==============================] - 1s 2ms/step - loss: 0.6093 - accuracy: 0.7589 - val_loss: 0.5965 - val_accuracy: 0.7732\n",
      "Epoch 368/1000\n",
      "239/239 [==============================] - 1s 2ms/step - loss: 0.6132 - accuracy: 0.7569 - val_loss: 0.6079 - val_accuracy: 0.7691\n",
      "Epoch 369/1000\n",
      "239/239 [==============================] - 1s 2ms/step - loss: 0.6114 - accuracy: 0.7586 - val_loss: 0.5987 - val_accuracy: 0.7710\n",
      "Epoch 370/1000\n",
      "239/239 [==============================] - 1s 2ms/step - loss: 0.6097 - accuracy: 0.7573 - val_loss: 0.6000 - val_accuracy: 0.7693\n",
      "Epoch 371/1000\n",
      "239/239 [==============================] - 1s 2ms/step - loss: 0.6105 - accuracy: 0.7583 - val_loss: 0.5961 - val_accuracy: 0.7718\n",
      "Epoch 372/1000\n",
      "239/239 [==============================] - 1s 2ms/step - loss: 0.6120 - accuracy: 0.7586 - val_loss: 0.5982 - val_accuracy: 0.7724\n",
      "Epoch 373/1000\n",
      "239/239 [==============================] - 1s 2ms/step - loss: 0.6116 - accuracy: 0.7588 - val_loss: 0.5987 - val_accuracy: 0.7707\n",
      "Epoch 374/1000\n",
      "239/239 [==============================] - 1s 2ms/step - loss: 0.6142 - accuracy: 0.7569 - val_loss: 0.6030 - val_accuracy: 0.7683\n",
      "Epoch 375/1000\n",
      "239/239 [==============================] - 1s 2ms/step - loss: 0.6122 - accuracy: 0.7570 - val_loss: 0.6092 - val_accuracy: 0.7664\n",
      "Epoch 376/1000\n",
      "239/239 [==============================] - 1s 2ms/step - loss: 0.6133 - accuracy: 0.7575 - val_loss: 0.6071 - val_accuracy: 0.7699\n",
      "Epoch 377/1000\n",
      "239/239 [==============================] - 1s 2ms/step - loss: 0.6113 - accuracy: 0.7583 - val_loss: 0.6001 - val_accuracy: 0.7710\n",
      "Epoch 378/1000\n",
      "239/239 [==============================] - 1s 2ms/step - loss: 0.6128 - accuracy: 0.7581 - val_loss: 0.6011 - val_accuracy: 0.7696\n",
      "Epoch 378: early stopping\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "<keras.src.callbacks.History at 0x147b6d480>"
      ]
     },
     "execution_count": 175,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "model=Sequential()\n",
    "model.add(Dense(128, input_dim=X_train.shape[1], activation=\"relu\"))\n",
    "model.add(Dropout(0.2))\n",
    "model.add(Dense(128, activation=\"relu\"))\n",
    "model.add(Dropout(0.8))\n",
    "model.add(Dense(64, activation=\"relu\"))\n",
    "model.add(Dropout(0.2))\n",
    "model.add(Dense(64, activation=\"relu\"))\n",
    "model.add(Dropout(0.2))\n",
    "model.add(Dense(32, activation=\"relu\"))\n",
    "model.add(Dropout(0.2))\n",
    "model.add(Dense(3, activation=\"softmax\"))\n",
    "\n",
    "model.compile(loss='categorical_crossentropy', optimizer=Adam(learning_rate=0.001), metrics=['accuracy'])\n",
    "\n",
    "es=EarlyStopping(monitor=\"val_loss\",patience=90,mode=\"auto\",verbose=1)\n",
    "\n",
    "model.fit(X_train,\n",
    "          y_train,\n",
    "          epochs=1000,\n",
    "               batch_size=512,\n",
    "               validation_split=0.1,\n",
    "               verbose=1,callbacks=[es])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 176,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "748/748 [==============================] - 0s 257us/step\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0       0.77      0.87      0.82      7973\n",
      "           1       0.73      0.84      0.78      7973\n",
      "           2       0.78      0.56      0.65      7972\n",
      "\n",
      "    accuracy                           0.76     23918\n",
      "   macro avg       0.76      0.76      0.75     23918\n",
      "weighted avg       0.76      0.76      0.75     23918\n",
      "\n"
     ]
    }
   ],
   "source": [
    "y_pred = model.predict(X_test)\n",
    "y_pred_classes = np.argmax(y_pred, axis=1)\n",
    "y_true = np.argmax(y_test, axis=1)\n",
    "print(classification_report(y_true, y_pred_classes))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 177,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "4236/4236 [==============================] - 1s 249us/step\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0       0.79      0.88      0.83     45176\n",
      "           1       0.74      0.85      0.80     45176\n",
      "           2       0.79      0.58      0.67     45177\n",
      "\n",
      "    accuracy                           0.77    135529\n",
      "   macro avg       0.77      0.77      0.77    135529\n",
      "weighted avg       0.77      0.77      0.77    135529\n",
      "\n"
     ]
    }
   ],
   "source": [
    "y_t_pred = model.predict(X_train)\n",
    "y_t_pred_classes = np.argmax(y_t_pred, axis=1)\n",
    "y_t_true = np.argmax(y_train, axis=1)\n",
    "print(classification_report(y_t_true, y_t_pred_classes))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 178,
   "metadata": {},
   "outputs": [],
   "source": [
    "X=df.drop('Credit_Score',axis=1)\n",
    "y = df.Credit_Score\n",
    "\n",
    "smote = SMOTE() \n",
    "X, y = smote.fit_resample(X,y)\n",
    "\n",
    "y=to_categorical(y, num_classes=3)\n",
    "\n",
    "X_train, X_test, y_train, y_test = train_test_split(X,y,test_size=0.2,random_state=42)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 179,
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.preprocessing import RobustScaler\n",
    "scaler = RobustScaler()\n",
    "X_train = scaler.fit_transform(X_train)\n",
    "X_test = scaler.transform(X_test)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 180,
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 1/1000\n",
      "225/225 [==============================] - 1s 2ms/step - loss: 0.7832 - accuracy: 0.6867 - val_loss: 0.6873 - val_accuracy: 0.7302\n",
      "Epoch 2/1000\n",
      "225/225 [==============================] - 1s 2ms/step - loss: 0.7116 - accuracy: 0.7264 - val_loss: 0.6677 - val_accuracy: 0.7372\n",
      "Epoch 3/1000\n",
      "225/225 [==============================] - 1s 2ms/step - loss: 0.6930 - accuracy: 0.7335 - val_loss: 0.6584 - val_accuracy: 0.7414\n",
      "Epoch 4/1000\n",
      "225/225 [==============================] - 0s 2ms/step - loss: 0.6847 - accuracy: 0.7347 - val_loss: 0.6530 - val_accuracy: 0.7424\n",
      "Epoch 5/1000\n",
      "225/225 [==============================] - 0s 2ms/step - loss: 0.6752 - accuracy: 0.7381 - val_loss: 0.6431 - val_accuracy: 0.7470\n",
      "Epoch 6/1000\n",
      "225/225 [==============================] - 0s 2ms/step - loss: 0.6691 - accuracy: 0.7410 - val_loss: 0.6404 - val_accuracy: 0.7477\n",
      "Epoch 7/1000\n",
      "225/225 [==============================] - 0s 2ms/step - loss: 0.6647 - accuracy: 0.7422 - val_loss: 0.6334 - val_accuracy: 0.7520\n",
      "Epoch 8/1000\n",
      "225/225 [==============================] - 0s 2ms/step - loss: 0.6605 - accuracy: 0.7439 - val_loss: 0.6324 - val_accuracy: 0.7522\n",
      "Epoch 9/1000\n",
      "225/225 [==============================] - 0s 2ms/step - loss: 0.6551 - accuracy: 0.7453 - val_loss: 0.6248 - val_accuracy: 0.7541\n",
      "Epoch 10/1000\n",
      "225/225 [==============================] - 0s 2ms/step - loss: 0.6527 - accuracy: 0.7473 - val_loss: 0.6249 - val_accuracy: 0.7533\n",
      "Epoch 11/1000\n",
      "225/225 [==============================] - 0s 2ms/step - loss: 0.6488 - accuracy: 0.7477 - val_loss: 0.6198 - val_accuracy: 0.7550\n",
      "Epoch 12/1000\n",
      "225/225 [==============================] - 0s 2ms/step - loss: 0.6453 - accuracy: 0.7489 - val_loss: 0.6159 - val_accuracy: 0.7584\n",
      "Epoch 13/1000\n",
      "225/225 [==============================] - 1s 2ms/step - loss: 0.6419 - accuracy: 0.7509 - val_loss: 0.6134 - val_accuracy: 0.7596\n",
      "Epoch 14/1000\n",
      "225/225 [==============================] - 0s 2ms/step - loss: 0.6404 - accuracy: 0.7499 - val_loss: 0.6137 - val_accuracy: 0.7593\n",
      "Epoch 15/1000\n",
      "225/225 [==============================] - 0s 2ms/step - loss: 0.6356 - accuracy: 0.7527 - val_loss: 0.6082 - val_accuracy: 0.7612\n",
      "Epoch 16/1000\n",
      "225/225 [==============================] - 1s 2ms/step - loss: 0.6335 - accuracy: 0.7519 - val_loss: 0.6029 - val_accuracy: 0.7605\n",
      "Epoch 17/1000\n",
      "225/225 [==============================] - 1s 2ms/step - loss: 0.6300 - accuracy: 0.7532 - val_loss: 0.6037 - val_accuracy: 0.7602\n",
      "Epoch 18/1000\n",
      "225/225 [==============================] - 0s 2ms/step - loss: 0.6286 - accuracy: 0.7548 - val_loss: 0.6008 - val_accuracy: 0.7633\n",
      "Epoch 19/1000\n",
      "225/225 [==============================] - 0s 2ms/step - loss: 0.6268 - accuracy: 0.7549 - val_loss: 0.5941 - val_accuracy: 0.7630\n",
      "Epoch 20/1000\n",
      "225/225 [==============================] - 1s 2ms/step - loss: 0.6231 - accuracy: 0.7560 - val_loss: 0.5919 - val_accuracy: 0.7638\n",
      "Epoch 21/1000\n",
      "225/225 [==============================] - 0s 2ms/step - loss: 0.6198 - accuracy: 0.7571 - val_loss: 0.5911 - val_accuracy: 0.7648\n",
      "Epoch 22/1000\n",
      "225/225 [==============================] - 0s 2ms/step - loss: 0.6175 - accuracy: 0.7584 - val_loss: 0.5877 - val_accuracy: 0.7683\n",
      "Epoch 23/1000\n",
      "225/225 [==============================] - 0s 2ms/step - loss: 0.6158 - accuracy: 0.7586 - val_loss: 0.5867 - val_accuracy: 0.7664\n",
      "Epoch 24/1000\n",
      "225/225 [==============================] - 0s 2ms/step - loss: 0.6144 - accuracy: 0.7587 - val_loss: 0.5827 - val_accuracy: 0.7698\n",
      "Epoch 25/1000\n",
      "225/225 [==============================] - 1s 2ms/step - loss: 0.6126 - accuracy: 0.7599 - val_loss: 0.5768 - val_accuracy: 0.7719\n",
      "Epoch 26/1000\n",
      "225/225 [==============================] - 0s 2ms/step - loss: 0.6103 - accuracy: 0.7610 - val_loss: 0.5792 - val_accuracy: 0.7704\n",
      "Epoch 27/1000\n",
      "225/225 [==============================] - 0s 2ms/step - loss: 0.6092 - accuracy: 0.7616 - val_loss: 0.5767 - val_accuracy: 0.7705\n",
      "Epoch 28/1000\n",
      "225/225 [==============================] - 0s 2ms/step - loss: 0.6069 - accuracy: 0.7615 - val_loss: 0.5730 - val_accuracy: 0.7706\n",
      "Epoch 29/1000\n",
      "225/225 [==============================] - 0s 2ms/step - loss: 0.6046 - accuracy: 0.7627 - val_loss: 0.5731 - val_accuracy: 0.7726\n",
      "Epoch 30/1000\n",
      "225/225 [==============================] - 1s 2ms/step - loss: 0.6033 - accuracy: 0.7632 - val_loss: 0.5689 - val_accuracy: 0.7734\n",
      "Epoch 31/1000\n",
      "225/225 [==============================] - 0s 2ms/step - loss: 0.6022 - accuracy: 0.7636 - val_loss: 0.5707 - val_accuracy: 0.7726\n",
      "Epoch 32/1000\n",
      "225/225 [==============================] - 0s 2ms/step - loss: 0.5999 - accuracy: 0.7644 - val_loss: 0.5666 - val_accuracy: 0.7770\n",
      "Epoch 33/1000\n",
      "225/225 [==============================] - 0s 2ms/step - loss: 0.5961 - accuracy: 0.7656 - val_loss: 0.5626 - val_accuracy: 0.7739\n",
      "Epoch 34/1000\n",
      "225/225 [==============================] - 1s 2ms/step - loss: 0.5967 - accuracy: 0.7650 - val_loss: 0.5636 - val_accuracy: 0.7765\n",
      "Epoch 35/1000\n",
      "225/225 [==============================] - 0s 2ms/step - loss: 0.5930 - accuracy: 0.7668 - val_loss: 0.5559 - val_accuracy: 0.7799\n",
      "Epoch 36/1000\n",
      "225/225 [==============================] - 0s 2ms/step - loss: 0.5930 - accuracy: 0.7667 - val_loss: 0.5553 - val_accuracy: 0.7830\n",
      "Epoch 37/1000\n",
      "225/225 [==============================] - 0s 2ms/step - loss: 0.5926 - accuracy: 0.7664 - val_loss: 0.5532 - val_accuracy: 0.7782\n",
      "Epoch 38/1000\n",
      "225/225 [==============================] - 0s 2ms/step - loss: 0.5897 - accuracy: 0.7675 - val_loss: 0.5542 - val_accuracy: 0.7796\n",
      "Epoch 39/1000\n",
      "225/225 [==============================] - 0s 2ms/step - loss: 0.5897 - accuracy: 0.7681 - val_loss: 0.5537 - val_accuracy: 0.7796\n",
      "Epoch 40/1000\n",
      "225/225 [==============================] - 1s 2ms/step - loss: 0.5887 - accuracy: 0.7680 - val_loss: 0.5515 - val_accuracy: 0.7796\n",
      "Epoch 41/1000\n",
      "225/225 [==============================] - 0s 2ms/step - loss: 0.5856 - accuracy: 0.7691 - val_loss: 0.5524 - val_accuracy: 0.7797\n",
      "Epoch 42/1000\n",
      "225/225 [==============================] - 0s 2ms/step - loss: 0.5852 - accuracy: 0.7689 - val_loss: 0.5469 - val_accuracy: 0.7802\n",
      "Epoch 43/1000\n",
      "225/225 [==============================] - 0s 2ms/step - loss: 0.5833 - accuracy: 0.7704 - val_loss: 0.5465 - val_accuracy: 0.7807\n",
      "Epoch 44/1000\n",
      "225/225 [==============================] - 1s 2ms/step - loss: 0.5854 - accuracy: 0.7693 - val_loss: 0.5457 - val_accuracy: 0.7821\n",
      "Epoch 45/1000\n",
      "225/225 [==============================] - 1s 2ms/step - loss: 0.5832 - accuracy: 0.7701 - val_loss: 0.5432 - val_accuracy: 0.7855\n",
      "Epoch 46/1000\n",
      "225/225 [==============================] - 0s 2ms/step - loss: 0.5804 - accuracy: 0.7708 - val_loss: 0.5450 - val_accuracy: 0.7823\n",
      "Epoch 47/1000\n",
      "225/225 [==============================] - 0s 2ms/step - loss: 0.5783 - accuracy: 0.7720 - val_loss: 0.5405 - val_accuracy: 0.7847\n",
      "Epoch 48/1000\n",
      "225/225 [==============================] - 0s 2ms/step - loss: 0.5795 - accuracy: 0.7713 - val_loss: 0.5392 - val_accuracy: 0.7872\n",
      "Epoch 49/1000\n",
      "225/225 [==============================] - 0s 2ms/step - loss: 0.5799 - accuracy: 0.7723 - val_loss: 0.5388 - val_accuracy: 0.7857\n",
      "Epoch 50/1000\n",
      "225/225 [==============================] - 0s 2ms/step - loss: 0.5759 - accuracy: 0.7723 - val_loss: 0.5374 - val_accuracy: 0.7870\n",
      "Epoch 51/1000\n",
      "225/225 [==============================] - 1s 2ms/step - loss: 0.5770 - accuracy: 0.7718 - val_loss: 0.5356 - val_accuracy: 0.7854\n",
      "Epoch 52/1000\n",
      "225/225 [==============================] - 1s 2ms/step - loss: 0.5762 - accuracy: 0.7728 - val_loss: 0.5379 - val_accuracy: 0.7858\n",
      "Epoch 53/1000\n",
      "225/225 [==============================] - 0s 2ms/step - loss: 0.5771 - accuracy: 0.7725 - val_loss: 0.5365 - val_accuracy: 0.7854\n",
      "Epoch 54/1000\n",
      "225/225 [==============================] - 0s 2ms/step - loss: 0.5727 - accuracy: 0.7745 - val_loss: 0.5344 - val_accuracy: 0.7864\n",
      "Epoch 55/1000\n",
      "225/225 [==============================] - 0s 2ms/step - loss: 0.5732 - accuracy: 0.7737 - val_loss: 0.5356 - val_accuracy: 0.7879\n",
      "Epoch 56/1000\n",
      "225/225 [==============================] - 0s 2ms/step - loss: 0.5741 - accuracy: 0.7730 - val_loss: 0.5321 - val_accuracy: 0.7884\n",
      "Epoch 57/1000\n",
      "225/225 [==============================] - 0s 2ms/step - loss: 0.5725 - accuracy: 0.7742 - val_loss: 0.5306 - val_accuracy: 0.7889\n",
      "Epoch 58/1000\n",
      "225/225 [==============================] - 0s 2ms/step - loss: 0.5713 - accuracy: 0.7738 - val_loss: 0.5291 - val_accuracy: 0.7894\n",
      "Epoch 59/1000\n",
      "225/225 [==============================] - 0s 2ms/step - loss: 0.5701 - accuracy: 0.7741 - val_loss: 0.5266 - val_accuracy: 0.7903\n",
      "Epoch 60/1000\n",
      "225/225 [==============================] - 0s 2ms/step - loss: 0.5698 - accuracy: 0.7755 - val_loss: 0.5275 - val_accuracy: 0.7912\n",
      "Epoch 61/1000\n",
      "225/225 [==============================] - 0s 2ms/step - loss: 0.5686 - accuracy: 0.7753 - val_loss: 0.5280 - val_accuracy: 0.7910\n",
      "Epoch 62/1000\n",
      "225/225 [==============================] - 0s 2ms/step - loss: 0.5684 - accuracy: 0.7760 - val_loss: 0.5258 - val_accuracy: 0.7906\n",
      "Epoch 63/1000\n",
      "225/225 [==============================] - 0s 2ms/step - loss: 0.5664 - accuracy: 0.7764 - val_loss: 0.5259 - val_accuracy: 0.7902\n",
      "Epoch 64/1000\n",
      "225/225 [==============================] - 0s 2ms/step - loss: 0.5658 - accuracy: 0.7764 - val_loss: 0.5241 - val_accuracy: 0.7919\n",
      "Epoch 65/1000\n",
      "225/225 [==============================] - 0s 2ms/step - loss: 0.5670 - accuracy: 0.7751 - val_loss: 0.5230 - val_accuracy: 0.7925\n",
      "Epoch 66/1000\n",
      "225/225 [==============================] - 0s 2ms/step - loss: 0.5658 - accuracy: 0.7774 - val_loss: 0.5244 - val_accuracy: 0.7902\n",
      "Epoch 67/1000\n",
      "225/225 [==============================] - 0s 2ms/step - loss: 0.5652 - accuracy: 0.7765 - val_loss: 0.5222 - val_accuracy: 0.7935\n",
      "Epoch 68/1000\n",
      "225/225 [==============================] - 0s 2ms/step - loss: 0.5638 - accuracy: 0.7774 - val_loss: 0.5202 - val_accuracy: 0.7948\n",
      "Epoch 69/1000\n",
      "225/225 [==============================] - 0s 2ms/step - loss: 0.5654 - accuracy: 0.7762 - val_loss: 0.5201 - val_accuracy: 0.7944\n",
      "Epoch 70/1000\n",
      "225/225 [==============================] - 0s 2ms/step - loss: 0.5620 - accuracy: 0.7769 - val_loss: 0.5192 - val_accuracy: 0.7937\n",
      "Epoch 71/1000\n",
      "225/225 [==============================] - 0s 2ms/step - loss: 0.5638 - accuracy: 0.7773 - val_loss: 0.5234 - val_accuracy: 0.7930\n",
      "Epoch 72/1000\n",
      "225/225 [==============================] - 0s 2ms/step - loss: 0.5633 - accuracy: 0.7776 - val_loss: 0.5189 - val_accuracy: 0.7941\n",
      "Epoch 73/1000\n",
      "225/225 [==============================] - 0s 2ms/step - loss: 0.5622 - accuracy: 0.7775 - val_loss: 0.5173 - val_accuracy: 0.7954\n",
      "Epoch 74/1000\n",
      "225/225 [==============================] - 0s 2ms/step - loss: 0.5605 - accuracy: 0.7792 - val_loss: 0.5176 - val_accuracy: 0.7949\n",
      "Epoch 75/1000\n",
      "225/225 [==============================] - 0s 2ms/step - loss: 0.5613 - accuracy: 0.7781 - val_loss: 0.5112 - val_accuracy: 0.7988\n",
      "Epoch 76/1000\n",
      "225/225 [==============================] - 0s 2ms/step - loss: 0.5591 - accuracy: 0.7796 - val_loss: 0.5135 - val_accuracy: 0.7962\n",
      "Epoch 77/1000\n",
      "225/225 [==============================] - 1s 2ms/step - loss: 0.5591 - accuracy: 0.7791 - val_loss: 0.5124 - val_accuracy: 0.7952\n",
      "Epoch 78/1000\n",
      "225/225 [==============================] - 0s 2ms/step - loss: 0.5585 - accuracy: 0.7786 - val_loss: 0.5141 - val_accuracy: 0.7952\n",
      "Epoch 79/1000\n",
      "225/225 [==============================] - 0s 2ms/step - loss: 0.5581 - accuracy: 0.7807 - val_loss: 0.5160 - val_accuracy: 0.7978\n",
      "Epoch 80/1000\n",
      "225/225 [==============================] - 0s 2ms/step - loss: 0.5579 - accuracy: 0.7802 - val_loss: 0.5116 - val_accuracy: 0.7999\n",
      "Epoch 81/1000\n",
      "225/225 [==============================] - 0s 2ms/step - loss: 0.5601 - accuracy: 0.7785 - val_loss: 0.5148 - val_accuracy: 0.7957\n",
      "Epoch 82/1000\n",
      "225/225 [==============================] - 0s 2ms/step - loss: 0.5585 - accuracy: 0.7790 - val_loss: 0.5103 - val_accuracy: 0.7963\n",
      "Epoch 83/1000\n",
      "225/225 [==============================] - 0s 2ms/step - loss: 0.5546 - accuracy: 0.7806 - val_loss: 0.5138 - val_accuracy: 0.7969\n",
      "Epoch 84/1000\n",
      "225/225 [==============================] - 0s 2ms/step - loss: 0.5548 - accuracy: 0.7797 - val_loss: 0.5100 - val_accuracy: 0.7979\n",
      "Epoch 85/1000\n",
      "225/225 [==============================] - 0s 2ms/step - loss: 0.5560 - accuracy: 0.7811 - val_loss: 0.5098 - val_accuracy: 0.7977\n",
      "Epoch 86/1000\n",
      "225/225 [==============================] - 0s 2ms/step - loss: 0.5568 - accuracy: 0.7795 - val_loss: 0.5120 - val_accuracy: 0.7989\n",
      "Epoch 87/1000\n",
      "225/225 [==============================] - 0s 2ms/step - loss: 0.5552 - accuracy: 0.7799 - val_loss: 0.5090 - val_accuracy: 0.7972\n",
      "Epoch 88/1000\n",
      "225/225 [==============================] - 0s 2ms/step - loss: 0.5530 - accuracy: 0.7813 - val_loss: 0.5084 - val_accuracy: 0.7969\n",
      "Epoch 89/1000\n",
      "225/225 [==============================] - 0s 2ms/step - loss: 0.5571 - accuracy: 0.7797 - val_loss: 0.5095 - val_accuracy: 0.7963\n",
      "Epoch 90/1000\n",
      "225/225 [==============================] - 0s 2ms/step - loss: 0.5543 - accuracy: 0.7810 - val_loss: 0.5090 - val_accuracy: 0.7998\n",
      "Epoch 91/1000\n",
      "225/225 [==============================] - 0s 2ms/step - loss: 0.5524 - accuracy: 0.7812 - val_loss: 0.5059 - val_accuracy: 0.7999\n",
      "Epoch 92/1000\n",
      "225/225 [==============================] - 0s 2ms/step - loss: 0.5520 - accuracy: 0.7821 - val_loss: 0.5046 - val_accuracy: 0.7989\n",
      "Epoch 93/1000\n",
      "225/225 [==============================] - 0s 2ms/step - loss: 0.5539 - accuracy: 0.7817 - val_loss: 0.5036 - val_accuracy: 0.7987\n",
      "Epoch 94/1000\n",
      "225/225 [==============================] - 0s 2ms/step - loss: 0.5525 - accuracy: 0.7810 - val_loss: 0.5030 - val_accuracy: 0.7999\n",
      "Epoch 95/1000\n",
      "225/225 [==============================] - 0s 2ms/step - loss: 0.5524 - accuracy: 0.7805 - val_loss: 0.5019 - val_accuracy: 0.8010\n",
      "Epoch 96/1000\n",
      "225/225 [==============================] - 0s 2ms/step - loss: 0.5511 - accuracy: 0.7817 - val_loss: 0.5028 - val_accuracy: 0.7988\n",
      "Epoch 97/1000\n",
      "225/225 [==============================] - 0s 2ms/step - loss: 0.5515 - accuracy: 0.7833 - val_loss: 0.5085 - val_accuracy: 0.7966\n",
      "Epoch 98/1000\n",
      "225/225 [==============================] - 0s 2ms/step - loss: 0.5498 - accuracy: 0.7837 - val_loss: 0.5015 - val_accuracy: 0.7999\n",
      "Epoch 99/1000\n",
      "225/225 [==============================] - 0s 2ms/step - loss: 0.5506 - accuracy: 0.7822 - val_loss: 0.5028 - val_accuracy: 0.7985\n",
      "Epoch 100/1000\n",
      "225/225 [==============================] - 0s 2ms/step - loss: 0.5492 - accuracy: 0.7834 - val_loss: 0.5021 - val_accuracy: 0.8003\n",
      "Epoch 101/1000\n",
      "225/225 [==============================] - 0s 2ms/step - loss: 0.5491 - accuracy: 0.7828 - val_loss: 0.5021 - val_accuracy: 0.7992\n",
      "Epoch 102/1000\n",
      "225/225 [==============================] - 0s 2ms/step - loss: 0.5470 - accuracy: 0.7833 - val_loss: 0.5027 - val_accuracy: 0.8022\n",
      "Epoch 103/1000\n",
      "225/225 [==============================] - 1s 2ms/step - loss: 0.5490 - accuracy: 0.7832 - val_loss: 0.5022 - val_accuracy: 0.8000\n",
      "Epoch 104/1000\n",
      "225/225 [==============================] - 0s 2ms/step - loss: 0.5495 - accuracy: 0.7832 - val_loss: 0.5004 - val_accuracy: 0.8028\n",
      "Epoch 105/1000\n",
      "225/225 [==============================] - 0s 2ms/step - loss: 0.5481 - accuracy: 0.7832 - val_loss: 0.5008 - val_accuracy: 0.8040\n",
      "Epoch 106/1000\n",
      "225/225 [==============================] - 0s 2ms/step - loss: 0.5491 - accuracy: 0.7844 - val_loss: 0.5014 - val_accuracy: 0.8017\n",
      "Epoch 107/1000\n",
      "225/225 [==============================] - 0s 2ms/step - loss: 0.5470 - accuracy: 0.7843 - val_loss: 0.4992 - val_accuracy: 0.8028\n",
      "Epoch 108/1000\n",
      "225/225 [==============================] - 0s 2ms/step - loss: 0.5473 - accuracy: 0.7836 - val_loss: 0.5018 - val_accuracy: 0.8006\n",
      "Epoch 109/1000\n",
      "225/225 [==============================] - 1s 2ms/step - loss: 0.5472 - accuracy: 0.7848 - val_loss: 0.5000 - val_accuracy: 0.8013\n",
      "Epoch 110/1000\n",
      "225/225 [==============================] - 1s 2ms/step - loss: 0.5462 - accuracy: 0.7841 - val_loss: 0.4930 - val_accuracy: 0.8049\n",
      "Epoch 111/1000\n",
      "225/225 [==============================] - 0s 2ms/step - loss: 0.5472 - accuracy: 0.7837 - val_loss: 0.4956 - val_accuracy: 0.8068\n",
      "Epoch 112/1000\n",
      "225/225 [==============================] - 0s 2ms/step - loss: 0.5449 - accuracy: 0.7845 - val_loss: 0.4968 - val_accuracy: 0.8040\n",
      "Epoch 113/1000\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "225/225 [==============================] - 0s 2ms/step - loss: 0.5453 - accuracy: 0.7846 - val_loss: 0.4974 - val_accuracy: 0.8035\n",
      "Epoch 114/1000\n",
      "225/225 [==============================] - 0s 2ms/step - loss: 0.5472 - accuracy: 0.7840 - val_loss: 0.4987 - val_accuracy: 0.8024\n",
      "Epoch 115/1000\n",
      "225/225 [==============================] - 0s 2ms/step - loss: 0.5445 - accuracy: 0.7849 - val_loss: 0.5012 - val_accuracy: 0.8015\n",
      "Epoch 116/1000\n",
      "225/225 [==============================] - 0s 2ms/step - loss: 0.5448 - accuracy: 0.7848 - val_loss: 0.4946 - val_accuracy: 0.8029\n",
      "Epoch 117/1000\n",
      "225/225 [==============================] - 0s 2ms/step - loss: 0.5447 - accuracy: 0.7848 - val_loss: 0.4947 - val_accuracy: 0.8048\n",
      "Epoch 118/1000\n",
      "225/225 [==============================] - 0s 2ms/step - loss: 0.5460 - accuracy: 0.7845 - val_loss: 0.4955 - val_accuracy: 0.8032\n",
      "Epoch 119/1000\n",
      "225/225 [==============================] - 0s 2ms/step - loss: 0.5449 - accuracy: 0.7852 - val_loss: 0.4927 - val_accuracy: 0.8054\n",
      "Epoch 120/1000\n",
      "225/225 [==============================] - 0s 2ms/step - loss: 0.5444 - accuracy: 0.7856 - val_loss: 0.4951 - val_accuracy: 0.8061\n",
      "Epoch 121/1000\n",
      "225/225 [==============================] - 0s 2ms/step - loss: 0.5419 - accuracy: 0.7864 - val_loss: 0.4948 - val_accuracy: 0.8046\n",
      "Epoch 122/1000\n",
      "225/225 [==============================] - 0s 2ms/step - loss: 0.5436 - accuracy: 0.7854 - val_loss: 0.4935 - val_accuracy: 0.8076\n",
      "Epoch 123/1000\n",
      "225/225 [==============================] - 0s 2ms/step - loss: 0.5447 - accuracy: 0.7852 - val_loss: 0.4934 - val_accuracy: 0.8055\n",
      "Epoch 124/1000\n",
      "225/225 [==============================] - 0s 2ms/step - loss: 0.5440 - accuracy: 0.7847 - val_loss: 0.4946 - val_accuracy: 0.8042\n",
      "Epoch 125/1000\n",
      "225/225 [==============================] - 0s 2ms/step - loss: 0.5432 - accuracy: 0.7867 - val_loss: 0.4958 - val_accuracy: 0.8032\n",
      "Epoch 126/1000\n",
      "225/225 [==============================] - 0s 2ms/step - loss: 0.5427 - accuracy: 0.7865 - val_loss: 0.4930 - val_accuracy: 0.8056\n",
      "Epoch 127/1000\n",
      "225/225 [==============================] - 0s 2ms/step - loss: 0.5445 - accuracy: 0.7843 - val_loss: 0.4935 - val_accuracy: 0.8062\n",
      "Epoch 128/1000\n",
      "225/225 [==============================] - 0s 2ms/step - loss: 0.5448 - accuracy: 0.7855 - val_loss: 0.4947 - val_accuracy: 0.8039\n",
      "Epoch 129/1000\n",
      "225/225 [==============================] - 0s 2ms/step - loss: 0.5423 - accuracy: 0.7868 - val_loss: 0.4935 - val_accuracy: 0.8058\n",
      "Epoch 130/1000\n",
      "225/225 [==============================] - 0s 2ms/step - loss: 0.5418 - accuracy: 0.7858 - val_loss: 0.4927 - val_accuracy: 0.8065\n",
      "Epoch 131/1000\n",
      "225/225 [==============================] - 0s 2ms/step - loss: 0.5426 - accuracy: 0.7857 - val_loss: 0.4925 - val_accuracy: 0.8045\n",
      "Epoch 132/1000\n",
      "225/225 [==============================] - 0s 2ms/step - loss: 0.5424 - accuracy: 0.7862 - val_loss: 0.4902 - val_accuracy: 0.8070\n",
      "Epoch 133/1000\n",
      "225/225 [==============================] - 0s 2ms/step - loss: 0.5413 - accuracy: 0.7857 - val_loss: 0.4916 - val_accuracy: 0.8049\n",
      "Epoch 134/1000\n",
      "225/225 [==============================] - 0s 2ms/step - loss: 0.5398 - accuracy: 0.7870 - val_loss: 0.4929 - val_accuracy: 0.8066\n",
      "Epoch 135/1000\n",
      "225/225 [==============================] - 0s 2ms/step - loss: 0.5406 - accuracy: 0.7874 - val_loss: 0.4883 - val_accuracy: 0.8061\n",
      "Epoch 136/1000\n",
      "225/225 [==============================] - 0s 2ms/step - loss: 0.5405 - accuracy: 0.7870 - val_loss: 0.4923 - val_accuracy: 0.8039\n",
      "Epoch 137/1000\n",
      "225/225 [==============================] - 0s 2ms/step - loss: 0.5422 - accuracy: 0.7864 - val_loss: 0.4912 - val_accuracy: 0.8050\n",
      "Epoch 138/1000\n",
      "225/225 [==============================] - 0s 2ms/step - loss: 0.5385 - accuracy: 0.7867 - val_loss: 0.4867 - val_accuracy: 0.8098\n",
      "Epoch 139/1000\n",
      "225/225 [==============================] - 0s 2ms/step - loss: 0.5402 - accuracy: 0.7878 - val_loss: 0.4889 - val_accuracy: 0.8051\n",
      "Epoch 140/1000\n",
      "225/225 [==============================] - 0s 2ms/step - loss: 0.5391 - accuracy: 0.7876 - val_loss: 0.4878 - val_accuracy: 0.8072\n",
      "Epoch 141/1000\n",
      "225/225 [==============================] - 0s 2ms/step - loss: 0.5397 - accuracy: 0.7860 - val_loss: 0.4916 - val_accuracy: 0.8067\n",
      "Epoch 142/1000\n",
      "225/225 [==============================] - 1s 2ms/step - loss: 0.5425 - accuracy: 0.7854 - val_loss: 0.4888 - val_accuracy: 0.8071\n",
      "Epoch 143/1000\n",
      "225/225 [==============================] - 0s 2ms/step - loss: 0.5395 - accuracy: 0.7868 - val_loss: 0.4878 - val_accuracy: 0.8064\n",
      "Epoch 144/1000\n",
      "225/225 [==============================] - 0s 2ms/step - loss: 0.5401 - accuracy: 0.7862 - val_loss: 0.4842 - val_accuracy: 0.8104\n",
      "Epoch 145/1000\n",
      "225/225 [==============================] - 0s 2ms/step - loss: 0.5401 - accuracy: 0.7872 - val_loss: 0.4893 - val_accuracy: 0.8063\n",
      "Epoch 146/1000\n",
      "225/225 [==============================] - 0s 2ms/step - loss: 0.5399 - accuracy: 0.7883 - val_loss: 0.4913 - val_accuracy: 0.8075\n",
      "Epoch 147/1000\n",
      "225/225 [==============================] - 0s 2ms/step - loss: 0.5375 - accuracy: 0.7877 - val_loss: 0.4919 - val_accuracy: 0.8050\n",
      "Epoch 148/1000\n",
      "225/225 [==============================] - 0s 2ms/step - loss: 0.5395 - accuracy: 0.7872 - val_loss: 0.4899 - val_accuracy: 0.8067\n",
      "Epoch 149/1000\n",
      "225/225 [==============================] - 0s 2ms/step - loss: 0.5415 - accuracy: 0.7873 - val_loss: 0.4884 - val_accuracy: 0.8086\n",
      "Epoch 150/1000\n",
      "225/225 [==============================] - 0s 2ms/step - loss: 0.5390 - accuracy: 0.7878 - val_loss: 0.4867 - val_accuracy: 0.8108\n",
      "Epoch 151/1000\n",
      "225/225 [==============================] - 0s 2ms/step - loss: 0.5377 - accuracy: 0.7871 - val_loss: 0.4851 - val_accuracy: 0.8103\n",
      "Epoch 152/1000\n",
      "225/225 [==============================] - 0s 2ms/step - loss: 0.5386 - accuracy: 0.7881 - val_loss: 0.4891 - val_accuracy: 0.8049\n",
      "Epoch 153/1000\n",
      "225/225 [==============================] - 0s 2ms/step - loss: 0.5391 - accuracy: 0.7873 - val_loss: 0.4866 - val_accuracy: 0.8087\n",
      "Epoch 154/1000\n",
      "225/225 [==============================] - 0s 2ms/step - loss: 0.5388 - accuracy: 0.7870 - val_loss: 0.4868 - val_accuracy: 0.8106\n",
      "Epoch 155/1000\n",
      "225/225 [==============================] - 1s 2ms/step - loss: 0.5367 - accuracy: 0.7888 - val_loss: 0.4875 - val_accuracy: 0.8079\n",
      "Epoch 156/1000\n",
      "225/225 [==============================] - 0s 2ms/step - loss: 0.5371 - accuracy: 0.7880 - val_loss: 0.4870 - val_accuracy: 0.8070\n",
      "Epoch 157/1000\n",
      "225/225 [==============================] - 0s 2ms/step - loss: 0.5383 - accuracy: 0.7883 - val_loss: 0.4852 - val_accuracy: 0.8093\n",
      "Epoch 158/1000\n",
      "225/225 [==============================] - 0s 2ms/step - loss: 0.5340 - accuracy: 0.7898 - val_loss: 0.4860 - val_accuracy: 0.8079\n",
      "Epoch 159/1000\n",
      "225/225 [==============================] - 0s 2ms/step - loss: 0.5369 - accuracy: 0.7886 - val_loss: 0.4858 - val_accuracy: 0.8084\n",
      "Epoch 160/1000\n",
      "225/225 [==============================] - 0s 2ms/step - loss: 0.5360 - accuracy: 0.7874 - val_loss: 0.4847 - val_accuracy: 0.8081\n",
      "Epoch 161/1000\n",
      "225/225 [==============================] - 0s 2ms/step - loss: 0.5367 - accuracy: 0.7890 - val_loss: 0.4840 - val_accuracy: 0.8086\n",
      "Epoch 162/1000\n",
      "225/225 [==============================] - 0s 2ms/step - loss: 0.5355 - accuracy: 0.7889 - val_loss: 0.4837 - val_accuracy: 0.8083\n",
      "Epoch 163/1000\n",
      "225/225 [==============================] - 0s 2ms/step - loss: 0.5370 - accuracy: 0.7897 - val_loss: 0.4828 - val_accuracy: 0.8089\n",
      "Epoch 164/1000\n",
      "225/225 [==============================] - 0s 2ms/step - loss: 0.5368 - accuracy: 0.7892 - val_loss: 0.4835 - val_accuracy: 0.8108\n",
      "Epoch 165/1000\n",
      "225/225 [==============================] - 0s 2ms/step - loss: 0.5364 - accuracy: 0.7891 - val_loss: 0.4817 - val_accuracy: 0.8105\n",
      "Epoch 166/1000\n",
      "225/225 [==============================] - 0s 2ms/step - loss: 0.5342 - accuracy: 0.7889 - val_loss: 0.4837 - val_accuracy: 0.8093\n",
      "Epoch 167/1000\n",
      "225/225 [==============================] - 0s 2ms/step - loss: 0.5338 - accuracy: 0.7905 - val_loss: 0.4814 - val_accuracy: 0.8119\n",
      "Epoch 168/1000\n",
      "225/225 [==============================] - 0s 2ms/step - loss: 0.5361 - accuracy: 0.7893 - val_loss: 0.4837 - val_accuracy: 0.8096\n",
      "Epoch 169/1000\n",
      "225/225 [==============================] - 0s 2ms/step - loss: 0.5343 - accuracy: 0.7907 - val_loss: 0.4833 - val_accuracy: 0.8094\n",
      "Epoch 170/1000\n",
      "225/225 [==============================] - 0s 2ms/step - loss: 0.5348 - accuracy: 0.7887 - val_loss: 0.4853 - val_accuracy: 0.8090\n",
      "Epoch 171/1000\n",
      "225/225 [==============================] - 0s 2ms/step - loss: 0.5344 - accuracy: 0.7897 - val_loss: 0.4835 - val_accuracy: 0.8086\n",
      "Epoch 172/1000\n",
      "225/225 [==============================] - 0s 2ms/step - loss: 0.5336 - accuracy: 0.7899 - val_loss: 0.4801 - val_accuracy: 0.8090\n",
      "Epoch 173/1000\n",
      "225/225 [==============================] - 0s 2ms/step - loss: 0.5347 - accuracy: 0.7896 - val_loss: 0.4784 - val_accuracy: 0.8116\n",
      "Epoch 174/1000\n",
      "225/225 [==============================] - 1s 2ms/step - loss: 0.5341 - accuracy: 0.7901 - val_loss: 0.4803 - val_accuracy: 0.8123\n",
      "Epoch 175/1000\n",
      "225/225 [==============================] - 0s 2ms/step - loss: 0.5352 - accuracy: 0.7895 - val_loss: 0.4839 - val_accuracy: 0.8085\n",
      "Epoch 176/1000\n",
      "225/225 [==============================] - 0s 2ms/step - loss: 0.5345 - accuracy: 0.7893 - val_loss: 0.4805 - val_accuracy: 0.8101\n",
      "Epoch 177/1000\n",
      "225/225 [==============================] - 0s 2ms/step - loss: 0.5336 - accuracy: 0.7894 - val_loss: 0.4793 - val_accuracy: 0.8131\n",
      "Epoch 178/1000\n",
      "225/225 [==============================] - 0s 2ms/step - loss: 0.5331 - accuracy: 0.7900 - val_loss: 0.4801 - val_accuracy: 0.8128\n",
      "Epoch 179/1000\n",
      "225/225 [==============================] - 0s 2ms/step - loss: 0.5342 - accuracy: 0.7898 - val_loss: 0.4819 - val_accuracy: 0.8114\n",
      "Epoch 180/1000\n",
      "225/225 [==============================] - 0s 2ms/step - loss: 0.5324 - accuracy: 0.7897 - val_loss: 0.4794 - val_accuracy: 0.8129\n",
      "Epoch 181/1000\n",
      "225/225 [==============================] - 0s 2ms/step - loss: 0.5324 - accuracy: 0.7907 - val_loss: 0.4789 - val_accuracy: 0.8126\n",
      "Epoch 182/1000\n",
      "225/225 [==============================] - 0s 2ms/step - loss: 0.5337 - accuracy: 0.7903 - val_loss: 0.4787 - val_accuracy: 0.8124\n",
      "Epoch 183/1000\n",
      "225/225 [==============================] - 0s 2ms/step - loss: 0.5305 - accuracy: 0.7917 - val_loss: 0.4818 - val_accuracy: 0.8124\n",
      "Epoch 184/1000\n",
      "225/225 [==============================] - 0s 2ms/step - loss: 0.5330 - accuracy: 0.7900 - val_loss: 0.4801 - val_accuracy: 0.8136\n",
      "Epoch 185/1000\n",
      "225/225 [==============================] - 0s 2ms/step - loss: 0.5317 - accuracy: 0.7903 - val_loss: 0.4799 - val_accuracy: 0.8134\n",
      "Epoch 186/1000\n",
      "225/225 [==============================] - 0s 2ms/step - loss: 0.5340 - accuracy: 0.7910 - val_loss: 0.4781 - val_accuracy: 0.8126\n",
      "Epoch 187/1000\n",
      "225/225 [==============================] - 0s 2ms/step - loss: 0.5324 - accuracy: 0.7904 - val_loss: 0.4817 - val_accuracy: 0.8118\n",
      "Epoch 188/1000\n",
      "225/225 [==============================] - 0s 2ms/step - loss: 0.5333 - accuracy: 0.7904 - val_loss: 0.4813 - val_accuracy: 0.8120\n",
      "Epoch 189/1000\n",
      "225/225 [==============================] - 0s 2ms/step - loss: 0.5310 - accuracy: 0.7913 - val_loss: 0.4797 - val_accuracy: 0.8142\n",
      "Epoch 190/1000\n",
      "225/225 [==============================] - 0s 2ms/step - loss: 0.5318 - accuracy: 0.7915 - val_loss: 0.4802 - val_accuracy: 0.8108\n",
      "Epoch 191/1000\n",
      "225/225 [==============================] - 0s 2ms/step - loss: 0.5304 - accuracy: 0.7915 - val_loss: 0.4795 - val_accuracy: 0.8131\n",
      "Epoch 192/1000\n",
      "225/225 [==============================] - 0s 2ms/step - loss: 0.5297 - accuracy: 0.7924 - val_loss: 0.4770 - val_accuracy: 0.8123\n",
      "Epoch 193/1000\n",
      "225/225 [==============================] - 0s 2ms/step - loss: 0.5317 - accuracy: 0.7905 - val_loss: 0.4803 - val_accuracy: 0.8129\n",
      "Epoch 194/1000\n",
      "225/225 [==============================] - 0s 2ms/step - loss: 0.5301 - accuracy: 0.7925 - val_loss: 0.4787 - val_accuracy: 0.8123\n",
      "Epoch 195/1000\n",
      "225/225 [==============================] - 0s 2ms/step - loss: 0.5302 - accuracy: 0.7921 - val_loss: 0.4804 - val_accuracy: 0.8124\n",
      "Epoch 196/1000\n",
      "225/225 [==============================] - 0s 2ms/step - loss: 0.5302 - accuracy: 0.7925 - val_loss: 0.4780 - val_accuracy: 0.8123\n",
      "Epoch 197/1000\n",
      "225/225 [==============================] - 0s 2ms/step - loss: 0.5323 - accuracy: 0.7911 - val_loss: 0.4800 - val_accuracy: 0.8122\n",
      "Epoch 198/1000\n",
      "225/225 [==============================] - 0s 2ms/step - loss: 0.5329 - accuracy: 0.7918 - val_loss: 0.4776 - val_accuracy: 0.8138\n",
      "Epoch 199/1000\n",
      "225/225 [==============================] - 0s 2ms/step - loss: 0.5304 - accuracy: 0.7908 - val_loss: 0.4800 - val_accuracy: 0.8115\n",
      "Epoch 200/1000\n",
      "225/225 [==============================] - 0s 2ms/step - loss: 0.5304 - accuracy: 0.7914 - val_loss: 0.4764 - val_accuracy: 0.8116\n",
      "Epoch 201/1000\n",
      "225/225 [==============================] - 0s 2ms/step - loss: 0.5313 - accuracy: 0.7906 - val_loss: 0.4752 - val_accuracy: 0.8152\n",
      "Epoch 202/1000\n",
      "225/225 [==============================] - 0s 2ms/step - loss: 0.5290 - accuracy: 0.7921 - val_loss: 0.4763 - val_accuracy: 0.8135\n",
      "Epoch 203/1000\n",
      "225/225 [==============================] - 0s 2ms/step - loss: 0.5312 - accuracy: 0.7916 - val_loss: 0.4788 - val_accuracy: 0.8121\n",
      "Epoch 204/1000\n",
      "225/225 [==============================] - 0s 2ms/step - loss: 0.5308 - accuracy: 0.7920 - val_loss: 0.4744 - val_accuracy: 0.8148\n",
      "Epoch 205/1000\n",
      "225/225 [==============================] - 0s 2ms/step - loss: 0.5299 - accuracy: 0.7910 - val_loss: 0.4771 - val_accuracy: 0.8151\n",
      "Epoch 206/1000\n",
      "225/225 [==============================] - 1s 2ms/step - loss: 0.5311 - accuracy: 0.7902 - val_loss: 0.4784 - val_accuracy: 0.8131\n",
      "Epoch 207/1000\n",
      "225/225 [==============================] - 1s 2ms/step - loss: 0.5296 - accuracy: 0.7917 - val_loss: 0.4763 - val_accuracy: 0.8113\n",
      "Epoch 208/1000\n",
      "225/225 [==============================] - 0s 2ms/step - loss: 0.5276 - accuracy: 0.7934 - val_loss: 0.4742 - val_accuracy: 0.8130\n",
      "Epoch 209/1000\n",
      "225/225 [==============================] - 0s 2ms/step - loss: 0.5286 - accuracy: 0.7924 - val_loss: 0.4786 - val_accuracy: 0.8125\n",
      "Epoch 210/1000\n",
      "225/225 [==============================] - 0s 2ms/step - loss: 0.5301 - accuracy: 0.7913 - val_loss: 0.4795 - val_accuracy: 0.8126\n",
      "Epoch 211/1000\n",
      "225/225 [==============================] - 0s 2ms/step - loss: 0.5299 - accuracy: 0.7917 - val_loss: 0.4751 - val_accuracy: 0.8141\n",
      "Epoch 212/1000\n",
      "225/225 [==============================] - 1s 2ms/step - loss: 0.5282 - accuracy: 0.7919 - val_loss: 0.4765 - val_accuracy: 0.8146\n",
      "Epoch 213/1000\n",
      "225/225 [==============================] - 0s 2ms/step - loss: 0.5295 - accuracy: 0.7921 - val_loss: 0.4757 - val_accuracy: 0.8144\n",
      "Epoch 214/1000\n",
      "225/225 [==============================] - 0s 2ms/step - loss: 0.5298 - accuracy: 0.7920 - val_loss: 0.4749 - val_accuracy: 0.8136\n",
      "Epoch 215/1000\n",
      "225/225 [==============================] - 0s 2ms/step - loss: 0.5279 - accuracy: 0.7923 - val_loss: 0.4741 - val_accuracy: 0.8140\n",
      "Epoch 216/1000\n",
      "225/225 [==============================] - 0s 2ms/step - loss: 0.5296 - accuracy: 0.7921 - val_loss: 0.4738 - val_accuracy: 0.8155\n",
      "Epoch 217/1000\n",
      "225/225 [==============================] - 0s 2ms/step - loss: 0.5278 - accuracy: 0.7924 - val_loss: 0.4756 - val_accuracy: 0.8146\n",
      "Epoch 218/1000\n",
      "225/225 [==============================] - 0s 2ms/step - loss: 0.5280 - accuracy: 0.7910 - val_loss: 0.4727 - val_accuracy: 0.8169\n",
      "Epoch 219/1000\n",
      "225/225 [==============================] - 0s 2ms/step - loss: 0.5268 - accuracy: 0.7921 - val_loss: 0.4735 - val_accuracy: 0.8142\n",
      "Epoch 220/1000\n",
      "225/225 [==============================] - 0s 2ms/step - loss: 0.5268 - accuracy: 0.7935 - val_loss: 0.4727 - val_accuracy: 0.8147\n",
      "Epoch 221/1000\n",
      "225/225 [==============================] - 0s 2ms/step - loss: 0.5282 - accuracy: 0.7918 - val_loss: 0.4759 - val_accuracy: 0.8141\n",
      "Epoch 222/1000\n",
      "225/225 [==============================] - 0s 2ms/step - loss: 0.5276 - accuracy: 0.7926 - val_loss: 0.4793 - val_accuracy: 0.8141\n",
      "Epoch 223/1000\n",
      "225/225 [==============================] - 0s 2ms/step - loss: 0.5275 - accuracy: 0.7939 - val_loss: 0.4746 - val_accuracy: 0.8172\n",
      "Epoch 224/1000\n",
      "225/225 [==============================] - 0s 2ms/step - loss: 0.5304 - accuracy: 0.7915 - val_loss: 0.4752 - val_accuracy: 0.8152\n",
      "Epoch 225/1000\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "225/225 [==============================] - 0s 2ms/step - loss: 0.5275 - accuracy: 0.7929 - val_loss: 0.4748 - val_accuracy: 0.8163\n",
      "Epoch 226/1000\n",
      "225/225 [==============================] - 0s 2ms/step - loss: 0.5277 - accuracy: 0.7932 - val_loss: 0.4745 - val_accuracy: 0.8140\n",
      "Epoch 227/1000\n",
      "225/225 [==============================] - 0s 2ms/step - loss: 0.5274 - accuracy: 0.7927 - val_loss: 0.4737 - val_accuracy: 0.8159\n",
      "Epoch 228/1000\n",
      "225/225 [==============================] - 0s 2ms/step - loss: 0.5253 - accuracy: 0.7936 - val_loss: 0.4704 - val_accuracy: 0.8188\n",
      "Epoch 229/1000\n",
      "225/225 [==============================] - 0s 2ms/step - loss: 0.5258 - accuracy: 0.7927 - val_loss: 0.4744 - val_accuracy: 0.8144\n",
      "Epoch 230/1000\n",
      "225/225 [==============================] - 0s 2ms/step - loss: 0.5268 - accuracy: 0.7934 - val_loss: 0.4741 - val_accuracy: 0.8151\n",
      "Epoch 231/1000\n",
      "225/225 [==============================] - 0s 2ms/step - loss: 0.5272 - accuracy: 0.7927 - val_loss: 0.4735 - val_accuracy: 0.8144\n",
      "Epoch 232/1000\n",
      "225/225 [==============================] - 0s 2ms/step - loss: 0.5262 - accuracy: 0.7933 - val_loss: 0.4730 - val_accuracy: 0.8140\n",
      "Epoch 233/1000\n",
      "225/225 [==============================] - 0s 2ms/step - loss: 0.5243 - accuracy: 0.7937 - val_loss: 0.4722 - val_accuracy: 0.8143\n",
      "Epoch 234/1000\n",
      "225/225 [==============================] - 0s 2ms/step - loss: 0.5268 - accuracy: 0.7936 - val_loss: 0.4764 - val_accuracy: 0.8135\n",
      "Epoch 235/1000\n",
      "225/225 [==============================] - 0s 2ms/step - loss: 0.5281 - accuracy: 0.7925 - val_loss: 0.4753 - val_accuracy: 0.8171\n",
      "Epoch 236/1000\n",
      "225/225 [==============================] - 0s 2ms/step - loss: 0.5262 - accuracy: 0.7934 - val_loss: 0.4704 - val_accuracy: 0.8151\n",
      "Epoch 237/1000\n",
      "225/225 [==============================] - 0s 2ms/step - loss: 0.5255 - accuracy: 0.7935 - val_loss: 0.4748 - val_accuracy: 0.8156\n",
      "Epoch 238/1000\n",
      "225/225 [==============================] - 0s 2ms/step - loss: 0.5263 - accuracy: 0.7914 - val_loss: 0.4754 - val_accuracy: 0.8134\n",
      "Epoch 239/1000\n",
      "225/225 [==============================] - 1s 2ms/step - loss: 0.5273 - accuracy: 0.7926 - val_loss: 0.4736 - val_accuracy: 0.8140\n",
      "Epoch 240/1000\n",
      "225/225 [==============================] - 0s 2ms/step - loss: 0.5265 - accuracy: 0.7939 - val_loss: 0.4721 - val_accuracy: 0.8170\n",
      "Epoch 241/1000\n",
      "225/225 [==============================] - 0s 2ms/step - loss: 0.5260 - accuracy: 0.7933 - val_loss: 0.4742 - val_accuracy: 0.8148\n",
      "Epoch 242/1000\n",
      "225/225 [==============================] - 0s 2ms/step - loss: 0.5253 - accuracy: 0.7928 - val_loss: 0.4721 - val_accuracy: 0.8155\n",
      "Epoch 243/1000\n",
      "225/225 [==============================] - 0s 2ms/step - loss: 0.5250 - accuracy: 0.7935 - val_loss: 0.4712 - val_accuracy: 0.8159\n",
      "Epoch 244/1000\n",
      "225/225 [==============================] - 0s 2ms/step - loss: 0.5264 - accuracy: 0.7929 - val_loss: 0.4708 - val_accuracy: 0.8167\n",
      "Epoch 245/1000\n",
      "225/225 [==============================] - 0s 2ms/step - loss: 0.5280 - accuracy: 0.7929 - val_loss: 0.4726 - val_accuracy: 0.8160\n",
      "Epoch 246/1000\n",
      "225/225 [==============================] - 0s 2ms/step - loss: 0.5249 - accuracy: 0.7947 - val_loss: 0.4708 - val_accuracy: 0.8151\n",
      "Epoch 247/1000\n",
      "225/225 [==============================] - 1s 2ms/step - loss: 0.5258 - accuracy: 0.7943 - val_loss: 0.4704 - val_accuracy: 0.8166\n",
      "Epoch 248/1000\n",
      "225/225 [==============================] - 0s 2ms/step - loss: 0.5258 - accuracy: 0.7933 - val_loss: 0.4709 - val_accuracy: 0.8162\n",
      "Epoch 249/1000\n",
      "225/225 [==============================] - 1s 2ms/step - loss: 0.5262 - accuracy: 0.7940 - val_loss: 0.4719 - val_accuracy: 0.8162\n",
      "Epoch 250/1000\n",
      "225/225 [==============================] - 1s 2ms/step - loss: 0.5266 - accuracy: 0.7939 - val_loss: 0.4721 - val_accuracy: 0.8178\n",
      "Epoch 251/1000\n",
      "225/225 [==============================] - 1s 2ms/step - loss: 0.5263 - accuracy: 0.7932 - val_loss: 0.4731 - val_accuracy: 0.8162\n",
      "Epoch 252/1000\n",
      "225/225 [==============================] - 0s 2ms/step - loss: 0.5243 - accuracy: 0.7944 - val_loss: 0.4748 - val_accuracy: 0.8155\n",
      "Epoch 253/1000\n",
      "225/225 [==============================] - 1s 2ms/step - loss: 0.5240 - accuracy: 0.7944 - val_loss: 0.4729 - val_accuracy: 0.8164\n",
      "Epoch 254/1000\n",
      "225/225 [==============================] - 1s 2ms/step - loss: 0.5241 - accuracy: 0.7939 - val_loss: 0.4701 - val_accuracy: 0.8178\n",
      "Epoch 255/1000\n",
      "225/225 [==============================] - 1s 2ms/step - loss: 0.5244 - accuracy: 0.7935 - val_loss: 0.4695 - val_accuracy: 0.8172\n",
      "Epoch 256/1000\n",
      "225/225 [==============================] - 1s 2ms/step - loss: 0.5245 - accuracy: 0.7936 - val_loss: 0.4722 - val_accuracy: 0.8155\n",
      "Epoch 257/1000\n",
      "225/225 [==============================] - 1s 2ms/step - loss: 0.5240 - accuracy: 0.7935 - val_loss: 0.4715 - val_accuracy: 0.8166\n",
      "Epoch 258/1000\n",
      "225/225 [==============================] - 1s 2ms/step - loss: 0.5269 - accuracy: 0.7931 - val_loss: 0.4732 - val_accuracy: 0.8146\n",
      "Epoch 259/1000\n",
      "225/225 [==============================] - 1s 2ms/step - loss: 0.5257 - accuracy: 0.7922 - val_loss: 0.4687 - val_accuracy: 0.8167\n",
      "Epoch 260/1000\n",
      "225/225 [==============================] - 0s 2ms/step - loss: 0.5256 - accuracy: 0.7920 - val_loss: 0.4713 - val_accuracy: 0.8148\n",
      "Epoch 261/1000\n",
      "225/225 [==============================] - 1s 3ms/step - loss: 0.5253 - accuracy: 0.7937 - val_loss: 0.4727 - val_accuracy: 0.8175\n",
      "Epoch 262/1000\n",
      "225/225 [==============================] - 1s 2ms/step - loss: 0.5251 - accuracy: 0.7934 - val_loss: 0.4723 - val_accuracy: 0.8164\n",
      "Epoch 263/1000\n",
      "225/225 [==============================] - 1s 2ms/step - loss: 0.5250 - accuracy: 0.7933 - val_loss: 0.4771 - val_accuracy: 0.8146\n",
      "Epoch 264/1000\n",
      "225/225 [==============================] - 0s 2ms/step - loss: 0.5245 - accuracy: 0.7942 - val_loss: 0.4713 - val_accuracy: 0.8166\n",
      "Epoch 265/1000\n",
      "225/225 [==============================] - 1s 2ms/step - loss: 0.5226 - accuracy: 0.7949 - val_loss: 0.4704 - val_accuracy: 0.8173\n",
      "Epoch 266/1000\n",
      "225/225 [==============================] - 1s 2ms/step - loss: 0.5226 - accuracy: 0.7939 - val_loss: 0.4695 - val_accuracy: 0.8166\n",
      "Epoch 267/1000\n",
      "225/225 [==============================] - 1s 2ms/step - loss: 0.5239 - accuracy: 0.7946 - val_loss: 0.4705 - val_accuracy: 0.8170\n",
      "Epoch 268/1000\n",
      "225/225 [==============================] - 1s 2ms/step - loss: 0.5209 - accuracy: 0.7953 - val_loss: 0.4689 - val_accuracy: 0.8177\n",
      "Epoch 269/1000\n",
      "225/225 [==============================] - 1s 2ms/step - loss: 0.5242 - accuracy: 0.7946 - val_loss: 0.4685 - val_accuracy: 0.8171\n",
      "Epoch 270/1000\n",
      "225/225 [==============================] - 1s 2ms/step - loss: 0.5253 - accuracy: 0.7937 - val_loss: 0.4703 - val_accuracy: 0.8176\n",
      "Epoch 271/1000\n",
      "225/225 [==============================] - 1s 2ms/step - loss: 0.5242 - accuracy: 0.7942 - val_loss: 0.4692 - val_accuracy: 0.8167\n",
      "Epoch 272/1000\n",
      "225/225 [==============================] - 1s 2ms/step - loss: 0.5228 - accuracy: 0.7941 - val_loss: 0.4684 - val_accuracy: 0.8188\n",
      "Epoch 273/1000\n",
      "225/225 [==============================] - 0s 2ms/step - loss: 0.5214 - accuracy: 0.7956 - val_loss: 0.4671 - val_accuracy: 0.8192\n",
      "Epoch 274/1000\n",
      "225/225 [==============================] - 0s 2ms/step - loss: 0.5246 - accuracy: 0.7934 - val_loss: 0.4675 - val_accuracy: 0.8175\n",
      "Epoch 275/1000\n",
      "225/225 [==============================] - 0s 2ms/step - loss: 0.5224 - accuracy: 0.7956 - val_loss: 0.4722 - val_accuracy: 0.8159\n",
      "Epoch 276/1000\n",
      "225/225 [==============================] - 0s 2ms/step - loss: 0.5218 - accuracy: 0.7948 - val_loss: 0.4673 - val_accuracy: 0.8163\n",
      "Epoch 277/1000\n",
      "225/225 [==============================] - 0s 2ms/step - loss: 0.5238 - accuracy: 0.7940 - val_loss: 0.4704 - val_accuracy: 0.8167\n",
      "Epoch 278/1000\n",
      "225/225 [==============================] - 1s 2ms/step - loss: 0.5241 - accuracy: 0.7941 - val_loss: 0.4693 - val_accuracy: 0.8185\n",
      "Epoch 279/1000\n",
      "225/225 [==============================] - 1s 2ms/step - loss: 0.5227 - accuracy: 0.7944 - val_loss: 0.4697 - val_accuracy: 0.8170\n",
      "Epoch 280/1000\n",
      "225/225 [==============================] - 0s 2ms/step - loss: 0.5226 - accuracy: 0.7952 - val_loss: 0.4680 - val_accuracy: 0.8179\n",
      "Epoch 281/1000\n",
      "225/225 [==============================] - 0s 2ms/step - loss: 0.5247 - accuracy: 0.7937 - val_loss: 0.4687 - val_accuracy: 0.8161\n",
      "Epoch 282/1000\n",
      "225/225 [==============================] - 0s 2ms/step - loss: 0.5246 - accuracy: 0.7938 - val_loss: 0.4655 - val_accuracy: 0.8183\n",
      "Epoch 283/1000\n",
      "225/225 [==============================] - 0s 2ms/step - loss: 0.5218 - accuracy: 0.7961 - val_loss: 0.4693 - val_accuracy: 0.8197\n",
      "Epoch 284/1000\n",
      "225/225 [==============================] - 0s 2ms/step - loss: 0.5237 - accuracy: 0.7942 - val_loss: 0.4687 - val_accuracy: 0.8183\n",
      "Epoch 285/1000\n",
      "225/225 [==============================] - 0s 2ms/step - loss: 0.5223 - accuracy: 0.7954 - val_loss: 0.4702 - val_accuracy: 0.8184\n",
      "Epoch 286/1000\n",
      "225/225 [==============================] - 0s 2ms/step - loss: 0.5212 - accuracy: 0.7950 - val_loss: 0.4685 - val_accuracy: 0.8173\n",
      "Epoch 287/1000\n",
      "225/225 [==============================] - 1s 2ms/step - loss: 0.5224 - accuracy: 0.7952 - val_loss: 0.4670 - val_accuracy: 0.8195\n",
      "Epoch 288/1000\n",
      "225/225 [==============================] - 1s 2ms/step - loss: 0.5217 - accuracy: 0.7941 - val_loss: 0.4678 - val_accuracy: 0.8173\n",
      "Epoch 289/1000\n",
      "225/225 [==============================] - 0s 2ms/step - loss: 0.5219 - accuracy: 0.7940 - val_loss: 0.4675 - val_accuracy: 0.8178\n",
      "Epoch 290/1000\n",
      "225/225 [==============================] - 0s 2ms/step - loss: 0.5198 - accuracy: 0.7954 - val_loss: 0.4663 - val_accuracy: 0.8189\n",
      "Epoch 291/1000\n",
      "225/225 [==============================] - 0s 2ms/step - loss: 0.5233 - accuracy: 0.7947 - val_loss: 0.4698 - val_accuracy: 0.8174\n",
      "Epoch 292/1000\n",
      "225/225 [==============================] - 0s 2ms/step - loss: 0.5228 - accuracy: 0.7943 - val_loss: 0.4696 - val_accuracy: 0.8168\n",
      "Epoch 293/1000\n",
      "225/225 [==============================] - 0s 2ms/step - loss: 0.5217 - accuracy: 0.7953 - val_loss: 0.4692 - val_accuracy: 0.8184\n",
      "Epoch 294/1000\n",
      "225/225 [==============================] - 0s 2ms/step - loss: 0.5205 - accuracy: 0.7947 - val_loss: 0.4670 - val_accuracy: 0.8191\n",
      "Epoch 295/1000\n",
      "225/225 [==============================] - 0s 2ms/step - loss: 0.5209 - accuracy: 0.7950 - val_loss: 0.4669 - val_accuracy: 0.8183\n",
      "Epoch 296/1000\n",
      "225/225 [==============================] - 0s 2ms/step - loss: 0.5202 - accuracy: 0.7949 - val_loss: 0.4664 - val_accuracy: 0.8191\n",
      "Epoch 297/1000\n",
      "225/225 [==============================] - 0s 2ms/step - loss: 0.5214 - accuracy: 0.7963 - val_loss: 0.4648 - val_accuracy: 0.8196\n",
      "Epoch 298/1000\n",
      "225/225 [==============================] - 0s 2ms/step - loss: 0.5203 - accuracy: 0.7950 - val_loss: 0.4652 - val_accuracy: 0.8198\n",
      "Epoch 299/1000\n",
      "225/225 [==============================] - 0s 2ms/step - loss: 0.5205 - accuracy: 0.7961 - val_loss: 0.4672 - val_accuracy: 0.8188\n",
      "Epoch 300/1000\n",
      "225/225 [==============================] - 0s 2ms/step - loss: 0.5199 - accuracy: 0.7960 - val_loss: 0.4663 - val_accuracy: 0.8169\n",
      "Epoch 301/1000\n",
      "225/225 [==============================] - 0s 2ms/step - loss: 0.5187 - accuracy: 0.7962 - val_loss: 0.4661 - val_accuracy: 0.8196\n",
      "Epoch 302/1000\n",
      "225/225 [==============================] - 0s 2ms/step - loss: 0.5192 - accuracy: 0.7962 - val_loss: 0.4687 - val_accuracy: 0.8182\n",
      "Epoch 303/1000\n",
      "225/225 [==============================] - 1s 2ms/step - loss: 0.5230 - accuracy: 0.7948 - val_loss: 0.4690 - val_accuracy: 0.8170\n",
      "Epoch 304/1000\n",
      "225/225 [==============================] - 0s 2ms/step - loss: 0.5220 - accuracy: 0.7957 - val_loss: 0.4692 - val_accuracy: 0.8186\n",
      "Epoch 305/1000\n",
      "225/225 [==============================] - 0s 2ms/step - loss: 0.5202 - accuracy: 0.7957 - val_loss: 0.4684 - val_accuracy: 0.8191\n",
      "Epoch 306/1000\n",
      "225/225 [==============================] - 0s 2ms/step - loss: 0.5200 - accuracy: 0.7966 - val_loss: 0.4688 - val_accuracy: 0.8184\n",
      "Epoch 307/1000\n",
      "225/225 [==============================] - 1s 2ms/step - loss: 0.5207 - accuracy: 0.7949 - val_loss: 0.4692 - val_accuracy: 0.8178\n",
      "Epoch 308/1000\n",
      "225/225 [==============================] - 0s 2ms/step - loss: 0.5179 - accuracy: 0.7969 - val_loss: 0.4664 - val_accuracy: 0.8180\n",
      "Epoch 309/1000\n",
      "225/225 [==============================] - 0s 2ms/step - loss: 0.5204 - accuracy: 0.7957 - val_loss: 0.4676 - val_accuracy: 0.8204\n",
      "Epoch 310/1000\n",
      "225/225 [==============================] - 0s 2ms/step - loss: 0.5206 - accuracy: 0.7957 - val_loss: 0.4653 - val_accuracy: 0.8213\n",
      "Epoch 311/1000\n",
      "225/225 [==============================] - 0s 2ms/step - loss: 0.5205 - accuracy: 0.7965 - val_loss: 0.4640 - val_accuracy: 0.8199\n",
      "Epoch 312/1000\n",
      "225/225 [==============================] - 0s 2ms/step - loss: 0.5199 - accuracy: 0.7953 - val_loss: 0.4644 - val_accuracy: 0.8202\n",
      "Epoch 313/1000\n",
      "225/225 [==============================] - 0s 2ms/step - loss: 0.5205 - accuracy: 0.7957 - val_loss: 0.4704 - val_accuracy: 0.8177\n",
      "Epoch 314/1000\n",
      "225/225 [==============================] - 0s 2ms/step - loss: 0.5192 - accuracy: 0.7966 - val_loss: 0.4679 - val_accuracy: 0.8198\n",
      "Epoch 315/1000\n",
      "225/225 [==============================] - 1s 2ms/step - loss: 0.5184 - accuracy: 0.7967 - val_loss: 0.4666 - val_accuracy: 0.8180\n",
      "Epoch 316/1000\n",
      "225/225 [==============================] - 1s 2ms/step - loss: 0.5216 - accuracy: 0.7956 - val_loss: 0.4686 - val_accuracy: 0.8184\n",
      "Epoch 317/1000\n",
      "225/225 [==============================] - 1s 2ms/step - loss: 0.5209 - accuracy: 0.7946 - val_loss: 0.4689 - val_accuracy: 0.8204\n",
      "Epoch 318/1000\n",
      "225/225 [==============================] - 0s 2ms/step - loss: 0.5216 - accuracy: 0.7954 - val_loss: 0.4643 - val_accuracy: 0.8214\n",
      "Epoch 319/1000\n",
      "225/225 [==============================] - 0s 2ms/step - loss: 0.5192 - accuracy: 0.7968 - val_loss: 0.4653 - val_accuracy: 0.8220\n",
      "Epoch 320/1000\n",
      "225/225 [==============================] - 0s 2ms/step - loss: 0.5192 - accuracy: 0.7964 - val_loss: 0.4675 - val_accuracy: 0.8191\n",
      "Epoch 321/1000\n",
      "225/225 [==============================] - 0s 2ms/step - loss: 0.5193 - accuracy: 0.7957 - val_loss: 0.4654 - val_accuracy: 0.8199\n",
      "Epoch 322/1000\n",
      "225/225 [==============================] - 0s 2ms/step - loss: 0.5193 - accuracy: 0.7970 - val_loss: 0.4636 - val_accuracy: 0.8213\n",
      "Epoch 323/1000\n",
      "225/225 [==============================] - 0s 2ms/step - loss: 0.5227 - accuracy: 0.7943 - val_loss: 0.4670 - val_accuracy: 0.8189\n",
      "Epoch 324/1000\n",
      "225/225 [==============================] - 0s 2ms/step - loss: 0.5169 - accuracy: 0.7965 - val_loss: 0.4639 - val_accuracy: 0.8209\n",
      "Epoch 325/1000\n",
      "225/225 [==============================] - 0s 2ms/step - loss: 0.5199 - accuracy: 0.7955 - val_loss: 0.4663 - val_accuracy: 0.8195\n",
      "Epoch 326/1000\n",
      "225/225 [==============================] - 0s 2ms/step - loss: 0.5203 - accuracy: 0.7975 - val_loss: 0.4648 - val_accuracy: 0.8206\n",
      "Epoch 327/1000\n",
      "225/225 [==============================] - 0s 2ms/step - loss: 0.5187 - accuracy: 0.7959 - val_loss: 0.4646 - val_accuracy: 0.8195\n",
      "Epoch 328/1000\n",
      "225/225 [==============================] - 0s 2ms/step - loss: 0.5186 - accuracy: 0.7965 - val_loss: 0.4659 - val_accuracy: 0.8191\n",
      "Epoch 329/1000\n",
      "225/225 [==============================] - 0s 2ms/step - loss: 0.5187 - accuracy: 0.7949 - val_loss: 0.4658 - val_accuracy: 0.8192\n",
      "Epoch 330/1000\n",
      "225/225 [==============================] - 1s 2ms/step - loss: 0.5191 - accuracy: 0.7974 - val_loss: 0.4685 - val_accuracy: 0.8177\n",
      "Epoch 331/1000\n",
      "225/225 [==============================] - 0s 2ms/step - loss: 0.5211 - accuracy: 0.7955 - val_loss: 0.4654 - val_accuracy: 0.8166\n",
      "Epoch 332/1000\n",
      "225/225 [==============================] - 0s 2ms/step - loss: 0.5175 - accuracy: 0.7974 - val_loss: 0.4673 - val_accuracy: 0.8175\n",
      "Epoch 333/1000\n",
      "225/225 [==============================] - 0s 2ms/step - loss: 0.5182 - accuracy: 0.7966 - val_loss: 0.4658 - val_accuracy: 0.8209\n",
      "Epoch 334/1000\n",
      "225/225 [==============================] - 1s 2ms/step - loss: 0.5186 - accuracy: 0.7963 - val_loss: 0.4674 - val_accuracy: 0.8197\n",
      "Epoch 335/1000\n",
      "225/225 [==============================] - 1s 2ms/step - loss: 0.5180 - accuracy: 0.7958 - val_loss: 0.4654 - val_accuracy: 0.8201\n",
      "Epoch 336/1000\n",
      "225/225 [==============================] - 1s 2ms/step - loss: 0.5194 - accuracy: 0.7965 - val_loss: 0.4649 - val_accuracy: 0.8224\n",
      "Epoch 337/1000\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "225/225 [==============================] - 0s 2ms/step - loss: 0.5218 - accuracy: 0.7945 - val_loss: 0.4649 - val_accuracy: 0.8212\n",
      "Epoch 338/1000\n",
      "225/225 [==============================] - 0s 2ms/step - loss: 0.5189 - accuracy: 0.7965 - val_loss: 0.4637 - val_accuracy: 0.8216\n",
      "Epoch 339/1000\n",
      "225/225 [==============================] - 0s 2ms/step - loss: 0.5192 - accuracy: 0.7960 - val_loss: 0.4657 - val_accuracy: 0.8172\n",
      "Epoch 340/1000\n",
      "225/225 [==============================] - 0s 2ms/step - loss: 0.5161 - accuracy: 0.7983 - val_loss: 0.4632 - val_accuracy: 0.8220\n",
      "Epoch 341/1000\n",
      "225/225 [==============================] - 0s 2ms/step - loss: 0.5180 - accuracy: 0.7967 - val_loss: 0.4661 - val_accuracy: 0.8193\n",
      "Epoch 342/1000\n",
      "225/225 [==============================] - 0s 2ms/step - loss: 0.5187 - accuracy: 0.7963 - val_loss: 0.4623 - val_accuracy: 0.8211\n",
      "Epoch 343/1000\n",
      "225/225 [==============================] - 0s 2ms/step - loss: 0.5163 - accuracy: 0.7973 - val_loss: 0.4649 - val_accuracy: 0.8198\n",
      "Epoch 344/1000\n",
      "225/225 [==============================] - 0s 2ms/step - loss: 0.5181 - accuracy: 0.7963 - val_loss: 0.4640 - val_accuracy: 0.8202\n",
      "Epoch 345/1000\n",
      "225/225 [==============================] - 0s 2ms/step - loss: 0.5196 - accuracy: 0.7968 - val_loss: 0.4627 - val_accuracy: 0.8220\n",
      "Epoch 346/1000\n",
      "225/225 [==============================] - 0s 2ms/step - loss: 0.5195 - accuracy: 0.7965 - val_loss: 0.4626 - val_accuracy: 0.8207\n",
      "Epoch 347/1000\n",
      "225/225 [==============================] - 0s 2ms/step - loss: 0.5174 - accuracy: 0.7972 - val_loss: 0.4664 - val_accuracy: 0.8217\n",
      "Epoch 348/1000\n",
      "225/225 [==============================] - 0s 2ms/step - loss: 0.5201 - accuracy: 0.7959 - val_loss: 0.4640 - val_accuracy: 0.8214\n",
      "Epoch 349/1000\n",
      "225/225 [==============================] - 0s 2ms/step - loss: 0.5186 - accuracy: 0.7980 - val_loss: 0.4648 - val_accuracy: 0.8207\n",
      "Epoch 350/1000\n",
      "225/225 [==============================] - 0s 2ms/step - loss: 0.5177 - accuracy: 0.7976 - val_loss: 0.4646 - val_accuracy: 0.8182\n",
      "Epoch 351/1000\n",
      "225/225 [==============================] - 0s 2ms/step - loss: 0.5179 - accuracy: 0.7971 - val_loss: 0.4627 - val_accuracy: 0.8211\n",
      "Epoch 352/1000\n",
      "225/225 [==============================] - 0s 2ms/step - loss: 0.5191 - accuracy: 0.7968 - val_loss: 0.4663 - val_accuracy: 0.8202\n",
      "Epoch 353/1000\n",
      "225/225 [==============================] - 1s 2ms/step - loss: 0.5178 - accuracy: 0.7973 - val_loss: 0.4635 - val_accuracy: 0.8209\n",
      "Epoch 354/1000\n",
      "225/225 [==============================] - 0s 2ms/step - loss: 0.5169 - accuracy: 0.7973 - val_loss: 0.4614 - val_accuracy: 0.8226\n",
      "Epoch 355/1000\n",
      "225/225 [==============================] - 0s 2ms/step - loss: 0.5178 - accuracy: 0.7985 - val_loss: 0.4634 - val_accuracy: 0.8215\n",
      "Epoch 356/1000\n",
      "225/225 [==============================] - 0s 2ms/step - loss: 0.5154 - accuracy: 0.7977 - val_loss: 0.4620 - val_accuracy: 0.8225\n",
      "Epoch 357/1000\n",
      "225/225 [==============================] - 1s 2ms/step - loss: 0.5181 - accuracy: 0.7970 - val_loss: 0.4595 - val_accuracy: 0.8224\n",
      "Epoch 358/1000\n",
      "225/225 [==============================] - 1s 2ms/step - loss: 0.5169 - accuracy: 0.7985 - val_loss: 0.4626 - val_accuracy: 0.8208\n",
      "Epoch 359/1000\n",
      "225/225 [==============================] - 1s 2ms/step - loss: 0.5205 - accuracy: 0.7970 - val_loss: 0.4650 - val_accuracy: 0.8206\n",
      "Epoch 360/1000\n",
      "225/225 [==============================] - 0s 2ms/step - loss: 0.5173 - accuracy: 0.7985 - val_loss: 0.4618 - val_accuracy: 0.8229\n",
      "Epoch 361/1000\n",
      "225/225 [==============================] - 0s 2ms/step - loss: 0.5181 - accuracy: 0.7965 - val_loss: 0.4636 - val_accuracy: 0.8202\n",
      "Epoch 362/1000\n",
      "225/225 [==============================] - 1s 2ms/step - loss: 0.5154 - accuracy: 0.7987 - val_loss: 0.4612 - val_accuracy: 0.8229\n",
      "Epoch 363/1000\n",
      "225/225 [==============================] - 1s 2ms/step - loss: 0.5183 - accuracy: 0.7980 - val_loss: 0.4644 - val_accuracy: 0.8214\n",
      "Epoch 364/1000\n",
      "225/225 [==============================] - 1s 2ms/step - loss: 0.5179 - accuracy: 0.7963 - val_loss: 0.4652 - val_accuracy: 0.8192\n",
      "Epoch 365/1000\n",
      "225/225 [==============================] - 1s 2ms/step - loss: 0.5181 - accuracy: 0.7974 - val_loss: 0.4638 - val_accuracy: 0.8235\n",
      "Epoch 366/1000\n",
      "225/225 [==============================] - 0s 2ms/step - loss: 0.5162 - accuracy: 0.7977 - val_loss: 0.4631 - val_accuracy: 0.8200\n",
      "Epoch 367/1000\n",
      "225/225 [==============================] - 1s 2ms/step - loss: 0.5183 - accuracy: 0.7975 - val_loss: 0.4636 - val_accuracy: 0.8207\n",
      "Epoch 368/1000\n",
      "225/225 [==============================] - 1s 2ms/step - loss: 0.5159 - accuracy: 0.7980 - val_loss: 0.4643 - val_accuracy: 0.8184\n",
      "Epoch 369/1000\n",
      "225/225 [==============================] - 1s 2ms/step - loss: 0.5176 - accuracy: 0.7979 - val_loss: 0.4659 - val_accuracy: 0.8201\n",
      "Epoch 370/1000\n",
      "225/225 [==============================] - 1s 2ms/step - loss: 0.5165 - accuracy: 0.7978 - val_loss: 0.4631 - val_accuracy: 0.8213\n",
      "Epoch 371/1000\n",
      "225/225 [==============================] - 1s 2ms/step - loss: 0.5167 - accuracy: 0.7963 - val_loss: 0.4646 - val_accuracy: 0.8224\n",
      "Epoch 372/1000\n",
      "225/225 [==============================] - 0s 2ms/step - loss: 0.5156 - accuracy: 0.7982 - val_loss: 0.4621 - val_accuracy: 0.8229\n",
      "Epoch 373/1000\n",
      "225/225 [==============================] - 0s 2ms/step - loss: 0.5162 - accuracy: 0.7981 - val_loss: 0.4618 - val_accuracy: 0.8217\n",
      "Epoch 374/1000\n",
      "225/225 [==============================] - 0s 2ms/step - loss: 0.5149 - accuracy: 0.7990 - val_loss: 0.4618 - val_accuracy: 0.8216\n",
      "Epoch 375/1000\n",
      "225/225 [==============================] - 0s 2ms/step - loss: 0.5143 - accuracy: 0.7990 - val_loss: 0.4609 - val_accuracy: 0.8238\n",
      "Epoch 376/1000\n",
      "225/225 [==============================] - 0s 2ms/step - loss: 0.5154 - accuracy: 0.7981 - val_loss: 0.4621 - val_accuracy: 0.8224\n",
      "Epoch 377/1000\n",
      "225/225 [==============================] - 0s 2ms/step - loss: 0.5142 - accuracy: 0.7985 - val_loss: 0.4618 - val_accuracy: 0.8226\n",
      "Epoch 378/1000\n",
      "225/225 [==============================] - 1s 2ms/step - loss: 0.5150 - accuracy: 0.7983 - val_loss: 0.4593 - val_accuracy: 0.8238\n",
      "Epoch 379/1000\n",
      "225/225 [==============================] - 0s 2ms/step - loss: 0.5159 - accuracy: 0.7982 - val_loss: 0.4650 - val_accuracy: 0.8223\n",
      "Epoch 380/1000\n",
      "225/225 [==============================] - 0s 2ms/step - loss: 0.5157 - accuracy: 0.7975 - val_loss: 0.4610 - val_accuracy: 0.8222\n",
      "Epoch 381/1000\n",
      "225/225 [==============================] - 0s 2ms/step - loss: 0.5159 - accuracy: 0.7976 - val_loss: 0.4617 - val_accuracy: 0.8226\n",
      "Epoch 382/1000\n",
      "225/225 [==============================] - 1s 2ms/step - loss: 0.5156 - accuracy: 0.7986 - val_loss: 0.4622 - val_accuracy: 0.8231\n",
      "Epoch 383/1000\n",
      "225/225 [==============================] - 0s 2ms/step - loss: 0.5147 - accuracy: 0.7984 - val_loss: 0.4590 - val_accuracy: 0.8241\n",
      "Epoch 384/1000\n",
      "225/225 [==============================] - 0s 2ms/step - loss: 0.5154 - accuracy: 0.7984 - val_loss: 0.4626 - val_accuracy: 0.8228\n",
      "Epoch 385/1000\n",
      "225/225 [==============================] - 0s 2ms/step - loss: 0.5171 - accuracy: 0.7970 - val_loss: 0.4621 - val_accuracy: 0.8226\n",
      "Epoch 386/1000\n",
      "225/225 [==============================] - 0s 2ms/step - loss: 0.5152 - accuracy: 0.7983 - val_loss: 0.4608 - val_accuracy: 0.8239\n",
      "Epoch 387/1000\n",
      "225/225 [==============================] - 0s 2ms/step - loss: 0.5154 - accuracy: 0.7978 - val_loss: 0.4608 - val_accuracy: 0.8237\n",
      "Epoch 388/1000\n",
      "225/225 [==============================] - 0s 2ms/step - loss: 0.5150 - accuracy: 0.7976 - val_loss: 0.4615 - val_accuracy: 0.8249\n",
      "Epoch 389/1000\n",
      "225/225 [==============================] - 0s 2ms/step - loss: 0.5166 - accuracy: 0.7978 - val_loss: 0.4620 - val_accuracy: 0.8227\n",
      "Epoch 390/1000\n",
      "225/225 [==============================] - 0s 2ms/step - loss: 0.5143 - accuracy: 0.7991 - val_loss: 0.4612 - val_accuracy: 0.8236\n",
      "Epoch 391/1000\n",
      "225/225 [==============================] - 1s 2ms/step - loss: 0.5139 - accuracy: 0.7981 - val_loss: 0.4605 - val_accuracy: 0.8239\n",
      "Epoch 392/1000\n",
      "225/225 [==============================] - 0s 2ms/step - loss: 0.5172 - accuracy: 0.7976 - val_loss: 0.4617 - val_accuracy: 0.8221\n",
      "Epoch 393/1000\n",
      "225/225 [==============================] - 0s 2ms/step - loss: 0.5159 - accuracy: 0.7971 - val_loss: 0.4628 - val_accuracy: 0.8217\n",
      "Epoch 394/1000\n",
      "225/225 [==============================] - 0s 2ms/step - loss: 0.5158 - accuracy: 0.7982 - val_loss: 0.4614 - val_accuracy: 0.8218\n",
      "Epoch 395/1000\n",
      "225/225 [==============================] - 0s 2ms/step - loss: 0.5160 - accuracy: 0.7983 - val_loss: 0.4603 - val_accuracy: 0.8222\n",
      "Epoch 396/1000\n",
      "225/225 [==============================] - 0s 2ms/step - loss: 0.5156 - accuracy: 0.7997 - val_loss: 0.4611 - val_accuracy: 0.8224\n",
      "Epoch 397/1000\n",
      "225/225 [==============================] - 0s 2ms/step - loss: 0.5149 - accuracy: 0.7985 - val_loss: 0.4605 - val_accuracy: 0.8233\n",
      "Epoch 398/1000\n",
      "225/225 [==============================] - 0s 2ms/step - loss: 0.5148 - accuracy: 0.7992 - val_loss: 0.4623 - val_accuracy: 0.8219\n",
      "Epoch 399/1000\n",
      "225/225 [==============================] - 1s 3ms/step - loss: 0.5169 - accuracy: 0.7983 - val_loss: 0.4621 - val_accuracy: 0.8220\n",
      "Epoch 400/1000\n",
      "225/225 [==============================] - 1s 2ms/step - loss: 0.5147 - accuracy: 0.7985 - val_loss: 0.4602 - val_accuracy: 0.8245\n",
      "Epoch 401/1000\n",
      "225/225 [==============================] - 0s 2ms/step - loss: 0.5137 - accuracy: 0.7989 - val_loss: 0.4603 - val_accuracy: 0.8209\n",
      "Epoch 402/1000\n",
      "225/225 [==============================] - 0s 2ms/step - loss: 0.5156 - accuracy: 0.7994 - val_loss: 0.4603 - val_accuracy: 0.8231\n",
      "Epoch 403/1000\n",
      "225/225 [==============================] - 0s 2ms/step - loss: 0.5157 - accuracy: 0.7979 - val_loss: 0.4639 - val_accuracy: 0.8222\n",
      "Epoch 404/1000\n",
      "225/225 [==============================] - 0s 2ms/step - loss: 0.5129 - accuracy: 0.7992 - val_loss: 0.4591 - val_accuracy: 0.8238\n",
      "Epoch 405/1000\n",
      "225/225 [==============================] - 0s 2ms/step - loss: 0.5142 - accuracy: 0.7978 - val_loss: 0.4601 - val_accuracy: 0.8235\n",
      "Epoch 406/1000\n",
      "225/225 [==============================] - 0s 2ms/step - loss: 0.5136 - accuracy: 0.7988 - val_loss: 0.4595 - val_accuracy: 0.8223\n",
      "Epoch 407/1000\n",
      "225/225 [==============================] - 0s 2ms/step - loss: 0.5154 - accuracy: 0.7979 - val_loss: 0.4605 - val_accuracy: 0.8238\n",
      "Epoch 408/1000\n",
      "225/225 [==============================] - 0s 2ms/step - loss: 0.5160 - accuracy: 0.7975 - val_loss: 0.4584 - val_accuracy: 0.8253\n",
      "Epoch 409/1000\n",
      "225/225 [==============================] - 0s 2ms/step - loss: 0.5152 - accuracy: 0.7981 - val_loss: 0.4615 - val_accuracy: 0.8204\n",
      "Epoch 410/1000\n",
      "225/225 [==============================] - 0s 2ms/step - loss: 0.5142 - accuracy: 0.7971 - val_loss: 0.4610 - val_accuracy: 0.8215\n",
      "Epoch 411/1000\n",
      "225/225 [==============================] - 0s 2ms/step - loss: 0.5169 - accuracy: 0.7969 - val_loss: 0.4602 - val_accuracy: 0.8224\n",
      "Epoch 412/1000\n",
      "225/225 [==============================] - 0s 2ms/step - loss: 0.5136 - accuracy: 0.7985 - val_loss: 0.4604 - val_accuracy: 0.8230\n",
      "Epoch 413/1000\n",
      "225/225 [==============================] - 0s 2ms/step - loss: 0.5116 - accuracy: 0.7988 - val_loss: 0.4581 - val_accuracy: 0.8247\n",
      "Epoch 414/1000\n",
      "225/225 [==============================] - 0s 2ms/step - loss: 0.5134 - accuracy: 0.7999 - val_loss: 0.4613 - val_accuracy: 0.8240\n",
      "Epoch 415/1000\n",
      "225/225 [==============================] - 0s 2ms/step - loss: 0.5132 - accuracy: 0.7994 - val_loss: 0.4597 - val_accuracy: 0.8224\n",
      "Epoch 416/1000\n",
      "225/225 [==============================] - 0s 2ms/step - loss: 0.5148 - accuracy: 0.7979 - val_loss: 0.4597 - val_accuracy: 0.8228\n",
      "Epoch 417/1000\n",
      "225/225 [==============================] - 0s 2ms/step - loss: 0.5151 - accuracy: 0.7979 - val_loss: 0.4571 - val_accuracy: 0.8250\n",
      "Epoch 418/1000\n",
      "225/225 [==============================] - 0s 2ms/step - loss: 0.5134 - accuracy: 0.7988 - val_loss: 0.4614 - val_accuracy: 0.8218\n",
      "Epoch 419/1000\n",
      "225/225 [==============================] - 0s 2ms/step - loss: 0.5152 - accuracy: 0.7979 - val_loss: 0.4585 - val_accuracy: 0.8238\n",
      "Epoch 420/1000\n",
      "225/225 [==============================] - 1s 2ms/step - loss: 0.5098 - accuracy: 0.8005 - val_loss: 0.4588 - val_accuracy: 0.8241\n",
      "Epoch 421/1000\n",
      "225/225 [==============================] - 0s 2ms/step - loss: 0.5136 - accuracy: 0.7989 - val_loss: 0.4600 - val_accuracy: 0.8240\n",
      "Epoch 422/1000\n",
      "225/225 [==============================] - 0s 2ms/step - loss: 0.5143 - accuracy: 0.7992 - val_loss: 0.4565 - val_accuracy: 0.8237\n",
      "Epoch 423/1000\n",
      "225/225 [==============================] - 0s 2ms/step - loss: 0.5141 - accuracy: 0.7987 - val_loss: 0.4578 - val_accuracy: 0.8238\n",
      "Epoch 424/1000\n",
      "225/225 [==============================] - 0s 2ms/step - loss: 0.5149 - accuracy: 0.7984 - val_loss: 0.4567 - val_accuracy: 0.8277\n",
      "Epoch 425/1000\n",
      "225/225 [==============================] - 0s 2ms/step - loss: 0.5129 - accuracy: 0.7997 - val_loss: 0.4569 - val_accuracy: 0.8230\n",
      "Epoch 426/1000\n",
      "225/225 [==============================] - 0s 2ms/step - loss: 0.5131 - accuracy: 0.7997 - val_loss: 0.4556 - val_accuracy: 0.8243\n",
      "Epoch 427/1000\n",
      "225/225 [==============================] - 0s 2ms/step - loss: 0.5155 - accuracy: 0.7988 - val_loss: 0.4563 - val_accuracy: 0.8267\n",
      "Epoch 428/1000\n",
      "225/225 [==============================] - 0s 2ms/step - loss: 0.5150 - accuracy: 0.7982 - val_loss: 0.4617 - val_accuracy: 0.8228\n",
      "Epoch 429/1000\n",
      "225/225 [==============================] - 0s 2ms/step - loss: 0.5142 - accuracy: 0.7986 - val_loss: 0.4567 - val_accuracy: 0.8251\n",
      "Epoch 430/1000\n",
      "225/225 [==============================] - 0s 2ms/step - loss: 0.5133 - accuracy: 0.7989 - val_loss: 0.4604 - val_accuracy: 0.8224\n",
      "Epoch 431/1000\n",
      "225/225 [==============================] - 0s 2ms/step - loss: 0.5140 - accuracy: 0.7979 - val_loss: 0.4588 - val_accuracy: 0.8246\n",
      "Epoch 432/1000\n",
      "225/225 [==============================] - 1s 2ms/step - loss: 0.5141 - accuracy: 0.7989 - val_loss: 0.4604 - val_accuracy: 0.8225\n",
      "Epoch 433/1000\n",
      "225/225 [==============================] - 0s 2ms/step - loss: 0.5138 - accuracy: 0.7990 - val_loss: 0.4591 - val_accuracy: 0.8223\n",
      "Epoch 434/1000\n",
      "225/225 [==============================] - 0s 2ms/step - loss: 0.5136 - accuracy: 0.7991 - val_loss: 0.4585 - val_accuracy: 0.8245\n",
      "Epoch 435/1000\n",
      "225/225 [==============================] - 0s 2ms/step - loss: 0.5117 - accuracy: 0.7994 - val_loss: 0.4571 - val_accuracy: 0.8243\n",
      "Epoch 436/1000\n",
      "225/225 [==============================] - 1s 2ms/step - loss: 0.5117 - accuracy: 0.8009 - val_loss: 0.4578 - val_accuracy: 0.8235\n",
      "Epoch 437/1000\n",
      "225/225 [==============================] - 0s 2ms/step - loss: 0.5142 - accuracy: 0.7986 - val_loss: 0.4587 - val_accuracy: 0.8238\n",
      "Epoch 438/1000\n",
      "225/225 [==============================] - 0s 2ms/step - loss: 0.5134 - accuracy: 0.7993 - val_loss: 0.4571 - val_accuracy: 0.8245\n",
      "Epoch 439/1000\n",
      "225/225 [==============================] - 0s 2ms/step - loss: 0.5157 - accuracy: 0.7983 - val_loss: 0.4612 - val_accuracy: 0.8206\n",
      "Epoch 440/1000\n",
      "225/225 [==============================] - 0s 2ms/step - loss: 0.5142 - accuracy: 0.7989 - val_loss: 0.4596 - val_accuracy: 0.8226\n",
      "Epoch 441/1000\n",
      "225/225 [==============================] - 1s 2ms/step - loss: 0.5144 - accuracy: 0.7984 - val_loss: 0.4604 - val_accuracy: 0.8211\n",
      "Epoch 442/1000\n",
      "225/225 [==============================] - 0s 2ms/step - loss: 0.5154 - accuracy: 0.7990 - val_loss: 0.4586 - val_accuracy: 0.8228\n",
      "Epoch 443/1000\n",
      "225/225 [==============================] - 0s 2ms/step - loss: 0.5123 - accuracy: 0.7996 - val_loss: 0.4580 - val_accuracy: 0.8228\n",
      "Epoch 444/1000\n",
      "225/225 [==============================] - 0s 2ms/step - loss: 0.5155 - accuracy: 0.7993 - val_loss: 0.4614 - val_accuracy: 0.8218\n",
      "Epoch 445/1000\n",
      "225/225 [==============================] - 0s 2ms/step - loss: 0.5128 - accuracy: 0.7986 - val_loss: 0.4613 - val_accuracy: 0.8230\n",
      "Epoch 446/1000\n",
      "225/225 [==============================] - 0s 2ms/step - loss: 0.5143 - accuracy: 0.7976 - val_loss: 0.4623 - val_accuracy: 0.8220\n",
      "Epoch 447/1000\n",
      "225/225 [==============================] - 1s 2ms/step - loss: 0.5110 - accuracy: 0.7994 - val_loss: 0.4598 - val_accuracy: 0.8239\n",
      "Epoch 448/1000\n",
      "225/225 [==============================] - 0s 2ms/step - loss: 0.5124 - accuracy: 0.7993 - val_loss: 0.4599 - val_accuracy: 0.8215\n",
      "Epoch 449/1000\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "225/225 [==============================] - 0s 2ms/step - loss: 0.5142 - accuracy: 0.7975 - val_loss: 0.4606 - val_accuracy: 0.8213\n",
      "Epoch 450/1000\n",
      "225/225 [==============================] - 0s 2ms/step - loss: 0.5125 - accuracy: 0.7992 - val_loss: 0.4570 - val_accuracy: 0.8238\n",
      "Epoch 451/1000\n",
      "225/225 [==============================] - 0s 2ms/step - loss: 0.5130 - accuracy: 0.7989 - val_loss: 0.4596 - val_accuracy: 0.8220\n",
      "Epoch 452/1000\n",
      "225/225 [==============================] - 0s 2ms/step - loss: 0.5129 - accuracy: 0.7998 - val_loss: 0.4574 - val_accuracy: 0.8246\n",
      "Epoch 453/1000\n",
      "225/225 [==============================] - 0s 2ms/step - loss: 0.5146 - accuracy: 0.7983 - val_loss: 0.4597 - val_accuracy: 0.8206\n",
      "Epoch 454/1000\n",
      "225/225 [==============================] - 0s 2ms/step - loss: 0.5124 - accuracy: 0.7995 - val_loss: 0.4582 - val_accuracy: 0.8216\n",
      "Epoch 455/1000\n",
      "225/225 [==============================] - 0s 2ms/step - loss: 0.5132 - accuracy: 0.7992 - val_loss: 0.4564 - val_accuracy: 0.8236\n",
      "Epoch 456/1000\n",
      "225/225 [==============================] - 0s 2ms/step - loss: 0.5133 - accuracy: 0.7981 - val_loss: 0.4570 - val_accuracy: 0.8218\n",
      "Epoch 457/1000\n",
      "225/225 [==============================] - 1s 2ms/step - loss: 0.5122 - accuracy: 0.7991 - val_loss: 0.4578 - val_accuracy: 0.8219\n",
      "Epoch 458/1000\n",
      "225/225 [==============================] - 0s 2ms/step - loss: 0.5141 - accuracy: 0.7974 - val_loss: 0.4575 - val_accuracy: 0.8231\n",
      "Epoch 459/1000\n",
      "225/225 [==============================] - 0s 2ms/step - loss: 0.5132 - accuracy: 0.7997 - val_loss: 0.4574 - val_accuracy: 0.8254\n",
      "Epoch 460/1000\n",
      "225/225 [==============================] - 0s 2ms/step - loss: 0.5122 - accuracy: 0.8001 - val_loss: 0.4594 - val_accuracy: 0.8228\n",
      "Epoch 461/1000\n",
      "225/225 [==============================] - 0s 2ms/step - loss: 0.5141 - accuracy: 0.7996 - val_loss: 0.4603 - val_accuracy: 0.8223\n",
      "Epoch 462/1000\n",
      "225/225 [==============================] - 0s 2ms/step - loss: 0.5122 - accuracy: 0.7988 - val_loss: 0.4568 - val_accuracy: 0.8242\n",
      "Epoch 463/1000\n",
      "225/225 [==============================] - 1s 2ms/step - loss: 0.5105 - accuracy: 0.8004 - val_loss: 0.4559 - val_accuracy: 0.8204\n",
      "Epoch 464/1000\n",
      "225/225 [==============================] - 1s 2ms/step - loss: 0.5126 - accuracy: 0.8000 - val_loss: 0.4605 - val_accuracy: 0.8217\n",
      "Epoch 465/1000\n",
      "225/225 [==============================] - 1s 2ms/step - loss: 0.5135 - accuracy: 0.7991 - val_loss: 0.4598 - val_accuracy: 0.8232\n",
      "Epoch 466/1000\n",
      "225/225 [==============================] - 0s 2ms/step - loss: 0.5128 - accuracy: 0.7992 - val_loss: 0.4587 - val_accuracy: 0.8216\n",
      "Epoch 467/1000\n",
      "225/225 [==============================] - 0s 2ms/step - loss: 0.5137 - accuracy: 0.7990 - val_loss: 0.4591 - val_accuracy: 0.8239\n",
      "Epoch 468/1000\n",
      "225/225 [==============================] - 1s 2ms/step - loss: 0.5123 - accuracy: 0.7989 - val_loss: 0.4559 - val_accuracy: 0.8247\n",
      "Epoch 469/1000\n",
      "225/225 [==============================] - 1s 2ms/step - loss: 0.5119 - accuracy: 0.8001 - val_loss: 0.4565 - val_accuracy: 0.8217\n",
      "Epoch 470/1000\n",
      "225/225 [==============================] - 1s 2ms/step - loss: 0.5132 - accuracy: 0.7995 - val_loss: 0.4550 - val_accuracy: 0.8257\n",
      "Epoch 471/1000\n",
      "225/225 [==============================] - 1s 2ms/step - loss: 0.5104 - accuracy: 0.8003 - val_loss: 0.4554 - val_accuracy: 0.8242\n",
      "Epoch 472/1000\n",
      "225/225 [==============================] - 1s 2ms/step - loss: 0.5111 - accuracy: 0.7997 - val_loss: 0.4562 - val_accuracy: 0.8231\n",
      "Epoch 473/1000\n",
      "225/225 [==============================] - 1s 2ms/step - loss: 0.5129 - accuracy: 0.8005 - val_loss: 0.4598 - val_accuracy: 0.8220\n",
      "Epoch 474/1000\n",
      "225/225 [==============================] - 0s 2ms/step - loss: 0.5111 - accuracy: 0.8009 - val_loss: 0.4564 - val_accuracy: 0.8247\n",
      "Epoch 475/1000\n",
      "225/225 [==============================] - 0s 2ms/step - loss: 0.5092 - accuracy: 0.8010 - val_loss: 0.4550 - val_accuracy: 0.8242\n",
      "Epoch 476/1000\n",
      "225/225 [==============================] - 0s 2ms/step - loss: 0.5114 - accuracy: 0.8004 - val_loss: 0.4586 - val_accuracy: 0.8228\n",
      "Epoch 477/1000\n",
      "225/225 [==============================] - 1s 2ms/step - loss: 0.5133 - accuracy: 0.7979 - val_loss: 0.4551 - val_accuracy: 0.8248\n",
      "Epoch 478/1000\n",
      "225/225 [==============================] - 0s 2ms/step - loss: 0.5139 - accuracy: 0.7994 - val_loss: 0.4581 - val_accuracy: 0.8257\n",
      "Epoch 479/1000\n",
      "225/225 [==============================] - 0s 2ms/step - loss: 0.5132 - accuracy: 0.8006 - val_loss: 0.4591 - val_accuracy: 0.8246\n",
      "Epoch 480/1000\n",
      "225/225 [==============================] - 1s 2ms/step - loss: 0.5110 - accuracy: 0.7998 - val_loss: 0.4557 - val_accuracy: 0.8255\n",
      "Epoch 481/1000\n",
      "225/225 [==============================] - 1s 2ms/step - loss: 0.5124 - accuracy: 0.7988 - val_loss: 0.4552 - val_accuracy: 0.8246\n",
      "Epoch 482/1000\n",
      "225/225 [==============================] - 0s 2ms/step - loss: 0.5114 - accuracy: 0.8006 - val_loss: 0.4588 - val_accuracy: 0.8249\n",
      "Epoch 483/1000\n",
      "225/225 [==============================] - 0s 2ms/step - loss: 0.5114 - accuracy: 0.7999 - val_loss: 0.4587 - val_accuracy: 0.8231\n",
      "Epoch 484/1000\n",
      "225/225 [==============================] - 0s 2ms/step - loss: 0.5096 - accuracy: 0.7999 - val_loss: 0.4593 - val_accuracy: 0.8228\n",
      "Epoch 485/1000\n",
      "225/225 [==============================] - 0s 2ms/step - loss: 0.5118 - accuracy: 0.7991 - val_loss: 0.4571 - val_accuracy: 0.8262\n",
      "Epoch 486/1000\n",
      "225/225 [==============================] - 0s 2ms/step - loss: 0.5104 - accuracy: 0.7993 - val_loss: 0.4565 - val_accuracy: 0.8244\n",
      "Epoch 487/1000\n",
      "225/225 [==============================] - 0s 2ms/step - loss: 0.5113 - accuracy: 0.8006 - val_loss: 0.4578 - val_accuracy: 0.8247\n",
      "Epoch 488/1000\n",
      "225/225 [==============================] - 0s 2ms/step - loss: 0.5114 - accuracy: 0.8003 - val_loss: 0.4569 - val_accuracy: 0.8260\n",
      "Epoch 489/1000\n",
      "225/225 [==============================] - 0s 2ms/step - loss: 0.5122 - accuracy: 0.7994 - val_loss: 0.4575 - val_accuracy: 0.8249\n",
      "Epoch 490/1000\n",
      "225/225 [==============================] - 1s 2ms/step - loss: 0.5103 - accuracy: 0.8004 - val_loss: 0.4556 - val_accuracy: 0.8255\n",
      "Epoch 491/1000\n",
      "225/225 [==============================] - 0s 2ms/step - loss: 0.5100 - accuracy: 0.8009 - val_loss: 0.4536 - val_accuracy: 0.8260\n",
      "Epoch 492/1000\n",
      "225/225 [==============================] - 0s 2ms/step - loss: 0.5123 - accuracy: 0.7995 - val_loss: 0.4573 - val_accuracy: 0.8229\n",
      "Epoch 493/1000\n",
      "225/225 [==============================] - 0s 2ms/step - loss: 0.5121 - accuracy: 0.7997 - val_loss: 0.4569 - val_accuracy: 0.8239\n",
      "Epoch 494/1000\n",
      "225/225 [==============================] - 0s 2ms/step - loss: 0.5101 - accuracy: 0.8010 - val_loss: 0.4547 - val_accuracy: 0.8250\n",
      "Epoch 495/1000\n",
      "225/225 [==============================] - 1s 2ms/step - loss: 0.5109 - accuracy: 0.8001 - val_loss: 0.4579 - val_accuracy: 0.8224\n",
      "Epoch 496/1000\n",
      "225/225 [==============================] - 1s 2ms/step - loss: 0.5094 - accuracy: 0.8006 - val_loss: 0.4560 - val_accuracy: 0.8231\n",
      "Epoch 497/1000\n",
      "225/225 [==============================] - 0s 2ms/step - loss: 0.5100 - accuracy: 0.8006 - val_loss: 0.4576 - val_accuracy: 0.8238\n",
      "Epoch 498/1000\n",
      "225/225 [==============================] - 0s 2ms/step - loss: 0.5133 - accuracy: 0.7994 - val_loss: 0.4568 - val_accuracy: 0.8247\n",
      "Epoch 499/1000\n",
      "225/225 [==============================] - 0s 2ms/step - loss: 0.5095 - accuracy: 0.8004 - val_loss: 0.4579 - val_accuracy: 0.8235\n",
      "Epoch 500/1000\n",
      "225/225 [==============================] - 0s 2ms/step - loss: 0.5094 - accuracy: 0.8014 - val_loss: 0.4568 - val_accuracy: 0.8229\n",
      "Epoch 501/1000\n",
      "225/225 [==============================] - 1s 2ms/step - loss: 0.5115 - accuracy: 0.8008 - val_loss: 0.4565 - val_accuracy: 0.8234\n",
      "Epoch 502/1000\n",
      "225/225 [==============================] - 0s 2ms/step - loss: 0.5130 - accuracy: 0.8007 - val_loss: 0.4579 - val_accuracy: 0.8217\n",
      "Epoch 503/1000\n",
      "225/225 [==============================] - 0s 2ms/step - loss: 0.5103 - accuracy: 0.8012 - val_loss: 0.4557 - val_accuracy: 0.8231\n",
      "Epoch 504/1000\n",
      "225/225 [==============================] - 1s 2ms/step - loss: 0.5114 - accuracy: 0.8002 - val_loss: 0.4564 - val_accuracy: 0.8235\n",
      "Epoch 505/1000\n",
      "225/225 [==============================] - 0s 2ms/step - loss: 0.5096 - accuracy: 0.8009 - val_loss: 0.4558 - val_accuracy: 0.8249\n",
      "Epoch 506/1000\n",
      "225/225 [==============================] - 1s 2ms/step - loss: 0.5099 - accuracy: 0.8001 - val_loss: 0.4546 - val_accuracy: 0.8232\n",
      "Epoch 507/1000\n",
      "225/225 [==============================] - 0s 2ms/step - loss: 0.5106 - accuracy: 0.8003 - val_loss: 0.4571 - val_accuracy: 0.8257\n",
      "Epoch 508/1000\n",
      "225/225 [==============================] - 1s 2ms/step - loss: 0.5108 - accuracy: 0.8003 - val_loss: 0.4550 - val_accuracy: 0.8230\n",
      "Epoch 509/1000\n",
      "225/225 [==============================] - 0s 2ms/step - loss: 0.5103 - accuracy: 0.8000 - val_loss: 0.4560 - val_accuracy: 0.8230\n",
      "Epoch 510/1000\n",
      "225/225 [==============================] - 1s 2ms/step - loss: 0.5105 - accuracy: 0.8005 - val_loss: 0.4557 - val_accuracy: 0.8238\n",
      "Epoch 511/1000\n",
      "225/225 [==============================] - 1s 2ms/step - loss: 0.5104 - accuracy: 0.7999 - val_loss: 0.4558 - val_accuracy: 0.8237\n",
      "Epoch 512/1000\n",
      "225/225 [==============================] - 1s 2ms/step - loss: 0.5121 - accuracy: 0.8000 - val_loss: 0.4574 - val_accuracy: 0.8237\n",
      "Epoch 513/1000\n",
      "225/225 [==============================] - 1s 2ms/step - loss: 0.5124 - accuracy: 0.7989 - val_loss: 0.4571 - val_accuracy: 0.8227\n",
      "Epoch 514/1000\n",
      "225/225 [==============================] - 0s 2ms/step - loss: 0.5081 - accuracy: 0.8017 - val_loss: 0.4561 - val_accuracy: 0.8243\n",
      "Epoch 515/1000\n",
      "225/225 [==============================] - 0s 2ms/step - loss: 0.5103 - accuracy: 0.8005 - val_loss: 0.4550 - val_accuracy: 0.8252\n",
      "Epoch 516/1000\n",
      "225/225 [==============================] - 0s 2ms/step - loss: 0.5118 - accuracy: 0.7999 - val_loss: 0.4567 - val_accuracy: 0.8245\n",
      "Epoch 517/1000\n",
      "225/225 [==============================] - 0s 2ms/step - loss: 0.5119 - accuracy: 0.7995 - val_loss: 0.4558 - val_accuracy: 0.8254\n",
      "Epoch 518/1000\n",
      "225/225 [==============================] - 0s 2ms/step - loss: 0.5097 - accuracy: 0.8007 - val_loss: 0.4541 - val_accuracy: 0.8238\n",
      "Epoch 519/1000\n",
      "225/225 [==============================] - 1s 2ms/step - loss: 0.5092 - accuracy: 0.8009 - val_loss: 0.4532 - val_accuracy: 0.8257\n",
      "Epoch 520/1000\n",
      "225/225 [==============================] - 0s 2ms/step - loss: 0.5093 - accuracy: 0.8015 - val_loss: 0.4538 - val_accuracy: 0.8263\n",
      "Epoch 521/1000\n",
      "225/225 [==============================] - 0s 2ms/step - loss: 0.5117 - accuracy: 0.8001 - val_loss: 0.4545 - val_accuracy: 0.8257\n",
      "Epoch 522/1000\n",
      "225/225 [==============================] - 0s 2ms/step - loss: 0.5092 - accuracy: 0.8011 - val_loss: 0.4581 - val_accuracy: 0.8238\n",
      "Epoch 523/1000\n",
      "225/225 [==============================] - 0s 2ms/step - loss: 0.5092 - accuracy: 0.8013 - val_loss: 0.4552 - val_accuracy: 0.8228\n",
      "Epoch 524/1000\n",
      "225/225 [==============================] - 0s 2ms/step - loss: 0.5100 - accuracy: 0.8003 - val_loss: 0.4537 - val_accuracy: 0.8249\n",
      "Epoch 525/1000\n",
      "225/225 [==============================] - 0s 2ms/step - loss: 0.5094 - accuracy: 0.8012 - val_loss: 0.4529 - val_accuracy: 0.8281\n",
      "Epoch 526/1000\n",
      "225/225 [==============================] - 1s 2ms/step - loss: 0.5076 - accuracy: 0.8016 - val_loss: 0.4541 - val_accuracy: 0.8267\n",
      "Epoch 527/1000\n",
      "225/225 [==============================] - 1s 2ms/step - loss: 0.5102 - accuracy: 0.8008 - val_loss: 0.4517 - val_accuracy: 0.8253\n",
      "Epoch 528/1000\n",
      "225/225 [==============================] - 1s 2ms/step - loss: 0.5117 - accuracy: 0.8011 - val_loss: 0.4568 - val_accuracy: 0.8245\n",
      "Epoch 529/1000\n",
      "225/225 [==============================] - 1s 2ms/step - loss: 0.5119 - accuracy: 0.8010 - val_loss: 0.4559 - val_accuracy: 0.8260\n",
      "Epoch 530/1000\n",
      "225/225 [==============================] - 0s 2ms/step - loss: 0.5105 - accuracy: 0.8010 - val_loss: 0.4551 - val_accuracy: 0.8243\n",
      "Epoch 531/1000\n",
      "225/225 [==============================] - 1s 2ms/step - loss: 0.5091 - accuracy: 0.8009 - val_loss: 0.4555 - val_accuracy: 0.8258\n",
      "Epoch 532/1000\n",
      "225/225 [==============================] - 0s 2ms/step - loss: 0.5092 - accuracy: 0.8008 - val_loss: 0.4543 - val_accuracy: 0.8246\n",
      "Epoch 533/1000\n",
      "225/225 [==============================] - 1s 2ms/step - loss: 0.5096 - accuracy: 0.7994 - val_loss: 0.4551 - val_accuracy: 0.8268\n",
      "Epoch 534/1000\n",
      "225/225 [==============================] - 0s 2ms/step - loss: 0.5098 - accuracy: 0.8009 - val_loss: 0.4578 - val_accuracy: 0.8252\n",
      "Epoch 535/1000\n",
      "225/225 [==============================] - 0s 2ms/step - loss: 0.5111 - accuracy: 0.8011 - val_loss: 0.4574 - val_accuracy: 0.8249\n",
      "Epoch 536/1000\n",
      "225/225 [==============================] - 0s 2ms/step - loss: 0.5099 - accuracy: 0.8008 - val_loss: 0.4566 - val_accuracy: 0.8237\n",
      "Epoch 537/1000\n",
      "225/225 [==============================] - 0s 2ms/step - loss: 0.5092 - accuracy: 0.8007 - val_loss: 0.4570 - val_accuracy: 0.8215\n",
      "Epoch 538/1000\n",
      "225/225 [==============================] - 1s 2ms/step - loss: 0.5103 - accuracy: 0.8004 - val_loss: 0.4582 - val_accuracy: 0.8238\n",
      "Epoch 539/1000\n",
      "225/225 [==============================] - 0s 2ms/step - loss: 0.5098 - accuracy: 0.8006 - val_loss: 0.4531 - val_accuracy: 0.8254\n",
      "Epoch 540/1000\n",
      "225/225 [==============================] - 0s 2ms/step - loss: 0.5083 - accuracy: 0.8007 - val_loss: 0.4548 - val_accuracy: 0.8253\n",
      "Epoch 541/1000\n",
      "225/225 [==============================] - 0s 2ms/step - loss: 0.5105 - accuracy: 0.8006 - val_loss: 0.4533 - val_accuracy: 0.8275\n",
      "Epoch 542/1000\n",
      "225/225 [==============================] - 0s 2ms/step - loss: 0.5091 - accuracy: 0.8007 - val_loss: 0.4532 - val_accuracy: 0.8246\n",
      "Epoch 543/1000\n",
      "225/225 [==============================] - 0s 2ms/step - loss: 0.5099 - accuracy: 0.8002 - val_loss: 0.4542 - val_accuracy: 0.8236\n",
      "Epoch 544/1000\n",
      "225/225 [==============================] - 0s 2ms/step - loss: 0.5109 - accuracy: 0.7998 - val_loss: 0.4535 - val_accuracy: 0.8246\n",
      "Epoch 545/1000\n",
      "225/225 [==============================] - 1s 2ms/step - loss: 0.5094 - accuracy: 0.8000 - val_loss: 0.4522 - val_accuracy: 0.8267\n",
      "Epoch 546/1000\n",
      "225/225 [==============================] - 0s 2ms/step - loss: 0.5087 - accuracy: 0.8004 - val_loss: 0.4545 - val_accuracy: 0.8253\n",
      "Epoch 547/1000\n",
      "225/225 [==============================] - 0s 2ms/step - loss: 0.5107 - accuracy: 0.8006 - val_loss: 0.4551 - val_accuracy: 0.8242\n",
      "Epoch 548/1000\n",
      "225/225 [==============================] - 0s 2ms/step - loss: 0.5107 - accuracy: 0.8009 - val_loss: 0.4543 - val_accuracy: 0.8240\n",
      "Epoch 549/1000\n",
      "225/225 [==============================] - 0s 2ms/step - loss: 0.5091 - accuracy: 0.8011 - val_loss: 0.4568 - val_accuracy: 0.8246\n",
      "Epoch 550/1000\n",
      "225/225 [==============================] - 1s 2ms/step - loss: 0.5105 - accuracy: 0.8005 - val_loss: 0.4543 - val_accuracy: 0.8233\n",
      "Epoch 551/1000\n",
      "225/225 [==============================] - 0s 2ms/step - loss: 0.5103 - accuracy: 0.8010 - val_loss: 0.4566 - val_accuracy: 0.8235\n",
      "Epoch 552/1000\n",
      "225/225 [==============================] - 0s 2ms/step - loss: 0.5079 - accuracy: 0.8019 - val_loss: 0.4539 - val_accuracy: 0.8261\n",
      "Epoch 553/1000\n",
      "225/225 [==============================] - 1s 2ms/step - loss: 0.5092 - accuracy: 0.8011 - val_loss: 0.4526 - val_accuracy: 0.8256\n",
      "Epoch 554/1000\n",
      "225/225 [==============================] - 0s 2ms/step - loss: 0.5064 - accuracy: 0.8019 - val_loss: 0.4563 - val_accuracy: 0.8249\n",
      "Epoch 555/1000\n",
      "225/225 [==============================] - 0s 2ms/step - loss: 0.5087 - accuracy: 0.8003 - val_loss: 0.4546 - val_accuracy: 0.8238\n",
      "Epoch 556/1000\n",
      "225/225 [==============================] - 1s 2ms/step - loss: 0.5089 - accuracy: 0.8006 - val_loss: 0.4530 - val_accuracy: 0.8264\n",
      "Epoch 557/1000\n",
      "225/225 [==============================] - 0s 2ms/step - loss: 0.5082 - accuracy: 0.8014 - val_loss: 0.4550 - val_accuracy: 0.8243\n",
      "Epoch 558/1000\n",
      "225/225 [==============================] - 1s 2ms/step - loss: 0.5097 - accuracy: 0.8015 - val_loss: 0.4528 - val_accuracy: 0.8269\n",
      "Epoch 559/1000\n",
      "225/225 [==============================] - 1s 2ms/step - loss: 0.5060 - accuracy: 0.8018 - val_loss: 0.4561 - val_accuracy: 0.8246\n",
      "Epoch 560/1000\n",
      "225/225 [==============================] - 1s 2ms/step - loss: 0.5068 - accuracy: 0.8029 - val_loss: 0.4542 - val_accuracy: 0.8257\n",
      "Epoch 561/1000\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "225/225 [==============================] - 0s 2ms/step - loss: 0.5083 - accuracy: 0.8017 - val_loss: 0.4535 - val_accuracy: 0.8256\n",
      "Epoch 562/1000\n",
      "225/225 [==============================] - 0s 2ms/step - loss: 0.5097 - accuracy: 0.8002 - val_loss: 0.4550 - val_accuracy: 0.8260\n",
      "Epoch 563/1000\n",
      "225/225 [==============================] - 0s 2ms/step - loss: 0.5082 - accuracy: 0.8025 - val_loss: 0.4542 - val_accuracy: 0.8242\n",
      "Epoch 564/1000\n",
      "225/225 [==============================] - 0s 2ms/step - loss: 0.5081 - accuracy: 0.8019 - val_loss: 0.4569 - val_accuracy: 0.8267\n",
      "Epoch 565/1000\n",
      "225/225 [==============================] - 0s 2ms/step - loss: 0.5093 - accuracy: 0.8013 - val_loss: 0.4521 - val_accuracy: 0.8270\n",
      "Epoch 566/1000\n",
      "225/225 [==============================] - 0s 2ms/step - loss: 0.5083 - accuracy: 0.8007 - val_loss: 0.4525 - val_accuracy: 0.8278\n",
      "Epoch 567/1000\n",
      "225/225 [==============================] - 0s 2ms/step - loss: 0.5104 - accuracy: 0.8014 - val_loss: 0.4536 - val_accuracy: 0.8251\n",
      "Epoch 568/1000\n",
      "225/225 [==============================] - 0s 2ms/step - loss: 0.5080 - accuracy: 0.8015 - val_loss: 0.4534 - val_accuracy: 0.8247\n",
      "Epoch 569/1000\n",
      "225/225 [==============================] - 0s 2ms/step - loss: 0.5099 - accuracy: 0.8008 - val_loss: 0.4521 - val_accuracy: 0.8289\n",
      "Epoch 570/1000\n",
      "225/225 [==============================] - 0s 2ms/step - loss: 0.5079 - accuracy: 0.8008 - val_loss: 0.4527 - val_accuracy: 0.8258\n",
      "Epoch 571/1000\n",
      "225/225 [==============================] - 0s 2ms/step - loss: 0.5116 - accuracy: 0.7991 - val_loss: 0.4535 - val_accuracy: 0.8257\n",
      "Epoch 572/1000\n",
      "225/225 [==============================] - 0s 2ms/step - loss: 0.5066 - accuracy: 0.8020 - val_loss: 0.4542 - val_accuracy: 0.8259\n",
      "Epoch 573/1000\n",
      "225/225 [==============================] - 0s 2ms/step - loss: 0.5081 - accuracy: 0.8025 - val_loss: 0.4552 - val_accuracy: 0.8250\n",
      "Epoch 574/1000\n",
      "225/225 [==============================] - 0s 2ms/step - loss: 0.5087 - accuracy: 0.8010 - val_loss: 0.4529 - val_accuracy: 0.8264\n",
      "Epoch 575/1000\n",
      "225/225 [==============================] - 0s 2ms/step - loss: 0.5066 - accuracy: 0.8019 - val_loss: 0.4529 - val_accuracy: 0.8253\n",
      "Epoch 576/1000\n",
      "225/225 [==============================] - 0s 2ms/step - loss: 0.5098 - accuracy: 0.8004 - val_loss: 0.4541 - val_accuracy: 0.8271\n",
      "Epoch 577/1000\n",
      "225/225 [==============================] - 0s 2ms/step - loss: 0.5089 - accuracy: 0.8015 - val_loss: 0.4541 - val_accuracy: 0.8262\n",
      "Epoch 578/1000\n",
      "225/225 [==============================] - 0s 2ms/step - loss: 0.5076 - accuracy: 0.8011 - val_loss: 0.4531 - val_accuracy: 0.8238\n",
      "Epoch 579/1000\n",
      "225/225 [==============================] - 0s 2ms/step - loss: 0.5095 - accuracy: 0.8003 - val_loss: 0.4570 - val_accuracy: 0.8244\n",
      "Epoch 580/1000\n",
      "225/225 [==============================] - 0s 2ms/step - loss: 0.5092 - accuracy: 0.8007 - val_loss: 0.4542 - val_accuracy: 0.8239\n",
      "Epoch 581/1000\n",
      "225/225 [==============================] - 0s 2ms/step - loss: 0.5104 - accuracy: 0.8015 - val_loss: 0.4565 - val_accuracy: 0.8238\n",
      "Epoch 582/1000\n",
      "225/225 [==============================] - 0s 2ms/step - loss: 0.5092 - accuracy: 0.7999 - val_loss: 0.4542 - val_accuracy: 0.8247\n",
      "Epoch 583/1000\n",
      "225/225 [==============================] - 0s 2ms/step - loss: 0.5094 - accuracy: 0.8015 - val_loss: 0.4555 - val_accuracy: 0.8260\n",
      "Epoch 584/1000\n",
      "225/225 [==============================] - 0s 2ms/step - loss: 0.5098 - accuracy: 0.8009 - val_loss: 0.4548 - val_accuracy: 0.8264\n",
      "Epoch 585/1000\n",
      "225/225 [==============================] - 1s 3ms/step - loss: 0.5097 - accuracy: 0.8012 - val_loss: 0.4519 - val_accuracy: 0.8273\n",
      "Epoch 586/1000\n",
      "225/225 [==============================] - 0s 2ms/step - loss: 0.5069 - accuracy: 0.8016 - val_loss: 0.4558 - val_accuracy: 0.8260\n",
      "Epoch 587/1000\n",
      "225/225 [==============================] - 0s 2ms/step - loss: 0.5100 - accuracy: 0.8010 - val_loss: 0.4542 - val_accuracy: 0.8247\n",
      "Epoch 588/1000\n",
      "225/225 [==============================] - 0s 2ms/step - loss: 0.5080 - accuracy: 0.8024 - val_loss: 0.4533 - val_accuracy: 0.8242\n",
      "Epoch 589/1000\n",
      "225/225 [==============================] - 0s 2ms/step - loss: 0.5088 - accuracy: 0.8015 - val_loss: 0.4530 - val_accuracy: 0.8256\n",
      "Epoch 590/1000\n",
      "225/225 [==============================] - 0s 2ms/step - loss: 0.5074 - accuracy: 0.8024 - val_loss: 0.4559 - val_accuracy: 0.8248\n",
      "Epoch 591/1000\n",
      "225/225 [==============================] - 0s 2ms/step - loss: 0.5084 - accuracy: 0.8018 - val_loss: 0.4559 - val_accuracy: 0.8264\n",
      "Epoch 592/1000\n",
      "225/225 [==============================] - 1s 2ms/step - loss: 0.5075 - accuracy: 0.8016 - val_loss: 0.4522 - val_accuracy: 0.8267\n",
      "Epoch 593/1000\n",
      "225/225 [==============================] - 0s 2ms/step - loss: 0.5088 - accuracy: 0.8012 - val_loss: 0.4526 - val_accuracy: 0.8262\n",
      "Epoch 594/1000\n",
      "225/225 [==============================] - 0s 2ms/step - loss: 0.5094 - accuracy: 0.8003 - val_loss: 0.4545 - val_accuracy: 0.8245\n",
      "Epoch 595/1000\n",
      "225/225 [==============================] - 0s 2ms/step - loss: 0.5070 - accuracy: 0.8025 - val_loss: 0.4531 - val_accuracy: 0.8258\n",
      "Epoch 596/1000\n",
      "225/225 [==============================] - 0s 2ms/step - loss: 0.5094 - accuracy: 0.8021 - val_loss: 0.4513 - val_accuracy: 0.8286\n",
      "Epoch 597/1000\n",
      "225/225 [==============================] - 0s 2ms/step - loss: 0.5084 - accuracy: 0.8020 - val_loss: 0.4547 - val_accuracy: 0.8253\n",
      "Epoch 598/1000\n",
      "225/225 [==============================] - 0s 2ms/step - loss: 0.5068 - accuracy: 0.8021 - val_loss: 0.4531 - val_accuracy: 0.8264\n",
      "Epoch 599/1000\n",
      "225/225 [==============================] - 0s 2ms/step - loss: 0.5072 - accuracy: 0.8027 - val_loss: 0.4497 - val_accuracy: 0.8283\n",
      "Epoch 600/1000\n",
      "225/225 [==============================] - 0s 2ms/step - loss: 0.5100 - accuracy: 0.8008 - val_loss: 0.4552 - val_accuracy: 0.8259\n",
      "Epoch 601/1000\n",
      "225/225 [==============================] - 0s 2ms/step - loss: 0.5073 - accuracy: 0.8016 - val_loss: 0.4507 - val_accuracy: 0.8270\n",
      "Epoch 602/1000\n",
      "225/225 [==============================] - 0s 2ms/step - loss: 0.5067 - accuracy: 0.8023 - val_loss: 0.4508 - val_accuracy: 0.8257\n",
      "Epoch 603/1000\n",
      "225/225 [==============================] - 0s 2ms/step - loss: 0.5082 - accuracy: 0.8009 - val_loss: 0.4521 - val_accuracy: 0.8278\n",
      "Epoch 604/1000\n",
      "225/225 [==============================] - 0s 2ms/step - loss: 0.5096 - accuracy: 0.8010 - val_loss: 0.4530 - val_accuracy: 0.8283\n",
      "Epoch 605/1000\n",
      "225/225 [==============================] - 0s 2ms/step - loss: 0.5084 - accuracy: 0.8007 - val_loss: 0.4514 - val_accuracy: 0.8285\n",
      "Epoch 606/1000\n",
      "225/225 [==============================] - 0s 2ms/step - loss: 0.5075 - accuracy: 0.8020 - val_loss: 0.4500 - val_accuracy: 0.8264\n",
      "Epoch 607/1000\n",
      "225/225 [==============================] - 0s 2ms/step - loss: 0.5084 - accuracy: 0.8015 - val_loss: 0.4534 - val_accuracy: 0.8232\n",
      "Epoch 608/1000\n",
      "225/225 [==============================] - 1s 2ms/step - loss: 0.5069 - accuracy: 0.8029 - val_loss: 0.4497 - val_accuracy: 0.8271\n",
      "Epoch 609/1000\n",
      "225/225 [==============================] - 0s 2ms/step - loss: 0.5055 - accuracy: 0.8022 - val_loss: 0.4514 - val_accuracy: 0.8282\n",
      "Epoch 610/1000\n",
      "225/225 [==============================] - 0s 2ms/step - loss: 0.5061 - accuracy: 0.8019 - val_loss: 0.4522 - val_accuracy: 0.8272\n",
      "Epoch 611/1000\n",
      "225/225 [==============================] - 0s 2ms/step - loss: 0.5092 - accuracy: 0.8015 - val_loss: 0.4532 - val_accuracy: 0.8249\n",
      "Epoch 612/1000\n",
      "225/225 [==============================] - 0s 2ms/step - loss: 0.5075 - accuracy: 0.8018 - val_loss: 0.4515 - val_accuracy: 0.8282\n",
      "Epoch 613/1000\n",
      "225/225 [==============================] - 0s 2ms/step - loss: 0.5066 - accuracy: 0.8019 - val_loss: 0.4510 - val_accuracy: 0.8261\n",
      "Epoch 614/1000\n",
      "225/225 [==============================] - 1s 2ms/step - loss: 0.5086 - accuracy: 0.8007 - val_loss: 0.4513 - val_accuracy: 0.8274\n",
      "Epoch 615/1000\n",
      "225/225 [==============================] - 0s 2ms/step - loss: 0.5089 - accuracy: 0.8019 - val_loss: 0.4505 - val_accuracy: 0.8276\n",
      "Epoch 616/1000\n",
      "225/225 [==============================] - 0s 2ms/step - loss: 0.5049 - accuracy: 0.8024 - val_loss: 0.4503 - val_accuracy: 0.8267\n",
      "Epoch 617/1000\n",
      "225/225 [==============================] - 0s 2ms/step - loss: 0.5076 - accuracy: 0.8022 - val_loss: 0.4502 - val_accuracy: 0.8264\n",
      "Epoch 618/1000\n",
      "225/225 [==============================] - 0s 2ms/step - loss: 0.5079 - accuracy: 0.8019 - val_loss: 0.4516 - val_accuracy: 0.8254\n",
      "Epoch 619/1000\n",
      "225/225 [==============================] - 0s 2ms/step - loss: 0.5076 - accuracy: 0.8009 - val_loss: 0.4491 - val_accuracy: 0.8284\n",
      "Epoch 620/1000\n",
      "225/225 [==============================] - 0s 2ms/step - loss: 0.5068 - accuracy: 0.8028 - val_loss: 0.4496 - val_accuracy: 0.8273\n",
      "Epoch 621/1000\n",
      "225/225 [==============================] - 0s 2ms/step - loss: 0.5076 - accuracy: 0.8031 - val_loss: 0.4498 - val_accuracy: 0.8266\n",
      "Epoch 622/1000\n",
      "225/225 [==============================] - 0s 2ms/step - loss: 0.5093 - accuracy: 0.8013 - val_loss: 0.4497 - val_accuracy: 0.8279\n",
      "Epoch 623/1000\n",
      "225/225 [==============================] - 0s 2ms/step - loss: 0.5062 - accuracy: 0.8022 - val_loss: 0.4511 - val_accuracy: 0.8269\n",
      "Epoch 624/1000\n",
      "225/225 [==============================] - 1s 2ms/step - loss: 0.5067 - accuracy: 0.8021 - val_loss: 0.4502 - val_accuracy: 0.8291\n",
      "Epoch 625/1000\n",
      "225/225 [==============================] - 0s 2ms/step - loss: 0.5071 - accuracy: 0.8017 - val_loss: 0.4514 - val_accuracy: 0.8272\n",
      "Epoch 626/1000\n",
      "225/225 [==============================] - 0s 2ms/step - loss: 0.5085 - accuracy: 0.8013 - val_loss: 0.4496 - val_accuracy: 0.8274\n",
      "Epoch 627/1000\n",
      "225/225 [==============================] - 0s 2ms/step - loss: 0.5060 - accuracy: 0.8024 - val_loss: 0.4520 - val_accuracy: 0.8271\n",
      "Epoch 628/1000\n",
      "225/225 [==============================] - 0s 2ms/step - loss: 0.5100 - accuracy: 0.8003 - val_loss: 0.4551 - val_accuracy: 0.8238\n",
      "Epoch 629/1000\n",
      "225/225 [==============================] - 0s 2ms/step - loss: 0.5073 - accuracy: 0.8017 - val_loss: 0.4530 - val_accuracy: 0.8258\n",
      "Epoch 630/1000\n",
      "225/225 [==============================] - 0s 2ms/step - loss: 0.5071 - accuracy: 0.8025 - val_loss: 0.4513 - val_accuracy: 0.8263\n",
      "Epoch 631/1000\n",
      "225/225 [==============================] - 0s 2ms/step - loss: 0.5067 - accuracy: 0.8016 - val_loss: 0.4519 - val_accuracy: 0.8272\n",
      "Epoch 632/1000\n",
      "225/225 [==============================] - 0s 2ms/step - loss: 0.5065 - accuracy: 0.8011 - val_loss: 0.4496 - val_accuracy: 0.8286\n",
      "Epoch 633/1000\n",
      "225/225 [==============================] - 0s 2ms/step - loss: 0.5059 - accuracy: 0.8015 - val_loss: 0.4490 - val_accuracy: 0.8288\n",
      "Epoch 634/1000\n",
      "225/225 [==============================] - 0s 2ms/step - loss: 0.5079 - accuracy: 0.8022 - val_loss: 0.4496 - val_accuracy: 0.8247\n",
      "Epoch 635/1000\n",
      "225/225 [==============================] - 0s 2ms/step - loss: 0.5056 - accuracy: 0.8030 - val_loss: 0.4512 - val_accuracy: 0.8278\n",
      "Epoch 636/1000\n",
      "225/225 [==============================] - 0s 2ms/step - loss: 0.5066 - accuracy: 0.8024 - val_loss: 0.4540 - val_accuracy: 0.8269\n",
      "Epoch 637/1000\n",
      "225/225 [==============================] - 0s 2ms/step - loss: 0.5063 - accuracy: 0.8014 - val_loss: 0.4537 - val_accuracy: 0.8271\n",
      "Epoch 638/1000\n",
      "225/225 [==============================] - 0s 2ms/step - loss: 0.5084 - accuracy: 0.8010 - val_loss: 0.4535 - val_accuracy: 0.8264\n",
      "Epoch 639/1000\n",
      "225/225 [==============================] - 0s 2ms/step - loss: 0.5097 - accuracy: 0.8014 - val_loss: 0.4529 - val_accuracy: 0.8266\n",
      "Epoch 640/1000\n",
      "225/225 [==============================] - 0s 2ms/step - loss: 0.5080 - accuracy: 0.8016 - val_loss: 0.4533 - val_accuracy: 0.8273\n",
      "Epoch 641/1000\n",
      "225/225 [==============================] - 0s 2ms/step - loss: 0.5070 - accuracy: 0.8023 - val_loss: 0.4501 - val_accuracy: 0.8262\n",
      "Epoch 642/1000\n",
      "225/225 [==============================] - 0s 2ms/step - loss: 0.5069 - accuracy: 0.8009 - val_loss: 0.4491 - val_accuracy: 0.8280\n",
      "Epoch 643/1000\n",
      "225/225 [==============================] - 0s 2ms/step - loss: 0.5060 - accuracy: 0.8025 - val_loss: 0.4508 - val_accuracy: 0.8275\n",
      "Epoch 644/1000\n",
      "225/225 [==============================] - 0s 2ms/step - loss: 0.5072 - accuracy: 0.8025 - val_loss: 0.4515 - val_accuracy: 0.8257\n",
      "Epoch 645/1000\n",
      "225/225 [==============================] - 0s 2ms/step - loss: 0.5063 - accuracy: 0.8023 - val_loss: 0.4505 - val_accuracy: 0.8263\n",
      "Epoch 646/1000\n",
      "225/225 [==============================] - 0s 2ms/step - loss: 0.5058 - accuracy: 0.8014 - val_loss: 0.4494 - val_accuracy: 0.8282\n",
      "Epoch 647/1000\n",
      "225/225 [==============================] - 0s 2ms/step - loss: 0.5057 - accuracy: 0.8031 - val_loss: 0.4520 - val_accuracy: 0.8274\n",
      "Epoch 648/1000\n",
      "225/225 [==============================] - 0s 2ms/step - loss: 0.5070 - accuracy: 0.8010 - val_loss: 0.4511 - val_accuracy: 0.8272\n",
      "Epoch 649/1000\n",
      "225/225 [==============================] - 0s 2ms/step - loss: 0.5067 - accuracy: 0.8021 - val_loss: 0.4530 - val_accuracy: 0.8271\n",
      "Epoch 650/1000\n",
      "225/225 [==============================] - 0s 2ms/step - loss: 0.5049 - accuracy: 0.8028 - val_loss: 0.4483 - val_accuracy: 0.8282\n",
      "Epoch 651/1000\n",
      "225/225 [==============================] - 1s 2ms/step - loss: 0.5052 - accuracy: 0.8019 - val_loss: 0.4515 - val_accuracy: 0.8285\n",
      "Epoch 652/1000\n",
      "225/225 [==============================] - 0s 2ms/step - loss: 0.5056 - accuracy: 0.8022 - val_loss: 0.4505 - val_accuracy: 0.8289\n",
      "Epoch 653/1000\n",
      "225/225 [==============================] - 0s 2ms/step - loss: 0.5068 - accuracy: 0.8020 - val_loss: 0.4497 - val_accuracy: 0.8265\n",
      "Epoch 654/1000\n",
      "225/225 [==============================] - 0s 2ms/step - loss: 0.5066 - accuracy: 0.8016 - val_loss: 0.4502 - val_accuracy: 0.8282\n",
      "Epoch 655/1000\n",
      "225/225 [==============================] - 0s 2ms/step - loss: 0.5071 - accuracy: 0.8007 - val_loss: 0.4517 - val_accuracy: 0.8257\n",
      "Epoch 656/1000\n",
      "225/225 [==============================] - 1s 2ms/step - loss: 0.5070 - accuracy: 0.8015 - val_loss: 0.4539 - val_accuracy: 0.8275\n",
      "Epoch 657/1000\n",
      "225/225 [==============================] - 1s 2ms/step - loss: 0.5052 - accuracy: 0.8027 - val_loss: 0.4472 - val_accuracy: 0.8267\n",
      "Epoch 658/1000\n",
      "225/225 [==============================] - 1s 2ms/step - loss: 0.5072 - accuracy: 0.8017 - val_loss: 0.4497 - val_accuracy: 0.8280\n",
      "Epoch 659/1000\n",
      "225/225 [==============================] - 0s 2ms/step - loss: 0.5065 - accuracy: 0.8021 - val_loss: 0.4499 - val_accuracy: 0.8282\n",
      "Epoch 660/1000\n",
      "225/225 [==============================] - 0s 2ms/step - loss: 0.5045 - accuracy: 0.8024 - val_loss: 0.4492 - val_accuracy: 0.8270\n",
      "Epoch 661/1000\n",
      "225/225 [==============================] - 1s 3ms/step - loss: 0.5057 - accuracy: 0.8025 - val_loss: 0.4492 - val_accuracy: 0.8278\n",
      "Epoch 662/1000\n",
      "225/225 [==============================] - 0s 2ms/step - loss: 0.5052 - accuracy: 0.8033 - val_loss: 0.4463 - val_accuracy: 0.8281\n",
      "Epoch 663/1000\n",
      "225/225 [==============================] - 1s 2ms/step - loss: 0.5073 - accuracy: 0.8021 - val_loss: 0.4492 - val_accuracy: 0.8275\n",
      "Epoch 664/1000\n",
      "225/225 [==============================] - 0s 2ms/step - loss: 0.5062 - accuracy: 0.8034 - val_loss: 0.4498 - val_accuracy: 0.8271\n",
      "Epoch 665/1000\n",
      "225/225 [==============================] - 0s 2ms/step - loss: 0.5081 - accuracy: 0.8012 - val_loss: 0.4491 - val_accuracy: 0.8278\n",
      "Epoch 666/1000\n",
      "225/225 [==============================] - 1s 2ms/step - loss: 0.5057 - accuracy: 0.8023 - val_loss: 0.4494 - val_accuracy: 0.8262\n",
      "Epoch 667/1000\n",
      "225/225 [==============================] - 0s 2ms/step - loss: 0.5055 - accuracy: 0.8019 - val_loss: 0.4510 - val_accuracy: 0.8262\n",
      "Epoch 668/1000\n",
      "225/225 [==============================] - 0s 2ms/step - loss: 0.5042 - accuracy: 0.8030 - val_loss: 0.4493 - val_accuracy: 0.8283\n",
      "Epoch 669/1000\n",
      "225/225 [==============================] - 0s 2ms/step - loss: 0.5087 - accuracy: 0.8009 - val_loss: 0.4487 - val_accuracy: 0.8277\n",
      "Epoch 670/1000\n",
      "225/225 [==============================] - 0s 2ms/step - loss: 0.5079 - accuracy: 0.8012 - val_loss: 0.4482 - val_accuracy: 0.8293\n",
      "Epoch 671/1000\n",
      "225/225 [==============================] - 0s 2ms/step - loss: 0.5062 - accuracy: 0.8024 - val_loss: 0.4500 - val_accuracy: 0.8294\n",
      "Epoch 672/1000\n",
      "225/225 [==============================] - 0s 2ms/step - loss: 0.5059 - accuracy: 0.8032 - val_loss: 0.4504 - val_accuracy: 0.8293\n",
      "Epoch 673/1000\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "225/225 [==============================] - 1s 2ms/step - loss: 0.5078 - accuracy: 0.8014 - val_loss: 0.4497 - val_accuracy: 0.8306\n",
      "Epoch 674/1000\n",
      "225/225 [==============================] - 1s 2ms/step - loss: 0.5059 - accuracy: 0.8008 - val_loss: 0.4491 - val_accuracy: 0.8272\n",
      "Epoch 675/1000\n",
      "225/225 [==============================] - 0s 2ms/step - loss: 0.5061 - accuracy: 0.8032 - val_loss: 0.4515 - val_accuracy: 0.8271\n",
      "Epoch 676/1000\n",
      "225/225 [==============================] - 0s 2ms/step - loss: 0.5051 - accuracy: 0.8017 - val_loss: 0.4493 - val_accuracy: 0.8284\n",
      "Epoch 677/1000\n",
      "225/225 [==============================] - 0s 2ms/step - loss: 0.5060 - accuracy: 0.8023 - val_loss: 0.4479 - val_accuracy: 0.8286\n",
      "Epoch 678/1000\n",
      "225/225 [==============================] - 0s 2ms/step - loss: 0.5048 - accuracy: 0.8031 - val_loss: 0.4503 - val_accuracy: 0.8282\n",
      "Epoch 679/1000\n",
      "225/225 [==============================] - 0s 2ms/step - loss: 0.5055 - accuracy: 0.8029 - val_loss: 0.4488 - val_accuracy: 0.8282\n",
      "Epoch 680/1000\n",
      "225/225 [==============================] - 0s 2ms/step - loss: 0.5058 - accuracy: 0.8023 - val_loss: 0.4481 - val_accuracy: 0.8293\n",
      "Epoch 681/1000\n",
      "225/225 [==============================] - 0s 2ms/step - loss: 0.5060 - accuracy: 0.8027 - val_loss: 0.4485 - val_accuracy: 0.8297\n",
      "Epoch 682/1000\n",
      "225/225 [==============================] - 0s 2ms/step - loss: 0.5068 - accuracy: 0.8012 - val_loss: 0.4489 - val_accuracy: 0.8296\n",
      "Epoch 683/1000\n",
      "225/225 [==============================] - 0s 2ms/step - loss: 0.5069 - accuracy: 0.8026 - val_loss: 0.4484 - val_accuracy: 0.8277\n",
      "Epoch 684/1000\n",
      "225/225 [==============================] - 0s 2ms/step - loss: 0.5042 - accuracy: 0.8029 - val_loss: 0.4513 - val_accuracy: 0.8275\n",
      "Epoch 685/1000\n",
      "225/225 [==============================] - 0s 2ms/step - loss: 0.5047 - accuracy: 0.8031 - val_loss: 0.4510 - val_accuracy: 0.8266\n",
      "Epoch 686/1000\n",
      "225/225 [==============================] - 0s 2ms/step - loss: 0.5029 - accuracy: 0.8036 - val_loss: 0.4455 - val_accuracy: 0.8290\n",
      "Epoch 687/1000\n",
      "225/225 [==============================] - 0s 2ms/step - loss: 0.5052 - accuracy: 0.8015 - val_loss: 0.4487 - val_accuracy: 0.8278\n",
      "Epoch 688/1000\n",
      "225/225 [==============================] - 1s 2ms/step - loss: 0.5044 - accuracy: 0.8024 - val_loss: 0.4497 - val_accuracy: 0.8288\n",
      "Epoch 689/1000\n",
      "225/225 [==============================] - 1s 3ms/step - loss: 0.5063 - accuracy: 0.8030 - val_loss: 0.4491 - val_accuracy: 0.8300\n",
      "Epoch 690/1000\n",
      "225/225 [==============================] - 0s 2ms/step - loss: 0.5040 - accuracy: 0.8028 - val_loss: 0.4484 - val_accuracy: 0.8284\n",
      "Epoch 691/1000\n",
      "225/225 [==============================] - 0s 2ms/step - loss: 0.5038 - accuracy: 0.8039 - val_loss: 0.4480 - val_accuracy: 0.8299\n",
      "Epoch 692/1000\n",
      "225/225 [==============================] - 0s 2ms/step - loss: 0.5052 - accuracy: 0.8022 - val_loss: 0.4476 - val_accuracy: 0.8296\n",
      "Epoch 693/1000\n",
      "225/225 [==============================] - 0s 2ms/step - loss: 0.5052 - accuracy: 0.8038 - val_loss: 0.4500 - val_accuracy: 0.8280\n",
      "Epoch 694/1000\n",
      "225/225 [==============================] - 0s 2ms/step - loss: 0.5059 - accuracy: 0.8018 - val_loss: 0.4509 - val_accuracy: 0.8289\n",
      "Epoch 695/1000\n",
      "225/225 [==============================] - 0s 2ms/step - loss: 0.5075 - accuracy: 0.8017 - val_loss: 0.4472 - val_accuracy: 0.8303\n",
      "Epoch 696/1000\n",
      "225/225 [==============================] - 0s 2ms/step - loss: 0.5035 - accuracy: 0.8032 - val_loss: 0.4505 - val_accuracy: 0.8282\n",
      "Epoch 697/1000\n",
      "225/225 [==============================] - 0s 2ms/step - loss: 0.5057 - accuracy: 0.8034 - val_loss: 0.4474 - val_accuracy: 0.8293\n",
      "Epoch 698/1000\n",
      "225/225 [==============================] - 0s 2ms/step - loss: 0.5057 - accuracy: 0.8021 - val_loss: 0.4496 - val_accuracy: 0.8270\n",
      "Epoch 699/1000\n",
      "225/225 [==============================] - 0s 2ms/step - loss: 0.5076 - accuracy: 0.8028 - val_loss: 0.4477 - val_accuracy: 0.8298\n",
      "Epoch 700/1000\n",
      "225/225 [==============================] - 0s 2ms/step - loss: 0.5062 - accuracy: 0.8025 - val_loss: 0.4512 - val_accuracy: 0.8275\n",
      "Epoch 701/1000\n",
      "225/225 [==============================] - 0s 2ms/step - loss: 0.5058 - accuracy: 0.8031 - val_loss: 0.4509 - val_accuracy: 0.8283\n",
      "Epoch 702/1000\n",
      "225/225 [==============================] - 0s 2ms/step - loss: 0.5055 - accuracy: 0.8030 - val_loss: 0.4544 - val_accuracy: 0.8260\n",
      "Epoch 703/1000\n",
      "225/225 [==============================] - 0s 2ms/step - loss: 0.5055 - accuracy: 0.8025 - val_loss: 0.4523 - val_accuracy: 0.8266\n",
      "Epoch 704/1000\n",
      "225/225 [==============================] - 0s 2ms/step - loss: 0.5057 - accuracy: 0.8024 - val_loss: 0.4486 - val_accuracy: 0.8296\n",
      "Epoch 705/1000\n",
      "225/225 [==============================] - 0s 2ms/step - loss: 0.5076 - accuracy: 0.8017 - val_loss: 0.4511 - val_accuracy: 0.8285\n",
      "Epoch 706/1000\n",
      "225/225 [==============================] - 0s 2ms/step - loss: 0.5062 - accuracy: 0.8033 - val_loss: 0.4485 - val_accuracy: 0.8293\n",
      "Epoch 707/1000\n",
      "225/225 [==============================] - 0s 2ms/step - loss: 0.5056 - accuracy: 0.8026 - val_loss: 0.4519 - val_accuracy: 0.8286\n",
      "Epoch 708/1000\n",
      "225/225 [==============================] - 0s 2ms/step - loss: 0.5036 - accuracy: 0.8025 - val_loss: 0.4519 - val_accuracy: 0.8271\n",
      "Epoch 709/1000\n",
      "225/225 [==============================] - 0s 2ms/step - loss: 0.5043 - accuracy: 0.8031 - val_loss: 0.4498 - val_accuracy: 0.8282\n",
      "Epoch 710/1000\n",
      "225/225 [==============================] - 0s 2ms/step - loss: 0.5047 - accuracy: 0.8029 - val_loss: 0.4490 - val_accuracy: 0.8290\n",
      "Epoch 711/1000\n",
      "225/225 [==============================] - 0s 2ms/step - loss: 0.5039 - accuracy: 0.8044 - val_loss: 0.4491 - val_accuracy: 0.8285\n",
      "Epoch 712/1000\n",
      "225/225 [==============================] - 0s 2ms/step - loss: 0.5071 - accuracy: 0.8013 - val_loss: 0.4515 - val_accuracy: 0.8271\n",
      "Epoch 713/1000\n",
      "225/225 [==============================] - 0s 2ms/step - loss: 0.5059 - accuracy: 0.8025 - val_loss: 0.4480 - val_accuracy: 0.8273\n",
      "Epoch 714/1000\n",
      "225/225 [==============================] - 0s 2ms/step - loss: 0.5038 - accuracy: 0.8039 - val_loss: 0.4474 - val_accuracy: 0.8304\n",
      "Epoch 715/1000\n",
      "225/225 [==============================] - 0s 2ms/step - loss: 0.5052 - accuracy: 0.8029 - val_loss: 0.4462 - val_accuracy: 0.8311\n",
      "Epoch 716/1000\n",
      "225/225 [==============================] - 0s 2ms/step - loss: 0.5040 - accuracy: 0.8037 - val_loss: 0.4485 - val_accuracy: 0.8304\n",
      "Epoch 717/1000\n",
      "225/225 [==============================] - 0s 2ms/step - loss: 0.5051 - accuracy: 0.8032 - val_loss: 0.4499 - val_accuracy: 0.8303\n",
      "Epoch 718/1000\n",
      "225/225 [==============================] - 1s 2ms/step - loss: 0.5056 - accuracy: 0.8035 - val_loss: 0.4501 - val_accuracy: 0.8296\n",
      "Epoch 719/1000\n",
      "225/225 [==============================] - 0s 2ms/step - loss: 0.5053 - accuracy: 0.8033 - val_loss: 0.4454 - val_accuracy: 0.8307\n",
      "Epoch 720/1000\n",
      "225/225 [==============================] - 0s 2ms/step - loss: 0.5072 - accuracy: 0.8026 - val_loss: 0.4494 - val_accuracy: 0.8279\n",
      "Epoch 721/1000\n",
      "225/225 [==============================] - 1s 2ms/step - loss: 0.5048 - accuracy: 0.8037 - val_loss: 0.4510 - val_accuracy: 0.8261\n",
      "Epoch 722/1000\n",
      "225/225 [==============================] - 0s 2ms/step - loss: 0.5033 - accuracy: 0.8038 - val_loss: 0.4512 - val_accuracy: 0.8280\n",
      "Epoch 723/1000\n",
      "225/225 [==============================] - 0s 2ms/step - loss: 0.5039 - accuracy: 0.8029 - val_loss: 0.4469 - val_accuracy: 0.8287\n",
      "Epoch 724/1000\n",
      "225/225 [==============================] - 0s 2ms/step - loss: 0.5044 - accuracy: 0.8026 - val_loss: 0.4483 - val_accuracy: 0.8252\n",
      "Epoch 725/1000\n",
      "225/225 [==============================] - 0s 2ms/step - loss: 0.5050 - accuracy: 0.8027 - val_loss: 0.4511 - val_accuracy: 0.8278\n",
      "Epoch 726/1000\n",
      "225/225 [==============================] - 0s 2ms/step - loss: 0.5052 - accuracy: 0.8022 - val_loss: 0.4473 - val_accuracy: 0.8290\n",
      "Epoch 727/1000\n",
      "225/225 [==============================] - 1s 2ms/step - loss: 0.5026 - accuracy: 0.8036 - val_loss: 0.4484 - val_accuracy: 0.8267\n",
      "Epoch 728/1000\n",
      "225/225 [==============================] - 0s 2ms/step - loss: 0.5050 - accuracy: 0.8040 - val_loss: 0.4491 - val_accuracy: 0.8271\n",
      "Epoch 729/1000\n",
      "225/225 [==============================] - 0s 2ms/step - loss: 0.5033 - accuracy: 0.8030 - val_loss: 0.4475 - val_accuracy: 0.8293\n",
      "Epoch 730/1000\n",
      "225/225 [==============================] - 0s 2ms/step - loss: 0.5044 - accuracy: 0.8026 - val_loss: 0.4494 - val_accuracy: 0.8272\n",
      "Epoch 731/1000\n",
      "225/225 [==============================] - 0s 2ms/step - loss: 0.5032 - accuracy: 0.8037 - val_loss: 0.4486 - val_accuracy: 0.8275\n",
      "Epoch 732/1000\n",
      "225/225 [==============================] - 0s 2ms/step - loss: 0.5051 - accuracy: 0.8028 - val_loss: 0.4491 - val_accuracy: 0.8271\n",
      "Epoch 733/1000\n",
      "225/225 [==============================] - 0s 2ms/step - loss: 0.5040 - accuracy: 0.8024 - val_loss: 0.4462 - val_accuracy: 0.8280\n",
      "Epoch 734/1000\n",
      "225/225 [==============================] - 1s 2ms/step - loss: 0.5030 - accuracy: 0.8027 - val_loss: 0.4487 - val_accuracy: 0.8285\n",
      "Epoch 735/1000\n",
      "225/225 [==============================] - 1s 2ms/step - loss: 0.5054 - accuracy: 0.8030 - val_loss: 0.4485 - val_accuracy: 0.8273\n",
      "Epoch 736/1000\n",
      "225/225 [==============================] - 1s 2ms/step - loss: 0.5018 - accuracy: 0.8039 - val_loss: 0.4484 - val_accuracy: 0.8282\n",
      "Epoch 737/1000\n",
      "225/225 [==============================] - 1s 2ms/step - loss: 0.5048 - accuracy: 0.8033 - val_loss: 0.4531 - val_accuracy: 0.8250\n",
      "Epoch 738/1000\n",
      "225/225 [==============================] - 0s 2ms/step - loss: 0.5039 - accuracy: 0.8029 - val_loss: 0.4508 - val_accuracy: 0.8290\n",
      "Epoch 739/1000\n",
      "225/225 [==============================] - 1s 2ms/step - loss: 0.5024 - accuracy: 0.8032 - val_loss: 0.4479 - val_accuracy: 0.8297\n",
      "Epoch 740/1000\n",
      "225/225 [==============================] - 0s 2ms/step - loss: 0.5037 - accuracy: 0.8030 - val_loss: 0.4484 - val_accuracy: 0.8281\n",
      "Epoch 741/1000\n",
      "225/225 [==============================] - 0s 2ms/step - loss: 0.5043 - accuracy: 0.8032 - val_loss: 0.4498 - val_accuracy: 0.8275\n",
      "Epoch 742/1000\n",
      "225/225 [==============================] - 0s 2ms/step - loss: 0.5038 - accuracy: 0.8026 - val_loss: 0.4503 - val_accuracy: 0.8281\n",
      "Epoch 743/1000\n",
      "225/225 [==============================] - 0s 2ms/step - loss: 0.5055 - accuracy: 0.8017 - val_loss: 0.4492 - val_accuracy: 0.8268\n",
      "Epoch 744/1000\n",
      "225/225 [==============================] - 0s 2ms/step - loss: 0.5047 - accuracy: 0.8037 - val_loss: 0.4481 - val_accuracy: 0.8288\n",
      "Epoch 745/1000\n",
      "225/225 [==============================] - 1s 2ms/step - loss: 0.5017 - accuracy: 0.8027 - val_loss: 0.4475 - val_accuracy: 0.8304\n",
      "Epoch 746/1000\n",
      "225/225 [==============================] - 1s 2ms/step - loss: 0.5042 - accuracy: 0.8029 - val_loss: 0.4494 - val_accuracy: 0.8283\n",
      "Epoch 747/1000\n",
      "225/225 [==============================] - 1s 2ms/step - loss: 0.5030 - accuracy: 0.8035 - val_loss: 0.4491 - val_accuracy: 0.8304\n",
      "Epoch 748/1000\n",
      "225/225 [==============================] - 1s 2ms/step - loss: 0.5027 - accuracy: 0.8032 - val_loss: 0.4478 - val_accuracy: 0.8280\n",
      "Epoch 749/1000\n",
      "225/225 [==============================] - 1s 2ms/step - loss: 0.5047 - accuracy: 0.8023 - val_loss: 0.4485 - val_accuracy: 0.8288\n",
      "Epoch 750/1000\n",
      "225/225 [==============================] - 1s 2ms/step - loss: 0.5031 - accuracy: 0.8031 - val_loss: 0.4482 - val_accuracy: 0.8300\n",
      "Epoch 751/1000\n",
      "225/225 [==============================] - 0s 2ms/step - loss: 0.5038 - accuracy: 0.8032 - val_loss: 0.4483 - val_accuracy: 0.8311\n",
      "Epoch 752/1000\n",
      "225/225 [==============================] - 0s 2ms/step - loss: 0.5037 - accuracy: 0.8029 - val_loss: 0.4482 - val_accuracy: 0.8269\n",
      "Epoch 753/1000\n",
      "225/225 [==============================] - 1s 2ms/step - loss: 0.5029 - accuracy: 0.8037 - val_loss: 0.4465 - val_accuracy: 0.8314\n",
      "Epoch 754/1000\n",
      "225/225 [==============================] - 1s 2ms/step - loss: 0.5027 - accuracy: 0.8040 - val_loss: 0.4482 - val_accuracy: 0.8300\n",
      "Epoch 755/1000\n",
      "225/225 [==============================] - 1s 2ms/step - loss: 0.5033 - accuracy: 0.8039 - val_loss: 0.4504 - val_accuracy: 0.8271\n",
      "Epoch 756/1000\n",
      "225/225 [==============================] - 1s 2ms/step - loss: 0.5049 - accuracy: 0.8033 - val_loss: 0.4497 - val_accuracy: 0.8286\n",
      "Epoch 757/1000\n",
      "225/225 [==============================] - 1s 2ms/step - loss: 0.5033 - accuracy: 0.8034 - val_loss: 0.4475 - val_accuracy: 0.8271\n",
      "Epoch 758/1000\n",
      "225/225 [==============================] - 0s 2ms/step - loss: 0.5043 - accuracy: 0.8036 - val_loss: 0.4446 - val_accuracy: 0.8309\n",
      "Epoch 759/1000\n",
      "225/225 [==============================] - 0s 2ms/step - loss: 0.5031 - accuracy: 0.8031 - val_loss: 0.4487 - val_accuracy: 0.8264\n",
      "Epoch 760/1000\n",
      "225/225 [==============================] - 0s 2ms/step - loss: 0.5033 - accuracy: 0.8042 - val_loss: 0.4483 - val_accuracy: 0.8297\n",
      "Epoch 761/1000\n",
      "225/225 [==============================] - 0s 2ms/step - loss: 0.5058 - accuracy: 0.8019 - val_loss: 0.4478 - val_accuracy: 0.8296\n",
      "Epoch 762/1000\n",
      "225/225 [==============================] - 0s 2ms/step - loss: 0.5059 - accuracy: 0.8029 - val_loss: 0.4491 - val_accuracy: 0.8290\n",
      "Epoch 763/1000\n",
      "225/225 [==============================] - 0s 2ms/step - loss: 0.5035 - accuracy: 0.8049 - val_loss: 0.4486 - val_accuracy: 0.8275\n",
      "Epoch 764/1000\n",
      "225/225 [==============================] - 0s 2ms/step - loss: 0.5029 - accuracy: 0.8051 - val_loss: 0.4490 - val_accuracy: 0.8282\n",
      "Epoch 765/1000\n",
      "225/225 [==============================] - 0s 2ms/step - loss: 0.5021 - accuracy: 0.8041 - val_loss: 0.4469 - val_accuracy: 0.8282\n",
      "Epoch 766/1000\n",
      "225/225 [==============================] - 1s 2ms/step - loss: 0.5062 - accuracy: 0.8014 - val_loss: 0.4472 - val_accuracy: 0.8290\n",
      "Epoch 767/1000\n",
      "225/225 [==============================] - 1s 2ms/step - loss: 0.5035 - accuracy: 0.8026 - val_loss: 0.4504 - val_accuracy: 0.8276\n",
      "Epoch 768/1000\n",
      "225/225 [==============================] - 0s 2ms/step - loss: 0.5032 - accuracy: 0.8028 - val_loss: 0.4490 - val_accuracy: 0.8285\n",
      "Epoch 769/1000\n",
      "225/225 [==============================] - 0s 2ms/step - loss: 0.5026 - accuracy: 0.8035 - val_loss: 0.4487 - val_accuracy: 0.8271\n",
      "Epoch 770/1000\n",
      "225/225 [==============================] - 0s 2ms/step - loss: 0.5054 - accuracy: 0.8025 - val_loss: 0.4466 - val_accuracy: 0.8289\n",
      "Epoch 771/1000\n",
      "225/225 [==============================] - 0s 2ms/step - loss: 0.5036 - accuracy: 0.8033 - val_loss: 0.4480 - val_accuracy: 0.8292\n",
      "Epoch 772/1000\n",
      "225/225 [==============================] - 1s 2ms/step - loss: 0.5047 - accuracy: 0.8043 - val_loss: 0.4487 - val_accuracy: 0.8285\n",
      "Epoch 773/1000\n",
      "225/225 [==============================] - 1s 2ms/step - loss: 0.5016 - accuracy: 0.8044 - val_loss: 0.4488 - val_accuracy: 0.8292\n",
      "Epoch 774/1000\n",
      "225/225 [==============================] - 0s 2ms/step - loss: 0.5061 - accuracy: 0.8016 - val_loss: 0.4499 - val_accuracy: 0.8286\n",
      "Epoch 775/1000\n",
      "225/225 [==============================] - 0s 2ms/step - loss: 0.5033 - accuracy: 0.8044 - val_loss: 0.4479 - val_accuracy: 0.8284\n",
      "Epoch 776/1000\n",
      "225/225 [==============================] - 0s 2ms/step - loss: 0.5022 - accuracy: 0.8054 - val_loss: 0.4481 - val_accuracy: 0.8282\n",
      "Epoch 777/1000\n",
      "225/225 [==============================] - 0s 2ms/step - loss: 0.5032 - accuracy: 0.8041 - val_loss: 0.4501 - val_accuracy: 0.8286\n",
      "Epoch 778/1000\n",
      "225/225 [==============================] - 0s 2ms/step - loss: 0.5044 - accuracy: 0.8033 - val_loss: 0.4477 - val_accuracy: 0.8279\n",
      "Epoch 779/1000\n",
      "225/225 [==============================] - 0s 2ms/step - loss: 0.5029 - accuracy: 0.8032 - val_loss: 0.4474 - val_accuracy: 0.8296\n",
      "Epoch 780/1000\n",
      "225/225 [==============================] - 0s 2ms/step - loss: 0.5063 - accuracy: 0.8030 - val_loss: 0.4497 - val_accuracy: 0.8274\n",
      "Epoch 781/1000\n",
      "225/225 [==============================] - 0s 2ms/step - loss: 0.5065 - accuracy: 0.8021 - val_loss: 0.4493 - val_accuracy: 0.8289\n",
      "Epoch 782/1000\n",
      "225/225 [==============================] - 0s 2ms/step - loss: 0.5039 - accuracy: 0.8037 - val_loss: 0.4483 - val_accuracy: 0.8293\n",
      "Epoch 783/1000\n",
      "225/225 [==============================] - 1s 2ms/step - loss: 0.5021 - accuracy: 0.8038 - val_loss: 0.4495 - val_accuracy: 0.8285\n",
      "Epoch 784/1000\n",
      "225/225 [==============================] - 1s 2ms/step - loss: 0.5013 - accuracy: 0.8044 - val_loss: 0.4478 - val_accuracy: 0.8286\n",
      "Epoch 785/1000\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "225/225 [==============================] - 1s 2ms/step - loss: 0.5050 - accuracy: 0.8039 - val_loss: 0.4501 - val_accuracy: 0.8257\n",
      "Epoch 786/1000\n",
      "225/225 [==============================] - 1s 2ms/step - loss: 0.5022 - accuracy: 0.8038 - val_loss: 0.4481 - val_accuracy: 0.8289\n",
      "Epoch 787/1000\n",
      "225/225 [==============================] - 0s 2ms/step - loss: 0.5029 - accuracy: 0.8037 - val_loss: 0.4476 - val_accuracy: 0.8289\n",
      "Epoch 788/1000\n",
      "225/225 [==============================] - 1s 2ms/step - loss: 0.5039 - accuracy: 0.8035 - val_loss: 0.4478 - val_accuracy: 0.8291\n",
      "Epoch 789/1000\n",
      "225/225 [==============================] - 1s 2ms/step - loss: 0.5023 - accuracy: 0.8041 - val_loss: 0.4514 - val_accuracy: 0.8285\n",
      "Epoch 790/1000\n",
      "225/225 [==============================] - 1s 2ms/step - loss: 0.5018 - accuracy: 0.8035 - val_loss: 0.4471 - val_accuracy: 0.8311\n",
      "Epoch 791/1000\n",
      "225/225 [==============================] - 1s 2ms/step - loss: 0.5039 - accuracy: 0.8029 - val_loss: 0.4479 - val_accuracy: 0.8289\n",
      "Epoch 792/1000\n",
      "225/225 [==============================] - 1s 2ms/step - loss: 0.5033 - accuracy: 0.8036 - val_loss: 0.4458 - val_accuracy: 0.8282\n",
      "Epoch 793/1000\n",
      "225/225 [==============================] - 0s 2ms/step - loss: 0.5041 - accuracy: 0.8027 - val_loss: 0.4452 - val_accuracy: 0.8311\n",
      "Epoch 794/1000\n",
      "225/225 [==============================] - 1s 2ms/step - loss: 0.5047 - accuracy: 0.8034 - val_loss: 0.4466 - val_accuracy: 0.8284\n",
      "Epoch 795/1000\n",
      "225/225 [==============================] - 1s 2ms/step - loss: 0.5019 - accuracy: 0.8036 - val_loss: 0.4465 - val_accuracy: 0.8283\n",
      "Epoch 796/1000\n",
      "225/225 [==============================] - 1s 2ms/step - loss: 0.5057 - accuracy: 0.8030 - val_loss: 0.4478 - val_accuracy: 0.8275\n",
      "Epoch 797/1000\n",
      "225/225 [==============================] - 1s 2ms/step - loss: 0.5034 - accuracy: 0.8037 - val_loss: 0.4484 - val_accuracy: 0.8301\n",
      "Epoch 798/1000\n",
      "225/225 [==============================] - 1s 2ms/step - loss: 0.5017 - accuracy: 0.8048 - val_loss: 0.4496 - val_accuracy: 0.8275\n",
      "Epoch 799/1000\n",
      "225/225 [==============================] - 1s 2ms/step - loss: 0.5042 - accuracy: 0.8033 - val_loss: 0.4472 - val_accuracy: 0.8290\n",
      "Epoch 800/1000\n",
      "225/225 [==============================] - 0s 2ms/step - loss: 0.5014 - accuracy: 0.8047 - val_loss: 0.4468 - val_accuracy: 0.8295\n",
      "Epoch 801/1000\n",
      "225/225 [==============================] - 1s 2ms/step - loss: 0.5045 - accuracy: 0.8041 - val_loss: 0.4488 - val_accuracy: 0.8256\n",
      "Epoch 802/1000\n",
      "225/225 [==============================] - 0s 2ms/step - loss: 0.5043 - accuracy: 0.8037 - val_loss: 0.4472 - val_accuracy: 0.8300\n",
      "Epoch 803/1000\n",
      "225/225 [==============================] - 0s 2ms/step - loss: 0.5048 - accuracy: 0.8030 - val_loss: 0.4466 - val_accuracy: 0.8304\n",
      "Epoch 804/1000\n",
      "225/225 [==============================] - 0s 2ms/step - loss: 0.5038 - accuracy: 0.8033 - val_loss: 0.4498 - val_accuracy: 0.8264\n",
      "Epoch 805/1000\n",
      "225/225 [==============================] - 0s 2ms/step - loss: 0.5032 - accuracy: 0.8032 - val_loss: 0.4468 - val_accuracy: 0.8281\n",
      "Epoch 806/1000\n",
      "225/225 [==============================] - 0s 2ms/step - loss: 0.5036 - accuracy: 0.8041 - val_loss: 0.4453 - val_accuracy: 0.8297\n",
      "Epoch 807/1000\n",
      "225/225 [==============================] - 0s 2ms/step - loss: 0.5014 - accuracy: 0.8049 - val_loss: 0.4487 - val_accuracy: 0.8269\n",
      "Epoch 808/1000\n",
      "225/225 [==============================] - 0s 2ms/step - loss: 0.5032 - accuracy: 0.8031 - val_loss: 0.4455 - val_accuracy: 0.8299\n",
      "Epoch 809/1000\n",
      "225/225 [==============================] - 0s 2ms/step - loss: 0.5029 - accuracy: 0.8038 - val_loss: 0.4450 - val_accuracy: 0.8298\n",
      "Epoch 810/1000\n",
      "225/225 [==============================] - 0s 2ms/step - loss: 0.5040 - accuracy: 0.8031 - val_loss: 0.4477 - val_accuracy: 0.8288\n",
      "Epoch 811/1000\n",
      "225/225 [==============================] - 0s 2ms/step - loss: 0.5034 - accuracy: 0.8032 - val_loss: 0.4474 - val_accuracy: 0.8292\n",
      "Epoch 812/1000\n",
      "225/225 [==============================] - 0s 2ms/step - loss: 0.5034 - accuracy: 0.8043 - val_loss: 0.4465 - val_accuracy: 0.8283\n",
      "Epoch 813/1000\n",
      "225/225 [==============================] - 0s 2ms/step - loss: 0.5009 - accuracy: 0.8045 - val_loss: 0.4462 - val_accuracy: 0.8293\n",
      "Epoch 814/1000\n",
      "225/225 [==============================] - 0s 2ms/step - loss: 0.5041 - accuracy: 0.8035 - val_loss: 0.4485 - val_accuracy: 0.8282\n",
      "Epoch 815/1000\n",
      "225/225 [==============================] - 0s 2ms/step - loss: 0.5030 - accuracy: 0.8041 - val_loss: 0.4470 - val_accuracy: 0.8286\n",
      "Epoch 816/1000\n",
      "225/225 [==============================] - 1s 2ms/step - loss: 0.5020 - accuracy: 0.8035 - val_loss: 0.4464 - val_accuracy: 0.8285\n",
      "Epoch 817/1000\n",
      "225/225 [==============================] - 1s 2ms/step - loss: 0.5032 - accuracy: 0.8032 - val_loss: 0.4478 - val_accuracy: 0.8275\n",
      "Epoch 818/1000\n",
      "225/225 [==============================] - 1s 2ms/step - loss: 0.5035 - accuracy: 0.8038 - val_loss: 0.4474 - val_accuracy: 0.8305\n",
      "Epoch 819/1000\n",
      "225/225 [==============================] - 1s 2ms/step - loss: 0.5031 - accuracy: 0.8041 - val_loss: 0.4491 - val_accuracy: 0.8274\n",
      "Epoch 820/1000\n",
      "225/225 [==============================] - 1s 2ms/step - loss: 0.5042 - accuracy: 0.8034 - val_loss: 0.4483 - val_accuracy: 0.8276\n",
      "Epoch 821/1000\n",
      "225/225 [==============================] - 0s 2ms/step - loss: 0.5039 - accuracy: 0.8037 - val_loss: 0.4482 - val_accuracy: 0.8278\n",
      "Epoch 822/1000\n",
      "225/225 [==============================] - 0s 2ms/step - loss: 0.5033 - accuracy: 0.8034 - val_loss: 0.4483 - val_accuracy: 0.8288\n",
      "Epoch 823/1000\n",
      "225/225 [==============================] - 0s 2ms/step - loss: 0.5047 - accuracy: 0.8044 - val_loss: 0.4478 - val_accuracy: 0.8286\n",
      "Epoch 824/1000\n",
      "225/225 [==============================] - 0s 2ms/step - loss: 0.5039 - accuracy: 0.8039 - val_loss: 0.4452 - val_accuracy: 0.8303\n",
      "Epoch 825/1000\n",
      "225/225 [==============================] - 1s 2ms/step - loss: 0.5022 - accuracy: 0.8040 - val_loss: 0.4454 - val_accuracy: 0.8293\n",
      "Epoch 826/1000\n",
      "225/225 [==============================] - 1s 2ms/step - loss: 0.5038 - accuracy: 0.8047 - val_loss: 0.4483 - val_accuracy: 0.8289\n",
      "Epoch 827/1000\n",
      "225/225 [==============================] - 1s 2ms/step - loss: 0.5028 - accuracy: 0.8038 - val_loss: 0.4503 - val_accuracy: 0.8274\n",
      "Epoch 828/1000\n",
      "225/225 [==============================] - 1s 2ms/step - loss: 0.5016 - accuracy: 0.8033 - val_loss: 0.4471 - val_accuracy: 0.8288\n",
      "Epoch 829/1000\n",
      "225/225 [==============================] - 1s 2ms/step - loss: 0.5023 - accuracy: 0.8046 - val_loss: 0.4477 - val_accuracy: 0.8288\n",
      "Epoch 830/1000\n",
      "225/225 [==============================] - 0s 2ms/step - loss: 0.5016 - accuracy: 0.8046 - val_loss: 0.4484 - val_accuracy: 0.8289\n",
      "Epoch 831/1000\n",
      "225/225 [==============================] - 1s 2ms/step - loss: 0.5028 - accuracy: 0.8031 - val_loss: 0.4498 - val_accuracy: 0.8267\n",
      "Epoch 832/1000\n",
      "225/225 [==============================] - 1s 2ms/step - loss: 0.5037 - accuracy: 0.8043 - val_loss: 0.4477 - val_accuracy: 0.8288\n",
      "Epoch 833/1000\n",
      "225/225 [==============================] - 1s 2ms/step - loss: 0.5029 - accuracy: 0.8033 - val_loss: 0.4482 - val_accuracy: 0.8260\n",
      "Epoch 834/1000\n",
      "225/225 [==============================] - 1s 2ms/step - loss: 0.5052 - accuracy: 0.8026 - val_loss: 0.4461 - val_accuracy: 0.8299\n",
      "Epoch 835/1000\n",
      "225/225 [==============================] - 0s 2ms/step - loss: 0.5036 - accuracy: 0.8044 - val_loss: 0.4507 - val_accuracy: 0.8251\n",
      "Epoch 836/1000\n",
      "225/225 [==============================] - 1s 2ms/step - loss: 0.5006 - accuracy: 0.8054 - val_loss: 0.4498 - val_accuracy: 0.8275\n",
      "Epoch 837/1000\n",
      "225/225 [==============================] - 1s 2ms/step - loss: 0.5018 - accuracy: 0.8042 - val_loss: 0.4466 - val_accuracy: 0.8284\n",
      "Epoch 838/1000\n",
      "225/225 [==============================] - 0s 2ms/step - loss: 0.5031 - accuracy: 0.8042 - val_loss: 0.4466 - val_accuracy: 0.8289\n",
      "Epoch 839/1000\n",
      "225/225 [==============================] - 0s 2ms/step - loss: 0.5012 - accuracy: 0.8046 - val_loss: 0.4458 - val_accuracy: 0.8301\n",
      "Epoch 840/1000\n",
      "225/225 [==============================] - 1s 2ms/step - loss: 0.5013 - accuracy: 0.8047 - val_loss: 0.4464 - val_accuracy: 0.8286\n",
      "Epoch 841/1000\n",
      "225/225 [==============================] - 1s 2ms/step - loss: 0.5022 - accuracy: 0.8037 - val_loss: 0.4496 - val_accuracy: 0.8265\n",
      "Epoch 842/1000\n",
      "225/225 [==============================] - 1s 2ms/step - loss: 0.5020 - accuracy: 0.8036 - val_loss: 0.4473 - val_accuracy: 0.8282\n",
      "Epoch 843/1000\n",
      "225/225 [==============================] - 1s 2ms/step - loss: 0.5030 - accuracy: 0.8029 - val_loss: 0.4475 - val_accuracy: 0.8282\n",
      "Epoch 844/1000\n",
      "225/225 [==============================] - 1s 2ms/step - loss: 0.5018 - accuracy: 0.8040 - val_loss: 0.4465 - val_accuracy: 0.8276\n",
      "Epoch 845/1000\n",
      "225/225 [==============================] - 1s 3ms/step - loss: 0.5030 - accuracy: 0.8041 - val_loss: 0.4474 - val_accuracy: 0.8292\n",
      "Epoch 846/1000\n",
      "225/225 [==============================] - 1s 2ms/step - loss: 0.5023 - accuracy: 0.8040 - val_loss: 0.4494 - val_accuracy: 0.8273\n",
      "Epoch 847/1000\n",
      "225/225 [==============================] - 1s 2ms/step - loss: 0.5049 - accuracy: 0.8029 - val_loss: 0.4473 - val_accuracy: 0.8277\n",
      "Epoch 848/1000\n",
      "225/225 [==============================] - 1s 2ms/step - loss: 0.5038 - accuracy: 0.8037 - val_loss: 0.4458 - val_accuracy: 0.8293\n",
      "Epoch 848: early stopping\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "<keras.src.callbacks.History at 0x147a514e0>"
      ]
     },
     "execution_count": 180,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "model=Sequential()\n",
    "model.add(Dense(128, input_dim=X_train.shape[1], activation=\"relu\"))\n",
    "model.add(Dropout(0.2))\n",
    "model.add(Dense(128, activation=\"relu\"))\n",
    "model.add(Dropout(0.2))\n",
    "model.add(Dense(64, activation=\"relu\"))\n",
    "model.add(Dropout(0.2))\n",
    "model.add(Dense(64, activation=\"relu\"))\n",
    "model.add(Dropout(0.2))\n",
    "model.add(Dense(32, activation=\"relu\"))\n",
    "model.add(Dropout(0.2))\n",
    "model.add(Dense(3, activation=\"softmax\"))\n",
    "\n",
    "model.compile(loss='categorical_crossentropy', optimizer=Adam(learning_rate=0.001), metrics=['accuracy'])\n",
    "\n",
    "es=EarlyStopping(monitor=\"val_loss\",patience=90,mode=\"auto\",verbose=1)\n",
    "\n",
    "model.fit(X_train,\n",
    "          y_train,\n",
    "          epochs=1000,\n",
    "               batch_size=512,\n",
    "               validation_split=0.1,\n",
    "               verbose=1,callbacks=[es])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 181,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "997/997 [==============================] - 0s 256us/step\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0       0.83      0.93      0.88     10867\n",
      "           1       0.83      0.88      0.85     10432\n",
      "           2       0.82      0.67      0.74     10591\n",
      "\n",
      "    accuracy                           0.83     31890\n",
      "   macro avg       0.83      0.83      0.82     31890\n",
      "weighted avg       0.83      0.83      0.82     31890\n",
      "\n"
     ]
    }
   ],
   "source": [
    "y_pred = model.predict(X_test)\n",
    "y_pred_classes = np.argmax(y_pred, axis=1)\n",
    "y_true = np.argmax(y_test, axis=1)\n",
    "print(classification_report(y_true, y_pred_classes))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 182,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "3987/3987 [==============================] - 1s 254us/step\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0       0.86      0.95      0.90     42282\n",
      "           1       0.84      0.90      0.87     42717\n",
      "           2       0.85      0.70      0.77     42558\n",
      "\n",
      "    accuracy                           0.85    127557\n",
      "   macro avg       0.85      0.85      0.85    127557\n",
      "weighted avg       0.85      0.85      0.85    127557\n",
      "\n"
     ]
    }
   ],
   "source": [
    "y_t_pred = model.predict(X_train)\n",
    "y_t_pred_classes = np.argmax(y_t_pred, axis=1)\n",
    "y_t_true = np.argmax(y_train, axis=1)\n",
    "print(classification_report(y_t_true, y_t_pred_classes))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 183,
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 1/1000\n",
      "225/225 [==============================] - 0s 1ms/step - loss: 0.7667 - accuracy: 0.6956 - val_loss: 0.6835 - val_accuracy: 0.7320\n",
      "Epoch 2/1000\n",
      "225/225 [==============================] - 0s 1ms/step - loss: 0.6965 - accuracy: 0.7301 - val_loss: 0.6641 - val_accuracy: 0.7390\n",
      "Epoch 3/1000\n",
      "225/225 [==============================] - 0s 1ms/step - loss: 0.6821 - accuracy: 0.7350 - val_loss: 0.6547 - val_accuracy: 0.7416\n",
      "Epoch 4/1000\n",
      "225/225 [==============================] - 0s 1ms/step - loss: 0.6728 - accuracy: 0.7383 - val_loss: 0.6504 - val_accuracy: 0.7458\n",
      "Epoch 5/1000\n",
      "225/225 [==============================] - 0s 1ms/step - loss: 0.6649 - accuracy: 0.7397 - val_loss: 0.6421 - val_accuracy: 0.7461\n",
      "Epoch 6/1000\n",
      "225/225 [==============================] - 0s 1ms/step - loss: 0.6597 - accuracy: 0.7425 - val_loss: 0.6382 - val_accuracy: 0.7473\n",
      "Epoch 7/1000\n",
      "225/225 [==============================] - 0s 1ms/step - loss: 0.6556 - accuracy: 0.7423 - val_loss: 0.6338 - val_accuracy: 0.7490\n",
      "Epoch 8/1000\n",
      "225/225 [==============================] - 0s 1ms/step - loss: 0.6511 - accuracy: 0.7456 - val_loss: 0.6315 - val_accuracy: 0.7489\n",
      "Epoch 9/1000\n",
      "225/225 [==============================] - 0s 1ms/step - loss: 0.6466 - accuracy: 0.7465 - val_loss: 0.6283 - val_accuracy: 0.7520\n",
      "Epoch 10/1000\n",
      "225/225 [==============================] - 0s 1ms/step - loss: 0.6432 - accuracy: 0.7470 - val_loss: 0.6235 - val_accuracy: 0.7524\n",
      "Epoch 11/1000\n",
      "225/225 [==============================] - 0s 1ms/step - loss: 0.6402 - accuracy: 0.7482 - val_loss: 0.6204 - val_accuracy: 0.7544\n",
      "Epoch 12/1000\n",
      "225/225 [==============================] - 0s 1ms/step - loss: 0.6353 - accuracy: 0.7487 - val_loss: 0.6172 - val_accuracy: 0.7549\n",
      "Epoch 13/1000\n",
      "225/225 [==============================] - 0s 1ms/step - loss: 0.6339 - accuracy: 0.7491 - val_loss: 0.6144 - val_accuracy: 0.7559\n",
      "Epoch 14/1000\n",
      "225/225 [==============================] - 0s 1ms/step - loss: 0.6301 - accuracy: 0.7516 - val_loss: 0.6124 - val_accuracy: 0.7563\n",
      "Epoch 15/1000\n",
      "225/225 [==============================] - 0s 1ms/step - loss: 0.6274 - accuracy: 0.7522 - val_loss: 0.6110 - val_accuracy: 0.7577\n",
      "Epoch 16/1000\n",
      "225/225 [==============================] - 0s 1ms/step - loss: 0.6246 - accuracy: 0.7529 - val_loss: 0.6048 - val_accuracy: 0.7597\n",
      "Epoch 17/1000\n",
      "225/225 [==============================] - 0s 1ms/step - loss: 0.6234 - accuracy: 0.7537 - val_loss: 0.6071 - val_accuracy: 0.7583\n",
      "Epoch 18/1000\n",
      "225/225 [==============================] - 0s 1ms/step - loss: 0.6201 - accuracy: 0.7544 - val_loss: 0.6023 - val_accuracy: 0.7596\n",
      "Epoch 19/1000\n",
      "225/225 [==============================] - 0s 1ms/step - loss: 0.6187 - accuracy: 0.7547 - val_loss: 0.5994 - val_accuracy: 0.7604\n",
      "Epoch 20/1000\n",
      "225/225 [==============================] - 0s 1ms/step - loss: 0.6150 - accuracy: 0.7563 - val_loss: 0.6002 - val_accuracy: 0.7598\n",
      "Epoch 21/1000\n",
      "225/225 [==============================] - 0s 2ms/step - loss: 0.6137 - accuracy: 0.7565 - val_loss: 0.5937 - val_accuracy: 0.7635\n",
      "Epoch 22/1000\n",
      "225/225 [==============================] - 0s 1ms/step - loss: 0.6105 - accuracy: 0.7576 - val_loss: 0.5939 - val_accuracy: 0.7629\n",
      "Epoch 23/1000\n",
      "225/225 [==============================] - 0s 1ms/step - loss: 0.6089 - accuracy: 0.7588 - val_loss: 0.5918 - val_accuracy: 0.7666\n",
      "Epoch 24/1000\n",
      "225/225 [==============================] - 0s 1ms/step - loss: 0.6065 - accuracy: 0.7595 - val_loss: 0.5882 - val_accuracy: 0.7646\n",
      "Epoch 25/1000\n",
      "225/225 [==============================] - 0s 1ms/step - loss: 0.6047 - accuracy: 0.7596 - val_loss: 0.5893 - val_accuracy: 0.7648\n",
      "Epoch 26/1000\n",
      "225/225 [==============================] - 0s 1ms/step - loss: 0.6038 - accuracy: 0.7604 - val_loss: 0.5893 - val_accuracy: 0.7638\n",
      "Epoch 27/1000\n",
      "225/225 [==============================] - 0s 1ms/step - loss: 0.6007 - accuracy: 0.7604 - val_loss: 0.5814 - val_accuracy: 0.7667\n",
      "Epoch 28/1000\n",
      "225/225 [==============================] - 0s 1ms/step - loss: 0.5987 - accuracy: 0.7618 - val_loss: 0.5830 - val_accuracy: 0.7669\n",
      "Epoch 29/1000\n",
      "225/225 [==============================] - 0s 1ms/step - loss: 0.5971 - accuracy: 0.7625 - val_loss: 0.5798 - val_accuracy: 0.7687\n",
      "Epoch 30/1000\n",
      "225/225 [==============================] - 0s 1ms/step - loss: 0.5946 - accuracy: 0.7632 - val_loss: 0.5781 - val_accuracy: 0.7658\n",
      "Epoch 31/1000\n",
      "225/225 [==============================] - 0s 1ms/step - loss: 0.5942 - accuracy: 0.7636 - val_loss: 0.5737 - val_accuracy: 0.7707\n",
      "Epoch 32/1000\n",
      "225/225 [==============================] - 0s 1ms/step - loss: 0.5924 - accuracy: 0.7641 - val_loss: 0.5729 - val_accuracy: 0.7704\n",
      "Epoch 33/1000\n",
      "225/225 [==============================] - 0s 1ms/step - loss: 0.5899 - accuracy: 0.7649 - val_loss: 0.5740 - val_accuracy: 0.7722\n",
      "Epoch 34/1000\n",
      "225/225 [==============================] - 0s 1ms/step - loss: 0.5888 - accuracy: 0.7646 - val_loss: 0.5704 - val_accuracy: 0.7721\n",
      "Epoch 35/1000\n",
      "225/225 [==============================] - 0s 1ms/step - loss: 0.5865 - accuracy: 0.7671 - val_loss: 0.5705 - val_accuracy: 0.7723\n",
      "Epoch 36/1000\n",
      "225/225 [==============================] - 0s 1ms/step - loss: 0.5862 - accuracy: 0.7665 - val_loss: 0.5690 - val_accuracy: 0.7716\n",
      "Epoch 37/1000\n",
      "225/225 [==============================] - 0s 1ms/step - loss: 0.5833 - accuracy: 0.7665 - val_loss: 0.5666 - val_accuracy: 0.7726\n",
      "Epoch 38/1000\n",
      "225/225 [==============================] - 0s 1ms/step - loss: 0.5832 - accuracy: 0.7671 - val_loss: 0.5642 - val_accuracy: 0.7746\n",
      "Epoch 39/1000\n",
      "225/225 [==============================] - 0s 1ms/step - loss: 0.5825 - accuracy: 0.7676 - val_loss: 0.5629 - val_accuracy: 0.7749\n",
      "Epoch 40/1000\n",
      "225/225 [==============================] - 0s 1ms/step - loss: 0.5819 - accuracy: 0.7674 - val_loss: 0.5595 - val_accuracy: 0.7752\n",
      "Epoch 41/1000\n",
      "225/225 [==============================] - 0s 1ms/step - loss: 0.5800 - accuracy: 0.7694 - val_loss: 0.5610 - val_accuracy: 0.7751\n",
      "Epoch 42/1000\n",
      "225/225 [==============================] - 0s 1ms/step - loss: 0.5786 - accuracy: 0.7692 - val_loss: 0.5592 - val_accuracy: 0.7780\n",
      "Epoch 43/1000\n",
      "225/225 [==============================] - 0s 1ms/step - loss: 0.5773 - accuracy: 0.7693 - val_loss: 0.5565 - val_accuracy: 0.7774\n",
      "Epoch 44/1000\n",
      "225/225 [==============================] - 0s 1ms/step - loss: 0.5742 - accuracy: 0.7706 - val_loss: 0.5598 - val_accuracy: 0.7767\n",
      "Epoch 45/1000\n",
      "225/225 [==============================] - 0s 1ms/step - loss: 0.5743 - accuracy: 0.7702 - val_loss: 0.5524 - val_accuracy: 0.7786\n",
      "Epoch 46/1000\n",
      "225/225 [==============================] - 0s 1ms/step - loss: 0.5741 - accuracy: 0.7710 - val_loss: 0.5546 - val_accuracy: 0.7788\n",
      "Epoch 47/1000\n",
      "225/225 [==============================] - 0s 1ms/step - loss: 0.5718 - accuracy: 0.7711 - val_loss: 0.5534 - val_accuracy: 0.7815\n",
      "Epoch 48/1000\n",
      "225/225 [==============================] - 0s 1ms/step - loss: 0.5726 - accuracy: 0.7714 - val_loss: 0.5509 - val_accuracy: 0.7800\n",
      "Epoch 49/1000\n",
      "225/225 [==============================] - 0s 1ms/step - loss: 0.5717 - accuracy: 0.7722 - val_loss: 0.5474 - val_accuracy: 0.7812\n",
      "Epoch 50/1000\n",
      "225/225 [==============================] - 0s 1ms/step - loss: 0.5691 - accuracy: 0.7718 - val_loss: 0.5470 - val_accuracy: 0.7840\n",
      "Epoch 51/1000\n",
      "225/225 [==============================] - 0s 1ms/step - loss: 0.5700 - accuracy: 0.7716 - val_loss: 0.5464 - val_accuracy: 0.7815\n",
      "Epoch 52/1000\n",
      "225/225 [==============================] - 0s 1ms/step - loss: 0.5665 - accuracy: 0.7736 - val_loss: 0.5463 - val_accuracy: 0.7821\n",
      "Epoch 53/1000\n",
      "225/225 [==============================] - 0s 1ms/step - loss: 0.5669 - accuracy: 0.7743 - val_loss: 0.5501 - val_accuracy: 0.7831\n",
      "Epoch 54/1000\n",
      "225/225 [==============================] - 0s 1ms/step - loss: 0.5655 - accuracy: 0.7734 - val_loss: 0.5459 - val_accuracy: 0.7817\n",
      "Epoch 55/1000\n",
      "225/225 [==============================] - 0s 1ms/step - loss: 0.5649 - accuracy: 0.7741 - val_loss: 0.5437 - val_accuracy: 0.7837\n",
      "Epoch 56/1000\n",
      "225/225 [==============================] - 0s 1ms/step - loss: 0.5653 - accuracy: 0.7746 - val_loss: 0.5455 - val_accuracy: 0.7821\n",
      "Epoch 57/1000\n",
      "225/225 [==============================] - 0s 1ms/step - loss: 0.5644 - accuracy: 0.7743 - val_loss: 0.5379 - val_accuracy: 0.7858\n",
      "Epoch 58/1000\n",
      "225/225 [==============================] - 0s 1ms/step - loss: 0.5627 - accuracy: 0.7753 - val_loss: 0.5389 - val_accuracy: 0.7850\n",
      "Epoch 59/1000\n",
      "225/225 [==============================] - 0s 1ms/step - loss: 0.5614 - accuracy: 0.7760 - val_loss: 0.5400 - val_accuracy: 0.7857\n",
      "Epoch 60/1000\n",
      "225/225 [==============================] - 0s 1ms/step - loss: 0.5600 - accuracy: 0.7768 - val_loss: 0.5406 - val_accuracy: 0.7843\n",
      "Epoch 61/1000\n",
      "225/225 [==============================] - 0s 1ms/step - loss: 0.5596 - accuracy: 0.7756 - val_loss: 0.5411 - val_accuracy: 0.7836\n",
      "Epoch 62/1000\n",
      "225/225 [==============================] - 0s 1ms/step - loss: 0.5593 - accuracy: 0.7772 - val_loss: 0.5349 - val_accuracy: 0.7867\n",
      "Epoch 63/1000\n",
      "225/225 [==============================] - 0s 1ms/step - loss: 0.5587 - accuracy: 0.7768 - val_loss: 0.5361 - val_accuracy: 0.7870\n",
      "Epoch 64/1000\n",
      "225/225 [==============================] - 0s 1ms/step - loss: 0.5566 - accuracy: 0.7778 - val_loss: 0.5338 - val_accuracy: 0.7893\n",
      "Epoch 65/1000\n",
      "225/225 [==============================] - 0s 1ms/step - loss: 0.5573 - accuracy: 0.7774 - val_loss: 0.5367 - val_accuracy: 0.7891\n",
      "Epoch 66/1000\n",
      "225/225 [==============================] - 0s 1ms/step - loss: 0.5563 - accuracy: 0.7776 - val_loss: 0.5330 - val_accuracy: 0.7894\n",
      "Epoch 67/1000\n",
      "225/225 [==============================] - 0s 1ms/step - loss: 0.5551 - accuracy: 0.7777 - val_loss: 0.5298 - val_accuracy: 0.7895\n",
      "Epoch 68/1000\n",
      "225/225 [==============================] - 0s 1ms/step - loss: 0.5549 - accuracy: 0.7779 - val_loss: 0.5313 - val_accuracy: 0.7891\n",
      "Epoch 69/1000\n",
      "225/225 [==============================] - 0s 1ms/step - loss: 0.5537 - accuracy: 0.7781 - val_loss: 0.5337 - val_accuracy: 0.7879\n",
      "Epoch 70/1000\n",
      "225/225 [==============================] - 0s 1ms/step - loss: 0.5541 - accuracy: 0.7785 - val_loss: 0.5289 - val_accuracy: 0.7876\n",
      "Epoch 71/1000\n",
      "225/225 [==============================] - 0s 1ms/step - loss: 0.5532 - accuracy: 0.7797 - val_loss: 0.5285 - val_accuracy: 0.7908\n",
      "Epoch 72/1000\n",
      "225/225 [==============================] - 0s 1ms/step - loss: 0.5534 - accuracy: 0.7793 - val_loss: 0.5289 - val_accuracy: 0.7907\n",
      "Epoch 73/1000\n",
      "225/225 [==============================] - 0s 1ms/step - loss: 0.5513 - accuracy: 0.7784 - val_loss: 0.5298 - val_accuracy: 0.7915\n",
      "Epoch 74/1000\n",
      "225/225 [==============================] - 0s 1ms/step - loss: 0.5523 - accuracy: 0.7790 - val_loss: 0.5260 - val_accuracy: 0.7901\n",
      "Epoch 75/1000\n",
      "225/225 [==============================] - 0s 1ms/step - loss: 0.5507 - accuracy: 0.7796 - val_loss: 0.5257 - val_accuracy: 0.7912\n",
      "Epoch 76/1000\n",
      "225/225 [==============================] - 0s 1ms/step - loss: 0.5499 - accuracy: 0.7808 - val_loss: 0.5260 - val_accuracy: 0.7899\n",
      "Epoch 77/1000\n",
      "225/225 [==============================] - 0s 1ms/step - loss: 0.5494 - accuracy: 0.7807 - val_loss: 0.5245 - val_accuracy: 0.7941\n",
      "Epoch 78/1000\n",
      "225/225 [==============================] - 0s 1ms/step - loss: 0.5498 - accuracy: 0.7802 - val_loss: 0.5259 - val_accuracy: 0.7933\n",
      "Epoch 79/1000\n",
      "225/225 [==============================] - 0s 1ms/step - loss: 0.5482 - accuracy: 0.7812 - val_loss: 0.5232 - val_accuracy: 0.7923\n",
      "Epoch 80/1000\n",
      "225/225 [==============================] - 0s 1ms/step - loss: 0.5483 - accuracy: 0.7819 - val_loss: 0.5216 - val_accuracy: 0.7935\n",
      "Epoch 81/1000\n",
      "225/225 [==============================] - 0s 1ms/step - loss: 0.5480 - accuracy: 0.7818 - val_loss: 0.5238 - val_accuracy: 0.7919\n",
      "Epoch 82/1000\n",
      "225/225 [==============================] - 0s 1ms/step - loss: 0.5471 - accuracy: 0.7816 - val_loss: 0.5215 - val_accuracy: 0.7938\n",
      "Epoch 83/1000\n",
      "225/225 [==============================] - 0s 1ms/step - loss: 0.5484 - accuracy: 0.7821 - val_loss: 0.5230 - val_accuracy: 0.7924\n",
      "Epoch 84/1000\n",
      "225/225 [==============================] - 0s 1ms/step - loss: 0.5454 - accuracy: 0.7815 - val_loss: 0.5213 - val_accuracy: 0.7937\n",
      "Epoch 85/1000\n",
      "225/225 [==============================] - 0s 1ms/step - loss: 0.5472 - accuracy: 0.7819 - val_loss: 0.5227 - val_accuracy: 0.7942\n",
      "Epoch 86/1000\n",
      "225/225 [==============================] - 0s 1ms/step - loss: 0.5465 - accuracy: 0.7821 - val_loss: 0.5193 - val_accuracy: 0.7960\n",
      "Epoch 87/1000\n",
      "225/225 [==============================] - 0s 1ms/step - loss: 0.5452 - accuracy: 0.7831 - val_loss: 0.5216 - val_accuracy: 0.7925\n",
      "Epoch 88/1000\n",
      "225/225 [==============================] - 0s 1ms/step - loss: 0.5447 - accuracy: 0.7830 - val_loss: 0.5209 - val_accuracy: 0.7940\n",
      "Epoch 89/1000\n",
      "225/225 [==============================] - 0s 1ms/step - loss: 0.5418 - accuracy: 0.7834 - val_loss: 0.5172 - val_accuracy: 0.7967\n",
      "Epoch 90/1000\n",
      "225/225 [==============================] - 0s 1ms/step - loss: 0.5448 - accuracy: 0.7823 - val_loss: 0.5183 - val_accuracy: 0.7948\n",
      "Epoch 91/1000\n",
      "225/225 [==============================] - 0s 1ms/step - loss: 0.5441 - accuracy: 0.7840 - val_loss: 0.5163 - val_accuracy: 0.7951\n",
      "Epoch 92/1000\n",
      "225/225 [==============================] - 0s 1ms/step - loss: 0.5413 - accuracy: 0.7838 - val_loss: 0.5158 - val_accuracy: 0.7969\n",
      "Epoch 93/1000\n",
      "225/225 [==============================] - 0s 1ms/step - loss: 0.5406 - accuracy: 0.7840 - val_loss: 0.5175 - val_accuracy: 0.7941\n",
      "Epoch 94/1000\n",
      "225/225 [==============================] - 0s 1ms/step - loss: 0.5404 - accuracy: 0.7848 - val_loss: 0.5151 - val_accuracy: 0.7981\n",
      "Epoch 95/1000\n",
      "225/225 [==============================] - 0s 1ms/step - loss: 0.5426 - accuracy: 0.7838 - val_loss: 0.5158 - val_accuracy: 0.7941\n",
      "Epoch 96/1000\n",
      "225/225 [==============================] - 0s 1ms/step - loss: 0.5402 - accuracy: 0.7839 - val_loss: 0.5169 - val_accuracy: 0.7963\n",
      "Epoch 97/1000\n",
      "225/225 [==============================] - 0s 1ms/step - loss: 0.5398 - accuracy: 0.7847 - val_loss: 0.5131 - val_accuracy: 0.7995\n",
      "Epoch 98/1000\n",
      "225/225 [==============================] - 0s 1ms/step - loss: 0.5387 - accuracy: 0.7848 - val_loss: 0.5133 - val_accuracy: 0.7984\n",
      "Epoch 99/1000\n",
      "225/225 [==============================] - 0s 1ms/step - loss: 0.5405 - accuracy: 0.7850 - val_loss: 0.5163 - val_accuracy: 0.7966\n",
      "Epoch 100/1000\n",
      "225/225 [==============================] - 0s 1ms/step - loss: 0.5404 - accuracy: 0.7851 - val_loss: 0.5133 - val_accuracy: 0.8001\n",
      "Epoch 101/1000\n",
      "225/225 [==============================] - 0s 1ms/step - loss: 0.5397 - accuracy: 0.7856 - val_loss: 0.5124 - val_accuracy: 0.8003\n",
      "Epoch 102/1000\n",
      "225/225 [==============================] - 0s 1ms/step - loss: 0.5388 - accuracy: 0.7851 - val_loss: 0.5148 - val_accuracy: 0.7972\n",
      "Epoch 103/1000\n",
      "225/225 [==============================] - 0s 1ms/step - loss: 0.5395 - accuracy: 0.7849 - val_loss: 0.5148 - val_accuracy: 0.7995\n",
      "Epoch 104/1000\n",
      "225/225 [==============================] - 0s 1ms/step - loss: 0.5409 - accuracy: 0.7849 - val_loss: 0.5130 - val_accuracy: 0.7984\n",
      "Epoch 105/1000\n",
      "225/225 [==============================] - 0s 1ms/step - loss: 0.5383 - accuracy: 0.7855 - val_loss: 0.5110 - val_accuracy: 0.8002\n",
      "Epoch 106/1000\n",
      "225/225 [==============================] - 0s 1ms/step - loss: 0.5376 - accuracy: 0.7855 - val_loss: 0.5086 - val_accuracy: 0.8021\n",
      "Epoch 107/1000\n",
      "225/225 [==============================] - 0s 1ms/step - loss: 0.5385 - accuracy: 0.7851 - val_loss: 0.5097 - val_accuracy: 0.7978\n",
      "Epoch 108/1000\n",
      "225/225 [==============================] - 0s 1ms/step - loss: 0.5368 - accuracy: 0.7868 - val_loss: 0.5081 - val_accuracy: 0.7992\n",
      "Epoch 109/1000\n",
      "225/225 [==============================] - 0s 1ms/step - loss: 0.5353 - accuracy: 0.7871 - val_loss: 0.5092 - val_accuracy: 0.8006\n",
      "Epoch 110/1000\n",
      "225/225 [==============================] - 0s 1ms/step - loss: 0.5368 - accuracy: 0.7863 - val_loss: 0.5118 - val_accuracy: 0.7994\n",
      "Epoch 111/1000\n",
      "225/225 [==============================] - 0s 1ms/step - loss: 0.5366 - accuracy: 0.7857 - val_loss: 0.5087 - val_accuracy: 0.8013\n",
      "Epoch 112/1000\n",
      "225/225 [==============================] - 0s 1ms/step - loss: 0.5376 - accuracy: 0.7857 - val_loss: 0.5119 - val_accuracy: 0.7981\n",
      "Epoch 113/1000\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "225/225 [==============================] - 0s 1ms/step - loss: 0.5358 - accuracy: 0.7867 - val_loss: 0.5111 - val_accuracy: 0.8006\n",
      "Epoch 114/1000\n",
      "225/225 [==============================] - 0s 1ms/step - loss: 0.5354 - accuracy: 0.7864 - val_loss: 0.5126 - val_accuracy: 0.7970\n",
      "Epoch 115/1000\n",
      "225/225 [==============================] - 0s 1ms/step - loss: 0.5356 - accuracy: 0.7869 - val_loss: 0.5059 - val_accuracy: 0.8034\n",
      "Epoch 116/1000\n",
      "225/225 [==============================] - 0s 1ms/step - loss: 0.5347 - accuracy: 0.7870 - val_loss: 0.5110 - val_accuracy: 0.7980\n",
      "Epoch 117/1000\n",
      "225/225 [==============================] - 0s 1ms/step - loss: 0.5336 - accuracy: 0.7874 - val_loss: 0.5109 - val_accuracy: 0.7978\n",
      "Epoch 118/1000\n",
      "225/225 [==============================] - 0s 1ms/step - loss: 0.5331 - accuracy: 0.7876 - val_loss: 0.5071 - val_accuracy: 0.8011\n",
      "Epoch 119/1000\n",
      "225/225 [==============================] - 0s 1ms/step - loss: 0.5325 - accuracy: 0.7883 - val_loss: 0.5058 - val_accuracy: 0.8029\n",
      "Epoch 120/1000\n",
      "225/225 [==============================] - 0s 1ms/step - loss: 0.5325 - accuracy: 0.7880 - val_loss: 0.5080 - val_accuracy: 0.7984\n",
      "Epoch 121/1000\n",
      "225/225 [==============================] - 0s 1ms/step - loss: 0.5321 - accuracy: 0.7885 - val_loss: 0.5066 - val_accuracy: 0.7992\n",
      "Epoch 122/1000\n",
      "225/225 [==============================] - 0s 1ms/step - loss: 0.5323 - accuracy: 0.7876 - val_loss: 0.5088 - val_accuracy: 0.8000\n",
      "Epoch 123/1000\n",
      "225/225 [==============================] - 0s 1ms/step - loss: 0.5318 - accuracy: 0.7886 - val_loss: 0.5032 - val_accuracy: 0.8054\n",
      "Epoch 124/1000\n",
      "225/225 [==============================] - 0s 1ms/step - loss: 0.5314 - accuracy: 0.7880 - val_loss: 0.5058 - val_accuracy: 0.8025\n",
      "Epoch 125/1000\n",
      "225/225 [==============================] - 0s 1ms/step - loss: 0.5311 - accuracy: 0.7880 - val_loss: 0.5048 - val_accuracy: 0.8021\n",
      "Epoch 126/1000\n",
      "225/225 [==============================] - 0s 1ms/step - loss: 0.5327 - accuracy: 0.7882 - val_loss: 0.5059 - val_accuracy: 0.8015\n",
      "Epoch 127/1000\n",
      "225/225 [==============================] - 0s 1ms/step - loss: 0.5308 - accuracy: 0.7887 - val_loss: 0.5039 - val_accuracy: 0.8035\n",
      "Epoch 128/1000\n",
      "225/225 [==============================] - 0s 1ms/step - loss: 0.5311 - accuracy: 0.7884 - val_loss: 0.5043 - val_accuracy: 0.8017\n",
      "Epoch 129/1000\n",
      "225/225 [==============================] - 0s 1ms/step - loss: 0.5309 - accuracy: 0.7887 - val_loss: 0.5053 - val_accuracy: 0.8028\n",
      "Epoch 130/1000\n",
      "225/225 [==============================] - 0s 1ms/step - loss: 0.5309 - accuracy: 0.7897 - val_loss: 0.5035 - val_accuracy: 0.8021\n",
      "Epoch 131/1000\n",
      "225/225 [==============================] - 0s 1ms/step - loss: 0.5304 - accuracy: 0.7889 - val_loss: 0.5022 - val_accuracy: 0.8036\n",
      "Epoch 132/1000\n",
      "225/225 [==============================] - 0s 1ms/step - loss: 0.5309 - accuracy: 0.7896 - val_loss: 0.4993 - val_accuracy: 0.8052\n",
      "Epoch 133/1000\n",
      "225/225 [==============================] - 0s 1ms/step - loss: 0.5296 - accuracy: 0.7891 - val_loss: 0.4997 - val_accuracy: 0.8060\n",
      "Epoch 134/1000\n",
      "225/225 [==============================] - 0s 1ms/step - loss: 0.5289 - accuracy: 0.7901 - val_loss: 0.5039 - val_accuracy: 0.8015\n",
      "Epoch 135/1000\n",
      "225/225 [==============================] - 0s 1ms/step - loss: 0.5285 - accuracy: 0.7904 - val_loss: 0.5047 - val_accuracy: 0.8042\n",
      "Epoch 136/1000\n",
      "225/225 [==============================] - 0s 1ms/step - loss: 0.5294 - accuracy: 0.7891 - val_loss: 0.5046 - val_accuracy: 0.8012\n",
      "Epoch 137/1000\n",
      "225/225 [==============================] - 0s 1ms/step - loss: 0.5281 - accuracy: 0.7899 - val_loss: 0.4997 - val_accuracy: 0.8035\n",
      "Epoch 138/1000\n",
      "225/225 [==============================] - 0s 1ms/step - loss: 0.5289 - accuracy: 0.7886 - val_loss: 0.5002 - val_accuracy: 0.8028\n",
      "Epoch 139/1000\n",
      "225/225 [==============================] - 0s 1ms/step - loss: 0.5276 - accuracy: 0.7896 - val_loss: 0.5028 - val_accuracy: 0.8026\n",
      "Epoch 140/1000\n",
      "225/225 [==============================] - 0s 1ms/step - loss: 0.5297 - accuracy: 0.7896 - val_loss: 0.5003 - val_accuracy: 0.8065\n",
      "Epoch 141/1000\n",
      "225/225 [==============================] - 0s 1ms/step - loss: 0.5280 - accuracy: 0.7894 - val_loss: 0.4981 - val_accuracy: 0.8072\n",
      "Epoch 142/1000\n",
      "225/225 [==============================] - 0s 1ms/step - loss: 0.5270 - accuracy: 0.7908 - val_loss: 0.4992 - val_accuracy: 0.8046\n",
      "Epoch 143/1000\n",
      "225/225 [==============================] - 0s 1ms/step - loss: 0.5273 - accuracy: 0.7904 - val_loss: 0.4985 - val_accuracy: 0.8069\n",
      "Epoch 144/1000\n",
      "225/225 [==============================] - 0s 1ms/step - loss: 0.5265 - accuracy: 0.7901 - val_loss: 0.4980 - val_accuracy: 0.8048\n",
      "Epoch 145/1000\n",
      "225/225 [==============================] - 0s 1ms/step - loss: 0.5250 - accuracy: 0.7908 - val_loss: 0.4993 - val_accuracy: 0.8064\n",
      "Epoch 146/1000\n",
      "225/225 [==============================] - 0s 1ms/step - loss: 0.5287 - accuracy: 0.7890 - val_loss: 0.5000 - val_accuracy: 0.8058\n",
      "Epoch 147/1000\n",
      "225/225 [==============================] - 0s 2ms/step - loss: 0.5254 - accuracy: 0.7915 - val_loss: 0.4983 - val_accuracy: 0.8060\n",
      "Epoch 148/1000\n",
      "225/225 [==============================] - 0s 1ms/step - loss: 0.5256 - accuracy: 0.7906 - val_loss: 0.5010 - val_accuracy: 0.8049\n",
      "Epoch 149/1000\n",
      "225/225 [==============================] - 0s 1ms/step - loss: 0.5256 - accuracy: 0.7919 - val_loss: 0.4994 - val_accuracy: 0.8054\n",
      "Epoch 150/1000\n",
      "225/225 [==============================] - 0s 1ms/step - loss: 0.5250 - accuracy: 0.7913 - val_loss: 0.4978 - val_accuracy: 0.8063\n",
      "Epoch 151/1000\n",
      "225/225 [==============================] - 0s 1ms/step - loss: 0.5238 - accuracy: 0.7915 - val_loss: 0.4966 - val_accuracy: 0.8069\n",
      "Epoch 152/1000\n",
      "225/225 [==============================] - 0s 1ms/step - loss: 0.5255 - accuracy: 0.7912 - val_loss: 0.4964 - val_accuracy: 0.8097\n",
      "Epoch 153/1000\n",
      "225/225 [==============================] - 0s 1ms/step - loss: 0.5256 - accuracy: 0.7900 - val_loss: 0.4964 - val_accuracy: 0.8069\n",
      "Epoch 154/1000\n",
      "225/225 [==============================] - 0s 1ms/step - loss: 0.5256 - accuracy: 0.7915 - val_loss: 0.4932 - val_accuracy: 0.8074\n",
      "Epoch 155/1000\n",
      "225/225 [==============================] - 0s 1ms/step - loss: 0.5264 - accuracy: 0.7909 - val_loss: 0.4965 - val_accuracy: 0.8070\n",
      "Epoch 156/1000\n",
      "225/225 [==============================] - 0s 1ms/step - loss: 0.5236 - accuracy: 0.7922 - val_loss: 0.4975 - val_accuracy: 0.8057\n",
      "Epoch 157/1000\n",
      "225/225 [==============================] - 0s 1ms/step - loss: 0.5231 - accuracy: 0.7921 - val_loss: 0.4945 - val_accuracy: 0.8064\n",
      "Epoch 158/1000\n",
      "225/225 [==============================] - 0s 1ms/step - loss: 0.5236 - accuracy: 0.7917 - val_loss: 0.4981 - val_accuracy: 0.8053\n",
      "Epoch 159/1000\n",
      "225/225 [==============================] - 0s 1ms/step - loss: 0.5239 - accuracy: 0.7921 - val_loss: 0.4955 - val_accuracy: 0.8086\n",
      "Epoch 160/1000\n",
      "225/225 [==============================] - 0s 1ms/step - loss: 0.5251 - accuracy: 0.7909 - val_loss: 0.4940 - val_accuracy: 0.8065\n",
      "Epoch 161/1000\n",
      "225/225 [==============================] - 0s 1ms/step - loss: 0.5237 - accuracy: 0.7923 - val_loss: 0.4926 - val_accuracy: 0.8086\n",
      "Epoch 162/1000\n",
      "225/225 [==============================] - 0s 1ms/step - loss: 0.5218 - accuracy: 0.7935 - val_loss: 0.4917 - val_accuracy: 0.8096\n",
      "Epoch 163/1000\n",
      "225/225 [==============================] - 0s 1ms/step - loss: 0.5237 - accuracy: 0.7919 - val_loss: 0.4969 - val_accuracy: 0.8044\n",
      "Epoch 164/1000\n",
      "225/225 [==============================] - 0s 1ms/step - loss: 0.5228 - accuracy: 0.7930 - val_loss: 0.4935 - val_accuracy: 0.8073\n",
      "Epoch 165/1000\n",
      "225/225 [==============================] - 0s 1ms/step - loss: 0.5209 - accuracy: 0.7934 - val_loss: 0.4939 - val_accuracy: 0.8093\n",
      "Epoch 166/1000\n",
      "225/225 [==============================] - 0s 1ms/step - loss: 0.5229 - accuracy: 0.7914 - val_loss: 0.4918 - val_accuracy: 0.8103\n",
      "Epoch 167/1000\n",
      "225/225 [==============================] - 0s 1ms/step - loss: 0.5219 - accuracy: 0.7940 - val_loss: 0.4935 - val_accuracy: 0.8082\n",
      "Epoch 168/1000\n",
      "225/225 [==============================] - 0s 1ms/step - loss: 0.5222 - accuracy: 0.7926 - val_loss: 0.4941 - val_accuracy: 0.8090\n",
      "Epoch 169/1000\n",
      "225/225 [==============================] - 0s 1ms/step - loss: 0.5222 - accuracy: 0.7927 - val_loss: 0.4936 - val_accuracy: 0.8067\n",
      "Epoch 170/1000\n",
      "225/225 [==============================] - 0s 1ms/step - loss: 0.5186 - accuracy: 0.7949 - val_loss: 0.4956 - val_accuracy: 0.8095\n",
      "Epoch 171/1000\n",
      "225/225 [==============================] - 0s 1ms/step - loss: 0.5210 - accuracy: 0.7931 - val_loss: 0.4960 - val_accuracy: 0.8074\n",
      "Epoch 172/1000\n",
      "225/225 [==============================] - 0s 1ms/step - loss: 0.5213 - accuracy: 0.7924 - val_loss: 0.4913 - val_accuracy: 0.8080\n",
      "Epoch 173/1000\n",
      "225/225 [==============================] - 0s 1ms/step - loss: 0.5206 - accuracy: 0.7937 - val_loss: 0.4918 - val_accuracy: 0.8080\n",
      "Epoch 174/1000\n",
      "225/225 [==============================] - 0s 1ms/step - loss: 0.5211 - accuracy: 0.7940 - val_loss: 0.4906 - val_accuracy: 0.8083\n",
      "Epoch 175/1000\n",
      "225/225 [==============================] - 0s 1ms/step - loss: 0.5203 - accuracy: 0.7945 - val_loss: 0.4917 - val_accuracy: 0.8079\n",
      "Epoch 176/1000\n",
      "225/225 [==============================] - 0s 1ms/step - loss: 0.5193 - accuracy: 0.7939 - val_loss: 0.4923 - val_accuracy: 0.8102\n",
      "Epoch 177/1000\n",
      "225/225 [==============================] - 0s 1ms/step - loss: 0.5208 - accuracy: 0.7936 - val_loss: 0.4877 - val_accuracy: 0.8097\n",
      "Epoch 178/1000\n",
      "225/225 [==============================] - 0s 1ms/step - loss: 0.5209 - accuracy: 0.7937 - val_loss: 0.4893 - val_accuracy: 0.8086\n",
      "Epoch 179/1000\n",
      "225/225 [==============================] - 0s 1ms/step - loss: 0.5201 - accuracy: 0.7939 - val_loss: 0.4889 - val_accuracy: 0.8073\n",
      "Epoch 180/1000\n",
      "225/225 [==============================] - 0s 1ms/step - loss: 0.5202 - accuracy: 0.7931 - val_loss: 0.4880 - val_accuracy: 0.8117\n",
      "Epoch 181/1000\n",
      "225/225 [==============================] - 0s 1ms/step - loss: 0.5201 - accuracy: 0.7935 - val_loss: 0.4932 - val_accuracy: 0.8077\n",
      "Epoch 182/1000\n",
      "225/225 [==============================] - 0s 1ms/step - loss: 0.5189 - accuracy: 0.7945 - val_loss: 0.4912 - val_accuracy: 0.8085\n",
      "Epoch 183/1000\n",
      "225/225 [==============================] - 0s 1ms/step - loss: 0.5190 - accuracy: 0.7941 - val_loss: 0.4897 - val_accuracy: 0.8099\n",
      "Epoch 184/1000\n",
      "225/225 [==============================] - 0s 1ms/step - loss: 0.5194 - accuracy: 0.7941 - val_loss: 0.4893 - val_accuracy: 0.8095\n",
      "Epoch 185/1000\n",
      "225/225 [==============================] - 0s 1ms/step - loss: 0.5193 - accuracy: 0.7952 - val_loss: 0.4879 - val_accuracy: 0.8108\n",
      "Epoch 186/1000\n",
      "225/225 [==============================] - 0s 1ms/step - loss: 0.5186 - accuracy: 0.7943 - val_loss: 0.4920 - val_accuracy: 0.8112\n",
      "Epoch 187/1000\n",
      "225/225 [==============================] - 0s 1ms/step - loss: 0.5187 - accuracy: 0.7934 - val_loss: 0.4887 - val_accuracy: 0.8115\n",
      "Epoch 188/1000\n",
      "225/225 [==============================] - 0s 1ms/step - loss: 0.5181 - accuracy: 0.7946 - val_loss: 0.4878 - val_accuracy: 0.8119\n",
      "Epoch 189/1000\n",
      "225/225 [==============================] - 0s 1ms/step - loss: 0.5179 - accuracy: 0.7947 - val_loss: 0.4873 - val_accuracy: 0.8119\n",
      "Epoch 190/1000\n",
      "225/225 [==============================] - 0s 1ms/step - loss: 0.5174 - accuracy: 0.7943 - val_loss: 0.4926 - val_accuracy: 0.8075\n",
      "Epoch 191/1000\n",
      "225/225 [==============================] - 0s 1ms/step - loss: 0.5192 - accuracy: 0.7947 - val_loss: 0.4882 - val_accuracy: 0.8120\n",
      "Epoch 192/1000\n",
      "225/225 [==============================] - 0s 1ms/step - loss: 0.5178 - accuracy: 0.7947 - val_loss: 0.4875 - val_accuracy: 0.8107\n",
      "Epoch 193/1000\n",
      "225/225 [==============================] - 0s 1ms/step - loss: 0.5180 - accuracy: 0.7958 - val_loss: 0.4888 - val_accuracy: 0.8125\n",
      "Epoch 194/1000\n",
      "225/225 [==============================] - 0s 1ms/step - loss: 0.5192 - accuracy: 0.7942 - val_loss: 0.4909 - val_accuracy: 0.8101\n",
      "Epoch 195/1000\n",
      "225/225 [==============================] - 0s 1ms/step - loss: 0.5189 - accuracy: 0.7957 - val_loss: 0.4866 - val_accuracy: 0.8137\n",
      "Epoch 196/1000\n",
      "225/225 [==============================] - 0s 1ms/step - loss: 0.5165 - accuracy: 0.7964 - val_loss: 0.4869 - val_accuracy: 0.8122\n",
      "Epoch 197/1000\n",
      "225/225 [==============================] - 0s 1ms/step - loss: 0.5181 - accuracy: 0.7953 - val_loss: 0.4897 - val_accuracy: 0.8097\n",
      "Epoch 198/1000\n",
      "225/225 [==============================] - 0s 1ms/step - loss: 0.5182 - accuracy: 0.7944 - val_loss: 0.4867 - val_accuracy: 0.8118\n",
      "Epoch 199/1000\n",
      "225/225 [==============================] - 0s 1ms/step - loss: 0.5154 - accuracy: 0.7958 - val_loss: 0.4874 - val_accuracy: 0.8115\n",
      "Epoch 200/1000\n",
      "225/225 [==============================] - 0s 1ms/step - loss: 0.5163 - accuracy: 0.7944 - val_loss: 0.4894 - val_accuracy: 0.8080\n",
      "Epoch 201/1000\n",
      "225/225 [==============================] - 0s 1ms/step - loss: 0.5171 - accuracy: 0.7942 - val_loss: 0.4875 - val_accuracy: 0.8130\n",
      "Epoch 202/1000\n",
      "225/225 [==============================] - 0s 1ms/step - loss: 0.5158 - accuracy: 0.7952 - val_loss: 0.4877 - val_accuracy: 0.8105\n",
      "Epoch 203/1000\n",
      "225/225 [==============================] - 0s 1ms/step - loss: 0.5170 - accuracy: 0.7947 - val_loss: 0.4857 - val_accuracy: 0.8140\n",
      "Epoch 204/1000\n",
      "225/225 [==============================] - 0s 1ms/step - loss: 0.5176 - accuracy: 0.7953 - val_loss: 0.4860 - val_accuracy: 0.8093\n",
      "Epoch 205/1000\n",
      "225/225 [==============================] - 0s 1ms/step - loss: 0.5160 - accuracy: 0.7955 - val_loss: 0.4873 - val_accuracy: 0.8091\n",
      "Epoch 206/1000\n",
      "225/225 [==============================] - 0s 2ms/step - loss: 0.5154 - accuracy: 0.7961 - val_loss: 0.4845 - val_accuracy: 0.8126\n",
      "Epoch 207/1000\n",
      "225/225 [==============================] - 0s 1ms/step - loss: 0.5165 - accuracy: 0.7952 - val_loss: 0.4861 - val_accuracy: 0.8131\n",
      "Epoch 208/1000\n",
      "225/225 [==============================] - 0s 1ms/step - loss: 0.5160 - accuracy: 0.7957 - val_loss: 0.4854 - val_accuracy: 0.8115\n",
      "Epoch 209/1000\n",
      "225/225 [==============================] - 0s 1ms/step - loss: 0.5164 - accuracy: 0.7955 - val_loss: 0.4873 - val_accuracy: 0.8128\n",
      "Epoch 210/1000\n",
      "225/225 [==============================] - 0s 1ms/step - loss: 0.5165 - accuracy: 0.7952 - val_loss: 0.4863 - val_accuracy: 0.8128\n",
      "Epoch 211/1000\n",
      "225/225 [==============================] - 0s 1ms/step - loss: 0.5150 - accuracy: 0.7957 - val_loss: 0.4866 - val_accuracy: 0.8101\n",
      "Epoch 212/1000\n",
      "225/225 [==============================] - 0s 1ms/step - loss: 0.5144 - accuracy: 0.7957 - val_loss: 0.4877 - val_accuracy: 0.8122\n",
      "Epoch 213/1000\n",
      "225/225 [==============================] - 0s 1ms/step - loss: 0.5168 - accuracy: 0.7946 - val_loss: 0.4874 - val_accuracy: 0.8097\n",
      "Epoch 214/1000\n",
      "225/225 [==============================] - 0s 1ms/step - loss: 0.5149 - accuracy: 0.7951 - val_loss: 0.4858 - val_accuracy: 0.8101\n",
      "Epoch 215/1000\n",
      "225/225 [==============================] - 0s 1ms/step - loss: 0.5141 - accuracy: 0.7967 - val_loss: 0.4892 - val_accuracy: 0.8093\n",
      "Epoch 216/1000\n",
      "225/225 [==============================] - 0s 1ms/step - loss: 0.5154 - accuracy: 0.7964 - val_loss: 0.4824 - val_accuracy: 0.8132\n",
      "Epoch 217/1000\n",
      "225/225 [==============================] - 0s 1ms/step - loss: 0.5155 - accuracy: 0.7961 - val_loss: 0.4859 - val_accuracy: 0.8115\n",
      "Epoch 218/1000\n",
      "225/225 [==============================] - 0s 1ms/step - loss: 0.5143 - accuracy: 0.7971 - val_loss: 0.4872 - val_accuracy: 0.8119\n",
      "Epoch 219/1000\n",
      "225/225 [==============================] - 0s 1ms/step - loss: 0.5145 - accuracy: 0.7966 - val_loss: 0.4831 - val_accuracy: 0.8148\n",
      "Epoch 220/1000\n",
      "225/225 [==============================] - 0s 1ms/step - loss: 0.5147 - accuracy: 0.7959 - val_loss: 0.4857 - val_accuracy: 0.8098\n",
      "Epoch 221/1000\n",
      "225/225 [==============================] - 0s 1ms/step - loss: 0.5144 - accuracy: 0.7969 - val_loss: 0.4822 - val_accuracy: 0.8136\n",
      "Epoch 222/1000\n",
      "225/225 [==============================] - 0s 1ms/step - loss: 0.5137 - accuracy: 0.7970 - val_loss: 0.4869 - val_accuracy: 0.8111\n",
      "Epoch 223/1000\n",
      "225/225 [==============================] - 0s 1ms/step - loss: 0.5125 - accuracy: 0.7986 - val_loss: 0.4848 - val_accuracy: 0.8124\n",
      "Epoch 224/1000\n",
      "225/225 [==============================] - 0s 1ms/step - loss: 0.5139 - accuracy: 0.7962 - val_loss: 0.4876 - val_accuracy: 0.8081\n",
      "Epoch 225/1000\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "225/225 [==============================] - 0s 1ms/step - loss: 0.5132 - accuracy: 0.7970 - val_loss: 0.4867 - val_accuracy: 0.8125\n",
      "Epoch 226/1000\n",
      "225/225 [==============================] - 0s 1ms/step - loss: 0.5140 - accuracy: 0.7968 - val_loss: 0.4819 - val_accuracy: 0.8160\n",
      "Epoch 227/1000\n",
      "225/225 [==============================] - 0s 1ms/step - loss: 0.5144 - accuracy: 0.7965 - val_loss: 0.4840 - val_accuracy: 0.8130\n",
      "Epoch 228/1000\n",
      "225/225 [==============================] - 0s 1ms/step - loss: 0.5140 - accuracy: 0.7962 - val_loss: 0.4848 - val_accuracy: 0.8138\n",
      "Epoch 229/1000\n",
      "225/225 [==============================] - 0s 1ms/step - loss: 0.5143 - accuracy: 0.7969 - val_loss: 0.4836 - val_accuracy: 0.8125\n",
      "Epoch 230/1000\n",
      "225/225 [==============================] - 0s 1ms/step - loss: 0.5124 - accuracy: 0.7969 - val_loss: 0.4848 - val_accuracy: 0.8117\n",
      "Epoch 231/1000\n",
      "225/225 [==============================] - 0s 1ms/step - loss: 0.5135 - accuracy: 0.7966 - val_loss: 0.4910 - val_accuracy: 0.8071\n",
      "Epoch 232/1000\n",
      "225/225 [==============================] - 0s 1ms/step - loss: 0.5108 - accuracy: 0.7983 - val_loss: 0.4843 - val_accuracy: 0.8133\n",
      "Epoch 233/1000\n",
      "225/225 [==============================] - 0s 1ms/step - loss: 0.5140 - accuracy: 0.7962 - val_loss: 0.4866 - val_accuracy: 0.8120\n",
      "Epoch 234/1000\n",
      "225/225 [==============================] - 0s 1ms/step - loss: 0.5117 - accuracy: 0.7972 - val_loss: 0.4828 - val_accuracy: 0.8150\n",
      "Epoch 235/1000\n",
      "225/225 [==============================] - 0s 1ms/step - loss: 0.5145 - accuracy: 0.7965 - val_loss: 0.4865 - val_accuracy: 0.8099\n",
      "Epoch 236/1000\n",
      "225/225 [==============================] - 0s 1ms/step - loss: 0.5118 - accuracy: 0.7978 - val_loss: 0.4807 - val_accuracy: 0.8129\n",
      "Epoch 237/1000\n",
      "225/225 [==============================] - 0s 1ms/step - loss: 0.5107 - accuracy: 0.7984 - val_loss: 0.4806 - val_accuracy: 0.8140\n",
      "Epoch 238/1000\n",
      "225/225 [==============================] - 0s 1ms/step - loss: 0.5101 - accuracy: 0.7973 - val_loss: 0.4828 - val_accuracy: 0.8136\n",
      "Epoch 239/1000\n",
      "225/225 [==============================] - 0s 1ms/step - loss: 0.5134 - accuracy: 0.7960 - val_loss: 0.4866 - val_accuracy: 0.8101\n",
      "Epoch 240/1000\n",
      "225/225 [==============================] - 0s 1ms/step - loss: 0.5113 - accuracy: 0.7976 - val_loss: 0.4832 - val_accuracy: 0.8115\n",
      "Epoch 241/1000\n",
      "225/225 [==============================] - 0s 1ms/step - loss: 0.5126 - accuracy: 0.7977 - val_loss: 0.4841 - val_accuracy: 0.8106\n",
      "Epoch 242/1000\n",
      "225/225 [==============================] - 0s 1ms/step - loss: 0.5114 - accuracy: 0.7976 - val_loss: 0.4825 - val_accuracy: 0.8133\n",
      "Epoch 243/1000\n",
      "225/225 [==============================] - 0s 1ms/step - loss: 0.5116 - accuracy: 0.7976 - val_loss: 0.4833 - val_accuracy: 0.8144\n",
      "Epoch 244/1000\n",
      "225/225 [==============================] - 0s 1ms/step - loss: 0.5108 - accuracy: 0.7974 - val_loss: 0.4839 - val_accuracy: 0.8142\n",
      "Epoch 245/1000\n",
      "225/225 [==============================] - 0s 1ms/step - loss: 0.5116 - accuracy: 0.7969 - val_loss: 0.4842 - val_accuracy: 0.8108\n",
      "Epoch 246/1000\n",
      "225/225 [==============================] - 0s 1ms/step - loss: 0.5129 - accuracy: 0.7968 - val_loss: 0.4825 - val_accuracy: 0.8140\n",
      "Epoch 247/1000\n",
      "225/225 [==============================] - 0s 1ms/step - loss: 0.5118 - accuracy: 0.7977 - val_loss: 0.4832 - val_accuracy: 0.8119\n",
      "Epoch 248/1000\n",
      "225/225 [==============================] - 0s 1ms/step - loss: 0.5127 - accuracy: 0.7960 - val_loss: 0.4838 - val_accuracy: 0.8133\n",
      "Epoch 249/1000\n",
      "225/225 [==============================] - 0s 1ms/step - loss: 0.5116 - accuracy: 0.7965 - val_loss: 0.4837 - val_accuracy: 0.8121\n",
      "Epoch 250/1000\n",
      "225/225 [==============================] - 0s 1ms/step - loss: 0.5116 - accuracy: 0.7977 - val_loss: 0.4828 - val_accuracy: 0.8142\n",
      "Epoch 251/1000\n",
      "225/225 [==============================] - 0s 1ms/step - loss: 0.5103 - accuracy: 0.7988 - val_loss: 0.4798 - val_accuracy: 0.8159\n",
      "Epoch 252/1000\n",
      "225/225 [==============================] - 0s 1ms/step - loss: 0.5103 - accuracy: 0.7985 - val_loss: 0.4832 - val_accuracy: 0.8138\n",
      "Epoch 253/1000\n",
      "225/225 [==============================] - 0s 1ms/step - loss: 0.5109 - accuracy: 0.7984 - val_loss: 0.4793 - val_accuracy: 0.8153\n",
      "Epoch 254/1000\n",
      "225/225 [==============================] - 0s 1ms/step - loss: 0.5099 - accuracy: 0.7979 - val_loss: 0.4829 - val_accuracy: 0.8141\n",
      "Epoch 255/1000\n",
      "225/225 [==============================] - 0s 1ms/step - loss: 0.5099 - accuracy: 0.7979 - val_loss: 0.4817 - val_accuracy: 0.8159\n",
      "Epoch 256/1000\n",
      "225/225 [==============================] - 0s 1ms/step - loss: 0.5110 - accuracy: 0.7976 - val_loss: 0.4807 - val_accuracy: 0.8153\n",
      "Epoch 257/1000\n",
      "225/225 [==============================] - 0s 1ms/step - loss: 0.5111 - accuracy: 0.7979 - val_loss: 0.4822 - val_accuracy: 0.8141\n",
      "Epoch 258/1000\n",
      "225/225 [==============================] - 0s 1ms/step - loss: 0.5122 - accuracy: 0.7981 - val_loss: 0.4802 - val_accuracy: 0.8159\n",
      "Epoch 259/1000\n",
      "225/225 [==============================] - 0s 1ms/step - loss: 0.5113 - accuracy: 0.7971 - val_loss: 0.4834 - val_accuracy: 0.8140\n",
      "Epoch 260/1000\n",
      "225/225 [==============================] - 0s 1ms/step - loss: 0.5113 - accuracy: 0.7972 - val_loss: 0.4804 - val_accuracy: 0.8144\n",
      "Epoch 261/1000\n",
      "225/225 [==============================] - 0s 1ms/step - loss: 0.5104 - accuracy: 0.7975 - val_loss: 0.4808 - val_accuracy: 0.8145\n",
      "Epoch 262/1000\n",
      "225/225 [==============================] - 0s 1ms/step - loss: 0.5123 - accuracy: 0.7973 - val_loss: 0.4812 - val_accuracy: 0.8162\n",
      "Epoch 263/1000\n",
      "225/225 [==============================] - 0s 1ms/step - loss: 0.5106 - accuracy: 0.7979 - val_loss: 0.4808 - val_accuracy: 0.8151\n",
      "Epoch 264/1000\n",
      "225/225 [==============================] - 0s 1ms/step - loss: 0.5103 - accuracy: 0.7983 - val_loss: 0.4804 - val_accuracy: 0.8168\n",
      "Epoch 265/1000\n",
      "225/225 [==============================] - 0s 1ms/step - loss: 0.5088 - accuracy: 0.7987 - val_loss: 0.4796 - val_accuracy: 0.8184\n",
      "Epoch 266/1000\n",
      "225/225 [==============================] - 0s 1ms/step - loss: 0.5099 - accuracy: 0.7983 - val_loss: 0.4807 - val_accuracy: 0.8136\n",
      "Epoch 267/1000\n",
      "225/225 [==============================] - 0s 1ms/step - loss: 0.5106 - accuracy: 0.7983 - val_loss: 0.4791 - val_accuracy: 0.8151\n",
      "Epoch 268/1000\n",
      "225/225 [==============================] - 0s 1ms/step - loss: 0.5085 - accuracy: 0.7985 - val_loss: 0.4811 - val_accuracy: 0.8133\n",
      "Epoch 269/1000\n",
      "225/225 [==============================] - 0s 1ms/step - loss: 0.5089 - accuracy: 0.7988 - val_loss: 0.4814 - val_accuracy: 0.8138\n",
      "Epoch 270/1000\n",
      "225/225 [==============================] - 0s 1ms/step - loss: 0.5094 - accuracy: 0.7984 - val_loss: 0.4808 - val_accuracy: 0.8121\n",
      "Epoch 271/1000\n",
      "225/225 [==============================] - 0s 1ms/step - loss: 0.5093 - accuracy: 0.7985 - val_loss: 0.4807 - val_accuracy: 0.8162\n",
      "Epoch 272/1000\n",
      "225/225 [==============================] - 0s 1ms/step - loss: 0.5098 - accuracy: 0.7978 - val_loss: 0.4798 - val_accuracy: 0.8164\n",
      "Epoch 273/1000\n",
      "225/225 [==============================] - 0s 1ms/step - loss: 0.5102 - accuracy: 0.7979 - val_loss: 0.4836 - val_accuracy: 0.8145\n",
      "Epoch 274/1000\n",
      "225/225 [==============================] - 0s 1ms/step - loss: 0.5089 - accuracy: 0.7983 - val_loss: 0.4801 - val_accuracy: 0.8159\n",
      "Epoch 275/1000\n",
      "225/225 [==============================] - 0s 1ms/step - loss: 0.5100 - accuracy: 0.7989 - val_loss: 0.4805 - val_accuracy: 0.8146\n",
      "Epoch 276/1000\n",
      "225/225 [==============================] - 0s 1ms/step - loss: 0.5093 - accuracy: 0.7977 - val_loss: 0.4829 - val_accuracy: 0.8141\n",
      "Epoch 277/1000\n",
      "225/225 [==============================] - 0s 1ms/step - loss: 0.5077 - accuracy: 0.7985 - val_loss: 0.4802 - val_accuracy: 0.8152\n",
      "Epoch 278/1000\n",
      "225/225 [==============================] - 0s 1ms/step - loss: 0.5101 - accuracy: 0.7985 - val_loss: 0.4793 - val_accuracy: 0.8149\n",
      "Epoch 279/1000\n",
      "225/225 [==============================] - 0s 2ms/step - loss: 0.5090 - accuracy: 0.7987 - val_loss: 0.4817 - val_accuracy: 0.8139\n",
      "Epoch 280/1000\n",
      "225/225 [==============================] - 0s 1ms/step - loss: 0.5095 - accuracy: 0.7992 - val_loss: 0.4773 - val_accuracy: 0.8167\n",
      "Epoch 281/1000\n",
      "225/225 [==============================] - 0s 1ms/step - loss: 0.5095 - accuracy: 0.7984 - val_loss: 0.4800 - val_accuracy: 0.8169\n",
      "Epoch 282/1000\n",
      "225/225 [==============================] - 0s 1ms/step - loss: 0.5111 - accuracy: 0.7972 - val_loss: 0.4803 - val_accuracy: 0.8161\n",
      "Epoch 283/1000\n",
      "225/225 [==============================] - 0s 1ms/step - loss: 0.5076 - accuracy: 0.7998 - val_loss: 0.4789 - val_accuracy: 0.8159\n",
      "Epoch 284/1000\n",
      "225/225 [==============================] - 0s 1ms/step - loss: 0.5071 - accuracy: 0.8003 - val_loss: 0.4793 - val_accuracy: 0.8154\n",
      "Epoch 285/1000\n",
      "225/225 [==============================] - 0s 1ms/step - loss: 0.5075 - accuracy: 0.7995 - val_loss: 0.4792 - val_accuracy: 0.8163\n",
      "Epoch 286/1000\n",
      "225/225 [==============================] - 0s 1ms/step - loss: 0.5076 - accuracy: 0.7993 - val_loss: 0.4814 - val_accuracy: 0.8146\n",
      "Epoch 287/1000\n",
      "225/225 [==============================] - 0s 1ms/step - loss: 0.5083 - accuracy: 0.8000 - val_loss: 0.4793 - val_accuracy: 0.8155\n",
      "Epoch 288/1000\n",
      "225/225 [==============================] - 0s 1ms/step - loss: 0.5093 - accuracy: 0.7977 - val_loss: 0.4789 - val_accuracy: 0.8157\n",
      "Epoch 289/1000\n",
      "225/225 [==============================] - 0s 1ms/step - loss: 0.5082 - accuracy: 0.7996 - val_loss: 0.4781 - val_accuracy: 0.8163\n",
      "Epoch 290/1000\n",
      "225/225 [==============================] - 0s 1ms/step - loss: 0.5065 - accuracy: 0.8000 - val_loss: 0.4801 - val_accuracy: 0.8148\n",
      "Epoch 291/1000\n",
      "225/225 [==============================] - 0s 1ms/step - loss: 0.5059 - accuracy: 0.7995 - val_loss: 0.4798 - val_accuracy: 0.8166\n",
      "Epoch 292/1000\n",
      "225/225 [==============================] - 0s 1ms/step - loss: 0.5080 - accuracy: 0.7993 - val_loss: 0.4833 - val_accuracy: 0.8132\n",
      "Epoch 293/1000\n",
      "225/225 [==============================] - 0s 1ms/step - loss: 0.5107 - accuracy: 0.7977 - val_loss: 0.4814 - val_accuracy: 0.8154\n",
      "Epoch 294/1000\n",
      "225/225 [==============================] - 0s 1ms/step - loss: 0.5070 - accuracy: 0.7999 - val_loss: 0.4777 - val_accuracy: 0.8159\n",
      "Epoch 295/1000\n",
      "225/225 [==============================] - 0s 1ms/step - loss: 0.5069 - accuracy: 0.8003 - val_loss: 0.4748 - val_accuracy: 0.8172\n",
      "Epoch 296/1000\n",
      "225/225 [==============================] - 0s 1ms/step - loss: 0.5074 - accuracy: 0.7998 - val_loss: 0.4784 - val_accuracy: 0.8163\n",
      "Epoch 297/1000\n",
      "225/225 [==============================] - 0s 1ms/step - loss: 0.5083 - accuracy: 0.7992 - val_loss: 0.4764 - val_accuracy: 0.8167\n",
      "Epoch 298/1000\n",
      "225/225 [==============================] - 0s 1ms/step - loss: 0.5069 - accuracy: 0.8001 - val_loss: 0.4780 - val_accuracy: 0.8144\n",
      "Epoch 299/1000\n",
      "225/225 [==============================] - 0s 1ms/step - loss: 0.5073 - accuracy: 0.7997 - val_loss: 0.4779 - val_accuracy: 0.8142\n",
      "Epoch 300/1000\n",
      "225/225 [==============================] - 0s 1ms/step - loss: 0.5081 - accuracy: 0.7993 - val_loss: 0.4763 - val_accuracy: 0.8158\n",
      "Epoch 301/1000\n",
      "225/225 [==============================] - 0s 1ms/step - loss: 0.5068 - accuracy: 0.8000 - val_loss: 0.4763 - val_accuracy: 0.8164\n",
      "Epoch 302/1000\n",
      "225/225 [==============================] - 0s 1ms/step - loss: 0.5073 - accuracy: 0.7997 - val_loss: 0.4770 - val_accuracy: 0.8155\n",
      "Epoch 303/1000\n",
      "225/225 [==============================] - 0s 1ms/step - loss: 0.5055 - accuracy: 0.8004 - val_loss: 0.4773 - val_accuracy: 0.8179\n",
      "Epoch 304/1000\n",
      "225/225 [==============================] - 0s 1ms/step - loss: 0.5083 - accuracy: 0.7989 - val_loss: 0.4774 - val_accuracy: 0.8171\n",
      "Epoch 305/1000\n",
      "225/225 [==============================] - 0s 1ms/step - loss: 0.5085 - accuracy: 0.7991 - val_loss: 0.4765 - val_accuracy: 0.8171\n",
      "Epoch 306/1000\n",
      "225/225 [==============================] - 0s 1ms/step - loss: 0.5060 - accuracy: 0.8003 - val_loss: 0.4755 - val_accuracy: 0.8179\n",
      "Epoch 307/1000\n",
      "225/225 [==============================] - 0s 1ms/step - loss: 0.5073 - accuracy: 0.7989 - val_loss: 0.4797 - val_accuracy: 0.8162\n",
      "Epoch 308/1000\n",
      "225/225 [==============================] - 0s 1ms/step - loss: 0.5062 - accuracy: 0.7997 - val_loss: 0.4781 - val_accuracy: 0.8174\n",
      "Epoch 309/1000\n",
      "225/225 [==============================] - 0s 1ms/step - loss: 0.5061 - accuracy: 0.8003 - val_loss: 0.4768 - val_accuracy: 0.8180\n",
      "Epoch 310/1000\n",
      "225/225 [==============================] - 0s 1ms/step - loss: 0.5052 - accuracy: 0.8000 - val_loss: 0.4747 - val_accuracy: 0.8191\n",
      "Epoch 311/1000\n",
      "225/225 [==============================] - 0s 1ms/step - loss: 0.5059 - accuracy: 0.8004 - val_loss: 0.4778 - val_accuracy: 0.8169\n",
      "Epoch 312/1000\n",
      "225/225 [==============================] - 0s 1ms/step - loss: 0.5072 - accuracy: 0.7995 - val_loss: 0.4772 - val_accuracy: 0.8151\n",
      "Epoch 313/1000\n",
      "225/225 [==============================] - 0s 1ms/step - loss: 0.5068 - accuracy: 0.7999 - val_loss: 0.4796 - val_accuracy: 0.8151\n",
      "Epoch 314/1000\n",
      "225/225 [==============================] - 0s 1ms/step - loss: 0.5070 - accuracy: 0.8001 - val_loss: 0.4764 - val_accuracy: 0.8163\n",
      "Epoch 315/1000\n",
      "225/225 [==============================] - 0s 1ms/step - loss: 0.5068 - accuracy: 0.8002 - val_loss: 0.4786 - val_accuracy: 0.8158\n",
      "Epoch 316/1000\n",
      "225/225 [==============================] - 0s 1ms/step - loss: 0.5066 - accuracy: 0.7997 - val_loss: 0.4770 - val_accuracy: 0.8151\n",
      "Epoch 317/1000\n",
      "225/225 [==============================] - 0s 1ms/step - loss: 0.5055 - accuracy: 0.8005 - val_loss: 0.4809 - val_accuracy: 0.8139\n",
      "Epoch 318/1000\n",
      "225/225 [==============================] - 0s 1ms/step - loss: 0.5049 - accuracy: 0.8001 - val_loss: 0.4799 - val_accuracy: 0.8140\n",
      "Epoch 319/1000\n",
      "225/225 [==============================] - 0s 1ms/step - loss: 0.5065 - accuracy: 0.8004 - val_loss: 0.4784 - val_accuracy: 0.8168\n",
      "Epoch 320/1000\n",
      "225/225 [==============================] - 0s 1ms/step - loss: 0.5050 - accuracy: 0.8005 - val_loss: 0.4798 - val_accuracy: 0.8140\n",
      "Epoch 321/1000\n",
      "225/225 [==============================] - 0s 1ms/step - loss: 0.5066 - accuracy: 0.8003 - val_loss: 0.4748 - val_accuracy: 0.8159\n",
      "Epoch 322/1000\n",
      "225/225 [==============================] - 0s 1ms/step - loss: 0.5063 - accuracy: 0.7996 - val_loss: 0.4772 - val_accuracy: 0.8161\n",
      "Epoch 323/1000\n",
      "225/225 [==============================] - 0s 1ms/step - loss: 0.5072 - accuracy: 0.7999 - val_loss: 0.4775 - val_accuracy: 0.8162\n",
      "Epoch 324/1000\n",
      "225/225 [==============================] - 0s 1ms/step - loss: 0.5075 - accuracy: 0.8007 - val_loss: 0.4775 - val_accuracy: 0.8166\n",
      "Epoch 325/1000\n",
      "225/225 [==============================] - 0s 1ms/step - loss: 0.5059 - accuracy: 0.8007 - val_loss: 0.4772 - val_accuracy: 0.8158\n",
      "Epoch 326/1000\n",
      "225/225 [==============================] - 0s 1ms/step - loss: 0.5057 - accuracy: 0.8002 - val_loss: 0.4788 - val_accuracy: 0.8166\n",
      "Epoch 327/1000\n",
      "225/225 [==============================] - 0s 1ms/step - loss: 0.5069 - accuracy: 0.8003 - val_loss: 0.4778 - val_accuracy: 0.8146\n",
      "Epoch 328/1000\n",
      "225/225 [==============================] - 0s 1ms/step - loss: 0.5039 - accuracy: 0.8004 - val_loss: 0.4758 - val_accuracy: 0.8171\n",
      "Epoch 329/1000\n",
      "225/225 [==============================] - 0s 1ms/step - loss: 0.5055 - accuracy: 0.8007 - val_loss: 0.4775 - val_accuracy: 0.8156\n",
      "Epoch 330/1000\n",
      "225/225 [==============================] - 0s 1ms/step - loss: 0.5038 - accuracy: 0.8019 - val_loss: 0.4758 - val_accuracy: 0.8158\n",
      "Epoch 331/1000\n",
      "225/225 [==============================] - 0s 1ms/step - loss: 0.5062 - accuracy: 0.7997 - val_loss: 0.4770 - val_accuracy: 0.8162\n",
      "Epoch 332/1000\n",
      "225/225 [==============================] - 0s 1ms/step - loss: 0.5052 - accuracy: 0.8004 - val_loss: 0.4813 - val_accuracy: 0.8151\n",
      "Epoch 333/1000\n",
      "225/225 [==============================] - 0s 1ms/step - loss: 0.5065 - accuracy: 0.8004 - val_loss: 0.4769 - val_accuracy: 0.8162\n",
      "Epoch 334/1000\n",
      "225/225 [==============================] - 0s 1ms/step - loss: 0.5047 - accuracy: 0.8010 - val_loss: 0.4771 - val_accuracy: 0.8155\n",
      "Epoch 335/1000\n",
      "225/225 [==============================] - 0s 1ms/step - loss: 0.5052 - accuracy: 0.8005 - val_loss: 0.4799 - val_accuracy: 0.8155\n",
      "Epoch 336/1000\n",
      "225/225 [==============================] - 0s 1ms/step - loss: 0.5053 - accuracy: 0.8005 - val_loss: 0.4753 - val_accuracy: 0.8177\n",
      "Epoch 337/1000\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "225/225 [==============================] - 0s 1ms/step - loss: 0.5049 - accuracy: 0.8010 - val_loss: 0.4739 - val_accuracy: 0.8162\n",
      "Epoch 338/1000\n",
      "225/225 [==============================] - 0s 1ms/step - loss: 0.5048 - accuracy: 0.7997 - val_loss: 0.4742 - val_accuracy: 0.8177\n",
      "Epoch 339/1000\n",
      "225/225 [==============================] - 0s 1ms/step - loss: 0.5036 - accuracy: 0.8022 - val_loss: 0.4724 - val_accuracy: 0.8164\n",
      "Epoch 340/1000\n",
      "225/225 [==============================] - 0s 1ms/step - loss: 0.5021 - accuracy: 0.8026 - val_loss: 0.4747 - val_accuracy: 0.8168\n",
      "Epoch 341/1000\n",
      "225/225 [==============================] - 0s 1ms/step - loss: 0.5042 - accuracy: 0.8017 - val_loss: 0.4710 - val_accuracy: 0.8180\n",
      "Epoch 342/1000\n",
      "225/225 [==============================] - 0s 1ms/step - loss: 0.5046 - accuracy: 0.8013 - val_loss: 0.4759 - val_accuracy: 0.8165\n",
      "Epoch 343/1000\n",
      "225/225 [==============================] - 0s 1ms/step - loss: 0.5062 - accuracy: 0.8005 - val_loss: 0.4732 - val_accuracy: 0.8180\n",
      "Epoch 344/1000\n",
      "225/225 [==============================] - 0s 1ms/step - loss: 0.5041 - accuracy: 0.8010 - val_loss: 0.4765 - val_accuracy: 0.8144\n",
      "Epoch 345/1000\n",
      "225/225 [==============================] - 0s 1ms/step - loss: 0.5031 - accuracy: 0.8008 - val_loss: 0.4778 - val_accuracy: 0.8162\n",
      "Epoch 346/1000\n",
      "225/225 [==============================] - 0s 1ms/step - loss: 0.5033 - accuracy: 0.8019 - val_loss: 0.4721 - val_accuracy: 0.8205\n",
      "Epoch 347/1000\n",
      "225/225 [==============================] - 0s 1ms/step - loss: 0.5020 - accuracy: 0.8019 - val_loss: 0.4759 - val_accuracy: 0.8162\n",
      "Epoch 348/1000\n",
      "225/225 [==============================] - 0s 1ms/step - loss: 0.5053 - accuracy: 0.8007 - val_loss: 0.4758 - val_accuracy: 0.8177\n",
      "Epoch 349/1000\n",
      "225/225 [==============================] - 0s 1ms/step - loss: 0.5027 - accuracy: 0.8019 - val_loss: 0.4786 - val_accuracy: 0.8149\n",
      "Epoch 350/1000\n",
      "225/225 [==============================] - 0s 1ms/step - loss: 0.5034 - accuracy: 0.8020 - val_loss: 0.4727 - val_accuracy: 0.8194\n",
      "Epoch 351/1000\n",
      "225/225 [==============================] - 0s 1ms/step - loss: 0.5040 - accuracy: 0.8006 - val_loss: 0.4735 - val_accuracy: 0.8178\n",
      "Epoch 352/1000\n",
      "225/225 [==============================] - 0s 1ms/step - loss: 0.5032 - accuracy: 0.8020 - val_loss: 0.4766 - val_accuracy: 0.8176\n",
      "Epoch 353/1000\n",
      "225/225 [==============================] - 0s 1ms/step - loss: 0.5023 - accuracy: 0.8022 - val_loss: 0.4743 - val_accuracy: 0.8188\n",
      "Epoch 354/1000\n",
      "225/225 [==============================] - 0s 1ms/step - loss: 0.5016 - accuracy: 0.8021 - val_loss: 0.4729 - val_accuracy: 0.8202\n",
      "Epoch 355/1000\n",
      "225/225 [==============================] - 0s 1ms/step - loss: 0.5022 - accuracy: 0.8028 - val_loss: 0.4738 - val_accuracy: 0.8190\n",
      "Epoch 356/1000\n",
      "225/225 [==============================] - 0s 1ms/step - loss: 0.5026 - accuracy: 0.8013 - val_loss: 0.4781 - val_accuracy: 0.8151\n",
      "Epoch 357/1000\n",
      "225/225 [==============================] - 0s 1ms/step - loss: 0.5018 - accuracy: 0.8021 - val_loss: 0.4734 - val_accuracy: 0.8195\n",
      "Epoch 358/1000\n",
      "225/225 [==============================] - 0s 1ms/step - loss: 0.5040 - accuracy: 0.8011 - val_loss: 0.4724 - val_accuracy: 0.8183\n",
      "Epoch 359/1000\n",
      "225/225 [==============================] - 0s 1ms/step - loss: 0.5036 - accuracy: 0.8031 - val_loss: 0.4740 - val_accuracy: 0.8164\n",
      "Epoch 360/1000\n",
      "225/225 [==============================] - 0s 1ms/step - loss: 0.5023 - accuracy: 0.8014 - val_loss: 0.4732 - val_accuracy: 0.8179\n",
      "Epoch 361/1000\n",
      "225/225 [==============================] - 0s 1ms/step - loss: 0.5058 - accuracy: 0.8005 - val_loss: 0.4789 - val_accuracy: 0.8138\n",
      "Epoch 362/1000\n",
      "225/225 [==============================] - 0s 1ms/step - loss: 0.5033 - accuracy: 0.8022 - val_loss: 0.4798 - val_accuracy: 0.8162\n",
      "Epoch 363/1000\n",
      "225/225 [==============================] - 0s 1ms/step - loss: 0.5025 - accuracy: 0.8023 - val_loss: 0.4727 - val_accuracy: 0.8202\n",
      "Epoch 364/1000\n",
      "225/225 [==============================] - 0s 1ms/step - loss: 0.5048 - accuracy: 0.8008 - val_loss: 0.4751 - val_accuracy: 0.8173\n",
      "Epoch 365/1000\n",
      "225/225 [==============================] - 0s 1ms/step - loss: 0.5032 - accuracy: 0.8018 - val_loss: 0.4743 - val_accuracy: 0.8167\n",
      "Epoch 366/1000\n",
      "225/225 [==============================] - 0s 1ms/step - loss: 0.5019 - accuracy: 0.8016 - val_loss: 0.4730 - val_accuracy: 0.8171\n",
      "Epoch 367/1000\n",
      "225/225 [==============================] - 0s 1ms/step - loss: 0.5028 - accuracy: 0.8023 - val_loss: 0.4737 - val_accuracy: 0.8184\n",
      "Epoch 368/1000\n",
      "225/225 [==============================] - 0s 1ms/step - loss: 0.5036 - accuracy: 0.8016 - val_loss: 0.4729 - val_accuracy: 0.8181\n",
      "Epoch 369/1000\n",
      "225/225 [==============================] - 0s 1ms/step - loss: 0.5024 - accuracy: 0.8017 - val_loss: 0.4749 - val_accuracy: 0.8186\n",
      "Epoch 370/1000\n",
      "225/225 [==============================] - 0s 1ms/step - loss: 0.5038 - accuracy: 0.8006 - val_loss: 0.4747 - val_accuracy: 0.8193\n",
      "Epoch 371/1000\n",
      "225/225 [==============================] - 0s 1ms/step - loss: 0.5014 - accuracy: 0.8027 - val_loss: 0.4773 - val_accuracy: 0.8161\n",
      "Epoch 372/1000\n",
      "225/225 [==============================] - 0s 1ms/step - loss: 0.5030 - accuracy: 0.8019 - val_loss: 0.4719 - val_accuracy: 0.8206\n",
      "Epoch 373/1000\n",
      "225/225 [==============================] - 0s 1ms/step - loss: 0.5019 - accuracy: 0.8017 - val_loss: 0.4751 - val_accuracy: 0.8182\n",
      "Epoch 374/1000\n",
      "225/225 [==============================] - 0s 1ms/step - loss: 0.5029 - accuracy: 0.8029 - val_loss: 0.4763 - val_accuracy: 0.8178\n",
      "Epoch 375/1000\n",
      "225/225 [==============================] - 0s 2ms/step - loss: 0.5025 - accuracy: 0.8020 - val_loss: 0.4766 - val_accuracy: 0.8170\n",
      "Epoch 376/1000\n",
      "225/225 [==============================] - 0s 1ms/step - loss: 0.5019 - accuracy: 0.8020 - val_loss: 0.4772 - val_accuracy: 0.8183\n",
      "Epoch 377/1000\n",
      "225/225 [==============================] - 0s 1ms/step - loss: 0.5014 - accuracy: 0.8024 - val_loss: 0.4744 - val_accuracy: 0.8180\n",
      "Epoch 378/1000\n",
      "225/225 [==============================] - 0s 1ms/step - loss: 0.5027 - accuracy: 0.8014 - val_loss: 0.4752 - val_accuracy: 0.8191\n",
      "Epoch 379/1000\n",
      "225/225 [==============================] - 0s 1ms/step - loss: 0.5036 - accuracy: 0.8016 - val_loss: 0.4731 - val_accuracy: 0.8166\n",
      "Epoch 380/1000\n",
      "225/225 [==============================] - 0s 1ms/step - loss: 0.5015 - accuracy: 0.8018 - val_loss: 0.4748 - val_accuracy: 0.8168\n",
      "Epoch 381/1000\n",
      "225/225 [==============================] - 0s 1ms/step - loss: 0.5037 - accuracy: 0.8010 - val_loss: 0.4780 - val_accuracy: 0.8162\n",
      "Epoch 382/1000\n",
      "225/225 [==============================] - 0s 1ms/step - loss: 0.4996 - accuracy: 0.8031 - val_loss: 0.4765 - val_accuracy: 0.8157\n",
      "Epoch 383/1000\n",
      "225/225 [==============================] - 0s 1ms/step - loss: 0.5041 - accuracy: 0.8015 - val_loss: 0.4747 - val_accuracy: 0.8144\n",
      "Epoch 384/1000\n",
      "225/225 [==============================] - 0s 1ms/step - loss: 0.5010 - accuracy: 0.8024 - val_loss: 0.4736 - val_accuracy: 0.8179\n",
      "Epoch 385/1000\n",
      "225/225 [==============================] - 0s 1ms/step - loss: 0.5027 - accuracy: 0.8018 - val_loss: 0.4757 - val_accuracy: 0.8160\n",
      "Epoch 386/1000\n",
      "225/225 [==============================] - 0s 1ms/step - loss: 0.5024 - accuracy: 0.8029 - val_loss: 0.4720 - val_accuracy: 0.8204\n",
      "Epoch 387/1000\n",
      "225/225 [==============================] - 0s 1ms/step - loss: 0.5030 - accuracy: 0.8013 - val_loss: 0.4723 - val_accuracy: 0.8177\n",
      "Epoch 388/1000\n",
      "225/225 [==============================] - 0s 1ms/step - loss: 0.5039 - accuracy: 0.8010 - val_loss: 0.4743 - val_accuracy: 0.8182\n",
      "Epoch 389/1000\n",
      "225/225 [==============================] - 0s 1ms/step - loss: 0.5016 - accuracy: 0.8017 - val_loss: 0.4747 - val_accuracy: 0.8175\n",
      "Epoch 390/1000\n",
      "225/225 [==============================] - 0s 1ms/step - loss: 0.5025 - accuracy: 0.8019 - val_loss: 0.4723 - val_accuracy: 0.8208\n",
      "Epoch 391/1000\n",
      "225/225 [==============================] - 0s 1ms/step - loss: 0.5015 - accuracy: 0.8023 - val_loss: 0.4697 - val_accuracy: 0.8199\n",
      "Epoch 392/1000\n",
      "225/225 [==============================] - 0s 1ms/step - loss: 0.5031 - accuracy: 0.8007 - val_loss: 0.4736 - val_accuracy: 0.8171\n",
      "Epoch 393/1000\n",
      "225/225 [==============================] - 0s 1ms/step - loss: 0.5025 - accuracy: 0.8029 - val_loss: 0.4723 - val_accuracy: 0.8187\n",
      "Epoch 394/1000\n",
      "225/225 [==============================] - 0s 1ms/step - loss: 0.5009 - accuracy: 0.8024 - val_loss: 0.4701 - val_accuracy: 0.8203\n",
      "Epoch 395/1000\n",
      "225/225 [==============================] - 0s 1ms/step - loss: 0.5000 - accuracy: 0.8038 - val_loss: 0.4741 - val_accuracy: 0.8162\n",
      "Epoch 396/1000\n",
      "225/225 [==============================] - 0s 1ms/step - loss: 0.5028 - accuracy: 0.8022 - val_loss: 0.4755 - val_accuracy: 0.8173\n",
      "Epoch 397/1000\n",
      "225/225 [==============================] - 0s 1ms/step - loss: 0.5023 - accuracy: 0.8023 - val_loss: 0.4719 - val_accuracy: 0.8206\n",
      "Epoch 398/1000\n",
      "225/225 [==============================] - 0s 1ms/step - loss: 0.5013 - accuracy: 0.8018 - val_loss: 0.4720 - val_accuracy: 0.8198\n",
      "Epoch 399/1000\n",
      "225/225 [==============================] - 0s 1ms/step - loss: 0.4995 - accuracy: 0.8030 - val_loss: 0.4699 - val_accuracy: 0.8205\n",
      "Epoch 400/1000\n",
      "225/225 [==============================] - 0s 1ms/step - loss: 0.5031 - accuracy: 0.8009 - val_loss: 0.4717 - val_accuracy: 0.8182\n",
      "Epoch 401/1000\n",
      "225/225 [==============================] - 0s 1ms/step - loss: 0.4991 - accuracy: 0.8035 - val_loss: 0.4716 - val_accuracy: 0.8195\n",
      "Epoch 402/1000\n",
      "225/225 [==============================] - 0s 1ms/step - loss: 0.5011 - accuracy: 0.8020 - val_loss: 0.4720 - val_accuracy: 0.8194\n",
      "Epoch 403/1000\n",
      "225/225 [==============================] - 0s 1ms/step - loss: 0.5006 - accuracy: 0.8031 - val_loss: 0.4738 - val_accuracy: 0.8177\n",
      "Epoch 404/1000\n",
      "225/225 [==============================] - 0s 1ms/step - loss: 0.5015 - accuracy: 0.8024 - val_loss: 0.4731 - val_accuracy: 0.8188\n",
      "Epoch 405/1000\n",
      "225/225 [==============================] - 0s 1ms/step - loss: 0.5007 - accuracy: 0.8029 - val_loss: 0.4728 - val_accuracy: 0.8192\n",
      "Epoch 406/1000\n",
      "225/225 [==============================] - 0s 1ms/step - loss: 0.5013 - accuracy: 0.8028 - val_loss: 0.4703 - val_accuracy: 0.8212\n",
      "Epoch 407/1000\n",
      "225/225 [==============================] - 0s 1ms/step - loss: 0.4998 - accuracy: 0.8032 - val_loss: 0.4756 - val_accuracy: 0.8184\n",
      "Epoch 408/1000\n",
      "225/225 [==============================] - 0s 1ms/step - loss: 0.5000 - accuracy: 0.8028 - val_loss: 0.4690 - val_accuracy: 0.8209\n",
      "Epoch 409/1000\n",
      "225/225 [==============================] - 0s 1ms/step - loss: 0.4989 - accuracy: 0.8042 - val_loss: 0.4717 - val_accuracy: 0.8198\n",
      "Epoch 410/1000\n",
      "225/225 [==============================] - 0s 1ms/step - loss: 0.5011 - accuracy: 0.8026 - val_loss: 0.4717 - val_accuracy: 0.8196\n",
      "Epoch 411/1000\n",
      "225/225 [==============================] - 0s 1ms/step - loss: 0.5018 - accuracy: 0.8016 - val_loss: 0.4710 - val_accuracy: 0.8203\n",
      "Epoch 412/1000\n",
      "225/225 [==============================] - 0s 1ms/step - loss: 0.4993 - accuracy: 0.8044 - val_loss: 0.4724 - val_accuracy: 0.8192\n",
      "Epoch 413/1000\n",
      "225/225 [==============================] - 0s 1ms/step - loss: 0.5013 - accuracy: 0.8037 - val_loss: 0.4717 - val_accuracy: 0.8226\n",
      "Epoch 414/1000\n",
      "225/225 [==============================] - 0s 1ms/step - loss: 0.5026 - accuracy: 0.8026 - val_loss: 0.4695 - val_accuracy: 0.8225\n",
      "Epoch 415/1000\n",
      "225/225 [==============================] - 0s 1ms/step - loss: 0.4998 - accuracy: 0.8029 - val_loss: 0.4698 - val_accuracy: 0.8220\n",
      "Epoch 416/1000\n",
      "225/225 [==============================] - 0s 1ms/step - loss: 0.4998 - accuracy: 0.8031 - val_loss: 0.4681 - val_accuracy: 0.8206\n",
      "Epoch 417/1000\n",
      "225/225 [==============================] - 0s 1ms/step - loss: 0.5002 - accuracy: 0.8031 - val_loss: 0.4712 - val_accuracy: 0.8195\n",
      "Epoch 418/1000\n",
      "225/225 [==============================] - 0s 1ms/step - loss: 0.5019 - accuracy: 0.8022 - val_loss: 0.4707 - val_accuracy: 0.8215\n",
      "Epoch 419/1000\n",
      "225/225 [==============================] - 0s 1ms/step - loss: 0.4994 - accuracy: 0.8041 - val_loss: 0.4686 - val_accuracy: 0.8223\n",
      "Epoch 420/1000\n",
      "225/225 [==============================] - 0s 1ms/step - loss: 0.5012 - accuracy: 0.8033 - val_loss: 0.4705 - val_accuracy: 0.8191\n",
      "Epoch 421/1000\n",
      "225/225 [==============================] - 0s 1ms/step - loss: 0.5008 - accuracy: 0.8029 - val_loss: 0.4698 - val_accuracy: 0.8194\n",
      "Epoch 422/1000\n",
      "225/225 [==============================] - 0s 1ms/step - loss: 0.5016 - accuracy: 0.8030 - val_loss: 0.4696 - val_accuracy: 0.8193\n",
      "Epoch 423/1000\n",
      "225/225 [==============================] - 0s 1ms/step - loss: 0.5017 - accuracy: 0.8032 - val_loss: 0.4710 - val_accuracy: 0.8182\n",
      "Epoch 424/1000\n",
      "225/225 [==============================] - 0s 1ms/step - loss: 0.5000 - accuracy: 0.8021 - val_loss: 0.4717 - val_accuracy: 0.8203\n",
      "Epoch 425/1000\n",
      "225/225 [==============================] - 0s 1ms/step - loss: 0.4997 - accuracy: 0.8029 - val_loss: 0.4690 - val_accuracy: 0.8217\n",
      "Epoch 426/1000\n",
      "225/225 [==============================] - 0s 1ms/step - loss: 0.4986 - accuracy: 0.8038 - val_loss: 0.4686 - val_accuracy: 0.8213\n",
      "Epoch 427/1000\n",
      "225/225 [==============================] - 0s 1ms/step - loss: 0.4993 - accuracy: 0.8034 - val_loss: 0.4681 - val_accuracy: 0.8225\n",
      "Epoch 428/1000\n",
      "225/225 [==============================] - 0s 1ms/step - loss: 0.4995 - accuracy: 0.8034 - val_loss: 0.4685 - val_accuracy: 0.8215\n",
      "Epoch 429/1000\n",
      "225/225 [==============================] - 0s 1ms/step - loss: 0.5002 - accuracy: 0.8036 - val_loss: 0.4682 - val_accuracy: 0.8237\n",
      "Epoch 430/1000\n",
      "225/225 [==============================] - 0s 1ms/step - loss: 0.4987 - accuracy: 0.8044 - val_loss: 0.4713 - val_accuracy: 0.8198\n",
      "Epoch 431/1000\n",
      "225/225 [==============================] - 0s 1ms/step - loss: 0.5007 - accuracy: 0.8029 - val_loss: 0.4710 - val_accuracy: 0.8186\n",
      "Epoch 432/1000\n",
      "225/225 [==============================] - 0s 1ms/step - loss: 0.5013 - accuracy: 0.8020 - val_loss: 0.4713 - val_accuracy: 0.8204\n",
      "Epoch 433/1000\n",
      "225/225 [==============================] - 0s 1ms/step - loss: 0.4989 - accuracy: 0.8040 - val_loss: 0.4714 - val_accuracy: 0.8217\n",
      "Epoch 434/1000\n",
      "225/225 [==============================] - 0s 1ms/step - loss: 0.4994 - accuracy: 0.8039 - val_loss: 0.4685 - val_accuracy: 0.8217\n",
      "Epoch 435/1000\n",
      "225/225 [==============================] - 0s 1ms/step - loss: 0.4980 - accuracy: 0.8043 - val_loss: 0.4699 - val_accuracy: 0.8210\n",
      "Epoch 436/1000\n",
      "225/225 [==============================] - 0s 1ms/step - loss: 0.4987 - accuracy: 0.8041 - val_loss: 0.4707 - val_accuracy: 0.8202\n",
      "Epoch 437/1000\n",
      "225/225 [==============================] - 0s 1ms/step - loss: 0.5003 - accuracy: 0.8037 - val_loss: 0.4707 - val_accuracy: 0.8217\n",
      "Epoch 438/1000\n",
      "225/225 [==============================] - 0s 1ms/step - loss: 0.4997 - accuracy: 0.8031 - val_loss: 0.4702 - val_accuracy: 0.8195\n",
      "Epoch 439/1000\n",
      "225/225 [==============================] - 0s 1ms/step - loss: 0.4992 - accuracy: 0.8035 - val_loss: 0.4695 - val_accuracy: 0.8207\n",
      "Epoch 440/1000\n",
      "225/225 [==============================] - 0s 1ms/step - loss: 0.4997 - accuracy: 0.8035 - val_loss: 0.4680 - val_accuracy: 0.8198\n",
      "Epoch 441/1000\n",
      "225/225 [==============================] - 0s 1ms/step - loss: 0.4987 - accuracy: 0.8039 - val_loss: 0.4701 - val_accuracy: 0.8195\n",
      "Epoch 442/1000\n",
      "225/225 [==============================] - 0s 1ms/step - loss: 0.4990 - accuracy: 0.8041 - val_loss: 0.4733 - val_accuracy: 0.8169\n",
      "Epoch 443/1000\n",
      "225/225 [==============================] - 0s 1ms/step - loss: 0.5002 - accuracy: 0.8029 - val_loss: 0.4733 - val_accuracy: 0.8174\n",
      "Epoch 444/1000\n",
      "225/225 [==============================] - 0s 1ms/step - loss: 0.5000 - accuracy: 0.8038 - val_loss: 0.4701 - val_accuracy: 0.8196\n",
      "Epoch 445/1000\n",
      "225/225 [==============================] - 0s 1ms/step - loss: 0.4996 - accuracy: 0.8038 - val_loss: 0.4738 - val_accuracy: 0.8162\n",
      "Epoch 446/1000\n",
      "225/225 [==============================] - 0s 1ms/step - loss: 0.5003 - accuracy: 0.8035 - val_loss: 0.4715 - val_accuracy: 0.8199\n",
      "Epoch 447/1000\n",
      "225/225 [==============================] - 0s 1ms/step - loss: 0.4984 - accuracy: 0.8030 - val_loss: 0.4713 - val_accuracy: 0.8206\n",
      "Epoch 448/1000\n",
      "225/225 [==============================] - 0s 1ms/step - loss: 0.4977 - accuracy: 0.8042 - val_loss: 0.4707 - val_accuracy: 0.8203\n",
      "Epoch 449/1000\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "225/225 [==============================] - 0s 1ms/step - loss: 0.4984 - accuracy: 0.8037 - val_loss: 0.4721 - val_accuracy: 0.8197\n",
      "Epoch 450/1000\n",
      "225/225 [==============================] - 0s 1ms/step - loss: 0.5003 - accuracy: 0.8029 - val_loss: 0.4696 - val_accuracy: 0.8191\n",
      "Epoch 451/1000\n",
      "225/225 [==============================] - 0s 1ms/step - loss: 0.4985 - accuracy: 0.8037 - val_loss: 0.4696 - val_accuracy: 0.8201\n",
      "Epoch 452/1000\n",
      "225/225 [==============================] - 0s 1ms/step - loss: 0.4982 - accuracy: 0.8042 - val_loss: 0.4701 - val_accuracy: 0.8213\n",
      "Epoch 453/1000\n",
      "225/225 [==============================] - 0s 1ms/step - loss: 0.4972 - accuracy: 0.8040 - val_loss: 0.4688 - val_accuracy: 0.8208\n",
      "Epoch 454/1000\n",
      "225/225 [==============================] - 0s 1ms/step - loss: 0.4999 - accuracy: 0.8036 - val_loss: 0.4689 - val_accuracy: 0.8210\n",
      "Epoch 455/1000\n",
      "225/225 [==============================] - 0s 1ms/step - loss: 0.4980 - accuracy: 0.8048 - val_loss: 0.4690 - val_accuracy: 0.8206\n",
      "Epoch 456/1000\n",
      "225/225 [==============================] - 0s 1ms/step - loss: 0.4994 - accuracy: 0.8033 - val_loss: 0.4703 - val_accuracy: 0.8200\n",
      "Epoch 457/1000\n",
      "225/225 [==============================] - 0s 1ms/step - loss: 0.4985 - accuracy: 0.8048 - val_loss: 0.4719 - val_accuracy: 0.8198\n",
      "Epoch 458/1000\n",
      "225/225 [==============================] - 0s 1ms/step - loss: 0.4983 - accuracy: 0.8037 - val_loss: 0.4696 - val_accuracy: 0.8211\n",
      "Epoch 459/1000\n",
      "225/225 [==============================] - 0s 1ms/step - loss: 0.4982 - accuracy: 0.8039 - val_loss: 0.4695 - val_accuracy: 0.8220\n",
      "Epoch 460/1000\n",
      "225/225 [==============================] - 0s 1ms/step - loss: 0.4976 - accuracy: 0.8048 - val_loss: 0.4685 - val_accuracy: 0.8213\n",
      "Epoch 461/1000\n",
      "225/225 [==============================] - 0s 1ms/step - loss: 0.4995 - accuracy: 0.8036 - val_loss: 0.4687 - val_accuracy: 0.8211\n",
      "Epoch 462/1000\n",
      "225/225 [==============================] - 0s 1ms/step - loss: 0.4989 - accuracy: 0.8042 - val_loss: 0.4691 - val_accuracy: 0.8199\n",
      "Epoch 463/1000\n",
      "225/225 [==============================] - 0s 1ms/step - loss: 0.4986 - accuracy: 0.8037 - val_loss: 0.4683 - val_accuracy: 0.8222\n",
      "Epoch 464/1000\n",
      "225/225 [==============================] - 0s 1ms/step - loss: 0.4988 - accuracy: 0.8043 - val_loss: 0.4696 - val_accuracy: 0.8216\n",
      "Epoch 465/1000\n",
      "225/225 [==============================] - 0s 1ms/step - loss: 0.4996 - accuracy: 0.8043 - val_loss: 0.4723 - val_accuracy: 0.8189\n",
      "Epoch 466/1000\n",
      "225/225 [==============================] - 0s 1ms/step - loss: 0.4970 - accuracy: 0.8040 - val_loss: 0.4672 - val_accuracy: 0.8223\n",
      "Epoch 467/1000\n",
      "225/225 [==============================] - 0s 1ms/step - loss: 0.4982 - accuracy: 0.8037 - val_loss: 0.4693 - val_accuracy: 0.8209\n",
      "Epoch 468/1000\n",
      "225/225 [==============================] - 0s 1ms/step - loss: 0.4981 - accuracy: 0.8038 - val_loss: 0.4687 - val_accuracy: 0.8219\n",
      "Epoch 469/1000\n",
      "225/225 [==============================] - 0s 1ms/step - loss: 0.4968 - accuracy: 0.8046 - val_loss: 0.4744 - val_accuracy: 0.8173\n",
      "Epoch 470/1000\n",
      "225/225 [==============================] - 0s 1ms/step - loss: 0.4996 - accuracy: 0.8029 - val_loss: 0.4692 - val_accuracy: 0.8208\n",
      "Epoch 471/1000\n",
      "225/225 [==============================] - 0s 1ms/step - loss: 0.4965 - accuracy: 0.8053 - val_loss: 0.4705 - val_accuracy: 0.8188\n",
      "Epoch 472/1000\n",
      "225/225 [==============================] - 0s 1ms/step - loss: 0.4985 - accuracy: 0.8037 - val_loss: 0.4676 - val_accuracy: 0.8211\n",
      "Epoch 473/1000\n",
      "225/225 [==============================] - 0s 1ms/step - loss: 0.4992 - accuracy: 0.8039 - val_loss: 0.4661 - val_accuracy: 0.8216\n",
      "Epoch 474/1000\n",
      "225/225 [==============================] - 0s 1ms/step - loss: 0.4990 - accuracy: 0.8029 - val_loss: 0.4683 - val_accuracy: 0.8209\n",
      "Epoch 475/1000\n",
      "225/225 [==============================] - 0s 1ms/step - loss: 0.4958 - accuracy: 0.8039 - val_loss: 0.4676 - val_accuracy: 0.8211\n",
      "Epoch 476/1000\n",
      "225/225 [==============================] - 0s 1ms/step - loss: 0.4989 - accuracy: 0.8037 - val_loss: 0.4728 - val_accuracy: 0.8202\n",
      "Epoch 477/1000\n",
      "225/225 [==============================] - 0s 1ms/step - loss: 0.4989 - accuracy: 0.8034 - val_loss: 0.4700 - val_accuracy: 0.8182\n",
      "Epoch 478/1000\n",
      "225/225 [==============================] - 0s 1ms/step - loss: 0.4969 - accuracy: 0.8043 - val_loss: 0.4687 - val_accuracy: 0.8216\n",
      "Epoch 479/1000\n",
      "225/225 [==============================] - 0s 1ms/step - loss: 0.4973 - accuracy: 0.8055 - val_loss: 0.4705 - val_accuracy: 0.8186\n",
      "Epoch 480/1000\n",
      "225/225 [==============================] - 0s 1ms/step - loss: 0.4983 - accuracy: 0.8049 - val_loss: 0.4705 - val_accuracy: 0.8197\n",
      "Epoch 481/1000\n",
      "225/225 [==============================] - 0s 1ms/step - loss: 0.4962 - accuracy: 0.8054 - val_loss: 0.4695 - val_accuracy: 0.8191\n",
      "Epoch 482/1000\n",
      "225/225 [==============================] - 0s 1ms/step - loss: 0.4964 - accuracy: 0.8047 - val_loss: 0.4742 - val_accuracy: 0.8182\n",
      "Epoch 483/1000\n",
      "225/225 [==============================] - 0s 1ms/step - loss: 0.4982 - accuracy: 0.8037 - val_loss: 0.4675 - val_accuracy: 0.8207\n",
      "Epoch 484/1000\n",
      "225/225 [==============================] - 0s 1ms/step - loss: 0.4988 - accuracy: 0.8032 - val_loss: 0.4679 - val_accuracy: 0.8219\n",
      "Epoch 485/1000\n",
      "225/225 [==============================] - 0s 1ms/step - loss: 0.4979 - accuracy: 0.8042 - val_loss: 0.4680 - val_accuracy: 0.8223\n",
      "Epoch 486/1000\n",
      "225/225 [==============================] - 0s 1ms/step - loss: 0.4970 - accuracy: 0.8060 - val_loss: 0.4716 - val_accuracy: 0.8200\n",
      "Epoch 487/1000\n",
      "225/225 [==============================] - 0s 1ms/step - loss: 0.4964 - accuracy: 0.8053 - val_loss: 0.4673 - val_accuracy: 0.8228\n",
      "Epoch 488/1000\n",
      "225/225 [==============================] - 0s 1ms/step - loss: 0.4965 - accuracy: 0.8056 - val_loss: 0.4679 - val_accuracy: 0.8201\n",
      "Epoch 489/1000\n",
      "225/225 [==============================] - 0s 1ms/step - loss: 0.4989 - accuracy: 0.8035 - val_loss: 0.4671 - val_accuracy: 0.8224\n",
      "Epoch 490/1000\n",
      "225/225 [==============================] - 0s 1ms/step - loss: 0.4977 - accuracy: 0.8044 - val_loss: 0.4688 - val_accuracy: 0.8193\n",
      "Epoch 491/1000\n",
      "225/225 [==============================] - 0s 1ms/step - loss: 0.4955 - accuracy: 0.8047 - val_loss: 0.4656 - val_accuracy: 0.8209\n",
      "Epoch 492/1000\n",
      "225/225 [==============================] - 0s 1ms/step - loss: 0.4979 - accuracy: 0.8039 - val_loss: 0.4684 - val_accuracy: 0.8207\n",
      "Epoch 493/1000\n",
      "225/225 [==============================] - 0s 1ms/step - loss: 0.4984 - accuracy: 0.8038 - val_loss: 0.4685 - val_accuracy: 0.8203\n",
      "Epoch 494/1000\n",
      "225/225 [==============================] - 0s 1ms/step - loss: 0.4955 - accuracy: 0.8060 - val_loss: 0.4706 - val_accuracy: 0.8216\n",
      "Epoch 495/1000\n",
      "225/225 [==============================] - 0s 1ms/step - loss: 0.4957 - accuracy: 0.8052 - val_loss: 0.4683 - val_accuracy: 0.8206\n",
      "Epoch 496/1000\n",
      "225/225 [==============================] - 0s 1ms/step - loss: 0.4962 - accuracy: 0.8045 - val_loss: 0.4673 - val_accuracy: 0.8197\n",
      "Epoch 497/1000\n",
      "225/225 [==============================] - 0s 1ms/step - loss: 0.4971 - accuracy: 0.8039 - val_loss: 0.4671 - val_accuracy: 0.8209\n",
      "Epoch 498/1000\n",
      "225/225 [==============================] - 0s 1ms/step - loss: 0.4973 - accuracy: 0.8043 - val_loss: 0.4684 - val_accuracy: 0.8214\n",
      "Epoch 499/1000\n",
      "225/225 [==============================] - 0s 1ms/step - loss: 0.4971 - accuracy: 0.8048 - val_loss: 0.4705 - val_accuracy: 0.8204\n",
      "Epoch 500/1000\n",
      "225/225 [==============================] - 0s 1ms/step - loss: 0.4968 - accuracy: 0.8047 - val_loss: 0.4675 - val_accuracy: 0.8226\n",
      "Epoch 501/1000\n",
      "225/225 [==============================] - 0s 1ms/step - loss: 0.4984 - accuracy: 0.8039 - val_loss: 0.4693 - val_accuracy: 0.8194\n",
      "Epoch 502/1000\n",
      "225/225 [==============================] - 0s 1ms/step - loss: 0.4951 - accuracy: 0.8053 - val_loss: 0.4692 - val_accuracy: 0.8204\n",
      "Epoch 503/1000\n",
      "225/225 [==============================] - 0s 1ms/step - loss: 0.4951 - accuracy: 0.8053 - val_loss: 0.4675 - val_accuracy: 0.8222\n",
      "Epoch 504/1000\n",
      "225/225 [==============================] - 0s 1ms/step - loss: 0.4974 - accuracy: 0.8047 - val_loss: 0.4665 - val_accuracy: 0.8201\n",
      "Epoch 505/1000\n",
      "225/225 [==============================] - 0s 1ms/step - loss: 0.4979 - accuracy: 0.8054 - val_loss: 0.4663 - val_accuracy: 0.8209\n",
      "Epoch 506/1000\n",
      "225/225 [==============================] - 0s 1ms/step - loss: 0.4960 - accuracy: 0.8060 - val_loss: 0.4651 - val_accuracy: 0.8209\n",
      "Epoch 507/1000\n",
      "225/225 [==============================] - 0s 1ms/step - loss: 0.4968 - accuracy: 0.8049 - val_loss: 0.4670 - val_accuracy: 0.8223\n",
      "Epoch 508/1000\n",
      "225/225 [==============================] - 0s 1ms/step - loss: 0.4967 - accuracy: 0.8053 - val_loss: 0.4665 - val_accuracy: 0.8214\n",
      "Epoch 509/1000\n",
      "225/225 [==============================] - 0s 1ms/step - loss: 0.4965 - accuracy: 0.8032 - val_loss: 0.4690 - val_accuracy: 0.8209\n",
      "Epoch 510/1000\n",
      "225/225 [==============================] - 0s 1ms/step - loss: 0.4945 - accuracy: 0.8057 - val_loss: 0.4689 - val_accuracy: 0.8204\n",
      "Epoch 511/1000\n",
      "225/225 [==============================] - 0s 1ms/step - loss: 0.4959 - accuracy: 0.8049 - val_loss: 0.4696 - val_accuracy: 0.8201\n",
      "Epoch 512/1000\n",
      "225/225 [==============================] - 0s 1ms/step - loss: 0.4968 - accuracy: 0.8047 - val_loss: 0.4712 - val_accuracy: 0.8206\n",
      "Epoch 513/1000\n",
      "225/225 [==============================] - 0s 1ms/step - loss: 0.4934 - accuracy: 0.8064 - val_loss: 0.4672 - val_accuracy: 0.8188\n",
      "Epoch 514/1000\n",
      "225/225 [==============================] - 0s 1ms/step - loss: 0.4945 - accuracy: 0.8050 - val_loss: 0.4688 - val_accuracy: 0.8224\n",
      "Epoch 515/1000\n",
      "225/225 [==============================] - 0s 1ms/step - loss: 0.4968 - accuracy: 0.8055 - val_loss: 0.4698 - val_accuracy: 0.8210\n",
      "Epoch 516/1000\n",
      "225/225 [==============================] - 0s 1ms/step - loss: 0.4955 - accuracy: 0.8049 - val_loss: 0.4673 - val_accuracy: 0.8217\n",
      "Epoch 517/1000\n",
      "225/225 [==============================] - 0s 1ms/step - loss: 0.4968 - accuracy: 0.8048 - val_loss: 0.4686 - val_accuracy: 0.8198\n",
      "Epoch 518/1000\n",
      "225/225 [==============================] - 0s 1ms/step - loss: 0.4963 - accuracy: 0.8040 - val_loss: 0.4663 - val_accuracy: 0.8212\n",
      "Epoch 519/1000\n",
      "225/225 [==============================] - 0s 1ms/step - loss: 0.4962 - accuracy: 0.8048 - val_loss: 0.4660 - val_accuracy: 0.8219\n",
      "Epoch 520/1000\n",
      "225/225 [==============================] - 0s 1ms/step - loss: 0.4969 - accuracy: 0.8053 - val_loss: 0.4652 - val_accuracy: 0.8227\n",
      "Epoch 521/1000\n",
      "225/225 [==============================] - 0s 1ms/step - loss: 0.4956 - accuracy: 0.8044 - val_loss: 0.4676 - val_accuracy: 0.8204\n",
      "Epoch 522/1000\n",
      "225/225 [==============================] - 0s 1ms/step - loss: 0.4965 - accuracy: 0.8051 - val_loss: 0.4653 - val_accuracy: 0.8211\n",
      "Epoch 523/1000\n",
      "225/225 [==============================] - 0s 1ms/step - loss: 0.4950 - accuracy: 0.8052 - val_loss: 0.4665 - val_accuracy: 0.8217\n",
      "Epoch 524/1000\n",
      "225/225 [==============================] - 0s 1ms/step - loss: 0.4952 - accuracy: 0.8052 - val_loss: 0.4674 - val_accuracy: 0.8230\n",
      "Epoch 525/1000\n",
      "225/225 [==============================] - 0s 1ms/step - loss: 0.4945 - accuracy: 0.8065 - val_loss: 0.4672 - val_accuracy: 0.8228\n",
      "Epoch 526/1000\n",
      "225/225 [==============================] - 0s 1ms/step - loss: 0.4954 - accuracy: 0.8049 - val_loss: 0.4653 - val_accuracy: 0.8228\n",
      "Epoch 527/1000\n",
      "225/225 [==============================] - 0s 1ms/step - loss: 0.4965 - accuracy: 0.8048 - val_loss: 0.4683 - val_accuracy: 0.8209\n",
      "Epoch 528/1000\n",
      "225/225 [==============================] - 0s 1ms/step - loss: 0.4966 - accuracy: 0.8050 - val_loss: 0.4660 - val_accuracy: 0.8210\n",
      "Epoch 529/1000\n",
      "225/225 [==============================] - 0s 1ms/step - loss: 0.4970 - accuracy: 0.8046 - val_loss: 0.4656 - val_accuracy: 0.8217\n",
      "Epoch 530/1000\n",
      "225/225 [==============================] - 0s 1ms/step - loss: 0.4945 - accuracy: 0.8060 - val_loss: 0.4690 - val_accuracy: 0.8217\n",
      "Epoch 531/1000\n",
      "225/225 [==============================] - 0s 1ms/step - loss: 0.4953 - accuracy: 0.8055 - val_loss: 0.4676 - val_accuracy: 0.8217\n",
      "Epoch 532/1000\n",
      "225/225 [==============================] - 0s 1ms/step - loss: 0.4945 - accuracy: 0.8068 - val_loss: 0.4653 - val_accuracy: 0.8228\n",
      "Epoch 533/1000\n",
      "225/225 [==============================] - 0s 1ms/step - loss: 0.4970 - accuracy: 0.8054 - val_loss: 0.4688 - val_accuracy: 0.8198\n",
      "Epoch 534/1000\n",
      "225/225 [==============================] - 0s 1ms/step - loss: 0.4949 - accuracy: 0.8057 - val_loss: 0.4678 - val_accuracy: 0.8209\n",
      "Epoch 535/1000\n",
      "225/225 [==============================] - 0s 1ms/step - loss: 0.4959 - accuracy: 0.8052 - val_loss: 0.4666 - val_accuracy: 0.8211\n",
      "Epoch 536/1000\n",
      "225/225 [==============================] - 0s 1ms/step - loss: 0.4939 - accuracy: 0.8059 - val_loss: 0.4724 - val_accuracy: 0.8193\n",
      "Epoch 537/1000\n",
      "225/225 [==============================] - 0s 1ms/step - loss: 0.4974 - accuracy: 0.8042 - val_loss: 0.4679 - val_accuracy: 0.8211\n",
      "Epoch 538/1000\n",
      "225/225 [==============================] - 0s 1ms/step - loss: 0.4954 - accuracy: 0.8056 - val_loss: 0.4664 - val_accuracy: 0.8208\n",
      "Epoch 539/1000\n",
      "225/225 [==============================] - 0s 1ms/step - loss: 0.4952 - accuracy: 0.8055 - val_loss: 0.4666 - val_accuracy: 0.8206\n",
      "Epoch 540/1000\n",
      "225/225 [==============================] - 0s 1ms/step - loss: 0.4955 - accuracy: 0.8059 - val_loss: 0.4673 - val_accuracy: 0.8213\n",
      "Epoch 541/1000\n",
      "225/225 [==============================] - 0s 1ms/step - loss: 0.4955 - accuracy: 0.8048 - val_loss: 0.4690 - val_accuracy: 0.8200\n",
      "Epoch 542/1000\n",
      "225/225 [==============================] - 0s 1ms/step - loss: 0.4971 - accuracy: 0.8045 - val_loss: 0.4692 - val_accuracy: 0.8198\n",
      "Epoch 543/1000\n",
      "225/225 [==============================] - 0s 1ms/step - loss: 0.4939 - accuracy: 0.8060 - val_loss: 0.4661 - val_accuracy: 0.8238\n",
      "Epoch 544/1000\n",
      "225/225 [==============================] - 0s 1ms/step - loss: 0.4947 - accuracy: 0.8059 - val_loss: 0.4660 - val_accuracy: 0.8216\n",
      "Epoch 545/1000\n",
      "225/225 [==============================] - 0s 1ms/step - loss: 0.4959 - accuracy: 0.8040 - val_loss: 0.4667 - val_accuracy: 0.8221\n",
      "Epoch 546/1000\n",
      "225/225 [==============================] - 0s 1ms/step - loss: 0.4956 - accuracy: 0.8045 - val_loss: 0.4670 - val_accuracy: 0.8231\n",
      "Epoch 547/1000\n",
      "225/225 [==============================] - 0s 1ms/step - loss: 0.4956 - accuracy: 0.8059 - val_loss: 0.4661 - val_accuracy: 0.8237\n",
      "Epoch 548/1000\n",
      "225/225 [==============================] - 0s 1ms/step - loss: 0.4952 - accuracy: 0.8042 - val_loss: 0.4672 - val_accuracy: 0.8217\n",
      "Epoch 549/1000\n",
      "225/225 [==============================] - 0s 1ms/step - loss: 0.4954 - accuracy: 0.8051 - val_loss: 0.4664 - val_accuracy: 0.8225\n",
      "Epoch 550/1000\n",
      "225/225 [==============================] - 0s 1ms/step - loss: 0.4944 - accuracy: 0.8064 - val_loss: 0.4642 - val_accuracy: 0.8228\n",
      "Epoch 551/1000\n",
      "225/225 [==============================] - 0s 1ms/step - loss: 0.4932 - accuracy: 0.8065 - val_loss: 0.4653 - val_accuracy: 0.8220\n",
      "Epoch 552/1000\n",
      "225/225 [==============================] - 0s 1ms/step - loss: 0.4956 - accuracy: 0.8053 - val_loss: 0.4690 - val_accuracy: 0.8207\n",
      "Epoch 553/1000\n",
      "225/225 [==============================] - 0s 1ms/step - loss: 0.4945 - accuracy: 0.8068 - val_loss: 0.4659 - val_accuracy: 0.8235\n",
      "Epoch 554/1000\n",
      "225/225 [==============================] - 0s 1ms/step - loss: 0.4950 - accuracy: 0.8067 - val_loss: 0.4634 - val_accuracy: 0.8265\n",
      "Epoch 555/1000\n",
      "225/225 [==============================] - 0s 1ms/step - loss: 0.4950 - accuracy: 0.8055 - val_loss: 0.4668 - val_accuracy: 0.8223\n",
      "Epoch 556/1000\n",
      "225/225 [==============================] - 0s 1ms/step - loss: 0.4960 - accuracy: 0.8051 - val_loss: 0.4645 - val_accuracy: 0.8232\n",
      "Epoch 557/1000\n",
      "225/225 [==============================] - 0s 1ms/step - loss: 0.4939 - accuracy: 0.8062 - val_loss: 0.4642 - val_accuracy: 0.8237\n",
      "Epoch 558/1000\n",
      "225/225 [==============================] - 0s 1ms/step - loss: 0.4941 - accuracy: 0.8055 - val_loss: 0.4622 - val_accuracy: 0.8228\n",
      "Epoch 559/1000\n",
      "225/225 [==============================] - 0s 1ms/step - loss: 0.4958 - accuracy: 0.8052 - val_loss: 0.4652 - val_accuracy: 0.8242\n",
      "Epoch 560/1000\n",
      "225/225 [==============================] - 0s 1ms/step - loss: 0.4949 - accuracy: 0.8051 - val_loss: 0.4660 - val_accuracy: 0.8238\n",
      "Epoch 561/1000\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "225/225 [==============================] - 0s 1ms/step - loss: 0.4942 - accuracy: 0.8058 - val_loss: 0.4653 - val_accuracy: 0.8245\n",
      "Epoch 562/1000\n",
      "225/225 [==============================] - 0s 1ms/step - loss: 0.4947 - accuracy: 0.8059 - val_loss: 0.4693 - val_accuracy: 0.8213\n",
      "Epoch 563/1000\n",
      "225/225 [==============================] - 0s 1ms/step - loss: 0.4953 - accuracy: 0.8057 - val_loss: 0.4642 - val_accuracy: 0.8243\n",
      "Epoch 564/1000\n",
      "225/225 [==============================] - 0s 1ms/step - loss: 0.4945 - accuracy: 0.8059 - val_loss: 0.4676 - val_accuracy: 0.8222\n",
      "Epoch 565/1000\n",
      "225/225 [==============================] - 0s 1ms/step - loss: 0.4959 - accuracy: 0.8051 - val_loss: 0.4676 - val_accuracy: 0.8236\n",
      "Epoch 566/1000\n",
      "225/225 [==============================] - 0s 2ms/step - loss: 0.4935 - accuracy: 0.8064 - val_loss: 0.4631 - val_accuracy: 0.8243\n",
      "Epoch 567/1000\n",
      "225/225 [==============================] - 0s 1ms/step - loss: 0.4965 - accuracy: 0.8046 - val_loss: 0.4671 - val_accuracy: 0.8224\n",
      "Epoch 568/1000\n",
      "225/225 [==============================] - 0s 1ms/step - loss: 0.4955 - accuracy: 0.8051 - val_loss: 0.4648 - val_accuracy: 0.8224\n",
      "Epoch 569/1000\n",
      "225/225 [==============================] - 0s 1ms/step - loss: 0.4940 - accuracy: 0.8055 - val_loss: 0.4678 - val_accuracy: 0.8224\n",
      "Epoch 570/1000\n",
      "225/225 [==============================] - 0s 1ms/step - loss: 0.4929 - accuracy: 0.8068 - val_loss: 0.4653 - val_accuracy: 0.8227\n",
      "Epoch 571/1000\n",
      "225/225 [==============================] - 0s 1ms/step - loss: 0.4944 - accuracy: 0.8056 - val_loss: 0.4649 - val_accuracy: 0.8223\n",
      "Epoch 572/1000\n",
      "225/225 [==============================] - 0s 1ms/step - loss: 0.4936 - accuracy: 0.8064 - val_loss: 0.4638 - val_accuracy: 0.8251\n",
      "Epoch 573/1000\n",
      "225/225 [==============================] - 0s 1ms/step - loss: 0.4940 - accuracy: 0.8063 - val_loss: 0.4640 - val_accuracy: 0.8238\n",
      "Epoch 574/1000\n",
      "225/225 [==============================] - 0s 1ms/step - loss: 0.4923 - accuracy: 0.8062 - val_loss: 0.4644 - val_accuracy: 0.8246\n",
      "Epoch 575/1000\n",
      "225/225 [==============================] - 0s 1ms/step - loss: 0.4932 - accuracy: 0.8066 - val_loss: 0.4681 - val_accuracy: 0.8222\n",
      "Epoch 576/1000\n",
      "225/225 [==============================] - 0s 1ms/step - loss: 0.4925 - accuracy: 0.8066 - val_loss: 0.4664 - val_accuracy: 0.8209\n",
      "Epoch 577/1000\n",
      "225/225 [==============================] - 0s 1ms/step - loss: 0.4931 - accuracy: 0.8068 - val_loss: 0.4652 - val_accuracy: 0.8209\n",
      "Epoch 578/1000\n",
      "225/225 [==============================] - 0s 1ms/step - loss: 0.4948 - accuracy: 0.8058 - val_loss: 0.4678 - val_accuracy: 0.8234\n",
      "Epoch 579/1000\n",
      "225/225 [==============================] - 0s 1ms/step - loss: 0.4947 - accuracy: 0.8052 - val_loss: 0.4650 - val_accuracy: 0.8220\n",
      "Epoch 580/1000\n",
      "225/225 [==============================] - 0s 1ms/step - loss: 0.4942 - accuracy: 0.8062 - val_loss: 0.4631 - val_accuracy: 0.8259\n",
      "Epoch 581/1000\n",
      "225/225 [==============================] - 0s 1ms/step - loss: 0.4928 - accuracy: 0.8059 - val_loss: 0.4645 - val_accuracy: 0.8220\n",
      "Epoch 582/1000\n",
      "225/225 [==============================] - 0s 1ms/step - loss: 0.4936 - accuracy: 0.8065 - val_loss: 0.4633 - val_accuracy: 0.8220\n",
      "Epoch 583/1000\n",
      "225/225 [==============================] - 0s 1ms/step - loss: 0.4926 - accuracy: 0.8068 - val_loss: 0.4628 - val_accuracy: 0.8237\n",
      "Epoch 584/1000\n",
      "225/225 [==============================] - 0s 1ms/step - loss: 0.4939 - accuracy: 0.8053 - val_loss: 0.4674 - val_accuracy: 0.8220\n",
      "Epoch 585/1000\n",
      "225/225 [==============================] - 0s 1ms/step - loss: 0.4955 - accuracy: 0.8058 - val_loss: 0.4650 - val_accuracy: 0.8224\n",
      "Epoch 586/1000\n",
      "225/225 [==============================] - 0s 1ms/step - loss: 0.4953 - accuracy: 0.8057 - val_loss: 0.4634 - val_accuracy: 0.8235\n",
      "Epoch 587/1000\n",
      "225/225 [==============================] - 0s 1ms/step - loss: 0.4940 - accuracy: 0.8064 - val_loss: 0.4655 - val_accuracy: 0.8223\n",
      "Epoch 588/1000\n",
      "225/225 [==============================] - 0s 1ms/step - loss: 0.4937 - accuracy: 0.8058 - val_loss: 0.4673 - val_accuracy: 0.8198\n",
      "Epoch 589/1000\n",
      "225/225 [==============================] - 0s 1ms/step - loss: 0.4953 - accuracy: 0.8054 - val_loss: 0.4674 - val_accuracy: 0.8221\n",
      "Epoch 590/1000\n",
      "225/225 [==============================] - 0s 1ms/step - loss: 0.4942 - accuracy: 0.8064 - val_loss: 0.4677 - val_accuracy: 0.8216\n",
      "Epoch 591/1000\n",
      "225/225 [==============================] - 0s 1ms/step - loss: 0.4937 - accuracy: 0.8067 - val_loss: 0.4684 - val_accuracy: 0.8223\n",
      "Epoch 592/1000\n",
      "225/225 [==============================] - 0s 1ms/step - loss: 0.4932 - accuracy: 0.8062 - val_loss: 0.4693 - val_accuracy: 0.8224\n",
      "Epoch 593/1000\n",
      "225/225 [==============================] - 0s 1ms/step - loss: 0.4924 - accuracy: 0.8067 - val_loss: 0.4686 - val_accuracy: 0.8219\n",
      "Epoch 594/1000\n",
      "225/225 [==============================] - 0s 1ms/step - loss: 0.4946 - accuracy: 0.8058 - val_loss: 0.4650 - val_accuracy: 0.8219\n",
      "Epoch 595/1000\n",
      "225/225 [==============================] - 0s 1ms/step - loss: 0.4926 - accuracy: 0.8076 - val_loss: 0.4677 - val_accuracy: 0.8215\n",
      "Epoch 596/1000\n",
      "225/225 [==============================] - 0s 1ms/step - loss: 0.4930 - accuracy: 0.8063 - val_loss: 0.4644 - val_accuracy: 0.8236\n",
      "Epoch 597/1000\n",
      "225/225 [==============================] - 0s 1ms/step - loss: 0.4955 - accuracy: 0.8061 - val_loss: 0.4643 - val_accuracy: 0.8225\n",
      "Epoch 598/1000\n",
      "225/225 [==============================] - 0s 1ms/step - loss: 0.4943 - accuracy: 0.8067 - val_loss: 0.4639 - val_accuracy: 0.8227\n",
      "Epoch 599/1000\n",
      "225/225 [==============================] - 0s 1ms/step - loss: 0.4937 - accuracy: 0.8051 - val_loss: 0.4637 - val_accuracy: 0.8239\n",
      "Epoch 600/1000\n",
      "225/225 [==============================] - 0s 1ms/step - loss: 0.4922 - accuracy: 0.8074 - val_loss: 0.4632 - val_accuracy: 0.8226\n",
      "Epoch 601/1000\n",
      "225/225 [==============================] - 0s 1ms/step - loss: 0.4925 - accuracy: 0.8066 - val_loss: 0.4649 - val_accuracy: 0.8241\n",
      "Epoch 602/1000\n",
      "225/225 [==============================] - 0s 1ms/step - loss: 0.4933 - accuracy: 0.8060 - val_loss: 0.4689 - val_accuracy: 0.8202\n",
      "Epoch 603/1000\n",
      "225/225 [==============================] - 0s 1ms/step - loss: 0.4933 - accuracy: 0.8066 - val_loss: 0.4654 - val_accuracy: 0.8236\n",
      "Epoch 604/1000\n",
      "225/225 [==============================] - 0s 1ms/step - loss: 0.4939 - accuracy: 0.8057 - val_loss: 0.4656 - val_accuracy: 0.8233\n",
      "Epoch 605/1000\n",
      "225/225 [==============================] - 0s 1ms/step - loss: 0.4941 - accuracy: 0.8061 - val_loss: 0.4637 - val_accuracy: 0.8237\n",
      "Epoch 606/1000\n",
      "225/225 [==============================] - 0s 1ms/step - loss: 0.4944 - accuracy: 0.8060 - val_loss: 0.4674 - val_accuracy: 0.8211\n",
      "Epoch 607/1000\n",
      "225/225 [==============================] - 0s 1ms/step - loss: 0.4938 - accuracy: 0.8067 - val_loss: 0.4693 - val_accuracy: 0.8196\n",
      "Epoch 608/1000\n",
      "225/225 [==============================] - 0s 1ms/step - loss: 0.4929 - accuracy: 0.8062 - val_loss: 0.4679 - val_accuracy: 0.8200\n",
      "Epoch 609/1000\n",
      "225/225 [==============================] - 0s 1ms/step - loss: 0.4928 - accuracy: 0.8064 - val_loss: 0.4658 - val_accuracy: 0.8229\n",
      "Epoch 610/1000\n",
      "225/225 [==============================] - 0s 1ms/step - loss: 0.4937 - accuracy: 0.8066 - val_loss: 0.4680 - val_accuracy: 0.8209\n",
      "Epoch 611/1000\n",
      "225/225 [==============================] - 0s 1ms/step - loss: 0.4935 - accuracy: 0.8062 - val_loss: 0.4668 - val_accuracy: 0.8225\n",
      "Epoch 612/1000\n",
      "225/225 [==============================] - 0s 1ms/step - loss: 0.4927 - accuracy: 0.8062 - val_loss: 0.4654 - val_accuracy: 0.8214\n",
      "Epoch 613/1000\n",
      "225/225 [==============================] - 0s 1ms/step - loss: 0.4922 - accuracy: 0.8060 - val_loss: 0.4659 - val_accuracy: 0.8218\n",
      "Epoch 614/1000\n",
      "225/225 [==============================] - 0s 1ms/step - loss: 0.4932 - accuracy: 0.8064 - val_loss: 0.4661 - val_accuracy: 0.8225\n",
      "Epoch 615/1000\n",
      "225/225 [==============================] - 0s 1ms/step - loss: 0.4919 - accuracy: 0.8067 - val_loss: 0.4649 - val_accuracy: 0.8220\n",
      "Epoch 616/1000\n",
      "225/225 [==============================] - 0s 1ms/step - loss: 0.4938 - accuracy: 0.8070 - val_loss: 0.4670 - val_accuracy: 0.8213\n",
      "Epoch 617/1000\n",
      "225/225 [==============================] - 0s 1ms/step - loss: 0.4951 - accuracy: 0.8058 - val_loss: 0.4644 - val_accuracy: 0.8219\n",
      "Epoch 618/1000\n",
      "225/225 [==============================] - 0s 1ms/step - loss: 0.4938 - accuracy: 0.8057 - val_loss: 0.4655 - val_accuracy: 0.8213\n",
      "Epoch 619/1000\n",
      "225/225 [==============================] - 0s 1ms/step - loss: 0.4935 - accuracy: 0.8061 - val_loss: 0.4637 - val_accuracy: 0.8224\n",
      "Epoch 620/1000\n",
      "225/225 [==============================] - 0s 1ms/step - loss: 0.4925 - accuracy: 0.8067 - val_loss: 0.4652 - val_accuracy: 0.8196\n",
      "Epoch 621/1000\n",
      "225/225 [==============================] - 0s 1ms/step - loss: 0.4924 - accuracy: 0.8062 - val_loss: 0.4670 - val_accuracy: 0.8224\n",
      "Epoch 622/1000\n",
      "225/225 [==============================] - 0s 1ms/step - loss: 0.4932 - accuracy: 0.8069 - val_loss: 0.4666 - val_accuracy: 0.8216\n",
      "Epoch 623/1000\n",
      "225/225 [==============================] - 0s 1ms/step - loss: 0.4927 - accuracy: 0.8063 - val_loss: 0.4686 - val_accuracy: 0.8196\n",
      "Epoch 624/1000\n",
      "225/225 [==============================] - 0s 1ms/step - loss: 0.4935 - accuracy: 0.8061 - val_loss: 0.4681 - val_accuracy: 0.8217\n",
      "Epoch 625/1000\n",
      "225/225 [==============================] - 0s 1ms/step - loss: 0.4932 - accuracy: 0.8066 - val_loss: 0.4657 - val_accuracy: 0.8224\n",
      "Epoch 626/1000\n",
      "225/225 [==============================] - 0s 1ms/step - loss: 0.4935 - accuracy: 0.8073 - val_loss: 0.4651 - val_accuracy: 0.8235\n",
      "Epoch 627/1000\n",
      "225/225 [==============================] - 0s 1ms/step - loss: 0.4918 - accuracy: 0.8075 - val_loss: 0.4632 - val_accuracy: 0.8249\n",
      "Epoch 628/1000\n",
      "225/225 [==============================] - 0s 1ms/step - loss: 0.4932 - accuracy: 0.8059 - val_loss: 0.4662 - val_accuracy: 0.8233\n",
      "Epoch 629/1000\n",
      "225/225 [==============================] - 0s 1ms/step - loss: 0.4926 - accuracy: 0.8068 - val_loss: 0.4657 - val_accuracy: 0.8237\n",
      "Epoch 630/1000\n",
      "225/225 [==============================] - 0s 1ms/step - loss: 0.4927 - accuracy: 0.8065 - val_loss: 0.4643 - val_accuracy: 0.8241\n",
      "Epoch 631/1000\n",
      "225/225 [==============================] - 0s 1ms/step - loss: 0.4930 - accuracy: 0.8061 - val_loss: 0.4686 - val_accuracy: 0.8215\n",
      "Epoch 632/1000\n",
      "225/225 [==============================] - 0s 1ms/step - loss: 0.4923 - accuracy: 0.8069 - val_loss: 0.4652 - val_accuracy: 0.8234\n",
      "Epoch 633/1000\n",
      "225/225 [==============================] - 0s 1ms/step - loss: 0.4931 - accuracy: 0.8065 - val_loss: 0.4652 - val_accuracy: 0.8208\n",
      "Epoch 634/1000\n",
      "225/225 [==============================] - 0s 1ms/step - loss: 0.4953 - accuracy: 0.8062 - val_loss: 0.4665 - val_accuracy: 0.8220\n",
      "Epoch 635/1000\n",
      "225/225 [==============================] - 0s 1ms/step - loss: 0.4918 - accuracy: 0.8069 - val_loss: 0.4651 - val_accuracy: 0.8220\n",
      "Epoch 636/1000\n",
      "225/225 [==============================] - 0s 1ms/step - loss: 0.4920 - accuracy: 0.8070 - val_loss: 0.4665 - val_accuracy: 0.8236\n",
      "Epoch 637/1000\n",
      "225/225 [==============================] - 0s 1ms/step - loss: 0.4935 - accuracy: 0.8068 - val_loss: 0.4659 - val_accuracy: 0.8216\n",
      "Epoch 638/1000\n",
      "225/225 [==============================] - 0s 1ms/step - loss: 0.4936 - accuracy: 0.8058 - val_loss: 0.4627 - val_accuracy: 0.8229\n",
      "Epoch 639/1000\n",
      "225/225 [==============================] - 0s 1ms/step - loss: 0.4904 - accuracy: 0.8075 - val_loss: 0.4652 - val_accuracy: 0.8223\n",
      "Epoch 640/1000\n",
      "225/225 [==============================] - 0s 1ms/step - loss: 0.4933 - accuracy: 0.8064 - val_loss: 0.4642 - val_accuracy: 0.8228\n",
      "Epoch 641/1000\n",
      "225/225 [==============================] - 0s 1ms/step - loss: 0.4926 - accuracy: 0.8071 - val_loss: 0.4636 - val_accuracy: 0.8243\n",
      "Epoch 642/1000\n",
      "225/225 [==============================] - 0s 1ms/step - loss: 0.4939 - accuracy: 0.8058 - val_loss: 0.4637 - val_accuracy: 0.8277\n",
      "Epoch 643/1000\n",
      "225/225 [==============================] - 0s 1ms/step - loss: 0.4919 - accuracy: 0.8076 - val_loss: 0.4626 - val_accuracy: 0.8247\n",
      "Epoch 644/1000\n",
      "225/225 [==============================] - 0s 1ms/step - loss: 0.4913 - accuracy: 0.8076 - val_loss: 0.4615 - val_accuracy: 0.8258\n",
      "Epoch 645/1000\n",
      "225/225 [==============================] - 0s 1ms/step - loss: 0.4915 - accuracy: 0.8073 - val_loss: 0.4620 - val_accuracy: 0.8226\n",
      "Epoch 646/1000\n",
      "225/225 [==============================] - 0s 1ms/step - loss: 0.4937 - accuracy: 0.8054 - val_loss: 0.4642 - val_accuracy: 0.8229\n",
      "Epoch 647/1000\n",
      "225/225 [==============================] - 0s 1ms/step - loss: 0.4902 - accuracy: 0.8079 - val_loss: 0.4630 - val_accuracy: 0.8225\n",
      "Epoch 648/1000\n",
      "225/225 [==============================] - 0s 1ms/step - loss: 0.4903 - accuracy: 0.8073 - val_loss: 0.4631 - val_accuracy: 0.8221\n",
      "Epoch 649/1000\n",
      "225/225 [==============================] - 0s 1ms/step - loss: 0.4922 - accuracy: 0.8068 - val_loss: 0.4662 - val_accuracy: 0.8224\n",
      "Epoch 650/1000\n",
      "225/225 [==============================] - 0s 1ms/step - loss: 0.4930 - accuracy: 0.8075 - val_loss: 0.4621 - val_accuracy: 0.8251\n",
      "Epoch 651/1000\n",
      "225/225 [==============================] - 0s 1ms/step - loss: 0.4912 - accuracy: 0.8067 - val_loss: 0.4636 - val_accuracy: 0.8247\n",
      "Epoch 652/1000\n",
      "225/225 [==============================] - 0s 1ms/step - loss: 0.4910 - accuracy: 0.8072 - val_loss: 0.4622 - val_accuracy: 0.8212\n",
      "Epoch 653/1000\n",
      "225/225 [==============================] - 0s 1ms/step - loss: 0.4927 - accuracy: 0.8057 - val_loss: 0.4617 - val_accuracy: 0.8262\n",
      "Epoch 654/1000\n",
      "225/225 [==============================] - 0s 1ms/step - loss: 0.4919 - accuracy: 0.8071 - val_loss: 0.4632 - val_accuracy: 0.8243\n",
      "Epoch 655/1000\n",
      "225/225 [==============================] - 0s 1ms/step - loss: 0.4910 - accuracy: 0.8073 - val_loss: 0.4642 - val_accuracy: 0.8226\n",
      "Epoch 656/1000\n",
      "225/225 [==============================] - 0s 1ms/step - loss: 0.4918 - accuracy: 0.8071 - val_loss: 0.4638 - val_accuracy: 0.8238\n",
      "Epoch 657/1000\n",
      "225/225 [==============================] - 0s 1ms/step - loss: 0.4919 - accuracy: 0.8065 - val_loss: 0.4626 - val_accuracy: 0.8236\n",
      "Epoch 658/1000\n",
      "225/225 [==============================] - 0s 1ms/step - loss: 0.4911 - accuracy: 0.8075 - val_loss: 0.4641 - val_accuracy: 0.8244\n",
      "Epoch 659/1000\n",
      "225/225 [==============================] - 0s 1ms/step - loss: 0.4933 - accuracy: 0.8066 - val_loss: 0.4664 - val_accuracy: 0.8213\n",
      "Epoch 660/1000\n",
      "225/225 [==============================] - 0s 1ms/step - loss: 0.4919 - accuracy: 0.8068 - val_loss: 0.4635 - val_accuracy: 0.8252\n",
      "Epoch 661/1000\n",
      "225/225 [==============================] - 0s 1ms/step - loss: 0.4921 - accuracy: 0.8061 - val_loss: 0.4642 - val_accuracy: 0.8213\n",
      "Epoch 662/1000\n",
      "225/225 [==============================] - 0s 1ms/step - loss: 0.4893 - accuracy: 0.8076 - val_loss: 0.4637 - val_accuracy: 0.8231\n",
      "Epoch 663/1000\n",
      "225/225 [==============================] - 0s 1ms/step - loss: 0.4912 - accuracy: 0.8072 - val_loss: 0.4646 - val_accuracy: 0.8242\n",
      "Epoch 664/1000\n",
      "225/225 [==============================] - 0s 1ms/step - loss: 0.4930 - accuracy: 0.8073 - val_loss: 0.4624 - val_accuracy: 0.8228\n",
      "Epoch 665/1000\n",
      "225/225 [==============================] - 0s 1ms/step - loss: 0.4918 - accuracy: 0.8063 - val_loss: 0.4621 - val_accuracy: 0.8252\n",
      "Epoch 666/1000\n",
      "225/225 [==============================] - 0s 1ms/step - loss: 0.4919 - accuracy: 0.8063 - val_loss: 0.4632 - val_accuracy: 0.8223\n",
      "Epoch 667/1000\n",
      "225/225 [==============================] - 0s 1ms/step - loss: 0.4907 - accuracy: 0.8077 - val_loss: 0.4618 - val_accuracy: 0.8245\n",
      "Epoch 668/1000\n",
      "225/225 [==============================] - 0s 1ms/step - loss: 0.4909 - accuracy: 0.8074 - val_loss: 0.4644 - val_accuracy: 0.8220\n",
      "Epoch 669/1000\n",
      "225/225 [==============================] - 0s 1ms/step - loss: 0.4906 - accuracy: 0.8074 - val_loss: 0.4663 - val_accuracy: 0.8238\n",
      "Epoch 670/1000\n",
      "225/225 [==============================] - 0s 1ms/step - loss: 0.4917 - accuracy: 0.8072 - val_loss: 0.4634 - val_accuracy: 0.8227\n",
      "Epoch 671/1000\n",
      "225/225 [==============================] - 0s 1ms/step - loss: 0.4917 - accuracy: 0.8059 - val_loss: 0.4632 - val_accuracy: 0.8222\n",
      "Epoch 672/1000\n",
      "225/225 [==============================] - 0s 1ms/step - loss: 0.4910 - accuracy: 0.8079 - val_loss: 0.4646 - val_accuracy: 0.8211\n",
      "Epoch 673/1000\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "225/225 [==============================] - 0s 1ms/step - loss: 0.4919 - accuracy: 0.8066 - val_loss: 0.4632 - val_accuracy: 0.8214\n",
      "Epoch 674/1000\n",
      "225/225 [==============================] - 0s 1ms/step - loss: 0.4914 - accuracy: 0.8074 - val_loss: 0.4636 - val_accuracy: 0.8223\n",
      "Epoch 675/1000\n",
      "225/225 [==============================] - 0s 1ms/step - loss: 0.4912 - accuracy: 0.8065 - val_loss: 0.4638 - val_accuracy: 0.8216\n",
      "Epoch 676/1000\n",
      "225/225 [==============================] - 0s 1ms/step - loss: 0.4920 - accuracy: 0.8076 - val_loss: 0.4662 - val_accuracy: 0.8209\n",
      "Epoch 677/1000\n",
      "225/225 [==============================] - 0s 1ms/step - loss: 0.4913 - accuracy: 0.8060 - val_loss: 0.4662 - val_accuracy: 0.8193\n",
      "Epoch 678/1000\n",
      "225/225 [==============================] - 0s 1ms/step - loss: 0.4932 - accuracy: 0.8061 - val_loss: 0.4656 - val_accuracy: 0.8206\n",
      "Epoch 679/1000\n",
      "225/225 [==============================] - 0s 1ms/step - loss: 0.4900 - accuracy: 0.8076 - val_loss: 0.4646 - val_accuracy: 0.8225\n",
      "Epoch 680/1000\n",
      "225/225 [==============================] - 0s 1ms/step - loss: 0.4915 - accuracy: 0.8067 - val_loss: 0.4665 - val_accuracy: 0.8206\n",
      "Epoch 681/1000\n",
      "225/225 [==============================] - 0s 1ms/step - loss: 0.4906 - accuracy: 0.8069 - val_loss: 0.4662 - val_accuracy: 0.8217\n",
      "Epoch 682/1000\n",
      "225/225 [==============================] - 0s 1ms/step - loss: 0.4912 - accuracy: 0.8072 - val_loss: 0.4645 - val_accuracy: 0.8230\n",
      "Epoch 683/1000\n",
      "225/225 [==============================] - 0s 1ms/step - loss: 0.4899 - accuracy: 0.8073 - val_loss: 0.4685 - val_accuracy: 0.8219\n",
      "Epoch 684/1000\n",
      "225/225 [==============================] - 0s 1ms/step - loss: 0.4909 - accuracy: 0.8077 - val_loss: 0.4651 - val_accuracy: 0.8230\n",
      "Epoch 685/1000\n",
      "225/225 [==============================] - 0s 1ms/step - loss: 0.4906 - accuracy: 0.8070 - val_loss: 0.4660 - val_accuracy: 0.8209\n",
      "Epoch 686/1000\n",
      "225/225 [==============================] - 0s 1ms/step - loss: 0.4900 - accuracy: 0.8078 - val_loss: 0.4638 - val_accuracy: 0.8226\n",
      "Epoch 687/1000\n",
      "225/225 [==============================] - 0s 1ms/step - loss: 0.4905 - accuracy: 0.8073 - val_loss: 0.4634 - val_accuracy: 0.8217\n",
      "Epoch 688/1000\n",
      "225/225 [==============================] - 0s 1ms/step - loss: 0.4919 - accuracy: 0.8059 - val_loss: 0.4638 - val_accuracy: 0.8234\n",
      "Epoch 689/1000\n",
      "225/225 [==============================] - 0s 1ms/step - loss: 0.4910 - accuracy: 0.8065 - val_loss: 0.4623 - val_accuracy: 0.8252\n",
      "Epoch 690/1000\n",
      "225/225 [==============================] - 0s 1ms/step - loss: 0.4892 - accuracy: 0.8081 - val_loss: 0.4611 - val_accuracy: 0.8250\n",
      "Epoch 691/1000\n",
      "225/225 [==============================] - 0s 1ms/step - loss: 0.4895 - accuracy: 0.8078 - val_loss: 0.4610 - val_accuracy: 0.8246\n",
      "Epoch 692/1000\n",
      "225/225 [==============================] - 0s 1ms/step - loss: 0.4898 - accuracy: 0.8087 - val_loss: 0.4632 - val_accuracy: 0.8253\n",
      "Epoch 693/1000\n",
      "225/225 [==============================] - 0s 1ms/step - loss: 0.4900 - accuracy: 0.8080 - val_loss: 0.4627 - val_accuracy: 0.8228\n",
      "Epoch 694/1000\n",
      "225/225 [==============================] - 0s 1ms/step - loss: 0.4927 - accuracy: 0.8058 - val_loss: 0.4631 - val_accuracy: 0.8230\n",
      "Epoch 695/1000\n",
      "225/225 [==============================] - 0s 1ms/step - loss: 0.4889 - accuracy: 0.8085 - val_loss: 0.4667 - val_accuracy: 0.8210\n",
      "Epoch 696/1000\n",
      "225/225 [==============================] - 0s 1ms/step - loss: 0.4915 - accuracy: 0.8072 - val_loss: 0.4630 - val_accuracy: 0.8253\n",
      "Epoch 697/1000\n",
      "225/225 [==============================] - 0s 1ms/step - loss: 0.4905 - accuracy: 0.8086 - val_loss: 0.4621 - val_accuracy: 0.8228\n",
      "Epoch 698/1000\n",
      "225/225 [==============================] - 0s 1ms/step - loss: 0.4912 - accuracy: 0.8073 - val_loss: 0.4659 - val_accuracy: 0.8231\n",
      "Epoch 699/1000\n",
      "225/225 [==============================] - 0s 1ms/step - loss: 0.4914 - accuracy: 0.8069 - val_loss: 0.4614 - val_accuracy: 0.8253\n",
      "Epoch 700/1000\n",
      "225/225 [==============================] - 0s 1ms/step - loss: 0.4904 - accuracy: 0.8080 - val_loss: 0.4651 - val_accuracy: 0.8202\n",
      "Epoch 701/1000\n",
      "225/225 [==============================] - 0s 1ms/step - loss: 0.4932 - accuracy: 0.8056 - val_loss: 0.4649 - val_accuracy: 0.8236\n",
      "Epoch 702/1000\n",
      "225/225 [==============================] - 0s 1ms/step - loss: 0.4932 - accuracy: 0.8067 - val_loss: 0.4635 - val_accuracy: 0.8219\n",
      "Epoch 703/1000\n",
      "225/225 [==============================] - 0s 1ms/step - loss: 0.4894 - accuracy: 0.8073 - val_loss: 0.4627 - val_accuracy: 0.8223\n",
      "Epoch 704/1000\n",
      "225/225 [==============================] - 0s 1ms/step - loss: 0.4897 - accuracy: 0.8082 - val_loss: 0.4618 - val_accuracy: 0.8249\n",
      "Epoch 705/1000\n",
      "225/225 [==============================] - 0s 1ms/step - loss: 0.4911 - accuracy: 0.8069 - val_loss: 0.4619 - val_accuracy: 0.8246\n",
      "Epoch 706/1000\n",
      "225/225 [==============================] - 0s 1ms/step - loss: 0.4915 - accuracy: 0.8074 - val_loss: 0.4643 - val_accuracy: 0.8234\n",
      "Epoch 707/1000\n",
      "225/225 [==============================] - 0s 1ms/step - loss: 0.4898 - accuracy: 0.8081 - val_loss: 0.4629 - val_accuracy: 0.8237\n",
      "Epoch 708/1000\n",
      "225/225 [==============================] - 0s 1ms/step - loss: 0.4906 - accuracy: 0.8057 - val_loss: 0.4623 - val_accuracy: 0.8233\n",
      "Epoch 709/1000\n",
      "225/225 [==============================] - 0s 1ms/step - loss: 0.4906 - accuracy: 0.8077 - val_loss: 0.4625 - val_accuracy: 0.8236\n",
      "Epoch 710/1000\n",
      "225/225 [==============================] - 0s 1ms/step - loss: 0.4907 - accuracy: 0.8086 - val_loss: 0.4625 - val_accuracy: 0.8231\n",
      "Epoch 711/1000\n",
      "225/225 [==============================] - 0s 1ms/step - loss: 0.4902 - accuracy: 0.8078 - val_loss: 0.4635 - val_accuracy: 0.8237\n",
      "Epoch 712/1000\n",
      "225/225 [==============================] - 0s 1ms/step - loss: 0.4909 - accuracy: 0.8079 - val_loss: 0.4612 - val_accuracy: 0.8234\n",
      "Epoch 713/1000\n",
      "225/225 [==============================] - 0s 1ms/step - loss: 0.4892 - accuracy: 0.8073 - val_loss: 0.4641 - val_accuracy: 0.8235\n",
      "Epoch 714/1000\n",
      "225/225 [==============================] - 0s 1ms/step - loss: 0.4909 - accuracy: 0.8070 - val_loss: 0.4637 - val_accuracy: 0.8251\n",
      "Epoch 715/1000\n",
      "225/225 [==============================] - 0s 1ms/step - loss: 0.4904 - accuracy: 0.8078 - val_loss: 0.4648 - val_accuracy: 0.8241\n",
      "Epoch 716/1000\n",
      "225/225 [==============================] - 0s 1ms/step - loss: 0.4897 - accuracy: 0.8073 - val_loss: 0.4623 - val_accuracy: 0.8246\n",
      "Epoch 717/1000\n",
      "225/225 [==============================] - 0s 1ms/step - loss: 0.4884 - accuracy: 0.8084 - val_loss: 0.4621 - val_accuracy: 0.8257\n",
      "Epoch 718/1000\n",
      "225/225 [==============================] - 0s 1ms/step - loss: 0.4919 - accuracy: 0.8073 - val_loss: 0.4651 - val_accuracy: 0.8256\n",
      "Epoch 719/1000\n",
      "225/225 [==============================] - 0s 1ms/step - loss: 0.4913 - accuracy: 0.8073 - val_loss: 0.4650 - val_accuracy: 0.8250\n",
      "Epoch 720/1000\n",
      "225/225 [==============================] - 0s 1ms/step - loss: 0.4892 - accuracy: 0.8083 - val_loss: 0.4635 - val_accuracy: 0.8240\n",
      "Epoch 721/1000\n",
      "225/225 [==============================] - 0s 1ms/step - loss: 0.4905 - accuracy: 0.8086 - val_loss: 0.4636 - val_accuracy: 0.8252\n",
      "Epoch 722/1000\n",
      "225/225 [==============================] - 0s 1ms/step - loss: 0.4904 - accuracy: 0.8071 - val_loss: 0.4641 - val_accuracy: 0.8246\n",
      "Epoch 723/1000\n",
      "225/225 [==============================] - 0s 1ms/step - loss: 0.4905 - accuracy: 0.8077 - val_loss: 0.4642 - val_accuracy: 0.8240\n",
      "Epoch 724/1000\n",
      "225/225 [==============================] - 0s 1ms/step - loss: 0.4921 - accuracy: 0.8068 - val_loss: 0.4650 - val_accuracy: 0.8232\n",
      "Epoch 725/1000\n",
      "225/225 [==============================] - 0s 1ms/step - loss: 0.4918 - accuracy: 0.8064 - val_loss: 0.4622 - val_accuracy: 0.8233\n",
      "Epoch 726/1000\n",
      "225/225 [==============================] - 0s 1ms/step - loss: 0.4901 - accuracy: 0.8066 - val_loss: 0.4655 - val_accuracy: 0.8216\n",
      "Epoch 727/1000\n",
      "225/225 [==============================] - 0s 1ms/step - loss: 0.4910 - accuracy: 0.8077 - val_loss: 0.4640 - val_accuracy: 0.8232\n",
      "Epoch 728/1000\n",
      "225/225 [==============================] - 0s 1ms/step - loss: 0.4894 - accuracy: 0.8082 - val_loss: 0.4607 - val_accuracy: 0.8248\n",
      "Epoch 729/1000\n",
      "225/225 [==============================] - 0s 1ms/step - loss: 0.4885 - accuracy: 0.8069 - val_loss: 0.4650 - val_accuracy: 0.8233\n",
      "Epoch 730/1000\n",
      "225/225 [==============================] - 0s 1ms/step - loss: 0.4926 - accuracy: 0.8065 - val_loss: 0.4668 - val_accuracy: 0.8213\n",
      "Epoch 731/1000\n",
      "225/225 [==============================] - 0s 1ms/step - loss: 0.4907 - accuracy: 0.8077 - val_loss: 0.4639 - val_accuracy: 0.8256\n",
      "Epoch 732/1000\n",
      "225/225 [==============================] - 0s 1ms/step - loss: 0.4901 - accuracy: 0.8075 - val_loss: 0.4649 - val_accuracy: 0.8234\n",
      "Epoch 733/1000\n",
      "225/225 [==============================] - 0s 1ms/step - loss: 0.4900 - accuracy: 0.8079 - val_loss: 0.4685 - val_accuracy: 0.8214\n",
      "Epoch 734/1000\n",
      "225/225 [==============================] - 0s 1ms/step - loss: 0.4914 - accuracy: 0.8077 - val_loss: 0.4604 - val_accuracy: 0.8264\n",
      "Epoch 735/1000\n",
      "225/225 [==============================] - 0s 1ms/step - loss: 0.4882 - accuracy: 0.8083 - val_loss: 0.4624 - val_accuracy: 0.8264\n",
      "Epoch 736/1000\n",
      "225/225 [==============================] - 0s 1ms/step - loss: 0.4918 - accuracy: 0.8074 - val_loss: 0.4650 - val_accuracy: 0.8226\n",
      "Epoch 737/1000\n",
      "225/225 [==============================] - 0s 1ms/step - loss: 0.4889 - accuracy: 0.8080 - val_loss: 0.4637 - val_accuracy: 0.8218\n",
      "Epoch 738/1000\n",
      "225/225 [==============================] - 0s 1ms/step - loss: 0.4895 - accuracy: 0.8077 - val_loss: 0.4640 - val_accuracy: 0.8258\n",
      "Epoch 739/1000\n",
      "225/225 [==============================] - 0s 1ms/step - loss: 0.4905 - accuracy: 0.8067 - val_loss: 0.4625 - val_accuracy: 0.8229\n",
      "Epoch 740/1000\n",
      "225/225 [==============================] - 0s 1ms/step - loss: 0.4915 - accuracy: 0.8070 - val_loss: 0.4617 - val_accuracy: 0.8246\n",
      "Epoch 741/1000\n",
      "225/225 [==============================] - 0s 1ms/step - loss: 0.4885 - accuracy: 0.8085 - val_loss: 0.4631 - val_accuracy: 0.8241\n",
      "Epoch 742/1000\n",
      "225/225 [==============================] - 0s 1ms/step - loss: 0.4915 - accuracy: 0.8068 - val_loss: 0.4622 - val_accuracy: 0.8245\n",
      "Epoch 743/1000\n",
      "225/225 [==============================] - 0s 1ms/step - loss: 0.4904 - accuracy: 0.8074 - val_loss: 0.4632 - val_accuracy: 0.8253\n",
      "Epoch 744/1000\n",
      "225/225 [==============================] - 0s 1ms/step - loss: 0.4892 - accuracy: 0.8074 - val_loss: 0.4635 - val_accuracy: 0.8228\n",
      "Epoch 745/1000\n",
      "225/225 [==============================] - 0s 1ms/step - loss: 0.4887 - accuracy: 0.8088 - val_loss: 0.4651 - val_accuracy: 0.8228\n",
      "Epoch 746/1000\n",
      "225/225 [==============================] - 0s 1ms/step - loss: 0.4902 - accuracy: 0.8079 - val_loss: 0.4626 - val_accuracy: 0.8246\n",
      "Epoch 747/1000\n",
      "225/225 [==============================] - 0s 1ms/step - loss: 0.4892 - accuracy: 0.8079 - val_loss: 0.4635 - val_accuracy: 0.8233\n",
      "Epoch 748/1000\n",
      "225/225 [==============================] - 0s 1ms/step - loss: 0.4894 - accuracy: 0.8072 - val_loss: 0.4620 - val_accuracy: 0.8243\n",
      "Epoch 749/1000\n",
      "225/225 [==============================] - 0s 1ms/step - loss: 0.4904 - accuracy: 0.8074 - val_loss: 0.4655 - val_accuracy: 0.8216\n",
      "Epoch 750/1000\n",
      "225/225 [==============================] - 0s 1ms/step - loss: 0.4893 - accuracy: 0.8076 - val_loss: 0.4628 - val_accuracy: 0.8238\n",
      "Epoch 751/1000\n",
      "225/225 [==============================] - 0s 1ms/step - loss: 0.4898 - accuracy: 0.8073 - val_loss: 0.4644 - val_accuracy: 0.8217\n",
      "Epoch 752/1000\n",
      "225/225 [==============================] - 0s 1ms/step - loss: 0.4883 - accuracy: 0.8088 - val_loss: 0.4635 - val_accuracy: 0.8251\n",
      "Epoch 753/1000\n",
      "225/225 [==============================] - 0s 1ms/step - loss: 0.4905 - accuracy: 0.8072 - val_loss: 0.4634 - val_accuracy: 0.8233\n",
      "Epoch 754/1000\n",
      "225/225 [==============================] - 0s 1ms/step - loss: 0.4907 - accuracy: 0.8063 - val_loss: 0.4643 - val_accuracy: 0.8243\n",
      "Epoch 755/1000\n",
      "225/225 [==============================] - 0s 1ms/step - loss: 0.4882 - accuracy: 0.8086 - val_loss: 0.4620 - val_accuracy: 0.8237\n",
      "Epoch 756/1000\n",
      "225/225 [==============================] - 0s 1ms/step - loss: 0.4911 - accuracy: 0.8091 - val_loss: 0.4606 - val_accuracy: 0.8263\n",
      "Epoch 757/1000\n",
      "225/225 [==============================] - 0s 1ms/step - loss: 0.4882 - accuracy: 0.8098 - val_loss: 0.4630 - val_accuracy: 0.8244\n",
      "Epoch 758/1000\n",
      "225/225 [==============================] - 0s 1ms/step - loss: 0.4891 - accuracy: 0.8085 - val_loss: 0.4659 - val_accuracy: 0.8241\n",
      "Epoch 759/1000\n",
      "225/225 [==============================] - 0s 1ms/step - loss: 0.4874 - accuracy: 0.8086 - val_loss: 0.4603 - val_accuracy: 0.8265\n",
      "Epoch 760/1000\n",
      "225/225 [==============================] - 0s 1ms/step - loss: 0.4889 - accuracy: 0.8084 - val_loss: 0.4636 - val_accuracy: 0.8228\n",
      "Epoch 761/1000\n",
      "225/225 [==============================] - 0s 1ms/step - loss: 0.4893 - accuracy: 0.8086 - val_loss: 0.4644 - val_accuracy: 0.8262\n",
      "Epoch 762/1000\n",
      "225/225 [==============================] - 0s 1ms/step - loss: 0.4894 - accuracy: 0.8077 - val_loss: 0.4643 - val_accuracy: 0.8239\n",
      "Epoch 763/1000\n",
      "225/225 [==============================] - 0s 1ms/step - loss: 0.4891 - accuracy: 0.8077 - val_loss: 0.4643 - val_accuracy: 0.8228\n",
      "Epoch 764/1000\n",
      "225/225 [==============================] - 0s 1ms/step - loss: 0.4893 - accuracy: 0.8077 - val_loss: 0.4639 - val_accuracy: 0.8237\n",
      "Epoch 765/1000\n",
      "225/225 [==============================] - 0s 1ms/step - loss: 0.4918 - accuracy: 0.8060 - val_loss: 0.4633 - val_accuracy: 0.8244\n",
      "Epoch 766/1000\n",
      "225/225 [==============================] - 0s 1ms/step - loss: 0.4895 - accuracy: 0.8072 - val_loss: 0.4655 - val_accuracy: 0.8226\n",
      "Epoch 767/1000\n",
      "225/225 [==============================] - 0s 1ms/step - loss: 0.4910 - accuracy: 0.8076 - val_loss: 0.4652 - val_accuracy: 0.8228\n",
      "Epoch 768/1000\n",
      "225/225 [==============================] - 0s 1ms/step - loss: 0.4888 - accuracy: 0.8085 - val_loss: 0.4619 - val_accuracy: 0.8264\n",
      "Epoch 769/1000\n",
      "225/225 [==============================] - 0s 1ms/step - loss: 0.4882 - accuracy: 0.8082 - val_loss: 0.4608 - val_accuracy: 0.8261\n",
      "Epoch 770/1000\n",
      "225/225 [==============================] - 0s 1ms/step - loss: 0.4911 - accuracy: 0.8072 - val_loss: 0.4608 - val_accuracy: 0.8264\n",
      "Epoch 771/1000\n",
      "225/225 [==============================] - 0s 1ms/step - loss: 0.4880 - accuracy: 0.8084 - val_loss: 0.4641 - val_accuracy: 0.8235\n",
      "Epoch 772/1000\n",
      "225/225 [==============================] - 0s 1ms/step - loss: 0.4885 - accuracy: 0.8081 - val_loss: 0.4626 - val_accuracy: 0.8231\n",
      "Epoch 773/1000\n",
      "225/225 [==============================] - 0s 1ms/step - loss: 0.4883 - accuracy: 0.8093 - val_loss: 0.4632 - val_accuracy: 0.8254\n",
      "Epoch 774/1000\n",
      "225/225 [==============================] - 0s 1ms/step - loss: 0.4885 - accuracy: 0.8086 - val_loss: 0.4612 - val_accuracy: 0.8266\n",
      "Epoch 775/1000\n",
      "225/225 [==============================] - 0s 1ms/step - loss: 0.4893 - accuracy: 0.8077 - val_loss: 0.4643 - val_accuracy: 0.8236\n",
      "Epoch 776/1000\n",
      "225/225 [==============================] - 0s 1ms/step - loss: 0.4897 - accuracy: 0.8077 - val_loss: 0.4629 - val_accuracy: 0.8235\n",
      "Epoch 777/1000\n",
      "225/225 [==============================] - 0s 1ms/step - loss: 0.4893 - accuracy: 0.8077 - val_loss: 0.4648 - val_accuracy: 0.8253\n",
      "Epoch 778/1000\n",
      "225/225 [==============================] - 0s 1ms/step - loss: 0.4887 - accuracy: 0.8084 - val_loss: 0.4634 - val_accuracy: 0.8244\n",
      "Epoch 779/1000\n",
      "225/225 [==============================] - 0s 1ms/step - loss: 0.4890 - accuracy: 0.8072 - val_loss: 0.4654 - val_accuracy: 0.8231\n",
      "Epoch 780/1000\n",
      "225/225 [==============================] - 0s 1ms/step - loss: 0.4891 - accuracy: 0.8076 - val_loss: 0.4610 - val_accuracy: 0.8267\n",
      "Epoch 781/1000\n",
      "225/225 [==============================] - 0s 2ms/step - loss: 0.4885 - accuracy: 0.8089 - val_loss: 0.4619 - val_accuracy: 0.8255\n",
      "Epoch 782/1000\n",
      "225/225 [==============================] - 0s 1ms/step - loss: 0.4903 - accuracy: 0.8068 - val_loss: 0.4630 - val_accuracy: 0.8238\n",
      "Epoch 783/1000\n",
      "225/225 [==============================] - 0s 1ms/step - loss: 0.4895 - accuracy: 0.8076 - val_loss: 0.4623 - val_accuracy: 0.8235\n",
      "Epoch 784/1000\n",
      "225/225 [==============================] - 0s 1ms/step - loss: 0.4877 - accuracy: 0.8087 - val_loss: 0.4640 - val_accuracy: 0.8246\n",
      "Epoch 785/1000\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "225/225 [==============================] - 0s 1ms/step - loss: 0.4892 - accuracy: 0.8078 - val_loss: 0.4634 - val_accuracy: 0.8264\n",
      "Epoch 786/1000\n",
      "225/225 [==============================] - 0s 1ms/step - loss: 0.4890 - accuracy: 0.8076 - val_loss: 0.4618 - val_accuracy: 0.8249\n",
      "Epoch 787/1000\n",
      "225/225 [==============================] - 0s 1ms/step - loss: 0.4886 - accuracy: 0.8085 - val_loss: 0.4622 - val_accuracy: 0.8253\n",
      "Epoch 788/1000\n",
      "225/225 [==============================] - 0s 1ms/step - loss: 0.4907 - accuracy: 0.8074 - val_loss: 0.4627 - val_accuracy: 0.8264\n",
      "Epoch 789/1000\n",
      "225/225 [==============================] - 0s 1ms/step - loss: 0.4895 - accuracy: 0.8082 - val_loss: 0.4632 - val_accuracy: 0.8257\n",
      "Epoch 790/1000\n",
      "225/225 [==============================] - 0s 1ms/step - loss: 0.4888 - accuracy: 0.8079 - val_loss: 0.4621 - val_accuracy: 0.8262\n",
      "Epoch 791/1000\n",
      "225/225 [==============================] - 0s 1ms/step - loss: 0.4887 - accuracy: 0.8077 - val_loss: 0.4600 - val_accuracy: 0.8249\n",
      "Epoch 792/1000\n",
      "225/225 [==============================] - 0s 1ms/step - loss: 0.4900 - accuracy: 0.8084 - val_loss: 0.4604 - val_accuracy: 0.8251\n",
      "Epoch 793/1000\n",
      "225/225 [==============================] - 0s 1ms/step - loss: 0.4885 - accuracy: 0.8082 - val_loss: 0.4614 - val_accuracy: 0.8268\n",
      "Epoch 794/1000\n",
      "225/225 [==============================] - 0s 1ms/step - loss: 0.4898 - accuracy: 0.8067 - val_loss: 0.4609 - val_accuracy: 0.8259\n",
      "Epoch 795/1000\n",
      "225/225 [==============================] - 0s 1ms/step - loss: 0.4892 - accuracy: 0.8084 - val_loss: 0.4637 - val_accuracy: 0.8245\n",
      "Epoch 796/1000\n",
      "225/225 [==============================] - 0s 1ms/step - loss: 0.4866 - accuracy: 0.8097 - val_loss: 0.4624 - val_accuracy: 0.8235\n",
      "Epoch 797/1000\n",
      "225/225 [==============================] - 0s 1ms/step - loss: 0.4889 - accuracy: 0.8083 - val_loss: 0.4674 - val_accuracy: 0.8231\n",
      "Epoch 798/1000\n",
      "225/225 [==============================] - 0s 1ms/step - loss: 0.4888 - accuracy: 0.8083 - val_loss: 0.4637 - val_accuracy: 0.8251\n",
      "Epoch 799/1000\n",
      "225/225 [==============================] - 0s 1ms/step - loss: 0.4907 - accuracy: 0.8073 - val_loss: 0.4631 - val_accuracy: 0.8254\n",
      "Epoch 800/1000\n",
      "225/225 [==============================] - 0s 1ms/step - loss: 0.4887 - accuracy: 0.8079 - val_loss: 0.4607 - val_accuracy: 0.8274\n",
      "Epoch 801/1000\n",
      "225/225 [==============================] - 0s 1ms/step - loss: 0.4897 - accuracy: 0.8079 - val_loss: 0.4662 - val_accuracy: 0.8253\n",
      "Epoch 802/1000\n",
      "225/225 [==============================] - 0s 1ms/step - loss: 0.4894 - accuracy: 0.8073 - val_loss: 0.4648 - val_accuracy: 0.8224\n",
      "Epoch 803/1000\n",
      "225/225 [==============================] - 0s 1ms/step - loss: 0.4907 - accuracy: 0.8076 - val_loss: 0.4617 - val_accuracy: 0.8249\n",
      "Epoch 804/1000\n",
      "225/225 [==============================] - 0s 1ms/step - loss: 0.4883 - accuracy: 0.8086 - val_loss: 0.4643 - val_accuracy: 0.8238\n",
      "Epoch 805/1000\n",
      "225/225 [==============================] - 0s 1ms/step - loss: 0.4887 - accuracy: 0.8086 - val_loss: 0.4632 - val_accuracy: 0.8256\n",
      "Epoch 806/1000\n",
      "225/225 [==============================] - 0s 1ms/step - loss: 0.4863 - accuracy: 0.8093 - val_loss: 0.4634 - val_accuracy: 0.8236\n",
      "Epoch 807/1000\n",
      "225/225 [==============================] - 0s 1ms/step - loss: 0.4881 - accuracy: 0.8089 - val_loss: 0.4632 - val_accuracy: 0.8220\n",
      "Epoch 808/1000\n",
      "225/225 [==============================] - 0s 1ms/step - loss: 0.4868 - accuracy: 0.8093 - val_loss: 0.4626 - val_accuracy: 0.8251\n",
      "Epoch 809/1000\n",
      "225/225 [==============================] - 0s 1ms/step - loss: 0.4857 - accuracy: 0.8089 - val_loss: 0.4610 - val_accuracy: 0.8246\n",
      "Epoch 810/1000\n",
      "225/225 [==============================] - 0s 1ms/step - loss: 0.4899 - accuracy: 0.8071 - val_loss: 0.4612 - val_accuracy: 0.8252\n",
      "Epoch 811/1000\n",
      "225/225 [==============================] - 0s 1ms/step - loss: 0.4878 - accuracy: 0.8090 - val_loss: 0.4639 - val_accuracy: 0.8235\n",
      "Epoch 812/1000\n",
      "225/225 [==============================] - 0s 1ms/step - loss: 0.4878 - accuracy: 0.8085 - val_loss: 0.4636 - val_accuracy: 0.8246\n",
      "Epoch 813/1000\n",
      "225/225 [==============================] - 0s 1ms/step - loss: 0.4910 - accuracy: 0.8079 - val_loss: 0.4627 - val_accuracy: 0.8229\n",
      "Epoch 814/1000\n",
      "225/225 [==============================] - 0s 1ms/step - loss: 0.4885 - accuracy: 0.8077 - val_loss: 0.4647 - val_accuracy: 0.8235\n",
      "Epoch 815/1000\n",
      "225/225 [==============================] - 0s 1ms/step - loss: 0.4887 - accuracy: 0.8086 - val_loss: 0.4659 - val_accuracy: 0.8231\n",
      "Epoch 816/1000\n",
      "225/225 [==============================] - 0s 1ms/step - loss: 0.4885 - accuracy: 0.8086 - val_loss: 0.4631 - val_accuracy: 0.8250\n",
      "Epoch 817/1000\n",
      "225/225 [==============================] - 0s 1ms/step - loss: 0.4875 - accuracy: 0.8087 - val_loss: 0.4625 - val_accuracy: 0.8225\n",
      "Epoch 818/1000\n",
      "225/225 [==============================] - 0s 1ms/step - loss: 0.4898 - accuracy: 0.8080 - val_loss: 0.4633 - val_accuracy: 0.8245\n",
      "Epoch 819/1000\n",
      "225/225 [==============================] - 0s 1ms/step - loss: 0.4885 - accuracy: 0.8084 - val_loss: 0.4616 - val_accuracy: 0.8262\n",
      "Epoch 820/1000\n",
      "225/225 [==============================] - 0s 1ms/step - loss: 0.4878 - accuracy: 0.8085 - val_loss: 0.4610 - val_accuracy: 0.8251\n",
      "Epoch 821/1000\n",
      "225/225 [==============================] - 0s 1ms/step - loss: 0.4872 - accuracy: 0.8086 - val_loss: 0.4616 - val_accuracy: 0.8246\n",
      "Epoch 822/1000\n",
      "225/225 [==============================] - 0s 1ms/step - loss: 0.4883 - accuracy: 0.8090 - val_loss: 0.4641 - val_accuracy: 0.8246\n",
      "Epoch 823/1000\n",
      "225/225 [==============================] - 0s 1ms/step - loss: 0.4913 - accuracy: 0.8067 - val_loss: 0.4613 - val_accuracy: 0.8260\n",
      "Epoch 824/1000\n",
      "225/225 [==============================] - 0s 1ms/step - loss: 0.4880 - accuracy: 0.8089 - val_loss: 0.4628 - val_accuracy: 0.8249\n",
      "Epoch 825/1000\n",
      "225/225 [==============================] - 0s 1ms/step - loss: 0.4879 - accuracy: 0.8088 - val_loss: 0.4630 - val_accuracy: 0.8250\n",
      "Epoch 826/1000\n",
      "225/225 [==============================] - 0s 1ms/step - loss: 0.4871 - accuracy: 0.8092 - val_loss: 0.4630 - val_accuracy: 0.8245\n",
      "Epoch 827/1000\n",
      "225/225 [==============================] - 0s 1ms/step - loss: 0.4885 - accuracy: 0.8085 - val_loss: 0.4628 - val_accuracy: 0.8264\n",
      "Epoch 828/1000\n",
      "225/225 [==============================] - 0s 1ms/step - loss: 0.4872 - accuracy: 0.8089 - val_loss: 0.4629 - val_accuracy: 0.8242\n",
      "Epoch 829/1000\n",
      "225/225 [==============================] - 0s 1ms/step - loss: 0.4864 - accuracy: 0.8076 - val_loss: 0.4629 - val_accuracy: 0.8237\n",
      "Epoch 830/1000\n",
      "225/225 [==============================] - 0s 1ms/step - loss: 0.4877 - accuracy: 0.8081 - val_loss: 0.4602 - val_accuracy: 0.8249\n",
      "Epoch 831/1000\n",
      "225/225 [==============================] - 0s 1ms/step - loss: 0.4905 - accuracy: 0.8075 - val_loss: 0.4633 - val_accuracy: 0.8238\n",
      "Epoch 832/1000\n",
      "225/225 [==============================] - 0s 1ms/step - loss: 0.4873 - accuracy: 0.8094 - val_loss: 0.4623 - val_accuracy: 0.8266\n",
      "Epoch 833/1000\n",
      "225/225 [==============================] - 0s 1ms/step - loss: 0.4865 - accuracy: 0.8094 - val_loss: 0.4638 - val_accuracy: 0.8254\n",
      "Epoch 834/1000\n",
      "225/225 [==============================] - 0s 1ms/step - loss: 0.4857 - accuracy: 0.8093 - val_loss: 0.4627 - val_accuracy: 0.8229\n",
      "Epoch 835/1000\n",
      "225/225 [==============================] - 0s 1ms/step - loss: 0.4890 - accuracy: 0.8084 - val_loss: 0.4618 - val_accuracy: 0.8252\n",
      "Epoch 836/1000\n",
      "225/225 [==============================] - 0s 1ms/step - loss: 0.4873 - accuracy: 0.8086 - val_loss: 0.4633 - val_accuracy: 0.8246\n",
      "Epoch 837/1000\n",
      "225/225 [==============================] - 0s 1ms/step - loss: 0.4892 - accuracy: 0.8072 - val_loss: 0.4633 - val_accuracy: 0.8242\n",
      "Epoch 838/1000\n",
      "225/225 [==============================] - 0s 1ms/step - loss: 0.4895 - accuracy: 0.8073 - val_loss: 0.4643 - val_accuracy: 0.8226\n",
      "Epoch 839/1000\n",
      "225/225 [==============================] - 0s 1ms/step - loss: 0.4893 - accuracy: 0.8084 - val_loss: 0.4613 - val_accuracy: 0.8254\n",
      "Epoch 840/1000\n",
      "225/225 [==============================] - 0s 1ms/step - loss: 0.4872 - accuracy: 0.8093 - val_loss: 0.4657 - val_accuracy: 0.8223\n",
      "Epoch 841/1000\n",
      "225/225 [==============================] - 0s 1ms/step - loss: 0.4875 - accuracy: 0.8093 - val_loss: 0.4633 - val_accuracy: 0.8241\n",
      "Epoch 842/1000\n",
      "225/225 [==============================] - 0s 1ms/step - loss: 0.4870 - accuracy: 0.8089 - val_loss: 0.4651 - val_accuracy: 0.8241\n",
      "Epoch 843/1000\n",
      "225/225 [==============================] - 0s 1ms/step - loss: 0.4884 - accuracy: 0.8085 - val_loss: 0.4629 - val_accuracy: 0.8235\n",
      "Epoch 844/1000\n",
      "225/225 [==============================] - 0s 1ms/step - loss: 0.4891 - accuracy: 0.8080 - val_loss: 0.4641 - val_accuracy: 0.8237\n",
      "Epoch 845/1000\n",
      "225/225 [==============================] - 0s 1ms/step - loss: 0.4875 - accuracy: 0.8087 - val_loss: 0.4627 - val_accuracy: 0.8240\n",
      "Epoch 846/1000\n",
      "225/225 [==============================] - 0s 1ms/step - loss: 0.4873 - accuracy: 0.8085 - val_loss: 0.4623 - val_accuracy: 0.8240\n",
      "Epoch 847/1000\n",
      "225/225 [==============================] - 0s 1ms/step - loss: 0.4886 - accuracy: 0.8087 - val_loss: 0.4614 - val_accuracy: 0.8251\n",
      "Epoch 848/1000\n",
      "225/225 [==============================] - 0s 1ms/step - loss: 0.4880 - accuracy: 0.8093 - val_loss: 0.4640 - val_accuracy: 0.8244\n",
      "Epoch 849/1000\n",
      "225/225 [==============================] - 0s 1ms/step - loss: 0.4897 - accuracy: 0.8077 - val_loss: 0.4621 - val_accuracy: 0.8247\n",
      "Epoch 850/1000\n",
      "225/225 [==============================] - 0s 1ms/step - loss: 0.4910 - accuracy: 0.8074 - val_loss: 0.4623 - val_accuracy: 0.8243\n",
      "Epoch 851/1000\n",
      "225/225 [==============================] - 0s 1ms/step - loss: 0.4879 - accuracy: 0.8082 - val_loss: 0.4636 - val_accuracy: 0.8219\n",
      "Epoch 852/1000\n",
      "225/225 [==============================] - 0s 1ms/step - loss: 0.4891 - accuracy: 0.8081 - val_loss: 0.4656 - val_accuracy: 0.8217\n",
      "Epoch 853/1000\n",
      "225/225 [==============================] - 0s 1ms/step - loss: 0.4885 - accuracy: 0.8085 - val_loss: 0.4648 - val_accuracy: 0.8239\n",
      "Epoch 854/1000\n",
      "225/225 [==============================] - 0s 1ms/step - loss: 0.4866 - accuracy: 0.8088 - val_loss: 0.4644 - val_accuracy: 0.8256\n",
      "Epoch 855/1000\n",
      "225/225 [==============================] - 0s 1ms/step - loss: 0.4873 - accuracy: 0.8085 - val_loss: 0.4608 - val_accuracy: 0.8246\n",
      "Epoch 856/1000\n",
      "225/225 [==============================] - 0s 1ms/step - loss: 0.4866 - accuracy: 0.8091 - val_loss: 0.4628 - val_accuracy: 0.8235\n",
      "Epoch 857/1000\n",
      "225/225 [==============================] - 0s 1ms/step - loss: 0.4887 - accuracy: 0.8079 - val_loss: 0.4627 - val_accuracy: 0.8249\n",
      "Epoch 858/1000\n",
      "225/225 [==============================] - 0s 1ms/step - loss: 0.4869 - accuracy: 0.8094 - val_loss: 0.4614 - val_accuracy: 0.8260\n",
      "Epoch 859/1000\n",
      "225/225 [==============================] - 0s 1ms/step - loss: 0.4887 - accuracy: 0.8094 - val_loss: 0.4608 - val_accuracy: 0.8260\n",
      "Epoch 860/1000\n",
      "225/225 [==============================] - 0s 1ms/step - loss: 0.4879 - accuracy: 0.8078 - val_loss: 0.4640 - val_accuracy: 0.8261\n",
      "Epoch 861/1000\n",
      "225/225 [==============================] - 0s 1ms/step - loss: 0.4888 - accuracy: 0.8085 - val_loss: 0.4612 - val_accuracy: 0.8264\n",
      "Epoch 862/1000\n",
      "225/225 [==============================] - 0s 1ms/step - loss: 0.4877 - accuracy: 0.8089 - val_loss: 0.4612 - val_accuracy: 0.8273\n",
      "Epoch 863/1000\n",
      "225/225 [==============================] - 0s 1ms/step - loss: 0.4905 - accuracy: 0.8072 - val_loss: 0.4617 - val_accuracy: 0.8238\n",
      "Epoch 864/1000\n",
      "225/225 [==============================] - 0s 1ms/step - loss: 0.4856 - accuracy: 0.8099 - val_loss: 0.4613 - val_accuracy: 0.8260\n",
      "Epoch 865/1000\n",
      "225/225 [==============================] - 0s 1ms/step - loss: 0.4878 - accuracy: 0.8088 - val_loss: 0.4628 - val_accuracy: 0.8263\n",
      "Epoch 866/1000\n",
      "225/225 [==============================] - 0s 1ms/step - loss: 0.4874 - accuracy: 0.8085 - val_loss: 0.4633 - val_accuracy: 0.8245\n",
      "Epoch 867/1000\n",
      "225/225 [==============================] - 0s 1ms/step - loss: 0.4894 - accuracy: 0.8082 - val_loss: 0.4623 - val_accuracy: 0.8249\n",
      "Epoch 868/1000\n",
      "225/225 [==============================] - 0s 1ms/step - loss: 0.4865 - accuracy: 0.8092 - val_loss: 0.4628 - val_accuracy: 0.8269\n",
      "Epoch 869/1000\n",
      "225/225 [==============================] - 0s 1ms/step - loss: 0.4886 - accuracy: 0.8080 - val_loss: 0.4623 - val_accuracy: 0.8251\n",
      "Epoch 870/1000\n",
      "225/225 [==============================] - 0s 1ms/step - loss: 0.4863 - accuracy: 0.8089 - val_loss: 0.4617 - val_accuracy: 0.8272\n",
      "Epoch 871/1000\n",
      "225/225 [==============================] - 0s 1ms/step - loss: 0.4872 - accuracy: 0.8098 - val_loss: 0.4632 - val_accuracy: 0.8249\n",
      "Epoch 872/1000\n",
      "225/225 [==============================] - 0s 1ms/step - loss: 0.4874 - accuracy: 0.8093 - val_loss: 0.4617 - val_accuracy: 0.8253\n",
      "Epoch 873/1000\n",
      "225/225 [==============================] - 0s 1ms/step - loss: 0.4865 - accuracy: 0.8085 - val_loss: 0.4623 - val_accuracy: 0.8242\n",
      "Epoch 874/1000\n",
      "225/225 [==============================] - 0s 1ms/step - loss: 0.4867 - accuracy: 0.8090 - val_loss: 0.4637 - val_accuracy: 0.8249\n",
      "Epoch 875/1000\n",
      "225/225 [==============================] - 0s 1ms/step - loss: 0.4867 - accuracy: 0.8088 - val_loss: 0.4619 - val_accuracy: 0.8270\n",
      "Epoch 876/1000\n",
      "225/225 [==============================] - 0s 1ms/step - loss: 0.4883 - accuracy: 0.8088 - val_loss: 0.4617 - val_accuracy: 0.8260\n",
      "Epoch 877/1000\n",
      "225/225 [==============================] - 0s 1ms/step - loss: 0.4872 - accuracy: 0.8092 - val_loss: 0.4597 - val_accuracy: 0.8268\n",
      "Epoch 878/1000\n",
      "225/225 [==============================] - 0s 1ms/step - loss: 0.4897 - accuracy: 0.8071 - val_loss: 0.4648 - val_accuracy: 0.8243\n",
      "Epoch 879/1000\n",
      "225/225 [==============================] - 0s 1ms/step - loss: 0.4867 - accuracy: 0.8096 - val_loss: 0.4622 - val_accuracy: 0.8235\n",
      "Epoch 880/1000\n",
      "225/225 [==============================] - 0s 1ms/step - loss: 0.4900 - accuracy: 0.8071 - val_loss: 0.4639 - val_accuracy: 0.8248\n",
      "Epoch 881/1000\n",
      "225/225 [==============================] - 0s 1ms/step - loss: 0.4872 - accuracy: 0.8090 - val_loss: 0.4613 - val_accuracy: 0.8255\n",
      "Epoch 882/1000\n",
      "225/225 [==============================] - 0s 1ms/step - loss: 0.4873 - accuracy: 0.8093 - val_loss: 0.4610 - val_accuracy: 0.8249\n",
      "Epoch 883/1000\n",
      "225/225 [==============================] - 0s 1ms/step - loss: 0.4892 - accuracy: 0.8077 - val_loss: 0.4645 - val_accuracy: 0.8237\n",
      "Epoch 884/1000\n",
      "225/225 [==============================] - 0s 1ms/step - loss: 0.4881 - accuracy: 0.8085 - val_loss: 0.4621 - val_accuracy: 0.8247\n",
      "Epoch 885/1000\n",
      "225/225 [==============================] - 0s 2ms/step - loss: 0.4893 - accuracy: 0.8082 - val_loss: 0.4610 - val_accuracy: 0.8243\n",
      "Epoch 886/1000\n",
      "225/225 [==============================] - 0s 1ms/step - loss: 0.4874 - accuracy: 0.8094 - val_loss: 0.4609 - val_accuracy: 0.8231\n",
      "Epoch 887/1000\n",
      "225/225 [==============================] - 0s 1ms/step - loss: 0.4874 - accuracy: 0.8087 - val_loss: 0.4622 - val_accuracy: 0.8256\n",
      "Epoch 888/1000\n",
      "225/225 [==============================] - 0s 1ms/step - loss: 0.4881 - accuracy: 0.8090 - val_loss: 0.4610 - val_accuracy: 0.8234\n",
      "Epoch 889/1000\n",
      "225/225 [==============================] - 0s 1ms/step - loss: 0.4877 - accuracy: 0.8086 - val_loss: 0.4633 - val_accuracy: 0.8220\n",
      "Epoch 890/1000\n",
      "225/225 [==============================] - 0s 1ms/step - loss: 0.4870 - accuracy: 0.8088 - val_loss: 0.4650 - val_accuracy: 0.8228\n",
      "Epoch 891/1000\n",
      "225/225 [==============================] - 0s 1ms/step - loss: 0.4861 - accuracy: 0.8086 - val_loss: 0.4632 - val_accuracy: 0.8249\n",
      "Epoch 892/1000\n",
      "225/225 [==============================] - 0s 1ms/step - loss: 0.4886 - accuracy: 0.8093 - val_loss: 0.4636 - val_accuracy: 0.8245\n",
      "Epoch 893/1000\n",
      "225/225 [==============================] - 0s 1ms/step - loss: 0.4862 - accuracy: 0.8099 - val_loss: 0.4618 - val_accuracy: 0.8262\n",
      "Epoch 894/1000\n",
      "225/225 [==============================] - 0s 1ms/step - loss: 0.4872 - accuracy: 0.8095 - val_loss: 0.4643 - val_accuracy: 0.8219\n",
      "Epoch 895/1000\n",
      "225/225 [==============================] - 0s 1ms/step - loss: 0.4873 - accuracy: 0.8085 - val_loss: 0.4614 - val_accuracy: 0.8257\n",
      "Epoch 896/1000\n",
      "225/225 [==============================] - 0s 1ms/step - loss: 0.4888 - accuracy: 0.8076 - val_loss: 0.4627 - val_accuracy: 0.8249\n",
      "Epoch 897/1000\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "225/225 [==============================] - 0s 1ms/step - loss: 0.4855 - accuracy: 0.8095 - val_loss: 0.4618 - val_accuracy: 0.8266\n",
      "Epoch 898/1000\n",
      "225/225 [==============================] - 0s 1ms/step - loss: 0.4868 - accuracy: 0.8089 - val_loss: 0.4625 - val_accuracy: 0.8243\n",
      "Epoch 899/1000\n",
      "225/225 [==============================] - 0s 1ms/step - loss: 0.4881 - accuracy: 0.8087 - val_loss: 0.4626 - val_accuracy: 0.8242\n",
      "Epoch 900/1000\n",
      "225/225 [==============================] - 0s 1ms/step - loss: 0.4877 - accuracy: 0.8089 - val_loss: 0.4644 - val_accuracy: 0.8235\n",
      "Epoch 901/1000\n",
      "225/225 [==============================] - 0s 1ms/step - loss: 0.4859 - accuracy: 0.8103 - val_loss: 0.4601 - val_accuracy: 0.8257\n",
      "Epoch 902/1000\n",
      "225/225 [==============================] - 0s 1ms/step - loss: 0.4872 - accuracy: 0.8095 - val_loss: 0.4628 - val_accuracy: 0.8234\n",
      "Epoch 903/1000\n",
      "225/225 [==============================] - 0s 1ms/step - loss: 0.4882 - accuracy: 0.8077 - val_loss: 0.4610 - val_accuracy: 0.8275\n",
      "Epoch 904/1000\n",
      "225/225 [==============================] - 0s 1ms/step - loss: 0.4868 - accuracy: 0.8088 - val_loss: 0.4606 - val_accuracy: 0.8250\n",
      "Epoch 905/1000\n",
      "225/225 [==============================] - 0s 1ms/step - loss: 0.4869 - accuracy: 0.8092 - val_loss: 0.4623 - val_accuracy: 0.8246\n",
      "Epoch 906/1000\n",
      "225/225 [==============================] - 0s 1ms/step - loss: 0.4862 - accuracy: 0.8091 - val_loss: 0.4644 - val_accuracy: 0.8224\n",
      "Epoch 907/1000\n",
      "225/225 [==============================] - 0s 1ms/step - loss: 0.4876 - accuracy: 0.8084 - val_loss: 0.4634 - val_accuracy: 0.8239\n",
      "Epoch 908/1000\n",
      "225/225 [==============================] - 0s 1ms/step - loss: 0.4853 - accuracy: 0.8101 - val_loss: 0.4642 - val_accuracy: 0.8231\n",
      "Epoch 909/1000\n",
      "225/225 [==============================] - 0s 1ms/step - loss: 0.4856 - accuracy: 0.8093 - val_loss: 0.4652 - val_accuracy: 0.8232\n",
      "Epoch 910/1000\n",
      "225/225 [==============================] - 0s 1ms/step - loss: 0.4871 - accuracy: 0.8087 - val_loss: 0.4615 - val_accuracy: 0.8255\n",
      "Epoch 911/1000\n",
      "225/225 [==============================] - 0s 1ms/step - loss: 0.4874 - accuracy: 0.8094 - val_loss: 0.4615 - val_accuracy: 0.8255\n",
      "Epoch 912/1000\n",
      "225/225 [==============================] - 0s 1ms/step - loss: 0.4873 - accuracy: 0.8088 - val_loss: 0.4650 - val_accuracy: 0.8230\n",
      "Epoch 913/1000\n",
      "225/225 [==============================] - 0s 1ms/step - loss: 0.4876 - accuracy: 0.8085 - val_loss: 0.4640 - val_accuracy: 0.8239\n",
      "Epoch 914/1000\n",
      "225/225 [==============================] - 0s 1ms/step - loss: 0.4878 - accuracy: 0.8086 - val_loss: 0.4608 - val_accuracy: 0.8239\n",
      "Epoch 915/1000\n",
      "225/225 [==============================] - 0s 1ms/step - loss: 0.4877 - accuracy: 0.8085 - val_loss: 0.4647 - val_accuracy: 0.8246\n",
      "Epoch 916/1000\n",
      "225/225 [==============================] - 0s 1ms/step - loss: 0.4865 - accuracy: 0.8089 - val_loss: 0.4631 - val_accuracy: 0.8245\n",
      "Epoch 917/1000\n",
      "225/225 [==============================] - 0s 1ms/step - loss: 0.4874 - accuracy: 0.8079 - val_loss: 0.4639 - val_accuracy: 0.8218\n",
      "Epoch 918/1000\n",
      "225/225 [==============================] - 0s 1ms/step - loss: 0.4877 - accuracy: 0.8082 - val_loss: 0.4653 - val_accuracy: 0.8228\n",
      "Epoch 919/1000\n",
      "225/225 [==============================] - 0s 1ms/step - loss: 0.4865 - accuracy: 0.8097 - val_loss: 0.4638 - val_accuracy: 0.8228\n",
      "Epoch 920/1000\n",
      "225/225 [==============================] - 0s 1ms/step - loss: 0.4850 - accuracy: 0.8102 - val_loss: 0.4617 - val_accuracy: 0.8257\n",
      "Epoch 921/1000\n",
      "225/225 [==============================] - 0s 1ms/step - loss: 0.4870 - accuracy: 0.8091 - val_loss: 0.4622 - val_accuracy: 0.8246\n",
      "Epoch 922/1000\n",
      "225/225 [==============================] - 0s 1ms/step - loss: 0.4850 - accuracy: 0.8102 - val_loss: 0.4599 - val_accuracy: 0.8258\n",
      "Epoch 923/1000\n",
      "225/225 [==============================] - 0s 1ms/step - loss: 0.4863 - accuracy: 0.8095 - val_loss: 0.4627 - val_accuracy: 0.8242\n",
      "Epoch 924/1000\n",
      "225/225 [==============================] - 0s 1ms/step - loss: 0.4858 - accuracy: 0.8088 - val_loss: 0.4606 - val_accuracy: 0.8260\n",
      "Epoch 925/1000\n",
      "225/225 [==============================] - 0s 1ms/step - loss: 0.4842 - accuracy: 0.8105 - val_loss: 0.4617 - val_accuracy: 0.8238\n",
      "Epoch 926/1000\n",
      "225/225 [==============================] - 0s 1ms/step - loss: 0.4854 - accuracy: 0.8094 - val_loss: 0.4625 - val_accuracy: 0.8263\n",
      "Epoch 927/1000\n",
      "225/225 [==============================] - 0s 1ms/step - loss: 0.4855 - accuracy: 0.8099 - val_loss: 0.4626 - val_accuracy: 0.8256\n",
      "Epoch 928/1000\n",
      "225/225 [==============================] - 0s 1ms/step - loss: 0.4854 - accuracy: 0.8106 - val_loss: 0.4610 - val_accuracy: 0.8268\n",
      "Epoch 929/1000\n",
      "225/225 [==============================] - 0s 1ms/step - loss: 0.4869 - accuracy: 0.8100 - val_loss: 0.4652 - val_accuracy: 0.8234\n",
      "Epoch 930/1000\n",
      "225/225 [==============================] - 0s 1ms/step - loss: 0.4872 - accuracy: 0.8093 - val_loss: 0.4604 - val_accuracy: 0.8253\n",
      "Epoch 931/1000\n",
      "225/225 [==============================] - 0s 1ms/step - loss: 0.4871 - accuracy: 0.8091 - val_loss: 0.4639 - val_accuracy: 0.8257\n",
      "Epoch 932/1000\n",
      "225/225 [==============================] - 0s 1ms/step - loss: 0.4855 - accuracy: 0.8108 - val_loss: 0.4615 - val_accuracy: 0.8253\n",
      "Epoch 933/1000\n",
      "225/225 [==============================] - 0s 1ms/step - loss: 0.4856 - accuracy: 0.8087 - val_loss: 0.4632 - val_accuracy: 0.8251\n",
      "Epoch 934/1000\n",
      "225/225 [==============================] - 0s 1ms/step - loss: 0.4850 - accuracy: 0.8093 - val_loss: 0.4658 - val_accuracy: 0.8230\n",
      "Epoch 935/1000\n",
      "225/225 [==============================] - 0s 1ms/step - loss: 0.4847 - accuracy: 0.8092 - val_loss: 0.4613 - val_accuracy: 0.8269\n",
      "Epoch 936/1000\n",
      "225/225 [==============================] - 0s 1ms/step - loss: 0.4870 - accuracy: 0.8097 - val_loss: 0.4608 - val_accuracy: 0.8246\n",
      "Epoch 937/1000\n",
      "225/225 [==============================] - 0s 1ms/step - loss: 0.4861 - accuracy: 0.8098 - val_loss: 0.4614 - val_accuracy: 0.8251\n",
      "Epoch 938/1000\n",
      "225/225 [==============================] - 0s 1ms/step - loss: 0.4866 - accuracy: 0.8090 - val_loss: 0.4643 - val_accuracy: 0.8242\n",
      "Epoch 939/1000\n",
      "225/225 [==============================] - 0s 1ms/step - loss: 0.4883 - accuracy: 0.8093 - val_loss: 0.4636 - val_accuracy: 0.8257\n",
      "Epoch 940/1000\n",
      "225/225 [==============================] - 0s 1ms/step - loss: 0.4856 - accuracy: 0.8096 - val_loss: 0.4634 - val_accuracy: 0.8268\n",
      "Epoch 941/1000\n",
      "225/225 [==============================] - 0s 1ms/step - loss: 0.4875 - accuracy: 0.8083 - val_loss: 0.4617 - val_accuracy: 0.8243\n",
      "Epoch 942/1000\n",
      "225/225 [==============================] - 0s 1ms/step - loss: 0.4860 - accuracy: 0.8096 - val_loss: 0.4630 - val_accuracy: 0.8231\n",
      "Epoch 943/1000\n",
      "225/225 [==============================] - 0s 1ms/step - loss: 0.4864 - accuracy: 0.8089 - val_loss: 0.4618 - val_accuracy: 0.8247\n",
      "Epoch 944/1000\n",
      "225/225 [==============================] - 0s 1ms/step - loss: 0.4848 - accuracy: 0.8111 - val_loss: 0.4610 - val_accuracy: 0.8260\n",
      "Epoch 945/1000\n",
      "225/225 [==============================] - 0s 1ms/step - loss: 0.4877 - accuracy: 0.8085 - val_loss: 0.4635 - val_accuracy: 0.8248\n",
      "Epoch 946/1000\n",
      "225/225 [==============================] - 0s 1ms/step - loss: 0.4848 - accuracy: 0.8102 - val_loss: 0.4622 - val_accuracy: 0.8241\n",
      "Epoch 947/1000\n",
      "225/225 [==============================] - 0s 1ms/step - loss: 0.4846 - accuracy: 0.8105 - val_loss: 0.4611 - val_accuracy: 0.8256\n",
      "Epoch 948/1000\n",
      "225/225 [==============================] - 0s 1ms/step - loss: 0.4856 - accuracy: 0.8093 - val_loss: 0.4617 - val_accuracy: 0.8253\n",
      "Epoch 949/1000\n",
      "225/225 [==============================] - 0s 1ms/step - loss: 0.4859 - accuracy: 0.8099 - val_loss: 0.4645 - val_accuracy: 0.8232\n",
      "Epoch 950/1000\n",
      "225/225 [==============================] - 0s 1ms/step - loss: 0.4838 - accuracy: 0.8105 - val_loss: 0.4621 - val_accuracy: 0.8238\n",
      "Epoch 951/1000\n",
      "225/225 [==============================] - 0s 1ms/step - loss: 0.4850 - accuracy: 0.8095 - val_loss: 0.4635 - val_accuracy: 0.8241\n",
      "Epoch 952/1000\n",
      "225/225 [==============================] - 0s 1ms/step - loss: 0.4856 - accuracy: 0.8092 - val_loss: 0.4638 - val_accuracy: 0.8247\n",
      "Epoch 953/1000\n",
      "225/225 [==============================] - 0s 1ms/step - loss: 0.4859 - accuracy: 0.8082 - val_loss: 0.4633 - val_accuracy: 0.8252\n",
      "Epoch 954/1000\n",
      "225/225 [==============================] - 0s 1ms/step - loss: 0.4873 - accuracy: 0.8082 - val_loss: 0.4662 - val_accuracy: 0.8221\n",
      "Epoch 955/1000\n",
      "225/225 [==============================] - 0s 1ms/step - loss: 0.4847 - accuracy: 0.8095 - val_loss: 0.4668 - val_accuracy: 0.8227\n",
      "Epoch 956/1000\n",
      "225/225 [==============================] - 0s 1ms/step - loss: 0.4894 - accuracy: 0.8089 - val_loss: 0.4624 - val_accuracy: 0.8246\n",
      "Epoch 957/1000\n",
      "225/225 [==============================] - 0s 1ms/step - loss: 0.4850 - accuracy: 0.8098 - val_loss: 0.4637 - val_accuracy: 0.8220\n",
      "Epoch 958/1000\n",
      "225/225 [==============================] - 0s 1ms/step - loss: 0.4872 - accuracy: 0.8100 - val_loss: 0.4645 - val_accuracy: 0.8224\n",
      "Epoch 959/1000\n",
      "225/225 [==============================] - 0s 1ms/step - loss: 0.4851 - accuracy: 0.8105 - val_loss: 0.4604 - val_accuracy: 0.8248\n",
      "Epoch 960/1000\n",
      "225/225 [==============================] - 0s 1ms/step - loss: 0.4865 - accuracy: 0.8098 - val_loss: 0.4626 - val_accuracy: 0.8242\n",
      "Epoch 961/1000\n",
      "225/225 [==============================] - 0s 1ms/step - loss: 0.4861 - accuracy: 0.8100 - val_loss: 0.4612 - val_accuracy: 0.8241\n",
      "Epoch 962/1000\n",
      "225/225 [==============================] - 0s 1ms/step - loss: 0.4859 - accuracy: 0.8088 - val_loss: 0.4634 - val_accuracy: 0.8229\n",
      "Epoch 963/1000\n",
      "225/225 [==============================] - 0s 1ms/step - loss: 0.4859 - accuracy: 0.8095 - val_loss: 0.4611 - val_accuracy: 0.8252\n",
      "Epoch 964/1000\n",
      "225/225 [==============================] - 0s 1ms/step - loss: 0.4861 - accuracy: 0.8095 - val_loss: 0.4614 - val_accuracy: 0.8228\n",
      "Epoch 965/1000\n",
      "225/225 [==============================] - 0s 1ms/step - loss: 0.4836 - accuracy: 0.8099 - val_loss: 0.4600 - val_accuracy: 0.8249\n",
      "Epoch 966/1000\n",
      "225/225 [==============================] - 0s 1ms/step - loss: 0.4881 - accuracy: 0.8090 - val_loss: 0.4625 - val_accuracy: 0.8241\n",
      "Epoch 967/1000\n",
      "225/225 [==============================] - 0s 1ms/step - loss: 0.4874 - accuracy: 0.8095 - val_loss: 0.4626 - val_accuracy: 0.8249\n",
      "Epoch 967: early stopping\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "<keras.src.callbacks.History at 0x141c82410>"
      ]
     },
     "execution_count": 183,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "model=Sequential()\n",
    "model.add(Dense(128, input_dim=X_train.shape[1], activation=\"relu\"))\n",
    "model.add(Dropout(0.2))\n",
    "\n",
    "model.add(Dense(64, activation=\"relu\"))\n",
    "\n",
    "model.add(Dense(32, activation=\"relu\"))\n",
    "model.add(Dropout(0.2))\n",
    "model.add(Dense(16, activation=\"relu\"))\n",
    "\n",
    "model.add(Dense(3, activation=\"softmax\"))\n",
    "\n",
    "model.compile(loss='categorical_crossentropy', optimizer=Adam(learning_rate=0.001), metrics=['accuracy'])\n",
    "\n",
    "es=EarlyStopping(monitor=\"val_loss\",patience=90,mode=\"auto\",verbose=1)\n",
    "\n",
    "model.fit(X_train,\n",
    "          y_train,\n",
    "          epochs=1000,\n",
    "               batch_size=512,\n",
    "               validation_split=0.1,\n",
    "               verbose=1,callbacks=[es])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 184,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "997/997 [==============================] - 0s 231us/step\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0       0.83      0.92      0.87     10867\n",
      "           1       0.82      0.88      0.85     10432\n",
      "           2       0.81      0.65      0.72     10591\n",
      "\n",
      "    accuracy                           0.82     31890\n",
      "   macro avg       0.82      0.82      0.82     31890\n",
      "weighted avg       0.82      0.82      0.82     31890\n",
      "\n"
     ]
    }
   ],
   "source": [
    "y_pred = model.predict(X_test)\n",
    "y_pred_classes = np.argmax(y_pred, axis=1)\n",
    "y_true = np.argmax(y_test, axis=1)\n",
    "print(classification_report(y_true, y_pred_classes))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 185,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "3987/3987 [==============================] - 1s 221us/step\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0       0.85      0.94      0.89     42282\n",
      "           1       0.84      0.91      0.87     42717\n",
      "           2       0.85      0.69      0.76     42558\n",
      "\n",
      "    accuracy                           0.84    127557\n",
      "   macro avg       0.85      0.85      0.84    127557\n",
      "weighted avg       0.85      0.84      0.84    127557\n",
      "\n"
     ]
    }
   ],
   "source": [
    "y_t_pred = model.predict(X_train)\n",
    "y_t_pred_classes = np.argmax(y_t_pred, axis=1)\n",
    "y_t_true = np.argmax(y_train, axis=1)\n",
    "print(classification_report(y_t_true, y_t_pred_classes))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 186,
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 1/1000\n",
      "225/225 [==============================] - 1s 2ms/step - loss: 0.7974 - accuracy: 0.6771 - val_loss: 0.6902 - val_accuracy: 0.7256\n",
      "Epoch 2/1000\n",
      "225/225 [==============================] - 1s 2ms/step - loss: 0.7196 - accuracy: 0.7260 - val_loss: 0.6700 - val_accuracy: 0.7390\n",
      "Epoch 3/1000\n",
      "225/225 [==============================] - 0s 2ms/step - loss: 0.6974 - accuracy: 0.7338 - val_loss: 0.6546 - val_accuracy: 0.7426\n",
      "Epoch 4/1000\n",
      "225/225 [==============================] - 0s 2ms/step - loss: 0.6865 - accuracy: 0.7379 - val_loss: 0.6461 - val_accuracy: 0.7451\n",
      "Epoch 5/1000\n",
      "225/225 [==============================] - 0s 2ms/step - loss: 0.6792 - accuracy: 0.7402 - val_loss: 0.6437 - val_accuracy: 0.7451\n",
      "Epoch 6/1000\n",
      "225/225 [==============================] - 0s 2ms/step - loss: 0.6715 - accuracy: 0.7420 - val_loss: 0.6342 - val_accuracy: 0.7493\n",
      "Epoch 7/1000\n",
      "225/225 [==============================] - 0s 2ms/step - loss: 0.6655 - accuracy: 0.7434 - val_loss: 0.6285 - val_accuracy: 0.7514\n",
      "Epoch 8/1000\n",
      "225/225 [==============================] - 0s 2ms/step - loss: 0.6608 - accuracy: 0.7452 - val_loss: 0.6266 - val_accuracy: 0.7545\n",
      "Epoch 9/1000\n",
      "225/225 [==============================] - 0s 2ms/step - loss: 0.6558 - accuracy: 0.7470 - val_loss: 0.6221 - val_accuracy: 0.7550\n",
      "Epoch 10/1000\n",
      "225/225 [==============================] - 0s 2ms/step - loss: 0.6484 - accuracy: 0.7494 - val_loss: 0.6153 - val_accuracy: 0.7572\n",
      "Epoch 11/1000\n",
      "225/225 [==============================] - 0s 2ms/step - loss: 0.6453 - accuracy: 0.7508 - val_loss: 0.6122 - val_accuracy: 0.7596\n",
      "Epoch 12/1000\n",
      "225/225 [==============================] - 0s 2ms/step - loss: 0.6406 - accuracy: 0.7526 - val_loss: 0.6061 - val_accuracy: 0.7604\n",
      "Epoch 13/1000\n",
      "225/225 [==============================] - 0s 2ms/step - loss: 0.6362 - accuracy: 0.7531 - val_loss: 0.6022 - val_accuracy: 0.7639\n",
      "Epoch 14/1000\n",
      "225/225 [==============================] - 0s 2ms/step - loss: 0.6308 - accuracy: 0.7553 - val_loss: 0.5954 - val_accuracy: 0.7640\n",
      "Epoch 15/1000\n",
      "225/225 [==============================] - 0s 2ms/step - loss: 0.6256 - accuracy: 0.7572 - val_loss: 0.5881 - val_accuracy: 0.7684\n",
      "Epoch 16/1000\n",
      "225/225 [==============================] - 0s 2ms/step - loss: 0.6215 - accuracy: 0.7585 - val_loss: 0.5862 - val_accuracy: 0.7716\n",
      "Epoch 17/1000\n",
      "225/225 [==============================] - 0s 2ms/step - loss: 0.6181 - accuracy: 0.7590 - val_loss: 0.5832 - val_accuracy: 0.7700\n",
      "Epoch 18/1000\n",
      "225/225 [==============================] - 0s 2ms/step - loss: 0.6140 - accuracy: 0.7604 - val_loss: 0.5792 - val_accuracy: 0.7709\n",
      "Epoch 19/1000\n",
      "225/225 [==============================] - 0s 2ms/step - loss: 0.6125 - accuracy: 0.7613 - val_loss: 0.5761 - val_accuracy: 0.7713\n",
      "Epoch 20/1000\n",
      "225/225 [==============================] - 0s 2ms/step - loss: 0.6076 - accuracy: 0.7629 - val_loss: 0.5696 - val_accuracy: 0.7728\n",
      "Epoch 21/1000\n",
      "225/225 [==============================] - 0s 2ms/step - loss: 0.6053 - accuracy: 0.7646 - val_loss: 0.5656 - val_accuracy: 0.7776\n",
      "Epoch 22/1000\n",
      "225/225 [==============================] - 1s 2ms/step - loss: 0.6007 - accuracy: 0.7654 - val_loss: 0.5670 - val_accuracy: 0.7756\n",
      "Epoch 23/1000\n",
      "225/225 [==============================] - 0s 2ms/step - loss: 0.5991 - accuracy: 0.7665 - val_loss: 0.5612 - val_accuracy: 0.7782\n",
      "Epoch 24/1000\n",
      "225/225 [==============================] - 0s 2ms/step - loss: 0.5951 - accuracy: 0.7669 - val_loss: 0.5581 - val_accuracy: 0.7776\n",
      "Epoch 25/1000\n",
      "225/225 [==============================] - 0s 2ms/step - loss: 0.5925 - accuracy: 0.7693 - val_loss: 0.5548 - val_accuracy: 0.7807\n",
      "Epoch 26/1000\n",
      "225/225 [==============================] - 0s 2ms/step - loss: 0.5894 - accuracy: 0.7687 - val_loss: 0.5580 - val_accuracy: 0.7803\n",
      "Epoch 27/1000\n",
      "225/225 [==============================] - 0s 2ms/step - loss: 0.5867 - accuracy: 0.7701 - val_loss: 0.5514 - val_accuracy: 0.7823\n",
      "Epoch 28/1000\n",
      "225/225 [==============================] - 0s 2ms/step - loss: 0.5846 - accuracy: 0.7705 - val_loss: 0.5476 - val_accuracy: 0.7840\n",
      "Epoch 29/1000\n",
      "225/225 [==============================] - 0s 2ms/step - loss: 0.5826 - accuracy: 0.7718 - val_loss: 0.5506 - val_accuracy: 0.7808\n",
      "Epoch 30/1000\n",
      "225/225 [==============================] - 0s 2ms/step - loss: 0.5794 - accuracy: 0.7731 - val_loss: 0.5442 - val_accuracy: 0.7839\n",
      "Epoch 31/1000\n",
      "225/225 [==============================] - 1s 2ms/step - loss: 0.5783 - accuracy: 0.7746 - val_loss: 0.5399 - val_accuracy: 0.7882\n",
      "Epoch 32/1000\n",
      "225/225 [==============================] - 0s 2ms/step - loss: 0.5753 - accuracy: 0.7744 - val_loss: 0.5389 - val_accuracy: 0.7862\n",
      "Epoch 33/1000\n",
      "225/225 [==============================] - 0s 2ms/step - loss: 0.5739 - accuracy: 0.7750 - val_loss: 0.5338 - val_accuracy: 0.7865\n",
      "Epoch 34/1000\n",
      "225/225 [==============================] - 0s 2ms/step - loss: 0.5716 - accuracy: 0.7754 - val_loss: 0.5362 - val_accuracy: 0.7861\n",
      "Epoch 35/1000\n",
      "225/225 [==============================] - 0s 2ms/step - loss: 0.5714 - accuracy: 0.7745 - val_loss: 0.5305 - val_accuracy: 0.7889\n",
      "Epoch 36/1000\n",
      "225/225 [==============================] - 0s 2ms/step - loss: 0.5683 - accuracy: 0.7776 - val_loss: 0.5279 - val_accuracy: 0.7911\n",
      "Epoch 37/1000\n",
      "225/225 [==============================] - 0s 2ms/step - loss: 0.5664 - accuracy: 0.7778 - val_loss: 0.5284 - val_accuracy: 0.7896\n",
      "Epoch 38/1000\n",
      "225/225 [==============================] - 0s 2ms/step - loss: 0.5632 - accuracy: 0.7782 - val_loss: 0.5258 - val_accuracy: 0.7920\n",
      "Epoch 39/1000\n",
      "225/225 [==============================] - 0s 2ms/step - loss: 0.5634 - accuracy: 0.7787 - val_loss: 0.5258 - val_accuracy: 0.7892\n",
      "Epoch 40/1000\n",
      "225/225 [==============================] - 0s 2ms/step - loss: 0.5635 - accuracy: 0.7789 - val_loss: 0.5247 - val_accuracy: 0.7929\n",
      "Epoch 41/1000\n",
      "225/225 [==============================] - 0s 2ms/step - loss: 0.5582 - accuracy: 0.7817 - val_loss: 0.5195 - val_accuracy: 0.7948\n",
      "Epoch 42/1000\n",
      "225/225 [==============================] - 0s 2ms/step - loss: 0.5601 - accuracy: 0.7794 - val_loss: 0.5203 - val_accuracy: 0.7920\n",
      "Epoch 43/1000\n",
      "225/225 [==============================] - 0s 2ms/step - loss: 0.5576 - accuracy: 0.7812 - val_loss: 0.5185 - val_accuracy: 0.7932\n",
      "Epoch 44/1000\n",
      "225/225 [==============================] - 0s 2ms/step - loss: 0.5547 - accuracy: 0.7814 - val_loss: 0.5187 - val_accuracy: 0.7943\n",
      "Epoch 45/1000\n",
      "225/225 [==============================] - 0s 2ms/step - loss: 0.5549 - accuracy: 0.7818 - val_loss: 0.5200 - val_accuracy: 0.7902\n",
      "Epoch 46/1000\n",
      "225/225 [==============================] - 0s 2ms/step - loss: 0.5539 - accuracy: 0.7826 - val_loss: 0.5133 - val_accuracy: 0.7969\n",
      "Epoch 47/1000\n",
      "225/225 [==============================] - 0s 2ms/step - loss: 0.5507 - accuracy: 0.7837 - val_loss: 0.5117 - val_accuracy: 0.7959\n",
      "Epoch 48/1000\n",
      "225/225 [==============================] - 0s 2ms/step - loss: 0.5521 - accuracy: 0.7833 - val_loss: 0.5116 - val_accuracy: 0.7966\n",
      "Epoch 49/1000\n",
      "225/225 [==============================] - 0s 2ms/step - loss: 0.5485 - accuracy: 0.7847 - val_loss: 0.5108 - val_accuracy: 0.7960\n",
      "Epoch 50/1000\n",
      "225/225 [==============================] - 0s 2ms/step - loss: 0.5482 - accuracy: 0.7838 - val_loss: 0.5113 - val_accuracy: 0.7983\n",
      "Epoch 51/1000\n",
      "225/225 [==============================] - 0s 2ms/step - loss: 0.5471 - accuracy: 0.7845 - val_loss: 0.5057 - val_accuracy: 0.7999\n",
      "Epoch 52/1000\n",
      "225/225 [==============================] - 0s 2ms/step - loss: 0.5448 - accuracy: 0.7863 - val_loss: 0.5065 - val_accuracy: 0.7974\n",
      "Epoch 53/1000\n",
      "225/225 [==============================] - 0s 2ms/step - loss: 0.5447 - accuracy: 0.7855 - val_loss: 0.5048 - val_accuracy: 0.7997\n",
      "Epoch 54/1000\n",
      "225/225 [==============================] - 0s 2ms/step - loss: 0.5438 - accuracy: 0.7858 - val_loss: 0.5024 - val_accuracy: 0.8010\n",
      "Epoch 55/1000\n",
      "225/225 [==============================] - 0s 2ms/step - loss: 0.5435 - accuracy: 0.7874 - val_loss: 0.5023 - val_accuracy: 0.7997\n",
      "Epoch 56/1000\n",
      "225/225 [==============================] - 0s 2ms/step - loss: 0.5447 - accuracy: 0.7869 - val_loss: 0.5030 - val_accuracy: 0.7982\n",
      "Epoch 57/1000\n",
      "225/225 [==============================] - 0s 2ms/step - loss: 0.5394 - accuracy: 0.7879 - val_loss: 0.4999 - val_accuracy: 0.8019\n",
      "Epoch 58/1000\n",
      "225/225 [==============================] - 0s 2ms/step - loss: 0.5386 - accuracy: 0.7875 - val_loss: 0.4992 - val_accuracy: 0.8024\n",
      "Epoch 59/1000\n",
      "225/225 [==============================] - 0s 2ms/step - loss: 0.5397 - accuracy: 0.7879 - val_loss: 0.4989 - val_accuracy: 0.8040\n",
      "Epoch 60/1000\n",
      "225/225 [==============================] - 0s 2ms/step - loss: 0.5378 - accuracy: 0.7892 - val_loss: 0.5004 - val_accuracy: 0.8032\n",
      "Epoch 61/1000\n",
      "225/225 [==============================] - 0s 2ms/step - loss: 0.5349 - accuracy: 0.7893 - val_loss: 0.4961 - val_accuracy: 0.8045\n",
      "Epoch 62/1000\n",
      "225/225 [==============================] - 0s 2ms/step - loss: 0.5360 - accuracy: 0.7895 - val_loss: 0.4973 - val_accuracy: 0.8022\n",
      "Epoch 63/1000\n",
      "225/225 [==============================] - 0s 2ms/step - loss: 0.5369 - accuracy: 0.7903 - val_loss: 0.4957 - val_accuracy: 0.8033\n",
      "Epoch 64/1000\n",
      "225/225 [==============================] - 0s 2ms/step - loss: 0.5339 - accuracy: 0.7904 - val_loss: 0.4900 - val_accuracy: 0.8074\n",
      "Epoch 65/1000\n",
      "225/225 [==============================] - 1s 2ms/step - loss: 0.5346 - accuracy: 0.7900 - val_loss: 0.4919 - val_accuracy: 0.8039\n",
      "Epoch 66/1000\n",
      "225/225 [==============================] - 0s 2ms/step - loss: 0.5319 - accuracy: 0.7916 - val_loss: 0.4901 - val_accuracy: 0.8044\n",
      "Epoch 67/1000\n",
      "225/225 [==============================] - 0s 2ms/step - loss: 0.5303 - accuracy: 0.7909 - val_loss: 0.4887 - val_accuracy: 0.8070\n",
      "Epoch 68/1000\n",
      "225/225 [==============================] - 0s 2ms/step - loss: 0.5315 - accuracy: 0.7914 - val_loss: 0.4950 - val_accuracy: 0.8040\n",
      "Epoch 69/1000\n",
      "225/225 [==============================] - 0s 2ms/step - loss: 0.5297 - accuracy: 0.7915 - val_loss: 0.4916 - val_accuracy: 0.8050\n",
      "Epoch 70/1000\n",
      "225/225 [==============================] - 0s 2ms/step - loss: 0.5313 - accuracy: 0.7906 - val_loss: 0.4886 - val_accuracy: 0.8069\n",
      "Epoch 71/1000\n",
      "225/225 [==============================] - 0s 2ms/step - loss: 0.5292 - accuracy: 0.7921 - val_loss: 0.4857 - val_accuracy: 0.8096\n",
      "Epoch 72/1000\n",
      "225/225 [==============================] - 0s 2ms/step - loss: 0.5285 - accuracy: 0.7918 - val_loss: 0.4902 - val_accuracy: 0.8053\n",
      "Epoch 73/1000\n",
      "225/225 [==============================] - 0s 2ms/step - loss: 0.5266 - accuracy: 0.7944 - val_loss: 0.4820 - val_accuracy: 0.8101\n",
      "Epoch 74/1000\n",
      "225/225 [==============================] - 0s 2ms/step - loss: 0.5266 - accuracy: 0.7925 - val_loss: 0.4829 - val_accuracy: 0.8077\n",
      "Epoch 75/1000\n",
      "225/225 [==============================] - 0s 2ms/step - loss: 0.5263 - accuracy: 0.7926 - val_loss: 0.4850 - val_accuracy: 0.8095\n",
      "Epoch 76/1000\n",
      "225/225 [==============================] - 0s 2ms/step - loss: 0.5248 - accuracy: 0.7943 - val_loss: 0.4831 - val_accuracy: 0.8095\n",
      "Epoch 77/1000\n",
      "225/225 [==============================] - 0s 2ms/step - loss: 0.5252 - accuracy: 0.7938 - val_loss: 0.4828 - val_accuracy: 0.8092\n",
      "Epoch 78/1000\n",
      "225/225 [==============================] - 0s 2ms/step - loss: 0.5237 - accuracy: 0.7939 - val_loss: 0.4822 - val_accuracy: 0.8126\n",
      "Epoch 79/1000\n",
      "225/225 [==============================] - 0s 2ms/step - loss: 0.5243 - accuracy: 0.7946 - val_loss: 0.4796 - val_accuracy: 0.8139\n",
      "Epoch 80/1000\n",
      "225/225 [==============================] - 0s 2ms/step - loss: 0.5223 - accuracy: 0.7950 - val_loss: 0.4792 - val_accuracy: 0.8118\n",
      "Epoch 81/1000\n",
      "225/225 [==============================] - 0s 2ms/step - loss: 0.5198 - accuracy: 0.7958 - val_loss: 0.4782 - val_accuracy: 0.8118\n",
      "Epoch 82/1000\n",
      "225/225 [==============================] - 0s 2ms/step - loss: 0.5207 - accuracy: 0.7940 - val_loss: 0.4819 - val_accuracy: 0.8101\n",
      "Epoch 83/1000\n",
      "225/225 [==============================] - 0s 2ms/step - loss: 0.5194 - accuracy: 0.7955 - val_loss: 0.4738 - val_accuracy: 0.8132\n",
      "Epoch 84/1000\n",
      "225/225 [==============================] - 0s 2ms/step - loss: 0.5207 - accuracy: 0.7956 - val_loss: 0.4757 - val_accuracy: 0.8132\n",
      "Epoch 85/1000\n",
      "225/225 [==============================] - 0s 2ms/step - loss: 0.5211 - accuracy: 0.7957 - val_loss: 0.4730 - val_accuracy: 0.8147\n",
      "Epoch 86/1000\n",
      "225/225 [==============================] - 0s 2ms/step - loss: 0.5190 - accuracy: 0.7968 - val_loss: 0.4767 - val_accuracy: 0.8122\n",
      "Epoch 87/1000\n",
      "225/225 [==============================] - 0s 2ms/step - loss: 0.5198 - accuracy: 0.7954 - val_loss: 0.4756 - val_accuracy: 0.8124\n",
      "Epoch 88/1000\n",
      "225/225 [==============================] - 0s 2ms/step - loss: 0.5186 - accuracy: 0.7967 - val_loss: 0.4777 - val_accuracy: 0.8114\n",
      "Epoch 89/1000\n",
      "225/225 [==============================] - 0s 2ms/step - loss: 0.5171 - accuracy: 0.7968 - val_loss: 0.4725 - val_accuracy: 0.8148\n",
      "Epoch 90/1000\n",
      "225/225 [==============================] - 0s 2ms/step - loss: 0.5184 - accuracy: 0.7956 - val_loss: 0.4737 - val_accuracy: 0.8132\n",
      "Epoch 91/1000\n",
      "225/225 [==============================] - 0s 2ms/step - loss: 0.5169 - accuracy: 0.7983 - val_loss: 0.4717 - val_accuracy: 0.8156\n",
      "Epoch 92/1000\n",
      "225/225 [==============================] - 1s 2ms/step - loss: 0.5148 - accuracy: 0.7976 - val_loss: 0.4705 - val_accuracy: 0.8173\n",
      "Epoch 93/1000\n",
      "225/225 [==============================] - 0s 2ms/step - loss: 0.5175 - accuracy: 0.7974 - val_loss: 0.4704 - val_accuracy: 0.8172\n",
      "Epoch 94/1000\n",
      "225/225 [==============================] - 0s 2ms/step - loss: 0.5144 - accuracy: 0.7972 - val_loss: 0.4723 - val_accuracy: 0.8149\n",
      "Epoch 95/1000\n",
      "225/225 [==============================] - 0s 2ms/step - loss: 0.5153 - accuracy: 0.7982 - val_loss: 0.4708 - val_accuracy: 0.8141\n",
      "Epoch 96/1000\n",
      "225/225 [==============================] - 0s 2ms/step - loss: 0.5134 - accuracy: 0.7995 - val_loss: 0.4686 - val_accuracy: 0.8164\n",
      "Epoch 97/1000\n",
      "225/225 [==============================] - 0s 2ms/step - loss: 0.5146 - accuracy: 0.7989 - val_loss: 0.4711 - val_accuracy: 0.8163\n",
      "Epoch 98/1000\n",
      "225/225 [==============================] - 1s 2ms/step - loss: 0.5130 - accuracy: 0.7972 - val_loss: 0.4713 - val_accuracy: 0.8144\n",
      "Epoch 99/1000\n",
      "225/225 [==============================] - 0s 2ms/step - loss: 0.5131 - accuracy: 0.7983 - val_loss: 0.4707 - val_accuracy: 0.8138\n",
      "Epoch 100/1000\n",
      "225/225 [==============================] - 0s 2ms/step - loss: 0.5134 - accuracy: 0.7984 - val_loss: 0.4740 - val_accuracy: 0.8154\n",
      "Epoch 101/1000\n",
      "225/225 [==============================] - 0s 2ms/step - loss: 0.5113 - accuracy: 0.7992 - val_loss: 0.4710 - val_accuracy: 0.8145\n",
      "Epoch 102/1000\n",
      "225/225 [==============================] - 0s 2ms/step - loss: 0.5112 - accuracy: 0.7995 - val_loss: 0.4703 - val_accuracy: 0.8172\n",
      "Epoch 103/1000\n",
      "225/225 [==============================] - 0s 2ms/step - loss: 0.5098 - accuracy: 0.8008 - val_loss: 0.4698 - val_accuracy: 0.8165\n",
      "Epoch 104/1000\n",
      "225/225 [==============================] - 0s 2ms/step - loss: 0.5098 - accuracy: 0.7994 - val_loss: 0.4699 - val_accuracy: 0.8156\n",
      "Epoch 105/1000\n",
      "225/225 [==============================] - 0s 2ms/step - loss: 0.5091 - accuracy: 0.7999 - val_loss: 0.4680 - val_accuracy: 0.8202\n",
      "Epoch 106/1000\n",
      "225/225 [==============================] - 0s 2ms/step - loss: 0.5094 - accuracy: 0.8000 - val_loss: 0.4682 - val_accuracy: 0.8172\n",
      "Epoch 107/1000\n",
      "225/225 [==============================] - 0s 2ms/step - loss: 0.5100 - accuracy: 0.8000 - val_loss: 0.4651 - val_accuracy: 0.8175\n",
      "Epoch 108/1000\n",
      "225/225 [==============================] - 0s 2ms/step - loss: 0.5073 - accuracy: 0.8019 - val_loss: 0.4632 - val_accuracy: 0.8201\n",
      "Epoch 109/1000\n",
      "225/225 [==============================] - 0s 2ms/step - loss: 0.5060 - accuracy: 0.8008 - val_loss: 0.4675 - val_accuracy: 0.8190\n",
      "Epoch 110/1000\n",
      "225/225 [==============================] - 0s 2ms/step - loss: 0.5093 - accuracy: 0.8015 - val_loss: 0.4652 - val_accuracy: 0.8193\n",
      "Epoch 111/1000\n",
      "225/225 [==============================] - 0s 2ms/step - loss: 0.5071 - accuracy: 0.8013 - val_loss: 0.4641 - val_accuracy: 0.8195\n",
      "Epoch 112/1000\n",
      "225/225 [==============================] - 0s 2ms/step - loss: 0.5070 - accuracy: 0.8008 - val_loss: 0.4642 - val_accuracy: 0.8197\n",
      "Epoch 113/1000\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "225/225 [==============================] - 0s 2ms/step - loss: 0.5076 - accuracy: 0.8017 - val_loss: 0.4646 - val_accuracy: 0.8207\n",
      "Epoch 114/1000\n",
      "225/225 [==============================] - 0s 2ms/step - loss: 0.5066 - accuracy: 0.8029 - val_loss: 0.4643 - val_accuracy: 0.8228\n",
      "Epoch 115/1000\n",
      "225/225 [==============================] - 0s 2ms/step - loss: 0.5064 - accuracy: 0.8029 - val_loss: 0.4632 - val_accuracy: 0.8213\n",
      "Epoch 116/1000\n",
      "225/225 [==============================] - 0s 2ms/step - loss: 0.5046 - accuracy: 0.8021 - val_loss: 0.4622 - val_accuracy: 0.8209\n",
      "Epoch 117/1000\n",
      "225/225 [==============================] - 0s 2ms/step - loss: 0.5060 - accuracy: 0.8025 - val_loss: 0.4595 - val_accuracy: 0.8231\n",
      "Epoch 118/1000\n",
      "225/225 [==============================] - 0s 2ms/step - loss: 0.5048 - accuracy: 0.8029 - val_loss: 0.4591 - val_accuracy: 0.8223\n",
      "Epoch 119/1000\n",
      "225/225 [==============================] - 0s 2ms/step - loss: 0.5055 - accuracy: 0.8019 - val_loss: 0.4611 - val_accuracy: 0.8236\n",
      "Epoch 120/1000\n",
      "225/225 [==============================] - 0s 2ms/step - loss: 0.5045 - accuracy: 0.8022 - val_loss: 0.4663 - val_accuracy: 0.8191\n",
      "Epoch 121/1000\n",
      "225/225 [==============================] - 0s 2ms/step - loss: 0.5046 - accuracy: 0.8025 - val_loss: 0.4636 - val_accuracy: 0.8198\n",
      "Epoch 122/1000\n",
      "225/225 [==============================] - 0s 2ms/step - loss: 0.5030 - accuracy: 0.8037 - val_loss: 0.4605 - val_accuracy: 0.8218\n",
      "Epoch 123/1000\n",
      "225/225 [==============================] - 0s 2ms/step - loss: 0.5036 - accuracy: 0.8032 - val_loss: 0.4613 - val_accuracy: 0.8222\n",
      "Epoch 124/1000\n",
      "225/225 [==============================] - 0s 2ms/step - loss: 0.5063 - accuracy: 0.8024 - val_loss: 0.4637 - val_accuracy: 0.8196\n",
      "Epoch 125/1000\n",
      "225/225 [==============================] - 0s 2ms/step - loss: 0.5023 - accuracy: 0.8038 - val_loss: 0.4584 - val_accuracy: 0.8216\n",
      "Epoch 126/1000\n",
      "225/225 [==============================] - 0s 2ms/step - loss: 0.5021 - accuracy: 0.8045 - val_loss: 0.4586 - val_accuracy: 0.8257\n",
      "Epoch 127/1000\n",
      "225/225 [==============================] - 0s 2ms/step - loss: 0.5031 - accuracy: 0.8044 - val_loss: 0.4600 - val_accuracy: 0.8204\n",
      "Epoch 128/1000\n",
      "225/225 [==============================] - 0s 2ms/step - loss: 0.5018 - accuracy: 0.8043 - val_loss: 0.4598 - val_accuracy: 0.8222\n",
      "Epoch 129/1000\n",
      "225/225 [==============================] - 0s 2ms/step - loss: 0.5022 - accuracy: 0.8046 - val_loss: 0.4597 - val_accuracy: 0.8220\n",
      "Epoch 130/1000\n",
      "225/225 [==============================] - 0s 2ms/step - loss: 0.4983 - accuracy: 0.8040 - val_loss: 0.4582 - val_accuracy: 0.8241\n",
      "Epoch 131/1000\n",
      "225/225 [==============================] - 0s 2ms/step - loss: 0.5006 - accuracy: 0.8040 - val_loss: 0.4573 - val_accuracy: 0.8249\n",
      "Epoch 132/1000\n",
      "225/225 [==============================] - 0s 2ms/step - loss: 0.4989 - accuracy: 0.8054 - val_loss: 0.4566 - val_accuracy: 0.8267\n",
      "Epoch 133/1000\n",
      "225/225 [==============================] - 0s 2ms/step - loss: 0.5008 - accuracy: 0.8045 - val_loss: 0.4571 - val_accuracy: 0.8229\n",
      "Epoch 134/1000\n",
      "225/225 [==============================] - 0s 2ms/step - loss: 0.4997 - accuracy: 0.8058 - val_loss: 0.4584 - val_accuracy: 0.8218\n",
      "Epoch 135/1000\n",
      "225/225 [==============================] - 0s 2ms/step - loss: 0.4998 - accuracy: 0.8049 - val_loss: 0.4597 - val_accuracy: 0.8240\n",
      "Epoch 136/1000\n",
      "225/225 [==============================] - 0s 2ms/step - loss: 0.4991 - accuracy: 0.8052 - val_loss: 0.4565 - val_accuracy: 0.8254\n",
      "Epoch 137/1000\n",
      "225/225 [==============================] - 0s 2ms/step - loss: 0.4991 - accuracy: 0.8058 - val_loss: 0.4535 - val_accuracy: 0.8274\n",
      "Epoch 138/1000\n",
      "225/225 [==============================] - 0s 2ms/step - loss: 0.4968 - accuracy: 0.8063 - val_loss: 0.4548 - val_accuracy: 0.8237\n",
      "Epoch 139/1000\n",
      "225/225 [==============================] - 0s 2ms/step - loss: 0.4985 - accuracy: 0.8062 - val_loss: 0.4535 - val_accuracy: 0.8232\n",
      "Epoch 140/1000\n",
      "225/225 [==============================] - 0s 2ms/step - loss: 0.4964 - accuracy: 0.8056 - val_loss: 0.4543 - val_accuracy: 0.8251\n",
      "Epoch 141/1000\n",
      "225/225 [==============================] - 0s 2ms/step - loss: 0.4973 - accuracy: 0.8054 - val_loss: 0.4514 - val_accuracy: 0.8264\n",
      "Epoch 142/1000\n",
      "225/225 [==============================] - 0s 2ms/step - loss: 0.4972 - accuracy: 0.8059 - val_loss: 0.4520 - val_accuracy: 0.8275\n",
      "Epoch 143/1000\n",
      "225/225 [==============================] - 0s 2ms/step - loss: 0.4968 - accuracy: 0.8052 - val_loss: 0.4525 - val_accuracy: 0.8285\n",
      "Epoch 144/1000\n",
      "225/225 [==============================] - 0s 2ms/step - loss: 0.4985 - accuracy: 0.8062 - val_loss: 0.4528 - val_accuracy: 0.8245\n",
      "Epoch 145/1000\n",
      "225/225 [==============================] - 0s 2ms/step - loss: 0.4950 - accuracy: 0.8072 - val_loss: 0.4559 - val_accuracy: 0.8232\n",
      "Epoch 146/1000\n",
      "225/225 [==============================] - 0s 2ms/step - loss: 0.4955 - accuracy: 0.8067 - val_loss: 0.4521 - val_accuracy: 0.8267\n",
      "Epoch 147/1000\n",
      "225/225 [==============================] - 0s 2ms/step - loss: 0.4966 - accuracy: 0.8069 - val_loss: 0.4522 - val_accuracy: 0.8297\n",
      "Epoch 148/1000\n",
      "225/225 [==============================] - 0s 2ms/step - loss: 0.4957 - accuracy: 0.8065 - val_loss: 0.4495 - val_accuracy: 0.8279\n",
      "Epoch 149/1000\n",
      "225/225 [==============================] - 0s 2ms/step - loss: 0.4957 - accuracy: 0.8068 - val_loss: 0.4486 - val_accuracy: 0.8259\n",
      "Epoch 150/1000\n",
      "225/225 [==============================] - 1s 2ms/step - loss: 0.4960 - accuracy: 0.8060 - val_loss: 0.4531 - val_accuracy: 0.8253\n",
      "Epoch 151/1000\n",
      "225/225 [==============================] - 0s 2ms/step - loss: 0.4937 - accuracy: 0.8071 - val_loss: 0.4500 - val_accuracy: 0.8267\n",
      "Epoch 152/1000\n",
      "225/225 [==============================] - 0s 2ms/step - loss: 0.4929 - accuracy: 0.8087 - val_loss: 0.4498 - val_accuracy: 0.8243\n",
      "Epoch 153/1000\n",
      "225/225 [==============================] - 0s 2ms/step - loss: 0.4926 - accuracy: 0.8077 - val_loss: 0.4500 - val_accuracy: 0.8260\n",
      "Epoch 154/1000\n",
      "225/225 [==============================] - 0s 2ms/step - loss: 0.4926 - accuracy: 0.8076 - val_loss: 0.4506 - val_accuracy: 0.8275\n",
      "Epoch 155/1000\n",
      "225/225 [==============================] - 0s 2ms/step - loss: 0.4921 - accuracy: 0.8074 - val_loss: 0.4529 - val_accuracy: 0.8238\n",
      "Epoch 156/1000\n",
      "225/225 [==============================] - 0s 2ms/step - loss: 0.4926 - accuracy: 0.8083 - val_loss: 0.4516 - val_accuracy: 0.8262\n",
      "Epoch 157/1000\n",
      "225/225 [==============================] - 0s 2ms/step - loss: 0.4948 - accuracy: 0.8078 - val_loss: 0.4523 - val_accuracy: 0.8263\n",
      "Epoch 158/1000\n",
      "225/225 [==============================] - 0s 2ms/step - loss: 0.4926 - accuracy: 0.8080 - val_loss: 0.4511 - val_accuracy: 0.8275\n",
      "Epoch 159/1000\n",
      "225/225 [==============================] - 0s 2ms/step - loss: 0.4911 - accuracy: 0.8076 - val_loss: 0.4517 - val_accuracy: 0.8260\n",
      "Epoch 160/1000\n",
      "225/225 [==============================] - 0s 2ms/step - loss: 0.4912 - accuracy: 0.8081 - val_loss: 0.4531 - val_accuracy: 0.8263\n",
      "Epoch 161/1000\n",
      "225/225 [==============================] - 0s 2ms/step - loss: 0.4917 - accuracy: 0.8082 - val_loss: 0.4507 - val_accuracy: 0.8286\n",
      "Epoch 162/1000\n",
      "225/225 [==============================] - 0s 2ms/step - loss: 0.4924 - accuracy: 0.8080 - val_loss: 0.4493 - val_accuracy: 0.8278\n",
      "Epoch 163/1000\n",
      "225/225 [==============================] - 0s 2ms/step - loss: 0.4907 - accuracy: 0.8084 - val_loss: 0.4460 - val_accuracy: 0.8307\n",
      "Epoch 164/1000\n",
      "225/225 [==============================] - 0s 2ms/step - loss: 0.4899 - accuracy: 0.8093 - val_loss: 0.4470 - val_accuracy: 0.8283\n",
      "Epoch 165/1000\n",
      "225/225 [==============================] - 0s 2ms/step - loss: 0.4914 - accuracy: 0.8090 - val_loss: 0.4490 - val_accuracy: 0.8275\n",
      "Epoch 166/1000\n",
      "225/225 [==============================] - 0s 2ms/step - loss: 0.4919 - accuracy: 0.8088 - val_loss: 0.4513 - val_accuracy: 0.8247\n",
      "Epoch 167/1000\n",
      "225/225 [==============================] - 1s 2ms/step - loss: 0.4922 - accuracy: 0.8079 - val_loss: 0.4461 - val_accuracy: 0.8282\n",
      "Epoch 168/1000\n",
      "225/225 [==============================] - 0s 2ms/step - loss: 0.4896 - accuracy: 0.8087 - val_loss: 0.4466 - val_accuracy: 0.8312\n",
      "Epoch 169/1000\n",
      "225/225 [==============================] - 0s 2ms/step - loss: 0.4919 - accuracy: 0.8090 - val_loss: 0.4451 - val_accuracy: 0.8291\n",
      "Epoch 170/1000\n",
      "225/225 [==============================] - 0s 2ms/step - loss: 0.4890 - accuracy: 0.8086 - val_loss: 0.4475 - val_accuracy: 0.8265\n",
      "Epoch 171/1000\n",
      "225/225 [==============================] - 0s 2ms/step - loss: 0.4897 - accuracy: 0.8092 - val_loss: 0.4476 - val_accuracy: 0.8281\n",
      "Epoch 172/1000\n",
      "225/225 [==============================] - 0s 2ms/step - loss: 0.4887 - accuracy: 0.8104 - val_loss: 0.4442 - val_accuracy: 0.8315\n",
      "Epoch 173/1000\n",
      "225/225 [==============================] - 0s 2ms/step - loss: 0.4914 - accuracy: 0.8089 - val_loss: 0.4441 - val_accuracy: 0.8322\n",
      "Epoch 174/1000\n",
      "225/225 [==============================] - 0s 2ms/step - loss: 0.4880 - accuracy: 0.8107 - val_loss: 0.4487 - val_accuracy: 0.8286\n",
      "Epoch 175/1000\n",
      "225/225 [==============================] - 0s 2ms/step - loss: 0.4859 - accuracy: 0.8105 - val_loss: 0.4449 - val_accuracy: 0.8305\n",
      "Epoch 176/1000\n",
      "225/225 [==============================] - 0s 2ms/step - loss: 0.4879 - accuracy: 0.8093 - val_loss: 0.4452 - val_accuracy: 0.8288\n",
      "Epoch 177/1000\n",
      "225/225 [==============================] - 0s 2ms/step - loss: 0.4884 - accuracy: 0.8093 - val_loss: 0.4464 - val_accuracy: 0.8286\n",
      "Epoch 178/1000\n",
      "225/225 [==============================] - 0s 2ms/step - loss: 0.4875 - accuracy: 0.8100 - val_loss: 0.4452 - val_accuracy: 0.8278\n",
      "Epoch 179/1000\n",
      "225/225 [==============================] - 0s 2ms/step - loss: 0.4891 - accuracy: 0.8098 - val_loss: 0.4462 - val_accuracy: 0.8283\n",
      "Epoch 180/1000\n",
      "225/225 [==============================] - 0s 2ms/step - loss: 0.4858 - accuracy: 0.8104 - val_loss: 0.4462 - val_accuracy: 0.8270\n",
      "Epoch 181/1000\n",
      "225/225 [==============================] - 0s 2ms/step - loss: 0.4867 - accuracy: 0.8098 - val_loss: 0.4484 - val_accuracy: 0.8248\n",
      "Epoch 182/1000\n",
      "225/225 [==============================] - 0s 2ms/step - loss: 0.4870 - accuracy: 0.8110 - val_loss: 0.4449 - val_accuracy: 0.8291\n",
      "Epoch 183/1000\n",
      "225/225 [==============================] - 0s 2ms/step - loss: 0.4868 - accuracy: 0.8106 - val_loss: 0.4419 - val_accuracy: 0.8293\n",
      "Epoch 184/1000\n",
      "225/225 [==============================] - 0s 2ms/step - loss: 0.4882 - accuracy: 0.8096 - val_loss: 0.4443 - val_accuracy: 0.8295\n",
      "Epoch 185/1000\n",
      "225/225 [==============================] - 0s 2ms/step - loss: 0.4869 - accuracy: 0.8108 - val_loss: 0.4433 - val_accuracy: 0.8314\n",
      "Epoch 186/1000\n",
      "225/225 [==============================] - 0s 2ms/step - loss: 0.4860 - accuracy: 0.8105 - val_loss: 0.4445 - val_accuracy: 0.8310\n",
      "Epoch 187/1000\n",
      "225/225 [==============================] - 0s 2ms/step - loss: 0.4858 - accuracy: 0.8105 - val_loss: 0.4440 - val_accuracy: 0.8304\n",
      "Epoch 188/1000\n",
      "225/225 [==============================] - 0s 2ms/step - loss: 0.4867 - accuracy: 0.8106 - val_loss: 0.4404 - val_accuracy: 0.8321\n",
      "Epoch 189/1000\n",
      "225/225 [==============================] - 0s 2ms/step - loss: 0.4850 - accuracy: 0.8122 - val_loss: 0.4404 - val_accuracy: 0.8331\n",
      "Epoch 190/1000\n",
      "225/225 [==============================] - 0s 2ms/step - loss: 0.4843 - accuracy: 0.8117 - val_loss: 0.4422 - val_accuracy: 0.8301\n",
      "Epoch 191/1000\n",
      "225/225 [==============================] - 0s 2ms/step - loss: 0.4854 - accuracy: 0.8110 - val_loss: 0.4410 - val_accuracy: 0.8325\n",
      "Epoch 192/1000\n",
      "225/225 [==============================] - 0s 2ms/step - loss: 0.4848 - accuracy: 0.8114 - val_loss: 0.4424 - val_accuracy: 0.8305\n",
      "Epoch 193/1000\n",
      "225/225 [==============================] - 0s 2ms/step - loss: 0.4837 - accuracy: 0.8124 - val_loss: 0.4369 - val_accuracy: 0.8319\n",
      "Epoch 194/1000\n",
      "225/225 [==============================] - 0s 2ms/step - loss: 0.4857 - accuracy: 0.8108 - val_loss: 0.4426 - val_accuracy: 0.8293\n",
      "Epoch 195/1000\n",
      "225/225 [==============================] - 0s 2ms/step - loss: 0.4858 - accuracy: 0.8113 - val_loss: 0.4425 - val_accuracy: 0.8297\n",
      "Epoch 196/1000\n",
      "225/225 [==============================] - 0s 2ms/step - loss: 0.4834 - accuracy: 0.8114 - val_loss: 0.4405 - val_accuracy: 0.8323\n",
      "Epoch 197/1000\n",
      "225/225 [==============================] - 0s 2ms/step - loss: 0.4850 - accuracy: 0.8105 - val_loss: 0.4420 - val_accuracy: 0.8319\n",
      "Epoch 198/1000\n",
      "225/225 [==============================] - 0s 2ms/step - loss: 0.4872 - accuracy: 0.8106 - val_loss: 0.4415 - val_accuracy: 0.8333\n",
      "Epoch 199/1000\n",
      "225/225 [==============================] - 0s 2ms/step - loss: 0.4828 - accuracy: 0.8125 - val_loss: 0.4449 - val_accuracy: 0.8324\n",
      "Epoch 200/1000\n",
      "225/225 [==============================] - 0s 2ms/step - loss: 0.4861 - accuracy: 0.8100 - val_loss: 0.4415 - val_accuracy: 0.8304\n",
      "Epoch 201/1000\n",
      "225/225 [==============================] - 0s 2ms/step - loss: 0.4853 - accuracy: 0.8095 - val_loss: 0.4449 - val_accuracy: 0.8307\n",
      "Epoch 202/1000\n",
      "225/225 [==============================] - 1s 2ms/step - loss: 0.4853 - accuracy: 0.8114 - val_loss: 0.4454 - val_accuracy: 0.8307\n",
      "Epoch 203/1000\n",
      "225/225 [==============================] - 1s 2ms/step - loss: 0.4842 - accuracy: 0.8107 - val_loss: 0.4403 - val_accuracy: 0.8332\n",
      "Epoch 204/1000\n",
      "225/225 [==============================] - 0s 2ms/step - loss: 0.4812 - accuracy: 0.8123 - val_loss: 0.4426 - val_accuracy: 0.8329\n",
      "Epoch 205/1000\n",
      "225/225 [==============================] - 0s 2ms/step - loss: 0.4833 - accuracy: 0.8132 - val_loss: 0.4393 - val_accuracy: 0.8299\n",
      "Epoch 206/1000\n",
      "225/225 [==============================] - 0s 2ms/step - loss: 0.4806 - accuracy: 0.8131 - val_loss: 0.4405 - val_accuracy: 0.8335\n",
      "Epoch 207/1000\n",
      "225/225 [==============================] - 0s 2ms/step - loss: 0.4824 - accuracy: 0.8113 - val_loss: 0.4422 - val_accuracy: 0.8319\n",
      "Epoch 208/1000\n",
      "225/225 [==============================] - 0s 2ms/step - loss: 0.4844 - accuracy: 0.8121 - val_loss: 0.4406 - val_accuracy: 0.8336\n",
      "Epoch 209/1000\n",
      "225/225 [==============================] - 0s 2ms/step - loss: 0.4833 - accuracy: 0.8134 - val_loss: 0.4389 - val_accuracy: 0.8328\n",
      "Epoch 210/1000\n",
      "225/225 [==============================] - 0s 2ms/step - loss: 0.4806 - accuracy: 0.8146 - val_loss: 0.4416 - val_accuracy: 0.8325\n",
      "Epoch 211/1000\n",
      "225/225 [==============================] - 0s 2ms/step - loss: 0.4804 - accuracy: 0.8137 - val_loss: 0.4419 - val_accuracy: 0.8311\n",
      "Epoch 212/1000\n",
      "225/225 [==============================] - 0s 2ms/step - loss: 0.4814 - accuracy: 0.8122 - val_loss: 0.4393 - val_accuracy: 0.8303\n",
      "Epoch 213/1000\n",
      "225/225 [==============================] - 0s 2ms/step - loss: 0.4824 - accuracy: 0.8125 - val_loss: 0.4375 - val_accuracy: 0.8339\n",
      "Epoch 214/1000\n",
      "225/225 [==============================] - 0s 2ms/step - loss: 0.4849 - accuracy: 0.8116 - val_loss: 0.4401 - val_accuracy: 0.8326\n",
      "Epoch 215/1000\n",
      "225/225 [==============================] - 0s 2ms/step - loss: 0.4815 - accuracy: 0.8141 - val_loss: 0.4370 - val_accuracy: 0.8314\n",
      "Epoch 216/1000\n",
      "225/225 [==============================] - 0s 2ms/step - loss: 0.4794 - accuracy: 0.8132 - val_loss: 0.4405 - val_accuracy: 0.8330\n",
      "Epoch 217/1000\n",
      "225/225 [==============================] - 0s 2ms/step - loss: 0.4795 - accuracy: 0.8135 - val_loss: 0.4420 - val_accuracy: 0.8302\n",
      "Epoch 218/1000\n",
      "225/225 [==============================] - 0s 2ms/step - loss: 0.4817 - accuracy: 0.8126 - val_loss: 0.4399 - val_accuracy: 0.8304\n",
      "Epoch 219/1000\n",
      "225/225 [==============================] - 0s 2ms/step - loss: 0.4788 - accuracy: 0.8142 - val_loss: 0.4402 - val_accuracy: 0.8341\n",
      "Epoch 220/1000\n",
      "225/225 [==============================] - 0s 2ms/step - loss: 0.4791 - accuracy: 0.8144 - val_loss: 0.4359 - val_accuracy: 0.8360\n",
      "Epoch 221/1000\n",
      "225/225 [==============================] - 0s 2ms/step - loss: 0.4830 - accuracy: 0.8121 - val_loss: 0.4356 - val_accuracy: 0.8367\n",
      "Epoch 222/1000\n",
      "225/225 [==============================] - 0s 2ms/step - loss: 0.4794 - accuracy: 0.8138 - val_loss: 0.4353 - val_accuracy: 0.8330\n",
      "Epoch 223/1000\n",
      "225/225 [==============================] - 0s 2ms/step - loss: 0.4795 - accuracy: 0.8151 - val_loss: 0.4341 - val_accuracy: 0.8343\n",
      "Epoch 224/1000\n",
      "225/225 [==============================] - 0s 2ms/step - loss: 0.4783 - accuracy: 0.8142 - val_loss: 0.4351 - val_accuracy: 0.8370\n",
      "Epoch 225/1000\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "225/225 [==============================] - 0s 2ms/step - loss: 0.4804 - accuracy: 0.8131 - val_loss: 0.4343 - val_accuracy: 0.8378\n",
      "Epoch 226/1000\n",
      "225/225 [==============================] - 0s 2ms/step - loss: 0.4785 - accuracy: 0.8147 - val_loss: 0.4364 - val_accuracy: 0.8361\n",
      "Epoch 227/1000\n",
      "225/225 [==============================] - 0s 2ms/step - loss: 0.4804 - accuracy: 0.8135 - val_loss: 0.4362 - val_accuracy: 0.8340\n",
      "Epoch 228/1000\n",
      "225/225 [==============================] - 0s 2ms/step - loss: 0.4782 - accuracy: 0.8135 - val_loss: 0.4363 - val_accuracy: 0.8348\n",
      "Epoch 229/1000\n",
      "225/225 [==============================] - 0s 2ms/step - loss: 0.4796 - accuracy: 0.8142 - val_loss: 0.4341 - val_accuracy: 0.8343\n",
      "Epoch 230/1000\n",
      "225/225 [==============================] - 0s 2ms/step - loss: 0.4793 - accuracy: 0.8147 - val_loss: 0.4369 - val_accuracy: 0.8331\n",
      "Epoch 231/1000\n",
      "225/225 [==============================] - 0s 2ms/step - loss: 0.4782 - accuracy: 0.8143 - val_loss: 0.4354 - val_accuracy: 0.8340\n",
      "Epoch 232/1000\n",
      "225/225 [==============================] - 0s 2ms/step - loss: 0.4794 - accuracy: 0.8140 - val_loss: 0.4375 - val_accuracy: 0.8342\n",
      "Epoch 233/1000\n",
      "225/225 [==============================] - 0s 2ms/step - loss: 0.4812 - accuracy: 0.8137 - val_loss: 0.4375 - val_accuracy: 0.8361\n",
      "Epoch 234/1000\n",
      "225/225 [==============================] - 0s 2ms/step - loss: 0.4777 - accuracy: 0.8151 - val_loss: 0.4350 - val_accuracy: 0.8351\n",
      "Epoch 235/1000\n",
      "225/225 [==============================] - 1s 2ms/step - loss: 0.4777 - accuracy: 0.8137 - val_loss: 0.4357 - val_accuracy: 0.8334\n",
      "Epoch 236/1000\n",
      "225/225 [==============================] - 0s 2ms/step - loss: 0.4773 - accuracy: 0.8151 - val_loss: 0.4365 - val_accuracy: 0.8347\n",
      "Epoch 237/1000\n",
      "225/225 [==============================] - 0s 2ms/step - loss: 0.4794 - accuracy: 0.8141 - val_loss: 0.4344 - val_accuracy: 0.8380\n",
      "Epoch 238/1000\n",
      "225/225 [==============================] - 0s 2ms/step - loss: 0.4779 - accuracy: 0.8146 - val_loss: 0.4339 - val_accuracy: 0.8366\n",
      "Epoch 239/1000\n",
      "225/225 [==============================] - 0s 2ms/step - loss: 0.4773 - accuracy: 0.8150 - val_loss: 0.4354 - val_accuracy: 0.8358\n",
      "Epoch 240/1000\n",
      "225/225 [==============================] - 0s 2ms/step - loss: 0.4770 - accuracy: 0.8152 - val_loss: 0.4345 - val_accuracy: 0.8346\n",
      "Epoch 241/1000\n",
      "225/225 [==============================] - 0s 2ms/step - loss: 0.4769 - accuracy: 0.8155 - val_loss: 0.4365 - val_accuracy: 0.8329\n",
      "Epoch 242/1000\n",
      "225/225 [==============================] - 0s 2ms/step - loss: 0.4808 - accuracy: 0.8137 - val_loss: 0.4361 - val_accuracy: 0.8332\n",
      "Epoch 243/1000\n",
      "225/225 [==============================] - 0s 2ms/step - loss: 0.4774 - accuracy: 0.8146 - val_loss: 0.4333 - val_accuracy: 0.8372\n",
      "Epoch 244/1000\n",
      "225/225 [==============================] - 0s 2ms/step - loss: 0.4774 - accuracy: 0.8158 - val_loss: 0.4372 - val_accuracy: 0.8339\n",
      "Epoch 245/1000\n",
      "225/225 [==============================] - 0s 2ms/step - loss: 0.4771 - accuracy: 0.8147 - val_loss: 0.4340 - val_accuracy: 0.8380\n",
      "Epoch 246/1000\n",
      "225/225 [==============================] - 0s 2ms/step - loss: 0.4762 - accuracy: 0.8162 - val_loss: 0.4312 - val_accuracy: 0.8369\n",
      "Epoch 247/1000\n",
      "225/225 [==============================] - 0s 2ms/step - loss: 0.4780 - accuracy: 0.8150 - val_loss: 0.4324 - val_accuracy: 0.8375\n",
      "Epoch 248/1000\n",
      "225/225 [==============================] - 0s 2ms/step - loss: 0.4753 - accuracy: 0.8158 - val_loss: 0.4346 - val_accuracy: 0.8365\n",
      "Epoch 249/1000\n",
      "225/225 [==============================] - 0s 2ms/step - loss: 0.4749 - accuracy: 0.8160 - val_loss: 0.4344 - val_accuracy: 0.8366\n",
      "Epoch 250/1000\n",
      "225/225 [==============================] - 0s 2ms/step - loss: 0.4758 - accuracy: 0.8139 - val_loss: 0.4319 - val_accuracy: 0.8377\n",
      "Epoch 251/1000\n",
      "225/225 [==============================] - 0s 2ms/step - loss: 0.4771 - accuracy: 0.8154 - val_loss: 0.4327 - val_accuracy: 0.8364\n",
      "Epoch 252/1000\n",
      "225/225 [==============================] - 0s 2ms/step - loss: 0.4765 - accuracy: 0.8150 - val_loss: 0.4322 - val_accuracy: 0.8380\n",
      "Epoch 253/1000\n",
      "225/225 [==============================] - 0s 2ms/step - loss: 0.4749 - accuracy: 0.8150 - val_loss: 0.4318 - val_accuracy: 0.8373\n",
      "Epoch 254/1000\n",
      "225/225 [==============================] - 0s 2ms/step - loss: 0.4745 - accuracy: 0.8162 - val_loss: 0.4315 - val_accuracy: 0.8384\n",
      "Epoch 255/1000\n",
      "225/225 [==============================] - 0s 2ms/step - loss: 0.4779 - accuracy: 0.8156 - val_loss: 0.4327 - val_accuracy: 0.8373\n",
      "Epoch 256/1000\n",
      "225/225 [==============================] - 0s 2ms/step - loss: 0.4757 - accuracy: 0.8148 - val_loss: 0.4309 - val_accuracy: 0.8362\n",
      "Epoch 257/1000\n",
      "225/225 [==============================] - 0s 2ms/step - loss: 0.4775 - accuracy: 0.8149 - val_loss: 0.4324 - val_accuracy: 0.8371\n",
      "Epoch 258/1000\n",
      "225/225 [==============================] - 0s 2ms/step - loss: 0.4761 - accuracy: 0.8149 - val_loss: 0.4348 - val_accuracy: 0.8364\n",
      "Epoch 259/1000\n",
      "225/225 [==============================] - 0s 2ms/step - loss: 0.4743 - accuracy: 0.8171 - val_loss: 0.4332 - val_accuracy: 0.8370\n",
      "Epoch 260/1000\n",
      "225/225 [==============================] - 1s 2ms/step - loss: 0.4757 - accuracy: 0.8155 - val_loss: 0.4325 - val_accuracy: 0.8382\n",
      "Epoch 261/1000\n",
      "225/225 [==============================] - 0s 2ms/step - loss: 0.4736 - accuracy: 0.8166 - val_loss: 0.4321 - val_accuracy: 0.8386\n",
      "Epoch 262/1000\n",
      "225/225 [==============================] - 0s 2ms/step - loss: 0.4744 - accuracy: 0.8157 - val_loss: 0.4314 - val_accuracy: 0.8387\n",
      "Epoch 263/1000\n",
      "225/225 [==============================] - 0s 2ms/step - loss: 0.4731 - accuracy: 0.8155 - val_loss: 0.4305 - val_accuracy: 0.8371\n",
      "Epoch 264/1000\n",
      "225/225 [==============================] - 0s 2ms/step - loss: 0.4740 - accuracy: 0.8164 - val_loss: 0.4314 - val_accuracy: 0.8382\n",
      "Epoch 265/1000\n",
      "225/225 [==============================] - 0s 2ms/step - loss: 0.4740 - accuracy: 0.8172 - val_loss: 0.4307 - val_accuracy: 0.8383\n",
      "Epoch 266/1000\n",
      "225/225 [==============================] - 0s 2ms/step - loss: 0.4757 - accuracy: 0.8160 - val_loss: 0.4293 - val_accuracy: 0.8401\n",
      "Epoch 267/1000\n",
      "225/225 [==============================] - 0s 2ms/step - loss: 0.4738 - accuracy: 0.8169 - val_loss: 0.4312 - val_accuracy: 0.8377\n",
      "Epoch 268/1000\n",
      "225/225 [==============================] - 0s 2ms/step - loss: 0.4763 - accuracy: 0.8158 - val_loss: 0.4306 - val_accuracy: 0.8376\n",
      "Epoch 269/1000\n",
      "225/225 [==============================] - 1s 2ms/step - loss: 0.4739 - accuracy: 0.8165 - val_loss: 0.4316 - val_accuracy: 0.8383\n",
      "Epoch 270/1000\n",
      "225/225 [==============================] - 0s 2ms/step - loss: 0.4725 - accuracy: 0.8166 - val_loss: 0.4288 - val_accuracy: 0.8391\n",
      "Epoch 271/1000\n",
      "225/225 [==============================] - 0s 2ms/step - loss: 0.4741 - accuracy: 0.8165 - val_loss: 0.4331 - val_accuracy: 0.8368\n",
      "Epoch 272/1000\n",
      "225/225 [==============================] - 0s 2ms/step - loss: 0.4748 - accuracy: 0.8154 - val_loss: 0.4328 - val_accuracy: 0.8377\n",
      "Epoch 273/1000\n",
      "225/225 [==============================] - 0s 2ms/step - loss: 0.4731 - accuracy: 0.8156 - val_loss: 0.4290 - val_accuracy: 0.8402\n",
      "Epoch 274/1000\n",
      "225/225 [==============================] - 0s 2ms/step - loss: 0.4737 - accuracy: 0.8158 - val_loss: 0.4331 - val_accuracy: 0.8352\n",
      "Epoch 275/1000\n",
      "225/225 [==============================] - 0s 2ms/step - loss: 0.4725 - accuracy: 0.8180 - val_loss: 0.4301 - val_accuracy: 0.8391\n",
      "Epoch 276/1000\n",
      "225/225 [==============================] - 0s 2ms/step - loss: 0.4734 - accuracy: 0.8162 - val_loss: 0.4303 - val_accuracy: 0.8357\n",
      "Epoch 277/1000\n",
      "225/225 [==============================] - 0s 2ms/step - loss: 0.4729 - accuracy: 0.8162 - val_loss: 0.4302 - val_accuracy: 0.8376\n",
      "Epoch 278/1000\n",
      "225/225 [==============================] - 0s 2ms/step - loss: 0.4713 - accuracy: 0.8179 - val_loss: 0.4276 - val_accuracy: 0.8372\n",
      "Epoch 279/1000\n",
      "225/225 [==============================] - 0s 2ms/step - loss: 0.4734 - accuracy: 0.8164 - val_loss: 0.4292 - val_accuracy: 0.8371\n",
      "Epoch 280/1000\n",
      "225/225 [==============================] - 0s 2ms/step - loss: 0.4748 - accuracy: 0.8164 - val_loss: 0.4266 - val_accuracy: 0.8366\n",
      "Epoch 281/1000\n",
      "225/225 [==============================] - 0s 2ms/step - loss: 0.4725 - accuracy: 0.8174 - val_loss: 0.4278 - val_accuracy: 0.8394\n",
      "Epoch 282/1000\n",
      "225/225 [==============================] - 0s 2ms/step - loss: 0.4744 - accuracy: 0.8167 - val_loss: 0.4286 - val_accuracy: 0.8369\n",
      "Epoch 283/1000\n",
      "225/225 [==============================] - 0s 2ms/step - loss: 0.4725 - accuracy: 0.8170 - val_loss: 0.4298 - val_accuracy: 0.8364\n",
      "Epoch 284/1000\n",
      "225/225 [==============================] - 0s 2ms/step - loss: 0.4731 - accuracy: 0.8170 - val_loss: 0.4300 - val_accuracy: 0.8391\n",
      "Epoch 285/1000\n",
      "225/225 [==============================] - 0s 2ms/step - loss: 0.4716 - accuracy: 0.8173 - val_loss: 0.4283 - val_accuracy: 0.8387\n",
      "Epoch 286/1000\n",
      "225/225 [==============================] - 0s 2ms/step - loss: 0.4714 - accuracy: 0.8170 - val_loss: 0.4274 - val_accuracy: 0.8369\n",
      "Epoch 287/1000\n",
      "225/225 [==============================] - 0s 2ms/step - loss: 0.4724 - accuracy: 0.8167 - val_loss: 0.4260 - val_accuracy: 0.8407\n",
      "Epoch 288/1000\n",
      "225/225 [==============================] - 0s 2ms/step - loss: 0.4704 - accuracy: 0.8178 - val_loss: 0.4267 - val_accuracy: 0.8387\n",
      "Epoch 289/1000\n",
      "225/225 [==============================] - 0s 2ms/step - loss: 0.4719 - accuracy: 0.8173 - val_loss: 0.4270 - val_accuracy: 0.8378\n",
      "Epoch 290/1000\n",
      "225/225 [==============================] - 0s 2ms/step - loss: 0.4733 - accuracy: 0.8169 - val_loss: 0.4274 - val_accuracy: 0.8387\n",
      "Epoch 291/1000\n",
      "225/225 [==============================] - 0s 2ms/step - loss: 0.4727 - accuracy: 0.8170 - val_loss: 0.4288 - val_accuracy: 0.8383\n",
      "Epoch 292/1000\n",
      "225/225 [==============================] - 0s 2ms/step - loss: 0.4728 - accuracy: 0.8171 - val_loss: 0.4288 - val_accuracy: 0.8365\n",
      "Epoch 293/1000\n",
      "225/225 [==============================] - 0s 2ms/step - loss: 0.4724 - accuracy: 0.8168 - val_loss: 0.4285 - val_accuracy: 0.8392\n",
      "Epoch 294/1000\n",
      "225/225 [==============================] - 0s 2ms/step - loss: 0.4723 - accuracy: 0.8169 - val_loss: 0.4286 - val_accuracy: 0.8389\n",
      "Epoch 295/1000\n",
      "225/225 [==============================] - 0s 2ms/step - loss: 0.4717 - accuracy: 0.8168 - val_loss: 0.4281 - val_accuracy: 0.8394\n",
      "Epoch 296/1000\n",
      "225/225 [==============================] - 0s 2ms/step - loss: 0.4712 - accuracy: 0.8178 - val_loss: 0.4255 - val_accuracy: 0.8408\n",
      "Epoch 297/1000\n",
      "225/225 [==============================] - 0s 2ms/step - loss: 0.4730 - accuracy: 0.8156 - val_loss: 0.4295 - val_accuracy: 0.8399\n",
      "Epoch 298/1000\n",
      "225/225 [==============================] - 0s 2ms/step - loss: 0.4702 - accuracy: 0.8189 - val_loss: 0.4275 - val_accuracy: 0.8392\n",
      "Epoch 299/1000\n",
      "225/225 [==============================] - 0s 2ms/step - loss: 0.4711 - accuracy: 0.8181 - val_loss: 0.4281 - val_accuracy: 0.8389\n",
      "Epoch 300/1000\n",
      "225/225 [==============================] - 0s 2ms/step - loss: 0.4715 - accuracy: 0.8180 - val_loss: 0.4281 - val_accuracy: 0.8398\n",
      "Epoch 301/1000\n",
      "225/225 [==============================] - 0s 2ms/step - loss: 0.4705 - accuracy: 0.8180 - val_loss: 0.4286 - val_accuracy: 0.8377\n",
      "Epoch 302/1000\n",
      "225/225 [==============================] - 0s 2ms/step - loss: 0.4706 - accuracy: 0.8175 - val_loss: 0.4282 - val_accuracy: 0.8406\n",
      "Epoch 303/1000\n",
      "225/225 [==============================] - 1s 2ms/step - loss: 0.4721 - accuracy: 0.8183 - val_loss: 0.4267 - val_accuracy: 0.8411\n",
      "Epoch 304/1000\n",
      "225/225 [==============================] - 0s 2ms/step - loss: 0.4680 - accuracy: 0.8184 - val_loss: 0.4258 - val_accuracy: 0.8406\n",
      "Epoch 305/1000\n",
      "225/225 [==============================] - 0s 2ms/step - loss: 0.4691 - accuracy: 0.8194 - val_loss: 0.4256 - val_accuracy: 0.8400\n",
      "Epoch 306/1000\n",
      "225/225 [==============================] - 0s 2ms/step - loss: 0.4712 - accuracy: 0.8177 - val_loss: 0.4252 - val_accuracy: 0.8411\n",
      "Epoch 307/1000\n",
      "225/225 [==============================] - 0s 2ms/step - loss: 0.4674 - accuracy: 0.8196 - val_loss: 0.4258 - val_accuracy: 0.8413\n",
      "Epoch 308/1000\n",
      "225/225 [==============================] - 0s 2ms/step - loss: 0.4708 - accuracy: 0.8177 - val_loss: 0.4264 - val_accuracy: 0.8397\n",
      "Epoch 309/1000\n",
      "225/225 [==============================] - 0s 2ms/step - loss: 0.4712 - accuracy: 0.8182 - val_loss: 0.4299 - val_accuracy: 0.8401\n",
      "Epoch 310/1000\n",
      "225/225 [==============================] - 0s 2ms/step - loss: 0.4702 - accuracy: 0.8201 - val_loss: 0.4269 - val_accuracy: 0.8397\n",
      "Epoch 311/1000\n",
      "225/225 [==============================] - 0s 2ms/step - loss: 0.4706 - accuracy: 0.8180 - val_loss: 0.4274 - val_accuracy: 0.8377\n",
      "Epoch 312/1000\n",
      "225/225 [==============================] - 0s 2ms/step - loss: 0.4695 - accuracy: 0.8187 - val_loss: 0.4307 - val_accuracy: 0.8386\n",
      "Epoch 313/1000\n",
      "225/225 [==============================] - 0s 2ms/step - loss: 0.4703 - accuracy: 0.8182 - val_loss: 0.4258 - val_accuracy: 0.8409\n",
      "Epoch 314/1000\n",
      "225/225 [==============================] - 0s 2ms/step - loss: 0.4686 - accuracy: 0.8188 - val_loss: 0.4238 - val_accuracy: 0.8394\n",
      "Epoch 315/1000\n",
      "225/225 [==============================] - 0s 2ms/step - loss: 0.4667 - accuracy: 0.8199 - val_loss: 0.4267 - val_accuracy: 0.8373\n",
      "Epoch 316/1000\n",
      "225/225 [==============================] - 0s 2ms/step - loss: 0.4695 - accuracy: 0.8175 - val_loss: 0.4253 - val_accuracy: 0.8406\n",
      "Epoch 317/1000\n",
      "225/225 [==============================] - 0s 2ms/step - loss: 0.4703 - accuracy: 0.8176 - val_loss: 0.4255 - val_accuracy: 0.8409\n",
      "Epoch 318/1000\n",
      "225/225 [==============================] - 0s 2ms/step - loss: 0.4693 - accuracy: 0.8175 - val_loss: 0.4228 - val_accuracy: 0.8412\n",
      "Epoch 319/1000\n",
      "225/225 [==============================] - 0s 2ms/step - loss: 0.4685 - accuracy: 0.8176 - val_loss: 0.4239 - val_accuracy: 0.8412\n",
      "Epoch 320/1000\n",
      "225/225 [==============================] - 0s 2ms/step - loss: 0.4678 - accuracy: 0.8198 - val_loss: 0.4252 - val_accuracy: 0.8422\n",
      "Epoch 321/1000\n",
      "225/225 [==============================] - 0s 2ms/step - loss: 0.4671 - accuracy: 0.8192 - val_loss: 0.4272 - val_accuracy: 0.8401\n",
      "Epoch 322/1000\n",
      "225/225 [==============================] - 1s 2ms/step - loss: 0.4666 - accuracy: 0.8201 - val_loss: 0.4260 - val_accuracy: 0.8392\n",
      "Epoch 323/1000\n",
      "225/225 [==============================] - 0s 2ms/step - loss: 0.4702 - accuracy: 0.8184 - val_loss: 0.4285 - val_accuracy: 0.8393\n",
      "Epoch 324/1000\n",
      "225/225 [==============================] - 0s 2ms/step - loss: 0.4717 - accuracy: 0.8171 - val_loss: 0.4256 - val_accuracy: 0.8389\n",
      "Epoch 325/1000\n",
      "225/225 [==============================] - 0s 2ms/step - loss: 0.4675 - accuracy: 0.8187 - val_loss: 0.4232 - val_accuracy: 0.8394\n",
      "Epoch 326/1000\n",
      "225/225 [==============================] - 0s 2ms/step - loss: 0.4695 - accuracy: 0.8185 - val_loss: 0.4261 - val_accuracy: 0.8402\n",
      "Epoch 327/1000\n",
      "225/225 [==============================] - 0s 2ms/step - loss: 0.4666 - accuracy: 0.8212 - val_loss: 0.4271 - val_accuracy: 0.8386\n",
      "Epoch 328/1000\n",
      "225/225 [==============================] - 0s 2ms/step - loss: 0.4670 - accuracy: 0.8191 - val_loss: 0.4274 - val_accuracy: 0.8395\n",
      "Epoch 329/1000\n",
      "225/225 [==============================] - 0s 2ms/step - loss: 0.4690 - accuracy: 0.8191 - val_loss: 0.4264 - val_accuracy: 0.8391\n",
      "Epoch 330/1000\n",
      "225/225 [==============================] - 0s 2ms/step - loss: 0.4687 - accuracy: 0.8192 - val_loss: 0.4244 - val_accuracy: 0.8425\n",
      "Epoch 331/1000\n",
      "225/225 [==============================] - 0s 2ms/step - loss: 0.4672 - accuracy: 0.8194 - val_loss: 0.4236 - val_accuracy: 0.8416\n",
      "Epoch 332/1000\n",
      "225/225 [==============================] - 0s 2ms/step - loss: 0.4676 - accuracy: 0.8185 - val_loss: 0.4263 - val_accuracy: 0.8376\n",
      "Epoch 333/1000\n",
      "225/225 [==============================] - 0s 2ms/step - loss: 0.4689 - accuracy: 0.8194 - val_loss: 0.4268 - val_accuracy: 0.8402\n",
      "Epoch 334/1000\n",
      "225/225 [==============================] - 0s 2ms/step - loss: 0.4658 - accuracy: 0.8197 - val_loss: 0.4241 - val_accuracy: 0.8417\n",
      "Epoch 335/1000\n",
      "225/225 [==============================] - 0s 2ms/step - loss: 0.4689 - accuracy: 0.8189 - val_loss: 0.4255 - val_accuracy: 0.8424\n",
      "Epoch 336/1000\n",
      "225/225 [==============================] - 0s 2ms/step - loss: 0.4676 - accuracy: 0.8199 - val_loss: 0.4237 - val_accuracy: 0.8430\n",
      "Epoch 337/1000\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "225/225 [==============================] - 1s 2ms/step - loss: 0.4672 - accuracy: 0.8202 - val_loss: 0.4250 - val_accuracy: 0.8391\n",
      "Epoch 338/1000\n",
      "225/225 [==============================] - 0s 2ms/step - loss: 0.4670 - accuracy: 0.8208 - val_loss: 0.4267 - val_accuracy: 0.8387\n",
      "Epoch 339/1000\n",
      "225/225 [==============================] - 0s 2ms/step - loss: 0.4663 - accuracy: 0.8189 - val_loss: 0.4234 - val_accuracy: 0.8412\n",
      "Epoch 340/1000\n",
      "225/225 [==============================] - 0s 2ms/step - loss: 0.4667 - accuracy: 0.8189 - val_loss: 0.4225 - val_accuracy: 0.8411\n",
      "Epoch 341/1000\n",
      "225/225 [==============================] - 0s 2ms/step - loss: 0.4673 - accuracy: 0.8194 - val_loss: 0.4280 - val_accuracy: 0.8401\n",
      "Epoch 342/1000\n",
      "225/225 [==============================] - 0s 2ms/step - loss: 0.4663 - accuracy: 0.8199 - val_loss: 0.4235 - val_accuracy: 0.8440\n",
      "Epoch 343/1000\n",
      "225/225 [==============================] - 0s 2ms/step - loss: 0.4674 - accuracy: 0.8194 - val_loss: 0.4245 - val_accuracy: 0.8405\n",
      "Epoch 344/1000\n",
      "225/225 [==============================] - 0s 2ms/step - loss: 0.4654 - accuracy: 0.8193 - val_loss: 0.4261 - val_accuracy: 0.8416\n",
      "Epoch 345/1000\n",
      "225/225 [==============================] - 0s 2ms/step - loss: 0.4676 - accuracy: 0.8190 - val_loss: 0.4252 - val_accuracy: 0.8420\n",
      "Epoch 346/1000\n",
      "225/225 [==============================] - 0s 2ms/step - loss: 0.4699 - accuracy: 0.8187 - val_loss: 0.4251 - val_accuracy: 0.8426\n",
      "Epoch 347/1000\n",
      "225/225 [==============================] - 0s 2ms/step - loss: 0.4661 - accuracy: 0.8204 - val_loss: 0.4245 - val_accuracy: 0.8412\n",
      "Epoch 348/1000\n",
      "225/225 [==============================] - 0s 2ms/step - loss: 0.4662 - accuracy: 0.8202 - val_loss: 0.4261 - val_accuracy: 0.8421\n",
      "Epoch 349/1000\n",
      "225/225 [==============================] - 0s 2ms/step - loss: 0.4689 - accuracy: 0.8194 - val_loss: 0.4255 - val_accuracy: 0.8407\n",
      "Epoch 350/1000\n",
      "225/225 [==============================] - 0s 2ms/step - loss: 0.4654 - accuracy: 0.8206 - val_loss: 0.4237 - val_accuracy: 0.8432\n",
      "Epoch 351/1000\n",
      "225/225 [==============================] - 0s 2ms/step - loss: 0.4655 - accuracy: 0.8197 - val_loss: 0.4228 - val_accuracy: 0.8431\n",
      "Epoch 352/1000\n",
      "225/225 [==============================] - 0s 2ms/step - loss: 0.4658 - accuracy: 0.8204 - val_loss: 0.4240 - val_accuracy: 0.8410\n",
      "Epoch 353/1000\n",
      "225/225 [==============================] - 0s 2ms/step - loss: 0.4654 - accuracy: 0.8197 - val_loss: 0.4236 - val_accuracy: 0.8416\n",
      "Epoch 354/1000\n",
      "225/225 [==============================] - 0s 2ms/step - loss: 0.4664 - accuracy: 0.8200 - val_loss: 0.4250 - val_accuracy: 0.8435\n",
      "Epoch 355/1000\n",
      "225/225 [==============================] - 0s 2ms/step - loss: 0.4669 - accuracy: 0.8203 - val_loss: 0.4233 - val_accuracy: 0.8421\n",
      "Epoch 356/1000\n",
      "225/225 [==============================] - 0s 2ms/step - loss: 0.4680 - accuracy: 0.8200 - val_loss: 0.4212 - val_accuracy: 0.8401\n",
      "Epoch 357/1000\n",
      "225/225 [==============================] - 0s 2ms/step - loss: 0.4675 - accuracy: 0.8197 - val_loss: 0.4230 - val_accuracy: 0.8414\n",
      "Epoch 358/1000\n",
      "225/225 [==============================] - 0s 2ms/step - loss: 0.4652 - accuracy: 0.8207 - val_loss: 0.4219 - val_accuracy: 0.8431\n",
      "Epoch 359/1000\n",
      "225/225 [==============================] - 0s 2ms/step - loss: 0.4650 - accuracy: 0.8197 - val_loss: 0.4237 - val_accuracy: 0.8408\n",
      "Epoch 360/1000\n",
      "225/225 [==============================] - 0s 2ms/step - loss: 0.4672 - accuracy: 0.8195 - val_loss: 0.4241 - val_accuracy: 0.8430\n",
      "Epoch 361/1000\n",
      "225/225 [==============================] - 0s 2ms/step - loss: 0.4668 - accuracy: 0.8186 - val_loss: 0.4238 - val_accuracy: 0.8414\n",
      "Epoch 362/1000\n",
      "225/225 [==============================] - 0s 2ms/step - loss: 0.4673 - accuracy: 0.8181 - val_loss: 0.4249 - val_accuracy: 0.8395\n",
      "Epoch 363/1000\n",
      "225/225 [==============================] - 0s 2ms/step - loss: 0.4644 - accuracy: 0.8202 - val_loss: 0.4233 - val_accuracy: 0.8416\n",
      "Epoch 364/1000\n",
      "225/225 [==============================] - 0s 2ms/step - loss: 0.4653 - accuracy: 0.8201 - val_loss: 0.4223 - val_accuracy: 0.8405\n",
      "Epoch 365/1000\n",
      "225/225 [==============================] - 0s 2ms/step - loss: 0.4644 - accuracy: 0.8199 - val_loss: 0.4215 - val_accuracy: 0.8418\n",
      "Epoch 366/1000\n",
      "225/225 [==============================] - 0s 2ms/step - loss: 0.4646 - accuracy: 0.8209 - val_loss: 0.4202 - val_accuracy: 0.8433\n",
      "Epoch 367/1000\n",
      "225/225 [==============================] - 0s 2ms/step - loss: 0.4636 - accuracy: 0.8205 - val_loss: 0.4225 - val_accuracy: 0.8426\n",
      "Epoch 368/1000\n",
      "225/225 [==============================] - 0s 2ms/step - loss: 0.4648 - accuracy: 0.8205 - val_loss: 0.4212 - val_accuracy: 0.8427\n",
      "Epoch 369/1000\n",
      "225/225 [==============================] - 0s 2ms/step - loss: 0.4670 - accuracy: 0.8190 - val_loss: 0.4207 - val_accuracy: 0.8437\n",
      "Epoch 370/1000\n",
      "225/225 [==============================] - 0s 2ms/step - loss: 0.4646 - accuracy: 0.8208 - val_loss: 0.4251 - val_accuracy: 0.8401\n",
      "Epoch 371/1000\n",
      "225/225 [==============================] - 1s 2ms/step - loss: 0.4636 - accuracy: 0.8204 - val_loss: 0.4231 - val_accuracy: 0.8402\n",
      "Epoch 372/1000\n",
      "225/225 [==============================] - 0s 2ms/step - loss: 0.4650 - accuracy: 0.8197 - val_loss: 0.4236 - val_accuracy: 0.8393\n",
      "Epoch 373/1000\n",
      "225/225 [==============================] - 0s 2ms/step - loss: 0.4655 - accuracy: 0.8201 - val_loss: 0.4220 - val_accuracy: 0.8431\n",
      "Epoch 374/1000\n",
      "225/225 [==============================] - 0s 2ms/step - loss: 0.4620 - accuracy: 0.8220 - val_loss: 0.4221 - val_accuracy: 0.8427\n",
      "Epoch 375/1000\n",
      "225/225 [==============================] - 0s 2ms/step - loss: 0.4626 - accuracy: 0.8213 - val_loss: 0.4215 - val_accuracy: 0.8426\n",
      "Epoch 376/1000\n",
      "225/225 [==============================] - 0s 2ms/step - loss: 0.4659 - accuracy: 0.8207 - val_loss: 0.4201 - val_accuracy: 0.8456\n",
      "Epoch 377/1000\n",
      "225/225 [==============================] - 0s 2ms/step - loss: 0.4609 - accuracy: 0.8209 - val_loss: 0.4221 - val_accuracy: 0.8413\n",
      "Epoch 378/1000\n",
      "225/225 [==============================] - 0s 2ms/step - loss: 0.4633 - accuracy: 0.8218 - val_loss: 0.4199 - val_accuracy: 0.8444\n",
      "Epoch 379/1000\n",
      "225/225 [==============================] - 0s 2ms/step - loss: 0.4666 - accuracy: 0.8201 - val_loss: 0.4183 - val_accuracy: 0.8459\n",
      "Epoch 380/1000\n",
      "225/225 [==============================] - 0s 2ms/step - loss: 0.4655 - accuracy: 0.8191 - val_loss: 0.4193 - val_accuracy: 0.8448\n",
      "Epoch 381/1000\n",
      "225/225 [==============================] - 0s 2ms/step - loss: 0.4650 - accuracy: 0.8206 - val_loss: 0.4201 - val_accuracy: 0.8432\n",
      "Epoch 382/1000\n",
      "225/225 [==============================] - 0s 2ms/step - loss: 0.4623 - accuracy: 0.8215 - val_loss: 0.4190 - val_accuracy: 0.8448\n",
      "Epoch 383/1000\n",
      "225/225 [==============================] - 0s 2ms/step - loss: 0.4641 - accuracy: 0.8212 - val_loss: 0.4171 - val_accuracy: 0.8453\n",
      "Epoch 384/1000\n",
      "225/225 [==============================] - 0s 2ms/step - loss: 0.4648 - accuracy: 0.8210 - val_loss: 0.4183 - val_accuracy: 0.8456\n",
      "Epoch 385/1000\n",
      "225/225 [==============================] - 0s 2ms/step - loss: 0.4648 - accuracy: 0.8202 - val_loss: 0.4206 - val_accuracy: 0.8438\n",
      "Epoch 386/1000\n",
      "225/225 [==============================] - 1s 2ms/step - loss: 0.4629 - accuracy: 0.8217 - val_loss: 0.4198 - val_accuracy: 0.8427\n",
      "Epoch 387/1000\n",
      "225/225 [==============================] - 0s 2ms/step - loss: 0.4663 - accuracy: 0.8199 - val_loss: 0.4230 - val_accuracy: 0.8425\n",
      "Epoch 388/1000\n",
      "225/225 [==============================] - 0s 2ms/step - loss: 0.4640 - accuracy: 0.8215 - val_loss: 0.4178 - val_accuracy: 0.8423\n",
      "Epoch 389/1000\n",
      "225/225 [==============================] - 0s 2ms/step - loss: 0.4651 - accuracy: 0.8210 - val_loss: 0.4196 - val_accuracy: 0.8437\n",
      "Epoch 390/1000\n",
      "225/225 [==============================] - 0s 2ms/step - loss: 0.4658 - accuracy: 0.8208 - val_loss: 0.4221 - val_accuracy: 0.8431\n",
      "Epoch 391/1000\n",
      "225/225 [==============================] - 0s 2ms/step - loss: 0.4631 - accuracy: 0.8209 - val_loss: 0.4187 - val_accuracy: 0.8447\n",
      "Epoch 392/1000\n",
      "225/225 [==============================] - 0s 2ms/step - loss: 0.4641 - accuracy: 0.8206 - val_loss: 0.4209 - val_accuracy: 0.8423\n",
      "Epoch 393/1000\n",
      "225/225 [==============================] - 0s 2ms/step - loss: 0.4617 - accuracy: 0.8225 - val_loss: 0.4214 - val_accuracy: 0.8432\n",
      "Epoch 394/1000\n",
      "225/225 [==============================] - 0s 2ms/step - loss: 0.4631 - accuracy: 0.8207 - val_loss: 0.4181 - val_accuracy: 0.8447\n",
      "Epoch 395/1000\n",
      "225/225 [==============================] - 0s 2ms/step - loss: 0.4634 - accuracy: 0.8212 - val_loss: 0.4165 - val_accuracy: 0.8431\n",
      "Epoch 396/1000\n",
      "225/225 [==============================] - 0s 2ms/step - loss: 0.4614 - accuracy: 0.8212 - val_loss: 0.4179 - val_accuracy: 0.8431\n",
      "Epoch 397/1000\n",
      "225/225 [==============================] - 0s 2ms/step - loss: 0.4624 - accuracy: 0.8214 - val_loss: 0.4163 - val_accuracy: 0.8469\n",
      "Epoch 398/1000\n",
      "225/225 [==============================] - 0s 2ms/step - loss: 0.4622 - accuracy: 0.8215 - val_loss: 0.4206 - val_accuracy: 0.8436\n",
      "Epoch 399/1000\n",
      "225/225 [==============================] - 0s 2ms/step - loss: 0.4631 - accuracy: 0.8213 - val_loss: 0.4167 - val_accuracy: 0.8460\n",
      "Epoch 400/1000\n",
      "225/225 [==============================] - 0s 2ms/step - loss: 0.4620 - accuracy: 0.8218 - val_loss: 0.4178 - val_accuracy: 0.8445\n",
      "Epoch 401/1000\n",
      "225/225 [==============================] - 0s 2ms/step - loss: 0.4659 - accuracy: 0.8203 - val_loss: 0.4196 - val_accuracy: 0.8434\n",
      "Epoch 402/1000\n",
      "225/225 [==============================] - 0s 2ms/step - loss: 0.4630 - accuracy: 0.8213 - val_loss: 0.4206 - val_accuracy: 0.8428\n",
      "Epoch 403/1000\n",
      "225/225 [==============================] - 0s 2ms/step - loss: 0.4629 - accuracy: 0.8210 - val_loss: 0.4215 - val_accuracy: 0.8422\n",
      "Epoch 404/1000\n",
      "225/225 [==============================] - 0s 2ms/step - loss: 0.4617 - accuracy: 0.8219 - val_loss: 0.4195 - val_accuracy: 0.8431\n",
      "Epoch 405/1000\n",
      "225/225 [==============================] - 1s 2ms/step - loss: 0.4635 - accuracy: 0.8218 - val_loss: 0.4204 - val_accuracy: 0.8432\n",
      "Epoch 406/1000\n",
      "225/225 [==============================] - 0s 2ms/step - loss: 0.4638 - accuracy: 0.8208 - val_loss: 0.4195 - val_accuracy: 0.8432\n",
      "Epoch 407/1000\n",
      "225/225 [==============================] - 0s 2ms/step - loss: 0.4612 - accuracy: 0.8222 - val_loss: 0.4207 - val_accuracy: 0.8424\n",
      "Epoch 408/1000\n",
      "225/225 [==============================] - 0s 2ms/step - loss: 0.4633 - accuracy: 0.8211 - val_loss: 0.4196 - val_accuracy: 0.8429\n",
      "Epoch 409/1000\n",
      "225/225 [==============================] - 0s 2ms/step - loss: 0.4629 - accuracy: 0.8219 - val_loss: 0.4190 - val_accuracy: 0.8457\n",
      "Epoch 410/1000\n",
      "225/225 [==============================] - 0s 2ms/step - loss: 0.4623 - accuracy: 0.8223 - val_loss: 0.4170 - val_accuracy: 0.8446\n",
      "Epoch 411/1000\n",
      "225/225 [==============================] - 0s 2ms/step - loss: 0.4628 - accuracy: 0.8221 - val_loss: 0.4197 - val_accuracy: 0.8452\n",
      "Epoch 412/1000\n",
      "225/225 [==============================] - 0s 2ms/step - loss: 0.4616 - accuracy: 0.8227 - val_loss: 0.4190 - val_accuracy: 0.8422\n",
      "Epoch 413/1000\n",
      "225/225 [==============================] - 0s 2ms/step - loss: 0.4618 - accuracy: 0.8218 - val_loss: 0.4205 - val_accuracy: 0.8434\n",
      "Epoch 414/1000\n",
      "225/225 [==============================] - 0s 2ms/step - loss: 0.4601 - accuracy: 0.8220 - val_loss: 0.4193 - val_accuracy: 0.8454\n",
      "Epoch 415/1000\n",
      "225/225 [==============================] - 0s 2ms/step - loss: 0.4610 - accuracy: 0.8229 - val_loss: 0.4161 - val_accuracy: 0.8463\n",
      "Epoch 416/1000\n",
      "225/225 [==============================] - 0s 2ms/step - loss: 0.4608 - accuracy: 0.8222 - val_loss: 0.4155 - val_accuracy: 0.8465\n",
      "Epoch 417/1000\n",
      "225/225 [==============================] - 0s 2ms/step - loss: 0.4616 - accuracy: 0.8225 - val_loss: 0.4179 - val_accuracy: 0.8458\n",
      "Epoch 418/1000\n",
      "225/225 [==============================] - 0s 2ms/step - loss: 0.4634 - accuracy: 0.8209 - val_loss: 0.4194 - val_accuracy: 0.8443\n",
      "Epoch 419/1000\n",
      "225/225 [==============================] - 0s 2ms/step - loss: 0.4602 - accuracy: 0.8221 - val_loss: 0.4172 - val_accuracy: 0.8442\n",
      "Epoch 420/1000\n",
      "225/225 [==============================] - 0s 2ms/step - loss: 0.4620 - accuracy: 0.8219 - val_loss: 0.4180 - val_accuracy: 0.8462\n",
      "Epoch 421/1000\n",
      "225/225 [==============================] - 0s 2ms/step - loss: 0.4618 - accuracy: 0.8229 - val_loss: 0.4172 - val_accuracy: 0.8476\n",
      "Epoch 422/1000\n",
      "225/225 [==============================] - 0s 2ms/step - loss: 0.4617 - accuracy: 0.8225 - val_loss: 0.4174 - val_accuracy: 0.8452\n",
      "Epoch 423/1000\n",
      "225/225 [==============================] - 0s 2ms/step - loss: 0.4607 - accuracy: 0.8225 - val_loss: 0.4177 - val_accuracy: 0.8450\n",
      "Epoch 424/1000\n",
      "225/225 [==============================] - 0s 2ms/step - loss: 0.4613 - accuracy: 0.8223 - val_loss: 0.4176 - val_accuracy: 0.8423\n",
      "Epoch 425/1000\n",
      "225/225 [==============================] - 0s 2ms/step - loss: 0.4608 - accuracy: 0.8220 - val_loss: 0.4179 - val_accuracy: 0.8435\n",
      "Epoch 426/1000\n",
      "225/225 [==============================] - 0s 2ms/step - loss: 0.4620 - accuracy: 0.8224 - val_loss: 0.4197 - val_accuracy: 0.8434\n",
      "Epoch 427/1000\n",
      "225/225 [==============================] - 0s 2ms/step - loss: 0.4597 - accuracy: 0.8222 - val_loss: 0.4197 - val_accuracy: 0.8417\n",
      "Epoch 428/1000\n",
      "225/225 [==============================] - 0s 2ms/step - loss: 0.4613 - accuracy: 0.8218 - val_loss: 0.4164 - val_accuracy: 0.8448\n",
      "Epoch 429/1000\n",
      "225/225 [==============================] - 0s 2ms/step - loss: 0.4602 - accuracy: 0.8236 - val_loss: 0.4186 - val_accuracy: 0.8444\n",
      "Epoch 430/1000\n",
      "225/225 [==============================] - 0s 2ms/step - loss: 0.4615 - accuracy: 0.8214 - val_loss: 0.4213 - val_accuracy: 0.8394\n",
      "Epoch 431/1000\n",
      "225/225 [==============================] - 1s 2ms/step - loss: 0.4609 - accuracy: 0.8219 - val_loss: 0.4179 - val_accuracy: 0.8459\n",
      "Epoch 432/1000\n",
      "225/225 [==============================] - 1s 2ms/step - loss: 0.4601 - accuracy: 0.8224 - val_loss: 0.4167 - val_accuracy: 0.8444\n",
      "Epoch 433/1000\n",
      "225/225 [==============================] - 0s 2ms/step - loss: 0.4640 - accuracy: 0.8202 - val_loss: 0.4168 - val_accuracy: 0.8442\n",
      "Epoch 434/1000\n",
      "225/225 [==============================] - 0s 2ms/step - loss: 0.4590 - accuracy: 0.8228 - val_loss: 0.4171 - val_accuracy: 0.8434\n",
      "Epoch 435/1000\n",
      "225/225 [==============================] - 0s 2ms/step - loss: 0.4610 - accuracy: 0.8219 - val_loss: 0.4164 - val_accuracy: 0.8461\n",
      "Epoch 436/1000\n",
      "225/225 [==============================] - 0s 2ms/step - loss: 0.4621 - accuracy: 0.8207 - val_loss: 0.4185 - val_accuracy: 0.8472\n",
      "Epoch 437/1000\n",
      "225/225 [==============================] - 0s 2ms/step - loss: 0.4603 - accuracy: 0.8214 - val_loss: 0.4170 - val_accuracy: 0.8456\n",
      "Epoch 438/1000\n",
      "225/225 [==============================] - 1s 2ms/step - loss: 0.4595 - accuracy: 0.8234 - val_loss: 0.4156 - val_accuracy: 0.8464\n",
      "Epoch 439/1000\n",
      "225/225 [==============================] - 0s 2ms/step - loss: 0.4586 - accuracy: 0.8224 - val_loss: 0.4170 - val_accuracy: 0.8478\n",
      "Epoch 440/1000\n",
      "225/225 [==============================] - 0s 2ms/step - loss: 0.4593 - accuracy: 0.8225 - val_loss: 0.4162 - val_accuracy: 0.8463\n",
      "Epoch 441/1000\n",
      "225/225 [==============================] - 1s 2ms/step - loss: 0.4599 - accuracy: 0.8217 - val_loss: 0.4170 - val_accuracy: 0.8453\n",
      "Epoch 442/1000\n",
      "225/225 [==============================] - 0s 2ms/step - loss: 0.4605 - accuracy: 0.8225 - val_loss: 0.4164 - val_accuracy: 0.8466\n",
      "Epoch 443/1000\n",
      "225/225 [==============================] - 0s 2ms/step - loss: 0.4610 - accuracy: 0.8230 - val_loss: 0.4163 - val_accuracy: 0.8463\n",
      "Epoch 444/1000\n",
      "225/225 [==============================] - 0s 2ms/step - loss: 0.4608 - accuracy: 0.8232 - val_loss: 0.4145 - val_accuracy: 0.8477\n",
      "Epoch 445/1000\n",
      "225/225 [==============================] - 0s 2ms/step - loss: 0.4612 - accuracy: 0.8226 - val_loss: 0.4148 - val_accuracy: 0.8457\n",
      "Epoch 446/1000\n",
      "225/225 [==============================] - 1s 2ms/step - loss: 0.4625 - accuracy: 0.8215 - val_loss: 0.4189 - val_accuracy: 0.8454\n",
      "Epoch 447/1000\n",
      "225/225 [==============================] - 0s 2ms/step - loss: 0.4595 - accuracy: 0.8230 - val_loss: 0.4157 - val_accuracy: 0.8457\n",
      "Epoch 448/1000\n",
      "225/225 [==============================] - 0s 2ms/step - loss: 0.4585 - accuracy: 0.8232 - val_loss: 0.4144 - val_accuracy: 0.8444\n",
      "Epoch 449/1000\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "225/225 [==============================] - 0s 2ms/step - loss: 0.4597 - accuracy: 0.8226 - val_loss: 0.4167 - val_accuracy: 0.8442\n",
      "Epoch 450/1000\n",
      "225/225 [==============================] - 0s 2ms/step - loss: 0.4582 - accuracy: 0.8227 - val_loss: 0.4167 - val_accuracy: 0.8442\n",
      "Epoch 451/1000\n",
      "225/225 [==============================] - 0s 2ms/step - loss: 0.4597 - accuracy: 0.8232 - val_loss: 0.4191 - val_accuracy: 0.8451\n",
      "Epoch 452/1000\n",
      "225/225 [==============================] - 0s 2ms/step - loss: 0.4601 - accuracy: 0.8227 - val_loss: 0.4159 - val_accuracy: 0.8455\n",
      "Epoch 453/1000\n",
      "225/225 [==============================] - 0s 2ms/step - loss: 0.4615 - accuracy: 0.8214 - val_loss: 0.4181 - val_accuracy: 0.8450\n",
      "Epoch 454/1000\n",
      "225/225 [==============================] - 0s 2ms/step - loss: 0.4575 - accuracy: 0.8234 - val_loss: 0.4157 - val_accuracy: 0.8439\n",
      "Epoch 455/1000\n",
      "225/225 [==============================] - 0s 2ms/step - loss: 0.4581 - accuracy: 0.8234 - val_loss: 0.4139 - val_accuracy: 0.8467\n",
      "Epoch 456/1000\n",
      "225/225 [==============================] - 0s 2ms/step - loss: 0.4579 - accuracy: 0.8232 - val_loss: 0.4155 - val_accuracy: 0.8454\n",
      "Epoch 457/1000\n",
      "225/225 [==============================] - 0s 2ms/step - loss: 0.4589 - accuracy: 0.8232 - val_loss: 0.4167 - val_accuracy: 0.8463\n",
      "Epoch 458/1000\n",
      "225/225 [==============================] - 0s 2ms/step - loss: 0.4574 - accuracy: 0.8228 - val_loss: 0.4120 - val_accuracy: 0.8464\n",
      "Epoch 459/1000\n",
      "225/225 [==============================] - 0s 2ms/step - loss: 0.4568 - accuracy: 0.8248 - val_loss: 0.4156 - val_accuracy: 0.8471\n",
      "Epoch 460/1000\n",
      "225/225 [==============================] - 0s 2ms/step - loss: 0.4588 - accuracy: 0.8226 - val_loss: 0.4166 - val_accuracy: 0.8449\n",
      "Epoch 461/1000\n",
      "225/225 [==============================] - 0s 2ms/step - loss: 0.4578 - accuracy: 0.8244 - val_loss: 0.4139 - val_accuracy: 0.8447\n",
      "Epoch 462/1000\n",
      "225/225 [==============================] - 0s 2ms/step - loss: 0.4572 - accuracy: 0.8227 - val_loss: 0.4157 - val_accuracy: 0.8452\n",
      "Epoch 463/1000\n",
      "225/225 [==============================] - 0s 2ms/step - loss: 0.4600 - accuracy: 0.8219 - val_loss: 0.4178 - val_accuracy: 0.8445\n",
      "Epoch 464/1000\n",
      "225/225 [==============================] - 0s 2ms/step - loss: 0.4585 - accuracy: 0.8230 - val_loss: 0.4149 - val_accuracy: 0.8471\n",
      "Epoch 465/1000\n",
      "225/225 [==============================] - 0s 2ms/step - loss: 0.4592 - accuracy: 0.8220 - val_loss: 0.4156 - val_accuracy: 0.8480\n",
      "Epoch 466/1000\n",
      "225/225 [==============================] - 0s 2ms/step - loss: 0.4592 - accuracy: 0.8224 - val_loss: 0.4160 - val_accuracy: 0.8470\n",
      "Epoch 467/1000\n",
      "225/225 [==============================] - 0s 2ms/step - loss: 0.4569 - accuracy: 0.8239 - val_loss: 0.4147 - val_accuracy: 0.8486\n",
      "Epoch 468/1000\n",
      "225/225 [==============================] - 0s 2ms/step - loss: 0.4571 - accuracy: 0.8237 - val_loss: 0.4128 - val_accuracy: 0.8480\n",
      "Epoch 469/1000\n",
      "225/225 [==============================] - 0s 2ms/step - loss: 0.4572 - accuracy: 0.8239 - val_loss: 0.4134 - val_accuracy: 0.8471\n",
      "Epoch 470/1000\n",
      "225/225 [==============================] - 0s 2ms/step - loss: 0.4577 - accuracy: 0.8231 - val_loss: 0.4151 - val_accuracy: 0.8462\n",
      "Epoch 471/1000\n",
      "225/225 [==============================] - 0s 2ms/step - loss: 0.4591 - accuracy: 0.8233 - val_loss: 0.4160 - val_accuracy: 0.8477\n",
      "Epoch 472/1000\n",
      "225/225 [==============================] - 0s 2ms/step - loss: 0.4590 - accuracy: 0.8243 - val_loss: 0.4141 - val_accuracy: 0.8456\n",
      "Epoch 473/1000\n",
      "225/225 [==============================] - 0s 2ms/step - loss: 0.4555 - accuracy: 0.8255 - val_loss: 0.4128 - val_accuracy: 0.8455\n",
      "Epoch 474/1000\n",
      "225/225 [==============================] - 0s 2ms/step - loss: 0.4598 - accuracy: 0.8224 - val_loss: 0.4148 - val_accuracy: 0.8442\n",
      "Epoch 475/1000\n",
      "225/225 [==============================] - 0s 2ms/step - loss: 0.4606 - accuracy: 0.8224 - val_loss: 0.4154 - val_accuracy: 0.8468\n",
      "Epoch 476/1000\n",
      "225/225 [==============================] - 0s 2ms/step - loss: 0.4567 - accuracy: 0.8250 - val_loss: 0.4114 - val_accuracy: 0.8485\n",
      "Epoch 477/1000\n",
      "225/225 [==============================] - 0s 2ms/step - loss: 0.4585 - accuracy: 0.8230 - val_loss: 0.4184 - val_accuracy: 0.8436\n",
      "Epoch 478/1000\n",
      "225/225 [==============================] - 0s 2ms/step - loss: 0.4576 - accuracy: 0.8243 - val_loss: 0.4141 - val_accuracy: 0.8478\n",
      "Epoch 479/1000\n",
      "225/225 [==============================] - 0s 2ms/step - loss: 0.4588 - accuracy: 0.8235 - val_loss: 0.4126 - val_accuracy: 0.8470\n",
      "Epoch 480/1000\n",
      "225/225 [==============================] - 0s 2ms/step - loss: 0.4592 - accuracy: 0.8224 - val_loss: 0.4105 - val_accuracy: 0.8467\n",
      "Epoch 481/1000\n",
      "225/225 [==============================] - 0s 2ms/step - loss: 0.4568 - accuracy: 0.8230 - val_loss: 0.4141 - val_accuracy: 0.8456\n",
      "Epoch 482/1000\n",
      "225/225 [==============================] - 0s 2ms/step - loss: 0.4568 - accuracy: 0.8246 - val_loss: 0.4170 - val_accuracy: 0.8449\n",
      "Epoch 483/1000\n",
      "225/225 [==============================] - 0s 2ms/step - loss: 0.4597 - accuracy: 0.8219 - val_loss: 0.4130 - val_accuracy: 0.8474\n",
      "Epoch 484/1000\n",
      "225/225 [==============================] - 0s 2ms/step - loss: 0.4567 - accuracy: 0.8239 - val_loss: 0.4150 - val_accuracy: 0.8460\n",
      "Epoch 485/1000\n",
      "225/225 [==============================] - 0s 2ms/step - loss: 0.4582 - accuracy: 0.8244 - val_loss: 0.4140 - val_accuracy: 0.8459\n",
      "Epoch 486/1000\n",
      "225/225 [==============================] - 0s 2ms/step - loss: 0.4574 - accuracy: 0.8228 - val_loss: 0.4138 - val_accuracy: 0.8454\n",
      "Epoch 487/1000\n",
      "225/225 [==============================] - 0s 2ms/step - loss: 0.4560 - accuracy: 0.8255 - val_loss: 0.4119 - val_accuracy: 0.8463\n",
      "Epoch 488/1000\n",
      "225/225 [==============================] - 0s 2ms/step - loss: 0.4578 - accuracy: 0.8240 - val_loss: 0.4157 - val_accuracy: 0.8438\n",
      "Epoch 489/1000\n",
      "225/225 [==============================] - 0s 2ms/step - loss: 0.4571 - accuracy: 0.8245 - val_loss: 0.4160 - val_accuracy: 0.8446\n",
      "Epoch 490/1000\n",
      "225/225 [==============================] - 0s 2ms/step - loss: 0.4586 - accuracy: 0.8235 - val_loss: 0.4131 - val_accuracy: 0.8457\n",
      "Epoch 491/1000\n",
      "225/225 [==============================] - 0s 2ms/step - loss: 0.4563 - accuracy: 0.8246 - val_loss: 0.4099 - val_accuracy: 0.8483\n",
      "Epoch 492/1000\n",
      "225/225 [==============================] - 0s 2ms/step - loss: 0.4594 - accuracy: 0.8229 - val_loss: 0.4137 - val_accuracy: 0.8452\n",
      "Epoch 493/1000\n",
      "225/225 [==============================] - 1s 2ms/step - loss: 0.4559 - accuracy: 0.8224 - val_loss: 0.4156 - val_accuracy: 0.8466\n",
      "Epoch 494/1000\n",
      "225/225 [==============================] - 0s 2ms/step - loss: 0.4583 - accuracy: 0.8236 - val_loss: 0.4148 - val_accuracy: 0.8463\n",
      "Epoch 495/1000\n",
      "225/225 [==============================] - 0s 2ms/step - loss: 0.4567 - accuracy: 0.8238 - val_loss: 0.4186 - val_accuracy: 0.8445\n",
      "Epoch 496/1000\n",
      "225/225 [==============================] - 0s 2ms/step - loss: 0.4591 - accuracy: 0.8229 - val_loss: 0.4174 - val_accuracy: 0.8447\n",
      "Epoch 497/1000\n",
      "225/225 [==============================] - 0s 2ms/step - loss: 0.4570 - accuracy: 0.8240 - val_loss: 0.4141 - val_accuracy: 0.8470\n",
      "Epoch 498/1000\n",
      "225/225 [==============================] - 0s 2ms/step - loss: 0.4566 - accuracy: 0.8228 - val_loss: 0.4175 - val_accuracy: 0.8427\n",
      "Epoch 499/1000\n",
      "225/225 [==============================] - 0s 2ms/step - loss: 0.4564 - accuracy: 0.8252 - val_loss: 0.4166 - val_accuracy: 0.8469\n",
      "Epoch 500/1000\n",
      "225/225 [==============================] - 0s 2ms/step - loss: 0.4568 - accuracy: 0.8240 - val_loss: 0.4145 - val_accuracy: 0.8463\n",
      "Epoch 501/1000\n",
      "225/225 [==============================] - 0s 2ms/step - loss: 0.4576 - accuracy: 0.8238 - val_loss: 0.4145 - val_accuracy: 0.8474\n",
      "Epoch 502/1000\n",
      "225/225 [==============================] - 0s 2ms/step - loss: 0.4566 - accuracy: 0.8241 - val_loss: 0.4156 - val_accuracy: 0.8477\n",
      "Epoch 503/1000\n",
      "225/225 [==============================] - 0s 2ms/step - loss: 0.4575 - accuracy: 0.8242 - val_loss: 0.4142 - val_accuracy: 0.8476\n",
      "Epoch 504/1000\n",
      "225/225 [==============================] - 0s 2ms/step - loss: 0.4565 - accuracy: 0.8244 - val_loss: 0.4145 - val_accuracy: 0.8467\n",
      "Epoch 505/1000\n",
      "225/225 [==============================] - 1s 2ms/step - loss: 0.4577 - accuracy: 0.8238 - val_loss: 0.4147 - val_accuracy: 0.8468\n",
      "Epoch 506/1000\n",
      "225/225 [==============================] - 0s 2ms/step - loss: 0.4551 - accuracy: 0.8238 - val_loss: 0.4141 - val_accuracy: 0.8456\n",
      "Epoch 507/1000\n",
      "225/225 [==============================] - 0s 2ms/step - loss: 0.4562 - accuracy: 0.8233 - val_loss: 0.4145 - val_accuracy: 0.8457\n",
      "Epoch 508/1000\n",
      "225/225 [==============================] - 0s 2ms/step - loss: 0.4577 - accuracy: 0.8237 - val_loss: 0.4137 - val_accuracy: 0.8475\n",
      "Epoch 509/1000\n",
      "225/225 [==============================] - 0s 2ms/step - loss: 0.4588 - accuracy: 0.8236 - val_loss: 0.4151 - val_accuracy: 0.8458\n",
      "Epoch 510/1000\n",
      "225/225 [==============================] - 1s 2ms/step - loss: 0.4554 - accuracy: 0.8242 - val_loss: 0.4161 - val_accuracy: 0.8446\n",
      "Epoch 511/1000\n",
      "225/225 [==============================] - 0s 2ms/step - loss: 0.4576 - accuracy: 0.8238 - val_loss: 0.4163 - val_accuracy: 0.8456\n",
      "Epoch 512/1000\n",
      "225/225 [==============================] - 0s 2ms/step - loss: 0.4560 - accuracy: 0.8235 - val_loss: 0.4142 - val_accuracy: 0.8479\n",
      "Epoch 513/1000\n",
      "225/225 [==============================] - 0s 2ms/step - loss: 0.4564 - accuracy: 0.8235 - val_loss: 0.4114 - val_accuracy: 0.8481\n",
      "Epoch 514/1000\n",
      "225/225 [==============================] - 0s 2ms/step - loss: 0.4561 - accuracy: 0.8232 - val_loss: 0.4110 - val_accuracy: 0.8474\n",
      "Epoch 515/1000\n",
      "225/225 [==============================] - 0s 2ms/step - loss: 0.4542 - accuracy: 0.8247 - val_loss: 0.4147 - val_accuracy: 0.8465\n",
      "Epoch 516/1000\n",
      "225/225 [==============================] - 0s 2ms/step - loss: 0.4567 - accuracy: 0.8238 - val_loss: 0.4115 - val_accuracy: 0.8496\n",
      "Epoch 517/1000\n",
      "225/225 [==============================] - 0s 2ms/step - loss: 0.4562 - accuracy: 0.8247 - val_loss: 0.4159 - val_accuracy: 0.8472\n",
      "Epoch 518/1000\n",
      "225/225 [==============================] - 0s 2ms/step - loss: 0.4550 - accuracy: 0.8239 - val_loss: 0.4146 - val_accuracy: 0.8469\n",
      "Epoch 519/1000\n",
      "225/225 [==============================] - 0s 2ms/step - loss: 0.4566 - accuracy: 0.8240 - val_loss: 0.4132 - val_accuracy: 0.8478\n",
      "Epoch 520/1000\n",
      "225/225 [==============================] - 0s 2ms/step - loss: 0.4570 - accuracy: 0.8241 - val_loss: 0.4140 - val_accuracy: 0.8473\n",
      "Epoch 521/1000\n",
      "225/225 [==============================] - 0s 2ms/step - loss: 0.4549 - accuracy: 0.8249 - val_loss: 0.4097 - val_accuracy: 0.8490\n",
      "Epoch 522/1000\n",
      "225/225 [==============================] - 0s 2ms/step - loss: 0.4576 - accuracy: 0.8264 - val_loss: 0.4123 - val_accuracy: 0.8448\n",
      "Epoch 523/1000\n",
      "225/225 [==============================] - 0s 2ms/step - loss: 0.4550 - accuracy: 0.8255 - val_loss: 0.4125 - val_accuracy: 0.8479\n",
      "Epoch 524/1000\n",
      "225/225 [==============================] - 0s 2ms/step - loss: 0.4587 - accuracy: 0.8227 - val_loss: 0.4148 - val_accuracy: 0.8470\n",
      "Epoch 525/1000\n",
      "225/225 [==============================] - 0s 2ms/step - loss: 0.4547 - accuracy: 0.8242 - val_loss: 0.4123 - val_accuracy: 0.8494\n",
      "Epoch 526/1000\n",
      "225/225 [==============================] - 0s 2ms/step - loss: 0.4555 - accuracy: 0.8247 - val_loss: 0.4129 - val_accuracy: 0.8484\n",
      "Epoch 527/1000\n",
      "225/225 [==============================] - 0s 2ms/step - loss: 0.4572 - accuracy: 0.8246 - val_loss: 0.4104 - val_accuracy: 0.8478\n",
      "Epoch 528/1000\n",
      "225/225 [==============================] - 0s 2ms/step - loss: 0.4545 - accuracy: 0.8243 - val_loss: 0.4115 - val_accuracy: 0.8492\n",
      "Epoch 529/1000\n",
      "225/225 [==============================] - 0s 2ms/step - loss: 0.4593 - accuracy: 0.8231 - val_loss: 0.4154 - val_accuracy: 0.8454\n",
      "Epoch 530/1000\n",
      "225/225 [==============================] - 0s 2ms/step - loss: 0.4537 - accuracy: 0.8255 - val_loss: 0.4132 - val_accuracy: 0.8478\n",
      "Epoch 531/1000\n",
      "225/225 [==============================] - 0s 2ms/step - loss: 0.4569 - accuracy: 0.8238 - val_loss: 0.4105 - val_accuracy: 0.8496\n",
      "Epoch 532/1000\n",
      "225/225 [==============================] - 0s 2ms/step - loss: 0.4544 - accuracy: 0.8248 - val_loss: 0.4125 - val_accuracy: 0.8468\n",
      "Epoch 533/1000\n",
      "225/225 [==============================] - 0s 2ms/step - loss: 0.4546 - accuracy: 0.8255 - val_loss: 0.4101 - val_accuracy: 0.8487\n",
      "Epoch 534/1000\n",
      "225/225 [==============================] - 0s 2ms/step - loss: 0.4548 - accuracy: 0.8243 - val_loss: 0.4127 - val_accuracy: 0.8479\n",
      "Epoch 535/1000\n",
      "225/225 [==============================] - 0s 2ms/step - loss: 0.4543 - accuracy: 0.8260 - val_loss: 0.4136 - val_accuracy: 0.8461\n",
      "Epoch 536/1000\n",
      "225/225 [==============================] - 0s 2ms/step - loss: 0.4550 - accuracy: 0.8247 - val_loss: 0.4128 - val_accuracy: 0.8456\n",
      "Epoch 537/1000\n",
      "225/225 [==============================] - 0s 2ms/step - loss: 0.4543 - accuracy: 0.8245 - val_loss: 0.4130 - val_accuracy: 0.8467\n",
      "Epoch 538/1000\n",
      "225/225 [==============================] - 0s 2ms/step - loss: 0.4573 - accuracy: 0.8240 - val_loss: 0.4141 - val_accuracy: 0.8467\n",
      "Epoch 539/1000\n",
      "225/225 [==============================] - 0s 2ms/step - loss: 0.4546 - accuracy: 0.8245 - val_loss: 0.4120 - val_accuracy: 0.8465\n",
      "Epoch 540/1000\n",
      "225/225 [==============================] - 0s 2ms/step - loss: 0.4527 - accuracy: 0.8261 - val_loss: 0.4121 - val_accuracy: 0.8456\n",
      "Epoch 541/1000\n",
      "225/225 [==============================] - 0s 2ms/step - loss: 0.4553 - accuracy: 0.8241 - val_loss: 0.4143 - val_accuracy: 0.8460\n",
      "Epoch 542/1000\n",
      "225/225 [==============================] - 0s 2ms/step - loss: 0.4562 - accuracy: 0.8239 - val_loss: 0.4126 - val_accuracy: 0.8474\n",
      "Epoch 543/1000\n",
      "225/225 [==============================] - 0s 2ms/step - loss: 0.4563 - accuracy: 0.8248 - val_loss: 0.4108 - val_accuracy: 0.8475\n",
      "Epoch 544/1000\n",
      "225/225 [==============================] - 0s 2ms/step - loss: 0.4561 - accuracy: 0.8260 - val_loss: 0.4114 - val_accuracy: 0.8459\n",
      "Epoch 545/1000\n",
      "225/225 [==============================] - 0s 2ms/step - loss: 0.4559 - accuracy: 0.8246 - val_loss: 0.4104 - val_accuracy: 0.8479\n",
      "Epoch 546/1000\n",
      "225/225 [==============================] - 0s 2ms/step - loss: 0.4544 - accuracy: 0.8255 - val_loss: 0.4123 - val_accuracy: 0.8475\n",
      "Epoch 547/1000\n",
      "225/225 [==============================] - 0s 2ms/step - loss: 0.4532 - accuracy: 0.8256 - val_loss: 0.4144 - val_accuracy: 0.8471\n",
      "Epoch 548/1000\n",
      "225/225 [==============================] - 0s 2ms/step - loss: 0.4564 - accuracy: 0.8247 - val_loss: 0.4102 - val_accuracy: 0.8497\n",
      "Epoch 549/1000\n",
      "225/225 [==============================] - 0s 2ms/step - loss: 0.4544 - accuracy: 0.8255 - val_loss: 0.4136 - val_accuracy: 0.8455\n",
      "Epoch 550/1000\n",
      "225/225 [==============================] - 0s 2ms/step - loss: 0.4535 - accuracy: 0.8265 - val_loss: 0.4142 - val_accuracy: 0.8463\n",
      "Epoch 551/1000\n",
      "225/225 [==============================] - 0s 2ms/step - loss: 0.4532 - accuracy: 0.8244 - val_loss: 0.4128 - val_accuracy: 0.8467\n",
      "Epoch 552/1000\n",
      "225/225 [==============================] - 0s 2ms/step - loss: 0.4558 - accuracy: 0.8244 - val_loss: 0.4111 - val_accuracy: 0.8472\n",
      "Epoch 553/1000\n",
      "225/225 [==============================] - 0s 2ms/step - loss: 0.4535 - accuracy: 0.8254 - val_loss: 0.4160 - val_accuracy: 0.8437\n",
      "Epoch 554/1000\n",
      "225/225 [==============================] - 0s 2ms/step - loss: 0.4541 - accuracy: 0.8254 - val_loss: 0.4125 - val_accuracy: 0.8473\n",
      "Epoch 555/1000\n",
      "225/225 [==============================] - 0s 2ms/step - loss: 0.4558 - accuracy: 0.8248 - val_loss: 0.4148 - val_accuracy: 0.8492\n",
      "Epoch 556/1000\n",
      "225/225 [==============================] - 0s 2ms/step - loss: 0.4531 - accuracy: 0.8242 - val_loss: 0.4123 - val_accuracy: 0.8483\n",
      "Epoch 557/1000\n",
      "225/225 [==============================] - 0s 2ms/step - loss: 0.4525 - accuracy: 0.8253 - val_loss: 0.4126 - val_accuracy: 0.8478\n",
      "Epoch 558/1000\n",
      "225/225 [==============================] - 0s 2ms/step - loss: 0.4549 - accuracy: 0.8246 - val_loss: 0.4136 - val_accuracy: 0.8462\n",
      "Epoch 559/1000\n",
      "225/225 [==============================] - 0s 2ms/step - loss: 0.4551 - accuracy: 0.8259 - val_loss: 0.4128 - val_accuracy: 0.8460\n",
      "Epoch 560/1000\n",
      "225/225 [==============================] - 0s 2ms/step - loss: 0.4556 - accuracy: 0.8238 - val_loss: 0.4145 - val_accuracy: 0.8490\n",
      "Epoch 561/1000\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "225/225 [==============================] - 0s 2ms/step - loss: 0.4525 - accuracy: 0.8255 - val_loss: 0.4152 - val_accuracy: 0.8467\n",
      "Epoch 562/1000\n",
      "225/225 [==============================] - 1s 2ms/step - loss: 0.4539 - accuracy: 0.8249 - val_loss: 0.4167 - val_accuracy: 0.8478\n",
      "Epoch 563/1000\n",
      "225/225 [==============================] - 0s 2ms/step - loss: 0.4560 - accuracy: 0.8248 - val_loss: 0.4149 - val_accuracy: 0.8456\n",
      "Epoch 564/1000\n",
      "225/225 [==============================] - 1s 2ms/step - loss: 0.4543 - accuracy: 0.8251 - val_loss: 0.4127 - val_accuracy: 0.8489\n",
      "Epoch 565/1000\n",
      "225/225 [==============================] - 0s 2ms/step - loss: 0.4533 - accuracy: 0.8253 - val_loss: 0.4131 - val_accuracy: 0.8463\n",
      "Epoch 566/1000\n",
      "225/225 [==============================] - 0s 2ms/step - loss: 0.4539 - accuracy: 0.8252 - val_loss: 0.4120 - val_accuracy: 0.8460\n",
      "Epoch 567/1000\n",
      "225/225 [==============================] - 0s 2ms/step - loss: 0.4549 - accuracy: 0.8239 - val_loss: 0.4124 - val_accuracy: 0.8481\n",
      "Epoch 568/1000\n",
      "225/225 [==============================] - 0s 2ms/step - loss: 0.4527 - accuracy: 0.8264 - val_loss: 0.4118 - val_accuracy: 0.8448\n",
      "Epoch 569/1000\n",
      "225/225 [==============================] - 0s 2ms/step - loss: 0.4547 - accuracy: 0.8246 - val_loss: 0.4128 - val_accuracy: 0.8475\n",
      "Epoch 570/1000\n",
      "225/225 [==============================] - 0s 2ms/step - loss: 0.4521 - accuracy: 0.8259 - val_loss: 0.4141 - val_accuracy: 0.8465\n",
      "Epoch 571/1000\n",
      "225/225 [==============================] - 1s 2ms/step - loss: 0.4526 - accuracy: 0.8248 - val_loss: 0.4121 - val_accuracy: 0.8469\n",
      "Epoch 571: early stopping\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "<keras.src.callbacks.History at 0x14208cf40>"
      ]
     },
     "execution_count": 186,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# batch size=512\n",
    "model=Sequential()\n",
    "model.add(Dense(128, input_dim=X_train.shape[1], activation=\"relu\"))\n",
    "model.add(Dropout(0.2))\n",
    "model.add(Dense(128, activation=\"relu\"))\n",
    "\n",
    "model.add(Dense(64, activation=\"relu\"))\n",
    "model.add(Dropout(0.2))\n",
    "model.add(Dense(64, activation=\"relu\"))\n",
    "\n",
    "model.add(Dense(32, activation=\"relu\"))\n",
    "model.add(Dropout(0.2))\n",
    "model.add(Dense(16, activation=\"relu\"))\n",
    "model.add(Dropout(0.2))\n",
    "model.add(Dense(3, activation=\"softmax\"))\n",
    "\n",
    "model.compile(loss='categorical_crossentropy', optimizer=Adam(learning_rate=0.001), metrics=['accuracy'])\n",
    "\n",
    "es=EarlyStopping(monitor=\"val_loss\",patience=50,mode=\"auto\",verbose=1)\n",
    "\n",
    "model.fit(X_train,\n",
    "          y_train,\n",
    "          epochs=1000,\n",
    "               batch_size=512,\n",
    "               validation_split=0.1,\n",
    "               verbose=1,callbacks=[es])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 187,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "997/997 [==============================] - 0s 314us/step\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0       0.86      0.93      0.89     10867\n",
      "           1       0.83      0.92      0.87     10432\n",
      "           2       0.84      0.68      0.75     10591\n",
      "\n",
      "    accuracy                           0.84     31890\n",
      "   macro avg       0.84      0.84      0.84     31890\n",
      "weighted avg       0.84      0.84      0.84     31890\n",
      "\n"
     ]
    }
   ],
   "source": [
    "y_pred = model.predict(X_test)\n",
    "y_pred_classes = np.argmax(y_pred, axis=1)\n",
    "y_true = np.argmax(y_test, axis=1)\n",
    "print(classification_report(y_true, y_pred_classes))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 188,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "3987/3987 [==============================] - 1s 254us/step\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0       0.88      0.96      0.92     42282\n",
      "           1       0.85      0.94      0.89     42717\n",
      "           2       0.89      0.72      0.80     42558\n",
      "\n",
      "    accuracy                           0.87    127557\n",
      "   macro avg       0.87      0.87      0.87    127557\n",
      "weighted avg       0.87      0.87      0.87    127557\n",
      "\n"
     ]
    }
   ],
   "source": [
    "y_t_pred = model.predict(X_train)\n",
    "y_t_pred_classes = np.argmax(y_t_pred, axis=1)\n",
    "y_t_true = np.argmax(y_train, axis=1)\n",
    "print(classification_report(y_t_true, y_t_pred_classes))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 189,
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 1/1000\n",
      "225/225 [==============================] - 1s 3ms/step - loss: 0.8211 - accuracy: 0.6700 - val_loss: 0.6873 - val_accuracy: 0.7327\n",
      "Epoch 2/1000\n",
      "225/225 [==============================] - 1s 3ms/step - loss: 0.7286 - accuracy: 0.7254 - val_loss: 0.6721 - val_accuracy: 0.7374\n",
      "Epoch 3/1000\n",
      "225/225 [==============================] - 1s 2ms/step - loss: 0.7080 - accuracy: 0.7308 - val_loss: 0.6626 - val_accuracy: 0.7455\n",
      "Epoch 4/1000\n",
      "225/225 [==============================] - 1s 3ms/step - loss: 0.6969 - accuracy: 0.7356 - val_loss: 0.6545 - val_accuracy: 0.7455\n",
      "Epoch 5/1000\n",
      "225/225 [==============================] - 1s 2ms/step - loss: 0.6893 - accuracy: 0.7377 - val_loss: 0.6515 - val_accuracy: 0.7479\n",
      "Epoch 6/1000\n",
      "225/225 [==============================] - 1s 2ms/step - loss: 0.6841 - accuracy: 0.7393 - val_loss: 0.6471 - val_accuracy: 0.7487\n",
      "Epoch 7/1000\n",
      "225/225 [==============================] - 1s 2ms/step - loss: 0.6789 - accuracy: 0.7399 - val_loss: 0.6383 - val_accuracy: 0.7498\n",
      "Epoch 8/1000\n",
      "225/225 [==============================] - 1s 2ms/step - loss: 0.6733 - accuracy: 0.7417 - val_loss: 0.6376 - val_accuracy: 0.7489\n",
      "Epoch 9/1000\n",
      "225/225 [==============================] - 1s 2ms/step - loss: 0.6685 - accuracy: 0.7431 - val_loss: 0.6343 - val_accuracy: 0.7516\n",
      "Epoch 10/1000\n",
      "225/225 [==============================] - 1s 2ms/step - loss: 0.6663 - accuracy: 0.7437 - val_loss: 0.6322 - val_accuracy: 0.7523\n",
      "Epoch 11/1000\n",
      "225/225 [==============================] - 1s 2ms/step - loss: 0.6617 - accuracy: 0.7454 - val_loss: 0.6263 - val_accuracy: 0.7538\n",
      "Epoch 12/1000\n",
      "225/225 [==============================] - 1s 2ms/step - loss: 0.6578 - accuracy: 0.7471 - val_loss: 0.6235 - val_accuracy: 0.7531\n",
      "Epoch 13/1000\n",
      "225/225 [==============================] - 1s 2ms/step - loss: 0.6541 - accuracy: 0.7467 - val_loss: 0.6204 - val_accuracy: 0.7544\n",
      "Epoch 14/1000\n",
      "225/225 [==============================] - 1s 2ms/step - loss: 0.6510 - accuracy: 0.7479 - val_loss: 0.6157 - val_accuracy: 0.7570\n",
      "Epoch 15/1000\n",
      "225/225 [==============================] - 1s 2ms/step - loss: 0.6484 - accuracy: 0.7487 - val_loss: 0.6138 - val_accuracy: 0.7582\n",
      "Epoch 16/1000\n",
      "225/225 [==============================] - 1s 2ms/step - loss: 0.6460 - accuracy: 0.7497 - val_loss: 0.6122 - val_accuracy: 0.7571\n",
      "Epoch 17/1000\n",
      "225/225 [==============================] - 1s 2ms/step - loss: 0.6439 - accuracy: 0.7506 - val_loss: 0.6096 - val_accuracy: 0.7593\n",
      "Epoch 18/1000\n",
      "225/225 [==============================] - 1s 2ms/step - loss: 0.6414 - accuracy: 0.7520 - val_loss: 0.6072 - val_accuracy: 0.7608\n",
      "Epoch 19/1000\n",
      "225/225 [==============================] - 1s 2ms/step - loss: 0.6402 - accuracy: 0.7522 - val_loss: 0.6039 - val_accuracy: 0.7623\n",
      "Epoch 20/1000\n",
      "225/225 [==============================] - 1s 2ms/step - loss: 0.6341 - accuracy: 0.7534 - val_loss: 0.6000 - val_accuracy: 0.7630\n",
      "Epoch 21/1000\n",
      "225/225 [==============================] - 1s 3ms/step - loss: 0.6337 - accuracy: 0.7541 - val_loss: 0.5993 - val_accuracy: 0.7611\n",
      "Epoch 22/1000\n",
      "225/225 [==============================] - 1s 2ms/step - loss: 0.6317 - accuracy: 0.7538 - val_loss: 0.5965 - val_accuracy: 0.7647\n",
      "Epoch 23/1000\n",
      "225/225 [==============================] - 1s 2ms/step - loss: 0.6306 - accuracy: 0.7551 - val_loss: 0.5959 - val_accuracy: 0.7657\n",
      "Epoch 24/1000\n",
      "225/225 [==============================] - 1s 2ms/step - loss: 0.6274 - accuracy: 0.7564 - val_loss: 0.5917 - val_accuracy: 0.7659\n",
      "Epoch 25/1000\n",
      "225/225 [==============================] - 1s 2ms/step - loss: 0.6263 - accuracy: 0.7558 - val_loss: 0.5879 - val_accuracy: 0.7687\n",
      "Epoch 26/1000\n",
      "225/225 [==============================] - 1s 2ms/step - loss: 0.6233 - accuracy: 0.7584 - val_loss: 0.5897 - val_accuracy: 0.7662\n",
      "Epoch 27/1000\n",
      "225/225 [==============================] - 1s 2ms/step - loss: 0.6208 - accuracy: 0.7577 - val_loss: 0.5864 - val_accuracy: 0.7662\n",
      "Epoch 28/1000\n",
      "225/225 [==============================] - 1s 2ms/step - loss: 0.6192 - accuracy: 0.7590 - val_loss: 0.5839 - val_accuracy: 0.7679\n",
      "Epoch 29/1000\n",
      "225/225 [==============================] - 1s 2ms/step - loss: 0.6184 - accuracy: 0.7593 - val_loss: 0.5856 - val_accuracy: 0.7700\n",
      "Epoch 30/1000\n",
      "225/225 [==============================] - 1s 2ms/step - loss: 0.6165 - accuracy: 0.7593 - val_loss: 0.5816 - val_accuracy: 0.7687\n",
      "Epoch 31/1000\n",
      "225/225 [==============================] - 1s 2ms/step - loss: 0.6154 - accuracy: 0.7605 - val_loss: 0.5784 - val_accuracy: 0.7698\n",
      "Epoch 32/1000\n",
      "225/225 [==============================] - 1s 2ms/step - loss: 0.6138 - accuracy: 0.7606 - val_loss: 0.5760 - val_accuracy: 0.7709\n",
      "Epoch 33/1000\n",
      "225/225 [==============================] - 1s 2ms/step - loss: 0.6119 - accuracy: 0.7594 - val_loss: 0.5756 - val_accuracy: 0.7720\n",
      "Epoch 34/1000\n",
      "225/225 [==============================] - 1s 2ms/step - loss: 0.6104 - accuracy: 0.7612 - val_loss: 0.5715 - val_accuracy: 0.7741\n",
      "Epoch 35/1000\n",
      "225/225 [==============================] - 1s 2ms/step - loss: 0.6095 - accuracy: 0.7621 - val_loss: 0.5691 - val_accuracy: 0.7727\n",
      "Epoch 36/1000\n",
      "225/225 [==============================] - 1s 2ms/step - loss: 0.6082 - accuracy: 0.7621 - val_loss: 0.5682 - val_accuracy: 0.7756\n",
      "Epoch 37/1000\n",
      "225/225 [==============================] - 1s 2ms/step - loss: 0.6059 - accuracy: 0.7630 - val_loss: 0.5651 - val_accuracy: 0.7744\n",
      "Epoch 38/1000\n",
      "225/225 [==============================] - 1s 3ms/step - loss: 0.6048 - accuracy: 0.7635 - val_loss: 0.5676 - val_accuracy: 0.7740\n",
      "Epoch 39/1000\n",
      "225/225 [==============================] - 1s 2ms/step - loss: 0.6041 - accuracy: 0.7642 - val_loss: 0.5630 - val_accuracy: 0.7738\n",
      "Epoch 40/1000\n",
      "225/225 [==============================] - 1s 2ms/step - loss: 0.6023 - accuracy: 0.7634 - val_loss: 0.5633 - val_accuracy: 0.7766\n",
      "Epoch 41/1000\n",
      "225/225 [==============================] - 1s 2ms/step - loss: 0.6007 - accuracy: 0.7642 - val_loss: 0.5609 - val_accuracy: 0.7759\n",
      "Epoch 42/1000\n",
      "225/225 [==============================] - 1s 2ms/step - loss: 0.5997 - accuracy: 0.7641 - val_loss: 0.5591 - val_accuracy: 0.7754\n",
      "Epoch 43/1000\n",
      "225/225 [==============================] - 1s 2ms/step - loss: 0.5988 - accuracy: 0.7655 - val_loss: 0.5585 - val_accuracy: 0.7774\n",
      "Epoch 44/1000\n",
      "225/225 [==============================] - 1s 2ms/step - loss: 0.5974 - accuracy: 0.7658 - val_loss: 0.5589 - val_accuracy: 0.7781\n",
      "Epoch 45/1000\n",
      "225/225 [==============================] - 1s 2ms/step - loss: 0.5966 - accuracy: 0.7659 - val_loss: 0.5553 - val_accuracy: 0.7785\n",
      "Epoch 46/1000\n",
      "225/225 [==============================] - 1s 2ms/step - loss: 0.5940 - accuracy: 0.7667 - val_loss: 0.5546 - val_accuracy: 0.7788\n",
      "Epoch 47/1000\n",
      "225/225 [==============================] - 1s 2ms/step - loss: 0.5952 - accuracy: 0.7671 - val_loss: 0.5513 - val_accuracy: 0.7802\n",
      "Epoch 48/1000\n",
      "225/225 [==============================] - 1s 2ms/step - loss: 0.5952 - accuracy: 0.7661 - val_loss: 0.5505 - val_accuracy: 0.7813\n",
      "Epoch 49/1000\n",
      "225/225 [==============================] - 1s 2ms/step - loss: 0.5939 - accuracy: 0.7670 - val_loss: 0.5478 - val_accuracy: 0.7816\n",
      "Epoch 50/1000\n",
      "225/225 [==============================] - 1s 2ms/step - loss: 0.5921 - accuracy: 0.7671 - val_loss: 0.5478 - val_accuracy: 0.7813\n",
      "Epoch 51/1000\n",
      "225/225 [==============================] - 1s 2ms/step - loss: 0.5917 - accuracy: 0.7673 - val_loss: 0.5495 - val_accuracy: 0.7813\n",
      "Epoch 52/1000\n",
      "225/225 [==============================] - 1s 3ms/step - loss: 0.5912 - accuracy: 0.7673 - val_loss: 0.5488 - val_accuracy: 0.7827\n",
      "Epoch 53/1000\n",
      "225/225 [==============================] - 1s 2ms/step - loss: 0.5919 - accuracy: 0.7677 - val_loss: 0.5445 - val_accuracy: 0.7826\n",
      "Epoch 54/1000\n",
      "225/225 [==============================] - 1s 2ms/step - loss: 0.5889 - accuracy: 0.7679 - val_loss: 0.5419 - val_accuracy: 0.7839\n",
      "Epoch 55/1000\n",
      "225/225 [==============================] - 1s 2ms/step - loss: 0.5891 - accuracy: 0.7681 - val_loss: 0.5441 - val_accuracy: 0.7825\n",
      "Epoch 56/1000\n",
      "225/225 [==============================] - 1s 2ms/step - loss: 0.5872 - accuracy: 0.7706 - val_loss: 0.5419 - val_accuracy: 0.7840\n",
      "Epoch 57/1000\n",
      "225/225 [==============================] - 1s 2ms/step - loss: 0.5876 - accuracy: 0.7705 - val_loss: 0.5414 - val_accuracy: 0.7810\n",
      "Epoch 58/1000\n",
      "225/225 [==============================] - 1s 2ms/step - loss: 0.5853 - accuracy: 0.7695 - val_loss: 0.5402 - val_accuracy: 0.7845\n",
      "Epoch 59/1000\n",
      "225/225 [==============================] - 1s 2ms/step - loss: 0.5879 - accuracy: 0.7689 - val_loss: 0.5400 - val_accuracy: 0.7847\n",
      "Epoch 60/1000\n",
      "225/225 [==============================] - 1s 2ms/step - loss: 0.5861 - accuracy: 0.7691 - val_loss: 0.5354 - val_accuracy: 0.7880\n",
      "Epoch 61/1000\n",
      "225/225 [==============================] - 1s 2ms/step - loss: 0.5826 - accuracy: 0.7710 - val_loss: 0.5382 - val_accuracy: 0.7870\n",
      "Epoch 62/1000\n",
      "225/225 [==============================] - 1s 2ms/step - loss: 0.5820 - accuracy: 0.7715 - val_loss: 0.5368 - val_accuracy: 0.7871\n",
      "Epoch 63/1000\n",
      "225/225 [==============================] - 1s 2ms/step - loss: 0.5823 - accuracy: 0.7705 - val_loss: 0.5382 - val_accuracy: 0.7850\n",
      "Epoch 64/1000\n",
      "225/225 [==============================] - 1s 2ms/step - loss: 0.5815 - accuracy: 0.7714 - val_loss: 0.5334 - val_accuracy: 0.7888\n",
      "Epoch 65/1000\n",
      "225/225 [==============================] - 1s 3ms/step - loss: 0.5826 - accuracy: 0.7717 - val_loss: 0.5338 - val_accuracy: 0.7892\n",
      "Epoch 66/1000\n",
      "225/225 [==============================] - 1s 2ms/step - loss: 0.5799 - accuracy: 0.7717 - val_loss: 0.5327 - val_accuracy: 0.7855\n",
      "Epoch 67/1000\n",
      "225/225 [==============================] - 1s 2ms/step - loss: 0.5796 - accuracy: 0.7713 - val_loss: 0.5317 - val_accuracy: 0.7886\n",
      "Epoch 68/1000\n",
      "225/225 [==============================] - 1s 2ms/step - loss: 0.5801 - accuracy: 0.7706 - val_loss: 0.5335 - val_accuracy: 0.7860\n",
      "Epoch 69/1000\n",
      "225/225 [==============================] - 1s 2ms/step - loss: 0.5793 - accuracy: 0.7720 - val_loss: 0.5296 - val_accuracy: 0.7889\n",
      "Epoch 70/1000\n",
      "225/225 [==============================] - 1s 2ms/step - loss: 0.5781 - accuracy: 0.7722 - val_loss: 0.5330 - val_accuracy: 0.7882\n",
      "Epoch 71/1000\n",
      "225/225 [==============================] - 1s 3ms/step - loss: 0.5785 - accuracy: 0.7724 - val_loss: 0.5291 - val_accuracy: 0.7890\n",
      "Epoch 72/1000\n",
      "225/225 [==============================] - 1s 3ms/step - loss: 0.5777 - accuracy: 0.7724 - val_loss: 0.5279 - val_accuracy: 0.7923\n",
      "Epoch 73/1000\n",
      "225/225 [==============================] - 1s 2ms/step - loss: 0.5792 - accuracy: 0.7727 - val_loss: 0.5316 - val_accuracy: 0.7856\n",
      "Epoch 74/1000\n",
      "225/225 [==============================] - 1s 2ms/step - loss: 0.5777 - accuracy: 0.7727 - val_loss: 0.5295 - val_accuracy: 0.7898\n",
      "Epoch 75/1000\n",
      "225/225 [==============================] - 1s 2ms/step - loss: 0.5766 - accuracy: 0.7720 - val_loss: 0.5279 - val_accuracy: 0.7923\n",
      "Epoch 76/1000\n",
      "225/225 [==============================] - 1s 2ms/step - loss: 0.5751 - accuracy: 0.7737 - val_loss: 0.5312 - val_accuracy: 0.7909\n",
      "Epoch 77/1000\n",
      "225/225 [==============================] - 1s 2ms/step - loss: 0.5753 - accuracy: 0.7738 - val_loss: 0.5245 - val_accuracy: 0.7891\n",
      "Epoch 78/1000\n",
      "225/225 [==============================] - 1s 2ms/step - loss: 0.5749 - accuracy: 0.7741 - val_loss: 0.5275 - val_accuracy: 0.7907\n",
      "Epoch 79/1000\n",
      "225/225 [==============================] - 1s 2ms/step - loss: 0.5740 - accuracy: 0.7756 - val_loss: 0.5265 - val_accuracy: 0.7894\n",
      "Epoch 80/1000\n",
      "225/225 [==============================] - 1s 2ms/step - loss: 0.5728 - accuracy: 0.7740 - val_loss: 0.5240 - val_accuracy: 0.7885\n",
      "Epoch 81/1000\n",
      "225/225 [==============================] - 1s 3ms/step - loss: 0.5725 - accuracy: 0.7744 - val_loss: 0.5223 - val_accuracy: 0.7921\n",
      "Epoch 82/1000\n",
      "225/225 [==============================] - 1s 2ms/step - loss: 0.5738 - accuracy: 0.7740 - val_loss: 0.5194 - val_accuracy: 0.7928\n",
      "Epoch 83/1000\n",
      "225/225 [==============================] - 1s 2ms/step - loss: 0.5720 - accuracy: 0.7753 - val_loss: 0.5222 - val_accuracy: 0.7908\n",
      "Epoch 84/1000\n",
      "225/225 [==============================] - 1s 2ms/step - loss: 0.5731 - accuracy: 0.7749 - val_loss: 0.5202 - val_accuracy: 0.7928\n",
      "Epoch 85/1000\n",
      "225/225 [==============================] - 1s 2ms/step - loss: 0.5702 - accuracy: 0.7748 - val_loss: 0.5179 - val_accuracy: 0.7927\n",
      "Epoch 86/1000\n",
      "225/225 [==============================] - 1s 2ms/step - loss: 0.5726 - accuracy: 0.7735 - val_loss: 0.5235 - val_accuracy: 0.7929\n",
      "Epoch 87/1000\n",
      "225/225 [==============================] - 1s 2ms/step - loss: 0.5703 - accuracy: 0.7757 - val_loss: 0.5200 - val_accuracy: 0.7933\n",
      "Epoch 88/1000\n",
      "225/225 [==============================] - 1s 3ms/step - loss: 0.5692 - accuracy: 0.7773 - val_loss: 0.5193 - val_accuracy: 0.7937\n",
      "Epoch 89/1000\n",
      "225/225 [==============================] - 1s 2ms/step - loss: 0.5704 - accuracy: 0.7764 - val_loss: 0.5180 - val_accuracy: 0.7940\n",
      "Epoch 90/1000\n",
      "225/225 [==============================] - 1s 2ms/step - loss: 0.5695 - accuracy: 0.7768 - val_loss: 0.5164 - val_accuracy: 0.7955\n",
      "Epoch 91/1000\n",
      "225/225 [==============================] - 1s 2ms/step - loss: 0.5685 - accuracy: 0.7765 - val_loss: 0.5168 - val_accuracy: 0.7942\n",
      "Epoch 92/1000\n",
      "225/225 [==============================] - 1s 2ms/step - loss: 0.5683 - accuracy: 0.7766 - val_loss: 0.5143 - val_accuracy: 0.7984\n",
      "Epoch 93/1000\n",
      "225/225 [==============================] - 1s 2ms/step - loss: 0.5679 - accuracy: 0.7763 - val_loss: 0.5218 - val_accuracy: 0.7905\n",
      "Epoch 94/1000\n",
      "225/225 [==============================] - 1s 2ms/step - loss: 0.5688 - accuracy: 0.7763 - val_loss: 0.5176 - val_accuracy: 0.7941\n",
      "Epoch 95/1000\n",
      "225/225 [==============================] - 1s 2ms/step - loss: 0.5672 - accuracy: 0.7766 - val_loss: 0.5152 - val_accuracy: 0.7976\n",
      "Epoch 96/1000\n",
      "225/225 [==============================] - 1s 2ms/step - loss: 0.5644 - accuracy: 0.7772 - val_loss: 0.5131 - val_accuracy: 0.7970\n",
      "Epoch 97/1000\n",
      "225/225 [==============================] - 1s 2ms/step - loss: 0.5662 - accuracy: 0.7776 - val_loss: 0.5145 - val_accuracy: 0.7948\n",
      "Epoch 98/1000\n",
      "225/225 [==============================] - 1s 2ms/step - loss: 0.5658 - accuracy: 0.7766 - val_loss: 0.5138 - val_accuracy: 0.7952\n",
      "Epoch 99/1000\n",
      "225/225 [==============================] - 1s 2ms/step - loss: 0.5676 - accuracy: 0.7772 - val_loss: 0.5127 - val_accuracy: 0.7974\n",
      "Epoch 100/1000\n",
      "225/225 [==============================] - 1s 2ms/step - loss: 0.5652 - accuracy: 0.7772 - val_loss: 0.5137 - val_accuracy: 0.7960\n",
      "Epoch 101/1000\n",
      "225/225 [==============================] - 1s 2ms/step - loss: 0.5659 - accuracy: 0.7773 - val_loss: 0.5135 - val_accuracy: 0.7956\n",
      "Epoch 102/1000\n",
      "225/225 [==============================] - 1s 3ms/step - loss: 0.5627 - accuracy: 0.7782 - val_loss: 0.5122 - val_accuracy: 0.7986\n",
      "Epoch 103/1000\n",
      "225/225 [==============================] - 1s 2ms/step - loss: 0.5622 - accuracy: 0.7793 - val_loss: 0.5103 - val_accuracy: 0.7983\n",
      "Epoch 104/1000\n",
      "225/225 [==============================] - 1s 2ms/step - loss: 0.5646 - accuracy: 0.7778 - val_loss: 0.5135 - val_accuracy: 0.7949\n",
      "Epoch 105/1000\n",
      "225/225 [==============================] - 1s 2ms/step - loss: 0.5642 - accuracy: 0.7777 - val_loss: 0.5087 - val_accuracy: 0.7955\n",
      "Epoch 106/1000\n",
      "225/225 [==============================] - 1s 2ms/step - loss: 0.5628 - accuracy: 0.7790 - val_loss: 0.5081 - val_accuracy: 0.7988\n",
      "Epoch 107/1000\n",
      "225/225 [==============================] - 1s 2ms/step - loss: 0.5612 - accuracy: 0.7789 - val_loss: 0.5095 - val_accuracy: 0.7981\n",
      "Epoch 108/1000\n",
      "225/225 [==============================] - 1s 2ms/step - loss: 0.5628 - accuracy: 0.7781 - val_loss: 0.5088 - val_accuracy: 0.7986\n",
      "Epoch 109/1000\n",
      "225/225 [==============================] - 1s 2ms/step - loss: 0.5620 - accuracy: 0.7785 - val_loss: 0.5071 - val_accuracy: 0.7992\n",
      "Epoch 110/1000\n",
      "225/225 [==============================] - 1s 2ms/step - loss: 0.5623 - accuracy: 0.7790 - val_loss: 0.5088 - val_accuracy: 0.7981\n",
      "Epoch 111/1000\n",
      "225/225 [==============================] - 1s 2ms/step - loss: 0.5610 - accuracy: 0.7789 - val_loss: 0.5077 - val_accuracy: 0.7984\n",
      "Epoch 112/1000\n",
      "225/225 [==============================] - 1s 2ms/step - loss: 0.5596 - accuracy: 0.7798 - val_loss: 0.5074 - val_accuracy: 0.7984\n",
      "Epoch 113/1000\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "225/225 [==============================] - 1s 2ms/step - loss: 0.5605 - accuracy: 0.7792 - val_loss: 0.5067 - val_accuracy: 0.7992\n",
      "Epoch 114/1000\n",
      "225/225 [==============================] - 1s 2ms/step - loss: 0.5606 - accuracy: 0.7799 - val_loss: 0.5064 - val_accuracy: 0.7974\n",
      "Epoch 115/1000\n",
      "225/225 [==============================] - 1s 2ms/step - loss: 0.5605 - accuracy: 0.7793 - val_loss: 0.5076 - val_accuracy: 0.7967\n",
      "Epoch 116/1000\n",
      "225/225 [==============================] - 1s 2ms/step - loss: 0.5578 - accuracy: 0.7794 - val_loss: 0.5058 - val_accuracy: 0.7986\n",
      "Epoch 117/1000\n",
      "225/225 [==============================] - 1s 2ms/step - loss: 0.5607 - accuracy: 0.7788 - val_loss: 0.5066 - val_accuracy: 0.7992\n",
      "Epoch 118/1000\n",
      "225/225 [==============================] - 1s 2ms/step - loss: 0.5606 - accuracy: 0.7795 - val_loss: 0.5074 - val_accuracy: 0.7967\n",
      "Epoch 119/1000\n",
      "225/225 [==============================] - 1s 2ms/step - loss: 0.5607 - accuracy: 0.7793 - val_loss: 0.5059 - val_accuracy: 0.7978\n",
      "Epoch 120/1000\n",
      "225/225 [==============================] - 1s 2ms/step - loss: 0.5583 - accuracy: 0.7798 - val_loss: 0.5071 - val_accuracy: 0.7983\n",
      "Epoch 121/1000\n",
      "225/225 [==============================] - 1s 2ms/step - loss: 0.5596 - accuracy: 0.7802 - val_loss: 0.5071 - val_accuracy: 0.7966\n",
      "Epoch 122/1000\n",
      "225/225 [==============================] - 1s 2ms/step - loss: 0.5574 - accuracy: 0.7796 - val_loss: 0.5047 - val_accuracy: 0.7958\n",
      "Epoch 123/1000\n",
      "225/225 [==============================] - 1s 2ms/step - loss: 0.5582 - accuracy: 0.7803 - val_loss: 0.5051 - val_accuracy: 0.7970\n",
      "Epoch 124/1000\n",
      "225/225 [==============================] - 1s 2ms/step - loss: 0.5568 - accuracy: 0.7810 - val_loss: 0.5023 - val_accuracy: 0.7981\n",
      "Epoch 125/1000\n",
      "225/225 [==============================] - 1s 2ms/step - loss: 0.5557 - accuracy: 0.7809 - val_loss: 0.5049 - val_accuracy: 0.7985\n",
      "Epoch 126/1000\n",
      "225/225 [==============================] - 1s 2ms/step - loss: 0.5568 - accuracy: 0.7790 - val_loss: 0.5078 - val_accuracy: 0.7981\n",
      "Epoch 127/1000\n",
      "225/225 [==============================] - 1s 2ms/step - loss: 0.5576 - accuracy: 0.7795 - val_loss: 0.5045 - val_accuracy: 0.7966\n",
      "Epoch 128/1000\n",
      "225/225 [==============================] - 1s 2ms/step - loss: 0.5567 - accuracy: 0.7810 - val_loss: 0.5048 - val_accuracy: 0.7994\n",
      "Epoch 129/1000\n",
      "225/225 [==============================] - 1s 2ms/step - loss: 0.5562 - accuracy: 0.7805 - val_loss: 0.5063 - val_accuracy: 0.7976\n",
      "Epoch 130/1000\n",
      "225/225 [==============================] - 1s 2ms/step - loss: 0.5562 - accuracy: 0.7810 - val_loss: 0.5049 - val_accuracy: 0.7981\n",
      "Epoch 131/1000\n",
      "225/225 [==============================] - 1s 2ms/step - loss: 0.5574 - accuracy: 0.7803 - val_loss: 0.5021 - val_accuracy: 0.7992\n",
      "Epoch 132/1000\n",
      "225/225 [==============================] - 1s 2ms/step - loss: 0.5564 - accuracy: 0.7804 - val_loss: 0.5009 - val_accuracy: 0.7992\n",
      "Epoch 133/1000\n",
      "225/225 [==============================] - 1s 2ms/step - loss: 0.5567 - accuracy: 0.7801 - val_loss: 0.5000 - val_accuracy: 0.8015\n",
      "Epoch 134/1000\n",
      "225/225 [==============================] - 1s 2ms/step - loss: 0.5550 - accuracy: 0.7817 - val_loss: 0.5033 - val_accuracy: 0.8018\n",
      "Epoch 135/1000\n",
      "225/225 [==============================] - 1s 2ms/step - loss: 0.5553 - accuracy: 0.7804 - val_loss: 0.4987 - val_accuracy: 0.8013\n",
      "Epoch 136/1000\n",
      "225/225 [==============================] - 1s 2ms/step - loss: 0.5553 - accuracy: 0.7804 - val_loss: 0.5025 - val_accuracy: 0.7989\n",
      "Epoch 137/1000\n",
      "225/225 [==============================] - 1s 2ms/step - loss: 0.5559 - accuracy: 0.7822 - val_loss: 0.5039 - val_accuracy: 0.7982\n",
      "Epoch 138/1000\n",
      "225/225 [==============================] - 1s 2ms/step - loss: 0.5544 - accuracy: 0.7821 - val_loss: 0.4971 - val_accuracy: 0.8024\n",
      "Epoch 139/1000\n",
      "225/225 [==============================] - 1s 2ms/step - loss: 0.5545 - accuracy: 0.7808 - val_loss: 0.5007 - val_accuracy: 0.8011\n",
      "Epoch 140/1000\n",
      "225/225 [==============================] - 1s 2ms/step - loss: 0.5544 - accuracy: 0.7823 - val_loss: 0.4994 - val_accuracy: 0.8033\n",
      "Epoch 141/1000\n",
      "225/225 [==============================] - 1s 2ms/step - loss: 0.5550 - accuracy: 0.7802 - val_loss: 0.4967 - val_accuracy: 0.8044\n",
      "Epoch 142/1000\n",
      "225/225 [==============================] - 1s 2ms/step - loss: 0.5534 - accuracy: 0.7817 - val_loss: 0.4970 - val_accuracy: 0.8046\n",
      "Epoch 143/1000\n",
      "225/225 [==============================] - 1s 2ms/step - loss: 0.5541 - accuracy: 0.7817 - val_loss: 0.4982 - val_accuracy: 0.8030\n",
      "Epoch 144/1000\n",
      "225/225 [==============================] - 1s 2ms/step - loss: 0.5523 - accuracy: 0.7827 - val_loss: 0.4963 - val_accuracy: 0.8046\n",
      "Epoch 145/1000\n",
      "225/225 [==============================] - 1s 2ms/step - loss: 0.5534 - accuracy: 0.7820 - val_loss: 0.4983 - val_accuracy: 0.8009\n",
      "Epoch 146/1000\n",
      "225/225 [==============================] - 1s 2ms/step - loss: 0.5507 - accuracy: 0.7818 - val_loss: 0.4957 - val_accuracy: 0.8056\n",
      "Epoch 147/1000\n",
      "225/225 [==============================] - 1s 2ms/step - loss: 0.5532 - accuracy: 0.7824 - val_loss: 0.4969 - val_accuracy: 0.8036\n",
      "Epoch 148/1000\n",
      "225/225 [==============================] - 1s 2ms/step - loss: 0.5545 - accuracy: 0.7816 - val_loss: 0.4970 - val_accuracy: 0.8015\n",
      "Epoch 149/1000\n",
      "225/225 [==============================] - 1s 2ms/step - loss: 0.5542 - accuracy: 0.7814 - val_loss: 0.4968 - val_accuracy: 0.8038\n",
      "Epoch 150/1000\n",
      "225/225 [==============================] - 1s 2ms/step - loss: 0.5530 - accuracy: 0.7819 - val_loss: 0.4977 - val_accuracy: 0.8002\n",
      "Epoch 151/1000\n",
      "225/225 [==============================] - 1s 2ms/step - loss: 0.5525 - accuracy: 0.7820 - val_loss: 0.4975 - val_accuracy: 0.8039\n",
      "Epoch 152/1000\n",
      "225/225 [==============================] - 1s 2ms/step - loss: 0.5519 - accuracy: 0.7827 - val_loss: 0.4929 - val_accuracy: 0.8050\n",
      "Epoch 153/1000\n",
      "225/225 [==============================] - 1s 3ms/step - loss: 0.5508 - accuracy: 0.7829 - val_loss: 0.4972 - val_accuracy: 0.8023\n",
      "Epoch 154/1000\n",
      "225/225 [==============================] - 1s 2ms/step - loss: 0.5520 - accuracy: 0.7826 - val_loss: 0.4971 - val_accuracy: 0.7999\n",
      "Epoch 155/1000\n",
      "225/225 [==============================] - 1s 2ms/step - loss: 0.5521 - accuracy: 0.7827 - val_loss: 0.4959 - val_accuracy: 0.8044\n",
      "Epoch 156/1000\n",
      "225/225 [==============================] - 1s 2ms/step - loss: 0.5525 - accuracy: 0.7818 - val_loss: 0.4953 - val_accuracy: 0.8046\n",
      "Epoch 157/1000\n",
      "225/225 [==============================] - 1s 2ms/step - loss: 0.5497 - accuracy: 0.7833 - val_loss: 0.4946 - val_accuracy: 0.8060\n",
      "Epoch 158/1000\n",
      "225/225 [==============================] - 1s 2ms/step - loss: 0.5521 - accuracy: 0.7827 - val_loss: 0.4966 - val_accuracy: 0.8020\n",
      "Epoch 159/1000\n",
      "225/225 [==============================] - 1s 2ms/step - loss: 0.5500 - accuracy: 0.7833 - val_loss: 0.4942 - val_accuracy: 0.8046\n",
      "Epoch 160/1000\n",
      "225/225 [==============================] - 1s 2ms/step - loss: 0.5491 - accuracy: 0.7840 - val_loss: 0.4909 - val_accuracy: 0.8052\n",
      "Epoch 161/1000\n",
      "225/225 [==============================] - 1s 2ms/step - loss: 0.5504 - accuracy: 0.7837 - val_loss: 0.4910 - val_accuracy: 0.8046\n",
      "Epoch 162/1000\n",
      "225/225 [==============================] - 1s 2ms/step - loss: 0.5499 - accuracy: 0.7836 - val_loss: 0.4951 - val_accuracy: 0.8046\n",
      "Epoch 163/1000\n",
      "225/225 [==============================] - 1s 2ms/step - loss: 0.5508 - accuracy: 0.7846 - val_loss: 0.4903 - val_accuracy: 0.8039\n",
      "Epoch 164/1000\n",
      "225/225 [==============================] - 1s 2ms/step - loss: 0.5502 - accuracy: 0.7832 - val_loss: 0.4913 - val_accuracy: 0.8046\n",
      "Epoch 165/1000\n",
      "225/225 [==============================] - 1s 2ms/step - loss: 0.5528 - accuracy: 0.7832 - val_loss: 0.4915 - val_accuracy: 0.8064\n",
      "Epoch 166/1000\n",
      "225/225 [==============================] - 1s 2ms/step - loss: 0.5500 - accuracy: 0.7840 - val_loss: 0.4930 - val_accuracy: 0.8037\n",
      "Epoch 167/1000\n",
      "225/225 [==============================] - 1s 2ms/step - loss: 0.5500 - accuracy: 0.7840 - val_loss: 0.4951 - val_accuracy: 0.8039\n",
      "Epoch 168/1000\n",
      "225/225 [==============================] - 1s 2ms/step - loss: 0.5483 - accuracy: 0.7847 - val_loss: 0.4919 - val_accuracy: 0.8021\n",
      "Epoch 169/1000\n",
      "225/225 [==============================] - 1s 2ms/step - loss: 0.5487 - accuracy: 0.7844 - val_loss: 0.4920 - val_accuracy: 0.8045\n",
      "Epoch 170/1000\n",
      "225/225 [==============================] - 1s 2ms/step - loss: 0.5484 - accuracy: 0.7841 - val_loss: 0.4905 - val_accuracy: 0.8037\n",
      "Epoch 171/1000\n",
      "225/225 [==============================] - 1s 2ms/step - loss: 0.5473 - accuracy: 0.7836 - val_loss: 0.4902 - val_accuracy: 0.8051\n",
      "Epoch 172/1000\n",
      "225/225 [==============================] - 1s 2ms/step - loss: 0.5509 - accuracy: 0.7832 - val_loss: 0.4894 - val_accuracy: 0.8067\n",
      "Epoch 173/1000\n",
      "225/225 [==============================] - 1s 2ms/step - loss: 0.5476 - accuracy: 0.7843 - val_loss: 0.4894 - val_accuracy: 0.8057\n",
      "Epoch 174/1000\n",
      "225/225 [==============================] - 1s 2ms/step - loss: 0.5489 - accuracy: 0.7833 - val_loss: 0.4904 - val_accuracy: 0.8056\n",
      "Epoch 175/1000\n",
      "225/225 [==============================] - 1s 2ms/step - loss: 0.5494 - accuracy: 0.7841 - val_loss: 0.4898 - val_accuracy: 0.8064\n",
      "Epoch 176/1000\n",
      "225/225 [==============================] - 1s 2ms/step - loss: 0.5484 - accuracy: 0.7840 - val_loss: 0.4892 - val_accuracy: 0.8042\n",
      "Epoch 177/1000\n",
      "225/225 [==============================] - 1s 2ms/step - loss: 0.5464 - accuracy: 0.7842 - val_loss: 0.4888 - val_accuracy: 0.8071\n",
      "Epoch 178/1000\n",
      "225/225 [==============================] - 1s 2ms/step - loss: 0.5490 - accuracy: 0.7845 - val_loss: 0.4907 - val_accuracy: 0.8068\n",
      "Epoch 179/1000\n",
      "225/225 [==============================] - 1s 2ms/step - loss: 0.5470 - accuracy: 0.7851 - val_loss: 0.4899 - val_accuracy: 0.8064\n",
      "Epoch 180/1000\n",
      "225/225 [==============================] - 1s 2ms/step - loss: 0.5481 - accuracy: 0.7844 - val_loss: 0.4922 - val_accuracy: 0.8063\n",
      "Epoch 181/1000\n",
      "225/225 [==============================] - 1s 2ms/step - loss: 0.5469 - accuracy: 0.7843 - val_loss: 0.4902 - val_accuracy: 0.8042\n",
      "Epoch 182/1000\n",
      "225/225 [==============================] - 1s 2ms/step - loss: 0.5475 - accuracy: 0.7846 - val_loss: 0.4851 - val_accuracy: 0.8075\n",
      "Epoch 183/1000\n",
      "225/225 [==============================] - 1s 2ms/step - loss: 0.5458 - accuracy: 0.7855 - val_loss: 0.4883 - val_accuracy: 0.8070\n",
      "Epoch 184/1000\n",
      "225/225 [==============================] - 1s 2ms/step - loss: 0.5463 - accuracy: 0.7842 - val_loss: 0.4871 - val_accuracy: 0.8068\n",
      "Epoch 185/1000\n",
      "225/225 [==============================] - 1s 2ms/step - loss: 0.5486 - accuracy: 0.7841 - val_loss: 0.4935 - val_accuracy: 0.8090\n",
      "Epoch 186/1000\n",
      "225/225 [==============================] - 1s 2ms/step - loss: 0.5452 - accuracy: 0.7861 - val_loss: 0.4870 - val_accuracy: 0.8065\n",
      "Epoch 187/1000\n",
      "225/225 [==============================] - 1s 2ms/step - loss: 0.5468 - accuracy: 0.7845 - val_loss: 0.4909 - val_accuracy: 0.8067\n",
      "Epoch 188/1000\n",
      "225/225 [==============================] - 1s 2ms/step - loss: 0.5443 - accuracy: 0.7863 - val_loss: 0.4903 - val_accuracy: 0.8066\n",
      "Epoch 189/1000\n",
      "225/225 [==============================] - 1s 2ms/step - loss: 0.5470 - accuracy: 0.7844 - val_loss: 0.4873 - val_accuracy: 0.8096\n",
      "Epoch 190/1000\n",
      "225/225 [==============================] - 1s 2ms/step - loss: 0.5448 - accuracy: 0.7867 - val_loss: 0.4837 - val_accuracy: 0.8108\n",
      "Epoch 191/1000\n",
      "225/225 [==============================] - 1s 2ms/step - loss: 0.5449 - accuracy: 0.7847 - val_loss: 0.4868 - val_accuracy: 0.8087\n",
      "Epoch 192/1000\n",
      "225/225 [==============================] - 1s 2ms/step - loss: 0.5487 - accuracy: 0.7835 - val_loss: 0.4879 - val_accuracy: 0.8065\n",
      "Epoch 193/1000\n",
      "225/225 [==============================] - 1s 2ms/step - loss: 0.5464 - accuracy: 0.7850 - val_loss: 0.4866 - val_accuracy: 0.8083\n",
      "Epoch 194/1000\n",
      "225/225 [==============================] - 1s 2ms/step - loss: 0.5461 - accuracy: 0.7850 - val_loss: 0.4847 - val_accuracy: 0.8077\n",
      "Epoch 195/1000\n",
      "225/225 [==============================] - 1s 2ms/step - loss: 0.5442 - accuracy: 0.7854 - val_loss: 0.4859 - val_accuracy: 0.8068\n",
      "Epoch 196/1000\n",
      "225/225 [==============================] - 1s 2ms/step - loss: 0.5454 - accuracy: 0.7852 - val_loss: 0.4887 - val_accuracy: 0.8059\n",
      "Epoch 197/1000\n",
      "225/225 [==============================] - 1s 2ms/step - loss: 0.5441 - accuracy: 0.7852 - val_loss: 0.4860 - val_accuracy: 0.8082\n",
      "Epoch 198/1000\n",
      "225/225 [==============================] - 1s 2ms/step - loss: 0.5441 - accuracy: 0.7862 - val_loss: 0.4854 - val_accuracy: 0.8102\n",
      "Epoch 199/1000\n",
      "225/225 [==============================] - 1s 2ms/step - loss: 0.5450 - accuracy: 0.7853 - val_loss: 0.4848 - val_accuracy: 0.8072\n",
      "Epoch 200/1000\n",
      "225/225 [==============================] - 1s 2ms/step - loss: 0.5457 - accuracy: 0.7846 - val_loss: 0.4856 - val_accuracy: 0.8079\n",
      "Epoch 201/1000\n",
      "225/225 [==============================] - 1s 2ms/step - loss: 0.5453 - accuracy: 0.7853 - val_loss: 0.4856 - val_accuracy: 0.8092\n",
      "Epoch 202/1000\n",
      "225/225 [==============================] - 1s 2ms/step - loss: 0.5440 - accuracy: 0.7858 - val_loss: 0.4850 - val_accuracy: 0.8097\n",
      "Epoch 203/1000\n",
      "225/225 [==============================] - 1s 2ms/step - loss: 0.5450 - accuracy: 0.7864 - val_loss: 0.4886 - val_accuracy: 0.8073\n",
      "Epoch 204/1000\n",
      "225/225 [==============================] - 1s 2ms/step - loss: 0.5455 - accuracy: 0.7848 - val_loss: 0.4859 - val_accuracy: 0.8067\n",
      "Epoch 205/1000\n",
      "225/225 [==============================] - 1s 2ms/step - loss: 0.5430 - accuracy: 0.7862 - val_loss: 0.4833 - val_accuracy: 0.8083\n",
      "Epoch 206/1000\n",
      "225/225 [==============================] - 1s 2ms/step - loss: 0.5416 - accuracy: 0.7869 - val_loss: 0.4845 - val_accuracy: 0.8089\n",
      "Epoch 207/1000\n",
      "225/225 [==============================] - 1s 2ms/step - loss: 0.5451 - accuracy: 0.7850 - val_loss: 0.4826 - val_accuracy: 0.8105\n",
      "Epoch 208/1000\n",
      "225/225 [==============================] - 1s 2ms/step - loss: 0.5434 - accuracy: 0.7856 - val_loss: 0.4840 - val_accuracy: 0.8097\n",
      "Epoch 209/1000\n",
      "225/225 [==============================] - 1s 2ms/step - loss: 0.5434 - accuracy: 0.7866 - val_loss: 0.4857 - val_accuracy: 0.8090\n",
      "Epoch 210/1000\n",
      "225/225 [==============================] - 1s 2ms/step - loss: 0.5437 - accuracy: 0.7855 - val_loss: 0.4835 - val_accuracy: 0.8082\n",
      "Epoch 211/1000\n",
      "225/225 [==============================] - 1s 2ms/step - loss: 0.5428 - accuracy: 0.7850 - val_loss: 0.4807 - val_accuracy: 0.8122\n",
      "Epoch 212/1000\n",
      "225/225 [==============================] - 1s 2ms/step - loss: 0.5414 - accuracy: 0.7860 - val_loss: 0.4846 - val_accuracy: 0.8080\n",
      "Epoch 213/1000\n",
      "225/225 [==============================] - 1s 2ms/step - loss: 0.5435 - accuracy: 0.7875 - val_loss: 0.4855 - val_accuracy: 0.8090\n",
      "Epoch 214/1000\n",
      "225/225 [==============================] - 1s 2ms/step - loss: 0.5424 - accuracy: 0.7854 - val_loss: 0.4827 - val_accuracy: 0.8083\n",
      "Epoch 215/1000\n",
      "225/225 [==============================] - 1s 2ms/step - loss: 0.5429 - accuracy: 0.7864 - val_loss: 0.4821 - val_accuracy: 0.8102\n",
      "Epoch 216/1000\n",
      "225/225 [==============================] - 1s 2ms/step - loss: 0.5427 - accuracy: 0.7859 - val_loss: 0.4861 - val_accuracy: 0.8116\n",
      "Epoch 217/1000\n",
      "225/225 [==============================] - 1s 2ms/step - loss: 0.5409 - accuracy: 0.7854 - val_loss: 0.4802 - val_accuracy: 0.8127\n",
      "Epoch 218/1000\n",
      "225/225 [==============================] - 1s 2ms/step - loss: 0.5438 - accuracy: 0.7865 - val_loss: 0.4838 - val_accuracy: 0.8101\n",
      "Epoch 219/1000\n",
      "225/225 [==============================] - 1s 2ms/step - loss: 0.5429 - accuracy: 0.7859 - val_loss: 0.4822 - val_accuracy: 0.8102\n",
      "Epoch 220/1000\n",
      "225/225 [==============================] - 1s 2ms/step - loss: 0.5424 - accuracy: 0.7856 - val_loss: 0.4838 - val_accuracy: 0.8092\n",
      "Epoch 221/1000\n",
      "225/225 [==============================] - 1s 2ms/step - loss: 0.5426 - accuracy: 0.7853 - val_loss: 0.4813 - val_accuracy: 0.8099\n",
      "Epoch 222/1000\n",
      "225/225 [==============================] - 1s 2ms/step - loss: 0.5439 - accuracy: 0.7850 - val_loss: 0.4824 - val_accuracy: 0.8081\n",
      "Epoch 223/1000\n",
      "225/225 [==============================] - 1s 2ms/step - loss: 0.5428 - accuracy: 0.7863 - val_loss: 0.4867 - val_accuracy: 0.8104\n",
      "Epoch 224/1000\n",
      "225/225 [==============================] - 1s 3ms/step - loss: 0.5417 - accuracy: 0.7862 - val_loss: 0.4841 - val_accuracy: 0.8110\n",
      "Epoch 225/1000\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "225/225 [==============================] - 1s 2ms/step - loss: 0.5427 - accuracy: 0.7869 - val_loss: 0.4841 - val_accuracy: 0.8098\n",
      "Epoch 226/1000\n",
      "225/225 [==============================] - 1s 2ms/step - loss: 0.5416 - accuracy: 0.7861 - val_loss: 0.4817 - val_accuracy: 0.8105\n",
      "Epoch 227/1000\n",
      "225/225 [==============================] - 1s 2ms/step - loss: 0.5423 - accuracy: 0.7863 - val_loss: 0.4832 - val_accuracy: 0.8116\n",
      "Epoch 228/1000\n",
      "225/225 [==============================] - 1s 2ms/step - loss: 0.5436 - accuracy: 0.7866 - val_loss: 0.4814 - val_accuracy: 0.8107\n",
      "Epoch 229/1000\n",
      "225/225 [==============================] - 1s 2ms/step - loss: 0.5427 - accuracy: 0.7873 - val_loss: 0.4843 - val_accuracy: 0.8077\n",
      "Epoch 230/1000\n",
      "225/225 [==============================] - 1s 2ms/step - loss: 0.5412 - accuracy: 0.7875 - val_loss: 0.4799 - val_accuracy: 0.8094\n",
      "Epoch 231/1000\n",
      "225/225 [==============================] - 1s 2ms/step - loss: 0.5402 - accuracy: 0.7872 - val_loss: 0.4821 - val_accuracy: 0.8101\n",
      "Epoch 232/1000\n",
      "225/225 [==============================] - 1s 2ms/step - loss: 0.5435 - accuracy: 0.7861 - val_loss: 0.4785 - val_accuracy: 0.8112\n",
      "Epoch 233/1000\n",
      "225/225 [==============================] - 1s 2ms/step - loss: 0.5417 - accuracy: 0.7867 - val_loss: 0.4788 - val_accuracy: 0.8098\n",
      "Epoch 234/1000\n",
      "225/225 [==============================] - 1s 2ms/step - loss: 0.5422 - accuracy: 0.7867 - val_loss: 0.4819 - val_accuracy: 0.8096\n",
      "Epoch 235/1000\n",
      "225/225 [==============================] - 1s 2ms/step - loss: 0.5417 - accuracy: 0.7866 - val_loss: 0.4786 - val_accuracy: 0.8086\n",
      "Epoch 236/1000\n",
      "225/225 [==============================] - 1s 2ms/step - loss: 0.5407 - accuracy: 0.7879 - val_loss: 0.4801 - val_accuracy: 0.8089\n",
      "Epoch 237/1000\n",
      "225/225 [==============================] - 1s 2ms/step - loss: 0.5435 - accuracy: 0.7855 - val_loss: 0.4808 - val_accuracy: 0.8101\n",
      "Epoch 238/1000\n",
      "225/225 [==============================] - 1s 2ms/step - loss: 0.5400 - accuracy: 0.7876 - val_loss: 0.4808 - val_accuracy: 0.8132\n",
      "Epoch 239/1000\n",
      "225/225 [==============================] - 1s 2ms/step - loss: 0.5412 - accuracy: 0.7883 - val_loss: 0.4776 - val_accuracy: 0.8115\n",
      "Epoch 240/1000\n",
      "225/225 [==============================] - 1s 2ms/step - loss: 0.5386 - accuracy: 0.7876 - val_loss: 0.4772 - val_accuracy: 0.8128\n",
      "Epoch 241/1000\n",
      "225/225 [==============================] - 1s 2ms/step - loss: 0.5408 - accuracy: 0.7871 - val_loss: 0.4824 - val_accuracy: 0.8104\n",
      "Epoch 242/1000\n",
      "225/225 [==============================] - 1s 2ms/step - loss: 0.5381 - accuracy: 0.7887 - val_loss: 0.4786 - val_accuracy: 0.8129\n",
      "Epoch 243/1000\n",
      "225/225 [==============================] - 1s 2ms/step - loss: 0.5401 - accuracy: 0.7877 - val_loss: 0.4778 - val_accuracy: 0.8111\n",
      "Epoch 244/1000\n",
      "225/225 [==============================] - 1s 2ms/step - loss: 0.5408 - accuracy: 0.7871 - val_loss: 0.4796 - val_accuracy: 0.8117\n",
      "Epoch 245/1000\n",
      "225/225 [==============================] - 1s 2ms/step - loss: 0.5412 - accuracy: 0.7878 - val_loss: 0.4809 - val_accuracy: 0.8116\n",
      "Epoch 246/1000\n",
      "225/225 [==============================] - 1s 2ms/step - loss: 0.5400 - accuracy: 0.7879 - val_loss: 0.4767 - val_accuracy: 0.8125\n",
      "Epoch 247/1000\n",
      "225/225 [==============================] - 1s 2ms/step - loss: 0.5390 - accuracy: 0.7883 - val_loss: 0.4805 - val_accuracy: 0.8155\n",
      "Epoch 248/1000\n",
      "225/225 [==============================] - 1s 2ms/step - loss: 0.5401 - accuracy: 0.7874 - val_loss: 0.4797 - val_accuracy: 0.8110\n",
      "Epoch 249/1000\n",
      "225/225 [==============================] - 1s 2ms/step - loss: 0.5376 - accuracy: 0.7875 - val_loss: 0.4788 - val_accuracy: 0.8130\n",
      "Epoch 250/1000\n",
      "225/225 [==============================] - 1s 2ms/step - loss: 0.5385 - accuracy: 0.7890 - val_loss: 0.4781 - val_accuracy: 0.8126\n",
      "Epoch 251/1000\n",
      "225/225 [==============================] - 1s 2ms/step - loss: 0.5384 - accuracy: 0.7883 - val_loss: 0.4779 - val_accuracy: 0.8134\n",
      "Epoch 252/1000\n",
      "225/225 [==============================] - 1s 2ms/step - loss: 0.5391 - accuracy: 0.7874 - val_loss: 0.4774 - val_accuracy: 0.8130\n",
      "Epoch 253/1000\n",
      "225/225 [==============================] - 1s 2ms/step - loss: 0.5400 - accuracy: 0.7882 - val_loss: 0.4782 - val_accuracy: 0.8126\n",
      "Epoch 254/1000\n",
      "225/225 [==============================] - 1s 2ms/step - loss: 0.5399 - accuracy: 0.7872 - val_loss: 0.4816 - val_accuracy: 0.8103\n",
      "Epoch 255/1000\n",
      "225/225 [==============================] - 1s 2ms/step - loss: 0.5387 - accuracy: 0.7877 - val_loss: 0.4797 - val_accuracy: 0.8111\n",
      "Epoch 256/1000\n",
      "225/225 [==============================] - 1s 2ms/step - loss: 0.5380 - accuracy: 0.7890 - val_loss: 0.4759 - val_accuracy: 0.8128\n",
      "Epoch 257/1000\n",
      "225/225 [==============================] - 1s 2ms/step - loss: 0.5402 - accuracy: 0.7887 - val_loss: 0.4778 - val_accuracy: 0.8124\n",
      "Epoch 258/1000\n",
      "225/225 [==============================] - 1s 2ms/step - loss: 0.5384 - accuracy: 0.7891 - val_loss: 0.4764 - val_accuracy: 0.8148\n",
      "Epoch 259/1000\n",
      "225/225 [==============================] - 1s 2ms/step - loss: 0.5378 - accuracy: 0.7889 - val_loss: 0.4794 - val_accuracy: 0.8139\n",
      "Epoch 260/1000\n",
      "225/225 [==============================] - 1s 2ms/step - loss: 0.5390 - accuracy: 0.7882 - val_loss: 0.4759 - val_accuracy: 0.8119\n",
      "Epoch 261/1000\n",
      "225/225 [==============================] - 1s 2ms/step - loss: 0.5362 - accuracy: 0.7887 - val_loss: 0.4750 - val_accuracy: 0.8158\n",
      "Epoch 262/1000\n",
      "225/225 [==============================] - 1s 2ms/step - loss: 0.5380 - accuracy: 0.7884 - val_loss: 0.4780 - val_accuracy: 0.8130\n",
      "Epoch 263/1000\n",
      "225/225 [==============================] - 1s 2ms/step - loss: 0.5383 - accuracy: 0.7885 - val_loss: 0.4776 - val_accuracy: 0.8140\n",
      "Epoch 264/1000\n",
      "225/225 [==============================] - 1s 2ms/step - loss: 0.5377 - accuracy: 0.7896 - val_loss: 0.4782 - val_accuracy: 0.8136\n",
      "Epoch 265/1000\n",
      "225/225 [==============================] - 1s 2ms/step - loss: 0.5383 - accuracy: 0.7885 - val_loss: 0.4778 - val_accuracy: 0.8135\n",
      "Epoch 266/1000\n",
      "225/225 [==============================] - 1s 2ms/step - loss: 0.5386 - accuracy: 0.7882 - val_loss: 0.4778 - val_accuracy: 0.8146\n",
      "Epoch 267/1000\n",
      "225/225 [==============================] - 1s 2ms/step - loss: 0.5380 - accuracy: 0.7885 - val_loss: 0.4762 - val_accuracy: 0.8122\n",
      "Epoch 268/1000\n",
      "225/225 [==============================] - 1s 2ms/step - loss: 0.5383 - accuracy: 0.7875 - val_loss: 0.4780 - val_accuracy: 0.8117\n",
      "Epoch 269/1000\n",
      "225/225 [==============================] - 1s 2ms/step - loss: 0.5393 - accuracy: 0.7880 - val_loss: 0.4805 - val_accuracy: 0.8149\n",
      "Epoch 270/1000\n",
      "225/225 [==============================] - 1s 2ms/step - loss: 0.5369 - accuracy: 0.7885 - val_loss: 0.4772 - val_accuracy: 0.8142\n",
      "Epoch 271/1000\n",
      "225/225 [==============================] - 1s 2ms/step - loss: 0.5368 - accuracy: 0.7887 - val_loss: 0.4752 - val_accuracy: 0.8168\n",
      "Epoch 272/1000\n",
      "225/225 [==============================] - 1s 2ms/step - loss: 0.5395 - accuracy: 0.7881 - val_loss: 0.4777 - val_accuracy: 0.8146\n",
      "Epoch 273/1000\n",
      "225/225 [==============================] - 1s 2ms/step - loss: 0.5364 - accuracy: 0.7888 - val_loss: 0.4772 - val_accuracy: 0.8137\n",
      "Epoch 274/1000\n",
      "225/225 [==============================] - 1s 2ms/step - loss: 0.5366 - accuracy: 0.7899 - val_loss: 0.4771 - val_accuracy: 0.8137\n",
      "Epoch 275/1000\n",
      "225/225 [==============================] - 1s 2ms/step - loss: 0.5355 - accuracy: 0.7884 - val_loss: 0.4742 - val_accuracy: 0.8144\n",
      "Epoch 276/1000\n",
      "225/225 [==============================] - 1s 2ms/step - loss: 0.5360 - accuracy: 0.7905 - val_loss: 0.4725 - val_accuracy: 0.8162\n",
      "Epoch 277/1000\n",
      "225/225 [==============================] - 1s 2ms/step - loss: 0.5360 - accuracy: 0.7888 - val_loss: 0.4750 - val_accuracy: 0.8158\n",
      "Epoch 278/1000\n",
      "225/225 [==============================] - 1s 2ms/step - loss: 0.5376 - accuracy: 0.7891 - val_loss: 0.4754 - val_accuracy: 0.8121\n",
      "Epoch 279/1000\n",
      "225/225 [==============================] - 1s 2ms/step - loss: 0.5363 - accuracy: 0.7904 - val_loss: 0.4734 - val_accuracy: 0.8167\n",
      "Epoch 280/1000\n",
      "225/225 [==============================] - 1s 2ms/step - loss: 0.5363 - accuracy: 0.7886 - val_loss: 0.4742 - val_accuracy: 0.8134\n",
      "Epoch 281/1000\n",
      "225/225 [==============================] - 1s 2ms/step - loss: 0.5367 - accuracy: 0.7900 - val_loss: 0.4736 - val_accuracy: 0.8159\n",
      "Epoch 282/1000\n",
      "225/225 [==============================] - 1s 2ms/step - loss: 0.5365 - accuracy: 0.7892 - val_loss: 0.4785 - val_accuracy: 0.8129\n",
      "Epoch 283/1000\n",
      "225/225 [==============================] - 1s 2ms/step - loss: 0.5377 - accuracy: 0.7891 - val_loss: 0.4757 - val_accuracy: 0.8136\n",
      "Epoch 284/1000\n",
      "225/225 [==============================] - 1s 2ms/step - loss: 0.5392 - accuracy: 0.7884 - val_loss: 0.4786 - val_accuracy: 0.8095\n",
      "Epoch 285/1000\n",
      "225/225 [==============================] - 1s 2ms/step - loss: 0.5375 - accuracy: 0.7892 - val_loss: 0.4746 - val_accuracy: 0.8131\n",
      "Epoch 286/1000\n",
      "225/225 [==============================] - 1s 2ms/step - loss: 0.5368 - accuracy: 0.7890 - val_loss: 0.4743 - val_accuracy: 0.8165\n",
      "Epoch 287/1000\n",
      "225/225 [==============================] - 1s 2ms/step - loss: 0.5352 - accuracy: 0.7897 - val_loss: 0.4708 - val_accuracy: 0.8176\n",
      "Epoch 288/1000\n",
      "225/225 [==============================] - 1s 2ms/step - loss: 0.5381 - accuracy: 0.7892 - val_loss: 0.4724 - val_accuracy: 0.8157\n",
      "Epoch 289/1000\n",
      "225/225 [==============================] - 1s 2ms/step - loss: 0.5387 - accuracy: 0.7888 - val_loss: 0.4756 - val_accuracy: 0.8140\n",
      "Epoch 290/1000\n",
      "225/225 [==============================] - 1s 2ms/step - loss: 0.5356 - accuracy: 0.7896 - val_loss: 0.4723 - val_accuracy: 0.8137\n",
      "Epoch 291/1000\n",
      "225/225 [==============================] - 1s 2ms/step - loss: 0.5366 - accuracy: 0.7883 - val_loss: 0.4713 - val_accuracy: 0.8140\n",
      "Epoch 292/1000\n",
      "225/225 [==============================] - 1s 2ms/step - loss: 0.5369 - accuracy: 0.7889 - val_loss: 0.4732 - val_accuracy: 0.8142\n",
      "Epoch 293/1000\n",
      "225/225 [==============================] - 1s 2ms/step - loss: 0.5365 - accuracy: 0.7899 - val_loss: 0.4752 - val_accuracy: 0.8126\n",
      "Epoch 294/1000\n",
      "225/225 [==============================] - 1s 2ms/step - loss: 0.5374 - accuracy: 0.7888 - val_loss: 0.4733 - val_accuracy: 0.8142\n",
      "Epoch 295/1000\n",
      "225/225 [==============================] - 0s 2ms/step - loss: 0.5349 - accuracy: 0.7897 - val_loss: 0.4723 - val_accuracy: 0.8156\n",
      "Epoch 296/1000\n",
      "225/225 [==============================] - 1s 2ms/step - loss: 0.5327 - accuracy: 0.7905 - val_loss: 0.4737 - val_accuracy: 0.8149\n",
      "Epoch 297/1000\n",
      "225/225 [==============================] - 1s 2ms/step - loss: 0.5358 - accuracy: 0.7891 - val_loss: 0.4762 - val_accuracy: 0.8122\n",
      "Epoch 298/1000\n",
      "225/225 [==============================] - 1s 2ms/step - loss: 0.5349 - accuracy: 0.7889 - val_loss: 0.4748 - val_accuracy: 0.8159\n",
      "Epoch 299/1000\n",
      "225/225 [==============================] - 1s 2ms/step - loss: 0.5355 - accuracy: 0.7904 - val_loss: 0.4749 - val_accuracy: 0.8144\n",
      "Epoch 300/1000\n",
      "225/225 [==============================] - 1s 3ms/step - loss: 0.5352 - accuracy: 0.7896 - val_loss: 0.4748 - val_accuracy: 0.8148\n",
      "Epoch 301/1000\n",
      "225/225 [==============================] - 1s 2ms/step - loss: 0.5353 - accuracy: 0.7894 - val_loss: 0.4723 - val_accuracy: 0.8163\n",
      "Epoch 302/1000\n",
      "225/225 [==============================] - 1s 2ms/step - loss: 0.5346 - accuracy: 0.7909 - val_loss: 0.4727 - val_accuracy: 0.8166\n",
      "Epoch 303/1000\n",
      "225/225 [==============================] - 1s 2ms/step - loss: 0.5347 - accuracy: 0.7906 - val_loss: 0.4769 - val_accuracy: 0.8155\n",
      "Epoch 304/1000\n",
      "225/225 [==============================] - 1s 2ms/step - loss: 0.5351 - accuracy: 0.7889 - val_loss: 0.4706 - val_accuracy: 0.8146\n",
      "Epoch 305/1000\n",
      "225/225 [==============================] - 1s 2ms/step - loss: 0.5357 - accuracy: 0.7903 - val_loss: 0.4722 - val_accuracy: 0.8146\n",
      "Epoch 306/1000\n",
      "225/225 [==============================] - 1s 2ms/step - loss: 0.5375 - accuracy: 0.7891 - val_loss: 0.4738 - val_accuracy: 0.8154\n",
      "Epoch 307/1000\n",
      "225/225 [==============================] - 1s 2ms/step - loss: 0.5363 - accuracy: 0.7898 - val_loss: 0.4694 - val_accuracy: 0.8177\n",
      "Epoch 308/1000\n",
      "225/225 [==============================] - 1s 2ms/step - loss: 0.5351 - accuracy: 0.7897 - val_loss: 0.4722 - val_accuracy: 0.8161\n",
      "Epoch 309/1000\n",
      "225/225 [==============================] - 1s 2ms/step - loss: 0.5342 - accuracy: 0.7896 - val_loss: 0.4736 - val_accuracy: 0.8133\n",
      "Epoch 310/1000\n",
      "225/225 [==============================] - 1s 2ms/step - loss: 0.5349 - accuracy: 0.7908 - val_loss: 0.4715 - val_accuracy: 0.8162\n",
      "Epoch 311/1000\n",
      "225/225 [==============================] - 1s 2ms/step - loss: 0.5337 - accuracy: 0.7909 - val_loss: 0.4727 - val_accuracy: 0.8155\n",
      "Epoch 312/1000\n",
      "225/225 [==============================] - 1s 2ms/step - loss: 0.5338 - accuracy: 0.7904 - val_loss: 0.4752 - val_accuracy: 0.8141\n",
      "Epoch 313/1000\n",
      "225/225 [==============================] - 1s 2ms/step - loss: 0.5361 - accuracy: 0.7888 - val_loss: 0.4722 - val_accuracy: 0.8166\n",
      "Epoch 314/1000\n",
      "225/225 [==============================] - 1s 2ms/step - loss: 0.5328 - accuracy: 0.7901 - val_loss: 0.4733 - val_accuracy: 0.8118\n",
      "Epoch 315/1000\n",
      "225/225 [==============================] - 1s 2ms/step - loss: 0.5331 - accuracy: 0.7913 - val_loss: 0.4733 - val_accuracy: 0.8140\n",
      "Epoch 316/1000\n",
      "225/225 [==============================] - 1s 2ms/step - loss: 0.5347 - accuracy: 0.7895 - val_loss: 0.4718 - val_accuracy: 0.8187\n",
      "Epoch 317/1000\n",
      "225/225 [==============================] - 1s 2ms/step - loss: 0.5325 - accuracy: 0.7906 - val_loss: 0.4691 - val_accuracy: 0.8179\n",
      "Epoch 318/1000\n",
      "225/225 [==============================] - 1s 2ms/step - loss: 0.5345 - accuracy: 0.7902 - val_loss: 0.4706 - val_accuracy: 0.8171\n",
      "Epoch 319/1000\n",
      "225/225 [==============================] - 1s 2ms/step - loss: 0.5365 - accuracy: 0.7893 - val_loss: 0.4731 - val_accuracy: 0.8144\n",
      "Epoch 320/1000\n",
      "225/225 [==============================] - 1s 2ms/step - loss: 0.5323 - accuracy: 0.7910 - val_loss: 0.4715 - val_accuracy: 0.8148\n",
      "Epoch 321/1000\n",
      "225/225 [==============================] - 1s 2ms/step - loss: 0.5341 - accuracy: 0.7895 - val_loss: 0.4719 - val_accuracy: 0.8127\n",
      "Epoch 322/1000\n",
      "225/225 [==============================] - 1s 2ms/step - loss: 0.5332 - accuracy: 0.7891 - val_loss: 0.4706 - val_accuracy: 0.8148\n",
      "Epoch 323/1000\n",
      "225/225 [==============================] - 1s 2ms/step - loss: 0.5339 - accuracy: 0.7905 - val_loss: 0.4706 - val_accuracy: 0.8137\n",
      "Epoch 324/1000\n",
      "225/225 [==============================] - 1s 2ms/step - loss: 0.5345 - accuracy: 0.7910 - val_loss: 0.4736 - val_accuracy: 0.8159\n",
      "Epoch 325/1000\n",
      "225/225 [==============================] - 1s 2ms/step - loss: 0.5351 - accuracy: 0.7905 - val_loss: 0.4722 - val_accuracy: 0.8154\n",
      "Epoch 326/1000\n",
      "225/225 [==============================] - 1s 2ms/step - loss: 0.5348 - accuracy: 0.7894 - val_loss: 0.4698 - val_accuracy: 0.8153\n",
      "Epoch 327/1000\n",
      "225/225 [==============================] - 1s 2ms/step - loss: 0.5367 - accuracy: 0.7893 - val_loss: 0.4699 - val_accuracy: 0.8153\n",
      "Epoch 328/1000\n",
      "225/225 [==============================] - 1s 2ms/step - loss: 0.5323 - accuracy: 0.7903 - val_loss: 0.4696 - val_accuracy: 0.8150\n",
      "Epoch 329/1000\n",
      "225/225 [==============================] - 1s 2ms/step - loss: 0.5353 - accuracy: 0.7892 - val_loss: 0.4736 - val_accuracy: 0.8138\n",
      "Epoch 330/1000\n",
      "225/225 [==============================] - 1s 2ms/step - loss: 0.5362 - accuracy: 0.7903 - val_loss: 0.4730 - val_accuracy: 0.8137\n",
      "Epoch 331/1000\n",
      "225/225 [==============================] - 1s 2ms/step - loss: 0.5322 - accuracy: 0.7916 - val_loss: 0.4683 - val_accuracy: 0.8166\n",
      "Epoch 332/1000\n",
      "225/225 [==============================] - 1s 2ms/step - loss: 0.5355 - accuracy: 0.7900 - val_loss: 0.4745 - val_accuracy: 0.8125\n",
      "Epoch 333/1000\n",
      "225/225 [==============================] - 1s 2ms/step - loss: 0.5328 - accuracy: 0.7896 - val_loss: 0.4741 - val_accuracy: 0.8123\n",
      "Epoch 334/1000\n",
      "225/225 [==============================] - 1s 2ms/step - loss: 0.5346 - accuracy: 0.7894 - val_loss: 0.4743 - val_accuracy: 0.8131\n",
      "Epoch 335/1000\n",
      "225/225 [==============================] - 1s 2ms/step - loss: 0.5294 - accuracy: 0.7924 - val_loss: 0.4710 - val_accuracy: 0.8130\n",
      "Epoch 336/1000\n",
      "225/225 [==============================] - 1s 2ms/step - loss: 0.5330 - accuracy: 0.7905 - val_loss: 0.4704 - val_accuracy: 0.8155\n",
      "Epoch 337/1000\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "225/225 [==============================] - 1s 2ms/step - loss: 0.5329 - accuracy: 0.7901 - val_loss: 0.4714 - val_accuracy: 0.8130\n",
      "Epoch 338/1000\n",
      "225/225 [==============================] - 1s 2ms/step - loss: 0.5333 - accuracy: 0.7905 - val_loss: 0.4717 - val_accuracy: 0.8159\n",
      "Epoch 339/1000\n",
      "225/225 [==============================] - 1s 2ms/step - loss: 0.5354 - accuracy: 0.7902 - val_loss: 0.4711 - val_accuracy: 0.8145\n",
      "Epoch 340/1000\n",
      "225/225 [==============================] - 1s 2ms/step - loss: 0.5316 - accuracy: 0.7916 - val_loss: 0.4710 - val_accuracy: 0.8156\n",
      "Epoch 341/1000\n",
      "225/225 [==============================] - 1s 3ms/step - loss: 0.5328 - accuracy: 0.7916 - val_loss: 0.4717 - val_accuracy: 0.8147\n",
      "Epoch 342/1000\n",
      "225/225 [==============================] - 1s 2ms/step - loss: 0.5337 - accuracy: 0.7901 - val_loss: 0.4696 - val_accuracy: 0.8178\n",
      "Epoch 343/1000\n",
      "225/225 [==============================] - 1s 2ms/step - loss: 0.5328 - accuracy: 0.7898 - val_loss: 0.4688 - val_accuracy: 0.8165\n",
      "Epoch 344/1000\n",
      "225/225 [==============================] - 1s 2ms/step - loss: 0.5334 - accuracy: 0.7896 - val_loss: 0.4721 - val_accuracy: 0.8143\n",
      "Epoch 345/1000\n",
      "225/225 [==============================] - 1s 2ms/step - loss: 0.5313 - accuracy: 0.7918 - val_loss: 0.4704 - val_accuracy: 0.8171\n",
      "Epoch 346/1000\n",
      "225/225 [==============================] - 1s 2ms/step - loss: 0.5316 - accuracy: 0.7930 - val_loss: 0.4690 - val_accuracy: 0.8155\n",
      "Epoch 347/1000\n",
      "225/225 [==============================] - 1s 2ms/step - loss: 0.5320 - accuracy: 0.7912 - val_loss: 0.4740 - val_accuracy: 0.8148\n",
      "Epoch 348/1000\n",
      "225/225 [==============================] - 1s 2ms/step - loss: 0.5332 - accuracy: 0.7907 - val_loss: 0.4701 - val_accuracy: 0.8157\n",
      "Epoch 349/1000\n",
      "225/225 [==============================] - 1s 2ms/step - loss: 0.5322 - accuracy: 0.7918 - val_loss: 0.4689 - val_accuracy: 0.8156\n",
      "Epoch 350/1000\n",
      "225/225 [==============================] - 1s 2ms/step - loss: 0.5301 - accuracy: 0.7914 - val_loss: 0.4691 - val_accuracy: 0.8166\n",
      "Epoch 351/1000\n",
      "225/225 [==============================] - 1s 2ms/step - loss: 0.5320 - accuracy: 0.7905 - val_loss: 0.4705 - val_accuracy: 0.8189\n",
      "Epoch 352/1000\n",
      "225/225 [==============================] - 1s 2ms/step - loss: 0.5312 - accuracy: 0.7917 - val_loss: 0.4694 - val_accuracy: 0.8164\n",
      "Epoch 353/1000\n",
      "225/225 [==============================] - 1s 2ms/step - loss: 0.5322 - accuracy: 0.7905 - val_loss: 0.4724 - val_accuracy: 0.8157\n",
      "Epoch 354/1000\n",
      "225/225 [==============================] - 1s 2ms/step - loss: 0.5327 - accuracy: 0.7908 - val_loss: 0.4702 - val_accuracy: 0.8158\n",
      "Epoch 355/1000\n",
      "225/225 [==============================] - 1s 2ms/step - loss: 0.5317 - accuracy: 0.7918 - val_loss: 0.4696 - val_accuracy: 0.8160\n",
      "Epoch 356/1000\n",
      "225/225 [==============================] - 1s 3ms/step - loss: 0.5316 - accuracy: 0.7908 - val_loss: 0.4678 - val_accuracy: 0.8184\n",
      "Epoch 357/1000\n",
      "225/225 [==============================] - 1s 2ms/step - loss: 0.5312 - accuracy: 0.7930 - val_loss: 0.4685 - val_accuracy: 0.8158\n",
      "Epoch 358/1000\n",
      "225/225 [==============================] - 1s 2ms/step - loss: 0.5318 - accuracy: 0.7911 - val_loss: 0.4672 - val_accuracy: 0.8188\n",
      "Epoch 359/1000\n",
      "225/225 [==============================] - 1s 2ms/step - loss: 0.5320 - accuracy: 0.7906 - val_loss: 0.4709 - val_accuracy: 0.8179\n",
      "Epoch 360/1000\n",
      "225/225 [==============================] - 1s 2ms/step - loss: 0.5320 - accuracy: 0.7910 - val_loss: 0.4701 - val_accuracy: 0.8177\n",
      "Epoch 361/1000\n",
      "225/225 [==============================] - 1s 2ms/step - loss: 0.5305 - accuracy: 0.7910 - val_loss: 0.4709 - val_accuracy: 0.8179\n",
      "Epoch 362/1000\n",
      "225/225 [==============================] - 1s 2ms/step - loss: 0.5331 - accuracy: 0.7915 - val_loss: 0.4714 - val_accuracy: 0.8154\n",
      "Epoch 363/1000\n",
      "225/225 [==============================] - 1s 2ms/step - loss: 0.5317 - accuracy: 0.7912 - val_loss: 0.4721 - val_accuracy: 0.8156\n",
      "Epoch 364/1000\n",
      "225/225 [==============================] - 1s 2ms/step - loss: 0.5317 - accuracy: 0.7910 - val_loss: 0.4691 - val_accuracy: 0.8155\n",
      "Epoch 365/1000\n",
      "225/225 [==============================] - 1s 2ms/step - loss: 0.5313 - accuracy: 0.7916 - val_loss: 0.4679 - val_accuracy: 0.8171\n",
      "Epoch 366/1000\n",
      "225/225 [==============================] - 1s 2ms/step - loss: 0.5333 - accuracy: 0.7910 - val_loss: 0.4690 - val_accuracy: 0.8160\n",
      "Epoch 367/1000\n",
      "225/225 [==============================] - 1s 2ms/step - loss: 0.5300 - accuracy: 0.7919 - val_loss: 0.4707 - val_accuracy: 0.8130\n",
      "Epoch 368/1000\n",
      "225/225 [==============================] - 1s 2ms/step - loss: 0.5295 - accuracy: 0.7915 - val_loss: 0.4668 - val_accuracy: 0.8159\n",
      "Epoch 369/1000\n",
      "225/225 [==============================] - 1s 2ms/step - loss: 0.5316 - accuracy: 0.7913 - val_loss: 0.4703 - val_accuracy: 0.8176\n",
      "Epoch 370/1000\n",
      "225/225 [==============================] - 1s 2ms/step - loss: 0.5317 - accuracy: 0.7916 - val_loss: 0.4693 - val_accuracy: 0.8159\n",
      "Epoch 371/1000\n",
      "225/225 [==============================] - 1s 2ms/step - loss: 0.5278 - accuracy: 0.7929 - val_loss: 0.4676 - val_accuracy: 0.8182\n",
      "Epoch 372/1000\n",
      "225/225 [==============================] - 1s 3ms/step - loss: 0.5318 - accuracy: 0.7914 - val_loss: 0.4679 - val_accuracy: 0.8153\n",
      "Epoch 373/1000\n",
      "225/225 [==============================] - 1s 3ms/step - loss: 0.5305 - accuracy: 0.7929 - val_loss: 0.4685 - val_accuracy: 0.8151\n",
      "Epoch 374/1000\n",
      "225/225 [==============================] - 1s 2ms/step - loss: 0.5324 - accuracy: 0.7916 - val_loss: 0.4674 - val_accuracy: 0.8183\n",
      "Epoch 375/1000\n",
      "225/225 [==============================] - 1s 2ms/step - loss: 0.5297 - accuracy: 0.7924 - val_loss: 0.4682 - val_accuracy: 0.8177\n",
      "Epoch 376/1000\n",
      "225/225 [==============================] - 1s 2ms/step - loss: 0.5325 - accuracy: 0.7915 - val_loss: 0.4707 - val_accuracy: 0.8168\n",
      "Epoch 377/1000\n",
      "225/225 [==============================] - 1s 2ms/step - loss: 0.5291 - accuracy: 0.7917 - val_loss: 0.4709 - val_accuracy: 0.8145\n",
      "Epoch 378/1000\n",
      "225/225 [==============================] - 1s 2ms/step - loss: 0.5292 - accuracy: 0.7931 - val_loss: 0.4687 - val_accuracy: 0.8169\n",
      "Epoch 379/1000\n",
      "225/225 [==============================] - 1s 2ms/step - loss: 0.5303 - accuracy: 0.7916 - val_loss: 0.4667 - val_accuracy: 0.8144\n",
      "Epoch 380/1000\n",
      "225/225 [==============================] - 1s 2ms/step - loss: 0.5312 - accuracy: 0.7915 - val_loss: 0.4669 - val_accuracy: 0.8176\n",
      "Epoch 381/1000\n",
      "225/225 [==============================] - 1s 2ms/step - loss: 0.5297 - accuracy: 0.7929 - val_loss: 0.4652 - val_accuracy: 0.8196\n",
      "Epoch 382/1000\n",
      "225/225 [==============================] - 1s 2ms/step - loss: 0.5312 - accuracy: 0.7914 - val_loss: 0.4684 - val_accuracy: 0.8176\n",
      "Epoch 383/1000\n",
      "225/225 [==============================] - 1s 2ms/step - loss: 0.5306 - accuracy: 0.7922 - val_loss: 0.4702 - val_accuracy: 0.8169\n",
      "Epoch 384/1000\n",
      "225/225 [==============================] - 1s 2ms/step - loss: 0.5289 - accuracy: 0.7920 - val_loss: 0.4660 - val_accuracy: 0.8185\n",
      "Epoch 385/1000\n",
      "225/225 [==============================] - 1s 2ms/step - loss: 0.5280 - accuracy: 0.7930 - val_loss: 0.4675 - val_accuracy: 0.8168\n",
      "Epoch 386/1000\n",
      "225/225 [==============================] - 1s 2ms/step - loss: 0.5321 - accuracy: 0.7919 - val_loss: 0.4696 - val_accuracy: 0.8167\n",
      "Epoch 387/1000\n",
      "225/225 [==============================] - 1s 2ms/step - loss: 0.5296 - accuracy: 0.7913 - val_loss: 0.4664 - val_accuracy: 0.8167\n",
      "Epoch 388/1000\n",
      "225/225 [==============================] - 1s 2ms/step - loss: 0.5305 - accuracy: 0.7915 - val_loss: 0.4668 - val_accuracy: 0.8173\n",
      "Epoch 389/1000\n",
      "225/225 [==============================] - 1s 2ms/step - loss: 0.5300 - accuracy: 0.7931 - val_loss: 0.4700 - val_accuracy: 0.8144\n",
      "Epoch 390/1000\n",
      "225/225 [==============================] - 1s 2ms/step - loss: 0.5294 - accuracy: 0.7908 - val_loss: 0.4686 - val_accuracy: 0.8170\n",
      "Epoch 391/1000\n",
      "225/225 [==============================] - 1s 2ms/step - loss: 0.5297 - accuracy: 0.7916 - val_loss: 0.4711 - val_accuracy: 0.8172\n",
      "Epoch 392/1000\n",
      "225/225 [==============================] - 1s 2ms/step - loss: 0.5312 - accuracy: 0.7921 - val_loss: 0.4667 - val_accuracy: 0.8174\n",
      "Epoch 393/1000\n",
      "225/225 [==============================] - 1s 2ms/step - loss: 0.5302 - accuracy: 0.7915 - val_loss: 0.4688 - val_accuracy: 0.8207\n",
      "Epoch 394/1000\n",
      "225/225 [==============================] - 1s 2ms/step - loss: 0.5296 - accuracy: 0.7919 - val_loss: 0.4665 - val_accuracy: 0.8168\n",
      "Epoch 395/1000\n",
      "225/225 [==============================] - 1s 2ms/step - loss: 0.5291 - accuracy: 0.7928 - val_loss: 0.4653 - val_accuracy: 0.8187\n",
      "Epoch 396/1000\n",
      "225/225 [==============================] - 1s 2ms/step - loss: 0.5300 - accuracy: 0.7914 - val_loss: 0.4679 - val_accuracy: 0.8173\n",
      "Epoch 397/1000\n",
      "225/225 [==============================] - 1s 2ms/step - loss: 0.5283 - accuracy: 0.7923 - val_loss: 0.4670 - val_accuracy: 0.8183\n",
      "Epoch 398/1000\n",
      "225/225 [==============================] - 1s 2ms/step - loss: 0.5285 - accuracy: 0.7924 - val_loss: 0.4681 - val_accuracy: 0.8166\n",
      "Epoch 399/1000\n",
      "225/225 [==============================] - 1s 2ms/step - loss: 0.5284 - accuracy: 0.7927 - val_loss: 0.4661 - val_accuracy: 0.8167\n",
      "Epoch 400/1000\n",
      "225/225 [==============================] - 1s 2ms/step - loss: 0.5292 - accuracy: 0.7929 - val_loss: 0.4648 - val_accuracy: 0.8167\n",
      "Epoch 401/1000\n",
      "225/225 [==============================] - 1s 3ms/step - loss: 0.5281 - accuracy: 0.7937 - val_loss: 0.4663 - val_accuracy: 0.8178\n",
      "Epoch 402/1000\n",
      "225/225 [==============================] - 1s 2ms/step - loss: 0.5292 - accuracy: 0.7922 - val_loss: 0.4687 - val_accuracy: 0.8189\n",
      "Epoch 403/1000\n",
      "225/225 [==============================] - 1s 2ms/step - loss: 0.5287 - accuracy: 0.7919 - val_loss: 0.4681 - val_accuracy: 0.8165\n",
      "Epoch 404/1000\n",
      "225/225 [==============================] - 1s 2ms/step - loss: 0.5283 - accuracy: 0.7924 - val_loss: 0.4646 - val_accuracy: 0.8182\n",
      "Epoch 405/1000\n",
      "225/225 [==============================] - 1s 2ms/step - loss: 0.5292 - accuracy: 0.7941 - val_loss: 0.4668 - val_accuracy: 0.8172\n",
      "Epoch 406/1000\n",
      "225/225 [==============================] - 1s 2ms/step - loss: 0.5299 - accuracy: 0.7906 - val_loss: 0.4649 - val_accuracy: 0.8184\n",
      "Epoch 407/1000\n",
      "225/225 [==============================] - 1s 2ms/step - loss: 0.5288 - accuracy: 0.7931 - val_loss: 0.4679 - val_accuracy: 0.8169\n",
      "Epoch 408/1000\n",
      "225/225 [==============================] - 1s 2ms/step - loss: 0.5303 - accuracy: 0.7917 - val_loss: 0.4669 - val_accuracy: 0.8195\n",
      "Epoch 409/1000\n",
      "225/225 [==============================] - 1s 2ms/step - loss: 0.5291 - accuracy: 0.7919 - val_loss: 0.4651 - val_accuracy: 0.8202\n",
      "Epoch 410/1000\n",
      "225/225 [==============================] - 1s 2ms/step - loss: 0.5294 - accuracy: 0.7924 - val_loss: 0.4651 - val_accuracy: 0.8166\n",
      "Epoch 411/1000\n",
      "225/225 [==============================] - 1s 2ms/step - loss: 0.5284 - accuracy: 0.7930 - val_loss: 0.4655 - val_accuracy: 0.8188\n",
      "Epoch 412/1000\n",
      "225/225 [==============================] - 1s 2ms/step - loss: 0.5266 - accuracy: 0.7920 - val_loss: 0.4702 - val_accuracy: 0.8186\n",
      "Epoch 413/1000\n",
      "225/225 [==============================] - 1s 2ms/step - loss: 0.5301 - accuracy: 0.7926 - val_loss: 0.4653 - val_accuracy: 0.8215\n",
      "Epoch 414/1000\n",
      "225/225 [==============================] - 1s 2ms/step - loss: 0.5313 - accuracy: 0.7921 - val_loss: 0.4693 - val_accuracy: 0.8182\n",
      "Epoch 415/1000\n",
      "225/225 [==============================] - 1s 2ms/step - loss: 0.5276 - accuracy: 0.7938 - val_loss: 0.4667 - val_accuracy: 0.8183\n",
      "Epoch 416/1000\n",
      "225/225 [==============================] - 1s 2ms/step - loss: 0.5281 - accuracy: 0.7930 - val_loss: 0.4675 - val_accuracy: 0.8167\n",
      "Epoch 417/1000\n",
      "225/225 [==============================] - 1s 2ms/step - loss: 0.5277 - accuracy: 0.7931 - val_loss: 0.4693 - val_accuracy: 0.8173\n",
      "Epoch 418/1000\n",
      "225/225 [==============================] - 1s 2ms/step - loss: 0.5273 - accuracy: 0.7927 - val_loss: 0.4648 - val_accuracy: 0.8179\n",
      "Epoch 419/1000\n",
      "225/225 [==============================] - 1s 2ms/step - loss: 0.5308 - accuracy: 0.7917 - val_loss: 0.4716 - val_accuracy: 0.8169\n",
      "Epoch 420/1000\n",
      "225/225 [==============================] - 0s 2ms/step - loss: 0.5283 - accuracy: 0.7933 - val_loss: 0.4676 - val_accuracy: 0.8162\n",
      "Epoch 421/1000\n",
      "225/225 [==============================] - 1s 2ms/step - loss: 0.5288 - accuracy: 0.7922 - val_loss: 0.4661 - val_accuracy: 0.8183\n",
      "Epoch 422/1000\n",
      "225/225 [==============================] - 1s 2ms/step - loss: 0.5310 - accuracy: 0.7930 - val_loss: 0.4659 - val_accuracy: 0.8180\n",
      "Epoch 423/1000\n",
      "225/225 [==============================] - 1s 2ms/step - loss: 0.5287 - accuracy: 0.7925 - val_loss: 0.4650 - val_accuracy: 0.8192\n",
      "Epoch 424/1000\n",
      "225/225 [==============================] - 1s 2ms/step - loss: 0.5287 - accuracy: 0.7923 - val_loss: 0.4661 - val_accuracy: 0.8194\n",
      "Epoch 425/1000\n",
      "225/225 [==============================] - 1s 2ms/step - loss: 0.5290 - accuracy: 0.7941 - val_loss: 0.4697 - val_accuracy: 0.8171\n",
      "Epoch 426/1000\n",
      "225/225 [==============================] - 1s 2ms/step - loss: 0.5313 - accuracy: 0.7927 - val_loss: 0.4677 - val_accuracy: 0.8177\n",
      "Epoch 427/1000\n",
      "225/225 [==============================] - 1s 2ms/step - loss: 0.5289 - accuracy: 0.7928 - val_loss: 0.4653 - val_accuracy: 0.8187\n",
      "Epoch 428/1000\n",
      "225/225 [==============================] - 1s 2ms/step - loss: 0.5246 - accuracy: 0.7945 - val_loss: 0.4637 - val_accuracy: 0.8208\n",
      "Epoch 429/1000\n",
      "225/225 [==============================] - 1s 2ms/step - loss: 0.5270 - accuracy: 0.7941 - val_loss: 0.4641 - val_accuracy: 0.8188\n",
      "Epoch 430/1000\n",
      "225/225 [==============================] - 1s 2ms/step - loss: 0.5268 - accuracy: 0.7940 - val_loss: 0.4677 - val_accuracy: 0.8173\n",
      "Epoch 431/1000\n",
      "225/225 [==============================] - 1s 2ms/step - loss: 0.5292 - accuracy: 0.7934 - val_loss: 0.4630 - val_accuracy: 0.8200\n",
      "Epoch 432/1000\n",
      "225/225 [==============================] - 1s 2ms/step - loss: 0.5286 - accuracy: 0.7923 - val_loss: 0.4673 - val_accuracy: 0.8202\n",
      "Epoch 433/1000\n",
      "225/225 [==============================] - 1s 2ms/step - loss: 0.5285 - accuracy: 0.7921 - val_loss: 0.4668 - val_accuracy: 0.8194\n",
      "Epoch 434/1000\n",
      "225/225 [==============================] - 1s 2ms/step - loss: 0.5296 - accuracy: 0.7920 - val_loss: 0.4692 - val_accuracy: 0.8186\n",
      "Epoch 435/1000\n",
      "225/225 [==============================] - 1s 2ms/step - loss: 0.5288 - accuracy: 0.7918 - val_loss: 0.4655 - val_accuracy: 0.8200\n",
      "Epoch 436/1000\n",
      "225/225 [==============================] - 1s 2ms/step - loss: 0.5293 - accuracy: 0.7937 - val_loss: 0.4678 - val_accuracy: 0.8186\n",
      "Epoch 437/1000\n",
      "225/225 [==============================] - 1s 2ms/step - loss: 0.5270 - accuracy: 0.7936 - val_loss: 0.4669 - val_accuracy: 0.8186\n",
      "Epoch 438/1000\n",
      "225/225 [==============================] - 1s 2ms/step - loss: 0.5283 - accuracy: 0.7938 - val_loss: 0.4678 - val_accuracy: 0.8170\n",
      "Epoch 439/1000\n",
      "225/225 [==============================] - 1s 2ms/step - loss: 0.5291 - accuracy: 0.7923 - val_loss: 0.4654 - val_accuracy: 0.8189\n",
      "Epoch 440/1000\n",
      "225/225 [==============================] - 1s 2ms/step - loss: 0.5274 - accuracy: 0.7931 - val_loss: 0.4635 - val_accuracy: 0.8181\n",
      "Epoch 441/1000\n",
      "225/225 [==============================] - 1s 2ms/step - loss: 0.5269 - accuracy: 0.7935 - val_loss: 0.4643 - val_accuracy: 0.8218\n",
      "Epoch 442/1000\n",
      "225/225 [==============================] - 1s 2ms/step - loss: 0.5299 - accuracy: 0.7935 - val_loss: 0.4653 - val_accuracy: 0.8202\n",
      "Epoch 443/1000\n",
      "225/225 [==============================] - 1s 2ms/step - loss: 0.5260 - accuracy: 0.7945 - val_loss: 0.4674 - val_accuracy: 0.8209\n",
      "Epoch 444/1000\n",
      "225/225 [==============================] - 1s 2ms/step - loss: 0.5268 - accuracy: 0.7937 - val_loss: 0.4650 - val_accuracy: 0.8192\n",
      "Epoch 445/1000\n",
      "225/225 [==============================] - 1s 2ms/step - loss: 0.5261 - accuracy: 0.7954 - val_loss: 0.4670 - val_accuracy: 0.8183\n",
      "Epoch 446/1000\n",
      "225/225 [==============================] - 1s 2ms/step - loss: 0.5263 - accuracy: 0.7946 - val_loss: 0.4653 - val_accuracy: 0.8201\n",
      "Epoch 447/1000\n",
      "225/225 [==============================] - 1s 2ms/step - loss: 0.5275 - accuracy: 0.7938 - val_loss: 0.4651 - val_accuracy: 0.8198\n",
      "Epoch 448/1000\n",
      "225/225 [==============================] - 1s 2ms/step - loss: 0.5251 - accuracy: 0.7938 - val_loss: 0.4643 - val_accuracy: 0.8186\n",
      "Epoch 449/1000\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "225/225 [==============================] - 1s 2ms/step - loss: 0.5281 - accuracy: 0.7931 - val_loss: 0.4664 - val_accuracy: 0.8177\n",
      "Epoch 450/1000\n",
      "225/225 [==============================] - 1s 2ms/step - loss: 0.5284 - accuracy: 0.7940 - val_loss: 0.4662 - val_accuracy: 0.8198\n",
      "Epoch 451/1000\n",
      "225/225 [==============================] - 1s 2ms/step - loss: 0.5284 - accuracy: 0.7931 - val_loss: 0.4650 - val_accuracy: 0.8203\n",
      "Epoch 452/1000\n",
      "225/225 [==============================] - 1s 2ms/step - loss: 0.5291 - accuracy: 0.7935 - val_loss: 0.4646 - val_accuracy: 0.8191\n",
      "Epoch 453/1000\n",
      "225/225 [==============================] - 1s 2ms/step - loss: 0.5280 - accuracy: 0.7934 - val_loss: 0.4651 - val_accuracy: 0.8211\n",
      "Epoch 454/1000\n",
      "225/225 [==============================] - 1s 2ms/step - loss: 0.5275 - accuracy: 0.7937 - val_loss: 0.4654 - val_accuracy: 0.8218\n",
      "Epoch 455/1000\n",
      "225/225 [==============================] - 1s 2ms/step - loss: 0.5268 - accuracy: 0.7939 - val_loss: 0.4618 - val_accuracy: 0.8180\n",
      "Epoch 456/1000\n",
      "225/225 [==============================] - 1s 2ms/step - loss: 0.5284 - accuracy: 0.7922 - val_loss: 0.4668 - val_accuracy: 0.8173\n",
      "Epoch 457/1000\n",
      "225/225 [==============================] - 1s 2ms/step - loss: 0.5265 - accuracy: 0.7943 - val_loss: 0.4664 - val_accuracy: 0.8195\n",
      "Epoch 458/1000\n",
      "225/225 [==============================] - 1s 3ms/step - loss: 0.5263 - accuracy: 0.7928 - val_loss: 0.4645 - val_accuracy: 0.8198\n",
      "Epoch 459/1000\n",
      "225/225 [==============================] - 1s 2ms/step - loss: 0.5283 - accuracy: 0.7924 - val_loss: 0.4660 - val_accuracy: 0.8191\n",
      "Epoch 460/1000\n",
      "225/225 [==============================] - 1s 2ms/step - loss: 0.5282 - accuracy: 0.7921 - val_loss: 0.4664 - val_accuracy: 0.8173\n",
      "Epoch 461/1000\n",
      "225/225 [==============================] - 1s 2ms/step - loss: 0.5282 - accuracy: 0.7932 - val_loss: 0.4622 - val_accuracy: 0.8219\n",
      "Epoch 462/1000\n",
      "225/225 [==============================] - 1s 2ms/step - loss: 0.5282 - accuracy: 0.7929 - val_loss: 0.4652 - val_accuracy: 0.8209\n",
      "Epoch 463/1000\n",
      "225/225 [==============================] - 1s 2ms/step - loss: 0.5275 - accuracy: 0.7929 - val_loss: 0.4615 - val_accuracy: 0.8208\n",
      "Epoch 464/1000\n",
      "225/225 [==============================] - 1s 2ms/step - loss: 0.5288 - accuracy: 0.7927 - val_loss: 0.4622 - val_accuracy: 0.8205\n",
      "Epoch 465/1000\n",
      "225/225 [==============================] - 1s 2ms/step - loss: 0.5264 - accuracy: 0.7933 - val_loss: 0.4632 - val_accuracy: 0.8222\n",
      "Epoch 466/1000\n",
      "225/225 [==============================] - 1s 2ms/step - loss: 0.5261 - accuracy: 0.7936 - val_loss: 0.4663 - val_accuracy: 0.8173\n",
      "Epoch 467/1000\n",
      "225/225 [==============================] - 1s 2ms/step - loss: 0.5265 - accuracy: 0.7929 - val_loss: 0.4652 - val_accuracy: 0.8190\n",
      "Epoch 468/1000\n",
      "225/225 [==============================] - 1s 2ms/step - loss: 0.5280 - accuracy: 0.7925 - val_loss: 0.4636 - val_accuracy: 0.8195\n",
      "Epoch 469/1000\n",
      "225/225 [==============================] - 1s 2ms/step - loss: 0.5266 - accuracy: 0.7923 - val_loss: 0.4625 - val_accuracy: 0.8195\n",
      "Epoch 470/1000\n",
      "225/225 [==============================] - 1s 2ms/step - loss: 0.5246 - accuracy: 0.7938 - val_loss: 0.4624 - val_accuracy: 0.8198\n",
      "Epoch 471/1000\n",
      "225/225 [==============================] - 1s 2ms/step - loss: 0.5264 - accuracy: 0.7933 - val_loss: 0.4668 - val_accuracy: 0.8167\n",
      "Epoch 472/1000\n",
      "225/225 [==============================] - 1s 2ms/step - loss: 0.5270 - accuracy: 0.7933 - val_loss: 0.4648 - val_accuracy: 0.8193\n",
      "Epoch 473/1000\n",
      "225/225 [==============================] - 1s 2ms/step - loss: 0.5265 - accuracy: 0.7936 - val_loss: 0.4643 - val_accuracy: 0.8216\n",
      "Epoch 474/1000\n",
      "225/225 [==============================] - 1s 2ms/step - loss: 0.5260 - accuracy: 0.7934 - val_loss: 0.4618 - val_accuracy: 0.8198\n",
      "Epoch 475/1000\n",
      "225/225 [==============================] - 1s 2ms/step - loss: 0.5272 - accuracy: 0.7936 - val_loss: 0.4627 - val_accuracy: 0.8207\n",
      "Epoch 476/1000\n",
      "225/225 [==============================] - 1s 2ms/step - loss: 0.5273 - accuracy: 0.7931 - val_loss: 0.4610 - val_accuracy: 0.8213\n",
      "Epoch 477/1000\n",
      "225/225 [==============================] - 1s 2ms/step - loss: 0.5276 - accuracy: 0.7938 - val_loss: 0.4652 - val_accuracy: 0.8209\n",
      "Epoch 478/1000\n",
      "225/225 [==============================] - 1s 2ms/step - loss: 0.5252 - accuracy: 0.7938 - val_loss: 0.4629 - val_accuracy: 0.8180\n",
      "Epoch 479/1000\n",
      "225/225 [==============================] - 1s 2ms/step - loss: 0.5262 - accuracy: 0.7944 - val_loss: 0.4664 - val_accuracy: 0.8184\n",
      "Epoch 480/1000\n",
      "225/225 [==============================] - 1s 3ms/step - loss: 0.5265 - accuracy: 0.7933 - val_loss: 0.4607 - val_accuracy: 0.8213\n",
      "Epoch 481/1000\n",
      "225/225 [==============================] - 1s 2ms/step - loss: 0.5273 - accuracy: 0.7924 - val_loss: 0.4631 - val_accuracy: 0.8227\n",
      "Epoch 482/1000\n",
      "225/225 [==============================] - 1s 2ms/step - loss: 0.5251 - accuracy: 0.7947 - val_loss: 0.4645 - val_accuracy: 0.8205\n",
      "Epoch 483/1000\n",
      "225/225 [==============================] - 1s 2ms/step - loss: 0.5247 - accuracy: 0.7949 - val_loss: 0.4643 - val_accuracy: 0.8209\n",
      "Epoch 484/1000\n",
      "225/225 [==============================] - 1s 2ms/step - loss: 0.5258 - accuracy: 0.7949 - val_loss: 0.4627 - val_accuracy: 0.8197\n",
      "Epoch 485/1000\n",
      "225/225 [==============================] - 1s 2ms/step - loss: 0.5270 - accuracy: 0.7937 - val_loss: 0.4616 - val_accuracy: 0.8196\n",
      "Epoch 486/1000\n",
      "225/225 [==============================] - 1s 2ms/step - loss: 0.5250 - accuracy: 0.7942 - val_loss: 0.4628 - val_accuracy: 0.8191\n",
      "Epoch 487/1000\n",
      "225/225 [==============================] - 1s 2ms/step - loss: 0.5275 - accuracy: 0.7943 - val_loss: 0.4609 - val_accuracy: 0.8213\n",
      "Epoch 488/1000\n",
      "225/225 [==============================] - 1s 2ms/step - loss: 0.5274 - accuracy: 0.7946 - val_loss: 0.4646 - val_accuracy: 0.8202\n",
      "Epoch 489/1000\n",
      "225/225 [==============================] - 1s 2ms/step - loss: 0.5254 - accuracy: 0.7932 - val_loss: 0.4609 - val_accuracy: 0.8195\n",
      "Epoch 490/1000\n",
      "225/225 [==============================] - 1s 2ms/step - loss: 0.5255 - accuracy: 0.7939 - val_loss: 0.4643 - val_accuracy: 0.8198\n",
      "Epoch 491/1000\n",
      "225/225 [==============================] - 1s 2ms/step - loss: 0.5265 - accuracy: 0.7935 - val_loss: 0.4611 - val_accuracy: 0.8209\n",
      "Epoch 492/1000\n",
      "225/225 [==============================] - 1s 2ms/step - loss: 0.5240 - accuracy: 0.7924 - val_loss: 0.4645 - val_accuracy: 0.8180\n",
      "Epoch 493/1000\n",
      "225/225 [==============================] - 1s 2ms/step - loss: 0.5250 - accuracy: 0.7942 - val_loss: 0.4616 - val_accuracy: 0.8166\n",
      "Epoch 494/1000\n",
      "225/225 [==============================] - 1s 2ms/step - loss: 0.5243 - accuracy: 0.7938 - val_loss: 0.4614 - val_accuracy: 0.8214\n",
      "Epoch 495/1000\n",
      "225/225 [==============================] - 1s 2ms/step - loss: 0.5293 - accuracy: 0.7921 - val_loss: 0.4662 - val_accuracy: 0.8178\n",
      "Epoch 496/1000\n",
      "225/225 [==============================] - 1s 2ms/step - loss: 0.5248 - accuracy: 0.7950 - val_loss: 0.4611 - val_accuracy: 0.8190\n",
      "Epoch 497/1000\n",
      "225/225 [==============================] - 1s 2ms/step - loss: 0.5231 - accuracy: 0.7952 - val_loss: 0.4606 - val_accuracy: 0.8223\n",
      "Epoch 498/1000\n",
      "225/225 [==============================] - 1s 2ms/step - loss: 0.5251 - accuracy: 0.7923 - val_loss: 0.4631 - val_accuracy: 0.8217\n",
      "Epoch 499/1000\n",
      "225/225 [==============================] - 1s 2ms/step - loss: 0.5262 - accuracy: 0.7943 - val_loss: 0.4632 - val_accuracy: 0.8206\n",
      "Epoch 500/1000\n",
      "225/225 [==============================] - 1s 2ms/step - loss: 0.5257 - accuracy: 0.7950 - val_loss: 0.4607 - val_accuracy: 0.8224\n",
      "Epoch 501/1000\n",
      "225/225 [==============================] - 1s 2ms/step - loss: 0.5237 - accuracy: 0.7948 - val_loss: 0.4593 - val_accuracy: 0.8214\n",
      "Epoch 502/1000\n",
      "225/225 [==============================] - 1s 2ms/step - loss: 0.5258 - accuracy: 0.7944 - val_loss: 0.4647 - val_accuracy: 0.8180\n",
      "Epoch 503/1000\n",
      "225/225 [==============================] - 1s 2ms/step - loss: 0.5262 - accuracy: 0.7927 - val_loss: 0.4629 - val_accuracy: 0.8188\n",
      "Epoch 504/1000\n",
      "225/225 [==============================] - 1s 2ms/step - loss: 0.5241 - accuracy: 0.7943 - val_loss: 0.4615 - val_accuracy: 0.8209\n",
      "Epoch 505/1000\n",
      "225/225 [==============================] - 1s 2ms/step - loss: 0.5245 - accuracy: 0.7945 - val_loss: 0.4649 - val_accuracy: 0.8195\n",
      "Epoch 506/1000\n",
      "225/225 [==============================] - 1s 2ms/step - loss: 0.5271 - accuracy: 0.7940 - val_loss: 0.4630 - val_accuracy: 0.8205\n",
      "Epoch 507/1000\n",
      "225/225 [==============================] - 1s 2ms/step - loss: 0.5260 - accuracy: 0.7931 - val_loss: 0.4647 - val_accuracy: 0.8196\n",
      "Epoch 508/1000\n",
      "225/225 [==============================] - 1s 2ms/step - loss: 0.5245 - accuracy: 0.7936 - val_loss: 0.4617 - val_accuracy: 0.8222\n",
      "Epoch 509/1000\n",
      "225/225 [==============================] - 1s 2ms/step - loss: 0.5255 - accuracy: 0.7943 - val_loss: 0.4638 - val_accuracy: 0.8221\n",
      "Epoch 510/1000\n",
      "225/225 [==============================] - 1s 2ms/step - loss: 0.5279 - accuracy: 0.7913 - val_loss: 0.4655 - val_accuracy: 0.8179\n",
      "Epoch 511/1000\n",
      "225/225 [==============================] - 1s 2ms/step - loss: 0.5276 - accuracy: 0.7945 - val_loss: 0.4624 - val_accuracy: 0.8231\n",
      "Epoch 512/1000\n",
      "225/225 [==============================] - 1s 2ms/step - loss: 0.5257 - accuracy: 0.7944 - val_loss: 0.4637 - val_accuracy: 0.8207\n",
      "Epoch 513/1000\n",
      "225/225 [==============================] - 1s 2ms/step - loss: 0.5258 - accuracy: 0.7950 - val_loss: 0.4654 - val_accuracy: 0.8182\n",
      "Epoch 514/1000\n",
      "225/225 [==============================] - 1s 2ms/step - loss: 0.5258 - accuracy: 0.7943 - val_loss: 0.4618 - val_accuracy: 0.8200\n",
      "Epoch 515/1000\n",
      "225/225 [==============================] - 1s 2ms/step - loss: 0.5262 - accuracy: 0.7927 - val_loss: 0.4634 - val_accuracy: 0.8201\n",
      "Epoch 516/1000\n",
      "225/225 [==============================] - 1s 2ms/step - loss: 0.5245 - accuracy: 0.7950 - val_loss: 0.4625 - val_accuracy: 0.8243\n",
      "Epoch 517/1000\n",
      "225/225 [==============================] - 1s 2ms/step - loss: 0.5234 - accuracy: 0.7950 - val_loss: 0.4649 - val_accuracy: 0.8206\n",
      "Epoch 518/1000\n",
      "225/225 [==============================] - 1s 2ms/step - loss: 0.5239 - accuracy: 0.7951 - val_loss: 0.4619 - val_accuracy: 0.8192\n",
      "Epoch 519/1000\n",
      "225/225 [==============================] - 1s 2ms/step - loss: 0.5242 - accuracy: 0.7948 - val_loss: 0.4629 - val_accuracy: 0.8208\n",
      "Epoch 520/1000\n",
      "225/225 [==============================] - 1s 2ms/step - loss: 0.5246 - accuracy: 0.7944 - val_loss: 0.4595 - val_accuracy: 0.8209\n",
      "Epoch 521/1000\n",
      "225/225 [==============================] - 1s 2ms/step - loss: 0.5234 - accuracy: 0.7950 - val_loss: 0.4621 - val_accuracy: 0.8198\n",
      "Epoch 522/1000\n",
      "225/225 [==============================] - 1s 2ms/step - loss: 0.5258 - accuracy: 0.7939 - val_loss: 0.4615 - val_accuracy: 0.8239\n",
      "Epoch 523/1000\n",
      "225/225 [==============================] - 1s 2ms/step - loss: 0.5239 - accuracy: 0.7943 - val_loss: 0.4609 - val_accuracy: 0.8210\n",
      "Epoch 524/1000\n",
      "225/225 [==============================] - 1s 2ms/step - loss: 0.5245 - accuracy: 0.7954 - val_loss: 0.4601 - val_accuracy: 0.8218\n",
      "Epoch 525/1000\n",
      "225/225 [==============================] - 1s 2ms/step - loss: 0.5268 - accuracy: 0.7939 - val_loss: 0.4623 - val_accuracy: 0.8204\n",
      "Epoch 526/1000\n",
      "225/225 [==============================] - 1s 2ms/step - loss: 0.5237 - accuracy: 0.7953 - val_loss: 0.4614 - val_accuracy: 0.8215\n",
      "Epoch 527/1000\n",
      "225/225 [==============================] - 1s 2ms/step - loss: 0.5238 - accuracy: 0.7941 - val_loss: 0.4614 - val_accuracy: 0.8188\n",
      "Epoch 528/1000\n",
      "225/225 [==============================] - 1s 2ms/step - loss: 0.5232 - accuracy: 0.7959 - val_loss: 0.4603 - val_accuracy: 0.8194\n",
      "Epoch 529/1000\n",
      "225/225 [==============================] - 1s 2ms/step - loss: 0.5261 - accuracy: 0.7941 - val_loss: 0.4645 - val_accuracy: 0.8181\n",
      "Epoch 530/1000\n",
      "225/225 [==============================] - 1s 2ms/step - loss: 0.5244 - accuracy: 0.7941 - val_loss: 0.4627 - val_accuracy: 0.8188\n",
      "Epoch 531/1000\n",
      "225/225 [==============================] - 1s 2ms/step - loss: 0.5233 - accuracy: 0.7949 - val_loss: 0.4625 - val_accuracy: 0.8207\n",
      "Epoch 532/1000\n",
      "225/225 [==============================] - 1s 2ms/step - loss: 0.5242 - accuracy: 0.7952 - val_loss: 0.4629 - val_accuracy: 0.8206\n",
      "Epoch 533/1000\n",
      "225/225 [==============================] - 1s 2ms/step - loss: 0.5256 - accuracy: 0.7930 - val_loss: 0.4623 - val_accuracy: 0.8191\n",
      "Epoch 534/1000\n",
      "225/225 [==============================] - 1s 2ms/step - loss: 0.5230 - accuracy: 0.7951 - val_loss: 0.4646 - val_accuracy: 0.8202\n",
      "Epoch 535/1000\n",
      "225/225 [==============================] - 1s 2ms/step - loss: 0.5235 - accuracy: 0.7952 - val_loss: 0.4625 - val_accuracy: 0.8217\n",
      "Epoch 536/1000\n",
      "225/225 [==============================] - 1s 2ms/step - loss: 0.5237 - accuracy: 0.7952 - val_loss: 0.4628 - val_accuracy: 0.8210\n",
      "Epoch 537/1000\n",
      "225/225 [==============================] - 1s 2ms/step - loss: 0.5242 - accuracy: 0.7956 - val_loss: 0.4637 - val_accuracy: 0.8226\n",
      "Epoch 538/1000\n",
      "225/225 [==============================] - 1s 2ms/step - loss: 0.5241 - accuracy: 0.7949 - val_loss: 0.4648 - val_accuracy: 0.8208\n",
      "Epoch 539/1000\n",
      "225/225 [==============================] - 1s 2ms/step - loss: 0.5224 - accuracy: 0.7948 - val_loss: 0.4602 - val_accuracy: 0.8224\n",
      "Epoch 540/1000\n",
      "225/225 [==============================] - 1s 2ms/step - loss: 0.5256 - accuracy: 0.7945 - val_loss: 0.4632 - val_accuracy: 0.8217\n",
      "Epoch 541/1000\n",
      "225/225 [==============================] - 1s 2ms/step - loss: 0.5253 - accuracy: 0.7946 - val_loss: 0.4633 - val_accuracy: 0.8195\n",
      "Epoch 542/1000\n",
      "225/225 [==============================] - 1s 2ms/step - loss: 0.5250 - accuracy: 0.7941 - val_loss: 0.4626 - val_accuracy: 0.8232\n",
      "Epoch 543/1000\n",
      "225/225 [==============================] - 1s 2ms/step - loss: 0.5247 - accuracy: 0.7943 - val_loss: 0.4612 - val_accuracy: 0.8199\n",
      "Epoch 544/1000\n",
      "225/225 [==============================] - 1s 2ms/step - loss: 0.5248 - accuracy: 0.7940 - val_loss: 0.4643 - val_accuracy: 0.8213\n",
      "Epoch 545/1000\n",
      "225/225 [==============================] - 1s 2ms/step - loss: 0.5259 - accuracy: 0.7945 - val_loss: 0.4611 - val_accuracy: 0.8221\n",
      "Epoch 546/1000\n",
      "225/225 [==============================] - 1s 2ms/step - loss: 0.5238 - accuracy: 0.7949 - val_loss: 0.4626 - val_accuracy: 0.8227\n",
      "Epoch 547/1000\n",
      "225/225 [==============================] - 1s 2ms/step - loss: 0.5235 - accuracy: 0.7935 - val_loss: 0.4629 - val_accuracy: 0.8194\n",
      "Epoch 548/1000\n",
      "225/225 [==============================] - 1s 2ms/step - loss: 0.5237 - accuracy: 0.7950 - val_loss: 0.4626 - val_accuracy: 0.8193\n",
      "Epoch 549/1000\n",
      "225/225 [==============================] - 1s 2ms/step - loss: 0.5253 - accuracy: 0.7949 - val_loss: 0.4634 - val_accuracy: 0.8202\n",
      "Epoch 550/1000\n",
      "225/225 [==============================] - 1s 2ms/step - loss: 0.5241 - accuracy: 0.7938 - val_loss: 0.4622 - val_accuracy: 0.8225\n",
      "Epoch 551/1000\n",
      "225/225 [==============================] - 1s 2ms/step - loss: 0.5224 - accuracy: 0.7961 - val_loss: 0.4632 - val_accuracy: 0.8209\n",
      "Epoch 552/1000\n",
      "225/225 [==============================] - 1s 3ms/step - loss: 0.5254 - accuracy: 0.7962 - val_loss: 0.4628 - val_accuracy: 0.8220\n",
      "Epoch 553/1000\n",
      "225/225 [==============================] - 1s 2ms/step - loss: 0.5233 - accuracy: 0.7946 - val_loss: 0.4621 - val_accuracy: 0.8220\n",
      "Epoch 554/1000\n",
      "225/225 [==============================] - 1s 2ms/step - loss: 0.5234 - accuracy: 0.7961 - val_loss: 0.4638 - val_accuracy: 0.8195\n",
      "Epoch 555/1000\n",
      "225/225 [==============================] - 1s 2ms/step - loss: 0.5228 - accuracy: 0.7946 - val_loss: 0.4609 - val_accuracy: 0.8203\n",
      "Epoch 556/1000\n",
      "225/225 [==============================] - 1s 2ms/step - loss: 0.5241 - accuracy: 0.7952 - val_loss: 0.4634 - val_accuracy: 0.8196\n",
      "Epoch 557/1000\n",
      "225/225 [==============================] - 1s 2ms/step - loss: 0.5247 - accuracy: 0.7954 - val_loss: 0.4632 - val_accuracy: 0.8225\n",
      "Epoch 558/1000\n",
      "225/225 [==============================] - 1s 2ms/step - loss: 0.5259 - accuracy: 0.7935 - val_loss: 0.4645 - val_accuracy: 0.8213\n",
      "Epoch 559/1000\n",
      "225/225 [==============================] - 1s 2ms/step - loss: 0.5240 - accuracy: 0.7942 - val_loss: 0.4608 - val_accuracy: 0.8209\n",
      "Epoch 560/1000\n",
      "225/225 [==============================] - 1s 2ms/step - loss: 0.5233 - accuracy: 0.7946 - val_loss: 0.4629 - val_accuracy: 0.8215\n",
      "Epoch 561/1000\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "225/225 [==============================] - 1s 2ms/step - loss: 0.5238 - accuracy: 0.7939 - val_loss: 0.4645 - val_accuracy: 0.8224\n",
      "Epoch 562/1000\n",
      "225/225 [==============================] - 1s 2ms/step - loss: 0.5242 - accuracy: 0.7948 - val_loss: 0.4609 - val_accuracy: 0.8210\n",
      "Epoch 563/1000\n",
      "225/225 [==============================] - 1s 2ms/step - loss: 0.5228 - accuracy: 0.7939 - val_loss: 0.4616 - val_accuracy: 0.8194\n",
      "Epoch 564/1000\n",
      "225/225 [==============================] - 1s 2ms/step - loss: 0.5234 - accuracy: 0.7947 - val_loss: 0.4600 - val_accuracy: 0.8217\n",
      "Epoch 565/1000\n",
      "225/225 [==============================] - 1s 2ms/step - loss: 0.5250 - accuracy: 0.7950 - val_loss: 0.4615 - val_accuracy: 0.8238\n",
      "Epoch 566/1000\n",
      "225/225 [==============================] - 1s 2ms/step - loss: 0.5229 - accuracy: 0.7958 - val_loss: 0.4587 - val_accuracy: 0.8226\n",
      "Epoch 567/1000\n",
      "225/225 [==============================] - 1s 2ms/step - loss: 0.5231 - accuracy: 0.7949 - val_loss: 0.4612 - val_accuracy: 0.8209\n",
      "Epoch 568/1000\n",
      "225/225 [==============================] - 1s 2ms/step - loss: 0.5243 - accuracy: 0.7945 - val_loss: 0.4602 - val_accuracy: 0.8194\n",
      "Epoch 569/1000\n",
      "225/225 [==============================] - 1s 2ms/step - loss: 0.5220 - accuracy: 0.7974 - val_loss: 0.4609 - val_accuracy: 0.8218\n",
      "Epoch 570/1000\n",
      "225/225 [==============================] - 1s 2ms/step - loss: 0.5230 - accuracy: 0.7950 - val_loss: 0.4607 - val_accuracy: 0.8208\n",
      "Epoch 571/1000\n",
      "225/225 [==============================] - 1s 2ms/step - loss: 0.5233 - accuracy: 0.7949 - val_loss: 0.4624 - val_accuracy: 0.8201\n",
      "Epoch 572/1000\n",
      "225/225 [==============================] - 1s 2ms/step - loss: 0.5231 - accuracy: 0.7948 - val_loss: 0.4598 - val_accuracy: 0.8222\n",
      "Epoch 573/1000\n",
      "225/225 [==============================] - 1s 2ms/step - loss: 0.5260 - accuracy: 0.7951 - val_loss: 0.4603 - val_accuracy: 0.8218\n",
      "Epoch 574/1000\n",
      "225/225 [==============================] - 1s 2ms/step - loss: 0.5218 - accuracy: 0.7963 - val_loss: 0.4607 - val_accuracy: 0.8223\n",
      "Epoch 575/1000\n",
      "225/225 [==============================] - 1s 2ms/step - loss: 0.5225 - accuracy: 0.7946 - val_loss: 0.4605 - val_accuracy: 0.8203\n",
      "Epoch 576/1000\n",
      "225/225 [==============================] - 1s 3ms/step - loss: 0.5231 - accuracy: 0.7944 - val_loss: 0.4613 - val_accuracy: 0.8213\n",
      "Epoch 577/1000\n",
      "225/225 [==============================] - 1s 2ms/step - loss: 0.5218 - accuracy: 0.7954 - val_loss: 0.4604 - val_accuracy: 0.8209\n",
      "Epoch 578/1000\n",
      "225/225 [==============================] - 1s 2ms/step - loss: 0.5230 - accuracy: 0.7945 - val_loss: 0.4630 - val_accuracy: 0.8197\n",
      "Epoch 579/1000\n",
      "225/225 [==============================] - 1s 2ms/step - loss: 0.5244 - accuracy: 0.7948 - val_loss: 0.4648 - val_accuracy: 0.8180\n",
      "Epoch 580/1000\n",
      "225/225 [==============================] - 1s 2ms/step - loss: 0.5232 - accuracy: 0.7953 - val_loss: 0.4629 - val_accuracy: 0.8174\n",
      "Epoch 581/1000\n",
      "225/225 [==============================] - 1s 2ms/step - loss: 0.5233 - accuracy: 0.7952 - val_loss: 0.4613 - val_accuracy: 0.8194\n",
      "Epoch 582/1000\n",
      "225/225 [==============================] - 1s 2ms/step - loss: 0.5218 - accuracy: 0.7955 - val_loss: 0.4631 - val_accuracy: 0.8220\n",
      "Epoch 583/1000\n",
      "225/225 [==============================] - 1s 2ms/step - loss: 0.5228 - accuracy: 0.7944 - val_loss: 0.4612 - val_accuracy: 0.8211\n",
      "Epoch 584/1000\n",
      "225/225 [==============================] - 1s 2ms/step - loss: 0.5213 - accuracy: 0.7960 - val_loss: 0.4616 - val_accuracy: 0.8192\n",
      "Epoch 585/1000\n",
      "225/225 [==============================] - 1s 2ms/step - loss: 0.5223 - accuracy: 0.7962 - val_loss: 0.4622 - val_accuracy: 0.8207\n",
      "Epoch 586/1000\n",
      "225/225 [==============================] - 1s 2ms/step - loss: 0.5222 - accuracy: 0.7960 - val_loss: 0.4606 - val_accuracy: 0.8222\n",
      "Epoch 587/1000\n",
      "225/225 [==============================] - 1s 2ms/step - loss: 0.5227 - accuracy: 0.7953 - val_loss: 0.4575 - val_accuracy: 0.8243\n",
      "Epoch 588/1000\n",
      "225/225 [==============================] - 1s 2ms/step - loss: 0.5222 - accuracy: 0.7965 - val_loss: 0.4603 - val_accuracy: 0.8220\n",
      "Epoch 589/1000\n",
      "225/225 [==============================] - 1s 2ms/step - loss: 0.5231 - accuracy: 0.7947 - val_loss: 0.4603 - val_accuracy: 0.8221\n",
      "Epoch 590/1000\n",
      "225/225 [==============================] - 1s 2ms/step - loss: 0.5225 - accuracy: 0.7941 - val_loss: 0.4627 - val_accuracy: 0.8202\n",
      "Epoch 591/1000\n",
      "225/225 [==============================] - 1s 2ms/step - loss: 0.5229 - accuracy: 0.7956 - val_loss: 0.4580 - val_accuracy: 0.8209\n",
      "Epoch 592/1000\n",
      "225/225 [==============================] - 1s 2ms/step - loss: 0.5199 - accuracy: 0.7961 - val_loss: 0.4609 - val_accuracy: 0.8218\n",
      "Epoch 593/1000\n",
      "225/225 [==============================] - 1s 3ms/step - loss: 0.5224 - accuracy: 0.7959 - val_loss: 0.4593 - val_accuracy: 0.8219\n",
      "Epoch 594/1000\n",
      "225/225 [==============================] - 1s 2ms/step - loss: 0.5225 - accuracy: 0.7958 - val_loss: 0.4607 - val_accuracy: 0.8226\n",
      "Epoch 595/1000\n",
      "225/225 [==============================] - 1s 2ms/step - loss: 0.5222 - accuracy: 0.7951 - val_loss: 0.4587 - val_accuracy: 0.8225\n",
      "Epoch 596/1000\n",
      "225/225 [==============================] - 1s 2ms/step - loss: 0.5231 - accuracy: 0.7948 - val_loss: 0.4597 - val_accuracy: 0.8221\n",
      "Epoch 597/1000\n",
      "225/225 [==============================] - 1s 3ms/step - loss: 0.5235 - accuracy: 0.7960 - val_loss: 0.4622 - val_accuracy: 0.8198\n",
      "Epoch 598/1000\n",
      "225/225 [==============================] - 1s 2ms/step - loss: 0.5218 - accuracy: 0.7956 - val_loss: 0.4583 - val_accuracy: 0.8211\n",
      "Epoch 599/1000\n",
      "225/225 [==============================] - 1s 2ms/step - loss: 0.5234 - accuracy: 0.7946 - val_loss: 0.4609 - val_accuracy: 0.8206\n",
      "Epoch 600/1000\n",
      "225/225 [==============================] - 1s 2ms/step - loss: 0.5214 - accuracy: 0.7955 - val_loss: 0.4579 - val_accuracy: 0.8214\n",
      "Epoch 601/1000\n",
      "225/225 [==============================] - 1s 2ms/step - loss: 0.5217 - accuracy: 0.7960 - val_loss: 0.4595 - val_accuracy: 0.8202\n",
      "Epoch 602/1000\n",
      "225/225 [==============================] - 1s 2ms/step - loss: 0.5229 - accuracy: 0.7951 - val_loss: 0.4609 - val_accuracy: 0.8212\n",
      "Epoch 603/1000\n",
      "225/225 [==============================] - 1s 2ms/step - loss: 0.5219 - accuracy: 0.7951 - val_loss: 0.4613 - val_accuracy: 0.8197\n",
      "Epoch 604/1000\n",
      "225/225 [==============================] - 1s 2ms/step - loss: 0.5196 - accuracy: 0.7961 - val_loss: 0.4594 - val_accuracy: 0.8215\n",
      "Epoch 605/1000\n",
      "225/225 [==============================] - 1s 2ms/step - loss: 0.5234 - accuracy: 0.7943 - val_loss: 0.4597 - val_accuracy: 0.8217\n",
      "Epoch 606/1000\n",
      "225/225 [==============================] - 1s 2ms/step - loss: 0.5248 - accuracy: 0.7934 - val_loss: 0.4640 - val_accuracy: 0.8213\n",
      "Epoch 607/1000\n",
      "225/225 [==============================] - 1s 2ms/step - loss: 0.5212 - accuracy: 0.7952 - val_loss: 0.4600 - val_accuracy: 0.8232\n",
      "Epoch 608/1000\n",
      "225/225 [==============================] - 1s 2ms/step - loss: 0.5231 - accuracy: 0.7955 - val_loss: 0.4614 - val_accuracy: 0.8200\n",
      "Epoch 609/1000\n",
      "225/225 [==============================] - 1s 2ms/step - loss: 0.5238 - accuracy: 0.7952 - val_loss: 0.4617 - val_accuracy: 0.8192\n",
      "Epoch 610/1000\n",
      "225/225 [==============================] - 1s 2ms/step - loss: 0.5237 - accuracy: 0.7948 - val_loss: 0.4602 - val_accuracy: 0.8213\n",
      "Epoch 611/1000\n",
      "225/225 [==============================] - 1s 2ms/step - loss: 0.5253 - accuracy: 0.7945 - val_loss: 0.4633 - val_accuracy: 0.8213\n",
      "Epoch 612/1000\n",
      "225/225 [==============================] - 1s 2ms/step - loss: 0.5227 - accuracy: 0.7946 - val_loss: 0.4609 - val_accuracy: 0.8212\n",
      "Epoch 613/1000\n",
      "225/225 [==============================] - 1s 2ms/step - loss: 0.5231 - accuracy: 0.7950 - val_loss: 0.4585 - val_accuracy: 0.8217\n",
      "Epoch 614/1000\n",
      "225/225 [==============================] - 1s 2ms/step - loss: 0.5224 - accuracy: 0.7959 - val_loss: 0.4565 - val_accuracy: 0.8229\n",
      "Epoch 615/1000\n",
      "225/225 [==============================] - 1s 2ms/step - loss: 0.5212 - accuracy: 0.7955 - val_loss: 0.4618 - val_accuracy: 0.8224\n",
      "Epoch 616/1000\n",
      "225/225 [==============================] - 1s 2ms/step - loss: 0.5240 - accuracy: 0.7953 - val_loss: 0.4603 - val_accuracy: 0.8218\n",
      "Epoch 617/1000\n",
      "225/225 [==============================] - 1s 2ms/step - loss: 0.5213 - accuracy: 0.7959 - val_loss: 0.4586 - val_accuracy: 0.8228\n",
      "Epoch 618/1000\n",
      "225/225 [==============================] - 1s 2ms/step - loss: 0.5221 - accuracy: 0.7959 - val_loss: 0.4605 - val_accuracy: 0.8224\n",
      "Epoch 619/1000\n",
      "225/225 [==============================] - 1s 2ms/step - loss: 0.5217 - accuracy: 0.7955 - val_loss: 0.4605 - val_accuracy: 0.8231\n",
      "Epoch 620/1000\n",
      "225/225 [==============================] - 1s 2ms/step - loss: 0.5200 - accuracy: 0.7961 - val_loss: 0.4592 - val_accuracy: 0.8221\n",
      "Epoch 621/1000\n",
      "225/225 [==============================] - 1s 2ms/step - loss: 0.5243 - accuracy: 0.7954 - val_loss: 0.4620 - val_accuracy: 0.8224\n",
      "Epoch 622/1000\n",
      "225/225 [==============================] - 1s 2ms/step - loss: 0.5221 - accuracy: 0.7959 - val_loss: 0.4620 - val_accuracy: 0.8209\n",
      "Epoch 623/1000\n",
      "225/225 [==============================] - 1s 2ms/step - loss: 0.5206 - accuracy: 0.7952 - val_loss: 0.4591 - val_accuracy: 0.8241\n",
      "Epoch 624/1000\n",
      "225/225 [==============================] - 1s 2ms/step - loss: 0.5219 - accuracy: 0.7953 - val_loss: 0.4613 - val_accuracy: 0.8221\n",
      "Epoch 625/1000\n",
      "225/225 [==============================] - 1s 2ms/step - loss: 0.5236 - accuracy: 0.7951 - val_loss: 0.4593 - val_accuracy: 0.8227\n",
      "Epoch 626/1000\n",
      "225/225 [==============================] - 1s 2ms/step - loss: 0.5217 - accuracy: 0.7954 - val_loss: 0.4579 - val_accuracy: 0.8224\n",
      "Epoch 627/1000\n",
      "225/225 [==============================] - 1s 2ms/step - loss: 0.5224 - accuracy: 0.7950 - val_loss: 0.4578 - val_accuracy: 0.8233\n",
      "Epoch 628/1000\n",
      "225/225 [==============================] - 1s 2ms/step - loss: 0.5214 - accuracy: 0.7951 - val_loss: 0.4604 - val_accuracy: 0.8242\n",
      "Epoch 629/1000\n",
      "225/225 [==============================] - 1s 2ms/step - loss: 0.5221 - accuracy: 0.7961 - val_loss: 0.4582 - val_accuracy: 0.8243\n",
      "Epoch 630/1000\n",
      "225/225 [==============================] - 1s 2ms/step - loss: 0.5223 - accuracy: 0.7960 - val_loss: 0.4628 - val_accuracy: 0.8236\n",
      "Epoch 631/1000\n",
      "225/225 [==============================] - 1s 2ms/step - loss: 0.5215 - accuracy: 0.7954 - val_loss: 0.4597 - val_accuracy: 0.8224\n",
      "Epoch 632/1000\n",
      "225/225 [==============================] - 1s 2ms/step - loss: 0.5224 - accuracy: 0.7957 - val_loss: 0.4576 - val_accuracy: 0.8228\n",
      "Epoch 633/1000\n",
      "225/225 [==============================] - 1s 2ms/step - loss: 0.5207 - accuracy: 0.7967 - val_loss: 0.4596 - val_accuracy: 0.8224\n",
      "Epoch 634/1000\n",
      "225/225 [==============================] - 1s 2ms/step - loss: 0.5231 - accuracy: 0.7951 - val_loss: 0.4621 - val_accuracy: 0.8208\n",
      "Epoch 635/1000\n",
      "225/225 [==============================] - 1s 2ms/step - loss: 0.5225 - accuracy: 0.7960 - val_loss: 0.4592 - val_accuracy: 0.8242\n",
      "Epoch 636/1000\n",
      "225/225 [==============================] - 1s 3ms/step - loss: 0.5180 - accuracy: 0.7970 - val_loss: 0.4584 - val_accuracy: 0.8235\n",
      "Epoch 637/1000\n",
      "225/225 [==============================] - 1s 2ms/step - loss: 0.5198 - accuracy: 0.7966 - val_loss: 0.4592 - val_accuracy: 0.8232\n",
      "Epoch 638/1000\n",
      "225/225 [==============================] - 1s 2ms/step - loss: 0.5234 - accuracy: 0.7968 - val_loss: 0.4596 - val_accuracy: 0.8245\n",
      "Epoch 639/1000\n",
      "225/225 [==============================] - 1s 2ms/step - loss: 0.5203 - accuracy: 0.7960 - val_loss: 0.4567 - val_accuracy: 0.8236\n",
      "Epoch 640/1000\n",
      "225/225 [==============================] - 1s 2ms/step - loss: 0.5220 - accuracy: 0.7968 - val_loss: 0.4585 - val_accuracy: 0.8226\n",
      "Epoch 641/1000\n",
      "225/225 [==============================] - 1s 2ms/step - loss: 0.5216 - accuracy: 0.7958 - val_loss: 0.4581 - val_accuracy: 0.8219\n",
      "Epoch 642/1000\n",
      "225/225 [==============================] - 1s 2ms/step - loss: 0.5197 - accuracy: 0.7970 - val_loss: 0.4572 - val_accuracy: 0.8241\n",
      "Epoch 643/1000\n",
      "225/225 [==============================] - 1s 2ms/step - loss: 0.5236 - accuracy: 0.7955 - val_loss: 0.4579 - val_accuracy: 0.8235\n",
      "Epoch 644/1000\n",
      "225/225 [==============================] - 1s 2ms/step - loss: 0.5212 - accuracy: 0.7959 - val_loss: 0.4564 - val_accuracy: 0.8217\n",
      "Epoch 645/1000\n",
      "225/225 [==============================] - 1s 2ms/step - loss: 0.5226 - accuracy: 0.7958 - val_loss: 0.4589 - val_accuracy: 0.8243\n",
      "Epoch 646/1000\n",
      "225/225 [==============================] - 1s 2ms/step - loss: 0.5204 - accuracy: 0.7967 - val_loss: 0.4592 - val_accuracy: 0.8228\n",
      "Epoch 647/1000\n",
      "225/225 [==============================] - 1s 2ms/step - loss: 0.5205 - accuracy: 0.7957 - val_loss: 0.4591 - val_accuracy: 0.8247\n",
      "Epoch 648/1000\n",
      "225/225 [==============================] - 1s 2ms/step - loss: 0.5218 - accuracy: 0.7953 - val_loss: 0.4598 - val_accuracy: 0.8242\n",
      "Epoch 649/1000\n",
      "225/225 [==============================] - 1s 2ms/step - loss: 0.5201 - accuracy: 0.7975 - val_loss: 0.4582 - val_accuracy: 0.8230\n",
      "Epoch 650/1000\n",
      "225/225 [==============================] - 1s 2ms/step - loss: 0.5217 - accuracy: 0.7967 - val_loss: 0.4560 - val_accuracy: 0.8231\n",
      "Epoch 651/1000\n",
      "225/225 [==============================] - 1s 2ms/step - loss: 0.5223 - accuracy: 0.7967 - val_loss: 0.4587 - val_accuracy: 0.8234\n",
      "Epoch 652/1000\n",
      "225/225 [==============================] - 1s 2ms/step - loss: 0.5228 - accuracy: 0.7963 - val_loss: 0.4596 - val_accuracy: 0.8235\n",
      "Epoch 653/1000\n",
      "225/225 [==============================] - 1s 2ms/step - loss: 0.5213 - accuracy: 0.7953 - val_loss: 0.4587 - val_accuracy: 0.8213\n",
      "Epoch 654/1000\n",
      "225/225 [==============================] - 1s 2ms/step - loss: 0.5196 - accuracy: 0.7966 - val_loss: 0.4566 - val_accuracy: 0.8231\n",
      "Epoch 655/1000\n",
      "225/225 [==============================] - 1s 2ms/step - loss: 0.5214 - accuracy: 0.7953 - val_loss: 0.4551 - val_accuracy: 0.8236\n",
      "Epoch 656/1000\n",
      "225/225 [==============================] - 1s 2ms/step - loss: 0.5199 - accuracy: 0.7955 - val_loss: 0.4590 - val_accuracy: 0.8230\n",
      "Epoch 657/1000\n",
      "225/225 [==============================] - 1s 2ms/step - loss: 0.5229 - accuracy: 0.7950 - val_loss: 0.4562 - val_accuracy: 0.8243\n",
      "Epoch 658/1000\n",
      "225/225 [==============================] - 1s 2ms/step - loss: 0.5217 - accuracy: 0.7956 - val_loss: 0.4559 - val_accuracy: 0.8242\n",
      "Epoch 659/1000\n",
      "225/225 [==============================] - 1s 2ms/step - loss: 0.5217 - accuracy: 0.7957 - val_loss: 0.4547 - val_accuracy: 0.8248\n",
      "Epoch 660/1000\n",
      "225/225 [==============================] - 1s 2ms/step - loss: 0.5199 - accuracy: 0.7943 - val_loss: 0.4607 - val_accuracy: 0.8222\n",
      "Epoch 661/1000\n",
      "225/225 [==============================] - 1s 2ms/step - loss: 0.5207 - accuracy: 0.7953 - val_loss: 0.4590 - val_accuracy: 0.8242\n",
      "Epoch 662/1000\n",
      "225/225 [==============================] - 1s 2ms/step - loss: 0.5210 - accuracy: 0.7970 - val_loss: 0.4597 - val_accuracy: 0.8226\n",
      "Epoch 663/1000\n",
      "225/225 [==============================] - 1s 3ms/step - loss: 0.5178 - accuracy: 0.7981 - val_loss: 0.4595 - val_accuracy: 0.8229\n",
      "Epoch 664/1000\n",
      "225/225 [==============================] - 1s 2ms/step - loss: 0.5214 - accuracy: 0.7957 - val_loss: 0.4615 - val_accuracy: 0.8222\n",
      "Epoch 665/1000\n",
      "225/225 [==============================] - 1s 2ms/step - loss: 0.5223 - accuracy: 0.7952 - val_loss: 0.4580 - val_accuracy: 0.8245\n",
      "Epoch 666/1000\n",
      "225/225 [==============================] - 1s 2ms/step - loss: 0.5207 - accuracy: 0.7970 - val_loss: 0.4591 - val_accuracy: 0.8261\n",
      "Epoch 667/1000\n",
      "225/225 [==============================] - 1s 2ms/step - loss: 0.5225 - accuracy: 0.7952 - val_loss: 0.4572 - val_accuracy: 0.8231\n",
      "Epoch 668/1000\n",
      "225/225 [==============================] - 1s 2ms/step - loss: 0.5199 - accuracy: 0.7974 - val_loss: 0.4596 - val_accuracy: 0.8220\n",
      "Epoch 669/1000\n",
      "225/225 [==============================] - 1s 2ms/step - loss: 0.5194 - accuracy: 0.7982 - val_loss: 0.4587 - val_accuracy: 0.8228\n",
      "Epoch 670/1000\n",
      "225/225 [==============================] - 1s 2ms/step - loss: 0.5217 - accuracy: 0.7957 - val_loss: 0.4575 - val_accuracy: 0.8237\n",
      "Epoch 671/1000\n",
      "225/225 [==============================] - 1s 2ms/step - loss: 0.5202 - accuracy: 0.7964 - val_loss: 0.4569 - val_accuracy: 0.8239\n",
      "Epoch 672/1000\n",
      "225/225 [==============================] - 1s 2ms/step - loss: 0.5232 - accuracy: 0.7955 - val_loss: 0.4582 - val_accuracy: 0.8243\n",
      "Epoch 673/1000\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "225/225 [==============================] - 1s 2ms/step - loss: 0.5189 - accuracy: 0.7978 - val_loss: 0.4576 - val_accuracy: 0.8224\n",
      "Epoch 674/1000\n",
      "225/225 [==============================] - 1s 2ms/step - loss: 0.5213 - accuracy: 0.7962 - val_loss: 0.4586 - val_accuracy: 0.8226\n",
      "Epoch 675/1000\n",
      "225/225 [==============================] - 1s 2ms/step - loss: 0.5193 - accuracy: 0.7971 - val_loss: 0.4584 - val_accuracy: 0.8220\n",
      "Epoch 676/1000\n",
      "225/225 [==============================] - 1s 3ms/step - loss: 0.5216 - accuracy: 0.7964 - val_loss: 0.4593 - val_accuracy: 0.8236\n",
      "Epoch 677/1000\n",
      "225/225 [==============================] - 1s 2ms/step - loss: 0.5217 - accuracy: 0.7962 - val_loss: 0.4593 - val_accuracy: 0.8242\n",
      "Epoch 678/1000\n",
      "225/225 [==============================] - 1s 2ms/step - loss: 0.5204 - accuracy: 0.7970 - val_loss: 0.4594 - val_accuracy: 0.8239\n",
      "Epoch 679/1000\n",
      "225/225 [==============================] - 1s 3ms/step - loss: 0.5228 - accuracy: 0.7954 - val_loss: 0.4613 - val_accuracy: 0.8215\n",
      "Epoch 680/1000\n",
      "225/225 [==============================] - 1s 3ms/step - loss: 0.5217 - accuracy: 0.7964 - val_loss: 0.4603 - val_accuracy: 0.8236\n",
      "Epoch 681/1000\n",
      "225/225 [==============================] - 1s 2ms/step - loss: 0.5202 - accuracy: 0.7968 - val_loss: 0.4602 - val_accuracy: 0.8234\n",
      "Epoch 682/1000\n",
      "225/225 [==============================] - 1s 2ms/step - loss: 0.5214 - accuracy: 0.7945 - val_loss: 0.4541 - val_accuracy: 0.8244\n",
      "Epoch 683/1000\n",
      "225/225 [==============================] - 1s 2ms/step - loss: 0.5206 - accuracy: 0.7963 - val_loss: 0.4574 - val_accuracy: 0.8267\n",
      "Epoch 684/1000\n",
      "225/225 [==============================] - 1s 2ms/step - loss: 0.5205 - accuracy: 0.7958 - val_loss: 0.4557 - val_accuracy: 0.8272\n",
      "Epoch 685/1000\n",
      "225/225 [==============================] - 1s 2ms/step - loss: 0.5213 - accuracy: 0.7963 - val_loss: 0.4580 - val_accuracy: 0.8259\n",
      "Epoch 686/1000\n",
      "225/225 [==============================] - 1s 2ms/step - loss: 0.5199 - accuracy: 0.7972 - val_loss: 0.4578 - val_accuracy: 0.8219\n",
      "Epoch 687/1000\n",
      "225/225 [==============================] - 1s 2ms/step - loss: 0.5187 - accuracy: 0.7975 - val_loss: 0.4562 - val_accuracy: 0.8266\n",
      "Epoch 688/1000\n",
      "225/225 [==============================] - 1s 2ms/step - loss: 0.5210 - accuracy: 0.7966 - val_loss: 0.4570 - val_accuracy: 0.8239\n",
      "Epoch 689/1000\n",
      "225/225 [==============================] - 1s 3ms/step - loss: 0.5214 - accuracy: 0.7958 - val_loss: 0.4590 - val_accuracy: 0.8221\n",
      "Epoch 690/1000\n",
      "225/225 [==============================] - 1s 2ms/step - loss: 0.5192 - accuracy: 0.7971 - val_loss: 0.4552 - val_accuracy: 0.8233\n",
      "Epoch 691/1000\n",
      "225/225 [==============================] - 1s 2ms/step - loss: 0.5198 - accuracy: 0.7964 - val_loss: 0.4552 - val_accuracy: 0.8257\n",
      "Epoch 692/1000\n",
      "225/225 [==============================] - 1s 3ms/step - loss: 0.5220 - accuracy: 0.7969 - val_loss: 0.4563 - val_accuracy: 0.8248\n",
      "Epoch 693/1000\n",
      "225/225 [==============================] - 1s 2ms/step - loss: 0.5184 - accuracy: 0.7975 - val_loss: 0.4563 - val_accuracy: 0.8248\n",
      "Epoch 694/1000\n",
      "225/225 [==============================] - 1s 2ms/step - loss: 0.5198 - accuracy: 0.7964 - val_loss: 0.4584 - val_accuracy: 0.8236\n",
      "Epoch 695/1000\n",
      "225/225 [==============================] - 1s 2ms/step - loss: 0.5203 - accuracy: 0.7954 - val_loss: 0.4552 - val_accuracy: 0.8254\n",
      "Epoch 696/1000\n",
      "225/225 [==============================] - 1s 2ms/step - loss: 0.5209 - accuracy: 0.7969 - val_loss: 0.4552 - val_accuracy: 0.8268\n",
      "Epoch 697/1000\n",
      "225/225 [==============================] - 1s 2ms/step - loss: 0.5212 - accuracy: 0.7960 - val_loss: 0.4540 - val_accuracy: 0.8249\n",
      "Epoch 698/1000\n",
      "225/225 [==============================] - 1s 2ms/step - loss: 0.5205 - accuracy: 0.7969 - val_loss: 0.4598 - val_accuracy: 0.8231\n",
      "Epoch 699/1000\n",
      "225/225 [==============================] - 1s 2ms/step - loss: 0.5202 - accuracy: 0.7967 - val_loss: 0.4549 - val_accuracy: 0.8229\n",
      "Epoch 700/1000\n",
      "225/225 [==============================] - 1s 2ms/step - loss: 0.5203 - accuracy: 0.7967 - val_loss: 0.4577 - val_accuracy: 0.8246\n",
      "Epoch 701/1000\n",
      "225/225 [==============================] - 1s 2ms/step - loss: 0.5214 - accuracy: 0.7966 - val_loss: 0.4559 - val_accuracy: 0.8239\n",
      "Epoch 702/1000\n",
      "225/225 [==============================] - 1s 2ms/step - loss: 0.5200 - accuracy: 0.7954 - val_loss: 0.4595 - val_accuracy: 0.8228\n",
      "Epoch 703/1000\n",
      "225/225 [==============================] - 1s 2ms/step - loss: 0.5194 - accuracy: 0.7972 - val_loss: 0.4605 - val_accuracy: 0.8219\n",
      "Epoch 704/1000\n",
      "225/225 [==============================] - 1s 2ms/step - loss: 0.5215 - accuracy: 0.7959 - val_loss: 0.4572 - val_accuracy: 0.8253\n",
      "Epoch 705/1000\n",
      "225/225 [==============================] - 1s 2ms/step - loss: 0.5199 - accuracy: 0.7967 - val_loss: 0.4552 - val_accuracy: 0.8258\n",
      "Epoch 706/1000\n",
      "225/225 [==============================] - 1s 2ms/step - loss: 0.5182 - accuracy: 0.7975 - val_loss: 0.4573 - val_accuracy: 0.8245\n",
      "Epoch 707/1000\n",
      "225/225 [==============================] - 1s 2ms/step - loss: 0.5188 - accuracy: 0.7975 - val_loss: 0.4556 - val_accuracy: 0.8256\n",
      "Epoch 708/1000\n",
      "225/225 [==============================] - 1s 2ms/step - loss: 0.5213 - accuracy: 0.7957 - val_loss: 0.4555 - val_accuracy: 0.8242\n",
      "Epoch 709/1000\n",
      "225/225 [==============================] - 1s 2ms/step - loss: 0.5201 - accuracy: 0.7946 - val_loss: 0.4551 - val_accuracy: 0.8267\n",
      "Epoch 710/1000\n",
      "225/225 [==============================] - 1s 2ms/step - loss: 0.5213 - accuracy: 0.7953 - val_loss: 0.4558 - val_accuracy: 0.8261\n",
      "Epoch 711/1000\n",
      "225/225 [==============================] - 1s 2ms/step - loss: 0.5212 - accuracy: 0.7962 - val_loss: 0.4580 - val_accuracy: 0.8238\n",
      "Epoch 712/1000\n",
      "225/225 [==============================] - 1s 2ms/step - loss: 0.5219 - accuracy: 0.7952 - val_loss: 0.4587 - val_accuracy: 0.8236\n",
      "Epoch 713/1000\n",
      "225/225 [==============================] - 1s 2ms/step - loss: 0.5200 - accuracy: 0.7974 - val_loss: 0.4563 - val_accuracy: 0.8224\n",
      "Epoch 714/1000\n",
      "225/225 [==============================] - 1s 2ms/step - loss: 0.5213 - accuracy: 0.7958 - val_loss: 0.4580 - val_accuracy: 0.8248\n",
      "Epoch 715/1000\n",
      "225/225 [==============================] - 1s 2ms/step - loss: 0.5212 - accuracy: 0.7964 - val_loss: 0.4586 - val_accuracy: 0.8221\n",
      "Epoch 716/1000\n",
      "225/225 [==============================] - 1s 2ms/step - loss: 0.5181 - accuracy: 0.7983 - val_loss: 0.4557 - val_accuracy: 0.8246\n",
      "Epoch 717/1000\n",
      "225/225 [==============================] - 1s 2ms/step - loss: 0.5193 - accuracy: 0.7965 - val_loss: 0.4567 - val_accuracy: 0.8243\n",
      "Epoch 718/1000\n",
      "225/225 [==============================] - 1s 2ms/step - loss: 0.5190 - accuracy: 0.7968 - val_loss: 0.4534 - val_accuracy: 0.8246\n",
      "Epoch 719/1000\n",
      "225/225 [==============================] - 1s 2ms/step - loss: 0.5179 - accuracy: 0.7984 - val_loss: 0.4534 - val_accuracy: 0.8253\n",
      "Epoch 720/1000\n",
      "225/225 [==============================] - 1s 2ms/step - loss: 0.5200 - accuracy: 0.7962 - val_loss: 0.4580 - val_accuracy: 0.8243\n",
      "Epoch 721/1000\n",
      "225/225 [==============================] - 1s 2ms/step - loss: 0.5189 - accuracy: 0.7970 - val_loss: 0.4568 - val_accuracy: 0.8257\n",
      "Epoch 722/1000\n",
      "225/225 [==============================] - 1s 3ms/step - loss: 0.5193 - accuracy: 0.7970 - val_loss: 0.4562 - val_accuracy: 0.8235\n",
      "Epoch 723/1000\n",
      "225/225 [==============================] - 1s 2ms/step - loss: 0.5206 - accuracy: 0.7959 - val_loss: 0.4553 - val_accuracy: 0.8251\n",
      "Epoch 724/1000\n",
      "225/225 [==============================] - 1s 2ms/step - loss: 0.5181 - accuracy: 0.7971 - val_loss: 0.4579 - val_accuracy: 0.8219\n",
      "Epoch 725/1000\n",
      "225/225 [==============================] - 1s 2ms/step - loss: 0.5198 - accuracy: 0.7970 - val_loss: 0.4538 - val_accuracy: 0.8249\n",
      "Epoch 726/1000\n",
      "225/225 [==============================] - 1s 2ms/step - loss: 0.5219 - accuracy: 0.7952 - val_loss: 0.4575 - val_accuracy: 0.8249\n",
      "Epoch 727/1000\n",
      "225/225 [==============================] - 1s 2ms/step - loss: 0.5197 - accuracy: 0.7962 - val_loss: 0.4592 - val_accuracy: 0.8209\n",
      "Epoch 728/1000\n",
      "225/225 [==============================] - 1s 2ms/step - loss: 0.5195 - accuracy: 0.7968 - val_loss: 0.4537 - val_accuracy: 0.8253\n",
      "Epoch 729/1000\n",
      "225/225 [==============================] - 1s 2ms/step - loss: 0.5205 - accuracy: 0.7964 - val_loss: 0.4562 - val_accuracy: 0.8228\n",
      "Epoch 730/1000\n",
      "225/225 [==============================] - 1s 2ms/step - loss: 0.5190 - accuracy: 0.7974 - val_loss: 0.4553 - val_accuracy: 0.8279\n",
      "Epoch 731/1000\n",
      "225/225 [==============================] - 1s 2ms/step - loss: 0.5191 - accuracy: 0.7968 - val_loss: 0.4549 - val_accuracy: 0.8242\n",
      "Epoch 732/1000\n",
      "225/225 [==============================] - 1s 2ms/step - loss: 0.5195 - accuracy: 0.7974 - val_loss: 0.4556 - val_accuracy: 0.8239\n",
      "Epoch 733/1000\n",
      "225/225 [==============================] - 1s 2ms/step - loss: 0.5211 - accuracy: 0.7965 - val_loss: 0.4571 - val_accuracy: 0.8251\n",
      "Epoch 734/1000\n",
      "225/225 [==============================] - 1s 2ms/step - loss: 0.5203 - accuracy: 0.7966 - val_loss: 0.4568 - val_accuracy: 0.8249\n",
      "Epoch 735/1000\n",
      "225/225 [==============================] - 1s 2ms/step - loss: 0.5192 - accuracy: 0.7967 - val_loss: 0.4565 - val_accuracy: 0.8253\n",
      "Epoch 736/1000\n",
      "225/225 [==============================] - 1s 2ms/step - loss: 0.5217 - accuracy: 0.7950 - val_loss: 0.4545 - val_accuracy: 0.8243\n",
      "Epoch 737/1000\n",
      "225/225 [==============================] - 1s 2ms/step - loss: 0.5185 - accuracy: 0.7966 - val_loss: 0.4572 - val_accuracy: 0.8231\n",
      "Epoch 738/1000\n",
      "225/225 [==============================] - 1s 2ms/step - loss: 0.5186 - accuracy: 0.7976 - val_loss: 0.4564 - val_accuracy: 0.8256\n",
      "Epoch 739/1000\n",
      "225/225 [==============================] - 1s 2ms/step - loss: 0.5198 - accuracy: 0.7966 - val_loss: 0.4560 - val_accuracy: 0.8255\n",
      "Epoch 740/1000\n",
      "225/225 [==============================] - 1s 2ms/step - loss: 0.5179 - accuracy: 0.7980 - val_loss: 0.4548 - val_accuracy: 0.8224\n",
      "Epoch 741/1000\n",
      "225/225 [==============================] - 1s 2ms/step - loss: 0.5183 - accuracy: 0.7982 - val_loss: 0.4572 - val_accuracy: 0.8247\n",
      "Epoch 742/1000\n",
      "225/225 [==============================] - 1s 2ms/step - loss: 0.5188 - accuracy: 0.7970 - val_loss: 0.4556 - val_accuracy: 0.8244\n",
      "Epoch 743/1000\n",
      "225/225 [==============================] - 1s 2ms/step - loss: 0.5209 - accuracy: 0.7968 - val_loss: 0.4550 - val_accuracy: 0.8250\n",
      "Epoch 744/1000\n",
      "225/225 [==============================] - 1s 2ms/step - loss: 0.5203 - accuracy: 0.7963 - val_loss: 0.4572 - val_accuracy: 0.8253\n",
      "Epoch 745/1000\n",
      "225/225 [==============================] - 1s 2ms/step - loss: 0.5186 - accuracy: 0.7974 - val_loss: 0.4538 - val_accuracy: 0.8254\n",
      "Epoch 746/1000\n",
      "225/225 [==============================] - 1s 2ms/step - loss: 0.5209 - accuracy: 0.7951 - val_loss: 0.4582 - val_accuracy: 0.8231\n",
      "Epoch 747/1000\n",
      "225/225 [==============================] - 1s 2ms/step - loss: 0.5185 - accuracy: 0.7967 - val_loss: 0.4556 - val_accuracy: 0.8260\n",
      "Epoch 748/1000\n",
      "225/225 [==============================] - 1s 2ms/step - loss: 0.5194 - accuracy: 0.7965 - val_loss: 0.4558 - val_accuracy: 0.8240\n",
      "Epoch 749/1000\n",
      "225/225 [==============================] - 1s 2ms/step - loss: 0.5174 - accuracy: 0.7974 - val_loss: 0.4573 - val_accuracy: 0.8256\n",
      "Epoch 750/1000\n",
      "225/225 [==============================] - 1s 2ms/step - loss: 0.5178 - accuracy: 0.7977 - val_loss: 0.4557 - val_accuracy: 0.8235\n",
      "Epoch 751/1000\n",
      "225/225 [==============================] - 1s 2ms/step - loss: 0.5192 - accuracy: 0.7970 - val_loss: 0.4570 - val_accuracy: 0.8252\n",
      "Epoch 752/1000\n",
      "225/225 [==============================] - 1s 2ms/step - loss: 0.5212 - accuracy: 0.7952 - val_loss: 0.4568 - val_accuracy: 0.8264\n",
      "Epoch 753/1000\n",
      "225/225 [==============================] - 1s 2ms/step - loss: 0.5211 - accuracy: 0.7950 - val_loss: 0.4564 - val_accuracy: 0.8257\n",
      "Epoch 754/1000\n",
      "225/225 [==============================] - 1s 2ms/step - loss: 0.5229 - accuracy: 0.7967 - val_loss: 0.4565 - val_accuracy: 0.8242\n",
      "Epoch 755/1000\n",
      "225/225 [==============================] - 1s 2ms/step - loss: 0.5179 - accuracy: 0.7978 - val_loss: 0.4562 - val_accuracy: 0.8238\n",
      "Epoch 756/1000\n",
      "225/225 [==============================] - 1s 2ms/step - loss: 0.5192 - accuracy: 0.7959 - val_loss: 0.4591 - val_accuracy: 0.8255\n",
      "Epoch 757/1000\n",
      "225/225 [==============================] - 1s 2ms/step - loss: 0.5185 - accuracy: 0.7974 - val_loss: 0.4561 - val_accuracy: 0.8240\n",
      "Epoch 758/1000\n",
      "225/225 [==============================] - 1s 2ms/step - loss: 0.5186 - accuracy: 0.7972 - val_loss: 0.4543 - val_accuracy: 0.8237\n",
      "Epoch 759/1000\n",
      "225/225 [==============================] - 1s 2ms/step - loss: 0.5191 - accuracy: 0.7974 - val_loss: 0.4545 - val_accuracy: 0.8240\n",
      "Epoch 760/1000\n",
      "225/225 [==============================] - 1s 2ms/step - loss: 0.5190 - accuracy: 0.7978 - val_loss: 0.4582 - val_accuracy: 0.8242\n",
      "Epoch 761/1000\n",
      "225/225 [==============================] - 1s 2ms/step - loss: 0.5187 - accuracy: 0.7981 - val_loss: 0.4543 - val_accuracy: 0.8244\n",
      "Epoch 762/1000\n",
      "225/225 [==============================] - 1s 2ms/step - loss: 0.5166 - accuracy: 0.7993 - val_loss: 0.4554 - val_accuracy: 0.8263\n",
      "Epoch 763/1000\n",
      "225/225 [==============================] - 1s 2ms/step - loss: 0.5205 - accuracy: 0.7965 - val_loss: 0.4574 - val_accuracy: 0.8242\n",
      "Epoch 764/1000\n",
      "225/225 [==============================] - 1s 2ms/step - loss: 0.5205 - accuracy: 0.7964 - val_loss: 0.4575 - val_accuracy: 0.8241\n",
      "Epoch 765/1000\n",
      "225/225 [==============================] - 1s 2ms/step - loss: 0.5213 - accuracy: 0.7960 - val_loss: 0.4557 - val_accuracy: 0.8251\n",
      "Epoch 766/1000\n",
      "225/225 [==============================] - 1s 2ms/step - loss: 0.5188 - accuracy: 0.7970 - val_loss: 0.4575 - val_accuracy: 0.8246\n",
      "Epoch 767/1000\n",
      "225/225 [==============================] - 1s 3ms/step - loss: 0.5211 - accuracy: 0.7971 - val_loss: 0.4575 - val_accuracy: 0.8220\n",
      "Epoch 768/1000\n",
      "225/225 [==============================] - 1s 2ms/step - loss: 0.5191 - accuracy: 0.7976 - val_loss: 0.4565 - val_accuracy: 0.8232\n",
      "Epoch 769/1000\n",
      "225/225 [==============================] - 1s 2ms/step - loss: 0.5179 - accuracy: 0.7973 - val_loss: 0.4586 - val_accuracy: 0.8228\n",
      "Epoch 770/1000\n",
      "225/225 [==============================] - 1s 2ms/step - loss: 0.5197 - accuracy: 0.7980 - val_loss: 0.4547 - val_accuracy: 0.8235\n",
      "Epoch 771/1000\n",
      "225/225 [==============================] - 1s 2ms/step - loss: 0.5194 - accuracy: 0.7977 - val_loss: 0.4587 - val_accuracy: 0.8248\n",
      "Epoch 772/1000\n",
      "225/225 [==============================] - 1s 2ms/step - loss: 0.5190 - accuracy: 0.7962 - val_loss: 0.4563 - val_accuracy: 0.8224\n",
      "Epoch 773/1000\n",
      "225/225 [==============================] - 1s 2ms/step - loss: 0.5174 - accuracy: 0.7984 - val_loss: 0.4582 - val_accuracy: 0.8225\n",
      "Epoch 774/1000\n",
      "225/225 [==============================] - 1s 2ms/step - loss: 0.5229 - accuracy: 0.7962 - val_loss: 0.4566 - val_accuracy: 0.8233\n",
      "Epoch 775/1000\n",
      "225/225 [==============================] - 1s 2ms/step - loss: 0.5186 - accuracy: 0.7981 - val_loss: 0.4549 - val_accuracy: 0.8259\n",
      "Epoch 776/1000\n",
      "225/225 [==============================] - 1s 2ms/step - loss: 0.5180 - accuracy: 0.7980 - val_loss: 0.4541 - val_accuracy: 0.8253\n",
      "Epoch 777/1000\n",
      "225/225 [==============================] - 1s 2ms/step - loss: 0.5200 - accuracy: 0.7978 - val_loss: 0.4557 - val_accuracy: 0.8228\n",
      "Epoch 778/1000\n",
      "225/225 [==============================] - 1s 2ms/step - loss: 0.5190 - accuracy: 0.7979 - val_loss: 0.4560 - val_accuracy: 0.8250\n",
      "Epoch 779/1000\n",
      "225/225 [==============================] - 1s 2ms/step - loss: 0.5184 - accuracy: 0.7983 - val_loss: 0.4569 - val_accuracy: 0.8253\n",
      "Epoch 780/1000\n",
      "225/225 [==============================] - 1s 3ms/step - loss: 0.5181 - accuracy: 0.7980 - val_loss: 0.4575 - val_accuracy: 0.8251\n",
      "Epoch 781/1000\n",
      "225/225 [==============================] - 1s 2ms/step - loss: 0.5180 - accuracy: 0.7981 - val_loss: 0.4578 - val_accuracy: 0.8234\n",
      "Epoch 782/1000\n",
      "225/225 [==============================] - 1s 2ms/step - loss: 0.5187 - accuracy: 0.7977 - val_loss: 0.4551 - val_accuracy: 0.8238\n",
      "Epoch 783/1000\n",
      "225/225 [==============================] - 1s 2ms/step - loss: 0.5148 - accuracy: 0.7985 - val_loss: 0.4543 - val_accuracy: 0.8235\n",
      "Epoch 784/1000\n",
      "225/225 [==============================] - 1s 2ms/step - loss: 0.5189 - accuracy: 0.7981 - val_loss: 0.4567 - val_accuracy: 0.8242\n",
      "Epoch 785/1000\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "225/225 [==============================] - 1s 2ms/step - loss: 0.5187 - accuracy: 0.7967 - val_loss: 0.4555 - val_accuracy: 0.8253\n",
      "Epoch 786/1000\n",
      "225/225 [==============================] - 1s 2ms/step - loss: 0.5172 - accuracy: 0.7978 - val_loss: 0.4528 - val_accuracy: 0.8243\n",
      "Epoch 787/1000\n",
      "225/225 [==============================] - 1s 2ms/step - loss: 0.5178 - accuracy: 0.7979 - val_loss: 0.4564 - val_accuracy: 0.8235\n",
      "Epoch 788/1000\n",
      "225/225 [==============================] - 1s 2ms/step - loss: 0.5197 - accuracy: 0.7977 - val_loss: 0.4562 - val_accuracy: 0.8242\n",
      "Epoch 789/1000\n",
      "225/225 [==============================] - 1s 2ms/step - loss: 0.5173 - accuracy: 0.7984 - val_loss: 0.4526 - val_accuracy: 0.8270\n",
      "Epoch 790/1000\n",
      "225/225 [==============================] - 1s 2ms/step - loss: 0.5184 - accuracy: 0.7982 - val_loss: 0.4572 - val_accuracy: 0.8245\n",
      "Epoch 791/1000\n",
      "225/225 [==============================] - 1s 2ms/step - loss: 0.5188 - accuracy: 0.7977 - val_loss: 0.4582 - val_accuracy: 0.8231\n",
      "Epoch 792/1000\n",
      "225/225 [==============================] - 1s 2ms/step - loss: 0.5176 - accuracy: 0.7981 - val_loss: 0.4569 - val_accuracy: 0.8260\n",
      "Epoch 793/1000\n",
      "225/225 [==============================] - 1s 2ms/step - loss: 0.5165 - accuracy: 0.7981 - val_loss: 0.4539 - val_accuracy: 0.8275\n",
      "Epoch 794/1000\n",
      "225/225 [==============================] - 1s 2ms/step - loss: 0.5168 - accuracy: 0.7986 - val_loss: 0.4508 - val_accuracy: 0.8275\n",
      "Epoch 795/1000\n",
      "225/225 [==============================] - 1s 2ms/step - loss: 0.5161 - accuracy: 0.7984 - val_loss: 0.4527 - val_accuracy: 0.8264\n",
      "Epoch 796/1000\n",
      "225/225 [==============================] - 1s 3ms/step - loss: 0.5184 - accuracy: 0.7974 - val_loss: 0.4553 - val_accuracy: 0.8229\n",
      "Epoch 797/1000\n",
      "225/225 [==============================] - 1s 2ms/step - loss: 0.5180 - accuracy: 0.7971 - val_loss: 0.4553 - val_accuracy: 0.8224\n",
      "Epoch 798/1000\n",
      "225/225 [==============================] - 1s 2ms/step - loss: 0.5149 - accuracy: 0.7992 - val_loss: 0.4550 - val_accuracy: 0.8264\n",
      "Epoch 799/1000\n",
      "225/225 [==============================] - 1s 2ms/step - loss: 0.5184 - accuracy: 0.7974 - val_loss: 0.4579 - val_accuracy: 0.8251\n",
      "Epoch 800/1000\n",
      "225/225 [==============================] - 1s 2ms/step - loss: 0.5184 - accuracy: 0.7976 - val_loss: 0.4569 - val_accuracy: 0.8236\n",
      "Epoch 801/1000\n",
      "225/225 [==============================] - 1s 2ms/step - loss: 0.5179 - accuracy: 0.7984 - val_loss: 0.4581 - val_accuracy: 0.8223\n",
      "Epoch 802/1000\n",
      "225/225 [==============================] - 1s 2ms/step - loss: 0.5207 - accuracy: 0.7973 - val_loss: 0.4579 - val_accuracy: 0.8265\n",
      "Epoch 803/1000\n",
      "225/225 [==============================] - 1s 2ms/step - loss: 0.5172 - accuracy: 0.7976 - val_loss: 0.4552 - val_accuracy: 0.8235\n",
      "Epoch 804/1000\n",
      "225/225 [==============================] - 1s 2ms/step - loss: 0.5188 - accuracy: 0.7974 - val_loss: 0.4561 - val_accuracy: 0.8224\n",
      "Epoch 805/1000\n",
      "225/225 [==============================] - 1s 2ms/step - loss: 0.5182 - accuracy: 0.7976 - val_loss: 0.4539 - val_accuracy: 0.8256\n",
      "Epoch 806/1000\n",
      "225/225 [==============================] - 1s 2ms/step - loss: 0.5171 - accuracy: 0.7978 - val_loss: 0.4574 - val_accuracy: 0.8249\n",
      "Epoch 807/1000\n",
      "225/225 [==============================] - 1s 2ms/step - loss: 0.5183 - accuracy: 0.7982 - val_loss: 0.4545 - val_accuracy: 0.8261\n",
      "Epoch 808/1000\n",
      "225/225 [==============================] - 1s 2ms/step - loss: 0.5178 - accuracy: 0.7983 - val_loss: 0.4571 - val_accuracy: 0.8242\n",
      "Epoch 809/1000\n",
      "225/225 [==============================] - 1s 2ms/step - loss: 0.5172 - accuracy: 0.7979 - val_loss: 0.4552 - val_accuracy: 0.8268\n",
      "Epoch 810/1000\n",
      "225/225 [==============================] - 1s 2ms/step - loss: 0.5190 - accuracy: 0.7980 - val_loss: 0.4559 - val_accuracy: 0.8245\n",
      "Epoch 811/1000\n",
      "225/225 [==============================] - 1s 3ms/step - loss: 0.5163 - accuracy: 0.7984 - val_loss: 0.4544 - val_accuracy: 0.8259\n",
      "Epoch 812/1000\n",
      "225/225 [==============================] - 1s 2ms/step - loss: 0.5184 - accuracy: 0.7975 - val_loss: 0.4558 - val_accuracy: 0.8271\n",
      "Epoch 813/1000\n",
      "225/225 [==============================] - 1s 2ms/step - loss: 0.5178 - accuracy: 0.7981 - val_loss: 0.4549 - val_accuracy: 0.8255\n",
      "Epoch 814/1000\n",
      "225/225 [==============================] - 1s 2ms/step - loss: 0.5196 - accuracy: 0.7972 - val_loss: 0.4567 - val_accuracy: 0.8255\n",
      "Epoch 815/1000\n",
      "225/225 [==============================] - 1s 2ms/step - loss: 0.5173 - accuracy: 0.7981 - val_loss: 0.4560 - val_accuracy: 0.8257\n",
      "Epoch 816/1000\n",
      "225/225 [==============================] - 1s 2ms/step - loss: 0.5160 - accuracy: 0.7987 - val_loss: 0.4525 - val_accuracy: 0.8249\n",
      "Epoch 817/1000\n",
      "225/225 [==============================] - 1s 2ms/step - loss: 0.5167 - accuracy: 0.7988 - val_loss: 0.4543 - val_accuracy: 0.8273\n",
      "Epoch 818/1000\n",
      "225/225 [==============================] - 1s 2ms/step - loss: 0.5194 - accuracy: 0.7986 - val_loss: 0.4562 - val_accuracy: 0.8257\n",
      "Epoch 819/1000\n",
      "225/225 [==============================] - 1s 2ms/step - loss: 0.5177 - accuracy: 0.7974 - val_loss: 0.4534 - val_accuracy: 0.8234\n",
      "Epoch 820/1000\n",
      "225/225 [==============================] - 1s 2ms/step - loss: 0.5178 - accuracy: 0.7977 - val_loss: 0.4537 - val_accuracy: 0.8253\n",
      "Epoch 821/1000\n",
      "225/225 [==============================] - 1s 2ms/step - loss: 0.5159 - accuracy: 0.7980 - val_loss: 0.4535 - val_accuracy: 0.8240\n",
      "Epoch 822/1000\n",
      "225/225 [==============================] - 1s 2ms/step - loss: 0.5198 - accuracy: 0.7976 - val_loss: 0.4564 - val_accuracy: 0.8253\n",
      "Epoch 823/1000\n",
      "225/225 [==============================] - 1s 2ms/step - loss: 0.5179 - accuracy: 0.7979 - val_loss: 0.4557 - val_accuracy: 0.8273\n",
      "Epoch 824/1000\n",
      "225/225 [==============================] - 1s 2ms/step - loss: 0.5162 - accuracy: 0.7989 - val_loss: 0.4575 - val_accuracy: 0.8246\n",
      "Epoch 825/1000\n",
      "225/225 [==============================] - 1s 2ms/step - loss: 0.5182 - accuracy: 0.7968 - val_loss: 0.4557 - val_accuracy: 0.8249\n",
      "Epoch 826/1000\n",
      "225/225 [==============================] - 1s 2ms/step - loss: 0.5166 - accuracy: 0.7979 - val_loss: 0.4556 - val_accuracy: 0.8259\n",
      "Epoch 827/1000\n",
      "225/225 [==============================] - 1s 2ms/step - loss: 0.5163 - accuracy: 0.7983 - val_loss: 0.4543 - val_accuracy: 0.8276\n",
      "Epoch 828/1000\n",
      "225/225 [==============================] - 1s 2ms/step - loss: 0.5166 - accuracy: 0.7969 - val_loss: 0.4577 - val_accuracy: 0.8275\n",
      "Epoch 829/1000\n",
      "225/225 [==============================] - 1s 3ms/step - loss: 0.5175 - accuracy: 0.7976 - val_loss: 0.4548 - val_accuracy: 0.8254\n",
      "Epoch 830/1000\n",
      "225/225 [==============================] - 1s 2ms/step - loss: 0.5175 - accuracy: 0.7974 - val_loss: 0.4544 - val_accuracy: 0.8256\n",
      "Epoch 831/1000\n",
      "225/225 [==============================] - 1s 2ms/step - loss: 0.5198 - accuracy: 0.7970 - val_loss: 0.4551 - val_accuracy: 0.8257\n",
      "Epoch 832/1000\n",
      "225/225 [==============================] - 1s 2ms/step - loss: 0.5171 - accuracy: 0.7974 - val_loss: 0.4547 - val_accuracy: 0.8272\n",
      "Epoch 833/1000\n",
      "225/225 [==============================] - 1s 2ms/step - loss: 0.5183 - accuracy: 0.7975 - val_loss: 0.4565 - val_accuracy: 0.8246\n",
      "Epoch 834/1000\n",
      "225/225 [==============================] - 1s 2ms/step - loss: 0.5192 - accuracy: 0.7982 - val_loss: 0.4539 - val_accuracy: 0.8278\n",
      "Epoch 835/1000\n",
      "225/225 [==============================] - 1s 2ms/step - loss: 0.5171 - accuracy: 0.7981 - val_loss: 0.4524 - val_accuracy: 0.8282\n",
      "Epoch 836/1000\n",
      "225/225 [==============================] - 1s 2ms/step - loss: 0.5179 - accuracy: 0.7967 - val_loss: 0.4554 - val_accuracy: 0.8256\n",
      "Epoch 837/1000\n",
      "225/225 [==============================] - 1s 2ms/step - loss: 0.5163 - accuracy: 0.7975 - val_loss: 0.4553 - val_accuracy: 0.8249\n",
      "Epoch 838/1000\n",
      "225/225 [==============================] - 1s 2ms/step - loss: 0.5180 - accuracy: 0.7966 - val_loss: 0.4507 - val_accuracy: 0.8254\n",
      "Epoch 839/1000\n",
      "225/225 [==============================] - 1s 2ms/step - loss: 0.5172 - accuracy: 0.7991 - val_loss: 0.4517 - val_accuracy: 0.8267\n",
      "Epoch 840/1000\n",
      "225/225 [==============================] - 1s 2ms/step - loss: 0.5171 - accuracy: 0.7981 - val_loss: 0.4554 - val_accuracy: 0.8255\n",
      "Epoch 841/1000\n",
      "225/225 [==============================] - 1s 2ms/step - loss: 0.5203 - accuracy: 0.7978 - val_loss: 0.4550 - val_accuracy: 0.8252\n",
      "Epoch 842/1000\n",
      "225/225 [==============================] - 1s 2ms/step - loss: 0.5186 - accuracy: 0.7972 - val_loss: 0.4534 - val_accuracy: 0.8263\n",
      "Epoch 843/1000\n",
      "225/225 [==============================] - 1s 2ms/step - loss: 0.5175 - accuracy: 0.7972 - val_loss: 0.4520 - val_accuracy: 0.8260\n",
      "Epoch 844/1000\n",
      "225/225 [==============================] - 1s 2ms/step - loss: 0.5167 - accuracy: 0.7982 - val_loss: 0.4536 - val_accuracy: 0.8239\n",
      "Epoch 845/1000\n",
      "225/225 [==============================] - 1s 2ms/step - loss: 0.5172 - accuracy: 0.7986 - val_loss: 0.4546 - val_accuracy: 0.8246\n",
      "Epoch 846/1000\n",
      "225/225 [==============================] - 1s 2ms/step - loss: 0.5166 - accuracy: 0.7990 - val_loss: 0.4513 - val_accuracy: 0.8258\n",
      "Epoch 847/1000\n",
      "225/225 [==============================] - 1s 2ms/step - loss: 0.5167 - accuracy: 0.7986 - val_loss: 0.4525 - val_accuracy: 0.8269\n",
      "Epoch 848/1000\n",
      "225/225 [==============================] - 1s 2ms/step - loss: 0.5184 - accuracy: 0.7978 - val_loss: 0.4499 - val_accuracy: 0.8261\n",
      "Epoch 849/1000\n",
      "225/225 [==============================] - 1s 2ms/step - loss: 0.5178 - accuracy: 0.7971 - val_loss: 0.4531 - val_accuracy: 0.8261\n",
      "Epoch 850/1000\n",
      "225/225 [==============================] - 1s 2ms/step - loss: 0.5189 - accuracy: 0.7979 - val_loss: 0.4538 - val_accuracy: 0.8249\n",
      "Epoch 851/1000\n",
      "225/225 [==============================] - 1s 2ms/step - loss: 0.5184 - accuracy: 0.7979 - val_loss: 0.4563 - val_accuracy: 0.8220\n",
      "Epoch 852/1000\n",
      "225/225 [==============================] - 1s 2ms/step - loss: 0.5175 - accuracy: 0.7981 - val_loss: 0.4554 - val_accuracy: 0.8263\n",
      "Epoch 853/1000\n",
      "225/225 [==============================] - 1s 2ms/step - loss: 0.5171 - accuracy: 0.7982 - val_loss: 0.4545 - val_accuracy: 0.8238\n",
      "Epoch 854/1000\n",
      "225/225 [==============================] - 1s 2ms/step - loss: 0.5161 - accuracy: 0.8003 - val_loss: 0.4530 - val_accuracy: 0.8238\n",
      "Epoch 855/1000\n",
      "225/225 [==============================] - 1s 2ms/step - loss: 0.5175 - accuracy: 0.7977 - val_loss: 0.4535 - val_accuracy: 0.8273\n",
      "Epoch 856/1000\n",
      "225/225 [==============================] - 1s 2ms/step - loss: 0.5171 - accuracy: 0.7985 - val_loss: 0.4534 - val_accuracy: 0.8278\n",
      "Epoch 857/1000\n",
      "225/225 [==============================] - 1s 2ms/step - loss: 0.5165 - accuracy: 0.7990 - val_loss: 0.4533 - val_accuracy: 0.8246\n",
      "Epoch 858/1000\n",
      "225/225 [==============================] - 1s 2ms/step - loss: 0.5176 - accuracy: 0.7982 - val_loss: 0.4526 - val_accuracy: 0.8260\n",
      "Epoch 859/1000\n",
      "225/225 [==============================] - 1s 2ms/step - loss: 0.5165 - accuracy: 0.7980 - val_loss: 0.4541 - val_accuracy: 0.8269\n",
      "Epoch 860/1000\n",
      "225/225 [==============================] - 1s 2ms/step - loss: 0.5192 - accuracy: 0.7966 - val_loss: 0.4553 - val_accuracy: 0.8250\n",
      "Epoch 861/1000\n",
      "225/225 [==============================] - 1s 2ms/step - loss: 0.5174 - accuracy: 0.7987 - val_loss: 0.4552 - val_accuracy: 0.8264\n",
      "Epoch 862/1000\n",
      "225/225 [==============================] - 1s 2ms/step - loss: 0.5176 - accuracy: 0.7977 - val_loss: 0.4555 - val_accuracy: 0.8265\n",
      "Epoch 863/1000\n",
      "225/225 [==============================] - 1s 2ms/step - loss: 0.5183 - accuracy: 0.7962 - val_loss: 0.4555 - val_accuracy: 0.8261\n",
      "Epoch 864/1000\n",
      "225/225 [==============================] - 1s 2ms/step - loss: 0.5196 - accuracy: 0.7967 - val_loss: 0.4575 - val_accuracy: 0.8244\n",
      "Epoch 865/1000\n",
      "225/225 [==============================] - 1s 2ms/step - loss: 0.5184 - accuracy: 0.7982 - val_loss: 0.4557 - val_accuracy: 0.8260\n",
      "Epoch 866/1000\n",
      "225/225 [==============================] - 1s 2ms/step - loss: 0.5164 - accuracy: 0.7982 - val_loss: 0.4569 - val_accuracy: 0.8271\n",
      "Epoch 867/1000\n",
      "225/225 [==============================] - 1s 2ms/step - loss: 0.5170 - accuracy: 0.7981 - val_loss: 0.4516 - val_accuracy: 0.8287\n",
      "Epoch 868/1000\n",
      "225/225 [==============================] - 1s 2ms/step - loss: 0.5193 - accuracy: 0.7975 - val_loss: 0.4555 - val_accuracy: 0.8254\n",
      "Epoch 869/1000\n",
      "225/225 [==============================] - 1s 2ms/step - loss: 0.5203 - accuracy: 0.7976 - val_loss: 0.4560 - val_accuracy: 0.8238\n",
      "Epoch 870/1000\n",
      "225/225 [==============================] - 1s 2ms/step - loss: 0.5191 - accuracy: 0.7968 - val_loss: 0.4548 - val_accuracy: 0.8257\n",
      "Epoch 871/1000\n",
      "225/225 [==============================] - 1s 2ms/step - loss: 0.5181 - accuracy: 0.7975 - val_loss: 0.4541 - val_accuracy: 0.8251\n",
      "Epoch 872/1000\n",
      "225/225 [==============================] - 1s 2ms/step - loss: 0.5167 - accuracy: 0.7995 - val_loss: 0.4535 - val_accuracy: 0.8259\n",
      "Epoch 873/1000\n",
      "225/225 [==============================] - 1s 2ms/step - loss: 0.5187 - accuracy: 0.7992 - val_loss: 0.4550 - val_accuracy: 0.8269\n",
      "Epoch 874/1000\n",
      "225/225 [==============================] - 1s 2ms/step - loss: 0.5201 - accuracy: 0.7974 - val_loss: 0.4564 - val_accuracy: 0.8240\n",
      "Epoch 875/1000\n",
      "225/225 [==============================] - 1s 2ms/step - loss: 0.5159 - accuracy: 0.7982 - val_loss: 0.4564 - val_accuracy: 0.8254\n",
      "Epoch 876/1000\n",
      "225/225 [==============================] - 1s 2ms/step - loss: 0.5182 - accuracy: 0.7980 - val_loss: 0.4545 - val_accuracy: 0.8257\n",
      "Epoch 877/1000\n",
      "225/225 [==============================] - 1s 2ms/step - loss: 0.5180 - accuracy: 0.7978 - val_loss: 0.4521 - val_accuracy: 0.8254\n",
      "Epoch 878/1000\n",
      "225/225 [==============================] - 1s 2ms/step - loss: 0.5161 - accuracy: 0.7989 - val_loss: 0.4508 - val_accuracy: 0.8257\n",
      "Epoch 879/1000\n",
      "225/225 [==============================] - 1s 2ms/step - loss: 0.5176 - accuracy: 0.7967 - val_loss: 0.4530 - val_accuracy: 0.8265\n",
      "Epoch 880/1000\n",
      "225/225 [==============================] - 1s 2ms/step - loss: 0.5166 - accuracy: 0.7991 - val_loss: 0.4518 - val_accuracy: 0.8257\n",
      "Epoch 881/1000\n",
      "225/225 [==============================] - 1s 2ms/step - loss: 0.5192 - accuracy: 0.7970 - val_loss: 0.4527 - val_accuracy: 0.8263\n",
      "Epoch 882/1000\n",
      "225/225 [==============================] - 1s 2ms/step - loss: 0.5161 - accuracy: 0.7994 - val_loss: 0.4541 - val_accuracy: 0.8256\n",
      "Epoch 883/1000\n",
      "225/225 [==============================] - 1s 2ms/step - loss: 0.5172 - accuracy: 0.7984 - val_loss: 0.4521 - val_accuracy: 0.8259\n",
      "Epoch 884/1000\n",
      "225/225 [==============================] - 1s 2ms/step - loss: 0.5180 - accuracy: 0.7973 - val_loss: 0.4524 - val_accuracy: 0.8286\n",
      "Epoch 885/1000\n",
      "225/225 [==============================] - 1s 2ms/step - loss: 0.5164 - accuracy: 0.7988 - val_loss: 0.4509 - val_accuracy: 0.8293\n",
      "Epoch 886/1000\n",
      "225/225 [==============================] - 1s 2ms/step - loss: 0.5127 - accuracy: 0.7995 - val_loss: 0.4536 - val_accuracy: 0.8255\n",
      "Epoch 887/1000\n",
      "225/225 [==============================] - 1s 2ms/step - loss: 0.5166 - accuracy: 0.7984 - val_loss: 0.4537 - val_accuracy: 0.8267\n",
      "Epoch 888/1000\n",
      "225/225 [==============================] - 1s 2ms/step - loss: 0.5183 - accuracy: 0.7982 - val_loss: 0.4562 - val_accuracy: 0.8270\n",
      "Epoch 889/1000\n",
      "225/225 [==============================] - 1s 2ms/step - loss: 0.5162 - accuracy: 0.7991 - val_loss: 0.4528 - val_accuracy: 0.8273\n",
      "Epoch 890/1000\n",
      "225/225 [==============================] - 1s 2ms/step - loss: 0.5154 - accuracy: 0.7990 - val_loss: 0.4508 - val_accuracy: 0.8291\n",
      "Epoch 891/1000\n",
      "225/225 [==============================] - 1s 2ms/step - loss: 0.5192 - accuracy: 0.7961 - val_loss: 0.4550 - val_accuracy: 0.8276\n",
      "Epoch 892/1000\n",
      "225/225 [==============================] - 1s 2ms/step - loss: 0.5181 - accuracy: 0.7982 - val_loss: 0.4541 - val_accuracy: 0.8245\n",
      "Epoch 893/1000\n",
      "225/225 [==============================] - 1s 2ms/step - loss: 0.5174 - accuracy: 0.7980 - val_loss: 0.4542 - val_accuracy: 0.8276\n",
      "Epoch 894/1000\n",
      "225/225 [==============================] - 1s 2ms/step - loss: 0.5156 - accuracy: 0.7982 - val_loss: 0.4545 - val_accuracy: 0.8250\n",
      "Epoch 895/1000\n",
      "225/225 [==============================] - 1s 2ms/step - loss: 0.5175 - accuracy: 0.7981 - val_loss: 0.4542 - val_accuracy: 0.8249\n",
      "Epoch 896/1000\n",
      "225/225 [==============================] - 1s 2ms/step - loss: 0.5165 - accuracy: 0.7983 - val_loss: 0.4571 - val_accuracy: 0.8247\n",
      "Epoch 897/1000\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "225/225 [==============================] - 1s 2ms/step - loss: 0.5166 - accuracy: 0.7977 - val_loss: 0.4550 - val_accuracy: 0.8264\n",
      "Epoch 898/1000\n",
      "225/225 [==============================] - 1s 3ms/step - loss: 0.5161 - accuracy: 0.7991 - val_loss: 0.4543 - val_accuracy: 0.8257\n",
      "Epoch 899/1000\n",
      "225/225 [==============================] - 1s 2ms/step - loss: 0.5164 - accuracy: 0.7995 - val_loss: 0.4547 - val_accuracy: 0.8260\n",
      "Epoch 900/1000\n",
      "225/225 [==============================] - 1s 2ms/step - loss: 0.5178 - accuracy: 0.7981 - val_loss: 0.4545 - val_accuracy: 0.8264\n",
      "Epoch 901/1000\n",
      "225/225 [==============================] - 1s 2ms/step - loss: 0.5160 - accuracy: 0.7986 - val_loss: 0.4567 - val_accuracy: 0.8271\n",
      "Epoch 902/1000\n",
      "225/225 [==============================] - 1s 2ms/step - loss: 0.5169 - accuracy: 0.7976 - val_loss: 0.4527 - val_accuracy: 0.8254\n",
      "Epoch 903/1000\n",
      "225/225 [==============================] - 1s 2ms/step - loss: 0.5173 - accuracy: 0.7985 - val_loss: 0.4513 - val_accuracy: 0.8279\n",
      "Epoch 904/1000\n",
      "225/225 [==============================] - 1s 2ms/step - loss: 0.5188 - accuracy: 0.7976 - val_loss: 0.4548 - val_accuracy: 0.8259\n",
      "Epoch 905/1000\n",
      "225/225 [==============================] - 1s 2ms/step - loss: 0.5182 - accuracy: 0.7974 - val_loss: 0.4526 - val_accuracy: 0.8273\n",
      "Epoch 906/1000\n",
      "225/225 [==============================] - 1s 2ms/step - loss: 0.5182 - accuracy: 0.7977 - val_loss: 0.4575 - val_accuracy: 0.8277\n",
      "Epoch 907/1000\n",
      "225/225 [==============================] - 1s 2ms/step - loss: 0.5153 - accuracy: 0.7986 - val_loss: 0.4562 - val_accuracy: 0.8264\n",
      "Epoch 908/1000\n",
      "225/225 [==============================] - 1s 2ms/step - loss: 0.5178 - accuracy: 0.7976 - val_loss: 0.4538 - val_accuracy: 0.8270\n",
      "Epoch 909/1000\n",
      "225/225 [==============================] - 1s 2ms/step - loss: 0.5151 - accuracy: 0.7980 - val_loss: 0.4545 - val_accuracy: 0.8256\n",
      "Epoch 910/1000\n",
      "225/225 [==============================] - 1s 2ms/step - loss: 0.5162 - accuracy: 0.7987 - val_loss: 0.4537 - val_accuracy: 0.8273\n",
      "Epoch 911/1000\n",
      "225/225 [==============================] - 1s 2ms/step - loss: 0.5159 - accuracy: 0.7989 - val_loss: 0.4535 - val_accuracy: 0.8276\n",
      "Epoch 912/1000\n",
      "225/225 [==============================] - 1s 3ms/step - loss: 0.5139 - accuracy: 0.8002 - val_loss: 0.4534 - val_accuracy: 0.8275\n",
      "Epoch 913/1000\n",
      "225/225 [==============================] - 1s 2ms/step - loss: 0.5158 - accuracy: 0.7979 - val_loss: 0.4550 - val_accuracy: 0.8276\n",
      "Epoch 914/1000\n",
      "225/225 [==============================] - 1s 2ms/step - loss: 0.5171 - accuracy: 0.7980 - val_loss: 0.4535 - val_accuracy: 0.8259\n",
      "Epoch 915/1000\n",
      "225/225 [==============================] - 1s 2ms/step - loss: 0.5182 - accuracy: 0.7988 - val_loss: 0.4531 - val_accuracy: 0.8279\n",
      "Epoch 916/1000\n",
      "225/225 [==============================] - 1s 2ms/step - loss: 0.5145 - accuracy: 0.7998 - val_loss: 0.4532 - val_accuracy: 0.8255\n",
      "Epoch 917/1000\n",
      "225/225 [==============================] - 1s 2ms/step - loss: 0.5155 - accuracy: 0.7992 - val_loss: 0.4554 - val_accuracy: 0.8268\n",
      "Epoch 918/1000\n",
      "225/225 [==============================] - 1s 2ms/step - loss: 0.5159 - accuracy: 0.7982 - val_loss: 0.4520 - val_accuracy: 0.8261\n",
      "Epoch 919/1000\n",
      "225/225 [==============================] - 1s 2ms/step - loss: 0.5144 - accuracy: 0.7990 - val_loss: 0.4518 - val_accuracy: 0.8271\n",
      "Epoch 920/1000\n",
      "225/225 [==============================] - 1s 2ms/step - loss: 0.5152 - accuracy: 0.7981 - val_loss: 0.4525 - val_accuracy: 0.8259\n",
      "Epoch 921/1000\n",
      "225/225 [==============================] - 1s 3ms/step - loss: 0.5145 - accuracy: 0.7987 - val_loss: 0.4524 - val_accuracy: 0.8246\n",
      "Epoch 922/1000\n",
      "225/225 [==============================] - 1s 2ms/step - loss: 0.5159 - accuracy: 0.7982 - val_loss: 0.4548 - val_accuracy: 0.8258\n",
      "Epoch 923/1000\n",
      "225/225 [==============================] - 1s 2ms/step - loss: 0.5148 - accuracy: 0.7991 - val_loss: 0.4548 - val_accuracy: 0.8250\n",
      "Epoch 924/1000\n",
      "225/225 [==============================] - 1s 2ms/step - loss: 0.5176 - accuracy: 0.7980 - val_loss: 0.4559 - val_accuracy: 0.8244\n",
      "Epoch 925/1000\n",
      "225/225 [==============================] - 1s 2ms/step - loss: 0.5166 - accuracy: 0.7982 - val_loss: 0.4554 - val_accuracy: 0.8250\n",
      "Epoch 926/1000\n",
      "225/225 [==============================] - 1s 2ms/step - loss: 0.5174 - accuracy: 0.7994 - val_loss: 0.4527 - val_accuracy: 0.8273\n",
      "Epoch 927/1000\n",
      "225/225 [==============================] - 1s 2ms/step - loss: 0.5189 - accuracy: 0.7981 - val_loss: 0.4517 - val_accuracy: 0.8285\n",
      "Epoch 928/1000\n",
      "225/225 [==============================] - 1s 2ms/step - loss: 0.5151 - accuracy: 0.7988 - val_loss: 0.4542 - val_accuracy: 0.8283\n",
      "Epoch 929/1000\n",
      "225/225 [==============================] - 1s 2ms/step - loss: 0.5161 - accuracy: 0.7991 - val_loss: 0.4544 - val_accuracy: 0.8266\n",
      "Epoch 930/1000\n",
      "225/225 [==============================] - 1s 2ms/step - loss: 0.5175 - accuracy: 0.7983 - val_loss: 0.4549 - val_accuracy: 0.8276\n",
      "Epoch 931/1000\n",
      "225/225 [==============================] - 1s 2ms/step - loss: 0.5152 - accuracy: 0.7988 - val_loss: 0.4522 - val_accuracy: 0.8286\n",
      "Epoch 932/1000\n",
      "225/225 [==============================] - 1s 2ms/step - loss: 0.5168 - accuracy: 0.7972 - val_loss: 0.4529 - val_accuracy: 0.8259\n",
      "Epoch 933/1000\n",
      "225/225 [==============================] - 1s 2ms/step - loss: 0.5129 - accuracy: 0.8001 - val_loss: 0.4522 - val_accuracy: 0.8271\n",
      "Epoch 934/1000\n",
      "225/225 [==============================] - 1s 2ms/step - loss: 0.5181 - accuracy: 0.7965 - val_loss: 0.4543 - val_accuracy: 0.8285\n",
      "Epoch 935/1000\n",
      "225/225 [==============================] - 1s 2ms/step - loss: 0.5156 - accuracy: 0.7994 - val_loss: 0.4521 - val_accuracy: 0.8289\n",
      "Epoch 936/1000\n",
      "225/225 [==============================] - 1s 2ms/step - loss: 0.5147 - accuracy: 0.7998 - val_loss: 0.4533 - val_accuracy: 0.8265\n",
      "Epoch 937/1000\n",
      "225/225 [==============================] - 1s 2ms/step - loss: 0.5172 - accuracy: 0.7983 - val_loss: 0.4518 - val_accuracy: 0.8271\n",
      "Epoch 938/1000\n",
      "225/225 [==============================] - 1s 2ms/step - loss: 0.5175 - accuracy: 0.7983 - val_loss: 0.4528 - val_accuracy: 0.8286\n",
      "Epoch 938: early stopping\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "<keras.src.callbacks.History at 0x14785dde0>"
      ]
     },
     "execution_count": 189,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# batch size=512\n",
    "model=Sequential()\n",
    "model.add(Dense(128, input_dim=X_train.shape[1], activation=\"relu\"))\n",
    "model.add(Dropout(0.2))\n",
    "model.add(Dense(128, activation=\"relu\"))\n",
    "model.add(Dropout(0.2))\n",
    "model.add(Dense(64, activation=\"relu\"))\n",
    "model.add(Dropout(0.2))\n",
    "model.add(Dense(64, activation=\"relu\"))\n",
    "model.add(Dropout(0.2))\n",
    "model.add(Dense(32, activation=\"relu\"))\n",
    "model.add(Dropout(0.2))\n",
    "model.add(Dense(16, activation=\"relu\"))\n",
    "model.add(Dropout(0.2))\n",
    "model.add(Dense(3, activation=\"softmax\"))\n",
    "\n",
    "model.compile(loss='categorical_crossentropy', optimizer=Adam(learning_rate=0.001), metrics=['accuracy'])\n",
    "\n",
    "es=EarlyStopping(monitor=\"val_loss\",patience=90,mode=\"auto\",verbose=1)\n",
    "\n",
    "model.fit(X_train,\n",
    "          y_train,\n",
    "          epochs=1000,\n",
    "               batch_size=512,\n",
    "               validation_split=0.1,\n",
    "               verbose=1,callbacks=[es])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 190,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "997/997 [==============================] - 0s 259us/step\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0       0.84      0.92      0.88     10867\n",
      "           1       0.82      0.88      0.85     10432\n",
      "           2       0.81      0.66      0.73     10591\n",
      "\n",
      "    accuracy                           0.82     31890\n",
      "   macro avg       0.82      0.82      0.82     31890\n",
      "weighted avg       0.82      0.82      0.82     31890\n",
      "\n"
     ]
    }
   ],
   "source": [
    "y_pred = model.predict(X_test)\n",
    "y_pred_classes = np.argmax(y_pred, axis=1)\n",
    "y_true = np.argmax(y_test, axis=1)\n",
    "print(classification_report(y_true, y_pred_classes))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 191,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "3987/3987 [==============================] - 1s 253us/step\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0       0.86      0.94      0.90     42282\n",
      "           1       0.84      0.91      0.87     42717\n",
      "           2       0.85      0.69      0.76     42558\n",
      "\n",
      "    accuracy                           0.85    127557\n",
      "   macro avg       0.85      0.85      0.84    127557\n",
      "weighted avg       0.85      0.85      0.84    127557\n",
      "\n"
     ]
    }
   ],
   "source": [
    "y_t_pred = model.predict(X_train)\n",
    "y_t_pred_classes = np.argmax(y_t_pred, axis=1)\n",
    "y_t_true = np.argmax(y_train, axis=1)\n",
    "print(classification_report(y_t_true, y_t_pred_classes))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 192,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 1/1000\n",
      "225/225 [==============================] - 1s 2ms/step - loss: 0.8365 - accuracy: 0.6384 - val_loss: 0.6924 - val_accuracy: 0.7320\n",
      "Epoch 2/1000\n",
      "225/225 [==============================] - 1s 3ms/step - loss: 0.7035 - accuracy: 0.7339 - val_loss: 0.6654 - val_accuracy: 0.7387\n",
      "Epoch 3/1000\n",
      "225/225 [==============================] - 1s 2ms/step - loss: 0.6874 - accuracy: 0.7370 - val_loss: 0.6666 - val_accuracy: 0.7396\n",
      "Epoch 4/1000\n",
      "225/225 [==============================] - 1s 2ms/step - loss: 0.6795 - accuracy: 0.7383 - val_loss: 0.6525 - val_accuracy: 0.7460\n",
      "Epoch 5/1000\n",
      "225/225 [==============================] - 1s 2ms/step - loss: 0.6768 - accuracy: 0.7391 - val_loss: 0.6558 - val_accuracy: 0.7394\n",
      "Epoch 6/1000\n",
      "225/225 [==============================] - 1s 2ms/step - loss: 0.6693 - accuracy: 0.7406 - val_loss: 0.6439 - val_accuracy: 0.7500\n",
      "Epoch 7/1000\n",
      "225/225 [==============================] - 1s 2ms/step - loss: 0.6572 - accuracy: 0.7449 - val_loss: 0.6346 - val_accuracy: 0.7497\n",
      "Epoch 8/1000\n",
      "225/225 [==============================] - 1s 2ms/step - loss: 0.6409 - accuracy: 0.7496 - val_loss: 0.6171 - val_accuracy: 0.7532\n",
      "Epoch 9/1000\n",
      "225/225 [==============================] - 1s 2ms/step - loss: 0.6259 - accuracy: 0.7552 - val_loss: 0.6001 - val_accuracy: 0.7598\n",
      "Epoch 10/1000\n",
      "225/225 [==============================] - 1s 2ms/step - loss: 0.6067 - accuracy: 0.7612 - val_loss: 0.5893 - val_accuracy: 0.7636\n",
      "Epoch 11/1000\n",
      "225/225 [==============================] - 1s 2ms/step - loss: 0.5982 - accuracy: 0.7644 - val_loss: 0.5893 - val_accuracy: 0.7642\n",
      "Epoch 12/1000\n",
      "225/225 [==============================] - 1s 2ms/step - loss: 0.6063 - accuracy: 0.7605 - val_loss: 0.5943 - val_accuracy: 0.7628\n",
      "Epoch 13/1000\n",
      "225/225 [==============================] - 1s 2ms/step - loss: 0.6154 - accuracy: 0.7582 - val_loss: 0.6000 - val_accuracy: 0.7630\n",
      "Epoch 14/1000\n",
      "225/225 [==============================] - 1s 2ms/step - loss: 0.6225 - accuracy: 0.7563 - val_loss: 0.6160 - val_accuracy: 0.7551\n",
      "Epoch 15/1000\n",
      "225/225 [==============================] - 1s 2ms/step - loss: 0.6303 - accuracy: 0.7547 - val_loss: 0.6168 - val_accuracy: 0.7583\n",
      "Epoch 16/1000\n",
      "225/225 [==============================] - 1s 2ms/step - loss: 0.6328 - accuracy: 0.7523 - val_loss: 0.6056 - val_accuracy: 0.7579\n",
      "Epoch 17/1000\n",
      "225/225 [==============================] - 1s 2ms/step - loss: 0.6161 - accuracy: 0.7583 - val_loss: 0.5955 - val_accuracy: 0.7584\n",
      "Epoch 18/1000\n",
      "225/225 [==============================] - 1s 3ms/step - loss: 0.5988 - accuracy: 0.7647 - val_loss: 0.5752 - val_accuracy: 0.7698\n",
      "Epoch 19/1000\n",
      "225/225 [==============================] - 1s 2ms/step - loss: 0.5789 - accuracy: 0.7703 - val_loss: 0.5633 - val_accuracy: 0.7749\n",
      "Epoch 20/1000\n",
      "225/225 [==============================] - 1s 3ms/step - loss: 0.5580 - accuracy: 0.7787 - val_loss: 0.5474 - val_accuracy: 0.7827\n",
      "Epoch 21/1000\n",
      "225/225 [==============================] - 1s 2ms/step - loss: 0.5477 - accuracy: 0.7827 - val_loss: 0.5521 - val_accuracy: 0.7808\n",
      "Epoch 22/1000\n",
      "225/225 [==============================] - 1s 2ms/step - loss: 0.5581 - accuracy: 0.7800 - val_loss: 0.5584 - val_accuracy: 0.7786\n",
      "Epoch 23/1000\n",
      "225/225 [==============================] - 1s 2ms/step - loss: 0.5723 - accuracy: 0.7733 - val_loss: 0.5729 - val_accuracy: 0.7703\n",
      "Epoch 24/1000\n",
      "225/225 [==============================] - 1s 2ms/step - loss: 0.5860 - accuracy: 0.7673 - val_loss: 0.5857 - val_accuracy: 0.7662\n",
      "Epoch 25/1000\n",
      "225/225 [==============================] - 1s 2ms/step - loss: 0.6009 - accuracy: 0.7618 - val_loss: 0.5849 - val_accuracy: 0.7628\n",
      "Epoch 26/1000\n",
      "225/225 [==============================] - 1s 2ms/step - loss: 0.5985 - accuracy: 0.7626 - val_loss: 0.5836 - val_accuracy: 0.7615\n",
      "Epoch 27/1000\n",
      "225/225 [==============================] - 1s 2ms/step - loss: 0.5859 - accuracy: 0.7683 - val_loss: 0.5650 - val_accuracy: 0.7761\n",
      "Epoch 28/1000\n",
      "225/225 [==============================] - 1s 2ms/step - loss: 0.5685 - accuracy: 0.7738 - val_loss: 0.5477 - val_accuracy: 0.7786\n",
      "Epoch 29/1000\n",
      "225/225 [==============================] - 1s 2ms/step - loss: 0.5448 - accuracy: 0.7825 - val_loss: 0.5306 - val_accuracy: 0.7869\n",
      "Epoch 30/1000\n",
      "225/225 [==============================] - 1s 2ms/step - loss: 0.5279 - accuracy: 0.7897 - val_loss: 0.5205 - val_accuracy: 0.7897\n",
      "Epoch 31/1000\n",
      "225/225 [==============================] - 1s 2ms/step - loss: 0.5204 - accuracy: 0.7918 - val_loss: 0.5231 - val_accuracy: 0.7891\n",
      "Epoch 32/1000\n",
      "225/225 [==============================] - 1s 2ms/step - loss: 0.5295 - accuracy: 0.7873 - val_loss: 0.5379 - val_accuracy: 0.7832\n",
      "Epoch 33/1000\n",
      "225/225 [==============================] - 1s 2ms/step - loss: 0.5443 - accuracy: 0.7825 - val_loss: 0.5465 - val_accuracy: 0.7786\n",
      "Epoch 34/1000\n",
      "225/225 [==============================] - 1s 2ms/step - loss: 0.5610 - accuracy: 0.7763 - val_loss: 0.5553 - val_accuracy: 0.7750\n",
      "Epoch 35/1000\n",
      "225/225 [==============================] - 1s 2ms/step - loss: 0.5785 - accuracy: 0.7715 - val_loss: 0.5672 - val_accuracy: 0.7727\n",
      "Epoch 36/1000\n",
      "225/225 [==============================] - 1s 2ms/step - loss: 0.5896 - accuracy: 0.7658 - val_loss: 0.5661 - val_accuracy: 0.7752\n",
      "Epoch 37/1000\n",
      "225/225 [==============================] - 1s 2ms/step - loss: 0.5705 - accuracy: 0.7744 - val_loss: 0.5427 - val_accuracy: 0.7833\n",
      "Epoch 38/1000\n",
      "225/225 [==============================] - 1s 2ms/step - loss: 0.5482 - accuracy: 0.7813 - val_loss: 0.5384 - val_accuracy: 0.7861\n",
      "Epoch 39/1000\n",
      "225/225 [==============================] - 1s 2ms/step - loss: 0.5284 - accuracy: 0.7891 - val_loss: 0.5180 - val_accuracy: 0.7935\n",
      "Epoch 40/1000\n",
      "225/225 [==============================] - 1s 2ms/step - loss: 0.5100 - accuracy: 0.7959 - val_loss: 0.5128 - val_accuracy: 0.7981\n",
      "Epoch 41/1000\n",
      "225/225 [==============================] - 1s 2ms/step - loss: 0.5031 - accuracy: 0.7993 - val_loss: 0.5125 - val_accuracy: 0.7972\n",
      "Epoch 42/1000\n",
      "225/225 [==============================] - 1s 2ms/step - loss: 0.5128 - accuracy: 0.7938 - val_loss: 0.5179 - val_accuracy: 0.7941\n",
      "Epoch 43/1000\n",
      "225/225 [==============================] - 1s 2ms/step - loss: 0.5283 - accuracy: 0.7892 - val_loss: 0.5285 - val_accuracy: 0.7905\n",
      "Epoch 44/1000\n",
      "225/225 [==============================] - 1s 2ms/step - loss: 0.5446 - accuracy: 0.7833 - val_loss: 0.5440 - val_accuracy: 0.7813\n",
      "Epoch 45/1000\n",
      "225/225 [==============================] - 1s 2ms/step - loss: 0.5635 - accuracy: 0.7769 - val_loss: 0.5601 - val_accuracy: 0.7762\n",
      "Epoch 46/1000\n",
      "225/225 [==============================] - 1s 2ms/step - loss: 0.5690 - accuracy: 0.7739 - val_loss: 0.5473 - val_accuracy: 0.7801\n",
      "Epoch 47/1000\n",
      "225/225 [==============================] - 1s 2ms/step - loss: 0.5521 - accuracy: 0.7805 - val_loss: 0.5337 - val_accuracy: 0.7845\n",
      "Epoch 48/1000\n",
      "225/225 [==============================] - 1s 2ms/step - loss: 0.5332 - accuracy: 0.7873 - val_loss: 0.5230 - val_accuracy: 0.7897\n",
      "Epoch 49/1000\n",
      "225/225 [==============================] - 1s 2ms/step - loss: 0.5140 - accuracy: 0.7951 - val_loss: 0.5065 - val_accuracy: 0.7959\n",
      "Epoch 50/1000\n",
      "225/225 [==============================] - 1s 2ms/step - loss: 0.4968 - accuracy: 0.8015 - val_loss: 0.4989 - val_accuracy: 0.7999\n",
      "Epoch 51/1000\n",
      "225/225 [==============================] - 1s 2ms/step - loss: 0.4867 - accuracy: 0.8048 - val_loss: 0.4990 - val_accuracy: 0.8004\n",
      "Epoch 52/1000\n",
      "225/225 [==============================] - 1s 2ms/step - loss: 0.4985 - accuracy: 0.8012 - val_loss: 0.5113 - val_accuracy: 0.7966\n",
      "Epoch 53/1000\n",
      "225/225 [==============================] - 1s 2ms/step - loss: 0.5129 - accuracy: 0.7955 - val_loss: 0.5207 - val_accuracy: 0.7928\n",
      "Epoch 54/1000\n",
      "225/225 [==============================] - 1s 2ms/step - loss: 0.5291 - accuracy: 0.7898 - val_loss: 0.5295 - val_accuracy: 0.7900\n",
      "Epoch 55/1000\n",
      "225/225 [==============================] - 1s 2ms/step - loss: 0.5471 - accuracy: 0.7833 - val_loss: 0.5541 - val_accuracy: 0.7761\n",
      "Epoch 56/1000\n",
      "225/225 [==============================] - 1s 2ms/step - loss: 0.5670 - accuracy: 0.7762 - val_loss: 0.5404 - val_accuracy: 0.7781\n",
      "Epoch 57/1000\n",
      "225/225 [==============================] - 0s 2ms/step - loss: 0.5531 - accuracy: 0.7796 - val_loss: 0.5327 - val_accuracy: 0.7857\n",
      "Epoch 58/1000\n",
      "225/225 [==============================] - 0s 2ms/step - loss: 0.5300 - accuracy: 0.7898 - val_loss: 0.5156 - val_accuracy: 0.7923\n",
      "Epoch 59/1000\n",
      "225/225 [==============================] - 1s 2ms/step - loss: 0.5072 - accuracy: 0.7979 - val_loss: 0.5006 - val_accuracy: 0.7968\n",
      "Epoch 60/1000\n",
      "225/225 [==============================] - 1s 2ms/step - loss: 0.4891 - accuracy: 0.8056 - val_loss: 0.4968 - val_accuracy: 0.8032\n",
      "Epoch 61/1000\n",
      "225/225 [==============================] - 1s 2ms/step - loss: 0.4833 - accuracy: 0.8081 - val_loss: 0.4987 - val_accuracy: 0.8036\n",
      "Epoch 62/1000\n",
      "225/225 [==============================] - 1s 2ms/step - loss: 0.4918 - accuracy: 0.8040 - val_loss: 0.5087 - val_accuracy: 0.7990\n",
      "Epoch 63/1000\n",
      "225/225 [==============================] - 1s 2ms/step - loss: 0.5050 - accuracy: 0.8003 - val_loss: 0.5166 - val_accuracy: 0.7924\n",
      "Epoch 64/1000\n",
      "225/225 [==============================] - 1s 2ms/step - loss: 0.5264 - accuracy: 0.7905 - val_loss: 0.5334 - val_accuracy: 0.7863\n",
      "Epoch 65/1000\n",
      "225/225 [==============================] - 1s 2ms/step - loss: 0.5496 - accuracy: 0.7814 - val_loss: 0.5426 - val_accuracy: 0.7852\n",
      "Epoch 66/1000\n",
      "225/225 [==============================] - 1s 2ms/step - loss: 0.5575 - accuracy: 0.7805 - val_loss: 0.5368 - val_accuracy: 0.7867\n",
      "Epoch 67/1000\n",
      "225/225 [==============================] - 1s 2ms/step - loss: 0.5383 - accuracy: 0.7862 - val_loss: 0.5284 - val_accuracy: 0.7868\n",
      "Epoch 68/1000\n",
      "225/225 [==============================] - 1s 2ms/step - loss: 0.5228 - accuracy: 0.7912 - val_loss: 0.5148 - val_accuracy: 0.7969\n",
      "Epoch 69/1000\n",
      "225/225 [==============================] - 1s 2ms/step - loss: 0.5025 - accuracy: 0.7991 - val_loss: 0.5021 - val_accuracy: 0.7995\n",
      "Epoch 70/1000\n",
      "225/225 [==============================] - 1s 2ms/step - loss: 0.4841 - accuracy: 0.8079 - val_loss: 0.4941 - val_accuracy: 0.8069\n",
      "Epoch 71/1000\n",
      "225/225 [==============================] - 1s 2ms/step - loss: 0.4779 - accuracy: 0.8101 - val_loss: 0.4922 - val_accuracy: 0.8053\n",
      "Epoch 72/1000\n",
      "225/225 [==============================] - 1s 2ms/step - loss: 0.4837 - accuracy: 0.8091 - val_loss: 0.4965 - val_accuracy: 0.8041\n",
      "Epoch 73/1000\n",
      "225/225 [==============================] - 1s 2ms/step - loss: 0.4997 - accuracy: 0.8013 - val_loss: 0.5027 - val_accuracy: 0.8005\n",
      "Epoch 74/1000\n",
      "225/225 [==============================] - 0s 2ms/step - loss: 0.5191 - accuracy: 0.7943 - val_loss: 0.5226 - val_accuracy: 0.7969\n",
      "Epoch 75/1000\n",
      "225/225 [==============================] - 0s 2ms/step - loss: 0.5361 - accuracy: 0.7867 - val_loss: 0.5387 - val_accuracy: 0.7866\n",
      "Epoch 76/1000\n",
      "225/225 [==============================] - 1s 2ms/step - loss: 0.5512 - accuracy: 0.7820 - val_loss: 0.5277 - val_accuracy: 0.7891\n",
      "Epoch 77/1000\n",
      "225/225 [==============================] - 1s 2ms/step - loss: 0.5404 - accuracy: 0.7851 - val_loss: 0.5267 - val_accuracy: 0.7908\n",
      "Epoch 78/1000\n",
      "225/225 [==============================] - 1s 2ms/step - loss: 0.5211 - accuracy: 0.7946 - val_loss: 0.5157 - val_accuracy: 0.7971\n",
      "Epoch 79/1000\n",
      "225/225 [==============================] - 1s 2ms/step - loss: 0.4994 - accuracy: 0.8016 - val_loss: 0.4963 - val_accuracy: 0.8022\n",
      "Epoch 80/1000\n",
      "225/225 [==============================] - 1s 2ms/step - loss: 0.4817 - accuracy: 0.8094 - val_loss: 0.4876 - val_accuracy: 0.8079\n",
      "Epoch 81/1000\n",
      "225/225 [==============================] - 1s 2ms/step - loss: 0.4745 - accuracy: 0.8127 - val_loss: 0.4881 - val_accuracy: 0.8078\n",
      "Epoch 82/1000\n",
      "225/225 [==============================] - 1s 2ms/step - loss: 0.4827 - accuracy: 0.8100 - val_loss: 0.4938 - val_accuracy: 0.8071\n",
      "Epoch 83/1000\n",
      "225/225 [==============================] - 1s 2ms/step - loss: 0.4955 - accuracy: 0.8038 - val_loss: 0.4986 - val_accuracy: 0.8008\n",
      "Epoch 84/1000\n",
      "225/225 [==============================] - 1s 2ms/step - loss: 0.5122 - accuracy: 0.7977 - val_loss: 0.5200 - val_accuracy: 0.7926\n",
      "Epoch 85/1000\n",
      "225/225 [==============================] - 1s 2ms/step - loss: 0.5381 - accuracy: 0.7873 - val_loss: 0.5329 - val_accuracy: 0.7950\n",
      "Epoch 86/1000\n",
      "225/225 [==============================] - 1s 2ms/step - loss: 0.5528 - accuracy: 0.7808 - val_loss: 0.5462 - val_accuracy: 0.7864\n",
      "Epoch 87/1000\n",
      "225/225 [==============================] - 1s 3ms/step - loss: 0.5375 - accuracy: 0.7865 - val_loss: 0.5287 - val_accuracy: 0.7919\n",
      "Epoch 88/1000\n",
      "225/225 [==============================] - 1s 2ms/step - loss: 0.5142 - accuracy: 0.7971 - val_loss: 0.5000 - val_accuracy: 0.8063\n",
      "Epoch 89/1000\n",
      "225/225 [==============================] - 1s 2ms/step - loss: 0.4951 - accuracy: 0.8047 - val_loss: 0.4952 - val_accuracy: 0.8060\n",
      "Epoch 90/1000\n",
      "225/225 [==============================] - 1s 2ms/step - loss: 0.4785 - accuracy: 0.8115 - val_loss: 0.4858 - val_accuracy: 0.8087\n",
      "Epoch 91/1000\n",
      "225/225 [==============================] - 0s 2ms/step - loss: 0.4695 - accuracy: 0.8158 - val_loss: 0.4909 - val_accuracy: 0.8118\n",
      "Epoch 92/1000\n",
      "225/225 [==============================] - 0s 2ms/step - loss: 0.4800 - accuracy: 0.8112 - val_loss: 0.4867 - val_accuracy: 0.8065\n",
      "Epoch 93/1000\n",
      "225/225 [==============================] - 0s 2ms/step - loss: 0.4878 - accuracy: 0.8068 - val_loss: 0.4991 - val_accuracy: 0.8028\n",
      "Epoch 94/1000\n",
      "225/225 [==============================] - 1s 2ms/step - loss: 0.5100 - accuracy: 0.7977 - val_loss: 0.5253 - val_accuracy: 0.7960\n",
      "Epoch 95/1000\n",
      "225/225 [==============================] - 1s 2ms/step - loss: 0.5390 - accuracy: 0.7879 - val_loss: 0.5547 - val_accuracy: 0.7860\n",
      "Epoch 96/1000\n",
      "225/225 [==============================] - 1s 2ms/step - loss: 0.5476 - accuracy: 0.7848 - val_loss: 0.5386 - val_accuracy: 0.7923\n",
      "Epoch 97/1000\n",
      "225/225 [==============================] - 1s 2ms/step - loss: 0.5341 - accuracy: 0.7895 - val_loss: 0.5230 - val_accuracy: 0.7954\n",
      "Epoch 98/1000\n",
      "225/225 [==============================] - 1s 2ms/step - loss: 0.5115 - accuracy: 0.7987 - val_loss: 0.5166 - val_accuracy: 0.7975\n",
      "Epoch 99/1000\n",
      "225/225 [==============================] - 1s 2ms/step - loss: 0.4965 - accuracy: 0.8040 - val_loss: 0.4942 - val_accuracy: 0.8059\n",
      "Epoch 100/1000\n",
      "225/225 [==============================] - 1s 2ms/step - loss: 0.4783 - accuracy: 0.8108 - val_loss: 0.4899 - val_accuracy: 0.8086\n",
      "Epoch 101/1000\n",
      "225/225 [==============================] - 1s 2ms/step - loss: 0.4719 - accuracy: 0.8147 - val_loss: 0.4884 - val_accuracy: 0.8084\n",
      "Epoch 102/1000\n",
      "225/225 [==============================] - 1s 2ms/step - loss: 0.4792 - accuracy: 0.8126 - val_loss: 0.4921 - val_accuracy: 0.8058\n",
      "Epoch 103/1000\n",
      "225/225 [==============================] - 1s 2ms/step - loss: 0.4912 - accuracy: 0.8074 - val_loss: 0.5058 - val_accuracy: 0.8036\n",
      "Epoch 104/1000\n",
      "225/225 [==============================] - 1s 3ms/step - loss: 0.5089 - accuracy: 0.7995 - val_loss: 0.5215 - val_accuracy: 0.7972\n",
      "Epoch 105/1000\n",
      "225/225 [==============================] - 1s 2ms/step - loss: 0.5308 - accuracy: 0.7899 - val_loss: 0.5303 - val_accuracy: 0.7949\n",
      "Epoch 106/1000\n",
      "225/225 [==============================] - 1s 2ms/step - loss: 0.5532 - accuracy: 0.7823 - val_loss: 0.5435 - val_accuracy: 0.7834\n",
      "Epoch 107/1000\n",
      "225/225 [==============================] - 1s 2ms/step - loss: 0.5312 - accuracy: 0.7908 - val_loss: 0.5208 - val_accuracy: 0.7934\n",
      "Epoch 108/1000\n",
      "225/225 [==============================] - 1s 2ms/step - loss: 0.5085 - accuracy: 0.8002 - val_loss: 0.5004 - val_accuracy: 0.8023\n",
      "Epoch 109/1000\n",
      "225/225 [==============================] - 1s 2ms/step - loss: 0.4890 - accuracy: 0.8069 - val_loss: 0.4894 - val_accuracy: 0.8069\n",
      "Epoch 110/1000\n",
      "225/225 [==============================] - 0s 2ms/step - loss: 0.4741 - accuracy: 0.8132 - val_loss: 0.4832 - val_accuracy: 0.8122\n",
      "Epoch 111/1000\n",
      "225/225 [==============================] - 1s 2ms/step - loss: 0.4676 - accuracy: 0.8161 - val_loss: 0.4841 - val_accuracy: 0.8133\n",
      "Epoch 112/1000\n",
      "225/225 [==============================] - 1s 2ms/step - loss: 0.4696 - accuracy: 0.8156 - val_loss: 0.4843 - val_accuracy: 0.8099\n",
      "Epoch 113/1000\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "225/225 [==============================] - 1s 2ms/step - loss: 0.4845 - accuracy: 0.8092 - val_loss: 0.4982 - val_accuracy: 0.8034\n",
      "Epoch 114/1000\n",
      "225/225 [==============================] - 1s 2ms/step - loss: 0.5109 - accuracy: 0.7992 - val_loss: 0.5106 - val_accuracy: 0.7977\n",
      "Epoch 115/1000\n",
      "225/225 [==============================] - 1s 2ms/step - loss: 0.5289 - accuracy: 0.7907 - val_loss: 0.5244 - val_accuracy: 0.7923\n",
      "Epoch 116/1000\n",
      "225/225 [==============================] - 1s 2ms/step - loss: 0.5350 - accuracy: 0.7907 - val_loss: 0.5207 - val_accuracy: 0.7917\n",
      "Epoch 117/1000\n",
      "225/225 [==============================] - 1s 2ms/step - loss: 0.5260 - accuracy: 0.7910 - val_loss: 0.5095 - val_accuracy: 0.7987\n",
      "Epoch 118/1000\n",
      "225/225 [==============================] - 1s 2ms/step - loss: 0.5044 - accuracy: 0.8011 - val_loss: 0.4922 - val_accuracy: 0.8037\n",
      "Epoch 119/1000\n",
      "225/225 [==============================] - 1s 2ms/step - loss: 0.4894 - accuracy: 0.8062 - val_loss: 0.4858 - val_accuracy: 0.8097\n",
      "Epoch 120/1000\n",
      "225/225 [==============================] - 1s 2ms/step - loss: 0.4686 - accuracy: 0.8159 - val_loss: 0.4763 - val_accuracy: 0.8171\n",
      "Epoch 121/1000\n",
      "225/225 [==============================] - 1s 2ms/step - loss: 0.4619 - accuracy: 0.8170 - val_loss: 0.4793 - val_accuracy: 0.8174\n",
      "Epoch 122/1000\n",
      "225/225 [==============================] - 1s 2ms/step - loss: 0.4686 - accuracy: 0.8155 - val_loss: 0.4796 - val_accuracy: 0.8145\n",
      "Epoch 123/1000\n",
      "225/225 [==============================] - 1s 2ms/step - loss: 0.4812 - accuracy: 0.8104 - val_loss: 0.4896 - val_accuracy: 0.8108\n",
      "Epoch 124/1000\n",
      "225/225 [==============================] - 0s 2ms/step - loss: 0.4954 - accuracy: 0.8061 - val_loss: 0.5150 - val_accuracy: 0.7991\n",
      "Epoch 125/1000\n",
      "225/225 [==============================] - 1s 2ms/step - loss: 0.5208 - accuracy: 0.7949 - val_loss: 0.5238 - val_accuracy: 0.7905\n",
      "Epoch 126/1000\n",
      "225/225 [==============================] - 1s 2ms/step - loss: 0.5479 - accuracy: 0.7848 - val_loss: 0.5256 - val_accuracy: 0.7945\n",
      "Epoch 127/1000\n",
      "225/225 [==============================] - 0s 2ms/step - loss: 0.5413 - accuracy: 0.7889 - val_loss: 0.5326 - val_accuracy: 0.7943\n",
      "Epoch 128/1000\n",
      "225/225 [==============================] - 0s 2ms/step - loss: 0.5124 - accuracy: 0.7991 - val_loss: 0.5085 - val_accuracy: 0.8015\n",
      "Epoch 129/1000\n",
      "225/225 [==============================] - 0s 2ms/step - loss: 0.4886 - accuracy: 0.8077 - val_loss: 0.4883 - val_accuracy: 0.8104\n",
      "Epoch 130/1000\n",
      "225/225 [==============================] - 0s 2ms/step - loss: 0.4741 - accuracy: 0.8140 - val_loss: 0.4845 - val_accuracy: 0.8104\n",
      "Epoch 131/1000\n",
      "225/225 [==============================] - 0s 2ms/step - loss: 0.4686 - accuracy: 0.8154 - val_loss: 0.4798 - val_accuracy: 0.8127\n",
      "Epoch 132/1000\n",
      "225/225 [==============================] - 0s 2ms/step - loss: 0.4721 - accuracy: 0.8147 - val_loss: 0.4852 - val_accuracy: 0.8120\n",
      "Epoch 133/1000\n",
      "225/225 [==============================] - 0s 2ms/step - loss: 0.4876 - accuracy: 0.8089 - val_loss: 0.5003 - val_accuracy: 0.8073\n",
      "Epoch 134/1000\n",
      "225/225 [==============================] - 0s 2ms/step - loss: 0.5037 - accuracy: 0.8027 - val_loss: 0.5352 - val_accuracy: 0.7887\n",
      "Epoch 135/1000\n",
      "225/225 [==============================] - 0s 2ms/step - loss: 0.5398 - accuracy: 0.7880 - val_loss: 0.5396 - val_accuracy: 0.7899\n",
      "Epoch 136/1000\n",
      "225/225 [==============================] - 0s 2ms/step - loss: 0.5518 - accuracy: 0.7836 - val_loss: 0.5454 - val_accuracy: 0.7828\n",
      "Epoch 137/1000\n",
      "225/225 [==============================] - 0s 2ms/step - loss: 0.5310 - accuracy: 0.7904 - val_loss: 0.5201 - val_accuracy: 0.7944\n",
      "Epoch 138/1000\n",
      "225/225 [==============================] - 0s 2ms/step - loss: 0.5083 - accuracy: 0.7993 - val_loss: 0.5019 - val_accuracy: 0.8035\n",
      "Epoch 139/1000\n",
      "225/225 [==============================] - 1s 2ms/step - loss: 0.4884 - accuracy: 0.8074 - val_loss: 0.4900 - val_accuracy: 0.8068\n",
      "Epoch 140/1000\n",
      "225/225 [==============================] - 0s 2ms/step - loss: 0.4741 - accuracy: 0.8138 - val_loss: 0.4849 - val_accuracy: 0.8121\n",
      "Epoch 141/1000\n",
      "225/225 [==============================] - 1s 2ms/step - loss: 0.4674 - accuracy: 0.8160 - val_loss: 0.4842 - val_accuracy: 0.8106\n",
      "Epoch 142/1000\n",
      "225/225 [==============================] - 0s 2ms/step - loss: 0.4721 - accuracy: 0.8156 - val_loss: 0.4981 - val_accuracy: 0.8079\n",
      "Epoch 143/1000\n",
      "225/225 [==============================] - 0s 2ms/step - loss: 0.4896 - accuracy: 0.8084 - val_loss: 0.4946 - val_accuracy: 0.8019\n",
      "Epoch 144/1000\n",
      "225/225 [==============================] - 0s 2ms/step - loss: 0.5008 - accuracy: 0.8041 - val_loss: 0.5141 - val_accuracy: 0.7976\n",
      "Epoch 145/1000\n",
      "225/225 [==============================] - 0s 2ms/step - loss: 0.5166 - accuracy: 0.7972 - val_loss: 0.5265 - val_accuracy: 0.7947\n",
      "Epoch 146/1000\n",
      "225/225 [==============================] - 1s 2ms/step - loss: 0.5208 - accuracy: 0.7958 - val_loss: 0.5315 - val_accuracy: 0.7936\n",
      "Epoch 147/1000\n",
      "225/225 [==============================] - 0s 2ms/step - loss: 0.5228 - accuracy: 0.7956 - val_loss: 0.5144 - val_accuracy: 0.7999\n",
      "Epoch 148/1000\n",
      "225/225 [==============================] - 1s 2ms/step - loss: 0.5034 - accuracy: 0.8029 - val_loss: 0.4947 - val_accuracy: 0.8045\n",
      "Epoch 149/1000\n",
      "225/225 [==============================] - 1s 2ms/step - loss: 0.4851 - accuracy: 0.8095 - val_loss: 0.4785 - val_accuracy: 0.8115\n",
      "Epoch 150/1000\n",
      "225/225 [==============================] - 0s 2ms/step - loss: 0.4681 - accuracy: 0.8159 - val_loss: 0.4736 - val_accuracy: 0.8144\n",
      "Epoch 151/1000\n",
      "225/225 [==============================] - 0s 2ms/step - loss: 0.4619 - accuracy: 0.8184 - val_loss: 0.4761 - val_accuracy: 0.8147\n",
      "Epoch 152/1000\n",
      "225/225 [==============================] - 0s 2ms/step - loss: 0.4635 - accuracy: 0.8177 - val_loss: 0.4787 - val_accuracy: 0.8108\n",
      "Epoch 153/1000\n",
      "225/225 [==============================] - 0s 2ms/step - loss: 0.4828 - accuracy: 0.8109 - val_loss: 0.4914 - val_accuracy: 0.8072\n",
      "Epoch 154/1000\n",
      "225/225 [==============================] - 0s 2ms/step - loss: 0.4937 - accuracy: 0.8059 - val_loss: 0.5116 - val_accuracy: 0.8012\n",
      "Epoch 155/1000\n",
      "225/225 [==============================] - 0s 2ms/step - loss: 0.5269 - accuracy: 0.7931 - val_loss: 0.5367 - val_accuracy: 0.7889\n",
      "Epoch 156/1000\n",
      "225/225 [==============================] - 0s 2ms/step - loss: 0.5427 - accuracy: 0.7882 - val_loss: 0.5201 - val_accuracy: 0.7919\n",
      "Epoch 157/1000\n",
      "225/225 [==============================] - 1s 2ms/step - loss: 0.5278 - accuracy: 0.7932 - val_loss: 0.5137 - val_accuracy: 0.7989\n",
      "Epoch 158/1000\n",
      "225/225 [==============================] - 1s 2ms/step - loss: 0.5084 - accuracy: 0.7988 - val_loss: 0.5027 - val_accuracy: 0.8000\n",
      "Epoch 159/1000\n",
      "225/225 [==============================] - 1s 2ms/step - loss: 0.4883 - accuracy: 0.8072 - val_loss: 0.4852 - val_accuracy: 0.8104\n",
      "Epoch 160/1000\n",
      "225/225 [==============================] - 0s 2ms/step - loss: 0.4738 - accuracy: 0.8130 - val_loss: 0.4840 - val_accuracy: 0.8111\n",
      "Epoch 161/1000\n",
      "225/225 [==============================] - 0s 2ms/step - loss: 0.4676 - accuracy: 0.8170 - val_loss: 0.4804 - val_accuracy: 0.8151\n",
      "Epoch 162/1000\n",
      "225/225 [==============================] - 0s 2ms/step - loss: 0.4707 - accuracy: 0.8158 - val_loss: 0.4952 - val_accuracy: 0.8116\n",
      "Epoch 163/1000\n",
      "225/225 [==============================] - 0s 2ms/step - loss: 0.4830 - accuracy: 0.8105 - val_loss: 0.4947 - val_accuracy: 0.8061\n",
      "Epoch 164/1000\n",
      "225/225 [==============================] - 0s 2ms/step - loss: 0.5038 - accuracy: 0.8037 - val_loss: 0.5140 - val_accuracy: 0.8012\n",
      "Epoch 165/1000\n",
      "225/225 [==============================] - 0s 2ms/step - loss: 0.5275 - accuracy: 0.7932 - val_loss: 0.5380 - val_accuracy: 0.7863\n",
      "Epoch 166/1000\n",
      "225/225 [==============================] - 0s 2ms/step - loss: 0.5350 - accuracy: 0.7912 - val_loss: 0.5366 - val_accuracy: 0.7860\n",
      "Epoch 167/1000\n",
      "225/225 [==============================] - 0s 2ms/step - loss: 0.5344 - accuracy: 0.7894 - val_loss: 0.5157 - val_accuracy: 0.7955\n",
      "Epoch 168/1000\n",
      "225/225 [==============================] - 0s 2ms/step - loss: 0.5089 - accuracy: 0.8000 - val_loss: 0.5058 - val_accuracy: 0.7986\n",
      "Epoch 169/1000\n",
      "225/225 [==============================] - 0s 2ms/step - loss: 0.4884 - accuracy: 0.8071 - val_loss: 0.4877 - val_accuracy: 0.8107\n",
      "Epoch 170/1000\n",
      "225/225 [==============================] - 0s 2ms/step - loss: 0.4745 - accuracy: 0.8133 - val_loss: 0.4844 - val_accuracy: 0.8108\n",
      "Epoch 171/1000\n",
      "225/225 [==============================] - 0s 2ms/step - loss: 0.4693 - accuracy: 0.8155 - val_loss: 0.4833 - val_accuracy: 0.8093\n",
      "Epoch 172/1000\n",
      "225/225 [==============================] - 0s 2ms/step - loss: 0.4684 - accuracy: 0.8154 - val_loss: 0.4894 - val_accuracy: 0.8095\n",
      "Epoch 173/1000\n",
      "225/225 [==============================] - 0s 2ms/step - loss: 0.4778 - accuracy: 0.8125 - val_loss: 0.4969 - val_accuracy: 0.8039\n",
      "Epoch 174/1000\n",
      "225/225 [==============================] - 0s 2ms/step - loss: 0.5148 - accuracy: 0.7959 - val_loss: 0.5164 - val_accuracy: 0.7973\n",
      "Epoch 175/1000\n",
      "225/225 [==============================] - 0s 2ms/step - loss: 0.5195 - accuracy: 0.7978 - val_loss: 0.5346 - val_accuracy: 0.7940\n",
      "Epoch 176/1000\n",
      "225/225 [==============================] - 0s 2ms/step - loss: 0.5429 - accuracy: 0.7885 - val_loss: 0.5237 - val_accuracy: 0.7957\n",
      "Epoch 177/1000\n",
      "225/225 [==============================] - 0s 2ms/step - loss: 0.5415 - accuracy: 0.7883 - val_loss: 0.5243 - val_accuracy: 0.7911\n",
      "Epoch 178/1000\n",
      "225/225 [==============================] - 0s 2ms/step - loss: 0.5131 - accuracy: 0.7989 - val_loss: 0.5037 - val_accuracy: 0.8021\n",
      "Epoch 179/1000\n",
      "225/225 [==============================] - 0s 2ms/step - loss: 0.4885 - accuracy: 0.8058 - val_loss: 0.4883 - val_accuracy: 0.8093\n",
      "Epoch 180/1000\n",
      "225/225 [==============================] - 0s 2ms/step - loss: 0.4736 - accuracy: 0.8137 - val_loss: 0.4839 - val_accuracy: 0.8126\n",
      "Epoch 181/1000\n",
      "225/225 [==============================] - 0s 2ms/step - loss: 0.4694 - accuracy: 0.8161 - val_loss: 0.4795 - val_accuracy: 0.8141\n",
      "Epoch 182/1000\n",
      "225/225 [==============================] - 0s 2ms/step - loss: 0.4685 - accuracy: 0.8153 - val_loss: 0.4836 - val_accuracy: 0.8107\n",
      "Epoch 183/1000\n",
      "225/225 [==============================] - 0s 2ms/step - loss: 0.4831 - accuracy: 0.8119 - val_loss: 0.4989 - val_accuracy: 0.8054\n",
      "Epoch 184/1000\n",
      "225/225 [==============================] - 0s 2ms/step - loss: 0.4902 - accuracy: 0.8084 - val_loss: 0.5067 - val_accuracy: 0.8006\n",
      "Epoch 185/1000\n",
      "225/225 [==============================] - 0s 2ms/step - loss: 0.5232 - accuracy: 0.7940 - val_loss: 0.5516 - val_accuracy: 0.7908\n",
      "Epoch 186/1000\n",
      "225/225 [==============================] - 0s 2ms/step - loss: 0.5462 - accuracy: 0.7884 - val_loss: 0.5302 - val_accuracy: 0.7868\n",
      "Epoch 187/1000\n",
      "225/225 [==============================] - 0s 2ms/step - loss: 0.5362 - accuracy: 0.7907 - val_loss: 0.5261 - val_accuracy: 0.7932\n",
      "Epoch 188/1000\n",
      "225/225 [==============================] - 0s 2ms/step - loss: 0.5194 - accuracy: 0.7954 - val_loss: 0.5146 - val_accuracy: 0.8004\n",
      "Epoch 189/1000\n",
      "225/225 [==============================] - 0s 2ms/step - loss: 0.5076 - accuracy: 0.7989 - val_loss: 0.5063 - val_accuracy: 0.8021\n",
      "Epoch 190/1000\n",
      "225/225 [==============================] - 0s 2ms/step - loss: 0.4887 - accuracy: 0.8081 - val_loss: 0.4972 - val_accuracy: 0.8036\n",
      "Epoch 191/1000\n",
      "225/225 [==============================] - 0s 2ms/step - loss: 0.4806 - accuracy: 0.8096 - val_loss: 0.4921 - val_accuracy: 0.8057\n",
      "Epoch 192/1000\n",
      "225/225 [==============================] - 1s 2ms/step - loss: 0.4757 - accuracy: 0.8136 - val_loss: 0.4919 - val_accuracy: 0.8046\n",
      "Epoch 193/1000\n",
      "225/225 [==============================] - 1s 2ms/step - loss: 0.4886 - accuracy: 0.8065 - val_loss: 0.5035 - val_accuracy: 0.7984\n",
      "Epoch 194/1000\n",
      "225/225 [==============================] - 0s 2ms/step - loss: 0.5034 - accuracy: 0.8035 - val_loss: 0.5139 - val_accuracy: 0.8013\n",
      "Epoch 195/1000\n",
      "225/225 [==============================] - 0s 2ms/step - loss: 0.5500 - accuracy: 0.7861 - val_loss: 0.5507 - val_accuracy: 0.7855\n",
      "Epoch 196/1000\n",
      "225/225 [==============================] - 0s 2ms/step - loss: 0.5484 - accuracy: 0.7827 - val_loss: 0.5265 - val_accuracy: 0.7885\n",
      "Epoch 197/1000\n",
      "225/225 [==============================] - 0s 2ms/step - loss: 0.5225 - accuracy: 0.7936 - val_loss: 0.5295 - val_accuracy: 0.7954\n",
      "Epoch 198/1000\n",
      "225/225 [==============================] - 1s 3ms/step - loss: 0.5230 - accuracy: 0.7915 - val_loss: 0.5137 - val_accuracy: 0.7923\n",
      "Epoch 199/1000\n",
      "225/225 [==============================] - 0s 2ms/step - loss: 0.4952 - accuracy: 0.8021 - val_loss: 0.5050 - val_accuracy: 0.7991\n",
      "Epoch 200/1000\n",
      "225/225 [==============================] - 0s 2ms/step - loss: 0.4813 - accuracy: 0.8089 - val_loss: 0.4933 - val_accuracy: 0.8040\n",
      "Epoch 201/1000\n",
      "225/225 [==============================] - 0s 2ms/step - loss: 0.4757 - accuracy: 0.8125 - val_loss: 0.4920 - val_accuracy: 0.8068\n",
      "Epoch 202/1000\n",
      "225/225 [==============================] - 0s 2ms/step - loss: 0.4781 - accuracy: 0.8123 - val_loss: 0.4963 - val_accuracy: 0.8040\n",
      "Epoch 203/1000\n",
      "225/225 [==============================] - 0s 2ms/step - loss: 0.4873 - accuracy: 0.8087 - val_loss: 0.4940 - val_accuracy: 0.8032\n",
      "Epoch 204/1000\n",
      "225/225 [==============================] - 1s 2ms/step - loss: 0.4999 - accuracy: 0.8048 - val_loss: 0.5177 - val_accuracy: 0.7977\n",
      "Epoch 205/1000\n",
      "225/225 [==============================] - 1s 2ms/step - loss: 0.5381 - accuracy: 0.7896 - val_loss: 0.5365 - val_accuracy: 0.7913\n",
      "Epoch 206/1000\n",
      "225/225 [==============================] - 0s 2ms/step - loss: 0.5552 - accuracy: 0.7822 - val_loss: 0.5407 - val_accuracy: 0.7861\n",
      "Epoch 207/1000\n",
      "225/225 [==============================] - 0s 2ms/step - loss: 0.5427 - accuracy: 0.7874 - val_loss: 0.5261 - val_accuracy: 0.7919\n",
      "Epoch 208/1000\n",
      "225/225 [==============================] - 1s 2ms/step - loss: 0.5270 - accuracy: 0.7925 - val_loss: 0.5089 - val_accuracy: 0.7971\n",
      "Epoch 209/1000\n",
      "225/225 [==============================] - 0s 2ms/step - loss: 0.5015 - accuracy: 0.8017 - val_loss: 0.4984 - val_accuracy: 0.8015\n",
      "Epoch 210/1000\n",
      "225/225 [==============================] - 0s 2ms/step - loss: 0.4857 - accuracy: 0.8076 - val_loss: 0.4921 - val_accuracy: 0.8068\n",
      "Epoch 211/1000\n",
      "225/225 [==============================] - 0s 2ms/step - loss: 0.4811 - accuracy: 0.8097 - val_loss: 0.4893 - val_accuracy: 0.8071\n",
      "Epoch 212/1000\n",
      "225/225 [==============================] - 0s 2ms/step - loss: 0.4818 - accuracy: 0.8105 - val_loss: 0.4941 - val_accuracy: 0.8035\n",
      "Epoch 213/1000\n",
      "225/225 [==============================] - 0s 2ms/step - loss: 0.4887 - accuracy: 0.8085 - val_loss: 0.4974 - val_accuracy: 0.8075\n",
      "Epoch 214/1000\n",
      "225/225 [==============================] - 0s 2ms/step - loss: 0.4986 - accuracy: 0.8049 - val_loss: 0.5063 - val_accuracy: 0.8014\n",
      "Epoch 215/1000\n",
      "225/225 [==============================] - 0s 2ms/step - loss: 0.5480 - accuracy: 0.7864 - val_loss: 0.5349 - val_accuracy: 0.7835\n",
      "Epoch 216/1000\n",
      "225/225 [==============================] - 0s 2ms/step - loss: 0.5479 - accuracy: 0.7825 - val_loss: 0.5409 - val_accuracy: 0.7796\n",
      "Epoch 217/1000\n",
      "225/225 [==============================] - 0s 2ms/step - loss: 0.5386 - accuracy: 0.7861 - val_loss: 0.5218 - val_accuracy: 0.7908\n",
      "Epoch 218/1000\n",
      "225/225 [==============================] - 0s 2ms/step - loss: 0.5176 - accuracy: 0.7950 - val_loss: 0.5160 - val_accuracy: 0.7950\n",
      "Epoch 219/1000\n",
      "225/225 [==============================] - 0s 2ms/step - loss: 0.5053 - accuracy: 0.7989 - val_loss: 0.5010 - val_accuracy: 0.8011\n",
      "Epoch 220/1000\n",
      "225/225 [==============================] - 0s 2ms/step - loss: 0.4884 - accuracy: 0.8076 - val_loss: 0.4937 - val_accuracy: 0.8050\n",
      "Epoch 221/1000\n",
      "225/225 [==============================] - 0s 2ms/step - loss: 0.4821 - accuracy: 0.8089 - val_loss: 0.4955 - val_accuracy: 0.8075\n",
      "Epoch 222/1000\n",
      "225/225 [==============================] - 0s 2ms/step - loss: 0.4800 - accuracy: 0.8102 - val_loss: 0.4942 - val_accuracy: 0.8042\n",
      "Epoch 223/1000\n",
      "225/225 [==============================] - 0s 2ms/step - loss: 0.4911 - accuracy: 0.8075 - val_loss: 0.5176 - val_accuracy: 0.7992\n",
      "Epoch 224/1000\n",
      "225/225 [==============================] - 0s 2ms/step - loss: 0.5206 - accuracy: 0.7963 - val_loss: 0.5122 - val_accuracy: 0.7996\n",
      "Epoch 225/1000\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "225/225 [==============================] - 0s 2ms/step - loss: 0.5406 - accuracy: 0.7882 - val_loss: 0.5322 - val_accuracy: 0.7927\n",
      "Epoch 226/1000\n",
      "225/225 [==============================] - 0s 2ms/step - loss: 0.5551 - accuracy: 0.7839 - val_loss: 0.5520 - val_accuracy: 0.7901\n",
      "Epoch 227/1000\n",
      "225/225 [==============================] - 0s 2ms/step - loss: 0.5398 - accuracy: 0.7904 - val_loss: 0.5274 - val_accuracy: 0.7946\n",
      "Epoch 228/1000\n",
      "225/225 [==============================] - 0s 2ms/step - loss: 0.5084 - accuracy: 0.8024 - val_loss: 0.5028 - val_accuracy: 0.8028\n",
      "Epoch 229/1000\n",
      "225/225 [==============================] - 0s 2ms/step - loss: 0.4957 - accuracy: 0.8071 - val_loss: 0.4957 - val_accuracy: 0.8084\n",
      "Epoch 230/1000\n",
      "225/225 [==============================] - 0s 2ms/step - loss: 0.4809 - accuracy: 0.8128 - val_loss: 0.4871 - val_accuracy: 0.8109\n",
      "Epoch 231/1000\n",
      "225/225 [==============================] - 0s 2ms/step - loss: 0.4754 - accuracy: 0.8137 - val_loss: 0.4903 - val_accuracy: 0.8073\n",
      "Epoch 232/1000\n",
      "225/225 [==============================] - 0s 2ms/step - loss: 0.4766 - accuracy: 0.8143 - val_loss: 0.4887 - val_accuracy: 0.8122\n",
      "Epoch 233/1000\n",
      "225/225 [==============================] - 0s 2ms/step - loss: 0.4890 - accuracy: 0.8091 - val_loss: 0.4987 - val_accuracy: 0.8017\n",
      "Epoch 234/1000\n",
      "225/225 [==============================] - 0s 2ms/step - loss: 0.5057 - accuracy: 0.8035 - val_loss: 0.5123 - val_accuracy: 0.7995\n",
      "Epoch 235/1000\n",
      "225/225 [==============================] - 0s 2ms/step - loss: 0.5372 - accuracy: 0.7877 - val_loss: 0.5497 - val_accuracy: 0.7828\n",
      "Epoch 236/1000\n",
      "225/225 [==============================] - 0s 2ms/step - loss: 0.5533 - accuracy: 0.7830 - val_loss: 0.5314 - val_accuracy: 0.7881\n",
      "Epoch 237/1000\n",
      "225/225 [==============================] - 0s 2ms/step - loss: 0.5398 - accuracy: 0.7874 - val_loss: 0.5202 - val_accuracy: 0.7915\n",
      "Epoch 238/1000\n",
      "225/225 [==============================] - 0s 2ms/step - loss: 0.5139 - accuracy: 0.7977 - val_loss: 0.5122 - val_accuracy: 0.7955\n",
      "Epoch 239/1000\n",
      "225/225 [==============================] - 0s 2ms/step - loss: 0.5006 - accuracy: 0.8021 - val_loss: 0.4911 - val_accuracy: 0.8061\n",
      "Epoch 240/1000\n",
      "225/225 [==============================] - 0s 2ms/step - loss: 0.4815 - accuracy: 0.8095 - val_loss: 0.4863 - val_accuracy: 0.8097\n",
      "Epoch 240: early stopping\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "<keras.src.callbacks.History at 0x1420da140>"
      ]
     },
     "execution_count": 192,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "model=Sequential()\n",
    "model.add(Dense(128, input_dim=X_train.shape[1], activation=\"relu\"))\n",
    "\n",
    "model.add(Dense(128, activation=\"relu\"))\n",
    "model.add(Dropout(0.2))\n",
    "model.add(Dense(64, activation=\"relu\"))\n",
    "\n",
    "model.add(Dense(64, activation=\"relu\"))\n",
    "model.add(Dropout(0.2))\n",
    "model.add(Dense(32, activation=\"relu\"))\n",
    "model.add(Dropout(0.2))\n",
    "model.add(Dense(16, activation=\"relu\"))\n",
    "model.add(Dropout(0.2))\n",
    "model.add(Dense(3, activation=\"softmax\"))\n",
    "\n",
    "model.compile(loss='categorical_crossentropy', optimizer=Adam(learning_rate=0.001), metrics=['accuracy'])\n",
    "\n",
    "es=EarlyStopping(monitor=\"val_loss\",patience=90,mode=\"auto\",verbose=1)\n",
    "clr = CyclicLR(base_lr=0.0001, max_lr=0.01,\n",
    "                                step_size=1125., mode='triangular')\n",
    "model.fit(X_train,\n",
    "          y_train,\n",
    "          epochs=1000,\n",
    "               batch_size=512,\n",
    "               validation_split=0.1,\n",
    "               verbose=1,callbacks=[es, clr])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 193,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "997/997 [==============================] - 0s 261us/step\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0       0.81      0.93      0.87     10867\n",
      "           1       0.81      0.85      0.83     10432\n",
      "           2       0.80      0.64      0.71     10591\n",
      "\n",
      "    accuracy                           0.81     31890\n",
      "   macro avg       0.81      0.81      0.80     31890\n",
      "weighted avg       0.81      0.81      0.80     31890\n",
      "\n"
     ]
    }
   ],
   "source": [
    "y_pred = model.predict(X_test)\n",
    "y_pred_classes = np.argmax(y_pred, axis=1)\n",
    "y_true = np.argmax(y_test, axis=1)\n",
    "print(classification_report(y_true, y_pred_classes))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 194,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "3987/3987 [==============================] - 1s 250us/step\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0       0.83      0.95      0.89     42282\n",
      "           1       0.83      0.88      0.85     42717\n",
      "           2       0.83      0.67      0.74     42558\n",
      "\n",
      "    accuracy                           0.83    127557\n",
      "   macro avg       0.83      0.83      0.83    127557\n",
      "weighted avg       0.83      0.83      0.83    127557\n",
      "\n"
     ]
    }
   ],
   "source": [
    "y_t_pred = model.predict(X_train)\n",
    "y_t_pred_classes = np.argmax(y_t_pred, axis=1)\n",
    "y_t_true = np.argmax(y_train, axis=1)\n",
    "print(classification_report(y_t_true, y_t_pred_classes))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 195,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 1/1000\n",
      "225/225 [==============================] - 1s 2ms/step - loss: 0.7719 - accuracy: 0.6977 - val_loss: 0.7102 - val_accuracy: 0.7172\n",
      "Epoch 2/1000\n",
      "225/225 [==============================] - 0s 2ms/step - loss: 0.7187 - accuracy: 0.7287 - val_loss: 0.7082 - val_accuracy: 0.7305\n",
      "Epoch 3/1000\n",
      "225/225 [==============================] - 0s 2ms/step - loss: 0.7097 - accuracy: 0.7312 - val_loss: 0.8463 - val_accuracy: 0.6864\n",
      "Epoch 4/1000\n",
      "225/225 [==============================] - 0s 2ms/step - loss: 0.7174 - accuracy: 0.7292 - val_loss: 0.6898 - val_accuracy: 0.7345\n",
      "Epoch 5/1000\n",
      "225/225 [==============================] - 0s 2ms/step - loss: 0.7250 - accuracy: 0.7268 - val_loss: 0.7577 - val_accuracy: 0.7262\n",
      "Epoch 6/1000\n",
      "225/225 [==============================] - 1s 2ms/step - loss: 0.7267 - accuracy: 0.7245 - val_loss: 0.7333 - val_accuracy: 0.7331\n",
      "Epoch 7/1000\n",
      "225/225 [==============================] - 0s 2ms/step - loss: 0.7115 - accuracy: 0.7301 - val_loss: 0.6948 - val_accuracy: 0.7418\n",
      "Epoch 8/1000\n",
      "225/225 [==============================] - 0s 2ms/step - loss: 0.6981 - accuracy: 0.7327 - val_loss: 0.6674 - val_accuracy: 0.7384\n",
      "Epoch 9/1000\n",
      "225/225 [==============================] - 0s 2ms/step - loss: 0.6821 - accuracy: 0.7384 - val_loss: 0.6599 - val_accuracy: 0.7447\n",
      "Epoch 10/1000\n",
      "225/225 [==============================] - 0s 2ms/step - loss: 0.6663 - accuracy: 0.7447 - val_loss: 0.6440 - val_accuracy: 0.7493\n",
      "Epoch 11/1000\n",
      "225/225 [==============================] - 0s 2ms/step - loss: 0.6601 - accuracy: 0.7458 - val_loss: 0.6562 - val_accuracy: 0.7476\n",
      "Epoch 12/1000\n",
      "225/225 [==============================] - 0s 2ms/step - loss: 0.6674 - accuracy: 0.7437 - val_loss: 0.6798 - val_accuracy: 0.7457\n",
      "Epoch 13/1000\n",
      "225/225 [==============================] - 0s 2ms/step - loss: 0.6812 - accuracy: 0.7386 - val_loss: 0.6864 - val_accuracy: 0.7287\n",
      "Epoch 14/1000\n",
      "225/225 [==============================] - 0s 2ms/step - loss: 0.6979 - accuracy: 0.7346 - val_loss: 0.6821 - val_accuracy: 0.7427\n",
      "Epoch 15/1000\n",
      "225/225 [==============================] - 0s 2ms/step - loss: 0.7210 - accuracy: 0.7296 - val_loss: 0.6936 - val_accuracy: 0.7348\n",
      "Epoch 16/1000\n",
      "225/225 [==============================] - 0s 2ms/step - loss: 0.7294 - accuracy: 0.7272 - val_loss: 0.7254 - val_accuracy: 0.7388\n",
      "Epoch 17/1000\n",
      "225/225 [==============================] - 0s 2ms/step - loss: 0.7234 - accuracy: 0.7256 - val_loss: 0.6856 - val_accuracy: 0.7360\n",
      "Epoch 18/1000\n",
      "225/225 [==============================] - 0s 2ms/step - loss: 0.7082 - accuracy: 0.7318 - val_loss: 0.6935 - val_accuracy: 0.7377\n",
      "Epoch 19/1000\n",
      "225/225 [==============================] - 0s 2ms/step - loss: 0.6959 - accuracy: 0.7356 - val_loss: 0.6784 - val_accuracy: 0.7409\n",
      "Epoch 20/1000\n",
      "225/225 [==============================] - 0s 2ms/step - loss: 0.6846 - accuracy: 0.7394 - val_loss: 0.6634 - val_accuracy: 0.7443\n",
      "Epoch 21/1000\n",
      "225/225 [==============================] - 0s 2ms/step - loss: 0.6788 - accuracy: 0.7410 - val_loss: 0.6624 - val_accuracy: 0.7456\n",
      "Epoch 22/1000\n",
      "225/225 [==============================] - 0s 2ms/step - loss: 0.6816 - accuracy: 0.7417 - val_loss: 0.6728 - val_accuracy: 0.7423\n",
      "Epoch 23/1000\n",
      "225/225 [==============================] - 1s 2ms/step - loss: 0.6937 - accuracy: 0.7384 - val_loss: 0.6788 - val_accuracy: 0.7415\n",
      "Epoch 24/1000\n",
      "225/225 [==============================] - 0s 2ms/step - loss: 0.7126 - accuracy: 0.7325 - val_loss: 0.6860 - val_accuracy: 0.7390\n",
      "Epoch 25/1000\n",
      "225/225 [==============================] - 0s 2ms/step - loss: 0.7302 - accuracy: 0.7274 - val_loss: 0.7044 - val_accuracy: 0.7260\n",
      "Epoch 26/1000\n",
      "225/225 [==============================] - 0s 2ms/step - loss: 0.7525 - accuracy: 0.7168 - val_loss: 0.6908 - val_accuracy: 0.7358\n",
      "Epoch 27/1000\n",
      "225/225 [==============================] - 0s 2ms/step - loss: 0.7371 - accuracy: 0.7226 - val_loss: 0.7206 - val_accuracy: 0.7324\n",
      "Epoch 28/1000\n",
      "225/225 [==============================] - 0s 2ms/step - loss: 0.7203 - accuracy: 0.7279 - val_loss: 0.6814 - val_accuracy: 0.7319\n",
      "Epoch 29/1000\n",
      "225/225 [==============================] - 0s 2ms/step - loss: 0.7059 - accuracy: 0.7287 - val_loss: 0.6693 - val_accuracy: 0.7397\n",
      "Epoch 30/1000\n",
      "225/225 [==============================] - 0s 2ms/step - loss: 0.6907 - accuracy: 0.7345 - val_loss: 0.6653 - val_accuracy: 0.7461\n",
      "Epoch 31/1000\n",
      "225/225 [==============================] - 0s 2ms/step - loss: 0.6909 - accuracy: 0.7340 - val_loss: 0.6835 - val_accuracy: 0.7382\n",
      "Epoch 32/1000\n",
      "225/225 [==============================] - 0s 2ms/step - loss: 0.7032 - accuracy: 0.7297 - val_loss: 0.6661 - val_accuracy: 0.7470\n",
      "Epoch 33/1000\n",
      "225/225 [==============================] - 0s 2ms/step - loss: 0.7007 - accuracy: 0.7340 - val_loss: 0.6910 - val_accuracy: 0.7299\n",
      "Epoch 34/1000\n",
      "225/225 [==============================] - 0s 2ms/step - loss: 0.7300 - accuracy: 0.7210 - val_loss: 0.7025 - val_accuracy: 0.7367\n",
      "Epoch 35/1000\n",
      "225/225 [==============================] - 0s 2ms/step - loss: 0.7470 - accuracy: 0.7154 - val_loss: 0.7268 - val_accuracy: 0.7343\n",
      "Epoch 36/1000\n",
      "225/225 [==============================] - 0s 2ms/step - loss: 0.7507 - accuracy: 0.7149 - val_loss: 0.8358 - val_accuracy: 0.6337\n",
      "Epoch 37/1000\n",
      "225/225 [==============================] - 0s 2ms/step - loss: 0.7388 - accuracy: 0.7165 - val_loss: 0.6674 - val_accuracy: 0.7400\n",
      "Epoch 38/1000\n",
      "225/225 [==============================] - 0s 2ms/step - loss: 0.7042 - accuracy: 0.7341 - val_loss: 0.6730 - val_accuracy: 0.7410\n",
      "Epoch 39/1000\n",
      "225/225 [==============================] - 0s 2ms/step - loss: 0.6975 - accuracy: 0.7361 - val_loss: 0.6695 - val_accuracy: 0.7443\n",
      "Epoch 40/1000\n",
      "225/225 [==============================] - 0s 2ms/step - loss: 0.6847 - accuracy: 0.7384 - val_loss: 0.6626 - val_accuracy: 0.7455\n",
      "Epoch 41/1000\n",
      "225/225 [==============================] - 1s 2ms/step - loss: 0.6828 - accuracy: 0.7395 - val_loss: 0.6639 - val_accuracy: 0.7466\n",
      "Epoch 42/1000\n",
      "225/225 [==============================] - 0s 2ms/step - loss: 0.6885 - accuracy: 0.7391 - val_loss: 0.6746 - val_accuracy: 0.7479\n",
      "Epoch 43/1000\n",
      "225/225 [==============================] - 0s 2ms/step - loss: 0.6996 - accuracy: 0.7355 - val_loss: 0.7028 - val_accuracy: 0.7410\n",
      "Epoch 44/1000\n",
      "225/225 [==============================] - 0s 2ms/step - loss: 0.7271 - accuracy: 0.7245 - val_loss: 0.6699 - val_accuracy: 0.7427\n",
      "Epoch 45/1000\n",
      "225/225 [==============================] - 0s 2ms/step - loss: 0.7572 - accuracy: 0.7151 - val_loss: 0.6961 - val_accuracy: 0.7386\n",
      "Epoch 46/1000\n",
      "225/225 [==============================] - 0s 2ms/step - loss: 0.7654 - accuracy: 0.7121 - val_loss: 0.7613 - val_accuracy: 0.7324\n",
      "Epoch 47/1000\n",
      "225/225 [==============================] - 0s 2ms/step - loss: 0.7257 - accuracy: 0.7302 - val_loss: 0.7111 - val_accuracy: 0.7373\n",
      "Epoch 48/1000\n",
      "225/225 [==============================] - 0s 2ms/step - loss: 0.7111 - accuracy: 0.7350 - val_loss: 0.6861 - val_accuracy: 0.7410\n",
      "Epoch 49/1000\n",
      "225/225 [==============================] - 0s 2ms/step - loss: 0.6967 - accuracy: 0.7384 - val_loss: 0.6676 - val_accuracy: 0.7428\n",
      "Epoch 50/1000\n",
      "225/225 [==============================] - 0s 2ms/step - loss: 0.6822 - accuracy: 0.7410 - val_loss: 0.6561 - val_accuracy: 0.7452\n",
      "Epoch 51/1000\n",
      "225/225 [==============================] - 0s 2ms/step - loss: 0.6779 - accuracy: 0.7426 - val_loss: 0.6866 - val_accuracy: 0.7434\n",
      "Epoch 52/1000\n",
      "225/225 [==============================] - 0s 2ms/step - loss: 0.6871 - accuracy: 0.7422 - val_loss: 0.6753 - val_accuracy: 0.7424\n",
      "Epoch 53/1000\n",
      "225/225 [==============================] - 0s 2ms/step - loss: 0.7035 - accuracy: 0.7370 - val_loss: 0.7069 - val_accuracy: 0.7458\n",
      "Epoch 54/1000\n",
      "225/225 [==============================] - 0s 2ms/step - loss: 0.7444 - accuracy: 0.7232 - val_loss: 0.7256 - val_accuracy: 0.7295\n",
      "Epoch 55/1000\n",
      "225/225 [==============================] - 0s 2ms/step - loss: 0.7608 - accuracy: 0.7168 - val_loss: 0.7324 - val_accuracy: 0.7280\n",
      "Epoch 56/1000\n",
      "225/225 [==============================] - 0s 2ms/step - loss: 0.7489 - accuracy: 0.7164 - val_loss: 0.7136 - val_accuracy: 0.7302\n",
      "Epoch 57/1000\n",
      "225/225 [==============================] - 0s 2ms/step - loss: 0.7444 - accuracy: 0.7170 - val_loss: 0.6887 - val_accuracy: 0.7209\n",
      "Epoch 58/1000\n",
      "225/225 [==============================] - 0s 2ms/step - loss: 0.7309 - accuracy: 0.7174 - val_loss: 0.6853 - val_accuracy: 0.7376\n",
      "Epoch 59/1000\n",
      "225/225 [==============================] - 0s 2ms/step - loss: 0.7050 - accuracy: 0.7338 - val_loss: 0.6778 - val_accuracy: 0.7449\n",
      "Epoch 60/1000\n",
      "225/225 [==============================] - 0s 2ms/step - loss: 0.6991 - accuracy: 0.7347 - val_loss: 0.6625 - val_accuracy: 0.7447\n",
      "Epoch 61/1000\n",
      "225/225 [==============================] - 0s 2ms/step - loss: 0.6935 - accuracy: 0.7372 - val_loss: 0.6608 - val_accuracy: 0.7480\n",
      "Epoch 62/1000\n",
      "225/225 [==============================] - 0s 2ms/step - loss: 0.6995 - accuracy: 0.7346 - val_loss: 0.6667 - val_accuracy: 0.7446\n",
      "Epoch 63/1000\n",
      "225/225 [==============================] - 0s 2ms/step - loss: 0.7060 - accuracy: 0.7351 - val_loss: 0.6608 - val_accuracy: 0.7480\n",
      "Epoch 64/1000\n",
      "225/225 [==============================] - 0s 2ms/step - loss: 0.7191 - accuracy: 0.7299 - val_loss: 0.6772 - val_accuracy: 0.7364\n",
      "Epoch 65/1000\n",
      "225/225 [==============================] - 0s 2ms/step - loss: 0.7556 - accuracy: 0.7172 - val_loss: 0.6862 - val_accuracy: 0.7364\n",
      "Epoch 66/1000\n",
      "225/225 [==============================] - 0s 2ms/step - loss: 0.7911 - accuracy: 0.6927 - val_loss: 0.7061 - val_accuracy: 0.7310\n",
      "Epoch 67/1000\n",
      "225/225 [==============================] - 0s 2ms/step - loss: 0.7355 - accuracy: 0.7242 - val_loss: 0.7060 - val_accuracy: 0.7346\n",
      "Epoch 68/1000\n",
      "225/225 [==============================] - 0s 2ms/step - loss: 0.7204 - accuracy: 0.7307 - val_loss: 0.6925 - val_accuracy: 0.7378\n",
      "Epoch 69/1000\n",
      "225/225 [==============================] - 0s 2ms/step - loss: 0.7142 - accuracy: 0.7314 - val_loss: 0.6721 - val_accuracy: 0.7415\n",
      "Epoch 70/1000\n",
      "225/225 [==============================] - 0s 2ms/step - loss: 0.7129 - accuracy: 0.7295 - val_loss: 0.6866 - val_accuracy: 0.7353\n",
      "Epoch 71/1000\n",
      "225/225 [==============================] - 0s 2ms/step - loss: 0.7103 - accuracy: 0.7293 - val_loss: 0.6738 - val_accuracy: 0.7384\n",
      "Epoch 72/1000\n",
      "225/225 [==============================] - 0s 2ms/step - loss: 0.7109 - accuracy: 0.7288 - val_loss: 0.7176 - val_accuracy: 0.7273\n",
      "Epoch 73/1000\n",
      "225/225 [==============================] - 0s 2ms/step - loss: 0.7298 - accuracy: 0.7209 - val_loss: 0.6936 - val_accuracy: 0.7401\n",
      "Epoch 74/1000\n",
      "225/225 [==============================] - 0s 2ms/step - loss: 0.7644 - accuracy: 0.6967 - val_loss: 0.7775 - val_accuracy: 0.5945\n",
      "Epoch 75/1000\n",
      "225/225 [==============================] - 0s 2ms/step - loss: 0.7744 - accuracy: 0.6861 - val_loss: 0.7091 - val_accuracy: 0.7352\n",
      "Epoch 76/1000\n",
      "225/225 [==============================] - 0s 2ms/step - loss: 0.7676 - accuracy: 0.6941 - val_loss: 0.7182 - val_accuracy: 0.7221\n",
      "Epoch 77/1000\n",
      "225/225 [==============================] - 0s 2ms/step - loss: 0.7505 - accuracy: 0.7045 - val_loss: 0.6820 - val_accuracy: 0.7347\n",
      "Epoch 78/1000\n",
      "225/225 [==============================] - 0s 2ms/step - loss: 0.7385 - accuracy: 0.7108 - val_loss: 0.6943 - val_accuracy: 0.7439\n",
      "Epoch 79/1000\n",
      "225/225 [==============================] - 0s 2ms/step - loss: 0.7137 - accuracy: 0.7264 - val_loss: 0.6619 - val_accuracy: 0.7456\n",
      "Epoch 80/1000\n",
      "225/225 [==============================] - 0s 2ms/step - loss: 0.7055 - accuracy: 0.7313 - val_loss: 0.6628 - val_accuracy: 0.7460\n",
      "Epoch 81/1000\n",
      "225/225 [==============================] - 0s 2ms/step - loss: 0.6984 - accuracy: 0.7315 - val_loss: 0.7054 - val_accuracy: 0.7470\n",
      "Epoch 82/1000\n",
      "225/225 [==============================] - 0s 2ms/step - loss: 0.7068 - accuracy: 0.7300 - val_loss: 0.7082 - val_accuracy: 0.7448\n",
      "Epoch 83/1000\n",
      "225/225 [==============================] - 0s 2ms/step - loss: 0.7327 - accuracy: 0.7180 - val_loss: 0.7285 - val_accuracy: 0.7288\n",
      "Epoch 84/1000\n",
      "225/225 [==============================] - 0s 2ms/step - loss: 0.7373 - accuracy: 0.7174 - val_loss: 0.7129 - val_accuracy: 0.7337\n",
      "Epoch 85/1000\n",
      "225/225 [==============================] - 0s 2ms/step - loss: 0.7648 - accuracy: 0.7103 - val_loss: 0.7431 - val_accuracy: 0.7336\n",
      "Epoch 86/1000\n",
      "225/225 [==============================] - 0s 2ms/step - loss: 0.7935 - accuracy: 0.6934 - val_loss: 0.7547 - val_accuracy: 0.7238\n",
      "Epoch 87/1000\n",
      "225/225 [==============================] - 0s 2ms/step - loss: 0.7819 - accuracy: 0.7064 - val_loss: 0.7224 - val_accuracy: 0.7248\n",
      "Epoch 88/1000\n",
      "225/225 [==============================] - 0s 2ms/step - loss: 0.7576 - accuracy: 0.7142 - val_loss: 0.7168 - val_accuracy: 0.7360\n",
      "Epoch 89/1000\n",
      "225/225 [==============================] - 0s 2ms/step - loss: 0.7394 - accuracy: 0.7204 - val_loss: 0.6983 - val_accuracy: 0.7402\n",
      "Epoch 90/1000\n",
      "225/225 [==============================] - 0s 2ms/step - loss: 0.7291 - accuracy: 0.7240 - val_loss: 0.6844 - val_accuracy: 0.7430\n",
      "Epoch 91/1000\n",
      "225/225 [==============================] - 0s 2ms/step - loss: 0.7253 - accuracy: 0.7238 - val_loss: 0.6828 - val_accuracy: 0.7435\n",
      "Epoch 92/1000\n",
      "225/225 [==============================] - 0s 2ms/step - loss: 0.7168 - accuracy: 0.7304 - val_loss: 0.6762 - val_accuracy: 0.7446\n",
      "Epoch 93/1000\n",
      "225/225 [==============================] - 0s 2ms/step - loss: 0.7193 - accuracy: 0.7296 - val_loss: 0.7347 - val_accuracy: 0.7343\n",
      "Epoch 94/1000\n",
      "225/225 [==============================] - 0s 2ms/step - loss: 0.7473 - accuracy: 0.7183 - val_loss: 0.7681 - val_accuracy: 0.7255\n",
      "Epoch 95/1000\n",
      "225/225 [==============================] - 0s 2ms/step - loss: 0.7518 - accuracy: 0.7205 - val_loss: 0.7515 - val_accuracy: 0.7134\n",
      "Epoch 96/1000\n",
      "225/225 [==============================] - 0s 2ms/step - loss: 0.7788 - accuracy: 0.6974 - val_loss: 0.7158 - val_accuracy: 0.7237\n",
      "Epoch 97/1000\n",
      "225/225 [==============================] - 0s 2ms/step - loss: 0.7685 - accuracy: 0.7031 - val_loss: 0.7303 - val_accuracy: 0.7255\n",
      "Epoch 98/1000\n",
      "225/225 [==============================] - 0s 2ms/step - loss: 0.7594 - accuracy: 0.7062 - val_loss: 0.7088 - val_accuracy: 0.7288\n",
      "Epoch 99/1000\n",
      "225/225 [==============================] - 0s 2ms/step - loss: 0.7319 - accuracy: 0.7213 - val_loss: 0.6920 - val_accuracy: 0.7434\n",
      "Epoch 100/1000\n",
      "225/225 [==============================] - 0s 2ms/step - loss: 0.7227 - accuracy: 0.7246 - val_loss: 0.6876 - val_accuracy: 0.7435\n",
      "Epoch 100: early stopping\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "<keras.src.callbacks.History at 0x1403ddf30>"
      ]
     },
     "execution_count": 195,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "model=Sequential()\n",
    "model.add(Dense(128, input_dim=X_train.shape[1], activation=\"relu\"))\n",
    "\n",
    "model.add(Dense(128, activation=\"relu\"))\n",
    "model.add(Dropout(0.2))\n",
    "model.add(Dense(64, activation=\"relu\"))\n",
    "\n",
    "model.add(Dense(64, activation=\"relu\"))\n",
    "model.add(Dropout(0.2))\n",
    "model.add(Dense(32, activation=\"relu\"))\n",
    "model.add(Dropout(0.2))\n",
    "model.add(Dense(16, activation=\"relu\"))\n",
    "model.add(Dropout(0.2))\n",
    "model.add(Dense(3, activation=\"softmax\"))\n",
    "\n",
    "model.compile(loss='categorical_crossentropy', optimizer='rmsprop', metrics=['accuracy'])\n",
    "\n",
    "es=EarlyStopping(monitor=\"val_loss\",patience=90,mode=\"auto\",verbose=1)\n",
    "clr = CyclicLR(base_lr=0.001, max_lr=0.02,\n",
    "                                step_size=1125., mode='triangular')\n",
    "model.fit(X_train,\n",
    "          y_train,\n",
    "          epochs=1000,\n",
    "               batch_size=512,\n",
    "               validation_split=0.1,\n",
    "               verbose=1,callbacks=[es, clr])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 196,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "997/997 [==============================] - 0s 259us/step\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0       0.73      0.86      0.79     10867\n",
      "           1       0.74      0.79      0.77     10432\n",
      "           2       0.76      0.57      0.65     10591\n",
      "\n",
      "    accuracy                           0.74     31890\n",
      "   macro avg       0.74      0.74      0.74     31890\n",
      "weighted avg       0.74      0.74      0.74     31890\n",
      "\n"
     ]
    }
   ],
   "source": [
    "y_pred = model.predict(X_test)\n",
    "y_pred_classes = np.argmax(y_pred, axis=1)\n",
    "y_true = np.argmax(y_test, axis=1)\n",
    "print(classification_report(y_true, y_pred_classes))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 197,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "3987/3987 [==============================] - 1s 253us/step\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0       0.73      0.86      0.79     42282\n",
      "           1       0.75      0.79      0.77     42717\n",
      "           2       0.76      0.58      0.65     42558\n",
      "\n",
      "    accuracy                           0.74    127557\n",
      "   macro avg       0.75      0.74      0.74    127557\n",
      "weighted avg       0.75      0.74      0.74    127557\n",
      "\n"
     ]
    }
   ],
   "source": [
    "y_t_pred = model.predict(X_train)\n",
    "y_t_pred_classes = np.argmax(y_t_pred, axis=1)\n",
    "y_t_true = np.argmax(y_train, axis=1)\n",
    "print(classification_report(y_t_true, y_t_pred_classes))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 203,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 1/1000\n",
      "225/225 [==============================] - 1s 2ms/step - loss: 0.7723 - accuracy: 0.6998 - val_loss: 0.6889 - val_accuracy: 0.7320\n",
      "Epoch 2/1000\n",
      "225/225 [==============================] - 0s 2ms/step - loss: 0.7064 - accuracy: 0.7327 - val_loss: 0.6677 - val_accuracy: 0.7406\n",
      "Epoch 3/1000\n",
      "225/225 [==============================] - 0s 2ms/step - loss: 0.6873 - accuracy: 0.7387 - val_loss: 0.6586 - val_accuracy: 0.7396\n",
      "Epoch 4/1000\n",
      "225/225 [==============================] - 0s 2ms/step - loss: 0.6762 - accuracy: 0.7423 - val_loss: 0.6499 - val_accuracy: 0.7472\n",
      "Epoch 5/1000\n",
      "225/225 [==============================] - 0s 2ms/step - loss: 0.6654 - accuracy: 0.7460 - val_loss: 0.6350 - val_accuracy: 0.7510\n",
      "Epoch 6/1000\n",
      "225/225 [==============================] - 0s 2ms/step - loss: 0.6562 - accuracy: 0.7485 - val_loss: 0.6288 - val_accuracy: 0.7518\n",
      "Epoch 7/1000\n",
      "225/225 [==============================] - 0s 2ms/step - loss: 0.6463 - accuracy: 0.7520 - val_loss: 0.6407 - val_accuracy: 0.7513\n",
      "Epoch 8/1000\n",
      "225/225 [==============================] - 0s 2ms/step - loss: 0.6380 - accuracy: 0.7550 - val_loss: 0.6108 - val_accuracy: 0.7593\n",
      "Epoch 9/1000\n",
      "225/225 [==============================] - 0s 2ms/step - loss: 0.6303 - accuracy: 0.7574 - val_loss: 0.6054 - val_accuracy: 0.7638\n",
      "Epoch 10/1000\n",
      "225/225 [==============================] - 0s 2ms/step - loss: 0.6241 - accuracy: 0.7593 - val_loss: 0.6095 - val_accuracy: 0.7614\n",
      "Epoch 11/1000\n",
      "225/225 [==============================] - 0s 2ms/step - loss: 0.6173 - accuracy: 0.7612 - val_loss: 0.6149 - val_accuracy: 0.7592\n",
      "Epoch 12/1000\n",
      "225/225 [==============================] - 0s 2ms/step - loss: 0.6097 - accuracy: 0.7637 - val_loss: 0.5976 - val_accuracy: 0.7647\n",
      "Epoch 13/1000\n",
      "225/225 [==============================] - 0s 2ms/step - loss: 0.6060 - accuracy: 0.7653 - val_loss: 0.5901 - val_accuracy: 0.7686\n",
      "Epoch 14/1000\n",
      "225/225 [==============================] - 0s 2ms/step - loss: 0.5982 - accuracy: 0.7687 - val_loss: 0.5829 - val_accuracy: 0.7705\n",
      "Epoch 15/1000\n",
      "225/225 [==============================] - 0s 2ms/step - loss: 0.5923 - accuracy: 0.7708 - val_loss: 0.5783 - val_accuracy: 0.7720\n",
      "Epoch 16/1000\n",
      "225/225 [==============================] - 0s 2ms/step - loss: 0.5873 - accuracy: 0.7719 - val_loss: 0.5750 - val_accuracy: 0.7744\n",
      "Epoch 17/1000\n",
      "225/225 [==============================] - 0s 2ms/step - loss: 0.5817 - accuracy: 0.7737 - val_loss: 0.5748 - val_accuracy: 0.7741\n",
      "Epoch 18/1000\n",
      "225/225 [==============================] - 0s 2ms/step - loss: 0.5779 - accuracy: 0.7759 - val_loss: 0.5622 - val_accuracy: 0.7804\n",
      "Epoch 19/1000\n",
      "225/225 [==============================] - 0s 2ms/step - loss: 0.5722 - accuracy: 0.7768 - val_loss: 0.5577 - val_accuracy: 0.7822\n",
      "Epoch 20/1000\n",
      "225/225 [==============================] - 0s 2ms/step - loss: 0.5678 - accuracy: 0.7795 - val_loss: 0.5596 - val_accuracy: 0.7806\n",
      "Epoch 21/1000\n",
      "225/225 [==============================] - 0s 2ms/step - loss: 0.5634 - accuracy: 0.7814 - val_loss: 0.5626 - val_accuracy: 0.7788\n",
      "Epoch 22/1000\n",
      "225/225 [==============================] - 0s 2ms/step - loss: 0.5609 - accuracy: 0.7820 - val_loss: 0.5474 - val_accuracy: 0.7854\n",
      "Epoch 23/1000\n",
      "225/225 [==============================] - 0s 2ms/step - loss: 0.5560 - accuracy: 0.7850 - val_loss: 0.5451 - val_accuracy: 0.7877\n",
      "Epoch 24/1000\n",
      "225/225 [==============================] - 0s 2ms/step - loss: 0.5531 - accuracy: 0.7874 - val_loss: 0.5477 - val_accuracy: 0.7823\n",
      "Epoch 25/1000\n",
      "225/225 [==============================] - 0s 2ms/step - loss: 0.5479 - accuracy: 0.7869 - val_loss: 0.5427 - val_accuracy: 0.7874\n",
      "Epoch 26/1000\n",
      "225/225 [==============================] - 1s 2ms/step - loss: 0.5450 - accuracy: 0.7883 - val_loss: 0.5375 - val_accuracy: 0.7902\n",
      "Epoch 27/1000\n",
      "225/225 [==============================] - 0s 2ms/step - loss: 0.5402 - accuracy: 0.7903 - val_loss: 0.5348 - val_accuracy: 0.7921\n",
      "Epoch 28/1000\n",
      "225/225 [==============================] - 0s 2ms/step - loss: 0.5382 - accuracy: 0.7908 - val_loss: 0.5449 - val_accuracy: 0.7865\n",
      "Epoch 29/1000\n",
      "225/225 [==============================] - 0s 2ms/step - loss: 0.5342 - accuracy: 0.7922 - val_loss: 0.5262 - val_accuracy: 0.7917\n",
      "Epoch 30/1000\n",
      "225/225 [==============================] - 0s 2ms/step - loss: 0.5327 - accuracy: 0.7942 - val_loss: 0.5254 - val_accuracy: 0.7946\n",
      "Epoch 31/1000\n",
      "225/225 [==============================] - 0s 2ms/step - loss: 0.5309 - accuracy: 0.7947 - val_loss: 0.5253 - val_accuracy: 0.7949\n",
      "Epoch 32/1000\n",
      "225/225 [==============================] - 0s 2ms/step - loss: 0.5271 - accuracy: 0.7968 - val_loss: 0.5309 - val_accuracy: 0.7929\n",
      "Epoch 33/1000\n",
      "225/225 [==============================] - 0s 2ms/step - loss: 0.5259 - accuracy: 0.7969 - val_loss: 0.5284 - val_accuracy: 0.7937\n",
      "Epoch 34/1000\n",
      "225/225 [==============================] - 0s 2ms/step - loss: 0.5217 - accuracy: 0.7981 - val_loss: 0.5226 - val_accuracy: 0.7968\n",
      "Epoch 35/1000\n",
      "225/225 [==============================] - 0s 2ms/step - loss: 0.5198 - accuracy: 0.7998 - val_loss: 0.5228 - val_accuracy: 0.7966\n",
      "Epoch 36/1000\n",
      "225/225 [==============================] - 0s 2ms/step - loss: 0.5189 - accuracy: 0.7990 - val_loss: 0.5095 - val_accuracy: 0.8023\n",
      "Epoch 37/1000\n",
      "225/225 [==============================] - 0s 2ms/step - loss: 0.5144 - accuracy: 0.8009 - val_loss: 0.5156 - val_accuracy: 0.7980\n",
      "Epoch 38/1000\n",
      "225/225 [==============================] - 0s 2ms/step - loss: 0.5122 - accuracy: 0.8010 - val_loss: 0.5107 - val_accuracy: 0.7997\n",
      "Epoch 39/1000\n",
      "225/225 [==============================] - 0s 2ms/step - loss: 0.5106 - accuracy: 0.8025 - val_loss: 0.5114 - val_accuracy: 0.7995\n",
      "Epoch 40/1000\n",
      "225/225 [==============================] - 0s 2ms/step - loss: 0.5080 - accuracy: 0.8033 - val_loss: 0.5069 - val_accuracy: 0.8030\n",
      "Epoch 41/1000\n",
      "225/225 [==============================] - 0s 2ms/step - loss: 0.5047 - accuracy: 0.8044 - val_loss: 0.5038 - val_accuracy: 0.8005\n",
      "Epoch 42/1000\n",
      "225/225 [==============================] - 0s 2ms/step - loss: 0.5046 - accuracy: 0.8047 - val_loss: 0.5008 - val_accuracy: 0.8061\n",
      "Epoch 43/1000\n",
      "225/225 [==============================] - 0s 2ms/step - loss: 0.5016 - accuracy: 0.8058 - val_loss: 0.4955 - val_accuracy: 0.8035\n",
      "Epoch 44/1000\n",
      "225/225 [==============================] - 0s 2ms/step - loss: 0.5004 - accuracy: 0.8078 - val_loss: 0.5118 - val_accuracy: 0.8015\n",
      "Epoch 45/1000\n",
      "225/225 [==============================] - 0s 2ms/step - loss: 0.4971 - accuracy: 0.8080 - val_loss: 0.5086 - val_accuracy: 0.8029\n",
      "Epoch 46/1000\n",
      "225/225 [==============================] - 0s 2ms/step - loss: 0.4960 - accuracy: 0.8072 - val_loss: 0.5092 - val_accuracy: 0.8016\n",
      "Epoch 47/1000\n",
      "225/225 [==============================] - 0s 2ms/step - loss: 0.4949 - accuracy: 0.8089 - val_loss: 0.5048 - val_accuracy: 0.8013\n",
      "Epoch 48/1000\n",
      "225/225 [==============================] - 0s 2ms/step - loss: 0.4921 - accuracy: 0.8097 - val_loss: 0.4955 - val_accuracy: 0.8106\n",
      "Epoch 49/1000\n",
      "225/225 [==============================] - 0s 2ms/step - loss: 0.4912 - accuracy: 0.8101 - val_loss: 0.4890 - val_accuracy: 0.8109\n",
      "Epoch 50/1000\n",
      "225/225 [==============================] - 0s 2ms/step - loss: 0.4898 - accuracy: 0.8115 - val_loss: 0.4884 - val_accuracy: 0.8118\n",
      "Epoch 51/1000\n",
      "225/225 [==============================] - 0s 2ms/step - loss: 0.4892 - accuracy: 0.8120 - val_loss: 0.4908 - val_accuracy: 0.8132\n",
      "Epoch 52/1000\n",
      "225/225 [==============================] - 0s 2ms/step - loss: 0.4875 - accuracy: 0.8114 - val_loss: 0.4869 - val_accuracy: 0.8094\n",
      "Epoch 53/1000\n",
      "225/225 [==============================] - 0s 2ms/step - loss: 0.4855 - accuracy: 0.8128 - val_loss: 0.4925 - val_accuracy: 0.8079\n",
      "Epoch 54/1000\n",
      "225/225 [==============================] - 0s 2ms/step - loss: 0.4861 - accuracy: 0.8143 - val_loss: 0.4881 - val_accuracy: 0.8130\n",
      "Epoch 55/1000\n",
      "225/225 [==============================] - 0s 2ms/step - loss: 0.4817 - accuracy: 0.8152 - val_loss: 0.4838 - val_accuracy: 0.8136\n",
      "Epoch 56/1000\n",
      "225/225 [==============================] - 1s 2ms/step - loss: 0.4811 - accuracy: 0.8158 - val_loss: 0.4865 - val_accuracy: 0.8142\n",
      "Epoch 57/1000\n",
      "225/225 [==============================] - 0s 2ms/step - loss: 0.4793 - accuracy: 0.8155 - val_loss: 0.4831 - val_accuracy: 0.8133\n",
      "Epoch 58/1000\n",
      "225/225 [==============================] - 0s 2ms/step - loss: 0.4772 - accuracy: 0.8164 - val_loss: 0.4832 - val_accuracy: 0.8166\n",
      "Epoch 59/1000\n",
      "225/225 [==============================] - 0s 2ms/step - loss: 0.4769 - accuracy: 0.8169 - val_loss: 0.4909 - val_accuracy: 0.8112\n",
      "Epoch 60/1000\n",
      "225/225 [==============================] - 0s 2ms/step - loss: 0.4766 - accuracy: 0.8171 - val_loss: 0.4831 - val_accuracy: 0.8145\n",
      "Epoch 61/1000\n",
      "225/225 [==============================] - 0s 2ms/step - loss: 0.4750 - accuracy: 0.8174 - val_loss: 0.4772 - val_accuracy: 0.8181\n",
      "Epoch 62/1000\n",
      "225/225 [==============================] - 0s 2ms/step - loss: 0.4721 - accuracy: 0.8191 - val_loss: 0.4805 - val_accuracy: 0.8157\n",
      "Epoch 63/1000\n",
      "225/225 [==============================] - 0s 2ms/step - loss: 0.4726 - accuracy: 0.8180 - val_loss: 0.4868 - val_accuracy: 0.8149\n",
      "Epoch 64/1000\n",
      "225/225 [==============================] - 0s 2ms/step - loss: 0.4680 - accuracy: 0.8209 - val_loss: 0.4755 - val_accuracy: 0.8179\n",
      "Epoch 65/1000\n",
      "225/225 [==============================] - 0s 2ms/step - loss: 0.4717 - accuracy: 0.8194 - val_loss: 0.4762 - val_accuracy: 0.8167\n",
      "Epoch 66/1000\n",
      "225/225 [==============================] - 0s 2ms/step - loss: 0.4692 - accuracy: 0.8201 - val_loss: 0.4781 - val_accuracy: 0.8209\n",
      "Epoch 67/1000\n",
      "225/225 [==============================] - 0s 2ms/step - loss: 0.4684 - accuracy: 0.8211 - val_loss: 0.4840 - val_accuracy: 0.8172\n",
      "Epoch 68/1000\n",
      "225/225 [==============================] - 0s 2ms/step - loss: 0.4690 - accuracy: 0.8200 - val_loss: 0.4737 - val_accuracy: 0.8234\n",
      "Epoch 69/1000\n",
      "225/225 [==============================] - 0s 2ms/step - loss: 0.4683 - accuracy: 0.8218 - val_loss: 0.4741 - val_accuracy: 0.8216\n",
      "Epoch 70/1000\n",
      "225/225 [==============================] - 0s 2ms/step - loss: 0.4656 - accuracy: 0.8220 - val_loss: 0.4715 - val_accuracy: 0.8229\n",
      "Epoch 71/1000\n",
      "225/225 [==============================] - 0s 2ms/step - loss: 0.4635 - accuracy: 0.8238 - val_loss: 0.4841 - val_accuracy: 0.8196\n",
      "Epoch 72/1000\n",
      "225/225 [==============================] - 0s 2ms/step - loss: 0.4637 - accuracy: 0.8229 - val_loss: 0.4766 - val_accuracy: 0.8181\n",
      "Epoch 73/1000\n",
      "225/225 [==============================] - 0s 2ms/step - loss: 0.4658 - accuracy: 0.8213 - val_loss: 0.4724 - val_accuracy: 0.8187\n",
      "Epoch 74/1000\n",
      "225/225 [==============================] - 0s 2ms/step - loss: 0.4633 - accuracy: 0.8226 - val_loss: 0.4718 - val_accuracy: 0.8202\n",
      "Epoch 75/1000\n",
      "225/225 [==============================] - 0s 2ms/step - loss: 0.4587 - accuracy: 0.8253 - val_loss: 0.4686 - val_accuracy: 0.8229\n",
      "Epoch 76/1000\n",
      "225/225 [==============================] - 0s 2ms/step - loss: 0.4635 - accuracy: 0.8226 - val_loss: 0.4729 - val_accuracy: 0.8260\n",
      "Epoch 77/1000\n",
      "225/225 [==============================] - 0s 2ms/step - loss: 0.4601 - accuracy: 0.8252 - val_loss: 0.4761 - val_accuracy: 0.8195\n",
      "Epoch 78/1000\n",
      "225/225 [==============================] - 0s 2ms/step - loss: 0.4609 - accuracy: 0.8241 - val_loss: 0.4657 - val_accuracy: 0.8254\n",
      "Epoch 79/1000\n",
      "225/225 [==============================] - 0s 2ms/step - loss: 0.4578 - accuracy: 0.8251 - val_loss: 0.4791 - val_accuracy: 0.8226\n",
      "Epoch 80/1000\n",
      "225/225 [==============================] - 0s 2ms/step - loss: 0.4590 - accuracy: 0.8255 - val_loss: 0.4674 - val_accuracy: 0.8238\n",
      "Epoch 81/1000\n",
      "225/225 [==============================] - 0s 2ms/step - loss: 0.4558 - accuracy: 0.8260 - val_loss: 0.4685 - val_accuracy: 0.8262\n",
      "Epoch 82/1000\n",
      "225/225 [==============================] - 0s 2ms/step - loss: 0.4537 - accuracy: 0.8268 - val_loss: 0.4649 - val_accuracy: 0.8250\n",
      "Epoch 83/1000\n",
      "225/225 [==============================] - 0s 2ms/step - loss: 0.4561 - accuracy: 0.8257 - val_loss: 0.4629 - val_accuracy: 0.8282\n",
      "Epoch 84/1000\n",
      "225/225 [==============================] - 0s 2ms/step - loss: 0.4542 - accuracy: 0.8274 - val_loss: 0.4684 - val_accuracy: 0.8224\n",
      "Epoch 85/1000\n",
      "225/225 [==============================] - 0s 2ms/step - loss: 0.4541 - accuracy: 0.8273 - val_loss: 0.4641 - val_accuracy: 0.8252\n",
      "Epoch 86/1000\n",
      "225/225 [==============================] - 0s 2ms/step - loss: 0.4528 - accuracy: 0.8268 - val_loss: 0.4702 - val_accuracy: 0.8251\n",
      "Epoch 87/1000\n",
      "225/225 [==============================] - 0s 2ms/step - loss: 0.4545 - accuracy: 0.8270 - val_loss: 0.4635 - val_accuracy: 0.8285\n",
      "Epoch 88/1000\n",
      "225/225 [==============================] - 0s 2ms/step - loss: 0.4510 - accuracy: 0.8284 - val_loss: 0.4638 - val_accuracy: 0.8257\n",
      "Epoch 89/1000\n",
      "225/225 [==============================] - 0s 2ms/step - loss: 0.4498 - accuracy: 0.8285 - val_loss: 0.4668 - val_accuracy: 0.8244\n",
      "Epoch 90/1000\n",
      "225/225 [==============================] - 0s 2ms/step - loss: 0.4498 - accuracy: 0.8295 - val_loss: 0.4642 - val_accuracy: 0.8271\n",
      "Epoch 91/1000\n",
      "225/225 [==============================] - 0s 2ms/step - loss: 0.4511 - accuracy: 0.8290 - val_loss: 0.4613 - val_accuracy: 0.8252\n",
      "Epoch 92/1000\n",
      "225/225 [==============================] - 0s 2ms/step - loss: 0.4495 - accuracy: 0.8290 - val_loss: 0.4609 - val_accuracy: 0.8257\n",
      "Epoch 93/1000\n",
      "225/225 [==============================] - 0s 2ms/step - loss: 0.4500 - accuracy: 0.8301 - val_loss: 0.4632 - val_accuracy: 0.8291\n",
      "Epoch 94/1000\n",
      "225/225 [==============================] - 0s 2ms/step - loss: 0.4489 - accuracy: 0.8307 - val_loss: 0.4557 - val_accuracy: 0.8310\n",
      "Epoch 95/1000\n",
      "225/225 [==============================] - 0s 2ms/step - loss: 0.4464 - accuracy: 0.8295 - val_loss: 0.4692 - val_accuracy: 0.8259\n",
      "Epoch 96/1000\n",
      "225/225 [==============================] - 0s 2ms/step - loss: 0.4484 - accuracy: 0.8302 - val_loss: 0.4639 - val_accuracy: 0.8274\n",
      "Epoch 97/1000\n",
      "225/225 [==============================] - 0s 2ms/step - loss: 0.4457 - accuracy: 0.8314 - val_loss: 0.4683 - val_accuracy: 0.8275\n",
      "Epoch 98/1000\n",
      "225/225 [==============================] - 0s 2ms/step - loss: 0.4464 - accuracy: 0.8307 - val_loss: 0.4602 - val_accuracy: 0.8322\n",
      "Epoch 99/1000\n",
      "225/225 [==============================] - 0s 2ms/step - loss: 0.4451 - accuracy: 0.8314 - val_loss: 0.4700 - val_accuracy: 0.8286\n",
      "Epoch 100/1000\n",
      "225/225 [==============================] - 1s 2ms/step - loss: 0.4440 - accuracy: 0.8314 - val_loss: 0.4562 - val_accuracy: 0.8313\n",
      "Epoch 101/1000\n",
      "225/225 [==============================] - 0s 2ms/step - loss: 0.4437 - accuracy: 0.8317 - val_loss: 0.4601 - val_accuracy: 0.8331\n",
      "Epoch 102/1000\n",
      "225/225 [==============================] - 0s 2ms/step - loss: 0.4427 - accuracy: 0.8323 - val_loss: 0.4703 - val_accuracy: 0.8268\n",
      "Epoch 103/1000\n",
      "225/225 [==============================] - 0s 2ms/step - loss: 0.4437 - accuracy: 0.8319 - val_loss: 0.4644 - val_accuracy: 0.8294\n",
      "Epoch 104/1000\n",
      "225/225 [==============================] - 0s 2ms/step - loss: 0.4429 - accuracy: 0.8317 - val_loss: 0.4664 - val_accuracy: 0.8273\n",
      "Epoch 105/1000\n",
      "225/225 [==============================] - 0s 2ms/step - loss: 0.4433 - accuracy: 0.8325 - val_loss: 0.4668 - val_accuracy: 0.8250\n",
      "Epoch 106/1000\n",
      "225/225 [==============================] - 0s 2ms/step - loss: 0.4413 - accuracy: 0.8324 - val_loss: 0.4565 - val_accuracy: 0.8296\n",
      "Epoch 107/1000\n",
      "225/225 [==============================] - 0s 2ms/step - loss: 0.4412 - accuracy: 0.8334 - val_loss: 0.4586 - val_accuracy: 0.8308\n",
      "Epoch 108/1000\n",
      "225/225 [==============================] - 0s 2ms/step - loss: 0.4396 - accuracy: 0.8337 - val_loss: 0.4612 - val_accuracy: 0.8254\n",
      "Epoch 109/1000\n",
      "225/225 [==============================] - 0s 2ms/step - loss: 0.4403 - accuracy: 0.8338 - val_loss: 0.4561 - val_accuracy: 0.8297\n",
      "Epoch 110/1000\n",
      "225/225 [==============================] - 0s 2ms/step - loss: 0.4396 - accuracy: 0.8330 - val_loss: 0.4567 - val_accuracy: 0.8304\n",
      "Epoch 111/1000\n",
      "225/225 [==============================] - 0s 2ms/step - loss: 0.4400 - accuracy: 0.8339 - val_loss: 0.4583 - val_accuracy: 0.8302\n",
      "Epoch 112/1000\n",
      "225/225 [==============================] - 0s 2ms/step - loss: 0.4388 - accuracy: 0.8345 - val_loss: 0.4608 - val_accuracy: 0.8287\n",
      "Epoch 113/1000\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "225/225 [==============================] - 0s 2ms/step - loss: 0.4384 - accuracy: 0.8343 - val_loss: 0.4613 - val_accuracy: 0.8270\n",
      "Epoch 114/1000\n",
      "225/225 [==============================] - 0s 2ms/step - loss: 0.4383 - accuracy: 0.8342 - val_loss: 0.4546 - val_accuracy: 0.8311\n",
      "Epoch 115/1000\n",
      "225/225 [==============================] - 0s 2ms/step - loss: 0.4371 - accuracy: 0.8355 - val_loss: 0.4661 - val_accuracy: 0.8301\n",
      "Epoch 116/1000\n",
      "225/225 [==============================] - 0s 2ms/step - loss: 0.4363 - accuracy: 0.8348 - val_loss: 0.4535 - val_accuracy: 0.8324\n",
      "Epoch 117/1000\n",
      "225/225 [==============================] - 0s 2ms/step - loss: 0.4363 - accuracy: 0.8351 - val_loss: 0.4514 - val_accuracy: 0.8341\n",
      "Epoch 118/1000\n",
      "225/225 [==============================] - 0s 2ms/step - loss: 0.4372 - accuracy: 0.8349 - val_loss: 0.4505 - val_accuracy: 0.8315\n",
      "Epoch 119/1000\n",
      "225/225 [==============================] - 0s 2ms/step - loss: 0.4398 - accuracy: 0.8347 - val_loss: 0.4554 - val_accuracy: 0.8354\n",
      "Epoch 120/1000\n",
      "225/225 [==============================] - 0s 2ms/step - loss: 0.4364 - accuracy: 0.8345 - val_loss: 0.4485 - val_accuracy: 0.8341\n",
      "Epoch 121/1000\n",
      "225/225 [==============================] - 0s 2ms/step - loss: 0.4333 - accuracy: 0.8368 - val_loss: 0.4545 - val_accuracy: 0.8330\n",
      "Epoch 122/1000\n",
      "225/225 [==============================] - 0s 2ms/step - loss: 0.4355 - accuracy: 0.8358 - val_loss: 0.4612 - val_accuracy: 0.8284\n",
      "Epoch 123/1000\n",
      "225/225 [==============================] - 0s 2ms/step - loss: 0.4352 - accuracy: 0.8364 - val_loss: 0.4594 - val_accuracy: 0.8296\n",
      "Epoch 124/1000\n",
      "225/225 [==============================] - 0s 2ms/step - loss: 0.4327 - accuracy: 0.8373 - val_loss: 0.4501 - val_accuracy: 0.8315\n",
      "Epoch 125/1000\n",
      "225/225 [==============================] - 0s 2ms/step - loss: 0.4333 - accuracy: 0.8368 - val_loss: 0.4616 - val_accuracy: 0.8333\n",
      "Epoch 126/1000\n",
      "225/225 [==============================] - 0s 2ms/step - loss: 0.4351 - accuracy: 0.8358 - val_loss: 0.4531 - val_accuracy: 0.8344\n",
      "Epoch 127/1000\n",
      "225/225 [==============================] - 0s 2ms/step - loss: 0.4325 - accuracy: 0.8375 - val_loss: 0.4656 - val_accuracy: 0.8247\n",
      "Epoch 128/1000\n",
      "225/225 [==============================] - 0s 2ms/step - loss: 0.4336 - accuracy: 0.8366 - val_loss: 0.4644 - val_accuracy: 0.8265\n",
      "Epoch 129/1000\n",
      "225/225 [==============================] - 0s 2ms/step - loss: 0.4343 - accuracy: 0.8361 - val_loss: 0.4544 - val_accuracy: 0.8319\n",
      "Epoch 130/1000\n",
      "225/225 [==============================] - 0s 2ms/step - loss: 0.4321 - accuracy: 0.8375 - val_loss: 0.4533 - val_accuracy: 0.8319\n",
      "Epoch 131/1000\n",
      "225/225 [==============================] - 0s 2ms/step - loss: 0.4318 - accuracy: 0.8377 - val_loss: 0.4475 - val_accuracy: 0.8355\n",
      "Epoch 132/1000\n",
      "225/225 [==============================] - 0s 2ms/step - loss: 0.4321 - accuracy: 0.8371 - val_loss: 0.4460 - val_accuracy: 0.8347\n",
      "Epoch 133/1000\n",
      "225/225 [==============================] - 0s 2ms/step - loss: 0.4321 - accuracy: 0.8377 - val_loss: 0.4607 - val_accuracy: 0.8287\n",
      "Epoch 134/1000\n",
      "225/225 [==============================] - 0s 2ms/step - loss: 0.4287 - accuracy: 0.8388 - val_loss: 0.4539 - val_accuracy: 0.8345\n",
      "Epoch 135/1000\n",
      "225/225 [==============================] - 0s 2ms/step - loss: 0.4316 - accuracy: 0.8379 - val_loss: 0.4493 - val_accuracy: 0.8329\n",
      "Epoch 136/1000\n",
      "225/225 [==============================] - 0s 2ms/step - loss: 0.4316 - accuracy: 0.8382 - val_loss: 0.4459 - val_accuracy: 0.8338\n",
      "Epoch 137/1000\n",
      "225/225 [==============================] - 0s 2ms/step - loss: 0.4306 - accuracy: 0.8376 - val_loss: 0.4682 - val_accuracy: 0.8293\n",
      "Epoch 138/1000\n",
      "225/225 [==============================] - 0s 2ms/step - loss: 0.4321 - accuracy: 0.8381 - val_loss: 0.4504 - val_accuracy: 0.8344\n",
      "Epoch 139/1000\n",
      "225/225 [==============================] - 0s 2ms/step - loss: 0.4315 - accuracy: 0.8378 - val_loss: 0.4544 - val_accuracy: 0.8336\n",
      "Epoch 140/1000\n",
      "225/225 [==============================] - 0s 2ms/step - loss: 0.4288 - accuracy: 0.8397 - val_loss: 0.4558 - val_accuracy: 0.8329\n",
      "Epoch 141/1000\n",
      "225/225 [==============================] - 0s 2ms/step - loss: 0.4325 - accuracy: 0.8379 - val_loss: 0.4500 - val_accuracy: 0.8347\n",
      "Epoch 142/1000\n",
      "225/225 [==============================] - 0s 2ms/step - loss: 0.4284 - accuracy: 0.8382 - val_loss: 0.4465 - val_accuracy: 0.8356\n",
      "Epoch 143/1000\n",
      "225/225 [==============================] - 0s 2ms/step - loss: 0.4280 - accuracy: 0.8389 - val_loss: 0.4541 - val_accuracy: 0.8335\n",
      "Epoch 144/1000\n",
      "225/225 [==============================] - 0s 2ms/step - loss: 0.4279 - accuracy: 0.8402 - val_loss: 0.4484 - val_accuracy: 0.8339\n",
      "Epoch 145/1000\n",
      "225/225 [==============================] - 0s 2ms/step - loss: 0.4275 - accuracy: 0.8395 - val_loss: 0.4567 - val_accuracy: 0.8343\n",
      "Epoch 146/1000\n",
      "225/225 [==============================] - 0s 2ms/step - loss: 0.4286 - accuracy: 0.8390 - val_loss: 0.4433 - val_accuracy: 0.8360\n",
      "Epoch 147/1000\n",
      "225/225 [==============================] - 0s 2ms/step - loss: 0.4286 - accuracy: 0.8389 - val_loss: 0.4444 - val_accuracy: 0.8371\n",
      "Epoch 148/1000\n",
      "225/225 [==============================] - 0s 2ms/step - loss: 0.4265 - accuracy: 0.8404 - val_loss: 0.4520 - val_accuracy: 0.8334\n",
      "Epoch 149/1000\n",
      "225/225 [==============================] - 0s 2ms/step - loss: 0.4248 - accuracy: 0.8397 - val_loss: 0.4468 - val_accuracy: 0.8351\n",
      "Epoch 150/1000\n",
      "225/225 [==============================] - 0s 2ms/step - loss: 0.4261 - accuracy: 0.8400 - val_loss: 0.4446 - val_accuracy: 0.8373\n",
      "Epoch 151/1000\n",
      "225/225 [==============================] - 1s 3ms/step - loss: 0.4267 - accuracy: 0.8405 - val_loss: 0.4558 - val_accuracy: 0.8332\n",
      "Epoch 152/1000\n",
      "225/225 [==============================] - 0s 2ms/step - loss: 0.4259 - accuracy: 0.8407 - val_loss: 0.4493 - val_accuracy: 0.8345\n",
      "Epoch 153/1000\n",
      "225/225 [==============================] - 0s 2ms/step - loss: 0.4235 - accuracy: 0.8412 - val_loss: 0.4540 - val_accuracy: 0.8354\n",
      "Epoch 154/1000\n",
      "225/225 [==============================] - 0s 2ms/step - loss: 0.4263 - accuracy: 0.8405 - val_loss: 0.4493 - val_accuracy: 0.8357\n",
      "Epoch 155/1000\n",
      "225/225 [==============================] - 0s 2ms/step - loss: 0.4270 - accuracy: 0.8395 - val_loss: 0.4447 - val_accuracy: 0.8358\n",
      "Epoch 156/1000\n",
      "225/225 [==============================] - 0s 2ms/step - loss: 0.4255 - accuracy: 0.8400 - val_loss: 0.4499 - val_accuracy: 0.8331\n",
      "Epoch 157/1000\n",
      "225/225 [==============================] - 0s 2ms/step - loss: 0.4229 - accuracy: 0.8401 - val_loss: 0.4524 - val_accuracy: 0.8355\n",
      "Epoch 158/1000\n",
      "225/225 [==============================] - 0s 2ms/step - loss: 0.4262 - accuracy: 0.8407 - val_loss: 0.4484 - val_accuracy: 0.8368\n",
      "Epoch 159/1000\n",
      "225/225 [==============================] - 0s 2ms/step - loss: 0.4248 - accuracy: 0.8403 - val_loss: 0.4495 - val_accuracy: 0.8394\n",
      "Epoch 160/1000\n",
      "225/225 [==============================] - 0s 2ms/step - loss: 0.4245 - accuracy: 0.8416 - val_loss: 0.4552 - val_accuracy: 0.8347\n",
      "Epoch 161/1000\n",
      "225/225 [==============================] - 0s 2ms/step - loss: 0.4239 - accuracy: 0.8418 - val_loss: 0.4585 - val_accuracy: 0.8310\n",
      "Epoch 162/1000\n",
      "225/225 [==============================] - 0s 2ms/step - loss: 0.4218 - accuracy: 0.8416 - val_loss: 0.4475 - val_accuracy: 0.8340\n",
      "Epoch 163/1000\n",
      "225/225 [==============================] - 0s 2ms/step - loss: 0.4231 - accuracy: 0.8411 - val_loss: 0.4415 - val_accuracy: 0.8379\n",
      "Epoch 164/1000\n",
      "225/225 [==============================] - 0s 2ms/step - loss: 0.4217 - accuracy: 0.8412 - val_loss: 0.4570 - val_accuracy: 0.8376\n",
      "Epoch 165/1000\n",
      "225/225 [==============================] - 0s 2ms/step - loss: 0.4224 - accuracy: 0.8413 - val_loss: 0.4388 - val_accuracy: 0.8407\n",
      "Epoch 166/1000\n",
      "225/225 [==============================] - 0s 2ms/step - loss: 0.4218 - accuracy: 0.8418 - val_loss: 0.4387 - val_accuracy: 0.8381\n",
      "Epoch 167/1000\n",
      "225/225 [==============================] - 0s 2ms/step - loss: 0.4228 - accuracy: 0.8405 - val_loss: 0.4378 - val_accuracy: 0.8402\n",
      "Epoch 168/1000\n",
      "225/225 [==============================] - 0s 2ms/step - loss: 0.4222 - accuracy: 0.8415 - val_loss: 0.4473 - val_accuracy: 0.8373\n",
      "Epoch 169/1000\n",
      "225/225 [==============================] - 0s 2ms/step - loss: 0.4229 - accuracy: 0.8414 - val_loss: 0.4504 - val_accuracy: 0.8373\n",
      "Epoch 170/1000\n",
      "225/225 [==============================] - 0s 2ms/step - loss: 0.4202 - accuracy: 0.8422 - val_loss: 0.4383 - val_accuracy: 0.8412\n",
      "Epoch 171/1000\n",
      "225/225 [==============================] - 0s 2ms/step - loss: 0.4201 - accuracy: 0.8429 - val_loss: 0.4434 - val_accuracy: 0.8406\n",
      "Epoch 172/1000\n",
      "225/225 [==============================] - 0s 2ms/step - loss: 0.4207 - accuracy: 0.8427 - val_loss: 0.4501 - val_accuracy: 0.8369\n",
      "Epoch 173/1000\n",
      "225/225 [==============================] - 0s 2ms/step - loss: 0.4197 - accuracy: 0.8435 - val_loss: 0.4376 - val_accuracy: 0.8391\n",
      "Epoch 174/1000\n",
      "225/225 [==============================] - 0s 2ms/step - loss: 0.4198 - accuracy: 0.8422 - val_loss: 0.4407 - val_accuracy: 0.8383\n",
      "Epoch 175/1000\n",
      "225/225 [==============================] - 0s 2ms/step - loss: 0.4230 - accuracy: 0.8416 - val_loss: 0.4482 - val_accuracy: 0.8362\n",
      "Epoch 176/1000\n",
      "225/225 [==============================] - 0s 2ms/step - loss: 0.4209 - accuracy: 0.8427 - val_loss: 0.4469 - val_accuracy: 0.8370\n",
      "Epoch 177/1000\n",
      "225/225 [==============================] - 0s 2ms/step - loss: 0.4225 - accuracy: 0.8414 - val_loss: 0.4425 - val_accuracy: 0.8363\n",
      "Epoch 178/1000\n",
      "225/225 [==============================] - 0s 2ms/step - loss: 0.4214 - accuracy: 0.8423 - val_loss: 0.4396 - val_accuracy: 0.8381\n",
      "Epoch 179/1000\n",
      "225/225 [==============================] - 0s 2ms/step - loss: 0.4176 - accuracy: 0.8439 - val_loss: 0.4387 - val_accuracy: 0.8403\n",
      "Epoch 180/1000\n",
      "225/225 [==============================] - 0s 2ms/step - loss: 0.4204 - accuracy: 0.8423 - val_loss: 0.4487 - val_accuracy: 0.8371\n",
      "Epoch 181/1000\n",
      "225/225 [==============================] - 0s 2ms/step - loss: 0.4181 - accuracy: 0.8434 - val_loss: 0.4412 - val_accuracy: 0.8355\n",
      "Epoch 182/1000\n",
      "225/225 [==============================] - 0s 2ms/step - loss: 0.4189 - accuracy: 0.8430 - val_loss: 0.4387 - val_accuracy: 0.8404\n",
      "Epoch 183/1000\n",
      "225/225 [==============================] - 0s 2ms/step - loss: 0.4178 - accuracy: 0.8441 - val_loss: 0.4429 - val_accuracy: 0.8379\n",
      "Epoch 184/1000\n",
      "225/225 [==============================] - 0s 2ms/step - loss: 0.4185 - accuracy: 0.8439 - val_loss: 0.4401 - val_accuracy: 0.8408\n",
      "Epoch 185/1000\n",
      "225/225 [==============================] - 0s 2ms/step - loss: 0.4160 - accuracy: 0.8447 - val_loss: 0.4542 - val_accuracy: 0.8373\n",
      "Epoch 186/1000\n",
      "225/225 [==============================] - 0s 2ms/step - loss: 0.4186 - accuracy: 0.8440 - val_loss: 0.4514 - val_accuracy: 0.8405\n",
      "Epoch 187/1000\n",
      "225/225 [==============================] - 0s 2ms/step - loss: 0.4190 - accuracy: 0.8431 - val_loss: 0.4502 - val_accuracy: 0.8364\n",
      "Epoch 188/1000\n",
      "225/225 [==============================] - 0s 2ms/step - loss: 0.4189 - accuracy: 0.8438 - val_loss: 0.4405 - val_accuracy: 0.8395\n",
      "Epoch 189/1000\n",
      "225/225 [==============================] - 0s 2ms/step - loss: 0.4175 - accuracy: 0.8439 - val_loss: 0.4365 - val_accuracy: 0.8392\n",
      "Epoch 190/1000\n",
      "225/225 [==============================] - 0s 2ms/step - loss: 0.4160 - accuracy: 0.8443 - val_loss: 0.4457 - val_accuracy: 0.8379\n",
      "Epoch 191/1000\n",
      "225/225 [==============================] - 0s 2ms/step - loss: 0.4155 - accuracy: 0.8439 - val_loss: 0.4567 - val_accuracy: 0.8344\n",
      "Epoch 192/1000\n",
      "225/225 [==============================] - 0s 2ms/step - loss: 0.4172 - accuracy: 0.8439 - val_loss: 0.4475 - val_accuracy: 0.8384\n",
      "Epoch 193/1000\n",
      "225/225 [==============================] - 0s 2ms/step - loss: 0.4145 - accuracy: 0.8443 - val_loss: 0.4619 - val_accuracy: 0.8380\n",
      "Epoch 194/1000\n",
      "225/225 [==============================] - 0s 2ms/step - loss: 0.4173 - accuracy: 0.8442 - val_loss: 0.4441 - val_accuracy: 0.8401\n",
      "Epoch 195/1000\n",
      "225/225 [==============================] - 0s 2ms/step - loss: 0.4184 - accuracy: 0.8424 - val_loss: 0.4483 - val_accuracy: 0.8372\n",
      "Epoch 196/1000\n",
      "225/225 [==============================] - 0s 2ms/step - loss: 0.4141 - accuracy: 0.8446 - val_loss: 0.4466 - val_accuracy: 0.8384\n",
      "Epoch 197/1000\n",
      "225/225 [==============================] - 0s 2ms/step - loss: 0.4161 - accuracy: 0.8450 - val_loss: 0.4415 - val_accuracy: 0.8392\n",
      "Epoch 198/1000\n",
      "225/225 [==============================] - 0s 2ms/step - loss: 0.4143 - accuracy: 0.8456 - val_loss: 0.4411 - val_accuracy: 0.8391\n",
      "Epoch 199/1000\n",
      "225/225 [==============================] - 0s 2ms/step - loss: 0.4160 - accuracy: 0.8448 - val_loss: 0.4616 - val_accuracy: 0.8381\n",
      "Epoch 200/1000\n",
      "225/225 [==============================] - 0s 2ms/step - loss: 0.4163 - accuracy: 0.8441 - val_loss: 0.4411 - val_accuracy: 0.8387\n",
      "Epoch 201/1000\n",
      "225/225 [==============================] - 1s 2ms/step - loss: 0.4181 - accuracy: 0.8430 - val_loss: 0.4511 - val_accuracy: 0.8351\n",
      "Epoch 202/1000\n",
      "225/225 [==============================] - 0s 2ms/step - loss: 0.4137 - accuracy: 0.8458 - val_loss: 0.4532 - val_accuracy: 0.8373\n",
      "Epoch 203/1000\n",
      "225/225 [==============================] - 0s 2ms/step - loss: 0.4141 - accuracy: 0.8455 - val_loss: 0.4463 - val_accuracy: 0.8377\n",
      "Epoch 204/1000\n",
      "225/225 [==============================] - 0s 2ms/step - loss: 0.4138 - accuracy: 0.8443 - val_loss: 0.4445 - val_accuracy: 0.8384\n",
      "Epoch 205/1000\n",
      "225/225 [==============================] - 0s 2ms/step - loss: 0.4129 - accuracy: 0.8455 - val_loss: 0.4440 - val_accuracy: 0.8397\n",
      "Epoch 206/1000\n",
      "225/225 [==============================] - 0s 2ms/step - loss: 0.4160 - accuracy: 0.8455 - val_loss: 0.4412 - val_accuracy: 0.8382\n",
      "Epoch 207/1000\n",
      "225/225 [==============================] - 0s 2ms/step - loss: 0.4167 - accuracy: 0.8437 - val_loss: 0.4408 - val_accuracy: 0.8380\n",
      "Epoch 208/1000\n",
      "225/225 [==============================] - 0s 2ms/step - loss: 0.4164 - accuracy: 0.8449 - val_loss: 0.4489 - val_accuracy: 0.8384\n",
      "Epoch 209/1000\n",
      "225/225 [==============================] - 0s 2ms/step - loss: 0.4121 - accuracy: 0.8458 - val_loss: 0.4433 - val_accuracy: 0.8375\n",
      "Epoch 210/1000\n",
      "225/225 [==============================] - 0s 2ms/step - loss: 0.4143 - accuracy: 0.8461 - val_loss: 0.4376 - val_accuracy: 0.8391\n",
      "Epoch 211/1000\n",
      "225/225 [==============================] - 0s 2ms/step - loss: 0.4137 - accuracy: 0.8452 - val_loss: 0.4506 - val_accuracy: 0.8394\n",
      "Epoch 212/1000\n",
      "225/225 [==============================] - 0s 2ms/step - loss: 0.4132 - accuracy: 0.8458 - val_loss: 0.4407 - val_accuracy: 0.8418\n",
      "Epoch 213/1000\n",
      "225/225 [==============================] - 0s 2ms/step - loss: 0.4109 - accuracy: 0.8471 - val_loss: 0.4412 - val_accuracy: 0.8373\n",
      "Epoch 214/1000\n",
      "225/225 [==============================] - 0s 2ms/step - loss: 0.4123 - accuracy: 0.8463 - val_loss: 0.4414 - val_accuracy: 0.8428\n",
      "Epoch 215/1000\n",
      "225/225 [==============================] - 0s 2ms/step - loss: 0.4110 - accuracy: 0.8461 - val_loss: 0.4381 - val_accuracy: 0.8406\n",
      "Epoch 216/1000\n",
      "225/225 [==============================] - 0s 2ms/step - loss: 0.4125 - accuracy: 0.8464 - val_loss: 0.4391 - val_accuracy: 0.8392\n",
      "Epoch 217/1000\n",
      "225/225 [==============================] - 0s 2ms/step - loss: 0.4135 - accuracy: 0.8459 - val_loss: 0.4441 - val_accuracy: 0.8366\n",
      "Epoch 218/1000\n",
      "225/225 [==============================] - 0s 2ms/step - loss: 0.4125 - accuracy: 0.8457 - val_loss: 0.4506 - val_accuracy: 0.8405\n",
      "Epoch 219/1000\n",
      "225/225 [==============================] - 0s 2ms/step - loss: 0.4140 - accuracy: 0.8453 - val_loss: 0.4414 - val_accuracy: 0.8398\n",
      "Epoch 220/1000\n",
      "225/225 [==============================] - 0s 2ms/step - loss: 0.4113 - accuracy: 0.8467 - val_loss: 0.4443 - val_accuracy: 0.8382\n",
      "Epoch 221/1000\n",
      "225/225 [==============================] - 0s 2ms/step - loss: 0.4132 - accuracy: 0.8460 - val_loss: 0.4426 - val_accuracy: 0.8391\n",
      "Epoch 222/1000\n",
      "225/225 [==============================] - 0s 2ms/step - loss: 0.4120 - accuracy: 0.8467 - val_loss: 0.4447 - val_accuracy: 0.8392\n",
      "Epoch 223/1000\n",
      "225/225 [==============================] - 0s 2ms/step - loss: 0.4125 - accuracy: 0.8458 - val_loss: 0.4344 - val_accuracy: 0.8424\n",
      "Epoch 224/1000\n",
      "225/225 [==============================] - 0s 2ms/step - loss: 0.4124 - accuracy: 0.8457 - val_loss: 0.4459 - val_accuracy: 0.8420\n",
      "Epoch 225/1000\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "225/225 [==============================] - 0s 2ms/step - loss: 0.4125 - accuracy: 0.8464 - val_loss: 0.4438 - val_accuracy: 0.8389\n",
      "Epoch 226/1000\n",
      "225/225 [==============================] - 0s 2ms/step - loss: 0.4112 - accuracy: 0.8473 - val_loss: 0.4422 - val_accuracy: 0.8364\n",
      "Epoch 227/1000\n",
      "225/225 [==============================] - 0s 2ms/step - loss: 0.4123 - accuracy: 0.8455 - val_loss: 0.4386 - val_accuracy: 0.8375\n",
      "Epoch 228/1000\n",
      "225/225 [==============================] - 0s 2ms/step - loss: 0.4110 - accuracy: 0.8465 - val_loss: 0.4578 - val_accuracy: 0.8388\n",
      "Epoch 229/1000\n",
      "225/225 [==============================] - 0s 2ms/step - loss: 0.4108 - accuracy: 0.8466 - val_loss: 0.4454 - val_accuracy: 0.8379\n",
      "Epoch 230/1000\n",
      "225/225 [==============================] - 0s 2ms/step - loss: 0.4107 - accuracy: 0.8472 - val_loss: 0.4349 - val_accuracy: 0.8431\n",
      "Epoch 231/1000\n",
      "225/225 [==============================] - 0s 2ms/step - loss: 0.4104 - accuracy: 0.8466 - val_loss: 0.4408 - val_accuracy: 0.8423\n",
      "Epoch 232/1000\n",
      "225/225 [==============================] - 0s 2ms/step - loss: 0.4127 - accuracy: 0.8462 - val_loss: 0.4377 - val_accuracy: 0.8439\n",
      "Epoch 233/1000\n",
      "225/225 [==============================] - 0s 2ms/step - loss: 0.4120 - accuracy: 0.8460 - val_loss: 0.4399 - val_accuracy: 0.8377\n",
      "Epoch 234/1000\n",
      "225/225 [==============================] - 0s 2ms/step - loss: 0.4092 - accuracy: 0.8471 - val_loss: 0.4431 - val_accuracy: 0.8395\n",
      "Epoch 235/1000\n",
      "225/225 [==============================] - 0s 2ms/step - loss: 0.4100 - accuracy: 0.8466 - val_loss: 0.4420 - val_accuracy: 0.8405\n",
      "Epoch 236/1000\n",
      "225/225 [==============================] - 0s 2ms/step - loss: 0.4092 - accuracy: 0.8478 - val_loss: 0.4338 - val_accuracy: 0.8453\n",
      "Epoch 237/1000\n",
      "225/225 [==============================] - 0s 2ms/step - loss: 0.4088 - accuracy: 0.8488 - val_loss: 0.4433 - val_accuracy: 0.8364\n",
      "Epoch 238/1000\n",
      "225/225 [==============================] - 0s 2ms/step - loss: 0.4113 - accuracy: 0.8465 - val_loss: 0.4452 - val_accuracy: 0.8396\n",
      "Epoch 239/1000\n",
      "225/225 [==============================] - 0s 2ms/step - loss: 0.4102 - accuracy: 0.8474 - val_loss: 0.4394 - val_accuracy: 0.8410\n",
      "Epoch 240/1000\n",
      "225/225 [==============================] - 0s 2ms/step - loss: 0.4085 - accuracy: 0.8475 - val_loss: 0.4379 - val_accuracy: 0.8410\n",
      "Epoch 241/1000\n",
      "225/225 [==============================] - 0s 2ms/step - loss: 0.4097 - accuracy: 0.8478 - val_loss: 0.4428 - val_accuracy: 0.8394\n",
      "Epoch 242/1000\n",
      "225/225 [==============================] - 0s 2ms/step - loss: 0.4088 - accuracy: 0.8466 - val_loss: 0.4402 - val_accuracy: 0.8404\n",
      "Epoch 243/1000\n",
      "225/225 [==============================] - 0s 2ms/step - loss: 0.4085 - accuracy: 0.8466 - val_loss: 0.4344 - val_accuracy: 0.8395\n",
      "Epoch 244/1000\n",
      "225/225 [==============================] - 0s 2ms/step - loss: 0.4118 - accuracy: 0.8469 - val_loss: 0.4392 - val_accuracy: 0.8419\n",
      "Epoch 245/1000\n",
      "225/225 [==============================] - 0s 2ms/step - loss: 0.4067 - accuracy: 0.8489 - val_loss: 0.4435 - val_accuracy: 0.8387\n",
      "Epoch 246/1000\n",
      "225/225 [==============================] - 0s 2ms/step - loss: 0.4098 - accuracy: 0.8475 - val_loss: 0.4383 - val_accuracy: 0.8391\n",
      "Epoch 247/1000\n",
      "225/225 [==============================] - 0s 2ms/step - loss: 0.4068 - accuracy: 0.8491 - val_loss: 0.4442 - val_accuracy: 0.8402\n",
      "Epoch 248/1000\n",
      "225/225 [==============================] - 0s 2ms/step - loss: 0.4088 - accuracy: 0.8478 - val_loss: 0.4446 - val_accuracy: 0.8401\n",
      "Epoch 249/1000\n",
      "225/225 [==============================] - 0s 2ms/step - loss: 0.4094 - accuracy: 0.8474 - val_loss: 0.4394 - val_accuracy: 0.8397\n",
      "Epoch 250/1000\n",
      "225/225 [==============================] - 0s 2ms/step - loss: 0.4085 - accuracy: 0.8472 - val_loss: 0.4493 - val_accuracy: 0.8379\n",
      "Epoch 251/1000\n",
      "225/225 [==============================] - 0s 2ms/step - loss: 0.4067 - accuracy: 0.8497 - val_loss: 0.4457 - val_accuracy: 0.8378\n",
      "Epoch 252/1000\n",
      "225/225 [==============================] - 0s 2ms/step - loss: 0.4075 - accuracy: 0.8485 - val_loss: 0.4452 - val_accuracy: 0.8384\n",
      "Epoch 253/1000\n",
      "225/225 [==============================] - 0s 2ms/step - loss: 0.4091 - accuracy: 0.8485 - val_loss: 0.4392 - val_accuracy: 0.8423\n",
      "Epoch 254/1000\n",
      "225/225 [==============================] - 0s 2ms/step - loss: 0.4069 - accuracy: 0.8486 - val_loss: 0.4437 - val_accuracy: 0.8394\n",
      "Epoch 255/1000\n",
      "225/225 [==============================] - 0s 2ms/step - loss: 0.4058 - accuracy: 0.8487 - val_loss: 0.4383 - val_accuracy: 0.8415\n",
      "Epoch 256/1000\n",
      "225/225 [==============================] - 0s 2ms/step - loss: 0.4066 - accuracy: 0.8486 - val_loss: 0.4423 - val_accuracy: 0.8400\n",
      "Epoch 257/1000\n",
      "225/225 [==============================] - 0s 2ms/step - loss: 0.4041 - accuracy: 0.8500 - val_loss: 0.4487 - val_accuracy: 0.8364\n",
      "Epoch 258/1000\n",
      "225/225 [==============================] - 0s 2ms/step - loss: 0.4080 - accuracy: 0.8470 - val_loss: 0.4415 - val_accuracy: 0.8391\n",
      "Epoch 259/1000\n",
      "225/225 [==============================] - 0s 2ms/step - loss: 0.4041 - accuracy: 0.8495 - val_loss: 0.4386 - val_accuracy: 0.8419\n",
      "Epoch 260/1000\n",
      "225/225 [==============================] - 0s 2ms/step - loss: 0.4077 - accuracy: 0.8475 - val_loss: 0.4420 - val_accuracy: 0.8431\n",
      "Epoch 261/1000\n",
      "225/225 [==============================] - 0s 2ms/step - loss: 0.4077 - accuracy: 0.8487 - val_loss: 0.4448 - val_accuracy: 0.8392\n",
      "Epoch 262/1000\n",
      "225/225 [==============================] - 0s 2ms/step - loss: 0.4072 - accuracy: 0.8485 - val_loss: 0.4382 - val_accuracy: 0.8376\n",
      "Epoch 263/1000\n",
      "225/225 [==============================] - 0s 2ms/step - loss: 0.4064 - accuracy: 0.8476 - val_loss: 0.4380 - val_accuracy: 0.8428\n",
      "Epoch 264/1000\n",
      "225/225 [==============================] - 0s 2ms/step - loss: 0.4055 - accuracy: 0.8484 - val_loss: 0.4420 - val_accuracy: 0.8392\n",
      "Epoch 265/1000\n",
      "225/225 [==============================] - 0s 2ms/step - loss: 0.4064 - accuracy: 0.8475 - val_loss: 0.4443 - val_accuracy: 0.8408\n",
      "Epoch 266/1000\n",
      "225/225 [==============================] - 0s 2ms/step - loss: 0.4087 - accuracy: 0.8472 - val_loss: 0.4429 - val_accuracy: 0.8430\n",
      "Epoch 267/1000\n",
      "225/225 [==============================] - 0s 2ms/step - loss: 0.4062 - accuracy: 0.8480 - val_loss: 0.4371 - val_accuracy: 0.8413\n",
      "Epoch 268/1000\n",
      "225/225 [==============================] - 0s 2ms/step - loss: 0.4055 - accuracy: 0.8488 - val_loss: 0.4437 - val_accuracy: 0.8382\n",
      "Epoch 269/1000\n",
      "225/225 [==============================] - 0s 2ms/step - loss: 0.4063 - accuracy: 0.8479 - val_loss: 0.4440 - val_accuracy: 0.8413\n",
      "Epoch 270/1000\n",
      "225/225 [==============================] - 0s 2ms/step - loss: 0.4070 - accuracy: 0.8494 - val_loss: 0.4478 - val_accuracy: 0.8385\n",
      "Epoch 271/1000\n",
      "225/225 [==============================] - 0s 2ms/step - loss: 0.4045 - accuracy: 0.8497 - val_loss: 0.4451 - val_accuracy: 0.8374\n",
      "Epoch 272/1000\n",
      "225/225 [==============================] - 0s 2ms/step - loss: 0.4053 - accuracy: 0.8492 - val_loss: 0.4476 - val_accuracy: 0.8379\n",
      "Epoch 273/1000\n",
      "225/225 [==============================] - 0s 2ms/step - loss: 0.4051 - accuracy: 0.8480 - val_loss: 0.4399 - val_accuracy: 0.8402\n",
      "Epoch 274/1000\n",
      "225/225 [==============================] - 0s 2ms/step - loss: 0.4051 - accuracy: 0.8488 - val_loss: 0.4419 - val_accuracy: 0.8406\n",
      "Epoch 275/1000\n",
      "225/225 [==============================] - 0s 2ms/step - loss: 0.4055 - accuracy: 0.8493 - val_loss: 0.4394 - val_accuracy: 0.8427\n",
      "Epoch 276/1000\n",
      "225/225 [==============================] - 0s 2ms/step - loss: 0.4067 - accuracy: 0.8474 - val_loss: 0.4436 - val_accuracy: 0.8391\n",
      "Epoch 277/1000\n",
      "225/225 [==============================] - 0s 2ms/step - loss: 0.4046 - accuracy: 0.8485 - val_loss: 0.4417 - val_accuracy: 0.8409\n",
      "Epoch 278/1000\n",
      "225/225 [==============================] - 0s 2ms/step - loss: 0.4032 - accuracy: 0.8494 - val_loss: 0.4294 - val_accuracy: 0.8451\n",
      "Epoch 279/1000\n",
      "225/225 [==============================] - 0s 2ms/step - loss: 0.4070 - accuracy: 0.8483 - val_loss: 0.4428 - val_accuracy: 0.8431\n",
      "Epoch 280/1000\n",
      "225/225 [==============================] - 1s 2ms/step - loss: 0.4047 - accuracy: 0.8493 - val_loss: 0.4441 - val_accuracy: 0.8384\n",
      "Epoch 281/1000\n",
      "225/225 [==============================] - 0s 2ms/step - loss: 0.4050 - accuracy: 0.8483 - val_loss: 0.4404 - val_accuracy: 0.8422\n",
      "Epoch 282/1000\n",
      "225/225 [==============================] - 0s 2ms/step - loss: 0.4032 - accuracy: 0.8490 - val_loss: 0.4359 - val_accuracy: 0.8417\n",
      "Epoch 283/1000\n",
      "225/225 [==============================] - 0s 2ms/step - loss: 0.4049 - accuracy: 0.8497 - val_loss: 0.4400 - val_accuracy: 0.8443\n",
      "Epoch 284/1000\n",
      "225/225 [==============================] - 0s 2ms/step - loss: 0.4037 - accuracy: 0.8504 - val_loss: 0.4325 - val_accuracy: 0.8418\n",
      "Epoch 285/1000\n",
      "225/225 [==============================] - 0s 2ms/step - loss: 0.4025 - accuracy: 0.8483 - val_loss: 0.4352 - val_accuracy: 0.8434\n",
      "Epoch 286/1000\n",
      "225/225 [==============================] - 0s 2ms/step - loss: 0.4064 - accuracy: 0.8486 - val_loss: 0.4404 - val_accuracy: 0.8408\n",
      "Epoch 287/1000\n",
      "225/225 [==============================] - 0s 2ms/step - loss: 0.4025 - accuracy: 0.8495 - val_loss: 0.4399 - val_accuracy: 0.8413\n",
      "Epoch 288/1000\n",
      "225/225 [==============================] - 0s 2ms/step - loss: 0.4035 - accuracy: 0.8499 - val_loss: 0.4409 - val_accuracy: 0.8415\n",
      "Epoch 289/1000\n",
      "225/225 [==============================] - 0s 2ms/step - loss: 0.4035 - accuracy: 0.8501 - val_loss: 0.4342 - val_accuracy: 0.8445\n",
      "Epoch 290/1000\n",
      "225/225 [==============================] - 0s 2ms/step - loss: 0.4026 - accuracy: 0.8501 - val_loss: 0.4387 - val_accuracy: 0.8419\n",
      "Epoch 291/1000\n",
      "225/225 [==============================] - 0s 2ms/step - loss: 0.4032 - accuracy: 0.8498 - val_loss: 0.4398 - val_accuracy: 0.8419\n",
      "Epoch 292/1000\n",
      "225/225 [==============================] - 0s 2ms/step - loss: 0.4023 - accuracy: 0.8504 - val_loss: 0.4396 - val_accuracy: 0.8390\n",
      "Epoch 293/1000\n",
      "225/225 [==============================] - 0s 2ms/step - loss: 0.4024 - accuracy: 0.8505 - val_loss: 0.4349 - val_accuracy: 0.8426\n",
      "Epoch 294/1000\n",
      "225/225 [==============================] - 0s 2ms/step - loss: 0.4032 - accuracy: 0.8505 - val_loss: 0.4286 - val_accuracy: 0.8444\n",
      "Epoch 295/1000\n",
      "225/225 [==============================] - 0s 2ms/step - loss: 0.4031 - accuracy: 0.8511 - val_loss: 0.4337 - val_accuracy: 0.8438\n",
      "Epoch 296/1000\n",
      "225/225 [==============================] - 0s 2ms/step - loss: 0.4038 - accuracy: 0.8493 - val_loss: 0.4345 - val_accuracy: 0.8451\n",
      "Epoch 297/1000\n",
      "225/225 [==============================] - 0s 2ms/step - loss: 0.4048 - accuracy: 0.8494 - val_loss: 0.4396 - val_accuracy: 0.8452\n",
      "Epoch 298/1000\n",
      "225/225 [==============================] - 0s 2ms/step - loss: 0.4016 - accuracy: 0.8500 - val_loss: 0.4333 - val_accuracy: 0.8439\n",
      "Epoch 299/1000\n",
      "225/225 [==============================] - 0s 2ms/step - loss: 0.4010 - accuracy: 0.8509 - val_loss: 0.4369 - val_accuracy: 0.8412\n",
      "Epoch 300/1000\n",
      "225/225 [==============================] - 0s 2ms/step - loss: 0.4034 - accuracy: 0.8504 - val_loss: 0.4290 - val_accuracy: 0.8442\n",
      "Epoch 301/1000\n",
      "225/225 [==============================] - 0s 2ms/step - loss: 0.4008 - accuracy: 0.8511 - val_loss: 0.4406 - val_accuracy: 0.8435\n",
      "Epoch 302/1000\n",
      "225/225 [==============================] - 0s 2ms/step - loss: 0.4021 - accuracy: 0.8505 - val_loss: 0.4370 - val_accuracy: 0.8423\n",
      "Epoch 303/1000\n",
      "225/225 [==============================] - 0s 2ms/step - loss: 0.4044 - accuracy: 0.8493 - val_loss: 0.4321 - val_accuracy: 0.8438\n",
      "Epoch 304/1000\n",
      "225/225 [==============================] - 0s 2ms/step - loss: 0.4026 - accuracy: 0.8498 - val_loss: 0.4370 - val_accuracy: 0.8449\n",
      "Epoch 305/1000\n",
      "225/225 [==============================] - 0s 2ms/step - loss: 0.4040 - accuracy: 0.8503 - val_loss: 0.4362 - val_accuracy: 0.8432\n",
      "Epoch 306/1000\n",
      "225/225 [==============================] - 0s 2ms/step - loss: 0.4039 - accuracy: 0.8498 - val_loss: 0.4419 - val_accuracy: 0.8429\n",
      "Epoch 307/1000\n",
      "225/225 [==============================] - 0s 2ms/step - loss: 0.4031 - accuracy: 0.8504 - val_loss: 0.4350 - val_accuracy: 0.8410\n",
      "Epoch 308/1000\n",
      "225/225 [==============================] - 0s 2ms/step - loss: 0.3999 - accuracy: 0.8518 - val_loss: 0.4366 - val_accuracy: 0.8458\n",
      "Epoch 309/1000\n",
      "225/225 [==============================] - 0s 2ms/step - loss: 0.4009 - accuracy: 0.8500 - val_loss: 0.4453 - val_accuracy: 0.8431\n",
      "Epoch 310/1000\n",
      "225/225 [==============================] - 0s 2ms/step - loss: 0.4019 - accuracy: 0.8497 - val_loss: 0.4288 - val_accuracy: 0.8425\n",
      "Epoch 311/1000\n",
      "225/225 [==============================] - 0s 2ms/step - loss: 0.3998 - accuracy: 0.8506 - val_loss: 0.4457 - val_accuracy: 0.8382\n",
      "Epoch 312/1000\n",
      "225/225 [==============================] - 0s 2ms/step - loss: 0.4005 - accuracy: 0.8515 - val_loss: 0.4504 - val_accuracy: 0.8416\n",
      "Epoch 313/1000\n",
      "225/225 [==============================] - 0s 2ms/step - loss: 0.4002 - accuracy: 0.8506 - val_loss: 0.4383 - val_accuracy: 0.8416\n",
      "Epoch 314/1000\n",
      "225/225 [==============================] - 0s 2ms/step - loss: 0.4023 - accuracy: 0.8506 - val_loss: 0.4423 - val_accuracy: 0.8409\n",
      "Epoch 315/1000\n",
      "225/225 [==============================] - 0s 2ms/step - loss: 0.4014 - accuracy: 0.8509 - val_loss: 0.4364 - val_accuracy: 0.8413\n",
      "Epoch 316/1000\n",
      "225/225 [==============================] - 0s 2ms/step - loss: 0.4009 - accuracy: 0.8507 - val_loss: 0.4431 - val_accuracy: 0.8441\n",
      "Epoch 317/1000\n",
      "225/225 [==============================] - 0s 2ms/step - loss: 0.4009 - accuracy: 0.8512 - val_loss: 0.4377 - val_accuracy: 0.8417\n",
      "Epoch 318/1000\n",
      "225/225 [==============================] - 0s 2ms/step - loss: 0.4045 - accuracy: 0.8490 - val_loss: 0.4359 - val_accuracy: 0.8393\n",
      "Epoch 319/1000\n",
      "225/225 [==============================] - 0s 2ms/step - loss: 0.4003 - accuracy: 0.8510 - val_loss: 0.4429 - val_accuracy: 0.8402\n",
      "Epoch 320/1000\n",
      "225/225 [==============================] - 0s 2ms/step - loss: 0.4026 - accuracy: 0.8499 - val_loss: 0.4341 - val_accuracy: 0.8416\n",
      "Epoch 321/1000\n",
      "225/225 [==============================] - 0s 2ms/step - loss: 0.4015 - accuracy: 0.8498 - val_loss: 0.4328 - val_accuracy: 0.8426\n",
      "Epoch 322/1000\n",
      "225/225 [==============================] - 0s 2ms/step - loss: 0.4016 - accuracy: 0.8505 - val_loss: 0.4427 - val_accuracy: 0.8407\n",
      "Epoch 323/1000\n",
      "225/225 [==============================] - 0s 2ms/step - loss: 0.3999 - accuracy: 0.8509 - val_loss: 0.4423 - val_accuracy: 0.8441\n",
      "Epoch 324/1000\n",
      "225/225 [==============================] - 0s 2ms/step - loss: 0.4012 - accuracy: 0.8511 - val_loss: 0.4510 - val_accuracy: 0.8392\n",
      "Epoch 325/1000\n",
      "225/225 [==============================] - 0s 2ms/step - loss: 0.3984 - accuracy: 0.8515 - val_loss: 0.4368 - val_accuracy: 0.8437\n",
      "Epoch 326/1000\n",
      "225/225 [==============================] - 0s 2ms/step - loss: 0.3986 - accuracy: 0.8525 - val_loss: 0.4340 - val_accuracy: 0.8434\n",
      "Epoch 327/1000\n",
      "225/225 [==============================] - 0s 2ms/step - loss: 0.4006 - accuracy: 0.8508 - val_loss: 0.4475 - val_accuracy: 0.8418\n",
      "Epoch 328/1000\n",
      "225/225 [==============================] - 0s 2ms/step - loss: 0.3989 - accuracy: 0.8522 - val_loss: 0.4420 - val_accuracy: 0.8413\n",
      "Epoch 329/1000\n",
      "225/225 [==============================] - 0s 2ms/step - loss: 0.4004 - accuracy: 0.8502 - val_loss: 0.4448 - val_accuracy: 0.8455\n",
      "Epoch 330/1000\n",
      "225/225 [==============================] - 0s 2ms/step - loss: 0.3973 - accuracy: 0.8518 - val_loss: 0.4334 - val_accuracy: 0.8440\n",
      "Epoch 331/1000\n",
      "225/225 [==============================] - 0s 2ms/step - loss: 0.4000 - accuracy: 0.8514 - val_loss: 0.4485 - val_accuracy: 0.8391\n",
      "Epoch 332/1000\n",
      "225/225 [==============================] - 0s 2ms/step - loss: 0.3995 - accuracy: 0.8514 - val_loss: 0.4307 - val_accuracy: 0.8458\n",
      "Epoch 333/1000\n",
      "225/225 [==============================] - 0s 2ms/step - loss: 0.4013 - accuracy: 0.8511 - val_loss: 0.4362 - val_accuracy: 0.8433\n",
      "Epoch 334/1000\n",
      "225/225 [==============================] - 0s 2ms/step - loss: 0.4002 - accuracy: 0.8516 - val_loss: 0.4334 - val_accuracy: 0.8445\n",
      "Epoch 335/1000\n",
      "225/225 [==============================] - 0s 2ms/step - loss: 0.3997 - accuracy: 0.8512 - val_loss: 0.4286 - val_accuracy: 0.8469\n",
      "Epoch 336/1000\n",
      "225/225 [==============================] - 0s 2ms/step - loss: 0.3990 - accuracy: 0.8522 - val_loss: 0.4402 - val_accuracy: 0.8434\n",
      "Epoch 337/1000\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "225/225 [==============================] - 0s 2ms/step - loss: 0.4009 - accuracy: 0.8502 - val_loss: 0.4448 - val_accuracy: 0.8416\n",
      "Epoch 338/1000\n",
      "225/225 [==============================] - 0s 2ms/step - loss: 0.3992 - accuracy: 0.8518 - val_loss: 0.4316 - val_accuracy: 0.8431\n",
      "Epoch 339/1000\n",
      "225/225 [==============================] - 0s 2ms/step - loss: 0.4008 - accuracy: 0.8510 - val_loss: 0.4318 - val_accuracy: 0.8453\n",
      "Epoch 340/1000\n",
      "225/225 [==============================] - 0s 2ms/step - loss: 0.3978 - accuracy: 0.8525 - val_loss: 0.4400 - val_accuracy: 0.8437\n",
      "Epoch 341/1000\n",
      "225/225 [==============================] - 0s 2ms/step - loss: 0.4018 - accuracy: 0.8505 - val_loss: 0.4306 - val_accuracy: 0.8451\n",
      "Epoch 342/1000\n",
      "225/225 [==============================] - 0s 2ms/step - loss: 0.3979 - accuracy: 0.8505 - val_loss: 0.4395 - val_accuracy: 0.8403\n",
      "Epoch 343/1000\n",
      "225/225 [==============================] - 0s 2ms/step - loss: 0.3996 - accuracy: 0.8520 - val_loss: 0.4475 - val_accuracy: 0.8421\n",
      "Epoch 344/1000\n",
      "225/225 [==============================] - 0s 2ms/step - loss: 0.4001 - accuracy: 0.8512 - val_loss: 0.4386 - val_accuracy: 0.8430\n",
      "Epoch 345/1000\n",
      "225/225 [==============================] - 0s 2ms/step - loss: 0.3982 - accuracy: 0.8517 - val_loss: 0.4460 - val_accuracy: 0.8399\n",
      "Epoch 346/1000\n",
      "225/225 [==============================] - 0s 2ms/step - loss: 0.3996 - accuracy: 0.8510 - val_loss: 0.4326 - val_accuracy: 0.8452\n",
      "Epoch 347/1000\n",
      "225/225 [==============================] - 0s 2ms/step - loss: 0.3989 - accuracy: 0.8517 - val_loss: 0.4310 - val_accuracy: 0.8473\n",
      "Epoch 348/1000\n",
      "225/225 [==============================] - 0s 2ms/step - loss: 0.4001 - accuracy: 0.8519 - val_loss: 0.4379 - val_accuracy: 0.8444\n",
      "Epoch 349/1000\n",
      "225/225 [==============================] - 0s 2ms/step - loss: 0.3978 - accuracy: 0.8521 - val_loss: 0.4353 - val_accuracy: 0.8449\n",
      "Epoch 350/1000\n",
      "225/225 [==============================] - 0s 2ms/step - loss: 0.3976 - accuracy: 0.8526 - val_loss: 0.4347 - val_accuracy: 0.8434\n",
      "Epoch 351/1000\n",
      "225/225 [==============================] - 0s 2ms/step - loss: 0.3963 - accuracy: 0.8536 - val_loss: 0.4481 - val_accuracy: 0.8416\n",
      "Epoch 352/1000\n",
      "225/225 [==============================] - 0s 2ms/step - loss: 0.3950 - accuracy: 0.8536 - val_loss: 0.4317 - val_accuracy: 0.8466\n",
      "Epoch 353/1000\n",
      "225/225 [==============================] - 0s 2ms/step - loss: 0.3984 - accuracy: 0.8521 - val_loss: 0.4331 - val_accuracy: 0.8435\n",
      "Epoch 354/1000\n",
      "225/225 [==============================] - 0s 2ms/step - loss: 0.3996 - accuracy: 0.8513 - val_loss: 0.4358 - val_accuracy: 0.8440\n",
      "Epoch 355/1000\n",
      "225/225 [==============================] - 0s 2ms/step - loss: 0.3977 - accuracy: 0.8528 - val_loss: 0.4295 - val_accuracy: 0.8447\n",
      "Epoch 356/1000\n",
      "225/225 [==============================] - 0s 2ms/step - loss: 0.3975 - accuracy: 0.8517 - val_loss: 0.4376 - val_accuracy: 0.8425\n",
      "Epoch 357/1000\n",
      "225/225 [==============================] - 0s 2ms/step - loss: 0.3995 - accuracy: 0.8511 - val_loss: 0.4305 - val_accuracy: 0.8445\n",
      "Epoch 358/1000\n",
      "225/225 [==============================] - 0s 2ms/step - loss: 0.3993 - accuracy: 0.8513 - val_loss: 0.4310 - val_accuracy: 0.8444\n",
      "Epoch 359/1000\n",
      "225/225 [==============================] - 0s 2ms/step - loss: 0.3977 - accuracy: 0.8528 - val_loss: 0.4349 - val_accuracy: 0.8467\n",
      "Epoch 360/1000\n",
      "225/225 [==============================] - 0s 2ms/step - loss: 0.3951 - accuracy: 0.8529 - val_loss: 0.4264 - val_accuracy: 0.8456\n",
      "Epoch 361/1000\n",
      "225/225 [==============================] - 0s 2ms/step - loss: 0.3972 - accuracy: 0.8516 - val_loss: 0.4279 - val_accuracy: 0.8480\n",
      "Epoch 362/1000\n",
      "225/225 [==============================] - 0s 2ms/step - loss: 0.3942 - accuracy: 0.8551 - val_loss: 0.4383 - val_accuracy: 0.8426\n",
      "Epoch 363/1000\n",
      "225/225 [==============================] - 0s 2ms/step - loss: 0.3969 - accuracy: 0.8528 - val_loss: 0.4310 - val_accuracy: 0.8488\n",
      "Epoch 364/1000\n",
      "225/225 [==============================] - 0s 2ms/step - loss: 0.3997 - accuracy: 0.8524 - val_loss: 0.4363 - val_accuracy: 0.8445\n",
      "Epoch 365/1000\n",
      "225/225 [==============================] - 0s 2ms/step - loss: 0.3960 - accuracy: 0.8535 - val_loss: 0.4305 - val_accuracy: 0.8444\n",
      "Epoch 366/1000\n",
      "225/225 [==============================] - 0s 2ms/step - loss: 0.3977 - accuracy: 0.8517 - val_loss: 0.4246 - val_accuracy: 0.8470\n",
      "Epoch 367/1000\n",
      "225/225 [==============================] - 0s 2ms/step - loss: 0.3933 - accuracy: 0.8527 - val_loss: 0.4401 - val_accuracy: 0.8467\n",
      "Epoch 368/1000\n",
      "225/225 [==============================] - 0s 2ms/step - loss: 0.3967 - accuracy: 0.8524 - val_loss: 0.4379 - val_accuracy: 0.8445\n",
      "Epoch 369/1000\n",
      "225/225 [==============================] - 0s 2ms/step - loss: 0.3997 - accuracy: 0.8518 - val_loss: 0.4353 - val_accuracy: 0.8442\n",
      "Epoch 370/1000\n",
      "225/225 [==============================] - 0s 2ms/step - loss: 0.3969 - accuracy: 0.8540 - val_loss: 0.4315 - val_accuracy: 0.8476\n",
      "Epoch 371/1000\n",
      "225/225 [==============================] - 0s 2ms/step - loss: 0.3948 - accuracy: 0.8532 - val_loss: 0.4437 - val_accuracy: 0.8434\n",
      "Epoch 372/1000\n",
      "225/225 [==============================] - 0s 2ms/step - loss: 0.3982 - accuracy: 0.8529 - val_loss: 0.4309 - val_accuracy: 0.8450\n",
      "Epoch 373/1000\n",
      "225/225 [==============================] - 0s 2ms/step - loss: 0.3958 - accuracy: 0.8534 - val_loss: 0.4301 - val_accuracy: 0.8445\n",
      "Epoch 374/1000\n",
      "225/225 [==============================] - 0s 2ms/step - loss: 0.3958 - accuracy: 0.8525 - val_loss: 0.4421 - val_accuracy: 0.8438\n",
      "Epoch 375/1000\n",
      "225/225 [==============================] - 0s 2ms/step - loss: 0.3958 - accuracy: 0.8522 - val_loss: 0.4282 - val_accuracy: 0.8504\n",
      "Epoch 376/1000\n",
      "225/225 [==============================] - 0s 2ms/step - loss: 0.3962 - accuracy: 0.8529 - val_loss: 0.4310 - val_accuracy: 0.8467\n",
      "Epoch 377/1000\n",
      "225/225 [==============================] - 0s 2ms/step - loss: 0.3961 - accuracy: 0.8529 - val_loss: 0.4353 - val_accuracy: 0.8423\n",
      "Epoch 378/1000\n",
      "225/225 [==============================] - 0s 2ms/step - loss: 0.3980 - accuracy: 0.8523 - val_loss: 0.4342 - val_accuracy: 0.8450\n",
      "Epoch 379/1000\n",
      "225/225 [==============================] - 0s 2ms/step - loss: 0.3983 - accuracy: 0.8520 - val_loss: 0.4500 - val_accuracy: 0.8418\n",
      "Epoch 380/1000\n",
      "225/225 [==============================] - 0s 2ms/step - loss: 0.3982 - accuracy: 0.8528 - val_loss: 0.4315 - val_accuracy: 0.8467\n",
      "Epoch 381/1000\n",
      "225/225 [==============================] - 0s 2ms/step - loss: 0.3994 - accuracy: 0.8509 - val_loss: 0.4353 - val_accuracy: 0.8466\n",
      "Epoch 382/1000\n",
      "225/225 [==============================] - 0s 2ms/step - loss: 0.3957 - accuracy: 0.8529 - val_loss: 0.4357 - val_accuracy: 0.8442\n",
      "Epoch 383/1000\n",
      "225/225 [==============================] - 0s 2ms/step - loss: 0.3963 - accuracy: 0.8520 - val_loss: 0.4382 - val_accuracy: 0.8429\n",
      "Epoch 384/1000\n",
      "225/225 [==============================] - 0s 2ms/step - loss: 0.3961 - accuracy: 0.8532 - val_loss: 0.4343 - val_accuracy: 0.8510\n",
      "Epoch 385/1000\n",
      "225/225 [==============================] - 0s 2ms/step - loss: 0.3985 - accuracy: 0.8518 - val_loss: 0.4418 - val_accuracy: 0.8413\n",
      "Epoch 386/1000\n",
      "225/225 [==============================] - 0s 2ms/step - loss: 0.3980 - accuracy: 0.8514 - val_loss: 0.4328 - val_accuracy: 0.8462\n",
      "Epoch 387/1000\n",
      "225/225 [==============================] - 0s 2ms/step - loss: 0.3973 - accuracy: 0.8529 - val_loss: 0.4381 - val_accuracy: 0.8446\n",
      "Epoch 388/1000\n",
      "225/225 [==============================] - 0s 2ms/step - loss: 0.3951 - accuracy: 0.8531 - val_loss: 0.4347 - val_accuracy: 0.8456\n",
      "Epoch 389/1000\n",
      "225/225 [==============================] - 0s 2ms/step - loss: 0.3949 - accuracy: 0.8533 - val_loss: 0.4367 - val_accuracy: 0.8460\n",
      "Epoch 390/1000\n",
      "225/225 [==============================] - 0s 2ms/step - loss: 0.3947 - accuracy: 0.8531 - val_loss: 0.4302 - val_accuracy: 0.8480\n",
      "Epoch 391/1000\n",
      "225/225 [==============================] - 0s 2ms/step - loss: 0.3949 - accuracy: 0.8546 - val_loss: 0.4243 - val_accuracy: 0.8497\n",
      "Epoch 392/1000\n",
      "225/225 [==============================] - 0s 2ms/step - loss: 0.3946 - accuracy: 0.8534 - val_loss: 0.4299 - val_accuracy: 0.8487\n",
      "Epoch 393/1000\n",
      "225/225 [==============================] - 0s 2ms/step - loss: 0.3956 - accuracy: 0.8536 - val_loss: 0.4447 - val_accuracy: 0.8449\n",
      "Epoch 394/1000\n",
      "225/225 [==============================] - 0s 2ms/step - loss: 0.3955 - accuracy: 0.8520 - val_loss: 0.4354 - val_accuracy: 0.8448\n",
      "Epoch 395/1000\n",
      "225/225 [==============================] - 0s 2ms/step - loss: 0.3929 - accuracy: 0.8537 - val_loss: 0.4276 - val_accuracy: 0.8467\n",
      "Epoch 396/1000\n",
      "225/225 [==============================] - 0s 2ms/step - loss: 0.3955 - accuracy: 0.8533 - val_loss: 0.4275 - val_accuracy: 0.8455\n",
      "Epoch 397/1000\n",
      "225/225 [==============================] - 0s 2ms/step - loss: 0.3933 - accuracy: 0.8542 - val_loss: 0.4364 - val_accuracy: 0.8464\n",
      "Epoch 398/1000\n",
      "225/225 [==============================] - 0s 2ms/step - loss: 0.3943 - accuracy: 0.8533 - val_loss: 0.4311 - val_accuracy: 0.8471\n",
      "Epoch 399/1000\n",
      "225/225 [==============================] - 0s 2ms/step - loss: 0.3930 - accuracy: 0.8542 - val_loss: 0.4421 - val_accuracy: 0.8460\n",
      "Epoch 400/1000\n",
      "225/225 [==============================] - 0s 2ms/step - loss: 0.3945 - accuracy: 0.8539 - val_loss: 0.4327 - val_accuracy: 0.8427\n",
      "Epoch 401/1000\n",
      "225/225 [==============================] - 0s 2ms/step - loss: 0.3956 - accuracy: 0.8533 - val_loss: 0.4287 - val_accuracy: 0.8457\n",
      "Epoch 402/1000\n",
      "225/225 [==============================] - 0s 2ms/step - loss: 0.3946 - accuracy: 0.8536 - val_loss: 0.4446 - val_accuracy: 0.8417\n",
      "Epoch 403/1000\n",
      "225/225 [==============================] - 0s 2ms/step - loss: 0.3947 - accuracy: 0.8533 - val_loss: 0.4319 - val_accuracy: 0.8450\n",
      "Epoch 404/1000\n",
      "225/225 [==============================] - 0s 2ms/step - loss: 0.3959 - accuracy: 0.8540 - val_loss: 0.4473 - val_accuracy: 0.8421\n",
      "Epoch 405/1000\n",
      "225/225 [==============================] - 0s 2ms/step - loss: 0.3939 - accuracy: 0.8539 - val_loss: 0.4325 - val_accuracy: 0.8474\n",
      "Epoch 406/1000\n",
      "225/225 [==============================] - 0s 2ms/step - loss: 0.3962 - accuracy: 0.8523 - val_loss: 0.4286 - val_accuracy: 0.8439\n",
      "Epoch 407/1000\n",
      "225/225 [==============================] - 0s 2ms/step - loss: 0.3923 - accuracy: 0.8546 - val_loss: 0.4369 - val_accuracy: 0.8467\n",
      "Epoch 408/1000\n",
      "225/225 [==============================] - 0s 2ms/step - loss: 0.3936 - accuracy: 0.8531 - val_loss: 0.4317 - val_accuracy: 0.8450\n",
      "Epoch 409/1000\n",
      "225/225 [==============================] - 0s 2ms/step - loss: 0.3982 - accuracy: 0.8531 - val_loss: 0.4315 - val_accuracy: 0.8438\n",
      "Epoch 410/1000\n",
      "225/225 [==============================] - 0s 2ms/step - loss: 0.3955 - accuracy: 0.8525 - val_loss: 0.4262 - val_accuracy: 0.8473\n",
      "Epoch 411/1000\n",
      "225/225 [==============================] - 0s 2ms/step - loss: 0.3949 - accuracy: 0.8529 - val_loss: 0.4342 - val_accuracy: 0.8485\n",
      "Epoch 412/1000\n",
      "225/225 [==============================] - 0s 2ms/step - loss: 0.3954 - accuracy: 0.8539 - val_loss: 0.4270 - val_accuracy: 0.8482\n",
      "Epoch 413/1000\n",
      "225/225 [==============================] - 0s 2ms/step - loss: 0.3931 - accuracy: 0.8544 - val_loss: 0.4399 - val_accuracy: 0.8435\n",
      "Epoch 414/1000\n",
      "225/225 [==============================] - 0s 2ms/step - loss: 0.3949 - accuracy: 0.8536 - val_loss: 0.4385 - val_accuracy: 0.8446\n",
      "Epoch 415/1000\n",
      "225/225 [==============================] - 0s 2ms/step - loss: 0.3944 - accuracy: 0.8538 - val_loss: 0.4336 - val_accuracy: 0.8481\n",
      "Epoch 416/1000\n",
      "225/225 [==============================] - 0s 2ms/step - loss: 0.3938 - accuracy: 0.8531 - val_loss: 0.4269 - val_accuracy: 0.8491\n",
      "Epoch 417/1000\n",
      "225/225 [==============================] - 0s 2ms/step - loss: 0.3926 - accuracy: 0.8536 - val_loss: 0.4318 - val_accuracy: 0.8455\n",
      "Epoch 418/1000\n",
      "225/225 [==============================] - 0s 2ms/step - loss: 0.3930 - accuracy: 0.8536 - val_loss: 0.4376 - val_accuracy: 0.8445\n",
      "Epoch 419/1000\n",
      "225/225 [==============================] - 0s 2ms/step - loss: 0.3931 - accuracy: 0.8545 - val_loss: 0.4353 - val_accuracy: 0.8439\n",
      "Epoch 420/1000\n",
      "225/225 [==============================] - 0s 2ms/step - loss: 0.3939 - accuracy: 0.8545 - val_loss: 0.4377 - val_accuracy: 0.8461\n",
      "Epoch 421/1000\n",
      "225/225 [==============================] - 0s 2ms/step - loss: 0.3920 - accuracy: 0.8539 - val_loss: 0.4333 - val_accuracy: 0.8460\n",
      "Epoch 422/1000\n",
      "225/225 [==============================] - 0s 2ms/step - loss: 0.3927 - accuracy: 0.8535 - val_loss: 0.4285 - val_accuracy: 0.8456\n",
      "Epoch 423/1000\n",
      "225/225 [==============================] - 0s 2ms/step - loss: 0.3947 - accuracy: 0.8538 - val_loss: 0.4314 - val_accuracy: 0.8499\n",
      "Epoch 424/1000\n",
      "225/225 [==============================] - 0s 2ms/step - loss: 0.3943 - accuracy: 0.8529 - val_loss: 0.4275 - val_accuracy: 0.8477\n",
      "Epoch 425/1000\n",
      "225/225 [==============================] - 0s 2ms/step - loss: 0.3937 - accuracy: 0.8543 - val_loss: 0.4276 - val_accuracy: 0.8459\n",
      "Epoch 426/1000\n",
      "225/225 [==============================] - 0s 2ms/step - loss: 0.3923 - accuracy: 0.8543 - val_loss: 0.4323 - val_accuracy: 0.8476\n",
      "Epoch 427/1000\n",
      "225/225 [==============================] - 0s 2ms/step - loss: 0.3923 - accuracy: 0.8539 - val_loss: 0.4227 - val_accuracy: 0.8464\n",
      "Epoch 428/1000\n",
      "225/225 [==============================] - 0s 2ms/step - loss: 0.3916 - accuracy: 0.8543 - val_loss: 0.4347 - val_accuracy: 0.8478\n",
      "Epoch 429/1000\n",
      "225/225 [==============================] - 0s 2ms/step - loss: 0.3921 - accuracy: 0.8542 - val_loss: 0.4432 - val_accuracy: 0.8450\n",
      "Epoch 430/1000\n",
      "225/225 [==============================] - 0s 2ms/step - loss: 0.3909 - accuracy: 0.8545 - val_loss: 0.4348 - val_accuracy: 0.8436\n",
      "Epoch 431/1000\n",
      "225/225 [==============================] - 0s 2ms/step - loss: 0.3927 - accuracy: 0.8530 - val_loss: 0.4367 - val_accuracy: 0.8462\n",
      "Epoch 432/1000\n",
      "225/225 [==============================] - 0s 2ms/step - loss: 0.3939 - accuracy: 0.8532 - val_loss: 0.4275 - val_accuracy: 0.8465\n",
      "Epoch 433/1000\n",
      "225/225 [==============================] - 0s 2ms/step - loss: 0.3949 - accuracy: 0.8527 - val_loss: 0.4363 - val_accuracy: 0.8460\n",
      "Epoch 434/1000\n",
      "225/225 [==============================] - 0s 2ms/step - loss: 0.3942 - accuracy: 0.8538 - val_loss: 0.4350 - val_accuracy: 0.8423\n",
      "Epoch 435/1000\n",
      "225/225 [==============================] - 0s 2ms/step - loss: 0.3946 - accuracy: 0.8533 - val_loss: 0.4379 - val_accuracy: 0.8434\n",
      "Epoch 436/1000\n",
      "225/225 [==============================] - 0s 2ms/step - loss: 0.3933 - accuracy: 0.8535 - val_loss: 0.4431 - val_accuracy: 0.8427\n",
      "Epoch 437/1000\n",
      "225/225 [==============================] - 0s 2ms/step - loss: 0.3942 - accuracy: 0.8535 - val_loss: 0.4361 - val_accuracy: 0.8471\n",
      "Epoch 438/1000\n",
      "225/225 [==============================] - 0s 2ms/step - loss: 0.3941 - accuracy: 0.8528 - val_loss: 0.4295 - val_accuracy: 0.8460\n",
      "Epoch 439/1000\n",
      "225/225 [==============================] - 0s 2ms/step - loss: 0.3950 - accuracy: 0.8540 - val_loss: 0.4390 - val_accuracy: 0.8447\n",
      "Epoch 440/1000\n",
      "225/225 [==============================] - 0s 2ms/step - loss: 0.3930 - accuracy: 0.8536 - val_loss: 0.4302 - val_accuracy: 0.8471\n",
      "Epoch 441/1000\n",
      "225/225 [==============================] - 0s 2ms/step - loss: 0.3919 - accuracy: 0.8545 - val_loss: 0.4391 - val_accuracy: 0.8449\n",
      "Epoch 442/1000\n",
      "225/225 [==============================] - 0s 2ms/step - loss: 0.3912 - accuracy: 0.8549 - val_loss: 0.4342 - val_accuracy: 0.8461\n",
      "Epoch 443/1000\n",
      "225/225 [==============================] - 0s 2ms/step - loss: 0.3925 - accuracy: 0.8538 - val_loss: 0.4409 - val_accuracy: 0.8466\n",
      "Epoch 444/1000\n",
      "225/225 [==============================] - 0s 2ms/step - loss: 0.3919 - accuracy: 0.8546 - val_loss: 0.4375 - val_accuracy: 0.8470\n",
      "Epoch 445/1000\n",
      "225/225 [==============================] - 0s 2ms/step - loss: 0.3919 - accuracy: 0.8547 - val_loss: 0.4288 - val_accuracy: 0.8471\n",
      "Epoch 446/1000\n",
      "225/225 [==============================] - 0s 2ms/step - loss: 0.3929 - accuracy: 0.8537 - val_loss: 0.4276 - val_accuracy: 0.8462\n",
      "Epoch 447/1000\n",
      "225/225 [==============================] - 0s 2ms/step - loss: 0.3925 - accuracy: 0.8557 - val_loss: 0.4367 - val_accuracy: 0.8478\n",
      "Epoch 448/1000\n",
      "225/225 [==============================] - 0s 2ms/step - loss: 0.3947 - accuracy: 0.8537 - val_loss: 0.4283 - val_accuracy: 0.8489\n",
      "Epoch 449/1000\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "225/225 [==============================] - 0s 2ms/step - loss: 0.3898 - accuracy: 0.8553 - val_loss: 0.4355 - val_accuracy: 0.8443\n",
      "Epoch 450/1000\n",
      "225/225 [==============================] - 0s 2ms/step - loss: 0.3935 - accuracy: 0.8545 - val_loss: 0.4359 - val_accuracy: 0.8481\n",
      "Epoch 451/1000\n",
      "225/225 [==============================] - 0s 2ms/step - loss: 0.3932 - accuracy: 0.8537 - val_loss: 0.4431 - val_accuracy: 0.8449\n",
      "Epoch 452/1000\n",
      "225/225 [==============================] - 0s 2ms/step - loss: 0.3935 - accuracy: 0.8537 - val_loss: 0.4280 - val_accuracy: 0.8491\n",
      "Epoch 453/1000\n",
      "225/225 [==============================] - 0s 2ms/step - loss: 0.3918 - accuracy: 0.8546 - val_loss: 0.4408 - val_accuracy: 0.8455\n",
      "Epoch 454/1000\n",
      "225/225 [==============================] - 0s 2ms/step - loss: 0.3898 - accuracy: 0.8548 - val_loss: 0.4347 - val_accuracy: 0.8481\n",
      "Epoch 455/1000\n",
      "225/225 [==============================] - 0s 2ms/step - loss: 0.3924 - accuracy: 0.8548 - val_loss: 0.4367 - val_accuracy: 0.8467\n",
      "Epoch 456/1000\n",
      "225/225 [==============================] - 0s 2ms/step - loss: 0.3906 - accuracy: 0.8558 - val_loss: 0.4382 - val_accuracy: 0.8463\n",
      "Epoch 457/1000\n",
      "225/225 [==============================] - 0s 2ms/step - loss: 0.3929 - accuracy: 0.8535 - val_loss: 0.4418 - val_accuracy: 0.8445\n",
      "Epoch 458/1000\n",
      "225/225 [==============================] - 0s 2ms/step - loss: 0.3931 - accuracy: 0.8542 - val_loss: 0.4402 - val_accuracy: 0.8439\n",
      "Epoch 459/1000\n",
      "225/225 [==============================] - 0s 2ms/step - loss: 0.3908 - accuracy: 0.8554 - val_loss: 0.4433 - val_accuracy: 0.8431\n",
      "Epoch 460/1000\n",
      "225/225 [==============================] - 0s 2ms/step - loss: 0.3947 - accuracy: 0.8535 - val_loss: 0.4263 - val_accuracy: 0.8479\n",
      "Epoch 461/1000\n",
      "225/225 [==============================] - 0s 2ms/step - loss: 0.3909 - accuracy: 0.8548 - val_loss: 0.4368 - val_accuracy: 0.8461\n",
      "Epoch 462/1000\n",
      "225/225 [==============================] - 0s 2ms/step - loss: 0.3933 - accuracy: 0.8541 - val_loss: 0.4300 - val_accuracy: 0.8462\n",
      "Epoch 463/1000\n",
      "225/225 [==============================] - 0s 2ms/step - loss: 0.3908 - accuracy: 0.8553 - val_loss: 0.4367 - val_accuracy: 0.8416\n",
      "Epoch 464/1000\n",
      "225/225 [==============================] - 0s 2ms/step - loss: 0.3911 - accuracy: 0.8548 - val_loss: 0.4279 - val_accuracy: 0.8451\n",
      "Epoch 465/1000\n",
      "225/225 [==============================] - 0s 2ms/step - loss: 0.3912 - accuracy: 0.8557 - val_loss: 0.4372 - val_accuracy: 0.8483\n",
      "Epoch 466/1000\n",
      "225/225 [==============================] - 0s 2ms/step - loss: 0.3922 - accuracy: 0.8543 - val_loss: 0.4404 - val_accuracy: 0.8438\n",
      "Epoch 467/1000\n",
      "225/225 [==============================] - 0s 2ms/step - loss: 0.3913 - accuracy: 0.8555 - val_loss: 0.4276 - val_accuracy: 0.8463\n",
      "Epoch 468/1000\n",
      "225/225 [==============================] - 0s 2ms/step - loss: 0.3908 - accuracy: 0.8541 - val_loss: 0.4336 - val_accuracy: 0.8447\n",
      "Epoch 469/1000\n",
      "225/225 [==============================] - 0s 2ms/step - loss: 0.3922 - accuracy: 0.8542 - val_loss: 0.4305 - val_accuracy: 0.8473\n",
      "Epoch 470/1000\n",
      "225/225 [==============================] - 0s 2ms/step - loss: 0.3926 - accuracy: 0.8551 - val_loss: 0.4311 - val_accuracy: 0.8498\n",
      "Epoch 471/1000\n",
      "225/225 [==============================] - 0s 2ms/step - loss: 0.3929 - accuracy: 0.8546 - val_loss: 0.4387 - val_accuracy: 0.8467\n",
      "Epoch 472/1000\n",
      "225/225 [==============================] - 0s 2ms/step - loss: 0.3942 - accuracy: 0.8543 - val_loss: 0.4286 - val_accuracy: 0.8494\n",
      "Epoch 473/1000\n",
      "225/225 [==============================] - 0s 2ms/step - loss: 0.3899 - accuracy: 0.8551 - val_loss: 0.4402 - val_accuracy: 0.8452\n",
      "Epoch 474/1000\n",
      "225/225 [==============================] - 0s 2ms/step - loss: 0.3914 - accuracy: 0.8548 - val_loss: 0.4447 - val_accuracy: 0.8438\n",
      "Epoch 475/1000\n",
      "225/225 [==============================] - 0s 2ms/step - loss: 0.3917 - accuracy: 0.8555 - val_loss: 0.4305 - val_accuracy: 0.8455\n",
      "Epoch 476/1000\n",
      "225/225 [==============================] - 0s 2ms/step - loss: 0.3928 - accuracy: 0.8551 - val_loss: 0.4358 - val_accuracy: 0.8477\n",
      "Epoch 477/1000\n",
      "225/225 [==============================] - 0s 2ms/step - loss: 0.3951 - accuracy: 0.8537 - val_loss: 0.4280 - val_accuracy: 0.8465\n",
      "Epoch 478/1000\n",
      "225/225 [==============================] - 0s 2ms/step - loss: 0.3904 - accuracy: 0.8552 - val_loss: 0.4423 - val_accuracy: 0.8456\n",
      "Epoch 479/1000\n",
      "225/225 [==============================] - 0s 2ms/step - loss: 0.3898 - accuracy: 0.8542 - val_loss: 0.4294 - val_accuracy: 0.8473\n",
      "Epoch 480/1000\n",
      "225/225 [==============================] - 0s 2ms/step - loss: 0.3892 - accuracy: 0.8559 - val_loss: 0.4393 - val_accuracy: 0.8458\n",
      "Epoch 481/1000\n",
      "225/225 [==============================] - 0s 2ms/step - loss: 0.3910 - accuracy: 0.8556 - val_loss: 0.4351 - val_accuracy: 0.8498\n",
      "Epoch 482/1000\n",
      "225/225 [==============================] - 0s 2ms/step - loss: 0.3900 - accuracy: 0.8551 - val_loss: 0.4370 - val_accuracy: 0.8483\n",
      "Epoch 483/1000\n",
      "225/225 [==============================] - 0s 2ms/step - loss: 0.3928 - accuracy: 0.8547 - val_loss: 0.4306 - val_accuracy: 0.8460\n",
      "Epoch 484/1000\n",
      "225/225 [==============================] - 0s 2ms/step - loss: 0.3904 - accuracy: 0.8545 - val_loss: 0.4320 - val_accuracy: 0.8467\n",
      "Epoch 485/1000\n",
      "225/225 [==============================] - 0s 2ms/step - loss: 0.3911 - accuracy: 0.8551 - val_loss: 0.4344 - val_accuracy: 0.8454\n",
      "Epoch 486/1000\n",
      "225/225 [==============================] - 0s 2ms/step - loss: 0.3909 - accuracy: 0.8547 - val_loss: 0.4276 - val_accuracy: 0.8489\n",
      "Epoch 487/1000\n",
      "225/225 [==============================] - 0s 2ms/step - loss: 0.3905 - accuracy: 0.8543 - val_loss: 0.4334 - val_accuracy: 0.8480\n",
      "Epoch 488/1000\n",
      "225/225 [==============================] - 0s 2ms/step - loss: 0.3896 - accuracy: 0.8561 - val_loss: 0.4448 - val_accuracy: 0.8410\n",
      "Epoch 489/1000\n",
      "225/225 [==============================] - 0s 2ms/step - loss: 0.3898 - accuracy: 0.8554 - val_loss: 0.4327 - val_accuracy: 0.8485\n",
      "Epoch 490/1000\n",
      "225/225 [==============================] - 0s 2ms/step - loss: 0.3898 - accuracy: 0.8551 - val_loss: 0.4421 - val_accuracy: 0.8484\n",
      "Epoch 491/1000\n",
      "225/225 [==============================] - 0s 2ms/step - loss: 0.3891 - accuracy: 0.8551 - val_loss: 0.4326 - val_accuracy: 0.8496\n",
      "Epoch 492/1000\n",
      "225/225 [==============================] - 0s 2ms/step - loss: 0.3917 - accuracy: 0.8541 - val_loss: 0.4324 - val_accuracy: 0.8460\n",
      "Epoch 493/1000\n",
      "225/225 [==============================] - 0s 2ms/step - loss: 0.3916 - accuracy: 0.8537 - val_loss: 0.4328 - val_accuracy: 0.8468\n",
      "Epoch 494/1000\n",
      "225/225 [==============================] - 0s 2ms/step - loss: 0.3916 - accuracy: 0.8543 - val_loss: 0.4315 - val_accuracy: 0.8478\n",
      "Epoch 495/1000\n",
      "225/225 [==============================] - 0s 2ms/step - loss: 0.3909 - accuracy: 0.8544 - val_loss: 0.4353 - val_accuracy: 0.8456\n",
      "Epoch 496/1000\n",
      "225/225 [==============================] - 0s 2ms/step - loss: 0.3893 - accuracy: 0.8552 - val_loss: 0.4338 - val_accuracy: 0.8486\n",
      "Epoch 497/1000\n",
      "225/225 [==============================] - 0s 2ms/step - loss: 0.3911 - accuracy: 0.8552 - val_loss: 0.4400 - val_accuracy: 0.8462\n",
      "Epoch 498/1000\n",
      "225/225 [==============================] - 0s 2ms/step - loss: 0.3900 - accuracy: 0.8551 - val_loss: 0.4429 - val_accuracy: 0.8438\n",
      "Epoch 499/1000\n",
      "225/225 [==============================] - 0s 2ms/step - loss: 0.3888 - accuracy: 0.8554 - val_loss: 0.4418 - val_accuracy: 0.8466\n",
      "Epoch 500/1000\n",
      "225/225 [==============================] - 0s 2ms/step - loss: 0.3879 - accuracy: 0.8559 - val_loss: 0.4260 - val_accuracy: 0.8494\n",
      "Epoch 501/1000\n",
      "225/225 [==============================] - 0s 2ms/step - loss: 0.3903 - accuracy: 0.8542 - val_loss: 0.4327 - val_accuracy: 0.8474\n",
      "Epoch 502/1000\n",
      "225/225 [==============================] - 0s 2ms/step - loss: 0.3896 - accuracy: 0.8557 - val_loss: 0.4333 - val_accuracy: 0.8500\n",
      "Epoch 503/1000\n",
      "225/225 [==============================] - 0s 2ms/step - loss: 0.3915 - accuracy: 0.8549 - val_loss: 0.4340 - val_accuracy: 0.8498\n",
      "Epoch 504/1000\n",
      "225/225 [==============================] - 0s 2ms/step - loss: 0.3897 - accuracy: 0.8552 - val_loss: 0.4485 - val_accuracy: 0.8458\n",
      "Epoch 505/1000\n",
      "225/225 [==============================] - 0s 2ms/step - loss: 0.3898 - accuracy: 0.8554 - val_loss: 0.4262 - val_accuracy: 0.8490\n",
      "Epoch 506/1000\n",
      "225/225 [==============================] - 0s 2ms/step - loss: 0.3910 - accuracy: 0.8550 - val_loss: 0.4423 - val_accuracy: 0.8449\n",
      "Epoch 507/1000\n",
      "225/225 [==============================] - 0s 2ms/step - loss: 0.3889 - accuracy: 0.8553 - val_loss: 0.4402 - val_accuracy: 0.8482\n",
      "Epoch 508/1000\n",
      "225/225 [==============================] - 0s 2ms/step - loss: 0.3883 - accuracy: 0.8550 - val_loss: 0.4399 - val_accuracy: 0.8478\n",
      "Epoch 509/1000\n",
      "225/225 [==============================] - 0s 2ms/step - loss: 0.3905 - accuracy: 0.8539 - val_loss: 0.4350 - val_accuracy: 0.8480\n",
      "Epoch 510/1000\n",
      "225/225 [==============================] - 0s 2ms/step - loss: 0.3871 - accuracy: 0.8556 - val_loss: 0.4307 - val_accuracy: 0.8489\n",
      "Epoch 511/1000\n",
      "225/225 [==============================] - 0s 2ms/step - loss: 0.3902 - accuracy: 0.8558 - val_loss: 0.4319 - val_accuracy: 0.8487\n",
      "Epoch 512/1000\n",
      "225/225 [==============================] - 0s 2ms/step - loss: 0.3906 - accuracy: 0.8561 - val_loss: 0.4366 - val_accuracy: 0.8454\n",
      "Epoch 513/1000\n",
      "225/225 [==============================] - 0s 2ms/step - loss: 0.3878 - accuracy: 0.8557 - val_loss: 0.4279 - val_accuracy: 0.8476\n",
      "Epoch 514/1000\n",
      "225/225 [==============================] - 0s 2ms/step - loss: 0.3911 - accuracy: 0.8550 - val_loss: 0.4335 - val_accuracy: 0.8437\n",
      "Epoch 515/1000\n",
      "225/225 [==============================] - 0s 2ms/step - loss: 0.3900 - accuracy: 0.8555 - val_loss: 0.4348 - val_accuracy: 0.8506\n",
      "Epoch 516/1000\n",
      "225/225 [==============================] - 0s 2ms/step - loss: 0.3893 - accuracy: 0.8558 - val_loss: 0.4370 - val_accuracy: 0.8467\n",
      "Epoch 517/1000\n",
      "225/225 [==============================] - 0s 2ms/step - loss: 0.3885 - accuracy: 0.8558 - val_loss: 0.4323 - val_accuracy: 0.8490\n",
      "Epoch 517: early stopping\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "<keras.src.callbacks.History at 0x140864ca0>"
      ]
     },
     "execution_count": 203,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "model=Sequential()\n",
    "model.add(Dense(128, input_dim=X_train.shape[1], activation=\"relu\"))\n",
    "\n",
    "model.add(Dense(128, activation=\"relu\"))\n",
    "model.add(Dropout(0.2))\n",
    "model.add(Dense(64, activation=\"relu\"))\n",
    "\n",
    "model.add(Dense(64, activation=\"relu\"))\n",
    "model.add(Dropout(0.2))\n",
    "model.add(Dense(32, activation=\"relu\"))\n",
    "model.add(Dropout(0.2))\n",
    "model.add(Dense(16, activation=\"relu\"))\n",
    "model.add(Dropout(0.2))\n",
    "model.add(Dense(3, activation=\"softmax\"))\n",
    "\n",
    "model.compile(loss='categorical_crossentropy', optimizer='rmsprop', metrics=['accuracy'])\n",
    "\n",
    "es=EarlyStopping(monitor=\"val_loss\",patience=90,mode=\"auto\",verbose=1)\n",
    "#clr = CyclicLR(base_lr=0.001, max_lr=0.02,step_size=1125., mode='triangular')\n",
    "model.fit(X_train, y_train,epochs=1000,batch_size=512,validation_split=0.1,verbose=1,callbacks=[es])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 204,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "997/997 [==============================] - 0s 259us/step\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0       0.86      0.93      0.89     10867\n",
      "           1       0.84      0.90      0.87     10432\n",
      "           2       0.84      0.70      0.77     10591\n",
      "\n",
      "    accuracy                           0.85     31890\n",
      "   macro avg       0.85      0.85      0.84     31890\n",
      "weighted avg       0.85      0.85      0.84     31890\n",
      "\n"
     ]
    }
   ],
   "source": [
    "y_pred = model.predict(X_test)\n",
    "y_pred_classes = np.argmax(y_pred, axis=1)\n",
    "y_true = np.argmax(y_test, axis=1)\n",
    "print(classification_report(y_true, y_pred_classes))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 205,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "3987/3987 [==============================] - 1s 251us/step\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0       0.89      0.96      0.93     42282\n",
      "           1       0.86      0.94      0.90     42717\n",
      "           2       0.91      0.75      0.82     42558\n",
      "\n",
      "    accuracy                           0.89    127557\n",
      "   macro avg       0.89      0.89      0.88    127557\n",
      "weighted avg       0.89      0.89      0.88    127557\n",
      "\n"
     ]
    }
   ],
   "source": [
    "y_t_pred = model.predict(X_train)\n",
    "y_t_pred_classes = np.argmax(y_t_pred, axis=1)\n",
    "y_t_true = np.argmax(y_train, axis=1)\n",
    "print(classification_report(y_t_true, y_t_pred_classes))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 208,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 1/1000\n",
      "225/225 [==============================] - 1s 2ms/step - loss: 0.7923 - accuracy: 0.6782 - val_loss: 0.6784 - val_accuracy: 0.7336\n",
      "Epoch 2/1000\n",
      "225/225 [==============================] - 1s 2ms/step - loss: 0.7036 - accuracy: 0.7341 - val_loss: 0.6596 - val_accuracy: 0.7430\n",
      "Epoch 3/1000\n",
      "225/225 [==============================] - 1s 2ms/step - loss: 0.6818 - accuracy: 0.7405 - val_loss: 0.6514 - val_accuracy: 0.7454\n",
      "Epoch 4/1000\n",
      "225/225 [==============================] - 0s 2ms/step - loss: 0.6688 - accuracy: 0.7447 - val_loss: 0.6343 - val_accuracy: 0.7513\n",
      "Epoch 5/1000\n",
      "225/225 [==============================] - 0s 2ms/step - loss: 0.6571 - accuracy: 0.7484 - val_loss: 0.6297 - val_accuracy: 0.7542\n",
      "Epoch 6/1000\n",
      "225/225 [==============================] - 0s 2ms/step - loss: 0.6451 - accuracy: 0.7527 - val_loss: 0.6182 - val_accuracy: 0.7583\n",
      "Epoch 7/1000\n",
      "225/225 [==============================] - 1s 2ms/step - loss: 0.6371 - accuracy: 0.7573 - val_loss: 0.6087 - val_accuracy: 0.7601\n",
      "Epoch 8/1000\n",
      "225/225 [==============================] - 1s 3ms/step - loss: 0.6260 - accuracy: 0.7606 - val_loss: 0.5989 - val_accuracy: 0.7641\n",
      "Epoch 9/1000\n",
      "225/225 [==============================] - 1s 2ms/step - loss: 0.6176 - accuracy: 0.7634 - val_loss: 0.5969 - val_accuracy: 0.7656\n",
      "Epoch 10/1000\n",
      "225/225 [==============================] - 1s 2ms/step - loss: 0.6076 - accuracy: 0.7670 - val_loss: 0.5875 - val_accuracy: 0.7682\n",
      "Epoch 11/1000\n",
      "225/225 [==============================] - 1s 2ms/step - loss: 0.5991 - accuracy: 0.7708 - val_loss: 0.5764 - val_accuracy: 0.7717\n",
      "Epoch 12/1000\n",
      "225/225 [==============================] - 0s 2ms/step - loss: 0.5917 - accuracy: 0.7752 - val_loss: 0.5699 - val_accuracy: 0.7758\n",
      "Epoch 13/1000\n",
      "225/225 [==============================] - 0s 2ms/step - loss: 0.5850 - accuracy: 0.7757 - val_loss: 0.5597 - val_accuracy: 0.7797\n",
      "Epoch 14/1000\n",
      "225/225 [==============================] - 1s 2ms/step - loss: 0.5797 - accuracy: 0.7783 - val_loss: 0.5567 - val_accuracy: 0.7799\n",
      "Epoch 15/1000\n",
      "225/225 [==============================] - 0s 2ms/step - loss: 0.5709 - accuracy: 0.7818 - val_loss: 0.5575 - val_accuracy: 0.7821\n",
      "Epoch 16/1000\n",
      "225/225 [==============================] - 0s 2ms/step - loss: 0.5646 - accuracy: 0.7837 - val_loss: 0.5419 - val_accuracy: 0.7891\n",
      "Epoch 17/1000\n",
      "225/225 [==============================] - 0s 2ms/step - loss: 0.5601 - accuracy: 0.7865 - val_loss: 0.5416 - val_accuracy: 0.7903\n",
      "Epoch 18/1000\n",
      "225/225 [==============================] - 1s 2ms/step - loss: 0.5530 - accuracy: 0.7878 - val_loss: 0.5363 - val_accuracy: 0.7884\n",
      "Epoch 19/1000\n",
      "225/225 [==============================] - 1s 2ms/step - loss: 0.5485 - accuracy: 0.7906 - val_loss: 0.5349 - val_accuracy: 0.7908\n",
      "Epoch 20/1000\n",
      "225/225 [==============================] - 1s 2ms/step - loss: 0.5428 - accuracy: 0.7924 - val_loss: 0.5317 - val_accuracy: 0.7914\n",
      "Epoch 21/1000\n",
      "225/225 [==============================] - 1s 2ms/step - loss: 0.5394 - accuracy: 0.7921 - val_loss: 0.5312 - val_accuracy: 0.7908\n",
      "Epoch 22/1000\n",
      "225/225 [==============================] - 1s 2ms/step - loss: 0.5341 - accuracy: 0.7953 - val_loss: 0.5192 - val_accuracy: 0.7995\n",
      "Epoch 23/1000\n",
      "225/225 [==============================] - 1s 3ms/step - loss: 0.5299 - accuracy: 0.7982 - val_loss: 0.5212 - val_accuracy: 0.7960\n",
      "Epoch 24/1000\n",
      "225/225 [==============================] - 1s 2ms/step - loss: 0.5255 - accuracy: 0.7989 - val_loss: 0.5146 - val_accuracy: 0.7995\n",
      "Epoch 25/1000\n",
      "225/225 [==============================] - 1s 2ms/step - loss: 0.5185 - accuracy: 0.8017 - val_loss: 0.5091 - val_accuracy: 0.8006\n",
      "Epoch 26/1000\n",
      "225/225 [==============================] - 1s 2ms/step - loss: 0.5137 - accuracy: 0.8036 - val_loss: 0.5056 - val_accuracy: 0.7999\n",
      "Epoch 27/1000\n",
      "225/225 [==============================] - 1s 2ms/step - loss: 0.5128 - accuracy: 0.8037 - val_loss: 0.5049 - val_accuracy: 0.8032\n",
      "Epoch 28/1000\n",
      "225/225 [==============================] - 1s 2ms/step - loss: 0.5087 - accuracy: 0.8053 - val_loss: 0.5036 - val_accuracy: 0.8053\n",
      "Epoch 29/1000\n",
      "225/225 [==============================] - 1s 2ms/step - loss: 0.5077 - accuracy: 0.8066 - val_loss: 0.5019 - val_accuracy: 0.8065\n",
      "Epoch 30/1000\n",
      "225/225 [==============================] - 1s 2ms/step - loss: 0.5022 - accuracy: 0.8089 - val_loss: 0.4965 - val_accuracy: 0.8076\n",
      "Epoch 31/1000\n",
      "225/225 [==============================] - 1s 2ms/step - loss: 0.4995 - accuracy: 0.8081 - val_loss: 0.4988 - val_accuracy: 0.8071\n",
      "Epoch 32/1000\n",
      "225/225 [==============================] - 1s 2ms/step - loss: 0.4983 - accuracy: 0.8088 - val_loss: 0.4917 - val_accuracy: 0.8104\n",
      "Epoch 33/1000\n",
      "225/225 [==============================] - 0s 2ms/step - loss: 0.4948 - accuracy: 0.8104 - val_loss: 0.4943 - val_accuracy: 0.8112\n",
      "Epoch 34/1000\n",
      "225/225 [==============================] - 0s 2ms/step - loss: 0.4909 - accuracy: 0.8116 - val_loss: 0.4935 - val_accuracy: 0.8098\n",
      "Epoch 35/1000\n",
      "225/225 [==============================] - 0s 2ms/step - loss: 0.4889 - accuracy: 0.8136 - val_loss: 0.4875 - val_accuracy: 0.8114\n",
      "Epoch 36/1000\n",
      "225/225 [==============================] - 0s 2ms/step - loss: 0.4845 - accuracy: 0.8153 - val_loss: 0.4895 - val_accuracy: 0.8107\n",
      "Epoch 37/1000\n",
      "225/225 [==============================] - 0s 2ms/step - loss: 0.4844 - accuracy: 0.8153 - val_loss: 0.4827 - val_accuracy: 0.8125\n",
      "Epoch 38/1000\n",
      "225/225 [==============================] - 1s 2ms/step - loss: 0.4808 - accuracy: 0.8164 - val_loss: 0.4849 - val_accuracy: 0.8137\n",
      "Epoch 39/1000\n",
      "225/225 [==============================] - 1s 2ms/step - loss: 0.4807 - accuracy: 0.8180 - val_loss: 0.4798 - val_accuracy: 0.8164\n",
      "Epoch 40/1000\n",
      "225/225 [==============================] - 0s 2ms/step - loss: 0.4784 - accuracy: 0.8169 - val_loss: 0.4799 - val_accuracy: 0.8155\n",
      "Epoch 41/1000\n",
      "225/225 [==============================] - 0s 2ms/step - loss: 0.4747 - accuracy: 0.8189 - val_loss: 0.4784 - val_accuracy: 0.8147\n",
      "Epoch 42/1000\n",
      "225/225 [==============================] - 0s 2ms/step - loss: 0.4738 - accuracy: 0.8196 - val_loss: 0.4749 - val_accuracy: 0.8175\n",
      "Epoch 43/1000\n",
      "225/225 [==============================] - 0s 2ms/step - loss: 0.4731 - accuracy: 0.8201 - val_loss: 0.4717 - val_accuracy: 0.8218\n",
      "Epoch 44/1000\n",
      "225/225 [==============================] - 0s 2ms/step - loss: 0.4702 - accuracy: 0.8213 - val_loss: 0.4736 - val_accuracy: 0.8199\n",
      "Epoch 45/1000\n",
      "225/225 [==============================] - 0s 2ms/step - loss: 0.4681 - accuracy: 0.8212 - val_loss: 0.4760 - val_accuracy: 0.8192\n",
      "Epoch 46/1000\n",
      "225/225 [==============================] - 0s 2ms/step - loss: 0.4678 - accuracy: 0.8215 - val_loss: 0.4728 - val_accuracy: 0.8192\n",
      "Epoch 47/1000\n",
      "225/225 [==============================] - 0s 2ms/step - loss: 0.4652 - accuracy: 0.8225 - val_loss: 0.4719 - val_accuracy: 0.8198\n",
      "Epoch 48/1000\n",
      "225/225 [==============================] - 0s 2ms/step - loss: 0.4642 - accuracy: 0.8222 - val_loss: 0.4666 - val_accuracy: 0.8228\n",
      "Epoch 49/1000\n",
      "225/225 [==============================] - 1s 2ms/step - loss: 0.4621 - accuracy: 0.8248 - val_loss: 0.4709 - val_accuracy: 0.8197\n",
      "Epoch 50/1000\n",
      "225/225 [==============================] - 1s 2ms/step - loss: 0.4593 - accuracy: 0.8257 - val_loss: 0.4674 - val_accuracy: 0.8191\n",
      "Epoch 51/1000\n",
      "225/225 [==============================] - 0s 2ms/step - loss: 0.4595 - accuracy: 0.8250 - val_loss: 0.4678 - val_accuracy: 0.8197\n",
      "Epoch 52/1000\n",
      "225/225 [==============================] - 1s 2ms/step - loss: 0.4595 - accuracy: 0.8254 - val_loss: 0.4677 - val_accuracy: 0.8207\n",
      "Epoch 53/1000\n",
      "225/225 [==============================] - 1s 2ms/step - loss: 0.4580 - accuracy: 0.8256 - val_loss: 0.4651 - val_accuracy: 0.8214\n",
      "Epoch 54/1000\n",
      "225/225 [==============================] - 1s 2ms/step - loss: 0.4565 - accuracy: 0.8268 - val_loss: 0.4609 - val_accuracy: 0.8264\n",
      "Epoch 55/1000\n",
      "225/225 [==============================] - 1s 2ms/step - loss: 0.4554 - accuracy: 0.8266 - val_loss: 0.4610 - val_accuracy: 0.8278\n",
      "Epoch 56/1000\n",
      "225/225 [==============================] - 1s 2ms/step - loss: 0.4525 - accuracy: 0.8278 - val_loss: 0.4614 - val_accuracy: 0.8255\n",
      "Epoch 57/1000\n",
      "225/225 [==============================] - 1s 2ms/step - loss: 0.4519 - accuracy: 0.8275 - val_loss: 0.4607 - val_accuracy: 0.8268\n",
      "Epoch 58/1000\n",
      "225/225 [==============================] - 0s 2ms/step - loss: 0.4509 - accuracy: 0.8275 - val_loss: 0.4613 - val_accuracy: 0.8264\n",
      "Epoch 59/1000\n",
      "225/225 [==============================] - 0s 2ms/step - loss: 0.4502 - accuracy: 0.8293 - val_loss: 0.4537 - val_accuracy: 0.8275\n",
      "Epoch 60/1000\n",
      "225/225 [==============================] - 0s 2ms/step - loss: 0.4497 - accuracy: 0.8294 - val_loss: 0.4571 - val_accuracy: 0.8258\n",
      "Epoch 61/1000\n",
      "225/225 [==============================] - 1s 2ms/step - loss: 0.4494 - accuracy: 0.8284 - val_loss: 0.4596 - val_accuracy: 0.8271\n",
      "Epoch 62/1000\n",
      "225/225 [==============================] - 1s 2ms/step - loss: 0.4475 - accuracy: 0.8301 - val_loss: 0.4601 - val_accuracy: 0.8262\n",
      "Epoch 63/1000\n",
      "225/225 [==============================] - 1s 2ms/step - loss: 0.4452 - accuracy: 0.8310 - val_loss: 0.4639 - val_accuracy: 0.8265\n",
      "Epoch 64/1000\n",
      "225/225 [==============================] - 1s 2ms/step - loss: 0.4464 - accuracy: 0.8311 - val_loss: 0.4596 - val_accuracy: 0.8282\n",
      "Epoch 65/1000\n",
      "225/225 [==============================] - 0s 2ms/step - loss: 0.4417 - accuracy: 0.8323 - val_loss: 0.4505 - val_accuracy: 0.8315\n",
      "Epoch 66/1000\n",
      "225/225 [==============================] - 0s 2ms/step - loss: 0.4442 - accuracy: 0.8314 - val_loss: 0.4521 - val_accuracy: 0.8296\n",
      "Epoch 67/1000\n",
      "225/225 [==============================] - 0s 2ms/step - loss: 0.4435 - accuracy: 0.8314 - val_loss: 0.4500 - val_accuracy: 0.8264\n",
      "Epoch 68/1000\n",
      "225/225 [==============================] - 0s 2ms/step - loss: 0.4389 - accuracy: 0.8328 - val_loss: 0.4572 - val_accuracy: 0.8308\n",
      "Epoch 69/1000\n",
      "225/225 [==============================] - 0s 2ms/step - loss: 0.4387 - accuracy: 0.8329 - val_loss: 0.4534 - val_accuracy: 0.8293\n",
      "Epoch 70/1000\n",
      "225/225 [==============================] - 1s 2ms/step - loss: 0.4395 - accuracy: 0.8331 - val_loss: 0.4499 - val_accuracy: 0.8296\n",
      "Epoch 71/1000\n",
      "225/225 [==============================] - 1s 3ms/step - loss: 0.4382 - accuracy: 0.8332 - val_loss: 0.4512 - val_accuracy: 0.8293\n",
      "Epoch 72/1000\n",
      "225/225 [==============================] - 0s 2ms/step - loss: 0.4375 - accuracy: 0.8332 - val_loss: 0.4555 - val_accuracy: 0.8279\n",
      "Epoch 73/1000\n",
      "225/225 [==============================] - 0s 2ms/step - loss: 0.4378 - accuracy: 0.8325 - val_loss: 0.4502 - val_accuracy: 0.8288\n",
      "Epoch 74/1000\n",
      "225/225 [==============================] - 0s 2ms/step - loss: 0.4362 - accuracy: 0.8339 - val_loss: 0.4501 - val_accuracy: 0.8291\n",
      "Epoch 75/1000\n",
      "225/225 [==============================] - 0s 2ms/step - loss: 0.4366 - accuracy: 0.8340 - val_loss: 0.4524 - val_accuracy: 0.8327\n",
      "Epoch 76/1000\n",
      "225/225 [==============================] - 0s 2ms/step - loss: 0.4343 - accuracy: 0.8360 - val_loss: 0.4483 - val_accuracy: 0.8297\n",
      "Epoch 77/1000\n",
      "225/225 [==============================] - 0s 2ms/step - loss: 0.4323 - accuracy: 0.8363 - val_loss: 0.4470 - val_accuracy: 0.8339\n",
      "Epoch 78/1000\n",
      "225/225 [==============================] - 0s 2ms/step - loss: 0.4282 - accuracy: 0.8375 - val_loss: 0.4486 - val_accuracy: 0.8317\n",
      "Epoch 79/1000\n",
      "225/225 [==============================] - 0s 2ms/step - loss: 0.4318 - accuracy: 0.8360 - val_loss: 0.4437 - val_accuracy: 0.8336\n",
      "Epoch 80/1000\n",
      "225/225 [==============================] - 0s 2ms/step - loss: 0.4327 - accuracy: 0.8361 - val_loss: 0.4459 - val_accuracy: 0.8311\n",
      "Epoch 81/1000\n",
      "225/225 [==============================] - 0s 2ms/step - loss: 0.4288 - accuracy: 0.8378 - val_loss: 0.4440 - val_accuracy: 0.8318\n",
      "Epoch 82/1000\n",
      "225/225 [==============================] - 0s 2ms/step - loss: 0.4291 - accuracy: 0.8381 - val_loss: 0.4471 - val_accuracy: 0.8322\n",
      "Epoch 83/1000\n",
      "225/225 [==============================] - 1s 2ms/step - loss: 0.4292 - accuracy: 0.8380 - val_loss: 0.4465 - val_accuracy: 0.8329\n",
      "Epoch 84/1000\n",
      "225/225 [==============================] - 1s 2ms/step - loss: 0.4300 - accuracy: 0.8375 - val_loss: 0.4478 - val_accuracy: 0.8347\n",
      "Epoch 85/1000\n",
      "225/225 [==============================] - 1s 2ms/step - loss: 0.4282 - accuracy: 0.8372 - val_loss: 0.4453 - val_accuracy: 0.8347\n",
      "Epoch 86/1000\n",
      "225/225 [==============================] - 1s 3ms/step - loss: 0.4249 - accuracy: 0.8383 - val_loss: 0.4448 - val_accuracy: 0.8345\n",
      "Epoch 87/1000\n",
      "225/225 [==============================] - 0s 2ms/step - loss: 0.4244 - accuracy: 0.8385 - val_loss: 0.4428 - val_accuracy: 0.8340\n",
      "Epoch 88/1000\n",
      "225/225 [==============================] - 1s 2ms/step - loss: 0.4253 - accuracy: 0.8380 - val_loss: 0.4444 - val_accuracy: 0.8348\n",
      "Epoch 89/1000\n",
      "225/225 [==============================] - 0s 2ms/step - loss: 0.4241 - accuracy: 0.8402 - val_loss: 0.4467 - val_accuracy: 0.8351\n",
      "Epoch 90/1000\n",
      "225/225 [==============================] - 1s 2ms/step - loss: 0.4252 - accuracy: 0.8391 - val_loss: 0.4423 - val_accuracy: 0.8336\n",
      "Epoch 91/1000\n",
      "225/225 [==============================] - 1s 2ms/step - loss: 0.4218 - accuracy: 0.8400 - val_loss: 0.4448 - val_accuracy: 0.8370\n",
      "Epoch 92/1000\n",
      "225/225 [==============================] - 0s 2ms/step - loss: 0.4233 - accuracy: 0.8397 - val_loss: 0.4352 - val_accuracy: 0.8385\n",
      "Epoch 93/1000\n",
      "225/225 [==============================] - 0s 2ms/step - loss: 0.4214 - accuracy: 0.8403 - val_loss: 0.4408 - val_accuracy: 0.8371\n",
      "Epoch 94/1000\n",
      "225/225 [==============================] - 1s 2ms/step - loss: 0.4231 - accuracy: 0.8409 - val_loss: 0.4402 - val_accuracy: 0.8384\n",
      "Epoch 95/1000\n",
      "225/225 [==============================] - 1s 2ms/step - loss: 0.4195 - accuracy: 0.8408 - val_loss: 0.4373 - val_accuracy: 0.8383\n",
      "Epoch 96/1000\n",
      "225/225 [==============================] - 0s 2ms/step - loss: 0.4220 - accuracy: 0.8397 - val_loss: 0.4396 - val_accuracy: 0.8365\n",
      "Epoch 97/1000\n",
      "225/225 [==============================] - 0s 2ms/step - loss: 0.4199 - accuracy: 0.8405 - val_loss: 0.4383 - val_accuracy: 0.8381\n",
      "Epoch 98/1000\n",
      "225/225 [==============================] - 0s 2ms/step - loss: 0.4200 - accuracy: 0.8416 - val_loss: 0.4409 - val_accuracy: 0.8362\n",
      "Epoch 99/1000\n",
      "225/225 [==============================] - 0s 2ms/step - loss: 0.4191 - accuracy: 0.8405 - val_loss: 0.4458 - val_accuracy: 0.8340\n",
      "Epoch 100/1000\n",
      "225/225 [==============================] - 0s 2ms/step - loss: 0.4176 - accuracy: 0.8421 - val_loss: 0.4375 - val_accuracy: 0.8368\n",
      "Epoch 101/1000\n",
      "225/225 [==============================] - 0s 2ms/step - loss: 0.4187 - accuracy: 0.8418 - val_loss: 0.4361 - val_accuracy: 0.8384\n",
      "Epoch 102/1000\n",
      "225/225 [==============================] - 1s 2ms/step - loss: 0.4155 - accuracy: 0.8425 - val_loss: 0.4380 - val_accuracy: 0.8334\n",
      "Epoch 103/1000\n",
      "225/225 [==============================] - 1s 2ms/step - loss: 0.4183 - accuracy: 0.8415 - val_loss: 0.4422 - val_accuracy: 0.8380\n",
      "Epoch 104/1000\n",
      "225/225 [==============================] - 1s 2ms/step - loss: 0.4153 - accuracy: 0.8426 - val_loss: 0.4409 - val_accuracy: 0.8376\n",
      "Epoch 105/1000\n",
      "225/225 [==============================] - 1s 2ms/step - loss: 0.4155 - accuracy: 0.8429 - val_loss: 0.4350 - val_accuracy: 0.8394\n",
      "Epoch 106/1000\n",
      "225/225 [==============================] - 1s 3ms/step - loss: 0.4149 - accuracy: 0.8438 - val_loss: 0.4401 - val_accuracy: 0.8386\n",
      "Epoch 107/1000\n",
      "225/225 [==============================] - 1s 2ms/step - loss: 0.4140 - accuracy: 0.8434 - val_loss: 0.4366 - val_accuracy: 0.8413\n",
      "Epoch 108/1000\n",
      "225/225 [==============================] - 0s 2ms/step - loss: 0.4134 - accuracy: 0.8434 - val_loss: 0.4327 - val_accuracy: 0.8395\n",
      "Epoch 109/1000\n",
      "225/225 [==============================] - 1s 2ms/step - loss: 0.4153 - accuracy: 0.8435 - val_loss: 0.4365 - val_accuracy: 0.8409\n",
      "Epoch 110/1000\n",
      "225/225 [==============================] - 0s 2ms/step - loss: 0.4139 - accuracy: 0.8439 - val_loss: 0.4337 - val_accuracy: 0.8368\n",
      "Epoch 111/1000\n",
      "225/225 [==============================] - 0s 2ms/step - loss: 0.4134 - accuracy: 0.8435 - val_loss: 0.4427 - val_accuracy: 0.8339\n",
      "Epoch 112/1000\n",
      "225/225 [==============================] - 0s 2ms/step - loss: 0.4115 - accuracy: 0.8448 - val_loss: 0.4322 - val_accuracy: 0.8383\n",
      "Epoch 113/1000\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "225/225 [==============================] - 1s 2ms/step - loss: 0.4131 - accuracy: 0.8437 - val_loss: 0.4330 - val_accuracy: 0.8413\n",
      "Epoch 114/1000\n",
      "225/225 [==============================] - 1s 2ms/step - loss: 0.4117 - accuracy: 0.8447 - val_loss: 0.4325 - val_accuracy: 0.8423\n",
      "Epoch 115/1000\n",
      "225/225 [==============================] - 1s 2ms/step - loss: 0.4103 - accuracy: 0.8459 - val_loss: 0.4405 - val_accuracy: 0.8410\n",
      "Epoch 116/1000\n",
      "225/225 [==============================] - 1s 2ms/step - loss: 0.4126 - accuracy: 0.8450 - val_loss: 0.4282 - val_accuracy: 0.8425\n",
      "Epoch 117/1000\n",
      "225/225 [==============================] - 1s 2ms/step - loss: 0.4076 - accuracy: 0.8451 - val_loss: 0.4274 - val_accuracy: 0.8416\n",
      "Epoch 118/1000\n",
      "225/225 [==============================] - 0s 2ms/step - loss: 0.4075 - accuracy: 0.8465 - val_loss: 0.4366 - val_accuracy: 0.8387\n",
      "Epoch 119/1000\n",
      "225/225 [==============================] - 0s 2ms/step - loss: 0.4078 - accuracy: 0.8450 - val_loss: 0.4345 - val_accuracy: 0.8390\n",
      "Epoch 120/1000\n",
      "225/225 [==============================] - 0s 2ms/step - loss: 0.4087 - accuracy: 0.8458 - val_loss: 0.4284 - val_accuracy: 0.8405\n",
      "Epoch 121/1000\n",
      "225/225 [==============================] - 0s 2ms/step - loss: 0.4067 - accuracy: 0.8463 - val_loss: 0.4351 - val_accuracy: 0.8389\n",
      "Epoch 122/1000\n",
      "225/225 [==============================] - 0s 2ms/step - loss: 0.4072 - accuracy: 0.8456 - val_loss: 0.4309 - val_accuracy: 0.8427\n",
      "Epoch 123/1000\n",
      "225/225 [==============================] - 1s 2ms/step - loss: 0.4069 - accuracy: 0.8452 - val_loss: 0.4314 - val_accuracy: 0.8420\n",
      "Epoch 124/1000\n",
      "225/225 [==============================] - 1s 2ms/step - loss: 0.4059 - accuracy: 0.8471 - val_loss: 0.4367 - val_accuracy: 0.8418\n",
      "Epoch 125/1000\n",
      "225/225 [==============================] - 0s 2ms/step - loss: 0.4054 - accuracy: 0.8472 - val_loss: 0.4378 - val_accuracy: 0.8406\n",
      "Epoch 126/1000\n",
      "225/225 [==============================] - 0s 2ms/step - loss: 0.4052 - accuracy: 0.8472 - val_loss: 0.4303 - val_accuracy: 0.8438\n",
      "Epoch 127/1000\n",
      "225/225 [==============================] - 0s 2ms/step - loss: 0.4047 - accuracy: 0.8473 - val_loss: 0.4317 - val_accuracy: 0.8438\n",
      "Epoch 128/1000\n",
      "225/225 [==============================] - 0s 2ms/step - loss: 0.4042 - accuracy: 0.8472 - val_loss: 0.4310 - val_accuracy: 0.8421\n",
      "Epoch 129/1000\n",
      "225/225 [==============================] - 0s 2ms/step - loss: 0.4031 - accuracy: 0.8470 - val_loss: 0.4328 - val_accuracy: 0.8427\n",
      "Epoch 130/1000\n",
      "225/225 [==============================] - 0s 2ms/step - loss: 0.4030 - accuracy: 0.8472 - val_loss: 0.4311 - val_accuracy: 0.8423\n",
      "Epoch 131/1000\n",
      "225/225 [==============================] - 0s 2ms/step - loss: 0.4034 - accuracy: 0.8475 - val_loss: 0.4312 - val_accuracy: 0.8443\n",
      "Epoch 132/1000\n",
      "225/225 [==============================] - 0s 2ms/step - loss: 0.4023 - accuracy: 0.8476 - val_loss: 0.4346 - val_accuracy: 0.8408\n",
      "Epoch 133/1000\n",
      "225/225 [==============================] - 1s 3ms/step - loss: 0.4030 - accuracy: 0.8479 - val_loss: 0.4279 - val_accuracy: 0.8429\n",
      "Epoch 134/1000\n",
      "225/225 [==============================] - 1s 2ms/step - loss: 0.4022 - accuracy: 0.8486 - val_loss: 0.4323 - val_accuracy: 0.8441\n",
      "Epoch 135/1000\n",
      "225/225 [==============================] - 0s 2ms/step - loss: 0.3996 - accuracy: 0.8490 - val_loss: 0.4308 - val_accuracy: 0.8409\n",
      "Epoch 136/1000\n",
      "225/225 [==============================] - 1s 2ms/step - loss: 0.4005 - accuracy: 0.8494 - val_loss: 0.4349 - val_accuracy: 0.8436\n",
      "Epoch 137/1000\n",
      "225/225 [==============================] - 1s 2ms/step - loss: 0.4037 - accuracy: 0.8479 - val_loss: 0.4290 - val_accuracy: 0.8445\n",
      "Epoch 138/1000\n",
      "225/225 [==============================] - 0s 2ms/step - loss: 0.4008 - accuracy: 0.8500 - val_loss: 0.4289 - val_accuracy: 0.8431\n",
      "Epoch 139/1000\n",
      "225/225 [==============================] - 0s 2ms/step - loss: 0.4021 - accuracy: 0.8474 - val_loss: 0.4311 - val_accuracy: 0.8445\n",
      "Epoch 140/1000\n",
      "225/225 [==============================] - 0s 2ms/step - loss: 0.4021 - accuracy: 0.8486 - val_loss: 0.4266 - val_accuracy: 0.8472\n",
      "Epoch 141/1000\n",
      "225/225 [==============================] - 1s 2ms/step - loss: 0.3985 - accuracy: 0.8501 - val_loss: 0.4307 - val_accuracy: 0.8439\n",
      "Epoch 142/1000\n",
      "225/225 [==============================] - 1s 2ms/step - loss: 0.4018 - accuracy: 0.8480 - val_loss: 0.4340 - val_accuracy: 0.8426\n",
      "Epoch 143/1000\n",
      "225/225 [==============================] - 1s 2ms/step - loss: 0.4014 - accuracy: 0.8490 - val_loss: 0.4257 - val_accuracy: 0.8426\n",
      "Epoch 144/1000\n",
      "225/225 [==============================] - 1s 2ms/step - loss: 0.4001 - accuracy: 0.8497 - val_loss: 0.4272 - val_accuracy: 0.8420\n",
      "Epoch 145/1000\n",
      "225/225 [==============================] - 0s 2ms/step - loss: 0.3993 - accuracy: 0.8497 - val_loss: 0.4342 - val_accuracy: 0.8429\n",
      "Epoch 146/1000\n",
      "225/225 [==============================] - 0s 2ms/step - loss: 0.3991 - accuracy: 0.8498 - val_loss: 0.4330 - val_accuracy: 0.8427\n",
      "Epoch 147/1000\n",
      "225/225 [==============================] - 0s 2ms/step - loss: 0.3994 - accuracy: 0.8495 - val_loss: 0.4318 - val_accuracy: 0.8418\n",
      "Epoch 148/1000\n",
      "225/225 [==============================] - 0s 2ms/step - loss: 0.3963 - accuracy: 0.8513 - val_loss: 0.4300 - val_accuracy: 0.8451\n",
      "Epoch 149/1000\n",
      "225/225 [==============================] - 0s 2ms/step - loss: 0.3975 - accuracy: 0.8504 - val_loss: 0.4314 - val_accuracy: 0.8420\n",
      "Epoch 150/1000\n",
      "225/225 [==============================] - 1s 2ms/step - loss: 0.3960 - accuracy: 0.8506 - val_loss: 0.4343 - val_accuracy: 0.8440\n",
      "Epoch 151/1000\n",
      "225/225 [==============================] - 1s 2ms/step - loss: 0.3975 - accuracy: 0.8503 - val_loss: 0.4334 - val_accuracy: 0.8439\n",
      "Epoch 152/1000\n",
      "225/225 [==============================] - 1s 2ms/step - loss: 0.3975 - accuracy: 0.8506 - val_loss: 0.4270 - val_accuracy: 0.8443\n",
      "Epoch 153/1000\n",
      "225/225 [==============================] - 0s 2ms/step - loss: 0.3948 - accuracy: 0.8520 - val_loss: 0.4248 - val_accuracy: 0.8460\n",
      "Epoch 154/1000\n",
      "225/225 [==============================] - 0s 2ms/step - loss: 0.3961 - accuracy: 0.8501 - val_loss: 0.4285 - val_accuracy: 0.8437\n",
      "Epoch 155/1000\n",
      "225/225 [==============================] - 0s 2ms/step - loss: 0.3974 - accuracy: 0.8500 - val_loss: 0.4242 - val_accuracy: 0.8452\n",
      "Epoch 156/1000\n",
      "225/225 [==============================] - 0s 2ms/step - loss: 0.3977 - accuracy: 0.8501 - val_loss: 0.4286 - val_accuracy: 0.8437\n",
      "Epoch 157/1000\n",
      "225/225 [==============================] - 0s 2ms/step - loss: 0.3945 - accuracy: 0.8507 - val_loss: 0.4307 - val_accuracy: 0.8437\n",
      "Epoch 158/1000\n",
      "225/225 [==============================] - 1s 3ms/step - loss: 0.3948 - accuracy: 0.8513 - val_loss: 0.4344 - val_accuracy: 0.8408\n",
      "Epoch 159/1000\n",
      "225/225 [==============================] - 1s 2ms/step - loss: 0.3941 - accuracy: 0.8514 - val_loss: 0.4323 - val_accuracy: 0.8442\n",
      "Epoch 160/1000\n",
      "225/225 [==============================] - 1s 2ms/step - loss: 0.3932 - accuracy: 0.8525 - val_loss: 0.4288 - val_accuracy: 0.8449\n",
      "Epoch 161/1000\n",
      "225/225 [==============================] - 0s 2ms/step - loss: 0.3961 - accuracy: 0.8521 - val_loss: 0.4336 - val_accuracy: 0.8423\n",
      "Epoch 162/1000\n",
      "225/225 [==============================] - 0s 2ms/step - loss: 0.3956 - accuracy: 0.8504 - val_loss: 0.4287 - val_accuracy: 0.8445\n",
      "Epoch 163/1000\n",
      "225/225 [==============================] - 1s 2ms/step - loss: 0.3923 - accuracy: 0.8529 - val_loss: 0.4322 - val_accuracy: 0.8422\n",
      "Epoch 164/1000\n",
      "225/225 [==============================] - 1s 2ms/step - loss: 0.3924 - accuracy: 0.8524 - val_loss: 0.4285 - val_accuracy: 0.8462\n",
      "Epoch 165/1000\n",
      "225/225 [==============================] - 1s 2ms/step - loss: 0.3922 - accuracy: 0.8518 - val_loss: 0.4283 - val_accuracy: 0.8458\n",
      "Epoch 166/1000\n",
      "225/225 [==============================] - 0s 2ms/step - loss: 0.3913 - accuracy: 0.8526 - val_loss: 0.4286 - val_accuracy: 0.8467\n",
      "Epoch 167/1000\n",
      "225/225 [==============================] - 0s 2ms/step - loss: 0.3898 - accuracy: 0.8533 - val_loss: 0.4254 - val_accuracy: 0.8474\n",
      "Epoch 168/1000\n",
      "225/225 [==============================] - 1s 2ms/step - loss: 0.3934 - accuracy: 0.8529 - val_loss: 0.4351 - val_accuracy: 0.8416\n",
      "Epoch 169/1000\n",
      "225/225 [==============================] - 1s 2ms/step - loss: 0.3912 - accuracy: 0.8531 - val_loss: 0.4278 - val_accuracy: 0.8442\n",
      "Epoch 170/1000\n",
      "225/225 [==============================] - 0s 2ms/step - loss: 0.3929 - accuracy: 0.8517 - val_loss: 0.4291 - val_accuracy: 0.8436\n",
      "Epoch 171/1000\n",
      "225/225 [==============================] - 0s 2ms/step - loss: 0.3927 - accuracy: 0.8530 - val_loss: 0.4285 - val_accuracy: 0.8435\n",
      "Epoch 172/1000\n",
      "225/225 [==============================] - 0s 2ms/step - loss: 0.3908 - accuracy: 0.8531 - val_loss: 0.4299 - val_accuracy: 0.8465\n",
      "Epoch 173/1000\n",
      "225/225 [==============================] - 0s 2ms/step - loss: 0.3907 - accuracy: 0.8529 - val_loss: 0.4336 - val_accuracy: 0.8455\n",
      "Epoch 174/1000\n",
      "225/225 [==============================] - 1s 2ms/step - loss: 0.3907 - accuracy: 0.8525 - val_loss: 0.4308 - val_accuracy: 0.8456\n",
      "Epoch 175/1000\n",
      "225/225 [==============================] - 0s 2ms/step - loss: 0.3898 - accuracy: 0.8539 - val_loss: 0.4296 - val_accuracy: 0.8464\n",
      "Epoch 176/1000\n",
      "225/225 [==============================] - 0s 2ms/step - loss: 0.3888 - accuracy: 0.8537 - val_loss: 0.4334 - val_accuracy: 0.8447\n",
      "Epoch 177/1000\n",
      "225/225 [==============================] - 1s 2ms/step - loss: 0.3894 - accuracy: 0.8522 - val_loss: 0.4285 - val_accuracy: 0.8452\n",
      "Epoch 178/1000\n",
      "225/225 [==============================] - 1s 2ms/step - loss: 0.3898 - accuracy: 0.8528 - val_loss: 0.4289 - val_accuracy: 0.8450\n",
      "Epoch 179/1000\n",
      "225/225 [==============================] - 0s 2ms/step - loss: 0.3880 - accuracy: 0.8533 - val_loss: 0.4305 - val_accuracy: 0.8427\n",
      "Epoch 180/1000\n",
      "225/225 [==============================] - 0s 2ms/step - loss: 0.3875 - accuracy: 0.8541 - val_loss: 0.4316 - val_accuracy: 0.8447\n",
      "Epoch 181/1000\n",
      "225/225 [==============================] - 0s 2ms/step - loss: 0.3874 - accuracy: 0.8541 - val_loss: 0.4322 - val_accuracy: 0.8454\n",
      "Epoch 182/1000\n",
      "225/225 [==============================] - 0s 2ms/step - loss: 0.3868 - accuracy: 0.8551 - val_loss: 0.4277 - val_accuracy: 0.8468\n",
      "Epoch 183/1000\n",
      "225/225 [==============================] - 0s 2ms/step - loss: 0.3889 - accuracy: 0.8544 - val_loss: 0.4288 - val_accuracy: 0.8443\n",
      "Epoch 184/1000\n",
      "225/225 [==============================] - 0s 2ms/step - loss: 0.3894 - accuracy: 0.8539 - val_loss: 0.4352 - val_accuracy: 0.8425\n",
      "Epoch 185/1000\n",
      "225/225 [==============================] - 1s 2ms/step - loss: 0.3888 - accuracy: 0.8540 - val_loss: 0.4271 - val_accuracy: 0.8463\n",
      "Epoch 186/1000\n",
      "225/225 [==============================] - 1s 2ms/step - loss: 0.3875 - accuracy: 0.8539 - val_loss: 0.4305 - val_accuracy: 0.8435\n",
      "Epoch 187/1000\n",
      "225/225 [==============================] - 0s 2ms/step - loss: 0.3868 - accuracy: 0.8545 - val_loss: 0.4333 - val_accuracy: 0.8449\n",
      "Epoch 188/1000\n",
      "225/225 [==============================] - 1s 2ms/step - loss: 0.3870 - accuracy: 0.8537 - val_loss: 0.4279 - val_accuracy: 0.8471\n",
      "Epoch 189/1000\n",
      "225/225 [==============================] - 0s 2ms/step - loss: 0.3865 - accuracy: 0.8544 - val_loss: 0.4328 - val_accuracy: 0.8413\n",
      "Epoch 190/1000\n",
      "225/225 [==============================] - 0s 2ms/step - loss: 0.3871 - accuracy: 0.8540 - val_loss: 0.4299 - val_accuracy: 0.8448\n",
      "Epoch 191/1000\n",
      "225/225 [==============================] - 0s 2ms/step - loss: 0.3853 - accuracy: 0.8554 - val_loss: 0.4378 - val_accuracy: 0.8442\n",
      "Epoch 192/1000\n",
      "225/225 [==============================] - 0s 2ms/step - loss: 0.3865 - accuracy: 0.8554 - val_loss: 0.4307 - val_accuracy: 0.8458\n",
      "Epoch 193/1000\n",
      "225/225 [==============================] - 0s 2ms/step - loss: 0.3838 - accuracy: 0.8560 - val_loss: 0.4360 - val_accuracy: 0.8412\n",
      "Epoch 194/1000\n",
      "225/225 [==============================] - 0s 2ms/step - loss: 0.3859 - accuracy: 0.8551 - val_loss: 0.4286 - val_accuracy: 0.8452\n",
      "Epoch 195/1000\n",
      "225/225 [==============================] - 0s 2ms/step - loss: 0.3847 - accuracy: 0.8544 - val_loss: 0.4287 - val_accuracy: 0.8471\n",
      "Epoch 196/1000\n",
      "225/225 [==============================] - 1s 2ms/step - loss: 0.3850 - accuracy: 0.8553 - val_loss: 0.4297 - val_accuracy: 0.8471\n",
      "Epoch 197/1000\n",
      "225/225 [==============================] - 1s 3ms/step - loss: 0.3856 - accuracy: 0.8548 - val_loss: 0.4254 - val_accuracy: 0.8482\n",
      "Epoch 198/1000\n",
      "225/225 [==============================] - 1s 2ms/step - loss: 0.3843 - accuracy: 0.8549 - val_loss: 0.4262 - val_accuracy: 0.8485\n",
      "Epoch 199/1000\n",
      "225/225 [==============================] - 1s 2ms/step - loss: 0.3848 - accuracy: 0.8545 - val_loss: 0.4259 - val_accuracy: 0.8475\n",
      "Epoch 200/1000\n",
      "225/225 [==============================] - 1s 2ms/step - loss: 0.3825 - accuracy: 0.8567 - val_loss: 0.4276 - val_accuracy: 0.8474\n",
      "Epoch 201/1000\n",
      "225/225 [==============================] - 1s 2ms/step - loss: 0.3840 - accuracy: 0.8545 - val_loss: 0.4313 - val_accuracy: 0.8464\n",
      "Epoch 202/1000\n",
      "225/225 [==============================] - 0s 2ms/step - loss: 0.3825 - accuracy: 0.8558 - val_loss: 0.4307 - val_accuracy: 0.8450\n",
      "Epoch 203/1000\n",
      "225/225 [==============================] - 0s 2ms/step - loss: 0.3836 - accuracy: 0.8553 - val_loss: 0.4256 - val_accuracy: 0.8474\n",
      "Epoch 204/1000\n",
      "225/225 [==============================] - 0s 2ms/step - loss: 0.3844 - accuracy: 0.8546 - val_loss: 0.4338 - val_accuracy: 0.8449\n",
      "Epoch 205/1000\n",
      "225/225 [==============================] - 0s 2ms/step - loss: 0.3836 - accuracy: 0.8555 - val_loss: 0.4297 - val_accuracy: 0.8445\n",
      "Epoch 206/1000\n",
      "225/225 [==============================] - 0s 2ms/step - loss: 0.3841 - accuracy: 0.8562 - val_loss: 0.4231 - val_accuracy: 0.8460\n",
      "Epoch 207/1000\n",
      "225/225 [==============================] - 1s 2ms/step - loss: 0.3842 - accuracy: 0.8565 - val_loss: 0.4286 - val_accuracy: 0.8445\n",
      "Epoch 208/1000\n",
      "225/225 [==============================] - 1s 2ms/step - loss: 0.3822 - accuracy: 0.8565 - val_loss: 0.4275 - val_accuracy: 0.8464\n",
      "Epoch 209/1000\n",
      "225/225 [==============================] - 0s 2ms/step - loss: 0.3826 - accuracy: 0.8560 - val_loss: 0.4248 - val_accuracy: 0.8475\n",
      "Epoch 210/1000\n",
      "225/225 [==============================] - 0s 2ms/step - loss: 0.3813 - accuracy: 0.8575 - val_loss: 0.4247 - val_accuracy: 0.8485\n",
      "Epoch 211/1000\n",
      "225/225 [==============================] - 0s 2ms/step - loss: 0.3803 - accuracy: 0.8578 - val_loss: 0.4295 - val_accuracy: 0.8477\n",
      "Epoch 212/1000\n",
      "225/225 [==============================] - 0s 2ms/step - loss: 0.3839 - accuracy: 0.8553 - val_loss: 0.4294 - val_accuracy: 0.8456\n",
      "Epoch 213/1000\n",
      "225/225 [==============================] - 0s 2ms/step - loss: 0.3812 - accuracy: 0.8567 - val_loss: 0.4322 - val_accuracy: 0.8456\n",
      "Epoch 214/1000\n",
      "225/225 [==============================] - 0s 2ms/step - loss: 0.3803 - accuracy: 0.8558 - val_loss: 0.4284 - val_accuracy: 0.8474\n",
      "Epoch 215/1000\n",
      "225/225 [==============================] - 0s 2ms/step - loss: 0.3819 - accuracy: 0.8580 - val_loss: 0.4273 - val_accuracy: 0.8501\n",
      "Epoch 216/1000\n",
      "225/225 [==============================] - 1s 2ms/step - loss: 0.3805 - accuracy: 0.8565 - val_loss: 0.4295 - val_accuracy: 0.8472\n",
      "Epoch 217/1000\n",
      "225/225 [==============================] - 0s 2ms/step - loss: 0.3810 - accuracy: 0.8576 - val_loss: 0.4265 - val_accuracy: 0.8465\n",
      "Epoch 218/1000\n",
      "225/225 [==============================] - 1s 2ms/step - loss: 0.3802 - accuracy: 0.8567 - val_loss: 0.4301 - val_accuracy: 0.8471\n",
      "Epoch 219/1000\n",
      "225/225 [==============================] - 0s 2ms/step - loss: 0.3783 - accuracy: 0.8576 - val_loss: 0.4293 - val_accuracy: 0.8481\n",
      "Epoch 220/1000\n",
      "225/225 [==============================] - 0s 2ms/step - loss: 0.3804 - accuracy: 0.8581 - val_loss: 0.4279 - val_accuracy: 0.8454\n",
      "Epoch 221/1000\n",
      "225/225 [==============================] - 1s 2ms/step - loss: 0.3803 - accuracy: 0.8564 - val_loss: 0.4267 - val_accuracy: 0.8469\n",
      "Epoch 222/1000\n",
      "225/225 [==============================] - 1s 2ms/step - loss: 0.3789 - accuracy: 0.8570 - val_loss: 0.4389 - val_accuracy: 0.8448\n",
      "Epoch 223/1000\n",
      "225/225 [==============================] - 1s 2ms/step - loss: 0.3806 - accuracy: 0.8564 - val_loss: 0.4295 - val_accuracy: 0.8493\n",
      "Epoch 224/1000\n",
      "225/225 [==============================] - 0s 2ms/step - loss: 0.3790 - accuracy: 0.8571 - val_loss: 0.4217 - val_accuracy: 0.8483\n",
      "Epoch 225/1000\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "225/225 [==============================] - 0s 2ms/step - loss: 0.3782 - accuracy: 0.8575 - val_loss: 0.4226 - val_accuracy: 0.8501\n",
      "Epoch 226/1000\n",
      "225/225 [==============================] - 0s 2ms/step - loss: 0.3794 - accuracy: 0.8583 - val_loss: 0.4233 - val_accuracy: 0.8493\n",
      "Epoch 227/1000\n",
      "225/225 [==============================] - 0s 2ms/step - loss: 0.3785 - accuracy: 0.8580 - val_loss: 0.4315 - val_accuracy: 0.8489\n",
      "Epoch 228/1000\n",
      "225/225 [==============================] - 1s 3ms/step - loss: 0.3803 - accuracy: 0.8573 - val_loss: 0.4266 - val_accuracy: 0.8469\n",
      "Epoch 229/1000\n",
      "225/225 [==============================] - 0s 2ms/step - loss: 0.3783 - accuracy: 0.8582 - val_loss: 0.4278 - val_accuracy: 0.8482\n",
      "Epoch 230/1000\n",
      "225/225 [==============================] - 0s 2ms/step - loss: 0.3780 - accuracy: 0.8596 - val_loss: 0.4284 - val_accuracy: 0.8452\n",
      "Epoch 231/1000\n",
      "225/225 [==============================] - 0s 2ms/step - loss: 0.3755 - accuracy: 0.8594 - val_loss: 0.4262 - val_accuracy: 0.8456\n",
      "Epoch 232/1000\n",
      "225/225 [==============================] - 1s 2ms/step - loss: 0.3773 - accuracy: 0.8581 - val_loss: 0.4294 - val_accuracy: 0.8485\n",
      "Epoch 233/1000\n",
      "225/225 [==============================] - 1s 2ms/step - loss: 0.3771 - accuracy: 0.8586 - val_loss: 0.4301 - val_accuracy: 0.8468\n",
      "Epoch 234/1000\n",
      "225/225 [==============================] - 1s 2ms/step - loss: 0.3783 - accuracy: 0.8580 - val_loss: 0.4261 - val_accuracy: 0.8456\n",
      "Epoch 235/1000\n",
      "225/225 [==============================] - 0s 2ms/step - loss: 0.3774 - accuracy: 0.8586 - val_loss: 0.4241 - val_accuracy: 0.8478\n",
      "Epoch 236/1000\n",
      "225/225 [==============================] - 0s 2ms/step - loss: 0.3783 - accuracy: 0.8581 - val_loss: 0.4296 - val_accuracy: 0.8423\n",
      "Epoch 237/1000\n",
      "225/225 [==============================] - 0s 2ms/step - loss: 0.3764 - accuracy: 0.8582 - val_loss: 0.4294 - val_accuracy: 0.8441\n",
      "Epoch 238/1000\n",
      "225/225 [==============================] - 1s 2ms/step - loss: 0.3796 - accuracy: 0.8567 - val_loss: 0.4215 - val_accuracy: 0.8494\n",
      "Epoch 239/1000\n",
      "225/225 [==============================] - 1s 2ms/step - loss: 0.3751 - accuracy: 0.8589 - val_loss: 0.4237 - val_accuracy: 0.8492\n",
      "Epoch 240/1000\n",
      "225/225 [==============================] - 0s 2ms/step - loss: 0.3771 - accuracy: 0.8582 - val_loss: 0.4245 - val_accuracy: 0.8473\n",
      "Epoch 241/1000\n",
      "225/225 [==============================] - 0s 2ms/step - loss: 0.3764 - accuracy: 0.8592 - val_loss: 0.4207 - val_accuracy: 0.8497\n",
      "Epoch 242/1000\n",
      "225/225 [==============================] - 0s 2ms/step - loss: 0.3756 - accuracy: 0.8590 - val_loss: 0.4239 - val_accuracy: 0.8464\n",
      "Epoch 243/1000\n",
      "225/225 [==============================] - 0s 2ms/step - loss: 0.3776 - accuracy: 0.8580 - val_loss: 0.4305 - val_accuracy: 0.8478\n",
      "Epoch 244/1000\n",
      "225/225 [==============================] - 0s 2ms/step - loss: 0.3772 - accuracy: 0.8588 - val_loss: 0.4186 - val_accuracy: 0.8479\n",
      "Epoch 245/1000\n",
      "225/225 [==============================] - 0s 2ms/step - loss: 0.3734 - accuracy: 0.8605 - val_loss: 0.4239 - val_accuracy: 0.8496\n",
      "Epoch 246/1000\n",
      "225/225 [==============================] - 1s 2ms/step - loss: 0.3774 - accuracy: 0.8586 - val_loss: 0.4327 - val_accuracy: 0.8492\n",
      "Epoch 247/1000\n",
      "225/225 [==============================] - 0s 2ms/step - loss: 0.3769 - accuracy: 0.8584 - val_loss: 0.4273 - val_accuracy: 0.8471\n",
      "Epoch 248/1000\n",
      "225/225 [==============================] - 1s 2ms/step - loss: 0.3755 - accuracy: 0.8591 - val_loss: 0.4194 - val_accuracy: 0.8502\n",
      "Epoch 249/1000\n",
      "225/225 [==============================] - 1s 2ms/step - loss: 0.3734 - accuracy: 0.8592 - val_loss: 0.4265 - val_accuracy: 0.8491\n",
      "Epoch 250/1000\n",
      "225/225 [==============================] - 1s 2ms/step - loss: 0.3760 - accuracy: 0.8590 - val_loss: 0.4289 - val_accuracy: 0.8471\n",
      "Epoch 251/1000\n",
      "225/225 [==============================] - 0s 2ms/step - loss: 0.3748 - accuracy: 0.8597 - val_loss: 0.4273 - val_accuracy: 0.8496\n",
      "Epoch 252/1000\n",
      "225/225 [==============================] - 1s 2ms/step - loss: 0.3734 - accuracy: 0.8597 - val_loss: 0.4289 - val_accuracy: 0.8500\n",
      "Epoch 253/1000\n",
      "225/225 [==============================] - 1s 2ms/step - loss: 0.3744 - accuracy: 0.8591 - val_loss: 0.4342 - val_accuracy: 0.8486\n",
      "Epoch 254/1000\n",
      "225/225 [==============================] - 1s 2ms/step - loss: 0.3742 - accuracy: 0.8593 - val_loss: 0.4345 - val_accuracy: 0.8462\n",
      "Epoch 255/1000\n",
      "225/225 [==============================] - 1s 2ms/step - loss: 0.3740 - accuracy: 0.8601 - val_loss: 0.4294 - val_accuracy: 0.8470\n",
      "Epoch 256/1000\n",
      "225/225 [==============================] - 1s 2ms/step - loss: 0.3747 - accuracy: 0.8585 - val_loss: 0.4263 - val_accuracy: 0.8498\n",
      "Epoch 257/1000\n",
      "225/225 [==============================] - 1s 2ms/step - loss: 0.3724 - accuracy: 0.8601 - val_loss: 0.4263 - val_accuracy: 0.8481\n",
      "Epoch 258/1000\n",
      "225/225 [==============================] - 1s 2ms/step - loss: 0.3726 - accuracy: 0.8606 - val_loss: 0.4274 - val_accuracy: 0.8502\n",
      "Epoch 259/1000\n",
      "225/225 [==============================] - 1s 2ms/step - loss: 0.3748 - accuracy: 0.8603 - val_loss: 0.4263 - val_accuracy: 0.8493\n",
      "Epoch 260/1000\n",
      "225/225 [==============================] - 0s 2ms/step - loss: 0.3731 - accuracy: 0.8589 - val_loss: 0.4239 - val_accuracy: 0.8508\n",
      "Epoch 261/1000\n",
      "225/225 [==============================] - 1s 2ms/step - loss: 0.3700 - accuracy: 0.8619 - val_loss: 0.4240 - val_accuracy: 0.8510\n",
      "Epoch 262/1000\n",
      "225/225 [==============================] - 0s 2ms/step - loss: 0.3713 - accuracy: 0.8596 - val_loss: 0.4216 - val_accuracy: 0.8501\n",
      "Epoch 263/1000\n",
      "225/225 [==============================] - 1s 2ms/step - loss: 0.3733 - accuracy: 0.8600 - val_loss: 0.4253 - val_accuracy: 0.8507\n",
      "Epoch 264/1000\n",
      "225/225 [==============================] - 1s 2ms/step - loss: 0.3735 - accuracy: 0.8599 - val_loss: 0.4241 - val_accuracy: 0.8499\n",
      "Epoch 265/1000\n",
      "225/225 [==============================] - 1s 2ms/step - loss: 0.3734 - accuracy: 0.8600 - val_loss: 0.4262 - val_accuracy: 0.8504\n",
      "Epoch 266/1000\n",
      "225/225 [==============================] - 1s 2ms/step - loss: 0.3720 - accuracy: 0.8605 - val_loss: 0.4280 - val_accuracy: 0.8485\n",
      "Epoch 267/1000\n",
      "225/225 [==============================] - 1s 2ms/step - loss: 0.3729 - accuracy: 0.8602 - val_loss: 0.4229 - val_accuracy: 0.8499\n",
      "Epoch 268/1000\n",
      "225/225 [==============================] - 1s 2ms/step - loss: 0.3726 - accuracy: 0.8593 - val_loss: 0.4236 - val_accuracy: 0.8496\n",
      "Epoch 269/1000\n",
      "225/225 [==============================] - 0s 2ms/step - loss: 0.3714 - accuracy: 0.8597 - val_loss: 0.4271 - val_accuracy: 0.8488\n",
      "Epoch 270/1000\n",
      "225/225 [==============================] - 0s 2ms/step - loss: 0.3716 - accuracy: 0.8600 - val_loss: 0.4346 - val_accuracy: 0.8441\n",
      "Epoch 271/1000\n",
      "225/225 [==============================] - 1s 2ms/step - loss: 0.3721 - accuracy: 0.8596 - val_loss: 0.4232 - val_accuracy: 0.8487\n",
      "Epoch 272/1000\n",
      "225/225 [==============================] - 0s 2ms/step - loss: 0.3729 - accuracy: 0.8589 - val_loss: 0.4286 - val_accuracy: 0.8507\n",
      "Epoch 273/1000\n",
      "225/225 [==============================] - 1s 2ms/step - loss: 0.3711 - accuracy: 0.8616 - val_loss: 0.4278 - val_accuracy: 0.8505\n",
      "Epoch 274/1000\n",
      "225/225 [==============================] - 0s 2ms/step - loss: 0.3690 - accuracy: 0.8612 - val_loss: 0.4314 - val_accuracy: 0.8471\n",
      "Epoch 275/1000\n",
      "225/225 [==============================] - 0s 2ms/step - loss: 0.3696 - accuracy: 0.8618 - val_loss: 0.4300 - val_accuracy: 0.8514\n",
      "Epoch 276/1000\n",
      "225/225 [==============================] - 1s 2ms/step - loss: 0.3698 - accuracy: 0.8621 - val_loss: 0.4233 - val_accuracy: 0.8477\n",
      "Epoch 277/1000\n",
      "225/225 [==============================] - 1s 2ms/step - loss: 0.3704 - accuracy: 0.8601 - val_loss: 0.4255 - val_accuracy: 0.8488\n",
      "Epoch 278/1000\n",
      "225/225 [==============================] - 0s 2ms/step - loss: 0.3700 - accuracy: 0.8608 - val_loss: 0.4258 - val_accuracy: 0.8500\n",
      "Epoch 279/1000\n",
      "225/225 [==============================] - 0s 2ms/step - loss: 0.3698 - accuracy: 0.8604 - val_loss: 0.4249 - val_accuracy: 0.8492\n",
      "Epoch 280/1000\n",
      "225/225 [==============================] - 1s 2ms/step - loss: 0.3707 - accuracy: 0.8606 - val_loss: 0.4218 - val_accuracy: 0.8478\n",
      "Epoch 281/1000\n",
      "225/225 [==============================] - 1s 2ms/step - loss: 0.3690 - accuracy: 0.8622 - val_loss: 0.4282 - val_accuracy: 0.8492\n",
      "Epoch 282/1000\n",
      "225/225 [==============================] - 1s 2ms/step - loss: 0.3715 - accuracy: 0.8605 - val_loss: 0.4338 - val_accuracy: 0.8476\n",
      "Epoch 283/1000\n",
      "225/225 [==============================] - 0s 2ms/step - loss: 0.3688 - accuracy: 0.8623 - val_loss: 0.4252 - val_accuracy: 0.8496\n",
      "Epoch 284/1000\n",
      "225/225 [==============================] - 1s 2ms/step - loss: 0.3723 - accuracy: 0.8603 - val_loss: 0.4266 - val_accuracy: 0.8513\n",
      "Epoch 285/1000\n",
      "225/225 [==============================] - 1s 2ms/step - loss: 0.3694 - accuracy: 0.8611 - val_loss: 0.4301 - val_accuracy: 0.8498\n",
      "Epoch 286/1000\n",
      "225/225 [==============================] - 1s 2ms/step - loss: 0.3690 - accuracy: 0.8621 - val_loss: 0.4194 - val_accuracy: 0.8514\n",
      "Epoch 287/1000\n",
      "225/225 [==============================] - 0s 2ms/step - loss: 0.3714 - accuracy: 0.8603 - val_loss: 0.4186 - val_accuracy: 0.8486\n",
      "Epoch 288/1000\n",
      "225/225 [==============================] - 1s 2ms/step - loss: 0.3699 - accuracy: 0.8610 - val_loss: 0.4301 - val_accuracy: 0.8513\n",
      "Epoch 289/1000\n",
      "225/225 [==============================] - 1s 2ms/step - loss: 0.3724 - accuracy: 0.8605 - val_loss: 0.4225 - val_accuracy: 0.8493\n",
      "Epoch 290/1000\n",
      "225/225 [==============================] - 1s 3ms/step - loss: 0.3712 - accuracy: 0.8609 - val_loss: 0.4239 - val_accuracy: 0.8535\n",
      "Epoch 291/1000\n",
      "225/225 [==============================] - 1s 2ms/step - loss: 0.3680 - accuracy: 0.8615 - val_loss: 0.4264 - val_accuracy: 0.8516\n",
      "Epoch 292/1000\n",
      "225/225 [==============================] - 1s 2ms/step - loss: 0.3669 - accuracy: 0.8626 - val_loss: 0.4260 - val_accuracy: 0.8506\n",
      "Epoch 293/1000\n",
      "225/225 [==============================] - 1s 2ms/step - loss: 0.3671 - accuracy: 0.8614 - val_loss: 0.4241 - val_accuracy: 0.8515\n",
      "Epoch 294/1000\n",
      "225/225 [==============================] - 0s 2ms/step - loss: 0.3688 - accuracy: 0.8629 - val_loss: 0.4290 - val_accuracy: 0.8475\n",
      "Epoch 295/1000\n",
      "225/225 [==============================] - 0s 2ms/step - loss: 0.3702 - accuracy: 0.8618 - val_loss: 0.4219 - val_accuracy: 0.8538\n",
      "Epoch 296/1000\n",
      "225/225 [==============================] - 0s 2ms/step - loss: 0.3676 - accuracy: 0.8628 - val_loss: 0.4284 - val_accuracy: 0.8514\n",
      "Epoch 297/1000\n",
      "225/225 [==============================] - 0s 2ms/step - loss: 0.3679 - accuracy: 0.8619 - val_loss: 0.4257 - val_accuracy: 0.8503\n",
      "Epoch 298/1000\n",
      "225/225 [==============================] - 1s 2ms/step - loss: 0.3680 - accuracy: 0.8613 - val_loss: 0.4295 - val_accuracy: 0.8507\n",
      "Epoch 299/1000\n",
      "225/225 [==============================] - 0s 2ms/step - loss: 0.3678 - accuracy: 0.8631 - val_loss: 0.4274 - val_accuracy: 0.8492\n",
      "Epoch 300/1000\n",
      "225/225 [==============================] - 0s 2ms/step - loss: 0.3689 - accuracy: 0.8615 - val_loss: 0.4246 - val_accuracy: 0.8533\n",
      "Epoch 301/1000\n",
      "225/225 [==============================] - 0s 2ms/step - loss: 0.3683 - accuracy: 0.8610 - val_loss: 0.4295 - val_accuracy: 0.8485\n",
      "Epoch 302/1000\n",
      "225/225 [==============================] - 1s 2ms/step - loss: 0.3699 - accuracy: 0.8610 - val_loss: 0.4255 - val_accuracy: 0.8497\n",
      "Epoch 303/1000\n",
      "225/225 [==============================] - 1s 2ms/step - loss: 0.3677 - accuracy: 0.8612 - val_loss: 0.4249 - val_accuracy: 0.8501\n",
      "Epoch 304/1000\n",
      "225/225 [==============================] - 0s 2ms/step - loss: 0.3693 - accuracy: 0.8602 - val_loss: 0.4244 - val_accuracy: 0.8508\n",
      "Epoch 305/1000\n",
      "225/225 [==============================] - 0s 2ms/step - loss: 0.3686 - accuracy: 0.8617 - val_loss: 0.4293 - val_accuracy: 0.8461\n",
      "Epoch 306/1000\n",
      "225/225 [==============================] - 1s 2ms/step - loss: 0.3684 - accuracy: 0.8615 - val_loss: 0.4261 - val_accuracy: 0.8503\n",
      "Epoch 307/1000\n",
      "225/225 [==============================] - 0s 2ms/step - loss: 0.3657 - accuracy: 0.8629 - val_loss: 0.4317 - val_accuracy: 0.8507\n",
      "Epoch 308/1000\n",
      "225/225 [==============================] - 1s 2ms/step - loss: 0.3656 - accuracy: 0.8618 - val_loss: 0.4293 - val_accuracy: 0.8496\n",
      "Epoch 309/1000\n",
      "225/225 [==============================] - 1s 2ms/step - loss: 0.3671 - accuracy: 0.8620 - val_loss: 0.4236 - val_accuracy: 0.8496\n",
      "Epoch 310/1000\n",
      "225/225 [==============================] - 1s 2ms/step - loss: 0.3669 - accuracy: 0.8632 - val_loss: 0.4291 - val_accuracy: 0.8474\n",
      "Epoch 311/1000\n",
      "225/225 [==============================] - 1s 2ms/step - loss: 0.3658 - accuracy: 0.8629 - val_loss: 0.4344 - val_accuracy: 0.8501\n",
      "Epoch 312/1000\n",
      "225/225 [==============================] - 1s 2ms/step - loss: 0.3677 - accuracy: 0.8614 - val_loss: 0.4281 - val_accuracy: 0.8494\n",
      "Epoch 313/1000\n",
      "225/225 [==============================] - 1s 2ms/step - loss: 0.3666 - accuracy: 0.8623 - val_loss: 0.4323 - val_accuracy: 0.8497\n",
      "Epoch 314/1000\n",
      "225/225 [==============================] - 1s 2ms/step - loss: 0.3670 - accuracy: 0.8613 - val_loss: 0.4321 - val_accuracy: 0.8494\n",
      "Epoch 315/1000\n",
      "225/225 [==============================] - 1s 3ms/step - loss: 0.3654 - accuracy: 0.8627 - val_loss: 0.4278 - val_accuracy: 0.8496\n",
      "Epoch 316/1000\n",
      "225/225 [==============================] - 1s 2ms/step - loss: 0.3655 - accuracy: 0.8627 - val_loss: 0.4226 - val_accuracy: 0.8519\n",
      "Epoch 317/1000\n",
      "225/225 [==============================] - 1s 2ms/step - loss: 0.3653 - accuracy: 0.8631 - val_loss: 0.4268 - val_accuracy: 0.8491\n",
      "Epoch 318/1000\n",
      "225/225 [==============================] - 1s 2ms/step - loss: 0.3663 - accuracy: 0.8618 - val_loss: 0.4226 - val_accuracy: 0.8540\n",
      "Epoch 319/1000\n",
      "225/225 [==============================] - 1s 2ms/step - loss: 0.3656 - accuracy: 0.8628 - val_loss: 0.4255 - val_accuracy: 0.8499\n",
      "Epoch 320/1000\n",
      "225/225 [==============================] - 1s 2ms/step - loss: 0.3632 - accuracy: 0.8631 - val_loss: 0.4258 - val_accuracy: 0.8513\n",
      "Epoch 321/1000\n",
      "225/225 [==============================] - 1s 3ms/step - loss: 0.3653 - accuracy: 0.8626 - val_loss: 0.4270 - val_accuracy: 0.8489\n",
      "Epoch 322/1000\n",
      "225/225 [==============================] - 1s 2ms/step - loss: 0.3647 - accuracy: 0.8621 - val_loss: 0.4260 - val_accuracy: 0.8524\n",
      "Epoch 323/1000\n",
      "225/225 [==============================] - 1s 2ms/step - loss: 0.3653 - accuracy: 0.8626 - val_loss: 0.4307 - val_accuracy: 0.8518\n",
      "Epoch 324/1000\n",
      "225/225 [==============================] - 1s 2ms/step - loss: 0.3652 - accuracy: 0.8626 - val_loss: 0.4263 - val_accuracy: 0.8489\n",
      "Epoch 325/1000\n",
      "225/225 [==============================] - 0s 2ms/step - loss: 0.3662 - accuracy: 0.8619 - val_loss: 0.4290 - val_accuracy: 0.8511\n",
      "Epoch 326/1000\n",
      "225/225 [==============================] - 1s 2ms/step - loss: 0.3657 - accuracy: 0.8625 - val_loss: 0.4230 - val_accuracy: 0.8514\n",
      "Epoch 327/1000\n",
      "225/225 [==============================] - 1s 2ms/step - loss: 0.3672 - accuracy: 0.8616 - val_loss: 0.4259 - val_accuracy: 0.8529\n",
      "Epoch 328/1000\n",
      "225/225 [==============================] - 1s 2ms/step - loss: 0.3647 - accuracy: 0.8626 - val_loss: 0.4256 - val_accuracy: 0.8489\n",
      "Epoch 329/1000\n",
      "225/225 [==============================] - 1s 2ms/step - loss: 0.3622 - accuracy: 0.8643 - val_loss: 0.4237 - val_accuracy: 0.8524\n",
      "Epoch 330/1000\n",
      "225/225 [==============================] - 1s 2ms/step - loss: 0.3640 - accuracy: 0.8635 - val_loss: 0.4275 - val_accuracy: 0.8517\n",
      "Epoch 331/1000\n",
      "225/225 [==============================] - 1s 2ms/step - loss: 0.3645 - accuracy: 0.8634 - val_loss: 0.4359 - val_accuracy: 0.8491\n",
      "Epoch 332/1000\n",
      "225/225 [==============================] - 1s 2ms/step - loss: 0.3663 - accuracy: 0.8614 - val_loss: 0.4278 - val_accuracy: 0.8513\n",
      "Epoch 333/1000\n",
      "225/225 [==============================] - 1s 2ms/step - loss: 0.3632 - accuracy: 0.8633 - val_loss: 0.4270 - val_accuracy: 0.8511\n",
      "Epoch 334/1000\n",
      "225/225 [==============================] - 0s 2ms/step - loss: 0.3638 - accuracy: 0.8637 - val_loss: 0.4265 - val_accuracy: 0.8521\n",
      "Epoch 334: early stopping\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "<keras.src.callbacks.History at 0x2c9757850>"
      ]
     },
     "execution_count": 208,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "model=Sequential()\n",
    "model.add(Dense(128, input_dim=X_train.shape[1], activation=\"relu\"))\n",
    "\n",
    "model.add(Dense(128, activation=\"relu\"))\n",
    "model.add(Dropout(0.2))\n",
    "model.add(Dense(64, activation=\"relu\"))\n",
    "\n",
    "model.add(Dense(64, activation=\"relu\"))\n",
    "model.add(Dropout(0.2))\n",
    "model.add(Dense(32, activation=\"relu\"))\n",
    "model.add(Dropout(0.2))\n",
    "model.add(Dense(16, activation=\"relu\"))\n",
    "model.add(Dropout(0.2))\n",
    "model.add(Dense(3, activation=\"softmax\"))\n",
    "\n",
    "optimizer = tf.keras.optimizers.legacy.Nadam(learning_rate=0.001)\n",
    "model.compile(loss='categorical_crossentropy', optimizer=optimizer, metrics=['accuracy'])\n",
    "\n",
    "es=EarlyStopping(monitor=\"val_loss\",patience=90,mode=\"auto\",verbose=1)\n",
    "\n",
    "model.fit(X_train, y_train,epochs=1000,batch_size=512,validation_split=0.1,verbose=1,callbacks=[es])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 209,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "997/997 [==============================] - 0s 317us/step\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0       0.87      0.92      0.90     10867\n",
      "           1       0.83      0.92      0.87     10432\n",
      "           2       0.84      0.70      0.76     10591\n",
      "\n",
      "    accuracy                           0.85     31890\n",
      "   macro avg       0.85      0.85      0.84     31890\n",
      "weighted avg       0.85      0.85      0.84     31890\n",
      "\n"
     ]
    }
   ],
   "source": [
    "y_pred = model.predict(X_test)\n",
    "y_pred_classes = np.argmax(y_pred, axis=1)\n",
    "y_true = np.argmax(y_test, axis=1)\n",
    "print(classification_report(y_true, y_pred_classes))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 210,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "3987/3987 [==============================] - 1s 255us/step\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0       0.91      0.97      0.94     42282\n",
      "           1       0.86      0.96      0.91     42717\n",
      "           2       0.93      0.76      0.83     42558\n",
      "\n",
      "    accuracy                           0.90    127557\n",
      "   macro avg       0.90      0.90      0.89    127557\n",
      "weighted avg       0.90      0.90      0.89    127557\n",
      "\n"
     ]
    }
   ],
   "source": [
    "y_t_pred = model.predict(X_train)\n",
    "y_t_pred_classes = np.argmax(y_t_pred, axis=1)\n",
    "y_t_true = np.argmax(y_train, axis=1)\n",
    "print(classification_report(y_t_true, y_t_pred_classes))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 211,
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 1/1000\n",
      "225/225 [==============================] - 1s 3ms/step - loss: 0.7863 - accuracy: 0.6818 - val_loss: 0.6909 - val_accuracy: 0.7310\n",
      "Epoch 2/1000\n",
      "225/225 [==============================] - 1s 3ms/step - loss: 0.7064 - accuracy: 0.7286 - val_loss: 0.6767 - val_accuracy: 0.7382\n",
      "Epoch 3/1000\n",
      "225/225 [==============================] - 1s 3ms/step - loss: 0.6920 - accuracy: 0.7333 - val_loss: 0.6671 - val_accuracy: 0.7437\n",
      "Epoch 4/1000\n",
      "225/225 [==============================] - 1s 3ms/step - loss: 0.6803 - accuracy: 0.7363 - val_loss: 0.6519 - val_accuracy: 0.7444\n",
      "Epoch 5/1000\n",
      "225/225 [==============================] - 1s 3ms/step - loss: 0.6723 - accuracy: 0.7392 - val_loss: 0.6475 - val_accuracy: 0.7458\n",
      "Epoch 6/1000\n",
      "225/225 [==============================] - 1s 3ms/step - loss: 0.6658 - accuracy: 0.7406 - val_loss: 0.6433 - val_accuracy: 0.7476\n",
      "Epoch 7/1000\n",
      "225/225 [==============================] - 1s 3ms/step - loss: 0.6614 - accuracy: 0.7421 - val_loss: 0.6388 - val_accuracy: 0.7513\n",
      "Epoch 8/1000\n",
      "225/225 [==============================] - 1s 3ms/step - loss: 0.6579 - accuracy: 0.7432 - val_loss: 0.6331 - val_accuracy: 0.7526\n",
      "Epoch 9/1000\n",
      "225/225 [==============================] - 1s 3ms/step - loss: 0.6532 - accuracy: 0.7452 - val_loss: 0.6318 - val_accuracy: 0.7516\n",
      "Epoch 10/1000\n",
      "225/225 [==============================] - 1s 2ms/step - loss: 0.6493 - accuracy: 0.7456 - val_loss: 0.6257 - val_accuracy: 0.7541\n",
      "Epoch 11/1000\n",
      "225/225 [==============================] - 1s 2ms/step - loss: 0.6452 - accuracy: 0.7474 - val_loss: 0.6223 - val_accuracy: 0.7569\n",
      "Epoch 12/1000\n",
      "225/225 [==============================] - 1s 2ms/step - loss: 0.6424 - accuracy: 0.7485 - val_loss: 0.6195 - val_accuracy: 0.7567\n",
      "Epoch 13/1000\n",
      "225/225 [==============================] - 1s 3ms/step - loss: 0.6389 - accuracy: 0.7499 - val_loss: 0.6186 - val_accuracy: 0.7578\n",
      "Epoch 14/1000\n",
      "225/225 [==============================] - 1s 3ms/step - loss: 0.6369 - accuracy: 0.7509 - val_loss: 0.6139 - val_accuracy: 0.7574\n",
      "Epoch 15/1000\n",
      "225/225 [==============================] - 1s 3ms/step - loss: 0.6338 - accuracy: 0.7518 - val_loss: 0.6111 - val_accuracy: 0.7614\n",
      "Epoch 16/1000\n",
      "225/225 [==============================] - 1s 3ms/step - loss: 0.6301 - accuracy: 0.7527 - val_loss: 0.6048 - val_accuracy: 0.7645\n",
      "Epoch 17/1000\n",
      "225/225 [==============================] - 1s 3ms/step - loss: 0.6276 - accuracy: 0.7543 - val_loss: 0.6045 - val_accuracy: 0.7619\n",
      "Epoch 18/1000\n",
      "225/225 [==============================] - 1s 3ms/step - loss: 0.6233 - accuracy: 0.7549 - val_loss: 0.6027 - val_accuracy: 0.7646\n",
      "Epoch 19/1000\n",
      "225/225 [==============================] - 1s 3ms/step - loss: 0.6227 - accuracy: 0.7558 - val_loss: 0.6006 - val_accuracy: 0.7645\n",
      "Epoch 20/1000\n",
      "225/225 [==============================] - 1s 3ms/step - loss: 0.6200 - accuracy: 0.7557 - val_loss: 0.5987 - val_accuracy: 0.7647\n",
      "Epoch 21/1000\n",
      "225/225 [==============================] - 1s 3ms/step - loss: 0.6174 - accuracy: 0.7570 - val_loss: 0.5939 - val_accuracy: 0.7652\n",
      "Epoch 22/1000\n",
      "225/225 [==============================] - 1s 3ms/step - loss: 0.6172 - accuracy: 0.7570 - val_loss: 0.5940 - val_accuracy: 0.7668\n",
      "Epoch 23/1000\n",
      "225/225 [==============================] - 1s 3ms/step - loss: 0.6132 - accuracy: 0.7586 - val_loss: 0.5875 - val_accuracy: 0.7680\n",
      "Epoch 24/1000\n",
      "225/225 [==============================] - 1s 3ms/step - loss: 0.6119 - accuracy: 0.7585 - val_loss: 0.5885 - val_accuracy: 0.7673\n",
      "Epoch 25/1000\n",
      "225/225 [==============================] - 1s 3ms/step - loss: 0.6100 - accuracy: 0.7593 - val_loss: 0.5905 - val_accuracy: 0.7693\n",
      "Epoch 26/1000\n",
      "225/225 [==============================] - 1s 3ms/step - loss: 0.6075 - accuracy: 0.7612 - val_loss: 0.5835 - val_accuracy: 0.7738\n",
      "Epoch 27/1000\n",
      "225/225 [==============================] - 1s 2ms/step - loss: 0.6058 - accuracy: 0.7615 - val_loss: 0.5818 - val_accuracy: 0.7710\n",
      "Epoch 28/1000\n",
      "225/225 [==============================] - 1s 3ms/step - loss: 0.6044 - accuracy: 0.7618 - val_loss: 0.5791 - val_accuracy: 0.7730\n",
      "Epoch 29/1000\n",
      "225/225 [==============================] - 1s 3ms/step - loss: 0.6023 - accuracy: 0.7627 - val_loss: 0.5789 - val_accuracy: 0.7738\n",
      "Epoch 30/1000\n",
      "225/225 [==============================] - 1s 3ms/step - loss: 0.6002 - accuracy: 0.7638 - val_loss: 0.5781 - val_accuracy: 0.7733\n",
      "Epoch 31/1000\n",
      "225/225 [==============================] - 1s 3ms/step - loss: 0.5976 - accuracy: 0.7649 - val_loss: 0.5702 - val_accuracy: 0.7760\n",
      "Epoch 32/1000\n",
      "225/225 [==============================] - 1s 3ms/step - loss: 0.5968 - accuracy: 0.7645 - val_loss: 0.5705 - val_accuracy: 0.7757\n",
      "Epoch 33/1000\n",
      "225/225 [==============================] - 1s 3ms/step - loss: 0.5957 - accuracy: 0.7650 - val_loss: 0.5693 - val_accuracy: 0.7785\n",
      "Epoch 34/1000\n",
      "225/225 [==============================] - 1s 3ms/step - loss: 0.5935 - accuracy: 0.7664 - val_loss: 0.5669 - val_accuracy: 0.7756\n",
      "Epoch 35/1000\n",
      "225/225 [==============================] - 1s 3ms/step - loss: 0.5913 - accuracy: 0.7669 - val_loss: 0.5652 - val_accuracy: 0.7799\n",
      "Epoch 36/1000\n",
      "225/225 [==============================] - 1s 3ms/step - loss: 0.5898 - accuracy: 0.7680 - val_loss: 0.5618 - val_accuracy: 0.7807\n",
      "Epoch 37/1000\n",
      "225/225 [==============================] - 1s 3ms/step - loss: 0.5903 - accuracy: 0.7674 - val_loss: 0.5602 - val_accuracy: 0.7790\n",
      "Epoch 38/1000\n",
      "225/225 [==============================] - 1s 3ms/step - loss: 0.5900 - accuracy: 0.7672 - val_loss: 0.5651 - val_accuracy: 0.7796\n",
      "Epoch 39/1000\n",
      "225/225 [==============================] - 1s 3ms/step - loss: 0.5875 - accuracy: 0.7682 - val_loss: 0.5598 - val_accuracy: 0.7810\n",
      "Epoch 40/1000\n",
      "225/225 [==============================] - 1s 3ms/step - loss: 0.5872 - accuracy: 0.7682 - val_loss: 0.5606 - val_accuracy: 0.7791\n",
      "Epoch 41/1000\n",
      "225/225 [==============================] - 1s 4ms/step - loss: 0.5858 - accuracy: 0.7680 - val_loss: 0.5552 - val_accuracy: 0.7816\n",
      "Epoch 42/1000\n",
      "225/225 [==============================] - 1s 3ms/step - loss: 0.5830 - accuracy: 0.7695 - val_loss: 0.5570 - val_accuracy: 0.7817\n",
      "Epoch 43/1000\n",
      "225/225 [==============================] - 1s 3ms/step - loss: 0.5833 - accuracy: 0.7683 - val_loss: 0.5524 - val_accuracy: 0.7864\n",
      "Epoch 44/1000\n",
      "225/225 [==============================] - 1s 4ms/step - loss: 0.5814 - accuracy: 0.7701 - val_loss: 0.5533 - val_accuracy: 0.7825\n",
      "Epoch 45/1000\n",
      "225/225 [==============================] - 1s 5ms/step - loss: 0.5801 - accuracy: 0.7709 - val_loss: 0.5509 - val_accuracy: 0.7833\n",
      "Epoch 46/1000\n",
      "225/225 [==============================] - 1s 4ms/step - loss: 0.5784 - accuracy: 0.7722 - val_loss: 0.5487 - val_accuracy: 0.7845\n",
      "Epoch 47/1000\n",
      "225/225 [==============================] - 1s 4ms/step - loss: 0.5774 - accuracy: 0.7715 - val_loss: 0.5460 - val_accuracy: 0.7846\n",
      "Epoch 48/1000\n",
      "225/225 [==============================] - 1s 3ms/step - loss: 0.5778 - accuracy: 0.7718 - val_loss: 0.5453 - val_accuracy: 0.7846\n",
      "Epoch 49/1000\n",
      "225/225 [==============================] - 1s 3ms/step - loss: 0.5771 - accuracy: 0.7723 - val_loss: 0.5480 - val_accuracy: 0.7863\n",
      "Epoch 50/1000\n",
      "225/225 [==============================] - 1s 2ms/step - loss: 0.5745 - accuracy: 0.7727 - val_loss: 0.5417 - val_accuracy: 0.7847\n",
      "Epoch 51/1000\n",
      "225/225 [==============================] - 1s 2ms/step - loss: 0.5743 - accuracy: 0.7719 - val_loss: 0.5436 - val_accuracy: 0.7856\n",
      "Epoch 52/1000\n",
      "225/225 [==============================] - 1s 3ms/step - loss: 0.5739 - accuracy: 0.7737 - val_loss: 0.5403 - val_accuracy: 0.7872\n",
      "Epoch 53/1000\n",
      "225/225 [==============================] - 1s 2ms/step - loss: 0.5727 - accuracy: 0.7737 - val_loss: 0.5447 - val_accuracy: 0.7889\n",
      "Epoch 54/1000\n",
      "225/225 [==============================] - 1s 3ms/step - loss: 0.5722 - accuracy: 0.7732 - val_loss: 0.5404 - val_accuracy: 0.7883\n",
      "Epoch 55/1000\n",
      "225/225 [==============================] - 1s 2ms/step - loss: 0.5719 - accuracy: 0.7735 - val_loss: 0.5361 - val_accuracy: 0.7879\n",
      "Epoch 56/1000\n",
      "225/225 [==============================] - 1s 3ms/step - loss: 0.5697 - accuracy: 0.7743 - val_loss: 0.5366 - val_accuracy: 0.7884\n",
      "Epoch 57/1000\n",
      "225/225 [==============================] - 1s 3ms/step - loss: 0.5686 - accuracy: 0.7756 - val_loss: 0.5349 - val_accuracy: 0.7916\n",
      "Epoch 58/1000\n",
      "225/225 [==============================] - 1s 3ms/step - loss: 0.5669 - accuracy: 0.7754 - val_loss: 0.5378 - val_accuracy: 0.7883\n",
      "Epoch 59/1000\n",
      "225/225 [==============================] - 1s 3ms/step - loss: 0.5675 - accuracy: 0.7750 - val_loss: 0.5334 - val_accuracy: 0.7886\n",
      "Epoch 60/1000\n",
      "225/225 [==============================] - 1s 2ms/step - loss: 0.5671 - accuracy: 0.7753 - val_loss: 0.5316 - val_accuracy: 0.7915\n",
      "Epoch 61/1000\n",
      "225/225 [==============================] - 1s 2ms/step - loss: 0.5657 - accuracy: 0.7760 - val_loss: 0.5322 - val_accuracy: 0.7912\n",
      "Epoch 62/1000\n",
      "225/225 [==============================] - 1s 2ms/step - loss: 0.5666 - accuracy: 0.7753 - val_loss: 0.5319 - val_accuracy: 0.7926\n",
      "Epoch 63/1000\n",
      "225/225 [==============================] - 1s 2ms/step - loss: 0.5642 - accuracy: 0.7754 - val_loss: 0.5322 - val_accuracy: 0.7936\n",
      "Epoch 64/1000\n",
      "225/225 [==============================] - 1s 2ms/step - loss: 0.5649 - accuracy: 0.7755 - val_loss: 0.5306 - val_accuracy: 0.7905\n",
      "Epoch 65/1000\n",
      "225/225 [==============================] - 1s 2ms/step - loss: 0.5635 - accuracy: 0.7756 - val_loss: 0.5326 - val_accuracy: 0.7894\n",
      "Epoch 66/1000\n",
      "225/225 [==============================] - 1s 3ms/step - loss: 0.5616 - accuracy: 0.7777 - val_loss: 0.5307 - val_accuracy: 0.7909\n",
      "Epoch 67/1000\n",
      "225/225 [==============================] - 1s 3ms/step - loss: 0.5635 - accuracy: 0.7768 - val_loss: 0.5286 - val_accuracy: 0.7923\n",
      "Epoch 68/1000\n",
      "225/225 [==============================] - 1s 3ms/step - loss: 0.5616 - accuracy: 0.7772 - val_loss: 0.5299 - val_accuracy: 0.7891\n",
      "Epoch 69/1000\n",
      "225/225 [==============================] - 1s 3ms/step - loss: 0.5607 - accuracy: 0.7790 - val_loss: 0.5261 - val_accuracy: 0.7925\n",
      "Epoch 70/1000\n",
      "225/225 [==============================] - 1s 3ms/step - loss: 0.5604 - accuracy: 0.7784 - val_loss: 0.5305 - val_accuracy: 0.7922\n",
      "Epoch 71/1000\n",
      "225/225 [==============================] - 1s 3ms/step - loss: 0.5590 - accuracy: 0.7787 - val_loss: 0.5271 - val_accuracy: 0.7924\n",
      "Epoch 72/1000\n",
      "225/225 [==============================] - 1s 3ms/step - loss: 0.5588 - accuracy: 0.7789 - val_loss: 0.5262 - val_accuracy: 0.7946\n",
      "Epoch 73/1000\n",
      "225/225 [==============================] - 1s 3ms/step - loss: 0.5588 - accuracy: 0.7804 - val_loss: 0.5239 - val_accuracy: 0.7935\n",
      "Epoch 74/1000\n",
      "225/225 [==============================] - 1s 3ms/step - loss: 0.5583 - accuracy: 0.7797 - val_loss: 0.5252 - val_accuracy: 0.7955\n",
      "Epoch 75/1000\n",
      "225/225 [==============================] - 1s 3ms/step - loss: 0.5575 - accuracy: 0.7791 - val_loss: 0.5222 - val_accuracy: 0.7922\n",
      "Epoch 76/1000\n",
      "225/225 [==============================] - 1s 3ms/step - loss: 0.5566 - accuracy: 0.7798 - val_loss: 0.5213 - val_accuracy: 0.7938\n",
      "Epoch 77/1000\n",
      "225/225 [==============================] - 1s 3ms/step - loss: 0.5577 - accuracy: 0.7788 - val_loss: 0.5219 - val_accuracy: 0.7908\n",
      "Epoch 78/1000\n",
      "225/225 [==============================] - 1s 3ms/step - loss: 0.5572 - accuracy: 0.7797 - val_loss: 0.5251 - val_accuracy: 0.7948\n",
      "Epoch 79/1000\n",
      "225/225 [==============================] - 1s 3ms/step - loss: 0.5554 - accuracy: 0.7808 - val_loss: 0.5225 - val_accuracy: 0.7943\n",
      "Epoch 80/1000\n",
      "225/225 [==============================] - 1s 3ms/step - loss: 0.5546 - accuracy: 0.7800 - val_loss: 0.5214 - val_accuracy: 0.7986\n",
      "Epoch 81/1000\n",
      "225/225 [==============================] - 1s 3ms/step - loss: 0.5544 - accuracy: 0.7795 - val_loss: 0.5180 - val_accuracy: 0.7956\n",
      "Epoch 82/1000\n",
      "225/225 [==============================] - 1s 3ms/step - loss: 0.5549 - accuracy: 0.7802 - val_loss: 0.5190 - val_accuracy: 0.7966\n",
      "Epoch 83/1000\n",
      "225/225 [==============================] - 1s 3ms/step - loss: 0.5550 - accuracy: 0.7796 - val_loss: 0.5172 - val_accuracy: 0.7937\n",
      "Epoch 84/1000\n",
      "225/225 [==============================] - 1s 2ms/step - loss: 0.5525 - accuracy: 0.7812 - val_loss: 0.5179 - val_accuracy: 0.7961\n",
      "Epoch 85/1000\n",
      "225/225 [==============================] - 1s 3ms/step - loss: 0.5545 - accuracy: 0.7795 - val_loss: 0.5169 - val_accuracy: 0.7985\n",
      "Epoch 86/1000\n",
      "225/225 [==============================] - 1s 2ms/step - loss: 0.5528 - accuracy: 0.7816 - val_loss: 0.5140 - val_accuracy: 0.7978\n",
      "Epoch 87/1000\n",
      "225/225 [==============================] - 1s 3ms/step - loss: 0.5535 - accuracy: 0.7804 - val_loss: 0.5166 - val_accuracy: 0.7976\n",
      "Epoch 88/1000\n",
      "225/225 [==============================] - 1s 3ms/step - loss: 0.5526 - accuracy: 0.7810 - val_loss: 0.5161 - val_accuracy: 0.7962\n",
      "Epoch 89/1000\n",
      "225/225 [==============================] - 1s 3ms/step - loss: 0.5509 - accuracy: 0.7821 - val_loss: 0.5145 - val_accuracy: 0.7970\n",
      "Epoch 90/1000\n",
      "225/225 [==============================] - 1s 3ms/step - loss: 0.5519 - accuracy: 0.7810 - val_loss: 0.5156 - val_accuracy: 0.7973\n",
      "Epoch 91/1000\n",
      "225/225 [==============================] - 1s 3ms/step - loss: 0.5505 - accuracy: 0.7817 - val_loss: 0.5166 - val_accuracy: 0.7992\n",
      "Epoch 92/1000\n",
      "225/225 [==============================] - 1s 3ms/step - loss: 0.5523 - accuracy: 0.7810 - val_loss: 0.5139 - val_accuracy: 0.7969\n",
      "Epoch 93/1000\n",
      "225/225 [==============================] - 1s 3ms/step - loss: 0.5500 - accuracy: 0.7824 - val_loss: 0.5164 - val_accuracy: 0.7939\n",
      "Epoch 94/1000\n",
      "225/225 [==============================] - 1s 3ms/step - loss: 0.5509 - accuracy: 0.7813 - val_loss: 0.5125 - val_accuracy: 0.7978\n",
      "Epoch 95/1000\n",
      "225/225 [==============================] - 1s 3ms/step - loss: 0.5490 - accuracy: 0.7814 - val_loss: 0.5152 - val_accuracy: 0.7963\n",
      "Epoch 96/1000\n",
      "225/225 [==============================] - 1s 3ms/step - loss: 0.5486 - accuracy: 0.7819 - val_loss: 0.5104 - val_accuracy: 0.7984\n",
      "Epoch 97/1000\n",
      "225/225 [==============================] - 1s 3ms/step - loss: 0.5480 - accuracy: 0.7822 - val_loss: 0.5132 - val_accuracy: 0.7982\n",
      "Epoch 98/1000\n",
      "225/225 [==============================] - 1s 3ms/step - loss: 0.5472 - accuracy: 0.7826 - val_loss: 0.5131 - val_accuracy: 0.8008\n",
      "Epoch 99/1000\n",
      "225/225 [==============================] - 1s 3ms/step - loss: 0.5473 - accuracy: 0.7839 - val_loss: 0.5103 - val_accuracy: 0.7992\n",
      "Epoch 100/1000\n",
      "225/225 [==============================] - 1s 3ms/step - loss: 0.5498 - accuracy: 0.7824 - val_loss: 0.5132 - val_accuracy: 0.7974\n",
      "Epoch 101/1000\n",
      "225/225 [==============================] - 1s 3ms/step - loss: 0.5472 - accuracy: 0.7831 - val_loss: 0.5108 - val_accuracy: 0.7984\n",
      "Epoch 102/1000\n",
      "225/225 [==============================] - 1s 3ms/step - loss: 0.5492 - accuracy: 0.7827 - val_loss: 0.5087 - val_accuracy: 0.7996\n",
      "Epoch 103/1000\n",
      "225/225 [==============================] - 1s 3ms/step - loss: 0.5465 - accuracy: 0.7845 - val_loss: 0.5102 - val_accuracy: 0.7999\n",
      "Epoch 104/1000\n",
      "225/225 [==============================] - 1s 3ms/step - loss: 0.5452 - accuracy: 0.7830 - val_loss: 0.5113 - val_accuracy: 0.7975\n",
      "Epoch 105/1000\n",
      "225/225 [==============================] - 1s 3ms/step - loss: 0.5463 - accuracy: 0.7821 - val_loss: 0.5092 - val_accuracy: 0.8003\n",
      "Epoch 106/1000\n",
      "225/225 [==============================] - 1s 3ms/step - loss: 0.5470 - accuracy: 0.7831 - val_loss: 0.5133 - val_accuracy: 0.7973\n",
      "Epoch 107/1000\n",
      "225/225 [==============================] - 1s 3ms/step - loss: 0.5446 - accuracy: 0.7835 - val_loss: 0.5115 - val_accuracy: 0.8006\n",
      "Epoch 108/1000\n",
      "225/225 [==============================] - 1s 3ms/step - loss: 0.5455 - accuracy: 0.7831 - val_loss: 0.5069 - val_accuracy: 0.7994\n",
      "Epoch 109/1000\n",
      "225/225 [==============================] - 1s 3ms/step - loss: 0.5444 - accuracy: 0.7839 - val_loss: 0.5093 - val_accuracy: 0.7984\n",
      "Epoch 110/1000\n",
      "225/225 [==============================] - 1s 3ms/step - loss: 0.5438 - accuracy: 0.7843 - val_loss: 0.5072 - val_accuracy: 0.8010\n",
      "Epoch 111/1000\n",
      "225/225 [==============================] - 1s 3ms/step - loss: 0.5441 - accuracy: 0.7847 - val_loss: 0.5080 - val_accuracy: 0.7996\n",
      "Epoch 112/1000\n",
      "225/225 [==============================] - 1s 3ms/step - loss: 0.5445 - accuracy: 0.7840 - val_loss: 0.5094 - val_accuracy: 0.7999\n",
      "Epoch 113/1000\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "225/225 [==============================] - 1s 3ms/step - loss: 0.5438 - accuracy: 0.7842 - val_loss: 0.5087 - val_accuracy: 0.8002\n",
      "Epoch 114/1000\n",
      "225/225 [==============================] - 1s 3ms/step - loss: 0.5431 - accuracy: 0.7842 - val_loss: 0.5022 - val_accuracy: 0.8005\n",
      "Epoch 115/1000\n",
      "225/225 [==============================] - 1s 3ms/step - loss: 0.5424 - accuracy: 0.7852 - val_loss: 0.5079 - val_accuracy: 0.7998\n",
      "Epoch 116/1000\n",
      "225/225 [==============================] - 1s 3ms/step - loss: 0.5419 - accuracy: 0.7859 - val_loss: 0.5081 - val_accuracy: 0.8004\n",
      "Epoch 117/1000\n",
      "225/225 [==============================] - 1s 3ms/step - loss: 0.5446 - accuracy: 0.7843 - val_loss: 0.5049 - val_accuracy: 0.8010\n",
      "Epoch 118/1000\n",
      "225/225 [==============================] - 1s 3ms/step - loss: 0.5410 - accuracy: 0.7851 - val_loss: 0.5042 - val_accuracy: 0.8007\n",
      "Epoch 119/1000\n",
      "225/225 [==============================] - 1s 3ms/step - loss: 0.5411 - accuracy: 0.7858 - val_loss: 0.5009 - val_accuracy: 0.8031\n",
      "Epoch 120/1000\n",
      "225/225 [==============================] - 1s 3ms/step - loss: 0.5424 - accuracy: 0.7853 - val_loss: 0.5048 - val_accuracy: 0.8002\n",
      "Epoch 121/1000\n",
      "225/225 [==============================] - 1s 3ms/step - loss: 0.5417 - accuracy: 0.7852 - val_loss: 0.5049 - val_accuracy: 0.8015\n",
      "Epoch 122/1000\n",
      "225/225 [==============================] - 1s 3ms/step - loss: 0.5426 - accuracy: 0.7847 - val_loss: 0.5029 - val_accuracy: 0.8021\n",
      "Epoch 123/1000\n",
      "225/225 [==============================] - 1s 3ms/step - loss: 0.5399 - accuracy: 0.7863 - val_loss: 0.5008 - val_accuracy: 0.8012\n",
      "Epoch 124/1000\n",
      "225/225 [==============================] - 1s 3ms/step - loss: 0.5402 - accuracy: 0.7863 - val_loss: 0.5058 - val_accuracy: 0.8047\n",
      "Epoch 125/1000\n",
      "225/225 [==============================] - 1s 3ms/step - loss: 0.5413 - accuracy: 0.7848 - val_loss: 0.5056 - val_accuracy: 0.8020\n",
      "Epoch 126/1000\n",
      "225/225 [==============================] - 1s 3ms/step - loss: 0.5417 - accuracy: 0.7865 - val_loss: 0.5038 - val_accuracy: 0.8021\n",
      "Epoch 127/1000\n",
      "225/225 [==============================] - 1s 3ms/step - loss: 0.5405 - accuracy: 0.7871 - val_loss: 0.5060 - val_accuracy: 0.7989\n",
      "Epoch 128/1000\n",
      "225/225 [==============================] - 1s 3ms/step - loss: 0.5409 - accuracy: 0.7853 - val_loss: 0.5014 - val_accuracy: 0.8009\n",
      "Epoch 129/1000\n",
      "225/225 [==============================] - 1s 3ms/step - loss: 0.5395 - accuracy: 0.7856 - val_loss: 0.5005 - val_accuracy: 0.8030\n",
      "Epoch 130/1000\n",
      "225/225 [==============================] - 1s 3ms/step - loss: 0.5396 - accuracy: 0.7869 - val_loss: 0.5008 - val_accuracy: 0.8031\n",
      "Epoch 131/1000\n",
      "225/225 [==============================] - 1s 3ms/step - loss: 0.5394 - accuracy: 0.7862 - val_loss: 0.5008 - val_accuracy: 0.8036\n",
      "Epoch 132/1000\n",
      "225/225 [==============================] - 1s 3ms/step - loss: 0.5377 - accuracy: 0.7866 - val_loss: 0.4968 - val_accuracy: 0.8062\n",
      "Epoch 133/1000\n",
      "225/225 [==============================] - 1s 3ms/step - loss: 0.5383 - accuracy: 0.7866 - val_loss: 0.4999 - val_accuracy: 0.8052\n",
      "Epoch 134/1000\n",
      "225/225 [==============================] - 1s 3ms/step - loss: 0.5390 - accuracy: 0.7853 - val_loss: 0.5007 - val_accuracy: 0.8031\n",
      "Epoch 135/1000\n",
      "225/225 [==============================] - 1s 3ms/step - loss: 0.5391 - accuracy: 0.7859 - val_loss: 0.4984 - val_accuracy: 0.8032\n",
      "Epoch 136/1000\n",
      "225/225 [==============================] - 1s 3ms/step - loss: 0.5381 - accuracy: 0.7866 - val_loss: 0.4994 - val_accuracy: 0.8031\n",
      "Epoch 137/1000\n",
      "225/225 [==============================] - 1s 3ms/step - loss: 0.5368 - accuracy: 0.7868 - val_loss: 0.4973 - val_accuracy: 0.8032\n",
      "Epoch 138/1000\n",
      "225/225 [==============================] - 1s 3ms/step - loss: 0.5371 - accuracy: 0.7874 - val_loss: 0.4980 - val_accuracy: 0.8053\n",
      "Epoch 139/1000\n",
      "225/225 [==============================] - 1s 3ms/step - loss: 0.5382 - accuracy: 0.7864 - val_loss: 0.4976 - val_accuracy: 0.8049\n",
      "Epoch 140/1000\n",
      "225/225 [==============================] - 1s 3ms/step - loss: 0.5385 - accuracy: 0.7868 - val_loss: 0.4989 - val_accuracy: 0.8049\n",
      "Epoch 141/1000\n",
      "225/225 [==============================] - 1s 3ms/step - loss: 0.5372 - accuracy: 0.7869 - val_loss: 0.4994 - val_accuracy: 0.8064\n",
      "Epoch 142/1000\n",
      "225/225 [==============================] - 1s 3ms/step - loss: 0.5385 - accuracy: 0.7855 - val_loss: 0.4979 - val_accuracy: 0.8050\n",
      "Epoch 143/1000\n",
      "225/225 [==============================] - 1s 3ms/step - loss: 0.5375 - accuracy: 0.7876 - val_loss: 0.4979 - val_accuracy: 0.8048\n",
      "Epoch 144/1000\n",
      "225/225 [==============================] - 1s 3ms/step - loss: 0.5370 - accuracy: 0.7859 - val_loss: 0.4979 - val_accuracy: 0.8037\n",
      "Epoch 145/1000\n",
      "225/225 [==============================] - 1s 3ms/step - loss: 0.5360 - accuracy: 0.7879 - val_loss: 0.4988 - val_accuracy: 0.8042\n",
      "Epoch 146/1000\n",
      "225/225 [==============================] - 1s 3ms/step - loss: 0.5365 - accuracy: 0.7862 - val_loss: 0.5029 - val_accuracy: 0.8028\n",
      "Epoch 147/1000\n",
      "225/225 [==============================] - 1s 3ms/step - loss: 0.5368 - accuracy: 0.7876 - val_loss: 0.5012 - val_accuracy: 0.8050\n",
      "Epoch 148/1000\n",
      "225/225 [==============================] - 1s 3ms/step - loss: 0.5359 - accuracy: 0.7862 - val_loss: 0.4995 - val_accuracy: 0.8042\n",
      "Epoch 149/1000\n",
      "225/225 [==============================] - 1s 3ms/step - loss: 0.5357 - accuracy: 0.7882 - val_loss: 0.4949 - val_accuracy: 0.8061\n",
      "Epoch 150/1000\n",
      "225/225 [==============================] - 1s 3ms/step - loss: 0.5350 - accuracy: 0.7881 - val_loss: 0.4971 - val_accuracy: 0.8080\n",
      "Epoch 151/1000\n",
      "225/225 [==============================] - 1s 3ms/step - loss: 0.5368 - accuracy: 0.7870 - val_loss: 0.4971 - val_accuracy: 0.8048\n",
      "Epoch 152/1000\n",
      "225/225 [==============================] - 1s 3ms/step - loss: 0.5349 - accuracy: 0.7889 - val_loss: 0.4949 - val_accuracy: 0.8073\n",
      "Epoch 153/1000\n",
      "225/225 [==============================] - 1s 3ms/step - loss: 0.5343 - accuracy: 0.7884 - val_loss: 0.4931 - val_accuracy: 0.8075\n",
      "Epoch 154/1000\n",
      "225/225 [==============================] - 1s 3ms/step - loss: 0.5349 - accuracy: 0.7886 - val_loss: 0.4940 - val_accuracy: 0.8092\n",
      "Epoch 155/1000\n",
      "225/225 [==============================] - 1s 3ms/step - loss: 0.5347 - accuracy: 0.7876 - val_loss: 0.4937 - val_accuracy: 0.8099\n",
      "Epoch 156/1000\n",
      "225/225 [==============================] - 1s 3ms/step - loss: 0.5363 - accuracy: 0.7857 - val_loss: 0.4929 - val_accuracy: 0.8092\n",
      "Epoch 157/1000\n",
      "225/225 [==============================] - 1s 3ms/step - loss: 0.5332 - accuracy: 0.7884 - val_loss: 0.4913 - val_accuracy: 0.8086\n",
      "Epoch 158/1000\n",
      "225/225 [==============================] - 1s 3ms/step - loss: 0.5343 - accuracy: 0.7886 - val_loss: 0.4911 - val_accuracy: 0.8115\n",
      "Epoch 159/1000\n",
      "225/225 [==============================] - 1s 3ms/step - loss: 0.5348 - accuracy: 0.7876 - val_loss: 0.4955 - val_accuracy: 0.8085\n",
      "Epoch 160/1000\n",
      "225/225 [==============================] - 1s 3ms/step - loss: 0.5322 - accuracy: 0.7888 - val_loss: 0.4941 - val_accuracy: 0.8071\n",
      "Epoch 161/1000\n",
      "225/225 [==============================] - 1s 3ms/step - loss: 0.5342 - accuracy: 0.7878 - val_loss: 0.4932 - val_accuracy: 0.8089\n",
      "Epoch 162/1000\n",
      "225/225 [==============================] - 1s 3ms/step - loss: 0.5334 - accuracy: 0.7889 - val_loss: 0.4932 - val_accuracy: 0.8094\n",
      "Epoch 163/1000\n",
      "225/225 [==============================] - 1s 3ms/step - loss: 0.5340 - accuracy: 0.7890 - val_loss: 0.4888 - val_accuracy: 0.8077\n",
      "Epoch 164/1000\n",
      "225/225 [==============================] - 1s 3ms/step - loss: 0.5324 - accuracy: 0.7897 - val_loss: 0.4911 - val_accuracy: 0.8104\n",
      "Epoch 165/1000\n",
      "225/225 [==============================] - 1s 3ms/step - loss: 0.5342 - accuracy: 0.7887 - val_loss: 0.4910 - val_accuracy: 0.8108\n",
      "Epoch 166/1000\n",
      "225/225 [==============================] - 1s 3ms/step - loss: 0.5334 - accuracy: 0.7885 - val_loss: 0.4896 - val_accuracy: 0.8099\n",
      "Epoch 167/1000\n",
      "225/225 [==============================] - 1s 3ms/step - loss: 0.5331 - accuracy: 0.7889 - val_loss: 0.4902 - val_accuracy: 0.8079\n",
      "Epoch 168/1000\n",
      "225/225 [==============================] - 1s 3ms/step - loss: 0.5320 - accuracy: 0.7896 - val_loss: 0.4932 - val_accuracy: 0.8109\n",
      "Epoch 169/1000\n",
      "225/225 [==============================] - 1s 3ms/step - loss: 0.5314 - accuracy: 0.7893 - val_loss: 0.4925 - val_accuracy: 0.8075\n",
      "Epoch 170/1000\n",
      "225/225 [==============================] - 1s 3ms/step - loss: 0.5312 - accuracy: 0.7904 - val_loss: 0.4915 - val_accuracy: 0.8086\n",
      "Epoch 171/1000\n",
      "225/225 [==============================] - 1s 3ms/step - loss: 0.5308 - accuracy: 0.7889 - val_loss: 0.4923 - val_accuracy: 0.8086\n",
      "Epoch 172/1000\n",
      "225/225 [==============================] - 1s 3ms/step - loss: 0.5326 - accuracy: 0.7877 - val_loss: 0.4904 - val_accuracy: 0.8114\n",
      "Epoch 173/1000\n",
      "225/225 [==============================] - 1s 3ms/step - loss: 0.5314 - accuracy: 0.7900 - val_loss: 0.4926 - val_accuracy: 0.8086\n",
      "Epoch 174/1000\n",
      "225/225 [==============================] - 1s 3ms/step - loss: 0.5314 - accuracy: 0.7897 - val_loss: 0.4891 - val_accuracy: 0.8078\n",
      "Epoch 175/1000\n",
      "225/225 [==============================] - 1s 3ms/step - loss: 0.5293 - accuracy: 0.7909 - val_loss: 0.4913 - val_accuracy: 0.8085\n",
      "Epoch 176/1000\n",
      "225/225 [==============================] - 1s 3ms/step - loss: 0.5321 - accuracy: 0.7902 - val_loss: 0.4900 - val_accuracy: 0.8115\n",
      "Epoch 177/1000\n",
      "225/225 [==============================] - 1s 3ms/step - loss: 0.5313 - accuracy: 0.7891 - val_loss: 0.4900 - val_accuracy: 0.8090\n",
      "Epoch 178/1000\n",
      "225/225 [==============================] - 1s 3ms/step - loss: 0.5301 - accuracy: 0.7900 - val_loss: 0.4875 - val_accuracy: 0.8116\n",
      "Epoch 179/1000\n",
      "225/225 [==============================] - 1s 3ms/step - loss: 0.5313 - accuracy: 0.7896 - val_loss: 0.4923 - val_accuracy: 0.8087\n",
      "Epoch 180/1000\n",
      "225/225 [==============================] - 1s 3ms/step - loss: 0.5314 - accuracy: 0.7912 - val_loss: 0.4889 - val_accuracy: 0.8107\n",
      "Epoch 181/1000\n",
      "225/225 [==============================] - 1s 3ms/step - loss: 0.5288 - accuracy: 0.7914 - val_loss: 0.4891 - val_accuracy: 0.8102\n",
      "Epoch 182/1000\n",
      "225/225 [==============================] - 1s 3ms/step - loss: 0.5290 - accuracy: 0.7889 - val_loss: 0.4909 - val_accuracy: 0.8082\n",
      "Epoch 183/1000\n",
      "225/225 [==============================] - 1s 3ms/step - loss: 0.5291 - accuracy: 0.7903 - val_loss: 0.4890 - val_accuracy: 0.8107\n",
      "Epoch 184/1000\n",
      "225/225 [==============================] - 1s 3ms/step - loss: 0.5282 - accuracy: 0.7911 - val_loss: 0.4873 - val_accuracy: 0.8131\n",
      "Epoch 185/1000\n",
      "225/225 [==============================] - 1s 3ms/step - loss: 0.5301 - accuracy: 0.7894 - val_loss: 0.4887 - val_accuracy: 0.8075\n",
      "Epoch 186/1000\n",
      "225/225 [==============================] - 1s 3ms/step - loss: 0.5301 - accuracy: 0.7905 - val_loss: 0.4884 - val_accuracy: 0.8115\n",
      "Epoch 187/1000\n",
      "225/225 [==============================] - 1s 3ms/step - loss: 0.5295 - accuracy: 0.7907 - val_loss: 0.4871 - val_accuracy: 0.8115\n",
      "Epoch 188/1000\n",
      "225/225 [==============================] - 1s 2ms/step - loss: 0.5294 - accuracy: 0.7894 - val_loss: 0.4893 - val_accuracy: 0.8102\n",
      "Epoch 189/1000\n",
      "225/225 [==============================] - 1s 3ms/step - loss: 0.5293 - accuracy: 0.7897 - val_loss: 0.4881 - val_accuracy: 0.8118\n",
      "Epoch 190/1000\n",
      "225/225 [==============================] - 1s 2ms/step - loss: 0.5282 - accuracy: 0.7913 - val_loss: 0.4865 - val_accuracy: 0.8127\n",
      "Epoch 191/1000\n",
      "225/225 [==============================] - 1s 3ms/step - loss: 0.5282 - accuracy: 0.7903 - val_loss: 0.4858 - val_accuracy: 0.8100\n",
      "Epoch 192/1000\n",
      "225/225 [==============================] - 1s 2ms/step - loss: 0.5297 - accuracy: 0.7904 - val_loss: 0.4870 - val_accuracy: 0.8111\n",
      "Epoch 193/1000\n",
      "225/225 [==============================] - 1s 3ms/step - loss: 0.5284 - accuracy: 0.7886 - val_loss: 0.4861 - val_accuracy: 0.8116\n",
      "Epoch 194/1000\n",
      "225/225 [==============================] - 1s 3ms/step - loss: 0.5279 - accuracy: 0.7913 - val_loss: 0.4853 - val_accuracy: 0.8093\n",
      "Epoch 195/1000\n",
      "225/225 [==============================] - 1s 3ms/step - loss: 0.5268 - accuracy: 0.7914 - val_loss: 0.4891 - val_accuracy: 0.8136\n",
      "Epoch 196/1000\n",
      "225/225 [==============================] - 1s 3ms/step - loss: 0.5308 - accuracy: 0.7885 - val_loss: 0.4906 - val_accuracy: 0.8095\n",
      "Epoch 197/1000\n",
      "225/225 [==============================] - 1s 3ms/step - loss: 0.5274 - accuracy: 0.7911 - val_loss: 0.4885 - val_accuracy: 0.8119\n",
      "Epoch 198/1000\n",
      "225/225 [==============================] - 1s 3ms/step - loss: 0.5286 - accuracy: 0.7908 - val_loss: 0.4883 - val_accuracy: 0.8102\n",
      "Epoch 199/1000\n",
      "225/225 [==============================] - 1s 3ms/step - loss: 0.5288 - accuracy: 0.7901 - val_loss: 0.4847 - val_accuracy: 0.8113\n",
      "Epoch 200/1000\n",
      "225/225 [==============================] - 1s 3ms/step - loss: 0.5268 - accuracy: 0.7915 - val_loss: 0.4831 - val_accuracy: 0.8105\n",
      "Epoch 201/1000\n",
      "225/225 [==============================] - 1s 3ms/step - loss: 0.5271 - accuracy: 0.7925 - val_loss: 0.4894 - val_accuracy: 0.8102\n",
      "Epoch 202/1000\n",
      "225/225 [==============================] - 1s 3ms/step - loss: 0.5273 - accuracy: 0.7919 - val_loss: 0.4856 - val_accuracy: 0.8114\n",
      "Epoch 203/1000\n",
      "225/225 [==============================] - 1s 2ms/step - loss: 0.5268 - accuracy: 0.7904 - val_loss: 0.4838 - val_accuracy: 0.8130\n",
      "Epoch 204/1000\n",
      "225/225 [==============================] - 1s 3ms/step - loss: 0.5267 - accuracy: 0.7921 - val_loss: 0.4839 - val_accuracy: 0.8144\n",
      "Epoch 205/1000\n",
      "225/225 [==============================] - 1s 3ms/step - loss: 0.5270 - accuracy: 0.7921 - val_loss: 0.4866 - val_accuracy: 0.8110\n",
      "Epoch 206/1000\n",
      "225/225 [==============================] - 1s 3ms/step - loss: 0.5256 - accuracy: 0.7920 - val_loss: 0.4839 - val_accuracy: 0.8144\n",
      "Epoch 207/1000\n",
      "225/225 [==============================] - 1s 3ms/step - loss: 0.5281 - accuracy: 0.7900 - val_loss: 0.4850 - val_accuracy: 0.8137\n",
      "Epoch 208/1000\n",
      "225/225 [==============================] - 1s 3ms/step - loss: 0.5280 - accuracy: 0.7914 - val_loss: 0.4836 - val_accuracy: 0.8128\n",
      "Epoch 209/1000\n",
      "225/225 [==============================] - 1s 3ms/step - loss: 0.5288 - accuracy: 0.7905 - val_loss: 0.4861 - val_accuracy: 0.8144\n",
      "Epoch 210/1000\n",
      "225/225 [==============================] - 1s 3ms/step - loss: 0.5253 - accuracy: 0.7928 - val_loss: 0.4818 - val_accuracy: 0.8133\n",
      "Epoch 211/1000\n",
      "225/225 [==============================] - 1s 3ms/step - loss: 0.5263 - accuracy: 0.7926 - val_loss: 0.4870 - val_accuracy: 0.8104\n",
      "Epoch 212/1000\n",
      "225/225 [==============================] - 1s 3ms/step - loss: 0.5269 - accuracy: 0.7913 - val_loss: 0.4842 - val_accuracy: 0.8132\n",
      "Epoch 213/1000\n",
      "225/225 [==============================] - 1s 3ms/step - loss: 0.5243 - accuracy: 0.7923 - val_loss: 0.4835 - val_accuracy: 0.8144\n",
      "Epoch 214/1000\n",
      "225/225 [==============================] - 1s 3ms/step - loss: 0.5265 - accuracy: 0.7920 - val_loss: 0.4857 - val_accuracy: 0.8130\n",
      "Epoch 215/1000\n",
      "225/225 [==============================] - 1s 3ms/step - loss: 0.5256 - accuracy: 0.7916 - val_loss: 0.4826 - val_accuracy: 0.8151\n",
      "Epoch 216/1000\n",
      "225/225 [==============================] - 1s 3ms/step - loss: 0.5243 - accuracy: 0.7931 - val_loss: 0.4806 - val_accuracy: 0.8121\n",
      "Epoch 217/1000\n",
      "225/225 [==============================] - 1s 3ms/step - loss: 0.5243 - accuracy: 0.7924 - val_loss: 0.4817 - val_accuracy: 0.8133\n",
      "Epoch 218/1000\n",
      "225/225 [==============================] - 1s 3ms/step - loss: 0.5266 - accuracy: 0.7914 - val_loss: 0.4810 - val_accuracy: 0.8148\n",
      "Epoch 219/1000\n",
      "225/225 [==============================] - 1s 3ms/step - loss: 0.5259 - accuracy: 0.7920 - val_loss: 0.4824 - val_accuracy: 0.8119\n",
      "Epoch 220/1000\n",
      "225/225 [==============================] - 1s 3ms/step - loss: 0.5231 - accuracy: 0.7934 - val_loss: 0.4858 - val_accuracy: 0.8112\n",
      "Epoch 221/1000\n",
      "225/225 [==============================] - 1s 3ms/step - loss: 0.5260 - accuracy: 0.7923 - val_loss: 0.4908 - val_accuracy: 0.8122\n",
      "Epoch 222/1000\n",
      "225/225 [==============================] - 1s 3ms/step - loss: 0.5251 - accuracy: 0.7921 - val_loss: 0.4807 - val_accuracy: 0.8166\n",
      "Epoch 223/1000\n",
      "225/225 [==============================] - 1s 3ms/step - loss: 0.5226 - accuracy: 0.7935 - val_loss: 0.4806 - val_accuracy: 0.8161\n",
      "Epoch 224/1000\n",
      "225/225 [==============================] - 1s 3ms/step - loss: 0.5249 - accuracy: 0.7926 - val_loss: 0.4807 - val_accuracy: 0.8151\n",
      "Epoch 225/1000\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "225/225 [==============================] - 1s 3ms/step - loss: 0.5257 - accuracy: 0.7920 - val_loss: 0.4807 - val_accuracy: 0.8144\n",
      "Epoch 226/1000\n",
      "225/225 [==============================] - 1s 3ms/step - loss: 0.5245 - accuracy: 0.7936 - val_loss: 0.4808 - val_accuracy: 0.8149\n",
      "Epoch 227/1000\n",
      "225/225 [==============================] - 1s 3ms/step - loss: 0.5240 - accuracy: 0.7936 - val_loss: 0.4849 - val_accuracy: 0.8144\n",
      "Epoch 228/1000\n",
      "225/225 [==============================] - 1s 3ms/step - loss: 0.5241 - accuracy: 0.7926 - val_loss: 0.4823 - val_accuracy: 0.8146\n",
      "Epoch 229/1000\n",
      "225/225 [==============================] - 1s 3ms/step - loss: 0.5242 - accuracy: 0.7934 - val_loss: 0.4822 - val_accuracy: 0.8133\n",
      "Epoch 230/1000\n",
      "225/225 [==============================] - 1s 3ms/step - loss: 0.5233 - accuracy: 0.7936 - val_loss: 0.4791 - val_accuracy: 0.8156\n",
      "Epoch 231/1000\n",
      "225/225 [==============================] - 1s 2ms/step - loss: 0.5239 - accuracy: 0.7931 - val_loss: 0.4827 - val_accuracy: 0.8159\n",
      "Epoch 232/1000\n",
      "225/225 [==============================] - 1s 2ms/step - loss: 0.5236 - accuracy: 0.7933 - val_loss: 0.4810 - val_accuracy: 0.8145\n",
      "Epoch 233/1000\n",
      "225/225 [==============================] - 1s 3ms/step - loss: 0.5230 - accuracy: 0.7942 - val_loss: 0.4812 - val_accuracy: 0.8130\n",
      "Epoch 234/1000\n",
      "225/225 [==============================] - 1s 3ms/step - loss: 0.5248 - accuracy: 0.7918 - val_loss: 0.4794 - val_accuracy: 0.8146\n",
      "Epoch 235/1000\n",
      "225/225 [==============================] - 1s 2ms/step - loss: 0.5237 - accuracy: 0.7926 - val_loss: 0.4822 - val_accuracy: 0.8138\n",
      "Epoch 236/1000\n",
      "225/225 [==============================] - 1s 2ms/step - loss: 0.5228 - accuracy: 0.7941 - val_loss: 0.4846 - val_accuracy: 0.8137\n",
      "Epoch 237/1000\n",
      "225/225 [==============================] - 1s 2ms/step - loss: 0.5226 - accuracy: 0.7929 - val_loss: 0.4810 - val_accuracy: 0.8143\n",
      "Epoch 238/1000\n",
      "225/225 [==============================] - 1s 3ms/step - loss: 0.5238 - accuracy: 0.7931 - val_loss: 0.4821 - val_accuracy: 0.8153\n",
      "Epoch 239/1000\n",
      "225/225 [==============================] - 1s 3ms/step - loss: 0.5210 - accuracy: 0.7935 - val_loss: 0.4817 - val_accuracy: 0.8152\n",
      "Epoch 240/1000\n",
      "225/225 [==============================] - 1s 3ms/step - loss: 0.5222 - accuracy: 0.7934 - val_loss: 0.4820 - val_accuracy: 0.8138\n",
      "Epoch 241/1000\n",
      "225/225 [==============================] - 1s 3ms/step - loss: 0.5235 - accuracy: 0.7933 - val_loss: 0.4792 - val_accuracy: 0.8184\n",
      "Epoch 242/1000\n",
      "225/225 [==============================] - 1s 3ms/step - loss: 0.5236 - accuracy: 0.7930 - val_loss: 0.4799 - val_accuracy: 0.8160\n",
      "Epoch 243/1000\n",
      "225/225 [==============================] - 1s 3ms/step - loss: 0.5225 - accuracy: 0.7941 - val_loss: 0.4792 - val_accuracy: 0.8139\n",
      "Epoch 244/1000\n",
      "225/225 [==============================] - 1s 2ms/step - loss: 0.5239 - accuracy: 0.7932 - val_loss: 0.4806 - val_accuracy: 0.8143\n",
      "Epoch 245/1000\n",
      "225/225 [==============================] - 1s 2ms/step - loss: 0.5207 - accuracy: 0.7941 - val_loss: 0.4752 - val_accuracy: 0.8187\n",
      "Epoch 246/1000\n",
      "225/225 [==============================] - 1s 3ms/step - loss: 0.5227 - accuracy: 0.7927 - val_loss: 0.4816 - val_accuracy: 0.8140\n",
      "Epoch 247/1000\n",
      "225/225 [==============================] - 1s 3ms/step - loss: 0.5223 - accuracy: 0.7931 - val_loss: 0.4783 - val_accuracy: 0.8155\n",
      "Epoch 248/1000\n",
      "225/225 [==============================] - 1s 3ms/step - loss: 0.5233 - accuracy: 0.7928 - val_loss: 0.4791 - val_accuracy: 0.8144\n",
      "Epoch 249/1000\n",
      "225/225 [==============================] - 1s 3ms/step - loss: 0.5222 - accuracy: 0.7940 - val_loss: 0.4817 - val_accuracy: 0.8169\n",
      "Epoch 250/1000\n",
      "225/225 [==============================] - 1s 3ms/step - loss: 0.5222 - accuracy: 0.7937 - val_loss: 0.4817 - val_accuracy: 0.8132\n",
      "Epoch 251/1000\n",
      "225/225 [==============================] - 1s 3ms/step - loss: 0.5224 - accuracy: 0.7936 - val_loss: 0.4822 - val_accuracy: 0.8158\n",
      "Epoch 252/1000\n",
      "225/225 [==============================] - 1s 3ms/step - loss: 0.5213 - accuracy: 0.7947 - val_loss: 0.4800 - val_accuracy: 0.8133\n",
      "Epoch 253/1000\n",
      "225/225 [==============================] - 1s 3ms/step - loss: 0.5216 - accuracy: 0.7932 - val_loss: 0.4816 - val_accuracy: 0.8156\n",
      "Epoch 254/1000\n",
      "225/225 [==============================] - 1s 3ms/step - loss: 0.5241 - accuracy: 0.7927 - val_loss: 0.4785 - val_accuracy: 0.8143\n",
      "Epoch 255/1000\n",
      "225/225 [==============================] - 1s 2ms/step - loss: 0.5209 - accuracy: 0.7954 - val_loss: 0.4812 - val_accuracy: 0.8155\n",
      "Epoch 256/1000\n",
      "225/225 [==============================] - 1s 3ms/step - loss: 0.5207 - accuracy: 0.7952 - val_loss: 0.4790 - val_accuracy: 0.8169\n",
      "Epoch 257/1000\n",
      "225/225 [==============================] - 1s 3ms/step - loss: 0.5210 - accuracy: 0.7948 - val_loss: 0.4776 - val_accuracy: 0.8165\n",
      "Epoch 258/1000\n",
      "225/225 [==============================] - 1s 3ms/step - loss: 0.5211 - accuracy: 0.7942 - val_loss: 0.4789 - val_accuracy: 0.8161\n",
      "Epoch 259/1000\n",
      "225/225 [==============================] - 1s 3ms/step - loss: 0.5213 - accuracy: 0.7946 - val_loss: 0.4779 - val_accuracy: 0.8159\n",
      "Epoch 260/1000\n",
      "225/225 [==============================] - 1s 3ms/step - loss: 0.5238 - accuracy: 0.7939 - val_loss: 0.4766 - val_accuracy: 0.8172\n",
      "Epoch 261/1000\n",
      "225/225 [==============================] - 1s 3ms/step - loss: 0.5207 - accuracy: 0.7947 - val_loss: 0.4800 - val_accuracy: 0.8169\n",
      "Epoch 262/1000\n",
      "225/225 [==============================] - 1s 3ms/step - loss: 0.5231 - accuracy: 0.7929 - val_loss: 0.4774 - val_accuracy: 0.8186\n",
      "Epoch 263/1000\n",
      "225/225 [==============================] - 1s 3ms/step - loss: 0.5206 - accuracy: 0.7939 - val_loss: 0.4768 - val_accuracy: 0.8180\n",
      "Epoch 264/1000\n",
      "225/225 [==============================] - 1s 3ms/step - loss: 0.5201 - accuracy: 0.7946 - val_loss: 0.4798 - val_accuracy: 0.8175\n",
      "Epoch 265/1000\n",
      "225/225 [==============================] - 1s 3ms/step - loss: 0.5212 - accuracy: 0.7950 - val_loss: 0.4788 - val_accuracy: 0.8164\n",
      "Epoch 266/1000\n",
      "225/225 [==============================] - 1s 3ms/step - loss: 0.5204 - accuracy: 0.7937 - val_loss: 0.4769 - val_accuracy: 0.8170\n",
      "Epoch 267/1000\n",
      "225/225 [==============================] - 1s 3ms/step - loss: 0.5201 - accuracy: 0.7936 - val_loss: 0.4784 - val_accuracy: 0.8164\n",
      "Epoch 268/1000\n",
      "225/225 [==============================] - 1s 3ms/step - loss: 0.5217 - accuracy: 0.7939 - val_loss: 0.4752 - val_accuracy: 0.8191\n",
      "Epoch 269/1000\n",
      "225/225 [==============================] - 1s 3ms/step - loss: 0.5194 - accuracy: 0.7949 - val_loss: 0.4762 - val_accuracy: 0.8198\n",
      "Epoch 270/1000\n",
      "225/225 [==============================] - 1s 3ms/step - loss: 0.5212 - accuracy: 0.7947 - val_loss: 0.4785 - val_accuracy: 0.8193\n",
      "Epoch 271/1000\n",
      "225/225 [==============================] - 1s 3ms/step - loss: 0.5211 - accuracy: 0.7948 - val_loss: 0.4771 - val_accuracy: 0.8176\n",
      "Epoch 272/1000\n",
      "225/225 [==============================] - 1s 3ms/step - loss: 0.5198 - accuracy: 0.7954 - val_loss: 0.4764 - val_accuracy: 0.8177\n",
      "Epoch 273/1000\n",
      "225/225 [==============================] - 1s 3ms/step - loss: 0.5201 - accuracy: 0.7945 - val_loss: 0.4766 - val_accuracy: 0.8171\n",
      "Epoch 274/1000\n",
      "225/225 [==============================] - 1s 3ms/step - loss: 0.5217 - accuracy: 0.7938 - val_loss: 0.4806 - val_accuracy: 0.8180\n",
      "Epoch 275/1000\n",
      "225/225 [==============================] - 1s 3ms/step - loss: 0.5203 - accuracy: 0.7944 - val_loss: 0.4801 - val_accuracy: 0.8179\n",
      "Epoch 276/1000\n",
      "225/225 [==============================] - 1s 3ms/step - loss: 0.5180 - accuracy: 0.7958 - val_loss: 0.4768 - val_accuracy: 0.8169\n",
      "Epoch 277/1000\n",
      "225/225 [==============================] - 1s 3ms/step - loss: 0.5197 - accuracy: 0.7946 - val_loss: 0.4770 - val_accuracy: 0.8188\n",
      "Epoch 278/1000\n",
      "225/225 [==============================] - 1s 3ms/step - loss: 0.5200 - accuracy: 0.7941 - val_loss: 0.4736 - val_accuracy: 0.8189\n",
      "Epoch 279/1000\n",
      "225/225 [==============================] - 1s 3ms/step - loss: 0.5187 - accuracy: 0.7952 - val_loss: 0.4761 - val_accuracy: 0.8197\n",
      "Epoch 280/1000\n",
      "225/225 [==============================] - 1s 3ms/step - loss: 0.5194 - accuracy: 0.7956 - val_loss: 0.4770 - val_accuracy: 0.8191\n",
      "Epoch 281/1000\n",
      "225/225 [==============================] - 1s 3ms/step - loss: 0.5200 - accuracy: 0.7950 - val_loss: 0.4743 - val_accuracy: 0.8228\n",
      "Epoch 282/1000\n",
      "225/225 [==============================] - 1s 3ms/step - loss: 0.5193 - accuracy: 0.7951 - val_loss: 0.4755 - val_accuracy: 0.8191\n",
      "Epoch 283/1000\n",
      "225/225 [==============================] - 1s 3ms/step - loss: 0.5167 - accuracy: 0.7960 - val_loss: 0.4779 - val_accuracy: 0.8218\n",
      "Epoch 284/1000\n",
      "225/225 [==============================] - 1s 2ms/step - loss: 0.5184 - accuracy: 0.7949 - val_loss: 0.4759 - val_accuracy: 0.8206\n",
      "Epoch 285/1000\n",
      "225/225 [==============================] - 1s 3ms/step - loss: 0.5197 - accuracy: 0.7947 - val_loss: 0.4769 - val_accuracy: 0.8174\n",
      "Epoch 286/1000\n",
      "225/225 [==============================] - 1s 3ms/step - loss: 0.5196 - accuracy: 0.7953 - val_loss: 0.4753 - val_accuracy: 0.8168\n",
      "Epoch 287/1000\n",
      "225/225 [==============================] - 1s 3ms/step - loss: 0.5185 - accuracy: 0.7954 - val_loss: 0.4768 - val_accuracy: 0.8207\n",
      "Epoch 288/1000\n",
      "225/225 [==============================] - 1s 3ms/step - loss: 0.5196 - accuracy: 0.7949 - val_loss: 0.4765 - val_accuracy: 0.8189\n",
      "Epoch 289/1000\n",
      "225/225 [==============================] - 1s 3ms/step - loss: 0.5195 - accuracy: 0.7956 - val_loss: 0.4755 - val_accuracy: 0.8191\n",
      "Epoch 290/1000\n",
      "225/225 [==============================] - 1s 3ms/step - loss: 0.5185 - accuracy: 0.7949 - val_loss: 0.4760 - val_accuracy: 0.8209\n",
      "Epoch 291/1000\n",
      "225/225 [==============================] - 1s 2ms/step - loss: 0.5189 - accuracy: 0.7958 - val_loss: 0.4764 - val_accuracy: 0.8192\n",
      "Epoch 292/1000\n",
      "225/225 [==============================] - 1s 2ms/step - loss: 0.5164 - accuracy: 0.7953 - val_loss: 0.4760 - val_accuracy: 0.8188\n",
      "Epoch 293/1000\n",
      "225/225 [==============================] - 1s 2ms/step - loss: 0.5173 - accuracy: 0.7955 - val_loss: 0.4745 - val_accuracy: 0.8186\n",
      "Epoch 294/1000\n",
      "225/225 [==============================] - 1s 3ms/step - loss: 0.5201 - accuracy: 0.7951 - val_loss: 0.4746 - val_accuracy: 0.8195\n",
      "Epoch 295/1000\n",
      "225/225 [==============================] - 1s 3ms/step - loss: 0.5168 - accuracy: 0.7959 - val_loss: 0.4710 - val_accuracy: 0.8211\n",
      "Epoch 296/1000\n",
      "225/225 [==============================] - 1s 3ms/step - loss: 0.5183 - accuracy: 0.7955 - val_loss: 0.4710 - val_accuracy: 0.8217\n",
      "Epoch 297/1000\n",
      "225/225 [==============================] - 1s 3ms/step - loss: 0.5180 - accuracy: 0.7956 - val_loss: 0.4765 - val_accuracy: 0.8188\n",
      "Epoch 298/1000\n",
      "225/225 [==============================] - 1s 3ms/step - loss: 0.5173 - accuracy: 0.7958 - val_loss: 0.4747 - val_accuracy: 0.8185\n",
      "Epoch 299/1000\n",
      "225/225 [==============================] - 1s 3ms/step - loss: 0.5177 - accuracy: 0.7953 - val_loss: 0.4777 - val_accuracy: 0.8167\n",
      "Epoch 300/1000\n",
      "225/225 [==============================] - 1s 3ms/step - loss: 0.5197 - accuracy: 0.7947 - val_loss: 0.4742 - val_accuracy: 0.8215\n",
      "Epoch 301/1000\n",
      "225/225 [==============================] - 1s 3ms/step - loss: 0.5187 - accuracy: 0.7953 - val_loss: 0.4738 - val_accuracy: 0.8186\n",
      "Epoch 302/1000\n",
      "225/225 [==============================] - 1s 3ms/step - loss: 0.5185 - accuracy: 0.7952 - val_loss: 0.4747 - val_accuracy: 0.8172\n",
      "Epoch 303/1000\n",
      "225/225 [==============================] - 1s 3ms/step - loss: 0.5178 - accuracy: 0.7959 - val_loss: 0.4731 - val_accuracy: 0.8195\n",
      "Epoch 304/1000\n",
      "225/225 [==============================] - 1s 3ms/step - loss: 0.5190 - accuracy: 0.7942 - val_loss: 0.4738 - val_accuracy: 0.8191\n",
      "Epoch 305/1000\n",
      "225/225 [==============================] - 1s 3ms/step - loss: 0.5180 - accuracy: 0.7963 - val_loss: 0.4750 - val_accuracy: 0.8177\n",
      "Epoch 306/1000\n",
      "225/225 [==============================] - 1s 3ms/step - loss: 0.5178 - accuracy: 0.7951 - val_loss: 0.4770 - val_accuracy: 0.8191\n",
      "Epoch 307/1000\n",
      "225/225 [==============================] - 1s 2ms/step - loss: 0.5163 - accuracy: 0.7963 - val_loss: 0.4742 - val_accuracy: 0.8176\n",
      "Epoch 308/1000\n",
      "225/225 [==============================] - 1s 3ms/step - loss: 0.5194 - accuracy: 0.7955 - val_loss: 0.4771 - val_accuracy: 0.8184\n",
      "Epoch 309/1000\n",
      "225/225 [==============================] - 1s 3ms/step - loss: 0.5167 - accuracy: 0.7963 - val_loss: 0.4756 - val_accuracy: 0.8193\n",
      "Epoch 310/1000\n",
      "225/225 [==============================] - 1s 3ms/step - loss: 0.5175 - accuracy: 0.7954 - val_loss: 0.4731 - val_accuracy: 0.8211\n",
      "Epoch 311/1000\n",
      "225/225 [==============================] - 1s 3ms/step - loss: 0.5149 - accuracy: 0.7977 - val_loss: 0.4735 - val_accuracy: 0.8164\n",
      "Epoch 312/1000\n",
      "225/225 [==============================] - 1s 3ms/step - loss: 0.5180 - accuracy: 0.7960 - val_loss: 0.4741 - val_accuracy: 0.8158\n",
      "Epoch 313/1000\n",
      "225/225 [==============================] - 1s 3ms/step - loss: 0.5155 - accuracy: 0.7966 - val_loss: 0.4727 - val_accuracy: 0.8214\n",
      "Epoch 314/1000\n",
      "225/225 [==============================] - 1s 3ms/step - loss: 0.5170 - accuracy: 0.7960 - val_loss: 0.4759 - val_accuracy: 0.8195\n",
      "Epoch 315/1000\n",
      "225/225 [==============================] - 1s 3ms/step - loss: 0.5174 - accuracy: 0.7954 - val_loss: 0.4720 - val_accuracy: 0.8211\n",
      "Epoch 316/1000\n",
      "225/225 [==============================] - 1s 3ms/step - loss: 0.5174 - accuracy: 0.7965 - val_loss: 0.4716 - val_accuracy: 0.8224\n",
      "Epoch 317/1000\n",
      "225/225 [==============================] - 1s 3ms/step - loss: 0.5181 - accuracy: 0.7955 - val_loss: 0.4758 - val_accuracy: 0.8194\n",
      "Epoch 318/1000\n",
      "225/225 [==============================] - 1s 3ms/step - loss: 0.5204 - accuracy: 0.7948 - val_loss: 0.4781 - val_accuracy: 0.8184\n",
      "Epoch 319/1000\n",
      "225/225 [==============================] - 1s 3ms/step - loss: 0.5182 - accuracy: 0.7952 - val_loss: 0.4751 - val_accuracy: 0.8169\n",
      "Epoch 320/1000\n",
      "225/225 [==============================] - 1s 3ms/step - loss: 0.5190 - accuracy: 0.7963 - val_loss: 0.4748 - val_accuracy: 0.8164\n",
      "Epoch 321/1000\n",
      "225/225 [==============================] - 1s 3ms/step - loss: 0.5174 - accuracy: 0.7959 - val_loss: 0.4792 - val_accuracy: 0.8180\n",
      "Epoch 322/1000\n",
      "225/225 [==============================] - 1s 3ms/step - loss: 0.5167 - accuracy: 0.7962 - val_loss: 0.4748 - val_accuracy: 0.8181\n",
      "Epoch 323/1000\n",
      "225/225 [==============================] - 1s 3ms/step - loss: 0.5167 - accuracy: 0.7957 - val_loss: 0.4739 - val_accuracy: 0.8191\n",
      "Epoch 324/1000\n",
      "225/225 [==============================] - 1s 3ms/step - loss: 0.5164 - accuracy: 0.7972 - val_loss: 0.4751 - val_accuracy: 0.8182\n",
      "Epoch 325/1000\n",
      "225/225 [==============================] - 1s 2ms/step - loss: 0.5159 - accuracy: 0.7971 - val_loss: 0.4759 - val_accuracy: 0.8184\n",
      "Epoch 326/1000\n",
      "225/225 [==============================] - 1s 2ms/step - loss: 0.5161 - accuracy: 0.7975 - val_loss: 0.4734 - val_accuracy: 0.8198\n",
      "Epoch 327/1000\n",
      "225/225 [==============================] - 1s 3ms/step - loss: 0.5169 - accuracy: 0.7970 - val_loss: 0.4750 - val_accuracy: 0.8198\n",
      "Epoch 328/1000\n",
      "225/225 [==============================] - 1s 3ms/step - loss: 0.5156 - accuracy: 0.7958 - val_loss: 0.4722 - val_accuracy: 0.8194\n",
      "Epoch 329/1000\n",
      "225/225 [==============================] - 1s 3ms/step - loss: 0.5148 - accuracy: 0.7959 - val_loss: 0.4731 - val_accuracy: 0.8212\n",
      "Epoch 330/1000\n",
      "225/225 [==============================] - 1s 3ms/step - loss: 0.5171 - accuracy: 0.7956 - val_loss: 0.4735 - val_accuracy: 0.8178\n",
      "Epoch 331/1000\n",
      "225/225 [==============================] - 1s 3ms/step - loss: 0.5173 - accuracy: 0.7963 - val_loss: 0.4727 - val_accuracy: 0.8202\n",
      "Epoch 332/1000\n",
      "225/225 [==============================] - 1s 3ms/step - loss: 0.5148 - accuracy: 0.7981 - val_loss: 0.4690 - val_accuracy: 0.8190\n",
      "Epoch 333/1000\n",
      "225/225 [==============================] - 1s 3ms/step - loss: 0.5143 - accuracy: 0.7974 - val_loss: 0.4701 - val_accuracy: 0.8197\n",
      "Epoch 334/1000\n",
      "225/225 [==============================] - 1s 3ms/step - loss: 0.5169 - accuracy: 0.7971 - val_loss: 0.4750 - val_accuracy: 0.8180\n",
      "Epoch 335/1000\n",
      "225/225 [==============================] - 1s 3ms/step - loss: 0.5167 - accuracy: 0.7958 - val_loss: 0.4710 - val_accuracy: 0.8235\n",
      "Epoch 336/1000\n",
      "225/225 [==============================] - 1s 3ms/step - loss: 0.5149 - accuracy: 0.7970 - val_loss: 0.4718 - val_accuracy: 0.8198\n",
      "Epoch 337/1000\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "225/225 [==============================] - 1s 3ms/step - loss: 0.5180 - accuracy: 0.7966 - val_loss: 0.4718 - val_accuracy: 0.8173\n",
      "Epoch 338/1000\n",
      "225/225 [==============================] - 1s 3ms/step - loss: 0.5158 - accuracy: 0.7970 - val_loss: 0.4700 - val_accuracy: 0.8189\n",
      "Epoch 339/1000\n",
      "225/225 [==============================] - 1s 3ms/step - loss: 0.5151 - accuracy: 0.7977 - val_loss: 0.4715 - val_accuracy: 0.8221\n",
      "Epoch 340/1000\n",
      "225/225 [==============================] - 1s 3ms/step - loss: 0.5156 - accuracy: 0.7971 - val_loss: 0.4741 - val_accuracy: 0.8211\n",
      "Epoch 341/1000\n",
      "225/225 [==============================] - 1s 3ms/step - loss: 0.5154 - accuracy: 0.7970 - val_loss: 0.4709 - val_accuracy: 0.8198\n",
      "Epoch 342/1000\n",
      "225/225 [==============================] - 1s 3ms/step - loss: 0.5146 - accuracy: 0.7958 - val_loss: 0.4722 - val_accuracy: 0.8210\n",
      "Epoch 343/1000\n",
      "225/225 [==============================] - 1s 3ms/step - loss: 0.5145 - accuracy: 0.7971 - val_loss: 0.4706 - val_accuracy: 0.8203\n",
      "Epoch 344/1000\n",
      "225/225 [==============================] - 1s 3ms/step - loss: 0.5160 - accuracy: 0.7969 - val_loss: 0.4735 - val_accuracy: 0.8216\n",
      "Epoch 345/1000\n",
      "225/225 [==============================] - 1s 3ms/step - loss: 0.5153 - accuracy: 0.7963 - val_loss: 0.4722 - val_accuracy: 0.8203\n",
      "Epoch 346/1000\n",
      "225/225 [==============================] - 1s 3ms/step - loss: 0.5162 - accuracy: 0.7963 - val_loss: 0.4744 - val_accuracy: 0.8208\n",
      "Epoch 347/1000\n",
      "225/225 [==============================] - 1s 3ms/step - loss: 0.5162 - accuracy: 0.7962 - val_loss: 0.4741 - val_accuracy: 0.8219\n",
      "Epoch 348/1000\n",
      "225/225 [==============================] - 1s 2ms/step - loss: 0.5146 - accuracy: 0.7968 - val_loss: 0.4731 - val_accuracy: 0.8233\n",
      "Epoch 349/1000\n",
      "225/225 [==============================] - 1s 2ms/step - loss: 0.5152 - accuracy: 0.7963 - val_loss: 0.4734 - val_accuracy: 0.8191\n",
      "Epoch 350/1000\n",
      "225/225 [==============================] - 1s 3ms/step - loss: 0.5161 - accuracy: 0.7968 - val_loss: 0.4711 - val_accuracy: 0.8192\n",
      "Epoch 351/1000\n",
      "225/225 [==============================] - 1s 3ms/step - loss: 0.5134 - accuracy: 0.7967 - val_loss: 0.4729 - val_accuracy: 0.8214\n",
      "Epoch 352/1000\n",
      "225/225 [==============================] - 1s 3ms/step - loss: 0.5129 - accuracy: 0.7977 - val_loss: 0.4728 - val_accuracy: 0.8185\n",
      "Epoch 353/1000\n",
      "225/225 [==============================] - 1s 3ms/step - loss: 0.5151 - accuracy: 0.7973 - val_loss: 0.4734 - val_accuracy: 0.8200\n",
      "Epoch 354/1000\n",
      "225/225 [==============================] - 1s 2ms/step - loss: 0.5149 - accuracy: 0.7966 - val_loss: 0.4726 - val_accuracy: 0.8205\n",
      "Epoch 355/1000\n",
      "225/225 [==============================] - 1s 2ms/step - loss: 0.5141 - accuracy: 0.7982 - val_loss: 0.4706 - val_accuracy: 0.8215\n",
      "Epoch 356/1000\n",
      "225/225 [==============================] - 1s 3ms/step - loss: 0.5139 - accuracy: 0.7967 - val_loss: 0.4734 - val_accuracy: 0.8196\n",
      "Epoch 357/1000\n",
      "225/225 [==============================] - 1s 3ms/step - loss: 0.5161 - accuracy: 0.7964 - val_loss: 0.4726 - val_accuracy: 0.8211\n",
      "Epoch 358/1000\n",
      "225/225 [==============================] - 1s 3ms/step - loss: 0.5120 - accuracy: 0.7981 - val_loss: 0.4718 - val_accuracy: 0.8170\n",
      "Epoch 359/1000\n",
      "225/225 [==============================] - 1s 3ms/step - loss: 0.5125 - accuracy: 0.7975 - val_loss: 0.4707 - val_accuracy: 0.8203\n",
      "Epoch 360/1000\n",
      "225/225 [==============================] - 1s 3ms/step - loss: 0.5153 - accuracy: 0.7976 - val_loss: 0.4745 - val_accuracy: 0.8191\n",
      "Epoch 361/1000\n",
      "225/225 [==============================] - 1s 3ms/step - loss: 0.5127 - accuracy: 0.7980 - val_loss: 0.4732 - val_accuracy: 0.8214\n",
      "Epoch 362/1000\n",
      "225/225 [==============================] - 1s 3ms/step - loss: 0.5153 - accuracy: 0.7960 - val_loss: 0.4708 - val_accuracy: 0.8200\n",
      "Epoch 363/1000\n",
      "225/225 [==============================] - 1s 3ms/step - loss: 0.5157 - accuracy: 0.7972 - val_loss: 0.4726 - val_accuracy: 0.8209\n",
      "Epoch 364/1000\n",
      "225/225 [==============================] - 1s 3ms/step - loss: 0.5149 - accuracy: 0.7975 - val_loss: 0.4714 - val_accuracy: 0.8225\n",
      "Epoch 365/1000\n",
      "225/225 [==============================] - 1s 3ms/step - loss: 0.5135 - accuracy: 0.7977 - val_loss: 0.4686 - val_accuracy: 0.8224\n",
      "Epoch 366/1000\n",
      "225/225 [==============================] - 1s 3ms/step - loss: 0.5141 - accuracy: 0.7978 - val_loss: 0.4719 - val_accuracy: 0.8183\n",
      "Epoch 367/1000\n",
      "225/225 [==============================] - 1s 3ms/step - loss: 0.5121 - accuracy: 0.7982 - val_loss: 0.4717 - val_accuracy: 0.8205\n",
      "Epoch 368/1000\n",
      "225/225 [==============================] - 1s 3ms/step - loss: 0.5125 - accuracy: 0.7966 - val_loss: 0.4709 - val_accuracy: 0.8200\n",
      "Epoch 369/1000\n",
      "225/225 [==============================] - 1s 3ms/step - loss: 0.5136 - accuracy: 0.7983 - val_loss: 0.4738 - val_accuracy: 0.8216\n",
      "Epoch 370/1000\n",
      "225/225 [==============================] - 1s 3ms/step - loss: 0.5128 - accuracy: 0.7972 - val_loss: 0.4739 - val_accuracy: 0.8195\n",
      "Epoch 371/1000\n",
      "225/225 [==============================] - 1s 3ms/step - loss: 0.5129 - accuracy: 0.7980 - val_loss: 0.4728 - val_accuracy: 0.8201\n",
      "Epoch 372/1000\n",
      "225/225 [==============================] - 1s 3ms/step - loss: 0.5133 - accuracy: 0.7968 - val_loss: 0.4700 - val_accuracy: 0.8177\n",
      "Epoch 373/1000\n",
      "225/225 [==============================] - 1s 3ms/step - loss: 0.5127 - accuracy: 0.7981 - val_loss: 0.4693 - val_accuracy: 0.8200\n",
      "Epoch 374/1000\n",
      "225/225 [==============================] - 1s 3ms/step - loss: 0.5143 - accuracy: 0.7974 - val_loss: 0.4724 - val_accuracy: 0.8209\n",
      "Epoch 375/1000\n",
      "225/225 [==============================] - 1s 3ms/step - loss: 0.5122 - accuracy: 0.7982 - val_loss: 0.4704 - val_accuracy: 0.8209\n",
      "Epoch 376/1000\n",
      "225/225 [==============================] - 1s 3ms/step - loss: 0.5133 - accuracy: 0.7974 - val_loss: 0.4731 - val_accuracy: 0.8173\n",
      "Epoch 377/1000\n",
      "225/225 [==============================] - 1s 3ms/step - loss: 0.5137 - accuracy: 0.7986 - val_loss: 0.4722 - val_accuracy: 0.8220\n",
      "Epoch 378/1000\n",
      "225/225 [==============================] - 1s 3ms/step - loss: 0.5144 - accuracy: 0.7971 - val_loss: 0.4706 - val_accuracy: 0.8202\n",
      "Epoch 379/1000\n",
      "225/225 [==============================] - 1s 3ms/step - loss: 0.5140 - accuracy: 0.7978 - val_loss: 0.4711 - val_accuracy: 0.8231\n",
      "Epoch 380/1000\n",
      "225/225 [==============================] - 1s 3ms/step - loss: 0.5142 - accuracy: 0.7977 - val_loss: 0.4762 - val_accuracy: 0.8191\n",
      "Epoch 381/1000\n",
      "225/225 [==============================] - 1s 2ms/step - loss: 0.5127 - accuracy: 0.7979 - val_loss: 0.4737 - val_accuracy: 0.8187\n",
      "Epoch 382/1000\n",
      "225/225 [==============================] - 1s 2ms/step - loss: 0.5152 - accuracy: 0.7979 - val_loss: 0.4719 - val_accuracy: 0.8188\n",
      "Epoch 383/1000\n",
      "225/225 [==============================] - 1s 3ms/step - loss: 0.5130 - accuracy: 0.7968 - val_loss: 0.4699 - val_accuracy: 0.8207\n",
      "Epoch 384/1000\n",
      "225/225 [==============================] - 1s 3ms/step - loss: 0.5115 - accuracy: 0.7974 - val_loss: 0.4696 - val_accuracy: 0.8213\n",
      "Epoch 385/1000\n",
      "225/225 [==============================] - 1s 3ms/step - loss: 0.5129 - accuracy: 0.7974 - val_loss: 0.4697 - val_accuracy: 0.8206\n",
      "Epoch 386/1000\n",
      "225/225 [==============================] - 1s 3ms/step - loss: 0.5141 - accuracy: 0.7977 - val_loss: 0.4717 - val_accuracy: 0.8204\n",
      "Epoch 387/1000\n",
      "225/225 [==============================] - 1s 3ms/step - loss: 0.5135 - accuracy: 0.7974 - val_loss: 0.4685 - val_accuracy: 0.8235\n",
      "Epoch 388/1000\n",
      "225/225 [==============================] - 1s 3ms/step - loss: 0.5124 - accuracy: 0.7982 - val_loss: 0.4708 - val_accuracy: 0.8224\n",
      "Epoch 389/1000\n",
      "225/225 [==============================] - 1s 3ms/step - loss: 0.5128 - accuracy: 0.7980 - val_loss: 0.4701 - val_accuracy: 0.8224\n",
      "Epoch 390/1000\n",
      "225/225 [==============================] - 1s 3ms/step - loss: 0.5159 - accuracy: 0.7971 - val_loss: 0.4685 - val_accuracy: 0.8235\n",
      "Epoch 391/1000\n",
      "225/225 [==============================] - 1s 3ms/step - loss: 0.5108 - accuracy: 0.7987 - val_loss: 0.4672 - val_accuracy: 0.8225\n",
      "Epoch 392/1000\n",
      "225/225 [==============================] - 1s 3ms/step - loss: 0.5128 - accuracy: 0.7987 - val_loss: 0.4698 - val_accuracy: 0.8231\n",
      "Epoch 393/1000\n",
      "225/225 [==============================] - 1s 3ms/step - loss: 0.5120 - accuracy: 0.7987 - val_loss: 0.4702 - val_accuracy: 0.8217\n",
      "Epoch 394/1000\n",
      "225/225 [==============================] - 1s 3ms/step - loss: 0.5134 - accuracy: 0.7974 - val_loss: 0.4725 - val_accuracy: 0.8198\n",
      "Epoch 395/1000\n",
      "225/225 [==============================] - 1s 3ms/step - loss: 0.5138 - accuracy: 0.7975 - val_loss: 0.4698 - val_accuracy: 0.8213\n",
      "Epoch 396/1000\n",
      "225/225 [==============================] - 1s 3ms/step - loss: 0.5119 - accuracy: 0.7985 - val_loss: 0.4747 - val_accuracy: 0.8192\n",
      "Epoch 397/1000\n",
      "225/225 [==============================] - 1s 3ms/step - loss: 0.5116 - accuracy: 0.7985 - val_loss: 0.4721 - val_accuracy: 0.8210\n",
      "Epoch 398/1000\n",
      "225/225 [==============================] - 1s 3ms/step - loss: 0.5122 - accuracy: 0.7987 - val_loss: 0.4686 - val_accuracy: 0.8231\n",
      "Epoch 399/1000\n",
      "225/225 [==============================] - 1s 3ms/step - loss: 0.5124 - accuracy: 0.7982 - val_loss: 0.4685 - val_accuracy: 0.8235\n",
      "Epoch 400/1000\n",
      "225/225 [==============================] - 1s 3ms/step - loss: 0.5101 - accuracy: 0.8002 - val_loss: 0.4668 - val_accuracy: 0.8242\n",
      "Epoch 401/1000\n",
      "225/225 [==============================] - 1s 3ms/step - loss: 0.5113 - accuracy: 0.7986 - val_loss: 0.4690 - val_accuracy: 0.8223\n",
      "Epoch 402/1000\n",
      "225/225 [==============================] - 1s 3ms/step - loss: 0.5117 - accuracy: 0.7981 - val_loss: 0.4691 - val_accuracy: 0.8217\n",
      "Epoch 403/1000\n",
      "225/225 [==============================] - 1s 3ms/step - loss: 0.5130 - accuracy: 0.7987 - val_loss: 0.4708 - val_accuracy: 0.8240\n",
      "Epoch 404/1000\n",
      "225/225 [==============================] - 1s 3ms/step - loss: 0.5119 - accuracy: 0.7987 - val_loss: 0.4695 - val_accuracy: 0.8216\n",
      "Epoch 405/1000\n",
      "225/225 [==============================] - 1s 3ms/step - loss: 0.5145 - accuracy: 0.7976 - val_loss: 0.4707 - val_accuracy: 0.8217\n",
      "Epoch 406/1000\n",
      "225/225 [==============================] - 1s 3ms/step - loss: 0.5131 - accuracy: 0.7992 - val_loss: 0.4709 - val_accuracy: 0.8228\n",
      "Epoch 407/1000\n",
      "225/225 [==============================] - 1s 3ms/step - loss: 0.5126 - accuracy: 0.7987 - val_loss: 0.4676 - val_accuracy: 0.8247\n",
      "Epoch 408/1000\n",
      "225/225 [==============================] - 1s 3ms/step - loss: 0.5122 - accuracy: 0.7988 - val_loss: 0.4672 - val_accuracy: 0.8267\n",
      "Epoch 409/1000\n",
      "225/225 [==============================] - 1s 3ms/step - loss: 0.5107 - accuracy: 0.7996 - val_loss: 0.4712 - val_accuracy: 0.8220\n",
      "Epoch 410/1000\n",
      "225/225 [==============================] - 1s 3ms/step - loss: 0.5128 - accuracy: 0.7978 - val_loss: 0.4664 - val_accuracy: 0.8223\n",
      "Epoch 411/1000\n",
      "225/225 [==============================] - 1s 3ms/step - loss: 0.5122 - accuracy: 0.7982 - val_loss: 0.4712 - val_accuracy: 0.8210\n",
      "Epoch 412/1000\n",
      "225/225 [==============================] - 1s 3ms/step - loss: 0.5097 - accuracy: 0.7994 - val_loss: 0.4668 - val_accuracy: 0.8253\n",
      "Epoch 413/1000\n",
      "225/225 [==============================] - 1s 3ms/step - loss: 0.5113 - accuracy: 0.7985 - val_loss: 0.4702 - val_accuracy: 0.8232\n",
      "Epoch 414/1000\n",
      "225/225 [==============================] - 1s 3ms/step - loss: 0.5116 - accuracy: 0.7988 - val_loss: 0.4683 - val_accuracy: 0.8219\n",
      "Epoch 415/1000\n",
      "225/225 [==============================] - 1s 3ms/step - loss: 0.5122 - accuracy: 0.7985 - val_loss: 0.4688 - val_accuracy: 0.8198\n",
      "Epoch 416/1000\n",
      "225/225 [==============================] - 1s 3ms/step - loss: 0.5107 - accuracy: 0.7999 - val_loss: 0.4674 - val_accuracy: 0.8207\n",
      "Epoch 417/1000\n",
      "225/225 [==============================] - 1s 3ms/step - loss: 0.5124 - accuracy: 0.7979 - val_loss: 0.4688 - val_accuracy: 0.8212\n",
      "Epoch 418/1000\n",
      "225/225 [==============================] - 1s 3ms/step - loss: 0.5092 - accuracy: 0.8002 - val_loss: 0.4678 - val_accuracy: 0.8224\n",
      "Epoch 419/1000\n",
      "225/225 [==============================] - 1s 3ms/step - loss: 0.5120 - accuracy: 0.7992 - val_loss: 0.4712 - val_accuracy: 0.8231\n",
      "Epoch 420/1000\n",
      "225/225 [==============================] - 1s 3ms/step - loss: 0.5126 - accuracy: 0.7982 - val_loss: 0.4694 - val_accuracy: 0.8231\n",
      "Epoch 421/1000\n",
      "225/225 [==============================] - 1s 3ms/step - loss: 0.5109 - accuracy: 0.7989 - val_loss: 0.4680 - val_accuracy: 0.8255\n",
      "Epoch 422/1000\n",
      "225/225 [==============================] - 1s 3ms/step - loss: 0.5098 - accuracy: 0.7997 - val_loss: 0.4687 - val_accuracy: 0.8214\n",
      "Epoch 423/1000\n",
      "225/225 [==============================] - 1s 3ms/step - loss: 0.5098 - accuracy: 0.7997 - val_loss: 0.4692 - val_accuracy: 0.8224\n",
      "Epoch 424/1000\n",
      "225/225 [==============================] - 1s 3ms/step - loss: 0.5116 - accuracy: 0.7986 - val_loss: 0.4695 - val_accuracy: 0.8204\n",
      "Epoch 425/1000\n",
      "225/225 [==============================] - 1s 3ms/step - loss: 0.5106 - accuracy: 0.8003 - val_loss: 0.4723 - val_accuracy: 0.8205\n",
      "Epoch 426/1000\n",
      "225/225 [==============================] - 1s 3ms/step - loss: 0.5122 - accuracy: 0.7984 - val_loss: 0.4674 - val_accuracy: 0.8221\n",
      "Epoch 427/1000\n",
      "225/225 [==============================] - 1s 3ms/step - loss: 0.5111 - accuracy: 0.7988 - val_loss: 0.4677 - val_accuracy: 0.8216\n",
      "Epoch 428/1000\n",
      "225/225 [==============================] - 1s 3ms/step - loss: 0.5097 - accuracy: 0.7993 - val_loss: 0.4667 - val_accuracy: 0.8224\n",
      "Epoch 429/1000\n",
      "225/225 [==============================] - 1s 3ms/step - loss: 0.5113 - accuracy: 0.7992 - val_loss: 0.4677 - val_accuracy: 0.8228\n",
      "Epoch 430/1000\n",
      "225/225 [==============================] - 1s 3ms/step - loss: 0.5104 - accuracy: 0.7999 - val_loss: 0.4676 - val_accuracy: 0.8236\n",
      "Epoch 431/1000\n",
      "225/225 [==============================] - 1s 3ms/step - loss: 0.5093 - accuracy: 0.7997 - val_loss: 0.4685 - val_accuracy: 0.8223\n",
      "Epoch 432/1000\n",
      "225/225 [==============================] - 1s 3ms/step - loss: 0.5095 - accuracy: 0.7989 - val_loss: 0.4683 - val_accuracy: 0.8246\n",
      "Epoch 433/1000\n",
      "225/225 [==============================] - 1s 3ms/step - loss: 0.5108 - accuracy: 0.7976 - val_loss: 0.4691 - val_accuracy: 0.8219\n",
      "Epoch 434/1000\n",
      "225/225 [==============================] - 1s 2ms/step - loss: 0.5106 - accuracy: 0.7986 - val_loss: 0.4680 - val_accuracy: 0.8238\n",
      "Epoch 435/1000\n",
      "225/225 [==============================] - 1s 3ms/step - loss: 0.5069 - accuracy: 0.8000 - val_loss: 0.4664 - val_accuracy: 0.8243\n",
      "Epoch 436/1000\n",
      "225/225 [==============================] - 1s 3ms/step - loss: 0.5108 - accuracy: 0.7995 - val_loss: 0.4723 - val_accuracy: 0.8206\n",
      "Epoch 437/1000\n",
      "225/225 [==============================] - 1s 3ms/step - loss: 0.5118 - accuracy: 0.7989 - val_loss: 0.4673 - val_accuracy: 0.8243\n",
      "Epoch 438/1000\n",
      "225/225 [==============================] - 1s 3ms/step - loss: 0.5098 - accuracy: 0.7990 - val_loss: 0.4651 - val_accuracy: 0.8238\n",
      "Epoch 439/1000\n",
      "225/225 [==============================] - 1s 3ms/step - loss: 0.5105 - accuracy: 0.7992 - val_loss: 0.4698 - val_accuracy: 0.8245\n",
      "Epoch 440/1000\n",
      "225/225 [==============================] - 1s 3ms/step - loss: 0.5090 - accuracy: 0.7994 - val_loss: 0.4693 - val_accuracy: 0.8232\n",
      "Epoch 441/1000\n",
      "225/225 [==============================] - 1s 3ms/step - loss: 0.5104 - accuracy: 0.7998 - val_loss: 0.4685 - val_accuracy: 0.8246\n",
      "Epoch 442/1000\n",
      "225/225 [==============================] - 1s 3ms/step - loss: 0.5093 - accuracy: 0.8001 - val_loss: 0.4652 - val_accuracy: 0.8249\n",
      "Epoch 443/1000\n",
      "225/225 [==============================] - 1s 3ms/step - loss: 0.5100 - accuracy: 0.7995 - val_loss: 0.4662 - val_accuracy: 0.8235\n",
      "Epoch 444/1000\n",
      "225/225 [==============================] - 1s 2ms/step - loss: 0.5121 - accuracy: 0.7987 - val_loss: 0.4697 - val_accuracy: 0.8223\n",
      "Epoch 445/1000\n",
      "225/225 [==============================] - 1s 3ms/step - loss: 0.5085 - accuracy: 0.8002 - val_loss: 0.4656 - val_accuracy: 0.8234\n",
      "Epoch 446/1000\n",
      "225/225 [==============================] - 1s 3ms/step - loss: 0.5092 - accuracy: 0.7992 - val_loss: 0.4681 - val_accuracy: 0.8212\n",
      "Epoch 447/1000\n",
      "225/225 [==============================] - 1s 2ms/step - loss: 0.5087 - accuracy: 0.7993 - val_loss: 0.4666 - val_accuracy: 0.8225\n",
      "Epoch 448/1000\n",
      "225/225 [==============================] - 1s 3ms/step - loss: 0.5116 - accuracy: 0.7986 - val_loss: 0.4677 - val_accuracy: 0.8245\n",
      "Epoch 449/1000\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "225/225 [==============================] - 1s 2ms/step - loss: 0.5096 - accuracy: 0.7991 - val_loss: 0.4682 - val_accuracy: 0.8225\n",
      "Epoch 450/1000\n",
      "225/225 [==============================] - 1s 2ms/step - loss: 0.5097 - accuracy: 0.8005 - val_loss: 0.4656 - val_accuracy: 0.8228\n",
      "Epoch 451/1000\n",
      "225/225 [==============================] - 1s 3ms/step - loss: 0.5104 - accuracy: 0.7992 - val_loss: 0.4655 - val_accuracy: 0.8218\n",
      "Epoch 452/1000\n",
      "225/225 [==============================] - 1s 3ms/step - loss: 0.5102 - accuracy: 0.7993 - val_loss: 0.4676 - val_accuracy: 0.8208\n",
      "Epoch 453/1000\n",
      "225/225 [==============================] - 1s 3ms/step - loss: 0.5091 - accuracy: 0.7997 - val_loss: 0.4697 - val_accuracy: 0.8204\n",
      "Epoch 454/1000\n",
      "225/225 [==============================] - 1s 3ms/step - loss: 0.5110 - accuracy: 0.8005 - val_loss: 0.4680 - val_accuracy: 0.8217\n",
      "Epoch 455/1000\n",
      "225/225 [==============================] - 1s 3ms/step - loss: 0.5113 - accuracy: 0.7987 - val_loss: 0.4690 - val_accuracy: 0.8245\n",
      "Epoch 456/1000\n",
      "225/225 [==============================] - 1s 3ms/step - loss: 0.5112 - accuracy: 0.7984 - val_loss: 0.4666 - val_accuracy: 0.8216\n",
      "Epoch 457/1000\n",
      "225/225 [==============================] - 1s 3ms/step - loss: 0.5101 - accuracy: 0.8001 - val_loss: 0.4656 - val_accuracy: 0.8226\n",
      "Epoch 458/1000\n",
      "225/225 [==============================] - 1s 2ms/step - loss: 0.5105 - accuracy: 0.7988 - val_loss: 0.4657 - val_accuracy: 0.8245\n",
      "Epoch 459/1000\n",
      "225/225 [==============================] - 1s 2ms/step - loss: 0.5114 - accuracy: 0.7993 - val_loss: 0.4701 - val_accuracy: 0.8231\n",
      "Epoch 460/1000\n",
      "225/225 [==============================] - 1s 3ms/step - loss: 0.5096 - accuracy: 0.7986 - val_loss: 0.4678 - val_accuracy: 0.8216\n",
      "Epoch 461/1000\n",
      "225/225 [==============================] - 1s 3ms/step - loss: 0.5082 - accuracy: 0.7996 - val_loss: 0.4663 - val_accuracy: 0.8234\n",
      "Epoch 462/1000\n",
      "225/225 [==============================] - 1s 3ms/step - loss: 0.5068 - accuracy: 0.8001 - val_loss: 0.4649 - val_accuracy: 0.8230\n",
      "Epoch 463/1000\n",
      "225/225 [==============================] - 1s 3ms/step - loss: 0.5084 - accuracy: 0.7996 - val_loss: 0.4647 - val_accuracy: 0.8227\n",
      "Epoch 464/1000\n",
      "225/225 [==============================] - 1s 3ms/step - loss: 0.5081 - accuracy: 0.8008 - val_loss: 0.4688 - val_accuracy: 0.8242\n",
      "Epoch 465/1000\n",
      "225/225 [==============================] - 1s 3ms/step - loss: 0.5090 - accuracy: 0.7995 - val_loss: 0.4682 - val_accuracy: 0.8228\n",
      "Epoch 466/1000\n",
      "225/225 [==============================] - 1s 3ms/step - loss: 0.5097 - accuracy: 0.7988 - val_loss: 0.4701 - val_accuracy: 0.8223\n",
      "Epoch 467/1000\n",
      "225/225 [==============================] - 1s 3ms/step - loss: 0.5073 - accuracy: 0.8003 - val_loss: 0.4671 - val_accuracy: 0.8241\n",
      "Epoch 468/1000\n",
      "225/225 [==============================] - 1s 3ms/step - loss: 0.5104 - accuracy: 0.7994 - val_loss: 0.4693 - val_accuracy: 0.8224\n",
      "Epoch 469/1000\n",
      "225/225 [==============================] - 1s 3ms/step - loss: 0.5091 - accuracy: 0.7994 - val_loss: 0.4666 - val_accuracy: 0.8227\n",
      "Epoch 470/1000\n",
      "225/225 [==============================] - 1s 3ms/step - loss: 0.5128 - accuracy: 0.7982 - val_loss: 0.4670 - val_accuracy: 0.8242\n",
      "Epoch 471/1000\n",
      "225/225 [==============================] - 1s 3ms/step - loss: 0.5098 - accuracy: 0.7996 - val_loss: 0.4668 - val_accuracy: 0.8242\n",
      "Epoch 472/1000\n",
      "225/225 [==============================] - 1s 2ms/step - loss: 0.5078 - accuracy: 0.8008 - val_loss: 0.4685 - val_accuracy: 0.8227\n",
      "Epoch 473/1000\n",
      "225/225 [==============================] - 1s 2ms/step - loss: 0.5081 - accuracy: 0.7996 - val_loss: 0.4655 - val_accuracy: 0.8249\n",
      "Epoch 474/1000\n",
      "225/225 [==============================] - 1s 3ms/step - loss: 0.5098 - accuracy: 0.7992 - val_loss: 0.4662 - val_accuracy: 0.8233\n",
      "Epoch 475/1000\n",
      "225/225 [==============================] - 1s 3ms/step - loss: 0.5075 - accuracy: 0.8013 - val_loss: 0.4683 - val_accuracy: 0.8225\n",
      "Epoch 476/1000\n",
      "225/225 [==============================] - 1s 3ms/step - loss: 0.5086 - accuracy: 0.8001 - val_loss: 0.4664 - val_accuracy: 0.8242\n",
      "Epoch 477/1000\n",
      "225/225 [==============================] - 1s 3ms/step - loss: 0.5103 - accuracy: 0.7992 - val_loss: 0.4669 - val_accuracy: 0.8222\n",
      "Epoch 478/1000\n",
      "225/225 [==============================] - 1s 3ms/step - loss: 0.5071 - accuracy: 0.8021 - val_loss: 0.4689 - val_accuracy: 0.8249\n",
      "Epoch 479/1000\n",
      "225/225 [==============================] - 1s 3ms/step - loss: 0.5079 - accuracy: 0.8010 - val_loss: 0.4666 - val_accuracy: 0.8223\n",
      "Epoch 480/1000\n",
      "225/225 [==============================] - 1s 3ms/step - loss: 0.5079 - accuracy: 0.8007 - val_loss: 0.4661 - val_accuracy: 0.8241\n",
      "Epoch 481/1000\n",
      "225/225 [==============================] - 1s 3ms/step - loss: 0.5076 - accuracy: 0.8007 - val_loss: 0.4651 - val_accuracy: 0.8246\n",
      "Epoch 482/1000\n",
      "225/225 [==============================] - 1s 3ms/step - loss: 0.5063 - accuracy: 0.8006 - val_loss: 0.4659 - val_accuracy: 0.8259\n",
      "Epoch 483/1000\n",
      "225/225 [==============================] - 1s 3ms/step - loss: 0.5084 - accuracy: 0.7999 - val_loss: 0.4677 - val_accuracy: 0.8220\n",
      "Epoch 484/1000\n",
      "225/225 [==============================] - 1s 3ms/step - loss: 0.5098 - accuracy: 0.7997 - val_loss: 0.4669 - val_accuracy: 0.8227\n",
      "Epoch 485/1000\n",
      "225/225 [==============================] - 1s 3ms/step - loss: 0.5083 - accuracy: 0.8003 - val_loss: 0.4645 - val_accuracy: 0.8224\n",
      "Epoch 486/1000\n",
      "225/225 [==============================] - 1s 3ms/step - loss: 0.5079 - accuracy: 0.8000 - val_loss: 0.4692 - val_accuracy: 0.8240\n",
      "Epoch 487/1000\n",
      "225/225 [==============================] - 1s 3ms/step - loss: 0.5100 - accuracy: 0.8005 - val_loss: 0.4653 - val_accuracy: 0.8238\n",
      "Epoch 488/1000\n",
      "225/225 [==============================] - 1s 3ms/step - loss: 0.5087 - accuracy: 0.8011 - val_loss: 0.4685 - val_accuracy: 0.8227\n",
      "Epoch 489/1000\n",
      "225/225 [==============================] - 1s 3ms/step - loss: 0.5069 - accuracy: 0.8008 - val_loss: 0.4686 - val_accuracy: 0.8261\n",
      "Epoch 490/1000\n",
      "225/225 [==============================] - 1s 3ms/step - loss: 0.5071 - accuracy: 0.8011 - val_loss: 0.4664 - val_accuracy: 0.8237\n",
      "Epoch 491/1000\n",
      "225/225 [==============================] - 1s 3ms/step - loss: 0.5082 - accuracy: 0.8003 - val_loss: 0.4649 - val_accuracy: 0.8242\n",
      "Epoch 492/1000\n",
      "225/225 [==============================] - 1s 3ms/step - loss: 0.5079 - accuracy: 0.8002 - val_loss: 0.4658 - val_accuracy: 0.8236\n",
      "Epoch 493/1000\n",
      "225/225 [==============================] - 1s 3ms/step - loss: 0.5094 - accuracy: 0.7997 - val_loss: 0.4633 - val_accuracy: 0.8252\n",
      "Epoch 494/1000\n",
      "225/225 [==============================] - 1s 3ms/step - loss: 0.5090 - accuracy: 0.7997 - val_loss: 0.4648 - val_accuracy: 0.8246\n",
      "Epoch 495/1000\n",
      "225/225 [==============================] - 1s 2ms/step - loss: 0.5079 - accuracy: 0.7998 - val_loss: 0.4659 - val_accuracy: 0.8247\n",
      "Epoch 496/1000\n",
      "225/225 [==============================] - 1s 3ms/step - loss: 0.5066 - accuracy: 0.8012 - val_loss: 0.4647 - val_accuracy: 0.8247\n",
      "Epoch 497/1000\n",
      "225/225 [==============================] - 1s 3ms/step - loss: 0.5098 - accuracy: 0.7992 - val_loss: 0.4624 - val_accuracy: 0.8254\n",
      "Epoch 498/1000\n",
      "225/225 [==============================] - 1s 3ms/step - loss: 0.5079 - accuracy: 0.8008 - val_loss: 0.4638 - val_accuracy: 0.8255\n",
      "Epoch 499/1000\n",
      "225/225 [==============================] - 1s 3ms/step - loss: 0.5079 - accuracy: 0.8005 - val_loss: 0.4643 - val_accuracy: 0.8244\n",
      "Epoch 500/1000\n",
      "225/225 [==============================] - 1s 3ms/step - loss: 0.5071 - accuracy: 0.8012 - val_loss: 0.4643 - val_accuracy: 0.8245\n",
      "Epoch 501/1000\n",
      "225/225 [==============================] - 1s 3ms/step - loss: 0.5063 - accuracy: 0.8019 - val_loss: 0.4662 - val_accuracy: 0.8251\n",
      "Epoch 502/1000\n",
      "225/225 [==============================] - 1s 3ms/step - loss: 0.5084 - accuracy: 0.8007 - val_loss: 0.4672 - val_accuracy: 0.8249\n",
      "Epoch 503/1000\n",
      "225/225 [==============================] - 1s 3ms/step - loss: 0.5078 - accuracy: 0.8001 - val_loss: 0.4632 - val_accuracy: 0.8256\n",
      "Epoch 504/1000\n",
      "225/225 [==============================] - 1s 3ms/step - loss: 0.5069 - accuracy: 0.8008 - val_loss: 0.4670 - val_accuracy: 0.8221\n",
      "Epoch 505/1000\n",
      "225/225 [==============================] - 1s 2ms/step - loss: 0.5074 - accuracy: 0.8008 - val_loss: 0.4657 - val_accuracy: 0.8246\n",
      "Epoch 506/1000\n",
      "225/225 [==============================] - 1s 3ms/step - loss: 0.5059 - accuracy: 0.8010 - val_loss: 0.4681 - val_accuracy: 0.8242\n",
      "Epoch 507/1000\n",
      "225/225 [==============================] - 1s 2ms/step - loss: 0.5070 - accuracy: 0.7997 - val_loss: 0.4678 - val_accuracy: 0.8231\n",
      "Epoch 508/1000\n",
      "225/225 [==============================] - 1s 3ms/step - loss: 0.5079 - accuracy: 0.8009 - val_loss: 0.4675 - val_accuracy: 0.8267\n",
      "Epoch 509/1000\n",
      "225/225 [==============================] - 1s 3ms/step - loss: 0.5062 - accuracy: 0.8013 - val_loss: 0.4652 - val_accuracy: 0.8234\n",
      "Epoch 510/1000\n",
      "225/225 [==============================] - 1s 3ms/step - loss: 0.5064 - accuracy: 0.8014 - val_loss: 0.4664 - val_accuracy: 0.8242\n",
      "Epoch 511/1000\n",
      "225/225 [==============================] - 1s 3ms/step - loss: 0.5089 - accuracy: 0.8003 - val_loss: 0.4634 - val_accuracy: 0.8235\n",
      "Epoch 512/1000\n",
      "225/225 [==============================] - 1s 2ms/step - loss: 0.5063 - accuracy: 0.8005 - val_loss: 0.4639 - val_accuracy: 0.8235\n",
      "Epoch 513/1000\n",
      "225/225 [==============================] - 1s 2ms/step - loss: 0.5083 - accuracy: 0.8004 - val_loss: 0.4645 - val_accuracy: 0.8248\n",
      "Epoch 514/1000\n",
      "225/225 [==============================] - 1s 2ms/step - loss: 0.5081 - accuracy: 0.8008 - val_loss: 0.4659 - val_accuracy: 0.8238\n",
      "Epoch 515/1000\n",
      "225/225 [==============================] - 1s 3ms/step - loss: 0.5089 - accuracy: 0.8004 - val_loss: 0.4649 - val_accuracy: 0.8242\n",
      "Epoch 516/1000\n",
      "225/225 [==============================] - 1s 2ms/step - loss: 0.5060 - accuracy: 0.8016 - val_loss: 0.4628 - val_accuracy: 0.8214\n",
      "Epoch 517/1000\n",
      "225/225 [==============================] - 1s 2ms/step - loss: 0.5083 - accuracy: 0.7998 - val_loss: 0.4645 - val_accuracy: 0.8248\n",
      "Epoch 518/1000\n",
      "225/225 [==============================] - 1s 2ms/step - loss: 0.5055 - accuracy: 0.8014 - val_loss: 0.4625 - val_accuracy: 0.8242\n",
      "Epoch 519/1000\n",
      "225/225 [==============================] - 1s 3ms/step - loss: 0.5080 - accuracy: 0.8008 - val_loss: 0.4675 - val_accuracy: 0.8222\n",
      "Epoch 520/1000\n",
      "225/225 [==============================] - 1s 3ms/step - loss: 0.5037 - accuracy: 0.8027 - val_loss: 0.4667 - val_accuracy: 0.8244\n",
      "Epoch 521/1000\n",
      "225/225 [==============================] - 1s 3ms/step - loss: 0.5063 - accuracy: 0.8013 - val_loss: 0.4622 - val_accuracy: 0.8246\n",
      "Epoch 522/1000\n",
      "225/225 [==============================] - 1s 3ms/step - loss: 0.5101 - accuracy: 0.8002 - val_loss: 0.4653 - val_accuracy: 0.8246\n",
      "Epoch 523/1000\n",
      "225/225 [==============================] - 1s 3ms/step - loss: 0.5070 - accuracy: 0.7997 - val_loss: 0.4646 - val_accuracy: 0.8232\n",
      "Epoch 524/1000\n",
      "225/225 [==============================] - 1s 3ms/step - loss: 0.5088 - accuracy: 0.7997 - val_loss: 0.4688 - val_accuracy: 0.8210\n",
      "Epoch 525/1000\n",
      "225/225 [==============================] - 1s 3ms/step - loss: 0.5059 - accuracy: 0.8020 - val_loss: 0.4651 - val_accuracy: 0.8231\n",
      "Epoch 526/1000\n",
      "225/225 [==============================] - 1s 3ms/step - loss: 0.5071 - accuracy: 0.8013 - val_loss: 0.4634 - val_accuracy: 0.8254\n",
      "Epoch 527/1000\n",
      "225/225 [==============================] - 1s 3ms/step - loss: 0.5035 - accuracy: 0.8016 - val_loss: 0.4661 - val_accuracy: 0.8228\n",
      "Epoch 528/1000\n",
      "225/225 [==============================] - 1s 3ms/step - loss: 0.5062 - accuracy: 0.8008 - val_loss: 0.4656 - val_accuracy: 0.8259\n",
      "Epoch 529/1000\n",
      "225/225 [==============================] - 1s 3ms/step - loss: 0.5079 - accuracy: 0.8009 - val_loss: 0.4657 - val_accuracy: 0.8242\n",
      "Epoch 530/1000\n",
      "225/225 [==============================] - 1s 3ms/step - loss: 0.5080 - accuracy: 0.8006 - val_loss: 0.4652 - val_accuracy: 0.8255\n",
      "Epoch 531/1000\n",
      "225/225 [==============================] - 1s 3ms/step - loss: 0.5065 - accuracy: 0.8017 - val_loss: 0.4661 - val_accuracy: 0.8238\n",
      "Epoch 532/1000\n",
      "225/225 [==============================] - 1s 3ms/step - loss: 0.5025 - accuracy: 0.8028 - val_loss: 0.4603 - val_accuracy: 0.8240\n",
      "Epoch 533/1000\n",
      "225/225 [==============================] - 1s 3ms/step - loss: 0.5066 - accuracy: 0.8015 - val_loss: 0.4648 - val_accuracy: 0.8248\n",
      "Epoch 534/1000\n",
      "225/225 [==============================] - 1s 3ms/step - loss: 0.5065 - accuracy: 0.8019 - val_loss: 0.4640 - val_accuracy: 0.8253\n",
      "Epoch 535/1000\n",
      "225/225 [==============================] - 1s 3ms/step - loss: 0.5074 - accuracy: 0.8000 - val_loss: 0.4669 - val_accuracy: 0.8215\n",
      "Epoch 536/1000\n",
      "225/225 [==============================] - 1s 3ms/step - loss: 0.5064 - accuracy: 0.8012 - val_loss: 0.4643 - val_accuracy: 0.8244\n",
      "Epoch 537/1000\n",
      "225/225 [==============================] - 1s 3ms/step - loss: 0.5051 - accuracy: 0.8023 - val_loss: 0.4653 - val_accuracy: 0.8259\n",
      "Epoch 538/1000\n",
      "225/225 [==============================] - 1s 3ms/step - loss: 0.5074 - accuracy: 0.8010 - val_loss: 0.4645 - val_accuracy: 0.8227\n",
      "Epoch 539/1000\n",
      "225/225 [==============================] - 1s 3ms/step - loss: 0.5069 - accuracy: 0.8014 - val_loss: 0.4644 - val_accuracy: 0.8248\n",
      "Epoch 540/1000\n",
      "225/225 [==============================] - 1s 3ms/step - loss: 0.5047 - accuracy: 0.8016 - val_loss: 0.4638 - val_accuracy: 0.8235\n",
      "Epoch 541/1000\n",
      "225/225 [==============================] - 1s 3ms/step - loss: 0.5070 - accuracy: 0.8006 - val_loss: 0.4656 - val_accuracy: 0.8230\n",
      "Epoch 542/1000\n",
      "225/225 [==============================] - 1s 3ms/step - loss: 0.5076 - accuracy: 0.8009 - val_loss: 0.4671 - val_accuracy: 0.8247\n",
      "Epoch 543/1000\n",
      "225/225 [==============================] - 1s 2ms/step - loss: 0.5066 - accuracy: 0.8004 - val_loss: 0.4641 - val_accuracy: 0.8235\n",
      "Epoch 544/1000\n",
      "225/225 [==============================] - 1s 2ms/step - loss: 0.5081 - accuracy: 0.8007 - val_loss: 0.4634 - val_accuracy: 0.8244\n",
      "Epoch 545/1000\n",
      "225/225 [==============================] - 1s 2ms/step - loss: 0.5054 - accuracy: 0.8013 - val_loss: 0.4651 - val_accuracy: 0.8246\n",
      "Epoch 546/1000\n",
      "225/225 [==============================] - 1s 2ms/step - loss: 0.5057 - accuracy: 0.8015 - val_loss: 0.4655 - val_accuracy: 0.8250\n",
      "Epoch 547/1000\n",
      "225/225 [==============================] - 1s 2ms/step - loss: 0.5058 - accuracy: 0.8014 - val_loss: 0.4628 - val_accuracy: 0.8235\n",
      "Epoch 548/1000\n",
      "225/225 [==============================] - 1s 3ms/step - loss: 0.5083 - accuracy: 0.8012 - val_loss: 0.4643 - val_accuracy: 0.8238\n",
      "Epoch 549/1000\n",
      "225/225 [==============================] - 1s 3ms/step - loss: 0.5060 - accuracy: 0.8012 - val_loss: 0.4649 - val_accuracy: 0.8227\n",
      "Epoch 550/1000\n",
      "225/225 [==============================] - 1s 3ms/step - loss: 0.5051 - accuracy: 0.8019 - val_loss: 0.4664 - val_accuracy: 0.8213\n",
      "Epoch 551/1000\n",
      "225/225 [==============================] - 1s 3ms/step - loss: 0.5061 - accuracy: 0.8018 - val_loss: 0.4653 - val_accuracy: 0.8243\n",
      "Epoch 552/1000\n",
      "225/225 [==============================] - 1s 3ms/step - loss: 0.5061 - accuracy: 0.8009 - val_loss: 0.4641 - val_accuracy: 0.8259\n",
      "Epoch 553/1000\n",
      "225/225 [==============================] - 1s 3ms/step - loss: 0.5056 - accuracy: 0.8015 - val_loss: 0.4637 - val_accuracy: 0.8228\n",
      "Epoch 554/1000\n",
      "225/225 [==============================] - 1s 2ms/step - loss: 0.5066 - accuracy: 0.8005 - val_loss: 0.4629 - val_accuracy: 0.8257\n",
      "Epoch 555/1000\n",
      "225/225 [==============================] - 1s 3ms/step - loss: 0.5052 - accuracy: 0.8023 - val_loss: 0.4645 - val_accuracy: 0.8231\n",
      "Epoch 556/1000\n",
      "225/225 [==============================] - 1s 3ms/step - loss: 0.5059 - accuracy: 0.8010 - val_loss: 0.4622 - val_accuracy: 0.8242\n",
      "Epoch 557/1000\n",
      "225/225 [==============================] - 1s 3ms/step - loss: 0.5064 - accuracy: 0.8021 - val_loss: 0.4660 - val_accuracy: 0.8248\n",
      "Epoch 558/1000\n",
      "225/225 [==============================] - 1s 3ms/step - loss: 0.5088 - accuracy: 0.8008 - val_loss: 0.4632 - val_accuracy: 0.8243\n",
      "Epoch 559/1000\n",
      "225/225 [==============================] - 1s 3ms/step - loss: 0.5042 - accuracy: 0.8014 - val_loss: 0.4642 - val_accuracy: 0.8258\n",
      "Epoch 560/1000\n",
      "225/225 [==============================] - 1s 3ms/step - loss: 0.5055 - accuracy: 0.8014 - val_loss: 0.4665 - val_accuracy: 0.8235\n",
      "Epoch 561/1000\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "225/225 [==============================] - 1s 3ms/step - loss: 0.5065 - accuracy: 0.8007 - val_loss: 0.4643 - val_accuracy: 0.8248\n",
      "Epoch 562/1000\n",
      "225/225 [==============================] - 1s 3ms/step - loss: 0.5053 - accuracy: 0.8018 - val_loss: 0.4642 - val_accuracy: 0.8238\n",
      "Epoch 563/1000\n",
      "225/225 [==============================] - 1s 3ms/step - loss: 0.5046 - accuracy: 0.8013 - val_loss: 0.4641 - val_accuracy: 0.8244\n",
      "Epoch 564/1000\n",
      "225/225 [==============================] - 1s 3ms/step - loss: 0.5044 - accuracy: 0.8029 - val_loss: 0.4637 - val_accuracy: 0.8239\n",
      "Epoch 565/1000\n",
      "225/225 [==============================] - 1s 3ms/step - loss: 0.5067 - accuracy: 0.8015 - val_loss: 0.4640 - val_accuracy: 0.8248\n",
      "Epoch 566/1000\n",
      "225/225 [==============================] - 1s 3ms/step - loss: 0.5059 - accuracy: 0.8016 - val_loss: 0.4635 - val_accuracy: 0.8239\n",
      "Epoch 567/1000\n",
      "225/225 [==============================] - 1s 3ms/step - loss: 0.5063 - accuracy: 0.8015 - val_loss: 0.4637 - val_accuracy: 0.8257\n",
      "Epoch 568/1000\n",
      "225/225 [==============================] - 1s 3ms/step - loss: 0.5031 - accuracy: 0.8025 - val_loss: 0.4601 - val_accuracy: 0.8265\n",
      "Epoch 569/1000\n",
      "225/225 [==============================] - 1s 3ms/step - loss: 0.5080 - accuracy: 0.8014 - val_loss: 0.4631 - val_accuracy: 0.8255\n",
      "Epoch 570/1000\n",
      "225/225 [==============================] - 1s 3ms/step - loss: 0.5042 - accuracy: 0.8018 - val_loss: 0.4631 - val_accuracy: 0.8253\n",
      "Epoch 571/1000\n",
      "225/225 [==============================] - 1s 3ms/step - loss: 0.5061 - accuracy: 0.8016 - val_loss: 0.4621 - val_accuracy: 0.8239\n",
      "Epoch 572/1000\n",
      "225/225 [==============================] - 1s 3ms/step - loss: 0.5071 - accuracy: 0.8016 - val_loss: 0.4636 - val_accuracy: 0.8241\n",
      "Epoch 573/1000\n",
      "225/225 [==============================] - 1s 3ms/step - loss: 0.5051 - accuracy: 0.8014 - val_loss: 0.4646 - val_accuracy: 0.8247\n",
      "Epoch 574/1000\n",
      "225/225 [==============================] - 1s 3ms/step - loss: 0.5067 - accuracy: 0.8010 - val_loss: 0.4638 - val_accuracy: 0.8252\n",
      "Epoch 575/1000\n",
      "225/225 [==============================] - 1s 3ms/step - loss: 0.5053 - accuracy: 0.8018 - val_loss: 0.4634 - val_accuracy: 0.8261\n",
      "Epoch 576/1000\n",
      "225/225 [==============================] - 1s 2ms/step - loss: 0.5052 - accuracy: 0.8025 - val_loss: 0.4628 - val_accuracy: 0.8243\n",
      "Epoch 577/1000\n",
      "225/225 [==============================] - 1s 2ms/step - loss: 0.5044 - accuracy: 0.8018 - val_loss: 0.4637 - val_accuracy: 0.8242\n",
      "Epoch 578/1000\n",
      "225/225 [==============================] - 1s 2ms/step - loss: 0.5032 - accuracy: 0.8030 - val_loss: 0.4649 - val_accuracy: 0.8235\n",
      "Epoch 579/1000\n",
      "225/225 [==============================] - 1s 3ms/step - loss: 0.5077 - accuracy: 0.8010 - val_loss: 0.4644 - val_accuracy: 0.8228\n",
      "Epoch 580/1000\n",
      "225/225 [==============================] - 1s 3ms/step - loss: 0.5044 - accuracy: 0.8020 - val_loss: 0.4640 - val_accuracy: 0.8230\n",
      "Epoch 581/1000\n",
      "225/225 [==============================] - 1s 3ms/step - loss: 0.5052 - accuracy: 0.8017 - val_loss: 0.4623 - val_accuracy: 0.8239\n",
      "Epoch 582/1000\n",
      "225/225 [==============================] - 1s 3ms/step - loss: 0.5049 - accuracy: 0.8022 - val_loss: 0.4633 - val_accuracy: 0.8230\n",
      "Epoch 583/1000\n",
      "225/225 [==============================] - 1s 3ms/step - loss: 0.5055 - accuracy: 0.8018 - val_loss: 0.4648 - val_accuracy: 0.8228\n",
      "Epoch 584/1000\n",
      "225/225 [==============================] - 1s 3ms/step - loss: 0.5066 - accuracy: 0.8013 - val_loss: 0.4644 - val_accuracy: 0.8245\n",
      "Epoch 585/1000\n",
      "225/225 [==============================] - 1s 3ms/step - loss: 0.5037 - accuracy: 0.8020 - val_loss: 0.4621 - val_accuracy: 0.8250\n",
      "Epoch 586/1000\n",
      "225/225 [==============================] - 1s 3ms/step - loss: 0.5048 - accuracy: 0.8011 - val_loss: 0.4618 - val_accuracy: 0.8267\n",
      "Epoch 587/1000\n",
      "225/225 [==============================] - 1s 3ms/step - loss: 0.5068 - accuracy: 0.8015 - val_loss: 0.4635 - val_accuracy: 0.8260\n",
      "Epoch 588/1000\n",
      "225/225 [==============================] - 1s 3ms/step - loss: 0.5064 - accuracy: 0.8010 - val_loss: 0.4648 - val_accuracy: 0.8246\n",
      "Epoch 589/1000\n",
      "225/225 [==============================] - 1s 3ms/step - loss: 0.5053 - accuracy: 0.8022 - val_loss: 0.4658 - val_accuracy: 0.8240\n",
      "Epoch 590/1000\n",
      "225/225 [==============================] - 1s 3ms/step - loss: 0.5059 - accuracy: 0.8009 - val_loss: 0.4638 - val_accuracy: 0.8255\n",
      "Epoch 591/1000\n",
      "225/225 [==============================] - 1s 3ms/step - loss: 0.5044 - accuracy: 0.8021 - val_loss: 0.4644 - val_accuracy: 0.8270\n",
      "Epoch 592/1000\n",
      "225/225 [==============================] - 1s 3ms/step - loss: 0.5074 - accuracy: 0.8006 - val_loss: 0.4613 - val_accuracy: 0.8259\n",
      "Epoch 593/1000\n",
      "225/225 [==============================] - 1s 3ms/step - loss: 0.5051 - accuracy: 0.8010 - val_loss: 0.4653 - val_accuracy: 0.8241\n",
      "Epoch 594/1000\n",
      "225/225 [==============================] - 1s 3ms/step - loss: 0.5065 - accuracy: 0.8008 - val_loss: 0.4653 - val_accuracy: 0.8244\n",
      "Epoch 595/1000\n",
      "225/225 [==============================] - 1s 3ms/step - loss: 0.5066 - accuracy: 0.8002 - val_loss: 0.4654 - val_accuracy: 0.8238\n",
      "Epoch 596/1000\n",
      "225/225 [==============================] - 1s 3ms/step - loss: 0.5070 - accuracy: 0.7999 - val_loss: 0.4647 - val_accuracy: 0.8253\n",
      "Epoch 597/1000\n",
      "225/225 [==============================] - 1s 3ms/step - loss: 0.5080 - accuracy: 0.8004 - val_loss: 0.4628 - val_accuracy: 0.8263\n",
      "Epoch 598/1000\n",
      "225/225 [==============================] - 1s 3ms/step - loss: 0.5055 - accuracy: 0.8016 - val_loss: 0.4628 - val_accuracy: 0.8248\n",
      "Epoch 599/1000\n",
      "225/225 [==============================] - 1s 3ms/step - loss: 0.5039 - accuracy: 0.8020 - val_loss: 0.4636 - val_accuracy: 0.8256\n",
      "Epoch 600/1000\n",
      "225/225 [==============================] - 1s 3ms/step - loss: 0.5076 - accuracy: 0.7998 - val_loss: 0.4641 - val_accuracy: 0.8226\n",
      "Epoch 601/1000\n",
      "225/225 [==============================] - 1s 3ms/step - loss: 0.5045 - accuracy: 0.8021 - val_loss: 0.4632 - val_accuracy: 0.8223\n",
      "Epoch 602/1000\n",
      "225/225 [==============================] - 1s 3ms/step - loss: 0.5045 - accuracy: 0.8026 - val_loss: 0.4640 - val_accuracy: 0.8235\n",
      "Epoch 603/1000\n",
      "225/225 [==============================] - 1s 3ms/step - loss: 0.5054 - accuracy: 0.8026 - val_loss: 0.4633 - val_accuracy: 0.8226\n",
      "Epoch 604/1000\n",
      "225/225 [==============================] - 1s 3ms/step - loss: 0.5055 - accuracy: 0.8005 - val_loss: 0.4644 - val_accuracy: 0.8234\n",
      "Epoch 605/1000\n",
      "225/225 [==============================] - 1s 3ms/step - loss: 0.5026 - accuracy: 0.8031 - val_loss: 0.4595 - val_accuracy: 0.8240\n",
      "Epoch 606/1000\n",
      "225/225 [==============================] - 1s 3ms/step - loss: 0.5044 - accuracy: 0.8017 - val_loss: 0.4605 - val_accuracy: 0.8253\n",
      "Epoch 607/1000\n",
      "225/225 [==============================] - 1s 3ms/step - loss: 0.5053 - accuracy: 0.8015 - val_loss: 0.4634 - val_accuracy: 0.8270\n",
      "Epoch 608/1000\n",
      "225/225 [==============================] - 1s 2ms/step - loss: 0.5044 - accuracy: 0.8026 - val_loss: 0.4633 - val_accuracy: 0.8239\n",
      "Epoch 609/1000\n",
      "225/225 [==============================] - 1s 3ms/step - loss: 0.5054 - accuracy: 0.8023 - val_loss: 0.4633 - val_accuracy: 0.8267\n",
      "Epoch 610/1000\n",
      "225/225 [==============================] - 1s 3ms/step - loss: 0.5048 - accuracy: 0.8011 - val_loss: 0.4645 - val_accuracy: 0.8246\n",
      "Epoch 611/1000\n",
      "225/225 [==============================] - 1s 3ms/step - loss: 0.5055 - accuracy: 0.8012 - val_loss: 0.4630 - val_accuracy: 0.8279\n",
      "Epoch 612/1000\n",
      "225/225 [==============================] - 1s 3ms/step - loss: 0.5043 - accuracy: 0.8015 - val_loss: 0.4636 - val_accuracy: 0.8246\n",
      "Epoch 613/1000\n",
      "225/225 [==============================] - 1s 3ms/step - loss: 0.5049 - accuracy: 0.8018 - val_loss: 0.4624 - val_accuracy: 0.8264\n",
      "Epoch 614/1000\n",
      "225/225 [==============================] - 1s 3ms/step - loss: 0.5042 - accuracy: 0.8015 - val_loss: 0.4608 - val_accuracy: 0.8271\n",
      "Epoch 615/1000\n",
      "225/225 [==============================] - 1s 3ms/step - loss: 0.5060 - accuracy: 0.8013 - val_loss: 0.4632 - val_accuracy: 0.8246\n",
      "Epoch 616/1000\n",
      "225/225 [==============================] - 1s 3ms/step - loss: 0.5054 - accuracy: 0.8011 - val_loss: 0.4607 - val_accuracy: 0.8261\n",
      "Epoch 617/1000\n",
      "225/225 [==============================] - 1s 3ms/step - loss: 0.5052 - accuracy: 0.8018 - val_loss: 0.4619 - val_accuracy: 0.8278\n",
      "Epoch 618/1000\n",
      "225/225 [==============================] - 1s 3ms/step - loss: 0.5040 - accuracy: 0.8023 - val_loss: 0.4624 - val_accuracy: 0.8274\n",
      "Epoch 619/1000\n",
      "225/225 [==============================] - 1s 3ms/step - loss: 0.5067 - accuracy: 0.8010 - val_loss: 0.4655 - val_accuracy: 0.8246\n",
      "Epoch 620/1000\n",
      "225/225 [==============================] - 1s 3ms/step - loss: 0.5048 - accuracy: 0.8021 - val_loss: 0.4636 - val_accuracy: 0.8239\n",
      "Epoch 621/1000\n",
      "225/225 [==============================] - 1s 3ms/step - loss: 0.5033 - accuracy: 0.8027 - val_loss: 0.4623 - val_accuracy: 0.8251\n",
      "Epoch 622/1000\n",
      "225/225 [==============================] - 1s 3ms/step - loss: 0.5040 - accuracy: 0.8012 - val_loss: 0.4613 - val_accuracy: 0.8252\n",
      "Epoch 623/1000\n",
      "225/225 [==============================] - 1s 3ms/step - loss: 0.5045 - accuracy: 0.8018 - val_loss: 0.4641 - val_accuracy: 0.8242\n",
      "Epoch 624/1000\n",
      "225/225 [==============================] - 1s 3ms/step - loss: 0.5063 - accuracy: 0.8001 - val_loss: 0.4607 - val_accuracy: 0.8256\n",
      "Epoch 625/1000\n",
      "225/225 [==============================] - 1s 3ms/step - loss: 0.5048 - accuracy: 0.8029 - val_loss: 0.4631 - val_accuracy: 0.8253\n",
      "Epoch 626/1000\n",
      "225/225 [==============================] - 1s 3ms/step - loss: 0.5047 - accuracy: 0.8014 - val_loss: 0.4630 - val_accuracy: 0.8252\n",
      "Epoch 627/1000\n",
      "225/225 [==============================] - 1s 3ms/step - loss: 0.5058 - accuracy: 0.8019 - val_loss: 0.4628 - val_accuracy: 0.8231\n",
      "Epoch 628/1000\n",
      "225/225 [==============================] - 1s 3ms/step - loss: 0.5062 - accuracy: 0.8014 - val_loss: 0.4622 - val_accuracy: 0.8258\n",
      "Epoch 629/1000\n",
      "225/225 [==============================] - 1s 3ms/step - loss: 0.5030 - accuracy: 0.8028 - val_loss: 0.4620 - val_accuracy: 0.8267\n",
      "Epoch 630/1000\n",
      "225/225 [==============================] - 1s 3ms/step - loss: 0.5016 - accuracy: 0.8030 - val_loss: 0.4613 - val_accuracy: 0.8254\n",
      "Epoch 631/1000\n",
      "225/225 [==============================] - 1s 3ms/step - loss: 0.5024 - accuracy: 0.8033 - val_loss: 0.4629 - val_accuracy: 0.8257\n",
      "Epoch 632/1000\n",
      "225/225 [==============================] - 1s 3ms/step - loss: 0.5061 - accuracy: 0.8028 - val_loss: 0.4642 - val_accuracy: 0.8228\n",
      "Epoch 633/1000\n",
      "225/225 [==============================] - 1s 3ms/step - loss: 0.5042 - accuracy: 0.8024 - val_loss: 0.4605 - val_accuracy: 0.8225\n",
      "Epoch 634/1000\n",
      "225/225 [==============================] - 1s 3ms/step - loss: 0.5031 - accuracy: 0.8031 - val_loss: 0.4616 - val_accuracy: 0.8260\n",
      "Epoch 635/1000\n",
      "225/225 [==============================] - 1s 3ms/step - loss: 0.5033 - accuracy: 0.8016 - val_loss: 0.4604 - val_accuracy: 0.8270\n",
      "Epoch 636/1000\n",
      "225/225 [==============================] - 1s 3ms/step - loss: 0.5030 - accuracy: 0.8021 - val_loss: 0.4607 - val_accuracy: 0.8247\n",
      "Epoch 637/1000\n",
      "225/225 [==============================] - 1s 3ms/step - loss: 0.5036 - accuracy: 0.8022 - val_loss: 0.4642 - val_accuracy: 0.8233\n",
      "Epoch 638/1000\n",
      "225/225 [==============================] - 1s 2ms/step - loss: 0.5038 - accuracy: 0.8020 - val_loss: 0.4637 - val_accuracy: 0.8233\n",
      "Epoch 639/1000\n",
      "225/225 [==============================] - 1s 3ms/step - loss: 0.5041 - accuracy: 0.8014 - val_loss: 0.4619 - val_accuracy: 0.8226\n",
      "Epoch 640/1000\n",
      "225/225 [==============================] - 1s 3ms/step - loss: 0.5049 - accuracy: 0.8024 - val_loss: 0.4609 - val_accuracy: 0.8254\n",
      "Epoch 641/1000\n",
      "225/225 [==============================] - 1s 3ms/step - loss: 0.5052 - accuracy: 0.8008 - val_loss: 0.4611 - val_accuracy: 0.8255\n",
      "Epoch 642/1000\n",
      "225/225 [==============================] - 1s 3ms/step - loss: 0.5036 - accuracy: 0.8031 - val_loss: 0.4625 - val_accuracy: 0.8236\n",
      "Epoch 643/1000\n",
      "225/225 [==============================] - 1s 3ms/step - loss: 0.5047 - accuracy: 0.8026 - val_loss: 0.4611 - val_accuracy: 0.8260\n",
      "Epoch 644/1000\n",
      "225/225 [==============================] - 1s 3ms/step - loss: 0.5028 - accuracy: 0.8024 - val_loss: 0.4594 - val_accuracy: 0.8255\n",
      "Epoch 645/1000\n",
      "225/225 [==============================] - 1s 3ms/step - loss: 0.5036 - accuracy: 0.8021 - val_loss: 0.4606 - val_accuracy: 0.8267\n",
      "Epoch 646/1000\n",
      "225/225 [==============================] - 1s 3ms/step - loss: 0.5039 - accuracy: 0.8026 - val_loss: 0.4616 - val_accuracy: 0.8253\n",
      "Epoch 647/1000\n",
      "225/225 [==============================] - 1s 3ms/step - loss: 0.5046 - accuracy: 0.8027 - val_loss: 0.4605 - val_accuracy: 0.8257\n",
      "Epoch 648/1000\n",
      "225/225 [==============================] - 1s 3ms/step - loss: 0.5052 - accuracy: 0.8022 - val_loss: 0.4605 - val_accuracy: 0.8267\n",
      "Epoch 649/1000\n",
      "225/225 [==============================] - 1s 3ms/step - loss: 0.5043 - accuracy: 0.8028 - val_loss: 0.4650 - val_accuracy: 0.8241\n",
      "Epoch 650/1000\n",
      "225/225 [==============================] - 1s 2ms/step - loss: 0.5053 - accuracy: 0.8016 - val_loss: 0.4632 - val_accuracy: 0.8227\n",
      "Epoch 651/1000\n",
      "225/225 [==============================] - 1s 2ms/step - loss: 0.5031 - accuracy: 0.8021 - val_loss: 0.4628 - val_accuracy: 0.8240\n",
      "Epoch 652/1000\n",
      "225/225 [==============================] - 1s 2ms/step - loss: 0.5038 - accuracy: 0.8014 - val_loss: 0.4649 - val_accuracy: 0.8221\n",
      "Epoch 653/1000\n",
      "225/225 [==============================] - 1s 2ms/step - loss: 0.5041 - accuracy: 0.8032 - val_loss: 0.4648 - val_accuracy: 0.8253\n",
      "Epoch 654/1000\n",
      "225/225 [==============================] - 1s 2ms/step - loss: 0.5026 - accuracy: 0.8033 - val_loss: 0.4606 - val_accuracy: 0.8256\n",
      "Epoch 655/1000\n",
      "225/225 [==============================] - 1s 2ms/step - loss: 0.5047 - accuracy: 0.8015 - val_loss: 0.4624 - val_accuracy: 0.8253\n",
      "Epoch 656/1000\n",
      "225/225 [==============================] - 1s 2ms/step - loss: 0.5046 - accuracy: 0.8018 - val_loss: 0.4625 - val_accuracy: 0.8241\n",
      "Epoch 657/1000\n",
      "225/225 [==============================] - 1s 2ms/step - loss: 0.5038 - accuracy: 0.8024 - val_loss: 0.4635 - val_accuracy: 0.8236\n",
      "Epoch 658/1000\n",
      "225/225 [==============================] - 1s 2ms/step - loss: 0.5054 - accuracy: 0.8011 - val_loss: 0.4624 - val_accuracy: 0.8249\n",
      "Epoch 659/1000\n",
      "225/225 [==============================] - 1s 2ms/step - loss: 0.5026 - accuracy: 0.8030 - val_loss: 0.4611 - val_accuracy: 0.8267\n",
      "Epoch 660/1000\n",
      "225/225 [==============================] - 1s 3ms/step - loss: 0.5031 - accuracy: 0.8024 - val_loss: 0.4638 - val_accuracy: 0.8246\n",
      "Epoch 661/1000\n",
      "225/225 [==============================] - 1s 2ms/step - loss: 0.5026 - accuracy: 0.8036 - val_loss: 0.4624 - val_accuracy: 0.8259\n",
      "Epoch 662/1000\n",
      "225/225 [==============================] - 1s 2ms/step - loss: 0.5055 - accuracy: 0.8014 - val_loss: 0.4652 - val_accuracy: 0.8219\n",
      "Epoch 663/1000\n",
      "225/225 [==============================] - 1s 2ms/step - loss: 0.5046 - accuracy: 0.8018 - val_loss: 0.4670 - val_accuracy: 0.8250\n",
      "Epoch 664/1000\n",
      "225/225 [==============================] - 1s 2ms/step - loss: 0.5036 - accuracy: 0.8022 - val_loss: 0.4638 - val_accuracy: 0.8252\n",
      "Epoch 665/1000\n",
      "225/225 [==============================] - 1s 2ms/step - loss: 0.5033 - accuracy: 0.8012 - val_loss: 0.4614 - val_accuracy: 0.8250\n",
      "Epoch 666/1000\n",
      "225/225 [==============================] - 1s 2ms/step - loss: 0.5019 - accuracy: 0.8031 - val_loss: 0.4640 - val_accuracy: 0.8240\n",
      "Epoch 667/1000\n",
      "225/225 [==============================] - 1s 3ms/step - loss: 0.5046 - accuracy: 0.8012 - val_loss: 0.4651 - val_accuracy: 0.8260\n",
      "Epoch 668/1000\n",
      "225/225 [==============================] - 1s 2ms/step - loss: 0.5027 - accuracy: 0.8029 - val_loss: 0.4621 - val_accuracy: 0.8258\n",
      "Epoch 669/1000\n",
      "225/225 [==============================] - 1s 2ms/step - loss: 0.5030 - accuracy: 0.8028 - val_loss: 0.4613 - val_accuracy: 0.8263\n",
      "Epoch 670/1000\n",
      "225/225 [==============================] - 1s 2ms/step - loss: 0.5038 - accuracy: 0.8013 - val_loss: 0.4634 - val_accuracy: 0.8264\n",
      "Epoch 671/1000\n",
      "225/225 [==============================] - 1s 2ms/step - loss: 0.5034 - accuracy: 0.8020 - val_loss: 0.4629 - val_accuracy: 0.8260\n",
      "Epoch 672/1000\n",
      "225/225 [==============================] - 1s 3ms/step - loss: 0.5041 - accuracy: 0.8029 - val_loss: 0.4600 - val_accuracy: 0.8254\n",
      "Epoch 673/1000\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "225/225 [==============================] - 1s 3ms/step - loss: 0.5040 - accuracy: 0.8029 - val_loss: 0.4645 - val_accuracy: 0.8261\n",
      "Epoch 674/1000\n",
      "225/225 [==============================] - 1s 2ms/step - loss: 0.5037 - accuracy: 0.8012 - val_loss: 0.4621 - val_accuracy: 0.8289\n",
      "Epoch 675/1000\n",
      "225/225 [==============================] - 1s 2ms/step - loss: 0.5055 - accuracy: 0.8027 - val_loss: 0.4658 - val_accuracy: 0.8232\n",
      "Epoch 676/1000\n",
      "225/225 [==============================] - 1s 2ms/step - loss: 0.5031 - accuracy: 0.8031 - val_loss: 0.4608 - val_accuracy: 0.8233\n",
      "Epoch 677/1000\n",
      "225/225 [==============================] - 1s 2ms/step - loss: 0.5039 - accuracy: 0.8020 - val_loss: 0.4602 - val_accuracy: 0.8260\n",
      "Epoch 678/1000\n",
      "225/225 [==============================] - 1s 2ms/step - loss: 0.5053 - accuracy: 0.8021 - val_loss: 0.4612 - val_accuracy: 0.8253\n",
      "Epoch 679/1000\n",
      "225/225 [==============================] - 1s 2ms/step - loss: 0.5030 - accuracy: 0.8028 - val_loss: 0.4607 - val_accuracy: 0.8248\n",
      "Epoch 680/1000\n",
      "225/225 [==============================] - 1s 3ms/step - loss: 0.5014 - accuracy: 0.8035 - val_loss: 0.4585 - val_accuracy: 0.8248\n",
      "Epoch 681/1000\n",
      "225/225 [==============================] - 1s 3ms/step - loss: 0.5028 - accuracy: 0.8018 - val_loss: 0.4616 - val_accuracy: 0.8254\n",
      "Epoch 682/1000\n",
      "225/225 [==============================] - 1s 2ms/step - loss: 0.5029 - accuracy: 0.8025 - val_loss: 0.4607 - val_accuracy: 0.8255\n",
      "Epoch 683/1000\n",
      "225/225 [==============================] - 1s 2ms/step - loss: 0.5030 - accuracy: 0.8027 - val_loss: 0.4595 - val_accuracy: 0.8260\n",
      "Epoch 684/1000\n",
      "225/225 [==============================] - 1s 2ms/step - loss: 0.5020 - accuracy: 0.8027 - val_loss: 0.4615 - val_accuracy: 0.8256\n",
      "Epoch 685/1000\n",
      "225/225 [==============================] - 1s 4ms/step - loss: 0.5019 - accuracy: 0.8050 - val_loss: 0.4576 - val_accuracy: 0.8287\n",
      "Epoch 686/1000\n",
      "225/225 [==============================] - 1s 3ms/step - loss: 0.5045 - accuracy: 0.8017 - val_loss: 0.4629 - val_accuracy: 0.8253\n",
      "Epoch 687/1000\n",
      "225/225 [==============================] - 1s 3ms/step - loss: 0.5033 - accuracy: 0.8020 - val_loss: 0.4640 - val_accuracy: 0.8280\n",
      "Epoch 688/1000\n",
      "225/225 [==============================] - 1s 3ms/step - loss: 0.5029 - accuracy: 0.8018 - val_loss: 0.4601 - val_accuracy: 0.8296\n",
      "Epoch 689/1000\n",
      "225/225 [==============================] - 1s 3ms/step - loss: 0.5025 - accuracy: 0.8033 - val_loss: 0.4592 - val_accuracy: 0.8286\n",
      "Epoch 690/1000\n",
      "225/225 [==============================] - 1s 3ms/step - loss: 0.5030 - accuracy: 0.8023 - val_loss: 0.4574 - val_accuracy: 0.8293\n",
      "Epoch 691/1000\n",
      "225/225 [==============================] - 1s 3ms/step - loss: 0.5044 - accuracy: 0.8024 - val_loss: 0.4607 - val_accuracy: 0.8267\n",
      "Epoch 692/1000\n",
      "225/225 [==============================] - 1s 3ms/step - loss: 0.5035 - accuracy: 0.8025 - val_loss: 0.4603 - val_accuracy: 0.8249\n",
      "Epoch 693/1000\n",
      "225/225 [==============================] - 1s 3ms/step - loss: 0.5035 - accuracy: 0.8024 - val_loss: 0.4598 - val_accuracy: 0.8253\n",
      "Epoch 694/1000\n",
      "225/225 [==============================] - 1s 3ms/step - loss: 0.5031 - accuracy: 0.8032 - val_loss: 0.4604 - val_accuracy: 0.8253\n",
      "Epoch 695/1000\n",
      "225/225 [==============================] - 1s 3ms/step - loss: 0.5025 - accuracy: 0.8025 - val_loss: 0.4584 - val_accuracy: 0.8257\n",
      "Epoch 696/1000\n",
      "225/225 [==============================] - 1s 3ms/step - loss: 0.5029 - accuracy: 0.8027 - val_loss: 0.4610 - val_accuracy: 0.8260\n",
      "Epoch 697/1000\n",
      "225/225 [==============================] - 1s 3ms/step - loss: 0.5027 - accuracy: 0.8031 - val_loss: 0.4579 - val_accuracy: 0.8271\n",
      "Epoch 698/1000\n",
      "225/225 [==============================] - 1s 3ms/step - loss: 0.5036 - accuracy: 0.8022 - val_loss: 0.4609 - val_accuracy: 0.8275\n",
      "Epoch 699/1000\n",
      "225/225 [==============================] - 1s 3ms/step - loss: 0.5038 - accuracy: 0.8015 - val_loss: 0.4566 - val_accuracy: 0.8276\n",
      "Epoch 700/1000\n",
      "225/225 [==============================] - 1s 3ms/step - loss: 0.5028 - accuracy: 0.8029 - val_loss: 0.4573 - val_accuracy: 0.8267\n",
      "Epoch 701/1000\n",
      "225/225 [==============================] - 1s 3ms/step - loss: 0.5035 - accuracy: 0.8030 - val_loss: 0.4584 - val_accuracy: 0.8264\n",
      "Epoch 702/1000\n",
      "225/225 [==============================] - 1s 3ms/step - loss: 0.5034 - accuracy: 0.8021 - val_loss: 0.4597 - val_accuracy: 0.8277\n",
      "Epoch 703/1000\n",
      "225/225 [==============================] - 1s 3ms/step - loss: 0.5040 - accuracy: 0.8020 - val_loss: 0.4601 - val_accuracy: 0.8269\n",
      "Epoch 704/1000\n",
      "225/225 [==============================] - 1s 3ms/step - loss: 0.5032 - accuracy: 0.8013 - val_loss: 0.4613 - val_accuracy: 0.8266\n",
      "Epoch 705/1000\n",
      "225/225 [==============================] - 1s 3ms/step - loss: 0.5027 - accuracy: 0.8024 - val_loss: 0.4593 - val_accuracy: 0.8275\n",
      "Epoch 706/1000\n",
      "225/225 [==============================] - 1s 3ms/step - loss: 0.5027 - accuracy: 0.8023 - val_loss: 0.4593 - val_accuracy: 0.8239\n",
      "Epoch 707/1000\n",
      "225/225 [==============================] - 1s 3ms/step - loss: 0.5026 - accuracy: 0.8037 - val_loss: 0.4596 - val_accuracy: 0.8249\n",
      "Epoch 708/1000\n",
      "225/225 [==============================] - 1s 3ms/step - loss: 0.5015 - accuracy: 0.8037 - val_loss: 0.4589 - val_accuracy: 0.8274\n",
      "Epoch 709/1000\n",
      "225/225 [==============================] - 1s 3ms/step - loss: 0.5007 - accuracy: 0.8032 - val_loss: 0.4592 - val_accuracy: 0.8283\n",
      "Epoch 710/1000\n",
      "225/225 [==============================] - 1s 3ms/step - loss: 0.5026 - accuracy: 0.8025 - val_loss: 0.4600 - val_accuracy: 0.8258\n",
      "Epoch 711/1000\n",
      "225/225 [==============================] - 1s 3ms/step - loss: 0.5022 - accuracy: 0.8033 - val_loss: 0.4588 - val_accuracy: 0.8272\n",
      "Epoch 712/1000\n",
      "225/225 [==============================] - 1s 3ms/step - loss: 0.5015 - accuracy: 0.8037 - val_loss: 0.4598 - val_accuracy: 0.8259\n",
      "Epoch 713/1000\n",
      "225/225 [==============================] - 1s 3ms/step - loss: 0.5021 - accuracy: 0.8034 - val_loss: 0.4589 - val_accuracy: 0.8270\n",
      "Epoch 714/1000\n",
      "225/225 [==============================] - 1s 3ms/step - loss: 0.5025 - accuracy: 0.8029 - val_loss: 0.4617 - val_accuracy: 0.8270\n",
      "Epoch 715/1000\n",
      "225/225 [==============================] - 1s 3ms/step - loss: 0.5029 - accuracy: 0.8024 - val_loss: 0.4601 - val_accuracy: 0.8267\n",
      "Epoch 716/1000\n",
      "225/225 [==============================] - 1s 3ms/step - loss: 0.5022 - accuracy: 0.8019 - val_loss: 0.4588 - val_accuracy: 0.8260\n",
      "Epoch 717/1000\n",
      "225/225 [==============================] - 1s 3ms/step - loss: 0.4999 - accuracy: 0.8039 - val_loss: 0.4579 - val_accuracy: 0.8267\n",
      "Epoch 718/1000\n",
      "225/225 [==============================] - 1s 3ms/step - loss: 0.5016 - accuracy: 0.8037 - val_loss: 0.4601 - val_accuracy: 0.8264\n",
      "Epoch 719/1000\n",
      "225/225 [==============================] - 1s 3ms/step - loss: 0.4997 - accuracy: 0.8045 - val_loss: 0.4571 - val_accuracy: 0.8264\n",
      "Epoch 720/1000\n",
      "225/225 [==============================] - 1s 3ms/step - loss: 0.5030 - accuracy: 0.8036 - val_loss: 0.4580 - val_accuracy: 0.8275\n",
      "Epoch 721/1000\n",
      "225/225 [==============================] - 1s 3ms/step - loss: 0.5031 - accuracy: 0.8034 - val_loss: 0.4576 - val_accuracy: 0.8273\n",
      "Epoch 722/1000\n",
      "225/225 [==============================] - 1s 3ms/step - loss: 0.5025 - accuracy: 0.8028 - val_loss: 0.4567 - val_accuracy: 0.8282\n",
      "Epoch 723/1000\n",
      "225/225 [==============================] - 1s 3ms/step - loss: 0.5011 - accuracy: 0.8040 - val_loss: 0.4585 - val_accuracy: 0.8271\n",
      "Epoch 724/1000\n",
      "225/225 [==============================] - 1s 2ms/step - loss: 0.5027 - accuracy: 0.8030 - val_loss: 0.4592 - val_accuracy: 0.8273\n",
      "Epoch 725/1000\n",
      "225/225 [==============================] - 1s 3ms/step - loss: 0.5026 - accuracy: 0.8023 - val_loss: 0.4575 - val_accuracy: 0.8293\n",
      "Epoch 726/1000\n",
      "225/225 [==============================] - 1s 3ms/step - loss: 0.5008 - accuracy: 0.8049 - val_loss: 0.4614 - val_accuracy: 0.8271\n",
      "Epoch 727/1000\n",
      "225/225 [==============================] - 1s 3ms/step - loss: 0.5013 - accuracy: 0.8037 - val_loss: 0.4593 - val_accuracy: 0.8271\n",
      "Epoch 728/1000\n",
      "225/225 [==============================] - 1s 3ms/step - loss: 0.4999 - accuracy: 0.8040 - val_loss: 0.4561 - val_accuracy: 0.8281\n",
      "Epoch 729/1000\n",
      "225/225 [==============================] - 1s 3ms/step - loss: 0.5012 - accuracy: 0.8035 - val_loss: 0.4584 - val_accuracy: 0.8271\n",
      "Epoch 730/1000\n",
      "225/225 [==============================] - 1s 3ms/step - loss: 0.5013 - accuracy: 0.8029 - val_loss: 0.4596 - val_accuracy: 0.8270\n",
      "Epoch 731/1000\n",
      "225/225 [==============================] - 1s 3ms/step - loss: 0.5029 - accuracy: 0.8029 - val_loss: 0.4611 - val_accuracy: 0.8273\n",
      "Epoch 732/1000\n",
      "225/225 [==============================] - 1s 3ms/step - loss: 0.4999 - accuracy: 0.8046 - val_loss: 0.4561 - val_accuracy: 0.8272\n",
      "Epoch 733/1000\n",
      "225/225 [==============================] - 1s 3ms/step - loss: 0.5004 - accuracy: 0.8035 - val_loss: 0.4582 - val_accuracy: 0.8268\n",
      "Epoch 734/1000\n",
      "225/225 [==============================] - 1s 3ms/step - loss: 0.5026 - accuracy: 0.8030 - val_loss: 0.4603 - val_accuracy: 0.8279\n",
      "Epoch 735/1000\n",
      "225/225 [==============================] - 1s 3ms/step - loss: 0.5005 - accuracy: 0.8045 - val_loss: 0.4608 - val_accuracy: 0.8258\n",
      "Epoch 736/1000\n",
      "225/225 [==============================] - 1s 3ms/step - loss: 0.5022 - accuracy: 0.8035 - val_loss: 0.4606 - val_accuracy: 0.8258\n",
      "Epoch 737/1000\n",
      "225/225 [==============================] - 1s 3ms/step - loss: 0.4998 - accuracy: 0.8041 - val_loss: 0.4632 - val_accuracy: 0.8246\n",
      "Epoch 738/1000\n",
      "225/225 [==============================] - 1s 3ms/step - loss: 0.5029 - accuracy: 0.8024 - val_loss: 0.4610 - val_accuracy: 0.8288\n",
      "Epoch 739/1000\n",
      "225/225 [==============================] - 1s 3ms/step - loss: 0.5009 - accuracy: 0.8049 - val_loss: 0.4564 - val_accuracy: 0.8284\n",
      "Epoch 740/1000\n",
      "225/225 [==============================] - 1s 3ms/step - loss: 0.5022 - accuracy: 0.8029 - val_loss: 0.4580 - val_accuracy: 0.8295\n",
      "Epoch 741/1000\n",
      "225/225 [==============================] - 1s 3ms/step - loss: 0.5009 - accuracy: 0.8043 - val_loss: 0.4602 - val_accuracy: 0.8256\n",
      "Epoch 742/1000\n",
      "225/225 [==============================] - 1s 3ms/step - loss: 0.4993 - accuracy: 0.8035 - val_loss: 0.4574 - val_accuracy: 0.8270\n",
      "Epoch 743/1000\n",
      "225/225 [==============================] - 1s 3ms/step - loss: 0.5011 - accuracy: 0.8031 - val_loss: 0.4571 - val_accuracy: 0.8286\n",
      "Epoch 744/1000\n",
      "225/225 [==============================] - 1s 3ms/step - loss: 0.5044 - accuracy: 0.8023 - val_loss: 0.4591 - val_accuracy: 0.8253\n",
      "Epoch 745/1000\n",
      "225/225 [==============================] - 1s 3ms/step - loss: 0.5017 - accuracy: 0.8036 - val_loss: 0.4584 - val_accuracy: 0.8282\n",
      "Epoch 746/1000\n",
      "225/225 [==============================] - 1s 3ms/step - loss: 0.5020 - accuracy: 0.8032 - val_loss: 0.4596 - val_accuracy: 0.8272\n",
      "Epoch 747/1000\n",
      "225/225 [==============================] - 1s 3ms/step - loss: 0.5004 - accuracy: 0.8043 - val_loss: 0.4577 - val_accuracy: 0.8287\n",
      "Epoch 748/1000\n",
      "225/225 [==============================] - 1s 3ms/step - loss: 0.5037 - accuracy: 0.8031 - val_loss: 0.4602 - val_accuracy: 0.8279\n",
      "Epoch 749/1000\n",
      "225/225 [==============================] - 1s 3ms/step - loss: 0.5024 - accuracy: 0.8043 - val_loss: 0.4561 - val_accuracy: 0.8300\n",
      "Epoch 750/1000\n",
      "225/225 [==============================] - 1s 3ms/step - loss: 0.5044 - accuracy: 0.8023 - val_loss: 0.4602 - val_accuracy: 0.8272\n",
      "Epoch 751/1000\n",
      "225/225 [==============================] - 1s 3ms/step - loss: 0.5026 - accuracy: 0.8033 - val_loss: 0.4589 - val_accuracy: 0.8278\n",
      "Epoch 752/1000\n",
      "225/225 [==============================] - 1s 3ms/step - loss: 0.5029 - accuracy: 0.8022 - val_loss: 0.4568 - val_accuracy: 0.8272\n",
      "Epoch 753/1000\n",
      "225/225 [==============================] - 1s 3ms/step - loss: 0.5013 - accuracy: 0.8027 - val_loss: 0.4606 - val_accuracy: 0.8275\n",
      "Epoch 754/1000\n",
      "225/225 [==============================] - 1s 3ms/step - loss: 0.5008 - accuracy: 0.8037 - val_loss: 0.4582 - val_accuracy: 0.8285\n",
      "Epoch 755/1000\n",
      "225/225 [==============================] - 1s 3ms/step - loss: 0.5015 - accuracy: 0.8026 - val_loss: 0.4573 - val_accuracy: 0.8286\n",
      "Epoch 756/1000\n",
      "225/225 [==============================] - 1s 3ms/step - loss: 0.5018 - accuracy: 0.8037 - val_loss: 0.4597 - val_accuracy: 0.8278\n",
      "Epoch 757/1000\n",
      "225/225 [==============================] - 1s 3ms/step - loss: 0.5022 - accuracy: 0.8026 - val_loss: 0.4582 - val_accuracy: 0.8275\n",
      "Epoch 758/1000\n",
      "225/225 [==============================] - 1s 2ms/step - loss: 0.5011 - accuracy: 0.8023 - val_loss: 0.4564 - val_accuracy: 0.8276\n",
      "Epoch 759/1000\n",
      "225/225 [==============================] - 1s 3ms/step - loss: 0.5018 - accuracy: 0.8032 - val_loss: 0.4608 - val_accuracy: 0.8279\n",
      "Epoch 760/1000\n",
      "225/225 [==============================] - 1s 3ms/step - loss: 0.5020 - accuracy: 0.8033 - val_loss: 0.4594 - val_accuracy: 0.8255\n",
      "Epoch 761/1000\n",
      "225/225 [==============================] - 1s 3ms/step - loss: 0.5046 - accuracy: 0.8024 - val_loss: 0.4581 - val_accuracy: 0.8277\n",
      "Epoch 762/1000\n",
      "225/225 [==============================] - 1s 3ms/step - loss: 0.5004 - accuracy: 0.8026 - val_loss: 0.4588 - val_accuracy: 0.8275\n",
      "Epoch 763/1000\n",
      "225/225 [==============================] - 1s 3ms/step - loss: 0.5018 - accuracy: 0.8039 - val_loss: 0.4582 - val_accuracy: 0.8260\n",
      "Epoch 764/1000\n",
      "225/225 [==============================] - 1s 3ms/step - loss: 0.5012 - accuracy: 0.8036 - val_loss: 0.4573 - val_accuracy: 0.8271\n",
      "Epoch 765/1000\n",
      "225/225 [==============================] - 1s 3ms/step - loss: 0.5013 - accuracy: 0.8037 - val_loss: 0.4616 - val_accuracy: 0.8274\n",
      "Epoch 766/1000\n",
      "225/225 [==============================] - 1s 3ms/step - loss: 0.5005 - accuracy: 0.8038 - val_loss: 0.4563 - val_accuracy: 0.8296\n",
      "Epoch 767/1000\n",
      "225/225 [==============================] - 1s 3ms/step - loss: 0.5017 - accuracy: 0.8034 - val_loss: 0.4576 - val_accuracy: 0.8285\n",
      "Epoch 768/1000\n",
      "225/225 [==============================] - 1s 3ms/step - loss: 0.5021 - accuracy: 0.8031 - val_loss: 0.4544 - val_accuracy: 0.8297\n",
      "Epoch 769/1000\n",
      "225/225 [==============================] - 1s 3ms/step - loss: 0.5012 - accuracy: 0.8042 - val_loss: 0.4595 - val_accuracy: 0.8253\n",
      "Epoch 770/1000\n",
      "225/225 [==============================] - 1s 3ms/step - loss: 0.5006 - accuracy: 0.8031 - val_loss: 0.4590 - val_accuracy: 0.8273\n",
      "Epoch 771/1000\n",
      "225/225 [==============================] - 1s 3ms/step - loss: 0.5026 - accuracy: 0.8035 - val_loss: 0.4569 - val_accuracy: 0.8282\n",
      "Epoch 772/1000\n",
      "225/225 [==============================] - 1s 3ms/step - loss: 0.5003 - accuracy: 0.8039 - val_loss: 0.4537 - val_accuracy: 0.8293\n",
      "Epoch 773/1000\n",
      "225/225 [==============================] - 1s 3ms/step - loss: 0.4990 - accuracy: 0.8032 - val_loss: 0.4550 - val_accuracy: 0.8288\n",
      "Epoch 774/1000\n",
      "225/225 [==============================] - 1s 3ms/step - loss: 0.5020 - accuracy: 0.8037 - val_loss: 0.4564 - val_accuracy: 0.8302\n",
      "Epoch 775/1000\n",
      "225/225 [==============================] - 1s 3ms/step - loss: 0.5013 - accuracy: 0.8040 - val_loss: 0.4560 - val_accuracy: 0.8295\n",
      "Epoch 776/1000\n",
      "225/225 [==============================] - 1s 3ms/step - loss: 0.5008 - accuracy: 0.8048 - val_loss: 0.4552 - val_accuracy: 0.8264\n",
      "Epoch 777/1000\n",
      "225/225 [==============================] - 1s 3ms/step - loss: 0.5025 - accuracy: 0.8021 - val_loss: 0.4573 - val_accuracy: 0.8264\n",
      "Epoch 778/1000\n",
      "225/225 [==============================] - 1s 3ms/step - loss: 0.5012 - accuracy: 0.8034 - val_loss: 0.4580 - val_accuracy: 0.8265\n",
      "Epoch 779/1000\n",
      "225/225 [==============================] - 1s 3ms/step - loss: 0.5011 - accuracy: 0.8045 - val_loss: 0.4587 - val_accuracy: 0.8258\n",
      "Epoch 780/1000\n",
      "225/225 [==============================] - 1s 3ms/step - loss: 0.5034 - accuracy: 0.8024 - val_loss: 0.4603 - val_accuracy: 0.8280\n",
      "Epoch 781/1000\n",
      "225/225 [==============================] - 1s 3ms/step - loss: 0.5013 - accuracy: 0.8041 - val_loss: 0.4577 - val_accuracy: 0.8265\n",
      "Epoch 782/1000\n",
      "225/225 [==============================] - 1s 3ms/step - loss: 0.5014 - accuracy: 0.8033 - val_loss: 0.4577 - val_accuracy: 0.8277\n",
      "Epoch 783/1000\n",
      "225/225 [==============================] - 1s 3ms/step - loss: 0.4993 - accuracy: 0.8036 - val_loss: 0.4548 - val_accuracy: 0.8285\n",
      "Epoch 784/1000\n",
      "225/225 [==============================] - 1s 3ms/step - loss: 0.5002 - accuracy: 0.8040 - val_loss: 0.4577 - val_accuracy: 0.8273\n",
      "Epoch 785/1000\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "225/225 [==============================] - 1s 3ms/step - loss: 0.4996 - accuracy: 0.8043 - val_loss: 0.4600 - val_accuracy: 0.8274\n",
      "Epoch 786/1000\n",
      "225/225 [==============================] - 1s 3ms/step - loss: 0.4991 - accuracy: 0.8047 - val_loss: 0.4563 - val_accuracy: 0.8275\n",
      "Epoch 787/1000\n",
      "225/225 [==============================] - 1s 3ms/step - loss: 0.5016 - accuracy: 0.8032 - val_loss: 0.4580 - val_accuracy: 0.8279\n",
      "Epoch 788/1000\n",
      "225/225 [==============================] - 1s 3ms/step - loss: 0.5015 - accuracy: 0.8036 - val_loss: 0.4618 - val_accuracy: 0.8262\n",
      "Epoch 789/1000\n",
      "225/225 [==============================] - 1s 3ms/step - loss: 0.5012 - accuracy: 0.8029 - val_loss: 0.4590 - val_accuracy: 0.8259\n",
      "Epoch 790/1000\n",
      "225/225 [==============================] - 1s 3ms/step - loss: 0.4998 - accuracy: 0.8036 - val_loss: 0.4570 - val_accuracy: 0.8293\n",
      "Epoch 791/1000\n",
      "225/225 [==============================] - 1s 3ms/step - loss: 0.5027 - accuracy: 0.8024 - val_loss: 0.4572 - val_accuracy: 0.8261\n",
      "Epoch 792/1000\n",
      "225/225 [==============================] - 1s 3ms/step - loss: 0.5013 - accuracy: 0.8031 - val_loss: 0.4596 - val_accuracy: 0.8269\n",
      "Epoch 793/1000\n",
      "225/225 [==============================] - 1s 3ms/step - loss: 0.4991 - accuracy: 0.8054 - val_loss: 0.4598 - val_accuracy: 0.8268\n",
      "Epoch 794/1000\n",
      "225/225 [==============================] - 1s 3ms/step - loss: 0.5004 - accuracy: 0.8048 - val_loss: 0.4588 - val_accuracy: 0.8271\n",
      "Epoch 795/1000\n",
      "225/225 [==============================] - 1s 3ms/step - loss: 0.5019 - accuracy: 0.8030 - val_loss: 0.4575 - val_accuracy: 0.8279\n",
      "Epoch 796/1000\n",
      "225/225 [==============================] - 1s 3ms/step - loss: 0.5026 - accuracy: 0.8033 - val_loss: 0.4601 - val_accuracy: 0.8244\n",
      "Epoch 797/1000\n",
      "225/225 [==============================] - 1s 3ms/step - loss: 0.5018 - accuracy: 0.8037 - val_loss: 0.4575 - val_accuracy: 0.8252\n",
      "Epoch 798/1000\n",
      "225/225 [==============================] - 1s 3ms/step - loss: 0.5002 - accuracy: 0.8039 - val_loss: 0.4582 - val_accuracy: 0.8237\n",
      "Epoch 799/1000\n",
      "225/225 [==============================] - 1s 3ms/step - loss: 0.5011 - accuracy: 0.8035 - val_loss: 0.4616 - val_accuracy: 0.8246\n",
      "Epoch 800/1000\n",
      "225/225 [==============================] - 1s 3ms/step - loss: 0.5005 - accuracy: 0.8029 - val_loss: 0.4603 - val_accuracy: 0.8260\n",
      "Epoch 801/1000\n",
      "225/225 [==============================] - 1s 3ms/step - loss: 0.4987 - accuracy: 0.8036 - val_loss: 0.4581 - val_accuracy: 0.8270\n",
      "Epoch 802/1000\n",
      "225/225 [==============================] - 1s 3ms/step - loss: 0.5002 - accuracy: 0.8030 - val_loss: 0.4592 - val_accuracy: 0.8257\n",
      "Epoch 803/1000\n",
      "225/225 [==============================] - 1s 3ms/step - loss: 0.5007 - accuracy: 0.8028 - val_loss: 0.4580 - val_accuracy: 0.8266\n",
      "Epoch 804/1000\n",
      "225/225 [==============================] - 1s 3ms/step - loss: 0.5007 - accuracy: 0.8023 - val_loss: 0.4563 - val_accuracy: 0.8264\n",
      "Epoch 805/1000\n",
      "225/225 [==============================] - 1s 3ms/step - loss: 0.5017 - accuracy: 0.8029 - val_loss: 0.4575 - val_accuracy: 0.8237\n",
      "Epoch 806/1000\n",
      "225/225 [==============================] - 1s 3ms/step - loss: 0.5004 - accuracy: 0.8032 - val_loss: 0.4589 - val_accuracy: 0.8263\n",
      "Epoch 807/1000\n",
      "225/225 [==============================] - 1s 3ms/step - loss: 0.4993 - accuracy: 0.8045 - val_loss: 0.4550 - val_accuracy: 0.8286\n",
      "Epoch 808/1000\n",
      "225/225 [==============================] - 1s 3ms/step - loss: 0.5003 - accuracy: 0.8039 - val_loss: 0.4586 - val_accuracy: 0.8238\n",
      "Epoch 809/1000\n",
      "225/225 [==============================] - 1s 3ms/step - loss: 0.4997 - accuracy: 0.8036 - val_loss: 0.4615 - val_accuracy: 0.8267\n",
      "Epoch 810/1000\n",
      "225/225 [==============================] - 1s 3ms/step - loss: 0.4994 - accuracy: 0.8048 - val_loss: 0.4573 - val_accuracy: 0.8297\n",
      "Epoch 811/1000\n",
      "225/225 [==============================] - 1s 3ms/step - loss: 0.4995 - accuracy: 0.8039 - val_loss: 0.4598 - val_accuracy: 0.8282\n",
      "Epoch 812/1000\n",
      "225/225 [==============================] - 1s 3ms/step - loss: 0.5002 - accuracy: 0.8037 - val_loss: 0.4559 - val_accuracy: 0.8291\n",
      "Epoch 813/1000\n",
      "225/225 [==============================] - 1s 3ms/step - loss: 0.5017 - accuracy: 0.8027 - val_loss: 0.4541 - val_accuracy: 0.8280\n",
      "Epoch 814/1000\n",
      "225/225 [==============================] - 1s 2ms/step - loss: 0.5009 - accuracy: 0.8045 - val_loss: 0.4597 - val_accuracy: 0.8265\n",
      "Epoch 815/1000\n",
      "225/225 [==============================] - 1s 3ms/step - loss: 0.5005 - accuracy: 0.8033 - val_loss: 0.4588 - val_accuracy: 0.8281\n",
      "Epoch 816/1000\n",
      "225/225 [==============================] - 1s 3ms/step - loss: 0.5012 - accuracy: 0.8030 - val_loss: 0.4614 - val_accuracy: 0.8254\n",
      "Epoch 817/1000\n",
      "225/225 [==============================] - 1s 3ms/step - loss: 0.4994 - accuracy: 0.8046 - val_loss: 0.4579 - val_accuracy: 0.8273\n",
      "Epoch 818/1000\n",
      "225/225 [==============================] - 1s 3ms/step - loss: 0.4987 - accuracy: 0.8049 - val_loss: 0.4544 - val_accuracy: 0.8298\n",
      "Epoch 819/1000\n",
      "225/225 [==============================] - 1s 3ms/step - loss: 0.4980 - accuracy: 0.8054 - val_loss: 0.4583 - val_accuracy: 0.8267\n",
      "Epoch 820/1000\n",
      "225/225 [==============================] - 1s 3ms/step - loss: 0.5021 - accuracy: 0.8034 - val_loss: 0.4568 - val_accuracy: 0.8278\n",
      "Epoch 821/1000\n",
      "225/225 [==============================] - 1s 3ms/step - loss: 0.5013 - accuracy: 0.8037 - val_loss: 0.4591 - val_accuracy: 0.8264\n",
      "Epoch 822/1000\n",
      "225/225 [==============================] - 1s 3ms/step - loss: 0.4989 - accuracy: 0.8040 - val_loss: 0.4571 - val_accuracy: 0.8282\n",
      "Epoch 823/1000\n",
      "225/225 [==============================] - 1s 3ms/step - loss: 0.5002 - accuracy: 0.8038 - val_loss: 0.4576 - val_accuracy: 0.8265\n",
      "Epoch 824/1000\n",
      "225/225 [==============================] - 1s 3ms/step - loss: 0.5005 - accuracy: 0.8042 - val_loss: 0.4571 - val_accuracy: 0.8277\n",
      "Epoch 825/1000\n",
      "225/225 [==============================] - 1s 3ms/step - loss: 0.5020 - accuracy: 0.8031 - val_loss: 0.4568 - val_accuracy: 0.8264\n",
      "Epoch 826/1000\n",
      "225/225 [==============================] - 1s 3ms/step - loss: 0.5006 - accuracy: 0.8038 - val_loss: 0.4567 - val_accuracy: 0.8290\n",
      "Epoch 827/1000\n",
      "225/225 [==============================] - 1s 3ms/step - loss: 0.5012 - accuracy: 0.8029 - val_loss: 0.4567 - val_accuracy: 0.8293\n",
      "Epoch 828/1000\n",
      "225/225 [==============================] - 1s 3ms/step - loss: 0.4986 - accuracy: 0.8050 - val_loss: 0.4571 - val_accuracy: 0.8290\n",
      "Epoch 829/1000\n",
      "225/225 [==============================] - 1s 3ms/step - loss: 0.5018 - accuracy: 0.8033 - val_loss: 0.4559 - val_accuracy: 0.8289\n",
      "Epoch 830/1000\n",
      "225/225 [==============================] - 1s 3ms/step - loss: 0.4969 - accuracy: 0.8057 - val_loss: 0.4562 - val_accuracy: 0.8277\n",
      "Epoch 831/1000\n",
      "225/225 [==============================] - 1s 3ms/step - loss: 0.5007 - accuracy: 0.8029 - val_loss: 0.4564 - val_accuracy: 0.8276\n",
      "Epoch 832/1000\n",
      "225/225 [==============================] - 1s 3ms/step - loss: 0.4997 - accuracy: 0.8033 - val_loss: 0.4572 - val_accuracy: 0.8290\n",
      "Epoch 833/1000\n",
      "225/225 [==============================] - 1s 3ms/step - loss: 0.5007 - accuracy: 0.8035 - val_loss: 0.4613 - val_accuracy: 0.8289\n",
      "Epoch 834/1000\n",
      "225/225 [==============================] - 1s 3ms/step - loss: 0.4992 - accuracy: 0.8043 - val_loss: 0.4583 - val_accuracy: 0.8253\n",
      "Epoch 835/1000\n",
      "225/225 [==============================] - 1s 3ms/step - loss: 0.4995 - accuracy: 0.8035 - val_loss: 0.4578 - val_accuracy: 0.8278\n",
      "Epoch 836/1000\n",
      "225/225 [==============================] - 1s 3ms/step - loss: 0.4993 - accuracy: 0.8041 - val_loss: 0.4572 - val_accuracy: 0.8284\n",
      "Epoch 837/1000\n",
      "225/225 [==============================] - 1s 3ms/step - loss: 0.5003 - accuracy: 0.8042 - val_loss: 0.4581 - val_accuracy: 0.8285\n",
      "Epoch 838/1000\n",
      "225/225 [==============================] - 1s 3ms/step - loss: 0.4995 - accuracy: 0.8038 - val_loss: 0.4555 - val_accuracy: 0.8283\n",
      "Epoch 839/1000\n",
      "225/225 [==============================] - 1s 3ms/step - loss: 0.4998 - accuracy: 0.8047 - val_loss: 0.4573 - val_accuracy: 0.8286\n",
      "Epoch 840/1000\n",
      "225/225 [==============================] - 1s 3ms/step - loss: 0.4996 - accuracy: 0.8044 - val_loss: 0.4601 - val_accuracy: 0.8271\n",
      "Epoch 841/1000\n",
      "225/225 [==============================] - 1s 3ms/step - loss: 0.5001 - accuracy: 0.8044 - val_loss: 0.4571 - val_accuracy: 0.8276\n",
      "Epoch 842/1000\n",
      "225/225 [==============================] - 1s 3ms/step - loss: 0.5010 - accuracy: 0.8028 - val_loss: 0.4602 - val_accuracy: 0.8295\n",
      "Epoch 843/1000\n",
      "225/225 [==============================] - 1s 3ms/step - loss: 0.5024 - accuracy: 0.8036 - val_loss: 0.4595 - val_accuracy: 0.8279\n",
      "Epoch 844/1000\n",
      "225/225 [==============================] - 1s 3ms/step - loss: 0.5014 - accuracy: 0.8031 - val_loss: 0.4596 - val_accuracy: 0.8260\n",
      "Epoch 845/1000\n",
      "225/225 [==============================] - 1s 3ms/step - loss: 0.5001 - accuracy: 0.8044 - val_loss: 0.4576 - val_accuracy: 0.8281\n",
      "Epoch 846/1000\n",
      "225/225 [==============================] - 1s 3ms/step - loss: 0.5013 - accuracy: 0.8035 - val_loss: 0.4571 - val_accuracy: 0.8264\n",
      "Epoch 847/1000\n",
      "225/225 [==============================] - 1s 3ms/step - loss: 0.4984 - accuracy: 0.8058 - val_loss: 0.4567 - val_accuracy: 0.8285\n",
      "Epoch 848/1000\n",
      "225/225 [==============================] - 1s 3ms/step - loss: 0.4981 - accuracy: 0.8037 - val_loss: 0.4566 - val_accuracy: 0.8280\n",
      "Epoch 849/1000\n",
      "225/225 [==============================] - 1s 3ms/step - loss: 0.4990 - accuracy: 0.8032 - val_loss: 0.4541 - val_accuracy: 0.8286\n",
      "Epoch 850/1000\n",
      "225/225 [==============================] - 1s 3ms/step - loss: 0.4996 - accuracy: 0.8045 - val_loss: 0.4586 - val_accuracy: 0.8278\n",
      "Epoch 851/1000\n",
      "225/225 [==============================] - 1s 3ms/step - loss: 0.4991 - accuracy: 0.8055 - val_loss: 0.4577 - val_accuracy: 0.8293\n",
      "Epoch 852/1000\n",
      "225/225 [==============================] - 1s 3ms/step - loss: 0.5002 - accuracy: 0.8051 - val_loss: 0.4573 - val_accuracy: 0.8300\n",
      "Epoch 853/1000\n",
      "225/225 [==============================] - 1s 3ms/step - loss: 0.4992 - accuracy: 0.8051 - val_loss: 0.4561 - val_accuracy: 0.8293\n",
      "Epoch 854/1000\n",
      "225/225 [==============================] - 1s 3ms/step - loss: 0.5005 - accuracy: 0.8043 - val_loss: 0.4556 - val_accuracy: 0.8278\n",
      "Epoch 855/1000\n",
      "225/225 [==============================] - 1s 3ms/step - loss: 0.4993 - accuracy: 0.8040 - val_loss: 0.4594 - val_accuracy: 0.8277\n",
      "Epoch 856/1000\n",
      "225/225 [==============================] - 1s 2ms/step - loss: 0.4975 - accuracy: 0.8060 - val_loss: 0.4566 - val_accuracy: 0.8298\n",
      "Epoch 857/1000\n",
      "225/225 [==============================] - 1s 2ms/step - loss: 0.4991 - accuracy: 0.8046 - val_loss: 0.4550 - val_accuracy: 0.8276\n",
      "Epoch 858/1000\n",
      "225/225 [==============================] - 1s 3ms/step - loss: 0.4997 - accuracy: 0.8044 - val_loss: 0.4577 - val_accuracy: 0.8306\n",
      "Epoch 859/1000\n",
      "225/225 [==============================] - 1s 3ms/step - loss: 0.5017 - accuracy: 0.8032 - val_loss: 0.4566 - val_accuracy: 0.8300\n",
      "Epoch 860/1000\n",
      "225/225 [==============================] - 1s 3ms/step - loss: 0.4979 - accuracy: 0.8045 - val_loss: 0.4549 - val_accuracy: 0.8301\n",
      "Epoch 861/1000\n",
      "225/225 [==============================] - 1s 3ms/step - loss: 0.5019 - accuracy: 0.8023 - val_loss: 0.4575 - val_accuracy: 0.8278\n",
      "Epoch 862/1000\n",
      "225/225 [==============================] - 1s 3ms/step - loss: 0.4991 - accuracy: 0.8042 - val_loss: 0.4548 - val_accuracy: 0.8289\n",
      "Epoch 862: early stopping\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "<keras.src.callbacks.History at 0x2ed5d5ae0>"
      ]
     },
     "execution_count": 211,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "model=Sequential()\n",
    "model.add(Dense(128, input_dim=X_train.shape[1], activation=\"relu\"))\n",
    "model.add(Dropout(0.2))\n",
    "model.add(Dense(128, activation=\"relu\"))\n",
    "model.add(Dropout(0.2))\n",
    "model.add(Dense(64, activation=\"relu\"))\n",
    "model.add(Dropout(0.2))\n",
    "model.add(Dense(64, activation=\"relu\"))\n",
    "model.add(Dropout(0.2))\n",
    "model.add(Dense(32, activation=\"relu\"))\n",
    "model.add(Dropout(0.2))\n",
    "model.add(Dense(16, activation=\"relu\"))\n",
    "\n",
    "model.add(Dense(3, activation=\"softmax\"))\n",
    "\n",
    "optimizer = tf.keras.optimizers.legacy.Nadam(learning_rate=0.001)\n",
    "model.compile(loss='categorical_crossentropy', optimizer=optimizer, metrics=['accuracy'])\n",
    "\n",
    "es=EarlyStopping(monitor=\"val_loss\",patience=90,mode=\"auto\",verbose=1)\n",
    "\n",
    "model.fit(X_train, y_train,epochs=1000,batch_size=512,validation_split=0.1,verbose=1,callbacks=[es])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 212,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "997/997 [==============================] - 0s 324us/step\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0       0.84      0.92      0.88     10867\n",
      "           1       0.82      0.88      0.85     10432\n",
      "           2       0.81      0.68      0.74     10591\n",
      "\n",
      "    accuracy                           0.83     31890\n",
      "   macro avg       0.83      0.83      0.82     31890\n",
      "weighted avg       0.83      0.83      0.82     31890\n",
      "\n"
     ]
    }
   ],
   "source": [
    "y_pred = model.predict(X_test)\n",
    "y_pred_classes = np.argmax(y_pred, axis=1)\n",
    "y_true = np.argmax(y_test, axis=1)\n",
    "print(classification_report(y_true, y_pred_classes))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 213,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "3987/3987 [==============================] - 1s 255us/step\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0       0.87      0.95      0.90     42282\n",
      "           1       0.84      0.91      0.87     42717\n",
      "           2       0.85      0.71      0.77     42558\n",
      "\n",
      "    accuracy                           0.85    127557\n",
      "   macro avg       0.85      0.85      0.85    127557\n",
      "weighted avg       0.85      0.85      0.85    127557\n",
      "\n"
     ]
    }
   ],
   "source": [
    "y_t_pred = model.predict(X_train)\n",
    "y_t_pred_classes = np.argmax(y_t_pred, axis=1)\n",
    "y_t_true = np.argmax(y_train, axis=1)\n",
    "print(classification_report(y_t_true, y_t_pred_classes))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 214,
   "metadata": {},
   "outputs": [],
   "source": [
    "from tensorflow.keras.layers import BatchNormalization"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 215,
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 1/1000\n",
      "225/225 [==============================] - 1s 3ms/step - loss: 0.8017 - accuracy: 0.6686 - val_loss: 0.7172 - val_accuracy: 0.7210\n",
      "Epoch 2/1000\n",
      "225/225 [==============================] - 1s 2ms/step - loss: 0.7083 - accuracy: 0.7221 - val_loss: 0.6659 - val_accuracy: 0.7368\n",
      "Epoch 3/1000\n",
      "225/225 [==============================] - 1s 2ms/step - loss: 0.6905 - accuracy: 0.7301 - val_loss: 0.6552 - val_accuracy: 0.7406\n",
      "Epoch 4/1000\n",
      "225/225 [==============================] - 1s 2ms/step - loss: 0.6788 - accuracy: 0.7353 - val_loss: 0.6464 - val_accuracy: 0.7461\n",
      "Epoch 5/1000\n",
      "225/225 [==============================] - 1s 2ms/step - loss: 0.6700 - accuracy: 0.7383 - val_loss: 0.6423 - val_accuracy: 0.7472\n",
      "Epoch 6/1000\n",
      "225/225 [==============================] - 1s 2ms/step - loss: 0.6623 - accuracy: 0.7408 - val_loss: 0.6359 - val_accuracy: 0.7493\n",
      "Epoch 7/1000\n",
      "225/225 [==============================] - 1s 3ms/step - loss: 0.6579 - accuracy: 0.7422 - val_loss: 0.6347 - val_accuracy: 0.7498\n",
      "Epoch 8/1000\n",
      "225/225 [==============================] - 1s 3ms/step - loss: 0.6528 - accuracy: 0.7431 - val_loss: 0.6328 - val_accuracy: 0.7524\n",
      "Epoch 9/1000\n",
      "225/225 [==============================] - 1s 3ms/step - loss: 0.6477 - accuracy: 0.7451 - val_loss: 0.6317 - val_accuracy: 0.7524\n",
      "Epoch 10/1000\n",
      "225/225 [==============================] - 1s 2ms/step - loss: 0.6413 - accuracy: 0.7469 - val_loss: 0.6240 - val_accuracy: 0.7537\n",
      "Epoch 11/1000\n",
      "225/225 [==============================] - 1s 2ms/step - loss: 0.6384 - accuracy: 0.7474 - val_loss: 0.6167 - val_accuracy: 0.7552\n",
      "Epoch 12/1000\n",
      "225/225 [==============================] - 1s 2ms/step - loss: 0.6339 - accuracy: 0.7489 - val_loss: 0.6140 - val_accuracy: 0.7542\n",
      "Epoch 13/1000\n",
      "225/225 [==============================] - 1s 2ms/step - loss: 0.6287 - accuracy: 0.7502 - val_loss: 0.6121 - val_accuracy: 0.7582\n",
      "Epoch 14/1000\n",
      "225/225 [==============================] - 1s 2ms/step - loss: 0.6254 - accuracy: 0.7519 - val_loss: 0.6060 - val_accuracy: 0.7595\n",
      "Epoch 15/1000\n",
      "225/225 [==============================] - 1s 2ms/step - loss: 0.6219 - accuracy: 0.7529 - val_loss: 0.6042 - val_accuracy: 0.7607\n",
      "Epoch 16/1000\n",
      "225/225 [==============================] - 1s 2ms/step - loss: 0.6178 - accuracy: 0.7536 - val_loss: 0.6009 - val_accuracy: 0.7622\n",
      "Epoch 17/1000\n",
      "225/225 [==============================] - 1s 2ms/step - loss: 0.6149 - accuracy: 0.7546 - val_loss: 0.5957 - val_accuracy: 0.7641\n",
      "Epoch 18/1000\n",
      "225/225 [==============================] - 1s 2ms/step - loss: 0.6111 - accuracy: 0.7564 - val_loss: 0.5917 - val_accuracy: 0.7642\n",
      "Epoch 19/1000\n",
      "225/225 [==============================] - 1s 2ms/step - loss: 0.6075 - accuracy: 0.7586 - val_loss: 0.5874 - val_accuracy: 0.7660\n",
      "Epoch 20/1000\n",
      "225/225 [==============================] - 1s 2ms/step - loss: 0.6029 - accuracy: 0.7591 - val_loss: 0.5839 - val_accuracy: 0.7682\n",
      "Epoch 21/1000\n",
      "225/225 [==============================] - 1s 2ms/step - loss: 0.6001 - accuracy: 0.7594 - val_loss: 0.5807 - val_accuracy: 0.7673\n",
      "Epoch 22/1000\n",
      "225/225 [==============================] - 1s 3ms/step - loss: 0.5954 - accuracy: 0.7620 - val_loss: 0.5765 - val_accuracy: 0.7709\n",
      "Epoch 23/1000\n",
      "225/225 [==============================] - 1s 3ms/step - loss: 0.5937 - accuracy: 0.7634 - val_loss: 0.5800 - val_accuracy: 0.7738\n",
      "Epoch 24/1000\n",
      "225/225 [==============================] - 1s 2ms/step - loss: 0.5916 - accuracy: 0.7636 - val_loss: 0.5707 - val_accuracy: 0.7727\n",
      "Epoch 25/1000\n",
      "225/225 [==============================] - 1s 2ms/step - loss: 0.5882 - accuracy: 0.7656 - val_loss: 0.5692 - val_accuracy: 0.7763\n",
      "Epoch 26/1000\n",
      "225/225 [==============================] - 1s 2ms/step - loss: 0.5860 - accuracy: 0.7659 - val_loss: 0.5637 - val_accuracy: 0.7775\n",
      "Epoch 27/1000\n",
      "225/225 [==============================] - 1s 3ms/step - loss: 0.5816 - accuracy: 0.7672 - val_loss: 0.5632 - val_accuracy: 0.7754\n",
      "Epoch 28/1000\n",
      "225/225 [==============================] - 1s 3ms/step - loss: 0.5812 - accuracy: 0.7676 - val_loss: 0.5660 - val_accuracy: 0.7755\n",
      "Epoch 29/1000\n",
      "225/225 [==============================] - 1s 2ms/step - loss: 0.5777 - accuracy: 0.7690 - val_loss: 0.5665 - val_accuracy: 0.7765\n",
      "Epoch 30/1000\n",
      "225/225 [==============================] - 1s 2ms/step - loss: 0.5746 - accuracy: 0.7698 - val_loss: 0.5531 - val_accuracy: 0.7814\n",
      "Epoch 31/1000\n",
      "225/225 [==============================] - 1s 2ms/step - loss: 0.5736 - accuracy: 0.7713 - val_loss: 0.5536 - val_accuracy: 0.7808\n",
      "Epoch 32/1000\n",
      "225/225 [==============================] - 1s 2ms/step - loss: 0.5710 - accuracy: 0.7712 - val_loss: 0.5489 - val_accuracy: 0.7838\n",
      "Epoch 33/1000\n",
      "225/225 [==============================] - 1s 2ms/step - loss: 0.5696 - accuracy: 0.7727 - val_loss: 0.5513 - val_accuracy: 0.7823\n",
      "Epoch 34/1000\n",
      "225/225 [==============================] - 1s 2ms/step - loss: 0.5669 - accuracy: 0.7732 - val_loss: 0.5455 - val_accuracy: 0.7866\n",
      "Epoch 35/1000\n",
      "225/225 [==============================] - 1s 2ms/step - loss: 0.5635 - accuracy: 0.7749 - val_loss: 0.5424 - val_accuracy: 0.7853\n",
      "Epoch 36/1000\n",
      "225/225 [==============================] - 1s 2ms/step - loss: 0.5616 - accuracy: 0.7750 - val_loss: 0.5376 - val_accuracy: 0.7852\n",
      "Epoch 37/1000\n",
      "225/225 [==============================] - 1s 2ms/step - loss: 0.5596 - accuracy: 0.7756 - val_loss: 0.5401 - val_accuracy: 0.7883\n",
      "Epoch 38/1000\n",
      "225/225 [==============================] - 1s 2ms/step - loss: 0.5602 - accuracy: 0.7773 - val_loss: 0.5356 - val_accuracy: 0.7886\n",
      "Epoch 39/1000\n",
      "225/225 [==============================] - 1s 2ms/step - loss: 0.5583 - accuracy: 0.7771 - val_loss: 0.5368 - val_accuracy: 0.7881\n",
      "Epoch 40/1000\n",
      "225/225 [==============================] - 1s 3ms/step - loss: 0.5554 - accuracy: 0.7780 - val_loss: 0.5347 - val_accuracy: 0.7877\n",
      "Epoch 41/1000\n",
      "225/225 [==============================] - 1s 2ms/step - loss: 0.5549 - accuracy: 0.7776 - val_loss: 0.5352 - val_accuracy: 0.7862\n",
      "Epoch 42/1000\n",
      "225/225 [==============================] - 1s 2ms/step - loss: 0.5533 - accuracy: 0.7793 - val_loss: 0.5327 - val_accuracy: 0.7946\n",
      "Epoch 43/1000\n",
      "225/225 [==============================] - 1s 3ms/step - loss: 0.5492 - accuracy: 0.7808 - val_loss: 0.5303 - val_accuracy: 0.7905\n",
      "Epoch 44/1000\n",
      "225/225 [==============================] - 1s 2ms/step - loss: 0.5513 - accuracy: 0.7786 - val_loss: 0.5228 - val_accuracy: 0.7937\n",
      "Epoch 45/1000\n",
      "225/225 [==============================] - 1s 2ms/step - loss: 0.5471 - accuracy: 0.7819 - val_loss: 0.5298 - val_accuracy: 0.7944\n",
      "Epoch 46/1000\n",
      "225/225 [==============================] - 1s 2ms/step - loss: 0.5475 - accuracy: 0.7812 - val_loss: 0.5276 - val_accuracy: 0.7915\n",
      "Epoch 47/1000\n",
      "225/225 [==============================] - 1s 2ms/step - loss: 0.5458 - accuracy: 0.7822 - val_loss: 0.5254 - val_accuracy: 0.7924\n",
      "Epoch 48/1000\n",
      "225/225 [==============================] - 1s 3ms/step - loss: 0.5441 - accuracy: 0.7827 - val_loss: 0.5217 - val_accuracy: 0.7952\n",
      "Epoch 49/1000\n",
      "225/225 [==============================] - 1s 2ms/step - loss: 0.5420 - accuracy: 0.7844 - val_loss: 0.5204 - val_accuracy: 0.7956\n",
      "Epoch 50/1000\n",
      "225/225 [==============================] - 1s 2ms/step - loss: 0.5398 - accuracy: 0.7842 - val_loss: 0.5195 - val_accuracy: 0.7971\n",
      "Epoch 51/1000\n",
      "225/225 [==============================] - 1s 2ms/step - loss: 0.5399 - accuracy: 0.7848 - val_loss: 0.5176 - val_accuracy: 0.7972\n",
      "Epoch 52/1000\n",
      "225/225 [==============================] - 1s 2ms/step - loss: 0.5387 - accuracy: 0.7841 - val_loss: 0.5161 - val_accuracy: 0.7963\n",
      "Epoch 53/1000\n",
      "225/225 [==============================] - 1s 2ms/step - loss: 0.5394 - accuracy: 0.7859 - val_loss: 0.5146 - val_accuracy: 0.8010\n",
      "Epoch 54/1000\n",
      "225/225 [==============================] - 1s 2ms/step - loss: 0.5357 - accuracy: 0.7869 - val_loss: 0.5138 - val_accuracy: 0.7992\n",
      "Epoch 55/1000\n",
      "225/225 [==============================] - 1s 2ms/step - loss: 0.5358 - accuracy: 0.7853 - val_loss: 0.5115 - val_accuracy: 0.7955\n",
      "Epoch 56/1000\n",
      "225/225 [==============================] - 1s 3ms/step - loss: 0.5337 - accuracy: 0.7862 - val_loss: 0.5124 - val_accuracy: 0.7977\n",
      "Epoch 57/1000\n",
      "225/225 [==============================] - 1s 2ms/step - loss: 0.5323 - accuracy: 0.7875 - val_loss: 0.5072 - val_accuracy: 0.8002\n",
      "Epoch 58/1000\n",
      "225/225 [==============================] - 1s 2ms/step - loss: 0.5321 - accuracy: 0.7875 - val_loss: 0.5111 - val_accuracy: 0.7992\n",
      "Epoch 59/1000\n",
      "225/225 [==============================] - 1s 2ms/step - loss: 0.5303 - accuracy: 0.7889 - val_loss: 0.5085 - val_accuracy: 0.8003\n",
      "Epoch 60/1000\n",
      "225/225 [==============================] - 1s 2ms/step - loss: 0.5313 - accuracy: 0.7870 - val_loss: 0.5056 - val_accuracy: 0.8047\n",
      "Epoch 61/1000\n",
      "225/225 [==============================] - 1s 2ms/step - loss: 0.5305 - accuracy: 0.7872 - val_loss: 0.5047 - val_accuracy: 0.8024\n",
      "Epoch 62/1000\n",
      "225/225 [==============================] - 1s 2ms/step - loss: 0.5273 - accuracy: 0.7896 - val_loss: 0.5027 - val_accuracy: 0.8032\n",
      "Epoch 63/1000\n",
      "225/225 [==============================] - 1s 2ms/step - loss: 0.5280 - accuracy: 0.7892 - val_loss: 0.5041 - val_accuracy: 0.8053\n",
      "Epoch 64/1000\n",
      "225/225 [==============================] - 1s 2ms/step - loss: 0.5242 - accuracy: 0.7907 - val_loss: 0.5045 - val_accuracy: 0.8045\n",
      "Epoch 65/1000\n",
      "225/225 [==============================] - 1s 2ms/step - loss: 0.5262 - accuracy: 0.7915 - val_loss: 0.4983 - val_accuracy: 0.8069\n",
      "Epoch 66/1000\n",
      "225/225 [==============================] - 1s 2ms/step - loss: 0.5247 - accuracy: 0.7913 - val_loss: 0.5000 - val_accuracy: 0.8042\n",
      "Epoch 67/1000\n",
      "225/225 [==============================] - 1s 2ms/step - loss: 0.5236 - accuracy: 0.7914 - val_loss: 0.5012 - val_accuracy: 0.8024\n",
      "Epoch 68/1000\n",
      "225/225 [==============================] - 1s 2ms/step - loss: 0.5242 - accuracy: 0.7918 - val_loss: 0.4959 - val_accuracy: 0.8093\n",
      "Epoch 69/1000\n",
      "225/225 [==============================] - 1s 2ms/step - loss: 0.5226 - accuracy: 0.7921 - val_loss: 0.4990 - val_accuracy: 0.8088\n",
      "Epoch 70/1000\n",
      "225/225 [==============================] - 1s 2ms/step - loss: 0.5207 - accuracy: 0.7929 - val_loss: 0.4945 - val_accuracy: 0.8058\n",
      "Epoch 71/1000\n",
      "225/225 [==============================] - 1s 2ms/step - loss: 0.5202 - accuracy: 0.7930 - val_loss: 0.4964 - val_accuracy: 0.8115\n",
      "Epoch 72/1000\n",
      "225/225 [==============================] - 1s 2ms/step - loss: 0.5191 - accuracy: 0.7934 - val_loss: 0.4927 - val_accuracy: 0.8082\n",
      "Epoch 73/1000\n",
      "225/225 [==============================] - 1s 2ms/step - loss: 0.5205 - accuracy: 0.7928 - val_loss: 0.4958 - val_accuracy: 0.8082\n",
      "Epoch 74/1000\n",
      "225/225 [==============================] - 1s 2ms/step - loss: 0.5194 - accuracy: 0.7928 - val_loss: 0.4907 - val_accuracy: 0.8085\n",
      "Epoch 75/1000\n",
      "225/225 [==============================] - 1s 2ms/step - loss: 0.5170 - accuracy: 0.7935 - val_loss: 0.4915 - val_accuracy: 0.8125\n",
      "Epoch 76/1000\n",
      "225/225 [==============================] - 1s 2ms/step - loss: 0.5183 - accuracy: 0.7933 - val_loss: 0.4883 - val_accuracy: 0.8133\n",
      "Epoch 77/1000\n",
      "225/225 [==============================] - 1s 2ms/step - loss: 0.5175 - accuracy: 0.7948 - val_loss: 0.4931 - val_accuracy: 0.8091\n",
      "Epoch 78/1000\n",
      "225/225 [==============================] - 1s 2ms/step - loss: 0.5164 - accuracy: 0.7953 - val_loss: 0.4926 - val_accuracy: 0.8092\n",
      "Epoch 79/1000\n",
      "225/225 [==============================] - 1s 2ms/step - loss: 0.5151 - accuracy: 0.7950 - val_loss: 0.4887 - val_accuracy: 0.8111\n",
      "Epoch 80/1000\n",
      "225/225 [==============================] - 1s 2ms/step - loss: 0.5173 - accuracy: 0.7936 - val_loss: 0.4935 - val_accuracy: 0.8068\n",
      "Epoch 81/1000\n",
      "225/225 [==============================] - 1s 2ms/step - loss: 0.5140 - accuracy: 0.7957 - val_loss: 0.4880 - val_accuracy: 0.8151\n",
      "Epoch 82/1000\n",
      "225/225 [==============================] - 1s 2ms/step - loss: 0.5153 - accuracy: 0.7957 - val_loss: 0.4931 - val_accuracy: 0.8135\n",
      "Epoch 83/1000\n",
      "225/225 [==============================] - 1s 2ms/step - loss: 0.5126 - accuracy: 0.7959 - val_loss: 0.4871 - val_accuracy: 0.8125\n",
      "Epoch 84/1000\n",
      "225/225 [==============================] - 1s 2ms/step - loss: 0.5126 - accuracy: 0.7967 - val_loss: 0.4860 - val_accuracy: 0.8104\n",
      "Epoch 85/1000\n",
      "225/225 [==============================] - 1s 3ms/step - loss: 0.5133 - accuracy: 0.7956 - val_loss: 0.4849 - val_accuracy: 0.8127\n",
      "Epoch 86/1000\n",
      "225/225 [==============================] - 1s 3ms/step - loss: 0.5122 - accuracy: 0.7967 - val_loss: 0.4830 - val_accuracy: 0.8111\n",
      "Epoch 87/1000\n",
      "225/225 [==============================] - 1s 3ms/step - loss: 0.5113 - accuracy: 0.7976 - val_loss: 0.4858 - val_accuracy: 0.8148\n",
      "Epoch 88/1000\n",
      "225/225 [==============================] - 1s 2ms/step - loss: 0.5091 - accuracy: 0.7974 - val_loss: 0.4854 - val_accuracy: 0.8160\n",
      "Epoch 89/1000\n",
      "225/225 [==============================] - 1s 2ms/step - loss: 0.5069 - accuracy: 0.7983 - val_loss: 0.4826 - val_accuracy: 0.8146\n",
      "Epoch 90/1000\n",
      "225/225 [==============================] - 1s 2ms/step - loss: 0.5100 - accuracy: 0.7973 - val_loss: 0.4817 - val_accuracy: 0.8158\n",
      "Epoch 91/1000\n",
      "225/225 [==============================] - 1s 2ms/step - loss: 0.5088 - accuracy: 0.7993 - val_loss: 0.4816 - val_accuracy: 0.8155\n",
      "Epoch 92/1000\n",
      "225/225 [==============================] - 1s 2ms/step - loss: 0.5079 - accuracy: 0.7988 - val_loss: 0.4808 - val_accuracy: 0.8156\n",
      "Epoch 93/1000\n",
      "225/225 [==============================] - 1s 2ms/step - loss: 0.5062 - accuracy: 0.7988 - val_loss: 0.4782 - val_accuracy: 0.8152\n",
      "Epoch 94/1000\n",
      "225/225 [==============================] - 1s 2ms/step - loss: 0.5081 - accuracy: 0.7986 - val_loss: 0.4850 - val_accuracy: 0.8124\n",
      "Epoch 95/1000\n",
      "225/225 [==============================] - 1s 3ms/step - loss: 0.5074 - accuracy: 0.7987 - val_loss: 0.4772 - val_accuracy: 0.8188\n",
      "Epoch 96/1000\n",
      "225/225 [==============================] - 1s 2ms/step - loss: 0.5065 - accuracy: 0.7993 - val_loss: 0.4797 - val_accuracy: 0.8148\n",
      "Epoch 97/1000\n",
      "225/225 [==============================] - 1s 2ms/step - loss: 0.5032 - accuracy: 0.7998 - val_loss: 0.4796 - val_accuracy: 0.8177\n",
      "Epoch 98/1000\n",
      "225/225 [==============================] - 1s 2ms/step - loss: 0.5054 - accuracy: 0.8002 - val_loss: 0.4770 - val_accuracy: 0.8149\n",
      "Epoch 99/1000\n",
      "225/225 [==============================] - 1s 2ms/step - loss: 0.5047 - accuracy: 0.8003 - val_loss: 0.4794 - val_accuracy: 0.8122\n",
      "Epoch 100/1000\n",
      "225/225 [==============================] - 1s 3ms/step - loss: 0.5034 - accuracy: 0.8014 - val_loss: 0.4776 - val_accuracy: 0.8154\n",
      "Epoch 101/1000\n",
      "225/225 [==============================] - 1s 2ms/step - loss: 0.5035 - accuracy: 0.8008 - val_loss: 0.4743 - val_accuracy: 0.8152\n",
      "Epoch 102/1000\n",
      "225/225 [==============================] - 1s 2ms/step - loss: 0.5023 - accuracy: 0.8010 - val_loss: 0.4756 - val_accuracy: 0.8173\n",
      "Epoch 103/1000\n",
      "225/225 [==============================] - 1s 2ms/step - loss: 0.5008 - accuracy: 0.8023 - val_loss: 0.4734 - val_accuracy: 0.8174\n",
      "Epoch 104/1000\n",
      "225/225 [==============================] - 1s 2ms/step - loss: 0.5028 - accuracy: 0.8007 - val_loss: 0.4761 - val_accuracy: 0.8186\n",
      "Epoch 105/1000\n",
      "225/225 [==============================] - 1s 2ms/step - loss: 0.5022 - accuracy: 0.8018 - val_loss: 0.4773 - val_accuracy: 0.8141\n",
      "Epoch 106/1000\n",
      "225/225 [==============================] - 1s 2ms/step - loss: 0.5005 - accuracy: 0.8019 - val_loss: 0.4754 - val_accuracy: 0.8161\n",
      "Epoch 107/1000\n",
      "225/225 [==============================] - 1s 2ms/step - loss: 0.5007 - accuracy: 0.8020 - val_loss: 0.4684 - val_accuracy: 0.8188\n",
      "Epoch 108/1000\n",
      "225/225 [==============================] - 1s 2ms/step - loss: 0.5013 - accuracy: 0.8025 - val_loss: 0.4698 - val_accuracy: 0.8203\n",
      "Epoch 109/1000\n",
      "225/225 [==============================] - 1s 2ms/step - loss: 0.4968 - accuracy: 0.8039 - val_loss: 0.4755 - val_accuracy: 0.8190\n",
      "Epoch 110/1000\n",
      "225/225 [==============================] - 1s 2ms/step - loss: 0.4980 - accuracy: 0.8032 - val_loss: 0.4743 - val_accuracy: 0.8152\n",
      "Epoch 111/1000\n",
      "225/225 [==============================] - 1s 2ms/step - loss: 0.4989 - accuracy: 0.8033 - val_loss: 0.4766 - val_accuracy: 0.8173\n",
      "Epoch 112/1000\n",
      "225/225 [==============================] - 1s 3ms/step - loss: 0.4982 - accuracy: 0.8028 - val_loss: 0.4745 - val_accuracy: 0.8168\n",
      "Epoch 113/1000\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "225/225 [==============================] - 1s 2ms/step - loss: 0.4971 - accuracy: 0.8037 - val_loss: 0.4718 - val_accuracy: 0.8176\n",
      "Epoch 114/1000\n",
      "225/225 [==============================] - 1s 3ms/step - loss: 0.4959 - accuracy: 0.8043 - val_loss: 0.4679 - val_accuracy: 0.8196\n",
      "Epoch 115/1000\n",
      "225/225 [==============================] - 1s 2ms/step - loss: 0.4969 - accuracy: 0.8034 - val_loss: 0.4662 - val_accuracy: 0.8214\n",
      "Epoch 116/1000\n",
      "225/225 [==============================] - 1s 2ms/step - loss: 0.4972 - accuracy: 0.8028 - val_loss: 0.4725 - val_accuracy: 0.8181\n",
      "Epoch 117/1000\n",
      "225/225 [==============================] - 1s 2ms/step - loss: 0.4972 - accuracy: 0.8023 - val_loss: 0.4696 - val_accuracy: 0.8204\n",
      "Epoch 118/1000\n",
      "225/225 [==============================] - 1s 2ms/step - loss: 0.4964 - accuracy: 0.8026 - val_loss: 0.4697 - val_accuracy: 0.8166\n",
      "Epoch 119/1000\n",
      "225/225 [==============================] - 1s 2ms/step - loss: 0.4958 - accuracy: 0.8046 - val_loss: 0.4670 - val_accuracy: 0.8216\n",
      "Epoch 120/1000\n",
      "225/225 [==============================] - 1s 2ms/step - loss: 0.4959 - accuracy: 0.8043 - val_loss: 0.4687 - val_accuracy: 0.8207\n",
      "Epoch 121/1000\n",
      "225/225 [==============================] - 1s 2ms/step - loss: 0.4934 - accuracy: 0.8041 - val_loss: 0.4675 - val_accuracy: 0.8219\n",
      "Epoch 122/1000\n",
      "225/225 [==============================] - 1s 2ms/step - loss: 0.4947 - accuracy: 0.8048 - val_loss: 0.4704 - val_accuracy: 0.8195\n",
      "Epoch 123/1000\n",
      "225/225 [==============================] - 1s 2ms/step - loss: 0.4946 - accuracy: 0.8041 - val_loss: 0.4669 - val_accuracy: 0.8209\n",
      "Epoch 124/1000\n",
      "225/225 [==============================] - 1s 3ms/step - loss: 0.4939 - accuracy: 0.8047 - val_loss: 0.4689 - val_accuracy: 0.8203\n",
      "Epoch 125/1000\n",
      "225/225 [==============================] - 1s 2ms/step - loss: 0.4919 - accuracy: 0.8045 - val_loss: 0.4674 - val_accuracy: 0.8202\n",
      "Epoch 126/1000\n",
      "225/225 [==============================] - 1s 2ms/step - loss: 0.4941 - accuracy: 0.8046 - val_loss: 0.4708 - val_accuracy: 0.8206\n",
      "Epoch 127/1000\n",
      "225/225 [==============================] - 1s 2ms/step - loss: 0.4921 - accuracy: 0.8055 - val_loss: 0.4682 - val_accuracy: 0.8199\n",
      "Epoch 128/1000\n",
      "225/225 [==============================] - 1s 2ms/step - loss: 0.4917 - accuracy: 0.8053 - val_loss: 0.4669 - val_accuracy: 0.8213\n",
      "Epoch 129/1000\n",
      "225/225 [==============================] - 1s 2ms/step - loss: 0.4923 - accuracy: 0.8051 - val_loss: 0.4625 - val_accuracy: 0.8233\n",
      "Epoch 130/1000\n",
      "225/225 [==============================] - 1s 3ms/step - loss: 0.4917 - accuracy: 0.8063 - val_loss: 0.4648 - val_accuracy: 0.8189\n",
      "Epoch 131/1000\n",
      "225/225 [==============================] - 1s 2ms/step - loss: 0.4919 - accuracy: 0.8053 - val_loss: 0.4647 - val_accuracy: 0.8198\n",
      "Epoch 132/1000\n",
      "225/225 [==============================] - 1s 2ms/step - loss: 0.4917 - accuracy: 0.8056 - val_loss: 0.4656 - val_accuracy: 0.8234\n",
      "Epoch 133/1000\n",
      "225/225 [==============================] - 1s 2ms/step - loss: 0.4931 - accuracy: 0.8049 - val_loss: 0.4636 - val_accuracy: 0.8254\n",
      "Epoch 134/1000\n",
      "225/225 [==============================] - 1s 2ms/step - loss: 0.4914 - accuracy: 0.8067 - val_loss: 0.4618 - val_accuracy: 0.8241\n",
      "Epoch 135/1000\n",
      "225/225 [==============================] - 1s 2ms/step - loss: 0.4911 - accuracy: 0.8055 - val_loss: 0.4613 - val_accuracy: 0.8233\n",
      "Epoch 136/1000\n",
      "225/225 [==============================] - 1s 2ms/step - loss: 0.4913 - accuracy: 0.8066 - val_loss: 0.4653 - val_accuracy: 0.8224\n",
      "Epoch 137/1000\n",
      "225/225 [==============================] - 1s 2ms/step - loss: 0.4899 - accuracy: 0.8074 - val_loss: 0.4620 - val_accuracy: 0.8221\n",
      "Epoch 138/1000\n",
      "225/225 [==============================] - 1s 2ms/step - loss: 0.4905 - accuracy: 0.8077 - val_loss: 0.4624 - val_accuracy: 0.8236\n",
      "Epoch 139/1000\n",
      "225/225 [==============================] - 1s 2ms/step - loss: 0.4901 - accuracy: 0.8069 - val_loss: 0.4650 - val_accuracy: 0.8217\n",
      "Epoch 140/1000\n",
      "225/225 [==============================] - 1s 2ms/step - loss: 0.4888 - accuracy: 0.8066 - val_loss: 0.4656 - val_accuracy: 0.8236\n",
      "Epoch 141/1000\n",
      "225/225 [==============================] - 1s 2ms/step - loss: 0.4892 - accuracy: 0.8068 - val_loss: 0.4636 - val_accuracy: 0.8239\n",
      "Epoch 142/1000\n",
      "225/225 [==============================] - 1s 2ms/step - loss: 0.4895 - accuracy: 0.8065 - val_loss: 0.4621 - val_accuracy: 0.8229\n",
      "Epoch 143/1000\n",
      "225/225 [==============================] - 1s 3ms/step - loss: 0.4870 - accuracy: 0.8084 - val_loss: 0.4592 - val_accuracy: 0.8234\n",
      "Epoch 144/1000\n",
      "225/225 [==============================] - 1s 2ms/step - loss: 0.4883 - accuracy: 0.8060 - val_loss: 0.4642 - val_accuracy: 0.8248\n",
      "Epoch 145/1000\n",
      "225/225 [==============================] - 1s 2ms/step - loss: 0.4853 - accuracy: 0.8076 - val_loss: 0.4598 - val_accuracy: 0.8275\n",
      "Epoch 146/1000\n",
      "225/225 [==============================] - 1s 2ms/step - loss: 0.4883 - accuracy: 0.8080 - val_loss: 0.4628 - val_accuracy: 0.8231\n",
      "Epoch 147/1000\n",
      "225/225 [==============================] - 1s 3ms/step - loss: 0.4880 - accuracy: 0.8073 - val_loss: 0.4603 - val_accuracy: 0.8220\n",
      "Epoch 148/1000\n",
      "225/225 [==============================] - 1s 2ms/step - loss: 0.4892 - accuracy: 0.8075 - val_loss: 0.4615 - val_accuracy: 0.8247\n",
      "Epoch 149/1000\n",
      "225/225 [==============================] - 1s 2ms/step - loss: 0.4854 - accuracy: 0.8090 - val_loss: 0.4585 - val_accuracy: 0.8252\n",
      "Epoch 150/1000\n",
      "225/225 [==============================] - 1s 2ms/step - loss: 0.4862 - accuracy: 0.8071 - val_loss: 0.4599 - val_accuracy: 0.8281\n",
      "Epoch 151/1000\n",
      "225/225 [==============================] - 1s 2ms/step - loss: 0.4845 - accuracy: 0.8086 - val_loss: 0.4571 - val_accuracy: 0.8257\n",
      "Epoch 152/1000\n",
      "225/225 [==============================] - 1s 2ms/step - loss: 0.4863 - accuracy: 0.8080 - val_loss: 0.4600 - val_accuracy: 0.8260\n",
      "Epoch 153/1000\n",
      "225/225 [==============================] - 1s 3ms/step - loss: 0.4871 - accuracy: 0.8086 - val_loss: 0.4582 - val_accuracy: 0.8261\n",
      "Epoch 154/1000\n",
      "225/225 [==============================] - 1s 3ms/step - loss: 0.4870 - accuracy: 0.8080 - val_loss: 0.4611 - val_accuracy: 0.8254\n",
      "Epoch 155/1000\n",
      "225/225 [==============================] - 1s 3ms/step - loss: 0.4851 - accuracy: 0.8077 - val_loss: 0.4574 - val_accuracy: 0.8270\n",
      "Epoch 156/1000\n",
      "225/225 [==============================] - 1s 3ms/step - loss: 0.4840 - accuracy: 0.8087 - val_loss: 0.4598 - val_accuracy: 0.8267\n",
      "Epoch 157/1000\n",
      "225/225 [==============================] - 1s 3ms/step - loss: 0.4872 - accuracy: 0.8071 - val_loss: 0.4628 - val_accuracy: 0.8224\n",
      "Epoch 158/1000\n",
      "225/225 [==============================] - 1s 3ms/step - loss: 0.4858 - accuracy: 0.8082 - val_loss: 0.4600 - val_accuracy: 0.8222\n",
      "Epoch 159/1000\n",
      "225/225 [==============================] - 1s 2ms/step - loss: 0.4832 - accuracy: 0.8095 - val_loss: 0.4581 - val_accuracy: 0.8266\n",
      "Epoch 160/1000\n",
      "225/225 [==============================] - 1s 3ms/step - loss: 0.4838 - accuracy: 0.8086 - val_loss: 0.4603 - val_accuracy: 0.8250\n",
      "Epoch 161/1000\n",
      "225/225 [==============================] - 1s 3ms/step - loss: 0.4847 - accuracy: 0.8101 - val_loss: 0.4569 - val_accuracy: 0.8265\n",
      "Epoch 162/1000\n",
      "225/225 [==============================] - 1s 3ms/step - loss: 0.4826 - accuracy: 0.8095 - val_loss: 0.4598 - val_accuracy: 0.8248\n",
      "Epoch 163/1000\n",
      "225/225 [==============================] - 1s 3ms/step - loss: 0.4866 - accuracy: 0.8077 - val_loss: 0.4556 - val_accuracy: 0.8254\n",
      "Epoch 164/1000\n",
      "225/225 [==============================] - 1s 2ms/step - loss: 0.4818 - accuracy: 0.8091 - val_loss: 0.4537 - val_accuracy: 0.8280\n",
      "Epoch 165/1000\n",
      "225/225 [==============================] - 1s 2ms/step - loss: 0.4841 - accuracy: 0.8101 - val_loss: 0.4535 - val_accuracy: 0.8282\n",
      "Epoch 166/1000\n",
      "225/225 [==============================] - 1s 3ms/step - loss: 0.4828 - accuracy: 0.8106 - val_loss: 0.4544 - val_accuracy: 0.8265\n",
      "Epoch 167/1000\n",
      "225/225 [==============================] - 1s 3ms/step - loss: 0.4822 - accuracy: 0.8097 - val_loss: 0.4572 - val_accuracy: 0.8271\n",
      "Epoch 168/1000\n",
      "225/225 [==============================] - 1s 2ms/step - loss: 0.4812 - accuracy: 0.8103 - val_loss: 0.4539 - val_accuracy: 0.8268\n",
      "Epoch 169/1000\n",
      "225/225 [==============================] - 1s 2ms/step - loss: 0.4834 - accuracy: 0.8082 - val_loss: 0.4527 - val_accuracy: 0.8246\n",
      "Epoch 170/1000\n",
      "225/225 [==============================] - 1s 2ms/step - loss: 0.4808 - accuracy: 0.8108 - val_loss: 0.4537 - val_accuracy: 0.8253\n",
      "Epoch 171/1000\n",
      "225/225 [==============================] - 1s 3ms/step - loss: 0.4821 - accuracy: 0.8103 - val_loss: 0.4567 - val_accuracy: 0.8238\n",
      "Epoch 172/1000\n",
      "225/225 [==============================] - 1s 3ms/step - loss: 0.4828 - accuracy: 0.8095 - val_loss: 0.4529 - val_accuracy: 0.8277\n",
      "Epoch 173/1000\n",
      "225/225 [==============================] - 1s 2ms/step - loss: 0.4828 - accuracy: 0.8094 - val_loss: 0.4542 - val_accuracy: 0.8275\n",
      "Epoch 174/1000\n",
      "225/225 [==============================] - 1s 2ms/step - loss: 0.4801 - accuracy: 0.8106 - val_loss: 0.4559 - val_accuracy: 0.8288\n",
      "Epoch 175/1000\n",
      "225/225 [==============================] - 1s 2ms/step - loss: 0.4812 - accuracy: 0.8101 - val_loss: 0.4558 - val_accuracy: 0.8263\n",
      "Epoch 176/1000\n",
      "225/225 [==============================] - 1s 2ms/step - loss: 0.4799 - accuracy: 0.8115 - val_loss: 0.4514 - val_accuracy: 0.8286\n",
      "Epoch 177/1000\n",
      "225/225 [==============================] - 1s 2ms/step - loss: 0.4799 - accuracy: 0.8111 - val_loss: 0.4518 - val_accuracy: 0.8287\n",
      "Epoch 178/1000\n",
      "225/225 [==============================] - 1s 3ms/step - loss: 0.4815 - accuracy: 0.8119 - val_loss: 0.4557 - val_accuracy: 0.8264\n",
      "Epoch 179/1000\n",
      "225/225 [==============================] - 1s 2ms/step - loss: 0.4813 - accuracy: 0.8103 - val_loss: 0.4539 - val_accuracy: 0.8275\n",
      "Epoch 180/1000\n",
      "225/225 [==============================] - 1s 3ms/step - loss: 0.4806 - accuracy: 0.8115 - val_loss: 0.4536 - val_accuracy: 0.8275\n",
      "Epoch 181/1000\n",
      "225/225 [==============================] - 1s 2ms/step - loss: 0.4799 - accuracy: 0.8105 - val_loss: 0.4504 - val_accuracy: 0.8268\n",
      "Epoch 182/1000\n",
      "225/225 [==============================] - 1s 2ms/step - loss: 0.4795 - accuracy: 0.8117 - val_loss: 0.4508 - val_accuracy: 0.8282\n",
      "Epoch 183/1000\n",
      "225/225 [==============================] - 1s 2ms/step - loss: 0.4799 - accuracy: 0.8099 - val_loss: 0.4540 - val_accuracy: 0.8271\n",
      "Epoch 184/1000\n",
      "225/225 [==============================] - 1s 2ms/step - loss: 0.4790 - accuracy: 0.8120 - val_loss: 0.4514 - val_accuracy: 0.8274\n",
      "Epoch 185/1000\n",
      "225/225 [==============================] - 1s 2ms/step - loss: 0.4807 - accuracy: 0.8099 - val_loss: 0.4498 - val_accuracy: 0.8275\n",
      "Epoch 186/1000\n",
      "225/225 [==============================] - 1s 2ms/step - loss: 0.4811 - accuracy: 0.8097 - val_loss: 0.4562 - val_accuracy: 0.8269\n",
      "Epoch 187/1000\n",
      "225/225 [==============================] - 1s 2ms/step - loss: 0.4785 - accuracy: 0.8107 - val_loss: 0.4518 - val_accuracy: 0.8296\n",
      "Epoch 188/1000\n",
      "225/225 [==============================] - 1s 2ms/step - loss: 0.4801 - accuracy: 0.8100 - val_loss: 0.4540 - val_accuracy: 0.8257\n",
      "Epoch 189/1000\n",
      "225/225 [==============================] - 1s 2ms/step - loss: 0.4774 - accuracy: 0.8118 - val_loss: 0.4499 - val_accuracy: 0.8290\n",
      "Epoch 190/1000\n",
      "225/225 [==============================] - 1s 3ms/step - loss: 0.4769 - accuracy: 0.8122 - val_loss: 0.4487 - val_accuracy: 0.8290\n",
      "Epoch 191/1000\n",
      "225/225 [==============================] - 1s 3ms/step - loss: 0.4791 - accuracy: 0.8111 - val_loss: 0.4494 - val_accuracy: 0.8296\n",
      "Epoch 192/1000\n",
      "225/225 [==============================] - 1s 3ms/step - loss: 0.4773 - accuracy: 0.8121 - val_loss: 0.4481 - val_accuracy: 0.8298\n",
      "Epoch 193/1000\n",
      "225/225 [==============================] - 1s 2ms/step - loss: 0.4763 - accuracy: 0.8119 - val_loss: 0.4481 - val_accuracy: 0.8303\n",
      "Epoch 194/1000\n",
      "225/225 [==============================] - 1s 2ms/step - loss: 0.4761 - accuracy: 0.8131 - val_loss: 0.4503 - val_accuracy: 0.8271\n",
      "Epoch 195/1000\n",
      "225/225 [==============================] - 1s 2ms/step - loss: 0.4783 - accuracy: 0.8112 - val_loss: 0.4520 - val_accuracy: 0.8304\n",
      "Epoch 196/1000\n",
      "225/225 [==============================] - 1s 3ms/step - loss: 0.4771 - accuracy: 0.8119 - val_loss: 0.4506 - val_accuracy: 0.8289\n",
      "Epoch 197/1000\n",
      "225/225 [==============================] - 1s 2ms/step - loss: 0.4771 - accuracy: 0.8117 - val_loss: 0.4524 - val_accuracy: 0.8263\n",
      "Epoch 198/1000\n",
      "225/225 [==============================] - 1s 2ms/step - loss: 0.4773 - accuracy: 0.8121 - val_loss: 0.4480 - val_accuracy: 0.8300\n",
      "Epoch 199/1000\n",
      "225/225 [==============================] - 1s 2ms/step - loss: 0.4742 - accuracy: 0.8131 - val_loss: 0.4484 - val_accuracy: 0.8307\n",
      "Epoch 200/1000\n",
      "225/225 [==============================] - 1s 2ms/step - loss: 0.4750 - accuracy: 0.8128 - val_loss: 0.4502 - val_accuracy: 0.8321\n",
      "Epoch 201/1000\n",
      "225/225 [==============================] - 1s 3ms/step - loss: 0.4767 - accuracy: 0.8123 - val_loss: 0.4513 - val_accuracy: 0.8304\n",
      "Epoch 202/1000\n",
      "225/225 [==============================] - 1s 2ms/step - loss: 0.4760 - accuracy: 0.8136 - val_loss: 0.4476 - val_accuracy: 0.8310\n",
      "Epoch 203/1000\n",
      "225/225 [==============================] - 1s 2ms/step - loss: 0.4773 - accuracy: 0.8121 - val_loss: 0.4458 - val_accuracy: 0.8345\n",
      "Epoch 204/1000\n",
      "225/225 [==============================] - 1s 2ms/step - loss: 0.4772 - accuracy: 0.8124 - val_loss: 0.4460 - val_accuracy: 0.8345\n",
      "Epoch 205/1000\n",
      "225/225 [==============================] - 1s 3ms/step - loss: 0.4752 - accuracy: 0.8131 - val_loss: 0.4479 - val_accuracy: 0.8305\n",
      "Epoch 206/1000\n",
      "225/225 [==============================] - 1s 2ms/step - loss: 0.4757 - accuracy: 0.8126 - val_loss: 0.4478 - val_accuracy: 0.8329\n",
      "Epoch 207/1000\n",
      "225/225 [==============================] - 1s 2ms/step - loss: 0.4756 - accuracy: 0.8130 - val_loss: 0.4475 - val_accuracy: 0.8296\n",
      "Epoch 208/1000\n",
      "225/225 [==============================] - 1s 2ms/step - loss: 0.4757 - accuracy: 0.8133 - val_loss: 0.4456 - val_accuracy: 0.8311\n",
      "Epoch 209/1000\n",
      "225/225 [==============================] - 1s 2ms/step - loss: 0.4756 - accuracy: 0.8126 - val_loss: 0.4457 - val_accuracy: 0.8315\n",
      "Epoch 210/1000\n",
      "225/225 [==============================] - 1s 3ms/step - loss: 0.4757 - accuracy: 0.8128 - val_loss: 0.4469 - val_accuracy: 0.8310\n",
      "Epoch 211/1000\n",
      "225/225 [==============================] - 1s 2ms/step - loss: 0.4761 - accuracy: 0.8139 - val_loss: 0.4468 - val_accuracy: 0.8298\n",
      "Epoch 212/1000\n",
      "225/225 [==============================] - 1s 2ms/step - loss: 0.4729 - accuracy: 0.8139 - val_loss: 0.4437 - val_accuracy: 0.8300\n",
      "Epoch 213/1000\n",
      "225/225 [==============================] - 1s 2ms/step - loss: 0.4742 - accuracy: 0.8131 - val_loss: 0.4493 - val_accuracy: 0.8306\n",
      "Epoch 214/1000\n",
      "225/225 [==============================] - 1s 3ms/step - loss: 0.4743 - accuracy: 0.8136 - val_loss: 0.4476 - val_accuracy: 0.8311\n",
      "Epoch 215/1000\n",
      "225/225 [==============================] - 1s 2ms/step - loss: 0.4731 - accuracy: 0.8131 - val_loss: 0.4455 - val_accuracy: 0.8319\n",
      "Epoch 216/1000\n",
      "225/225 [==============================] - 1s 2ms/step - loss: 0.4730 - accuracy: 0.8137 - val_loss: 0.4431 - val_accuracy: 0.8299\n",
      "Epoch 217/1000\n",
      "225/225 [==============================] - 1s 2ms/step - loss: 0.4719 - accuracy: 0.8148 - val_loss: 0.4452 - val_accuracy: 0.8356\n",
      "Epoch 218/1000\n",
      "225/225 [==============================] - 1s 3ms/step - loss: 0.4730 - accuracy: 0.8132 - val_loss: 0.4471 - val_accuracy: 0.8333\n",
      "Epoch 219/1000\n",
      "225/225 [==============================] - 1s 2ms/step - loss: 0.4734 - accuracy: 0.8134 - val_loss: 0.4464 - val_accuracy: 0.8329\n",
      "Epoch 220/1000\n",
      "225/225 [==============================] - 1s 2ms/step - loss: 0.4733 - accuracy: 0.8136 - val_loss: 0.4442 - val_accuracy: 0.8332\n",
      "Epoch 221/1000\n",
      "225/225 [==============================] - 1s 2ms/step - loss: 0.4721 - accuracy: 0.8147 - val_loss: 0.4446 - val_accuracy: 0.8330\n",
      "Epoch 222/1000\n",
      "225/225 [==============================] - 1s 2ms/step - loss: 0.4724 - accuracy: 0.8138 - val_loss: 0.4439 - val_accuracy: 0.8329\n",
      "Epoch 223/1000\n",
      "225/225 [==============================] - 1s 2ms/step - loss: 0.4732 - accuracy: 0.8141 - val_loss: 0.4472 - val_accuracy: 0.8323\n",
      "Epoch 224/1000\n",
      "225/225 [==============================] - 1s 2ms/step - loss: 0.4728 - accuracy: 0.8132 - val_loss: 0.4452 - val_accuracy: 0.8329\n",
      "Epoch 225/1000\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "225/225 [==============================] - 1s 2ms/step - loss: 0.4718 - accuracy: 0.8141 - val_loss: 0.4446 - val_accuracy: 0.8324\n",
      "Epoch 226/1000\n",
      "225/225 [==============================] - 1s 3ms/step - loss: 0.4714 - accuracy: 0.8144 - val_loss: 0.4474 - val_accuracy: 0.8304\n",
      "Epoch 227/1000\n",
      "225/225 [==============================] - 1s 2ms/step - loss: 0.4707 - accuracy: 0.8151 - val_loss: 0.4460 - val_accuracy: 0.8329\n",
      "Epoch 228/1000\n",
      "225/225 [==============================] - 1s 2ms/step - loss: 0.4716 - accuracy: 0.8134 - val_loss: 0.4424 - val_accuracy: 0.8335\n",
      "Epoch 229/1000\n",
      "225/225 [==============================] - 1s 3ms/step - loss: 0.4720 - accuracy: 0.8145 - val_loss: 0.4448 - val_accuracy: 0.8305\n",
      "Epoch 230/1000\n",
      "225/225 [==============================] - 1s 3ms/step - loss: 0.4730 - accuracy: 0.8143 - val_loss: 0.4466 - val_accuracy: 0.8331\n",
      "Epoch 231/1000\n",
      "225/225 [==============================] - 1s 2ms/step - loss: 0.4732 - accuracy: 0.8145 - val_loss: 0.4417 - val_accuracy: 0.8347\n",
      "Epoch 232/1000\n",
      "225/225 [==============================] - 1s 2ms/step - loss: 0.4709 - accuracy: 0.8159 - val_loss: 0.4464 - val_accuracy: 0.8306\n",
      "Epoch 233/1000\n",
      "225/225 [==============================] - 1s 2ms/step - loss: 0.4696 - accuracy: 0.8159 - val_loss: 0.4481 - val_accuracy: 0.8307\n",
      "Epoch 234/1000\n",
      "225/225 [==============================] - 1s 2ms/step - loss: 0.4713 - accuracy: 0.8139 - val_loss: 0.4471 - val_accuracy: 0.8328\n",
      "Epoch 235/1000\n",
      "225/225 [==============================] - 1s 2ms/step - loss: 0.4693 - accuracy: 0.8155 - val_loss: 0.4430 - val_accuracy: 0.8365\n",
      "Epoch 236/1000\n",
      "225/225 [==============================] - 1s 2ms/step - loss: 0.4703 - accuracy: 0.8153 - val_loss: 0.4409 - val_accuracy: 0.8367\n",
      "Epoch 237/1000\n",
      "225/225 [==============================] - 1s 2ms/step - loss: 0.4689 - accuracy: 0.8156 - val_loss: 0.4409 - val_accuracy: 0.8322\n",
      "Epoch 238/1000\n",
      "225/225 [==============================] - 1s 2ms/step - loss: 0.4699 - accuracy: 0.8146 - val_loss: 0.4415 - val_accuracy: 0.8353\n",
      "Epoch 239/1000\n",
      "225/225 [==============================] - 1s 2ms/step - loss: 0.4703 - accuracy: 0.8151 - val_loss: 0.4415 - val_accuracy: 0.8364\n",
      "Epoch 240/1000\n",
      "225/225 [==============================] - 1s 2ms/step - loss: 0.4701 - accuracy: 0.8156 - val_loss: 0.4407 - val_accuracy: 0.8351\n",
      "Epoch 241/1000\n",
      "225/225 [==============================] - 1s 2ms/step - loss: 0.4720 - accuracy: 0.8133 - val_loss: 0.4420 - val_accuracy: 0.8315\n",
      "Epoch 242/1000\n",
      "225/225 [==============================] - 1s 2ms/step - loss: 0.4696 - accuracy: 0.8159 - val_loss: 0.4456 - val_accuracy: 0.8358\n",
      "Epoch 243/1000\n",
      "225/225 [==============================] - 1s 2ms/step - loss: 0.4682 - accuracy: 0.8169 - val_loss: 0.4420 - val_accuracy: 0.8353\n",
      "Epoch 244/1000\n",
      "225/225 [==============================] - 1s 2ms/step - loss: 0.4709 - accuracy: 0.8143 - val_loss: 0.4427 - val_accuracy: 0.8358\n",
      "Epoch 245/1000\n",
      "225/225 [==============================] - 1s 2ms/step - loss: 0.4688 - accuracy: 0.8158 - val_loss: 0.4408 - val_accuracy: 0.8358\n",
      "Epoch 246/1000\n",
      "225/225 [==============================] - 1s 2ms/step - loss: 0.4683 - accuracy: 0.8162 - val_loss: 0.4420 - val_accuracy: 0.8337\n",
      "Epoch 247/1000\n",
      "225/225 [==============================] - 1s 3ms/step - loss: 0.4681 - accuracy: 0.8155 - val_loss: 0.4436 - val_accuracy: 0.8311\n",
      "Epoch 248/1000\n",
      "225/225 [==============================] - 1s 2ms/step - loss: 0.4684 - accuracy: 0.8152 - val_loss: 0.4414 - val_accuracy: 0.8336\n",
      "Epoch 249/1000\n",
      "225/225 [==============================] - 1s 2ms/step - loss: 0.4687 - accuracy: 0.8154 - val_loss: 0.4441 - val_accuracy: 0.8309\n",
      "Epoch 250/1000\n",
      "225/225 [==============================] - 1s 2ms/step - loss: 0.4698 - accuracy: 0.8159 - val_loss: 0.4428 - val_accuracy: 0.8322\n",
      "Epoch 251/1000\n",
      "225/225 [==============================] - 1s 2ms/step - loss: 0.4703 - accuracy: 0.8150 - val_loss: 0.4467 - val_accuracy: 0.8314\n",
      "Epoch 252/1000\n",
      "225/225 [==============================] - 1s 2ms/step - loss: 0.4697 - accuracy: 0.8151 - val_loss: 0.4426 - val_accuracy: 0.8331\n",
      "Epoch 253/1000\n",
      "225/225 [==============================] - 1s 2ms/step - loss: 0.4685 - accuracy: 0.8153 - val_loss: 0.4468 - val_accuracy: 0.8338\n",
      "Epoch 254/1000\n",
      "225/225 [==============================] - 1s 2ms/step - loss: 0.4668 - accuracy: 0.8164 - val_loss: 0.4439 - val_accuracy: 0.8351\n",
      "Epoch 255/1000\n",
      "225/225 [==============================] - 1s 3ms/step - loss: 0.4688 - accuracy: 0.8163 - val_loss: 0.4426 - val_accuracy: 0.8372\n",
      "Epoch 256/1000\n",
      "225/225 [==============================] - 1s 2ms/step - loss: 0.4682 - accuracy: 0.8155 - val_loss: 0.4438 - val_accuracy: 0.8330\n",
      "Epoch 257/1000\n",
      "225/225 [==============================] - 1s 3ms/step - loss: 0.4693 - accuracy: 0.8157 - val_loss: 0.4414 - val_accuracy: 0.8336\n",
      "Epoch 258/1000\n",
      "225/225 [==============================] - 1s 3ms/step - loss: 0.4703 - accuracy: 0.8149 - val_loss: 0.4426 - val_accuracy: 0.8333\n",
      "Epoch 259/1000\n",
      "225/225 [==============================] - 1s 2ms/step - loss: 0.4688 - accuracy: 0.8155 - val_loss: 0.4398 - val_accuracy: 0.8337\n",
      "Epoch 260/1000\n",
      "225/225 [==============================] - 1s 2ms/step - loss: 0.4653 - accuracy: 0.8177 - val_loss: 0.4394 - val_accuracy: 0.8329\n",
      "Epoch 261/1000\n",
      "225/225 [==============================] - 1s 2ms/step - loss: 0.4674 - accuracy: 0.8172 - val_loss: 0.4426 - val_accuracy: 0.8355\n",
      "Epoch 262/1000\n",
      "225/225 [==============================] - 1s 2ms/step - loss: 0.4664 - accuracy: 0.8164 - val_loss: 0.4448 - val_accuracy: 0.8318\n",
      "Epoch 263/1000\n",
      "225/225 [==============================] - 1s 2ms/step - loss: 0.4658 - accuracy: 0.8175 - val_loss: 0.4398 - val_accuracy: 0.8354\n",
      "Epoch 264/1000\n",
      "225/225 [==============================] - 1s 2ms/step - loss: 0.4667 - accuracy: 0.8172 - val_loss: 0.4410 - val_accuracy: 0.8332\n",
      "Epoch 265/1000\n",
      "225/225 [==============================] - 1s 2ms/step - loss: 0.4678 - accuracy: 0.8160 - val_loss: 0.4436 - val_accuracy: 0.8320\n",
      "Epoch 266/1000\n",
      "225/225 [==============================] - 1s 2ms/step - loss: 0.4677 - accuracy: 0.8162 - val_loss: 0.4412 - val_accuracy: 0.8330\n",
      "Epoch 267/1000\n",
      "225/225 [==============================] - 1s 2ms/step - loss: 0.4672 - accuracy: 0.8163 - val_loss: 0.4392 - val_accuracy: 0.8327\n",
      "Epoch 268/1000\n",
      "225/225 [==============================] - 1s 3ms/step - loss: 0.4655 - accuracy: 0.8167 - val_loss: 0.4401 - val_accuracy: 0.8340\n",
      "Epoch 269/1000\n",
      "225/225 [==============================] - 1s 2ms/step - loss: 0.4678 - accuracy: 0.8176 - val_loss: 0.4408 - val_accuracy: 0.8327\n",
      "Epoch 270/1000\n",
      "225/225 [==============================] - 1s 2ms/step - loss: 0.4654 - accuracy: 0.8169 - val_loss: 0.4410 - val_accuracy: 0.8356\n",
      "Epoch 271/1000\n",
      "225/225 [==============================] - 1s 2ms/step - loss: 0.4664 - accuracy: 0.8169 - val_loss: 0.4392 - val_accuracy: 0.8335\n",
      "Epoch 272/1000\n",
      "225/225 [==============================] - 1s 2ms/step - loss: 0.4659 - accuracy: 0.8171 - val_loss: 0.4371 - val_accuracy: 0.8346\n",
      "Epoch 273/1000\n",
      "225/225 [==============================] - 1s 3ms/step - loss: 0.4650 - accuracy: 0.8182 - val_loss: 0.4389 - val_accuracy: 0.8354\n",
      "Epoch 274/1000\n",
      "225/225 [==============================] - 1s 2ms/step - loss: 0.4668 - accuracy: 0.8174 - val_loss: 0.4426 - val_accuracy: 0.8365\n",
      "Epoch 275/1000\n",
      "225/225 [==============================] - 1s 2ms/step - loss: 0.4665 - accuracy: 0.8171 - val_loss: 0.4384 - val_accuracy: 0.8363\n",
      "Epoch 276/1000\n",
      "225/225 [==============================] - 1s 2ms/step - loss: 0.4662 - accuracy: 0.8170 - val_loss: 0.4401 - val_accuracy: 0.8340\n",
      "Epoch 277/1000\n",
      "225/225 [==============================] - 1s 2ms/step - loss: 0.4681 - accuracy: 0.8160 - val_loss: 0.4380 - val_accuracy: 0.8369\n",
      "Epoch 278/1000\n",
      "225/225 [==============================] - 1s 2ms/step - loss: 0.4652 - accuracy: 0.8180 - val_loss: 0.4414 - val_accuracy: 0.8375\n",
      "Epoch 279/1000\n",
      "225/225 [==============================] - 1s 2ms/step - loss: 0.4660 - accuracy: 0.8176 - val_loss: 0.4396 - val_accuracy: 0.8366\n",
      "Epoch 280/1000\n",
      "225/225 [==============================] - 1s 2ms/step - loss: 0.4652 - accuracy: 0.8170 - val_loss: 0.4408 - val_accuracy: 0.8374\n",
      "Epoch 281/1000\n",
      "225/225 [==============================] - 1s 2ms/step - loss: 0.4654 - accuracy: 0.8174 - val_loss: 0.4423 - val_accuracy: 0.8340\n",
      "Epoch 282/1000\n",
      "225/225 [==============================] - 1s 2ms/step - loss: 0.4655 - accuracy: 0.8175 - val_loss: 0.4374 - val_accuracy: 0.8384\n",
      "Epoch 283/1000\n",
      "225/225 [==============================] - 1s 3ms/step - loss: 0.4641 - accuracy: 0.8175 - val_loss: 0.4344 - val_accuracy: 0.8395\n",
      "Epoch 284/1000\n",
      "225/225 [==============================] - 1s 2ms/step - loss: 0.4664 - accuracy: 0.8171 - val_loss: 0.4373 - val_accuracy: 0.8344\n",
      "Epoch 285/1000\n",
      "225/225 [==============================] - 1s 2ms/step - loss: 0.4641 - accuracy: 0.8181 - val_loss: 0.4360 - val_accuracy: 0.8382\n",
      "Epoch 286/1000\n",
      "225/225 [==============================] - 1s 2ms/step - loss: 0.4637 - accuracy: 0.8183 - val_loss: 0.4365 - val_accuracy: 0.8368\n",
      "Epoch 287/1000\n",
      "225/225 [==============================] - 1s 3ms/step - loss: 0.4634 - accuracy: 0.8176 - val_loss: 0.4367 - val_accuracy: 0.8409\n",
      "Epoch 288/1000\n",
      "225/225 [==============================] - 1s 2ms/step - loss: 0.4632 - accuracy: 0.8179 - val_loss: 0.4379 - val_accuracy: 0.8349\n",
      "Epoch 289/1000\n",
      "225/225 [==============================] - 1s 2ms/step - loss: 0.4656 - accuracy: 0.8170 - val_loss: 0.4379 - val_accuracy: 0.8354\n",
      "Epoch 290/1000\n",
      "225/225 [==============================] - 1s 3ms/step - loss: 0.4672 - accuracy: 0.8158 - val_loss: 0.4390 - val_accuracy: 0.8375\n",
      "Epoch 291/1000\n",
      "225/225 [==============================] - 1s 2ms/step - loss: 0.4624 - accuracy: 0.8183 - val_loss: 0.4375 - val_accuracy: 0.8362\n",
      "Epoch 292/1000\n",
      "225/225 [==============================] - 1s 2ms/step - loss: 0.4647 - accuracy: 0.8176 - val_loss: 0.4405 - val_accuracy: 0.8339\n",
      "Epoch 293/1000\n",
      "225/225 [==============================] - 1s 2ms/step - loss: 0.4645 - accuracy: 0.8180 - val_loss: 0.4405 - val_accuracy: 0.8349\n",
      "Epoch 294/1000\n",
      "225/225 [==============================] - 1s 2ms/step - loss: 0.4649 - accuracy: 0.8167 - val_loss: 0.4356 - val_accuracy: 0.8369\n",
      "Epoch 295/1000\n",
      "225/225 [==============================] - 1s 2ms/step - loss: 0.4645 - accuracy: 0.8183 - val_loss: 0.4377 - val_accuracy: 0.8339\n",
      "Epoch 296/1000\n",
      "225/225 [==============================] - 1s 2ms/step - loss: 0.4621 - accuracy: 0.8181 - val_loss: 0.4376 - val_accuracy: 0.8354\n",
      "Epoch 297/1000\n",
      "225/225 [==============================] - 1s 2ms/step - loss: 0.4674 - accuracy: 0.8166 - val_loss: 0.4399 - val_accuracy: 0.8340\n",
      "Epoch 298/1000\n",
      "225/225 [==============================] - 1s 2ms/step - loss: 0.4631 - accuracy: 0.8176 - val_loss: 0.4398 - val_accuracy: 0.8342\n",
      "Epoch 299/1000\n",
      "225/225 [==============================] - 1s 2ms/step - loss: 0.4633 - accuracy: 0.8185 - val_loss: 0.4386 - val_accuracy: 0.8354\n",
      "Epoch 300/1000\n",
      "225/225 [==============================] - 1s 2ms/step - loss: 0.4646 - accuracy: 0.8180 - val_loss: 0.4383 - val_accuracy: 0.8396\n",
      "Epoch 301/1000\n",
      "225/225 [==============================] - 1s 2ms/step - loss: 0.4640 - accuracy: 0.8183 - val_loss: 0.4382 - val_accuracy: 0.8387\n",
      "Epoch 302/1000\n",
      "225/225 [==============================] - 1s 2ms/step - loss: 0.4631 - accuracy: 0.8194 - val_loss: 0.4377 - val_accuracy: 0.8350\n",
      "Epoch 303/1000\n",
      "225/225 [==============================] - 1s 2ms/step - loss: 0.4624 - accuracy: 0.8189 - val_loss: 0.4347 - val_accuracy: 0.8377\n",
      "Epoch 304/1000\n",
      "225/225 [==============================] - 1s 2ms/step - loss: 0.4613 - accuracy: 0.8196 - val_loss: 0.4352 - val_accuracy: 0.8372\n",
      "Epoch 305/1000\n",
      "225/225 [==============================] - 1s 2ms/step - loss: 0.4629 - accuracy: 0.8175 - val_loss: 0.4360 - val_accuracy: 0.8374\n",
      "Epoch 306/1000\n",
      "225/225 [==============================] - 1s 3ms/step - loss: 0.4659 - accuracy: 0.8184 - val_loss: 0.4368 - val_accuracy: 0.8409\n",
      "Epoch 307/1000\n",
      "225/225 [==============================] - 1s 2ms/step - loss: 0.4622 - accuracy: 0.8206 - val_loss: 0.4352 - val_accuracy: 0.8367\n",
      "Epoch 308/1000\n",
      "225/225 [==============================] - 1s 2ms/step - loss: 0.4617 - accuracy: 0.8179 - val_loss: 0.4342 - val_accuracy: 0.8374\n",
      "Epoch 309/1000\n",
      "225/225 [==============================] - 1s 2ms/step - loss: 0.4629 - accuracy: 0.8188 - val_loss: 0.4356 - val_accuracy: 0.8380\n",
      "Epoch 310/1000\n",
      "225/225 [==============================] - 1s 2ms/step - loss: 0.4632 - accuracy: 0.8182 - val_loss: 0.4346 - val_accuracy: 0.8398\n",
      "Epoch 311/1000\n",
      "225/225 [==============================] - 1s 2ms/step - loss: 0.4611 - accuracy: 0.8191 - val_loss: 0.4344 - val_accuracy: 0.8369\n",
      "Epoch 312/1000\n",
      "225/225 [==============================] - 1s 2ms/step - loss: 0.4612 - accuracy: 0.8193 - val_loss: 0.4384 - val_accuracy: 0.8392\n",
      "Epoch 313/1000\n",
      "225/225 [==============================] - 1s 2ms/step - loss: 0.4612 - accuracy: 0.8196 - val_loss: 0.4376 - val_accuracy: 0.8362\n",
      "Epoch 314/1000\n",
      "225/225 [==============================] - 1s 3ms/step - loss: 0.4637 - accuracy: 0.8182 - val_loss: 0.4351 - val_accuracy: 0.8389\n",
      "Epoch 315/1000\n",
      "225/225 [==============================] - 1s 5ms/step - loss: 0.4627 - accuracy: 0.8181 - val_loss: 0.4387 - val_accuracy: 0.8358\n",
      "Epoch 316/1000\n",
      "225/225 [==============================] - 1s 3ms/step - loss: 0.4601 - accuracy: 0.8205 - val_loss: 0.4373 - val_accuracy: 0.8366\n",
      "Epoch 317/1000\n",
      "225/225 [==============================] - 1s 3ms/step - loss: 0.4613 - accuracy: 0.8187 - val_loss: 0.4354 - val_accuracy: 0.8355\n",
      "Epoch 318/1000\n",
      "225/225 [==============================] - 1s 2ms/step - loss: 0.4624 - accuracy: 0.8202 - val_loss: 0.4371 - val_accuracy: 0.8336\n",
      "Epoch 319/1000\n",
      "225/225 [==============================] - 1s 2ms/step - loss: 0.4640 - accuracy: 0.8192 - val_loss: 0.4384 - val_accuracy: 0.8362\n",
      "Epoch 320/1000\n",
      "225/225 [==============================] - 1s 2ms/step - loss: 0.4614 - accuracy: 0.8189 - val_loss: 0.4354 - val_accuracy: 0.8380\n",
      "Epoch 321/1000\n",
      "225/225 [==============================] - 1s 2ms/step - loss: 0.4592 - accuracy: 0.8203 - val_loss: 0.4346 - val_accuracy: 0.8365\n",
      "Epoch 322/1000\n",
      "225/225 [==============================] - 1s 2ms/step - loss: 0.4600 - accuracy: 0.8197 - val_loss: 0.4327 - val_accuracy: 0.8380\n",
      "Epoch 323/1000\n",
      "225/225 [==============================] - 1s 2ms/step - loss: 0.4627 - accuracy: 0.8206 - val_loss: 0.4328 - val_accuracy: 0.8391\n",
      "Epoch 324/1000\n",
      "225/225 [==============================] - 1s 2ms/step - loss: 0.4604 - accuracy: 0.8192 - val_loss: 0.4314 - val_accuracy: 0.8399\n",
      "Epoch 325/1000\n",
      "225/225 [==============================] - 1s 2ms/step - loss: 0.4610 - accuracy: 0.8201 - val_loss: 0.4346 - val_accuracy: 0.8365\n",
      "Epoch 326/1000\n",
      "225/225 [==============================] - 443s 2s/step - loss: 0.4622 - accuracy: 0.8189 - val_loss: 0.4352 - val_accuracy: 0.8369\n",
      "Epoch 327/1000\n",
      "225/225 [==============================] - 1s 3ms/step - loss: 0.4631 - accuracy: 0.8187 - val_loss: 0.4336 - val_accuracy: 0.8387\n",
      "Epoch 328/1000\n",
      "225/225 [==============================] - 1s 3ms/step - loss: 0.4613 - accuracy: 0.8191 - val_loss: 0.4331 - val_accuracy: 0.8399\n",
      "Epoch 329/1000\n",
      "225/225 [==============================] - 1s 6ms/step - loss: 0.4625 - accuracy: 0.8183 - val_loss: 0.4353 - val_accuracy: 0.8398\n",
      "Epoch 330/1000\n",
      "225/225 [==============================] - 1s 3ms/step - loss: 0.4597 - accuracy: 0.8200 - val_loss: 0.4343 - val_accuracy: 0.8384\n",
      "Epoch 331/1000\n",
      "225/225 [==============================] - 1s 2ms/step - loss: 0.4609 - accuracy: 0.8197 - val_loss: 0.4347 - val_accuracy: 0.8391\n",
      "Epoch 332/1000\n",
      "225/225 [==============================] - 1s 3ms/step - loss: 0.4607 - accuracy: 0.8197 - val_loss: 0.4350 - val_accuracy: 0.8379\n",
      "Epoch 333/1000\n",
      "225/225 [==============================] - 1s 4ms/step - loss: 0.4614 - accuracy: 0.8187 - val_loss: 0.4343 - val_accuracy: 0.8399\n",
      "Epoch 334/1000\n",
      "225/225 [==============================] - 1s 3ms/step - loss: 0.4591 - accuracy: 0.8200 - val_loss: 0.4363 - val_accuracy: 0.8381\n",
      "Epoch 335/1000\n",
      "225/225 [==============================] - 1s 3ms/step - loss: 0.4607 - accuracy: 0.8193 - val_loss: 0.4351 - val_accuracy: 0.8389\n",
      "Epoch 336/1000\n",
      "225/225 [==============================] - 1s 3ms/step - loss: 0.4601 - accuracy: 0.8202 - val_loss: 0.4354 - val_accuracy: 0.8386\n",
      "Epoch 337/1000\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "225/225 [==============================] - 1s 3ms/step - loss: 0.4586 - accuracy: 0.8203 - val_loss: 0.4348 - val_accuracy: 0.8393\n",
      "Epoch 338/1000\n",
      "225/225 [==============================] - 1s 2ms/step - loss: 0.4602 - accuracy: 0.8186 - val_loss: 0.4380 - val_accuracy: 0.8362\n",
      "Epoch 339/1000\n",
      "225/225 [==============================] - 1s 2ms/step - loss: 0.4600 - accuracy: 0.8204 - val_loss: 0.4340 - val_accuracy: 0.8387\n",
      "Epoch 340/1000\n",
      "225/225 [==============================] - 1s 3ms/step - loss: 0.4600 - accuracy: 0.8206 - val_loss: 0.4361 - val_accuracy: 0.8401\n",
      "Epoch 341/1000\n",
      "225/225 [==============================] - 1s 3ms/step - loss: 0.4598 - accuracy: 0.8197 - val_loss: 0.4369 - val_accuracy: 0.8393\n",
      "Epoch 342/1000\n",
      "225/225 [==============================] - 1s 3ms/step - loss: 0.4617 - accuracy: 0.8191 - val_loss: 0.4365 - val_accuracy: 0.8371\n",
      "Epoch 343/1000\n",
      "225/225 [==============================] - 1s 3ms/step - loss: 0.4603 - accuracy: 0.8195 - val_loss: 0.4347 - val_accuracy: 0.8361\n",
      "Epoch 344/1000\n",
      "225/225 [==============================] - 1s 3ms/step - loss: 0.4594 - accuracy: 0.8199 - val_loss: 0.4326 - val_accuracy: 0.8378\n",
      "Epoch 345/1000\n",
      "225/225 [==============================] - 1s 2ms/step - loss: 0.4580 - accuracy: 0.8214 - val_loss: 0.4319 - val_accuracy: 0.8358\n",
      "Epoch 346/1000\n",
      "225/225 [==============================] - 1s 3ms/step - loss: 0.4622 - accuracy: 0.8188 - val_loss: 0.4311 - val_accuracy: 0.8384\n",
      "Epoch 347/1000\n",
      "225/225 [==============================] - 1s 2ms/step - loss: 0.4618 - accuracy: 0.8184 - val_loss: 0.4308 - val_accuracy: 0.8396\n",
      "Epoch 348/1000\n",
      "225/225 [==============================] - 1s 2ms/step - loss: 0.4593 - accuracy: 0.8204 - val_loss: 0.4314 - val_accuracy: 0.8406\n",
      "Epoch 349/1000\n",
      "225/225 [==============================] - 1s 2ms/step - loss: 0.4591 - accuracy: 0.8213 - val_loss: 0.4350 - val_accuracy: 0.8385\n",
      "Epoch 350/1000\n",
      "225/225 [==============================] - 1s 2ms/step - loss: 0.4584 - accuracy: 0.8208 - val_loss: 0.4329 - val_accuracy: 0.8402\n",
      "Epoch 351/1000\n",
      "225/225 [==============================] - 1s 3ms/step - loss: 0.4600 - accuracy: 0.8204 - val_loss: 0.4386 - val_accuracy: 0.8367\n",
      "Epoch 352/1000\n",
      "225/225 [==============================] - 1s 3ms/step - loss: 0.4584 - accuracy: 0.8204 - val_loss: 0.4355 - val_accuracy: 0.8366\n",
      "Epoch 353/1000\n",
      "225/225 [==============================] - 1s 2ms/step - loss: 0.4593 - accuracy: 0.8203 - val_loss: 0.4320 - val_accuracy: 0.8369\n",
      "Epoch 354/1000\n",
      "225/225 [==============================] - 1s 3ms/step - loss: 0.4604 - accuracy: 0.8201 - val_loss: 0.4333 - val_accuracy: 0.8380\n",
      "Epoch 355/1000\n",
      "225/225 [==============================] - 1s 3ms/step - loss: 0.4586 - accuracy: 0.8196 - val_loss: 0.4306 - val_accuracy: 0.8375\n",
      "Epoch 356/1000\n",
      "225/225 [==============================] - 1s 2ms/step - loss: 0.4596 - accuracy: 0.8196 - val_loss: 0.4317 - val_accuracy: 0.8377\n",
      "Epoch 357/1000\n",
      "225/225 [==============================] - 1s 3ms/step - loss: 0.4613 - accuracy: 0.8176 - val_loss: 0.4300 - val_accuracy: 0.8394\n",
      "Epoch 358/1000\n",
      "225/225 [==============================] - 1s 2ms/step - loss: 0.4586 - accuracy: 0.8204 - val_loss: 0.4353 - val_accuracy: 0.8386\n",
      "Epoch 359/1000\n",
      "225/225 [==============================] - 1s 2ms/step - loss: 0.4579 - accuracy: 0.8195 - val_loss: 0.4332 - val_accuracy: 0.8391\n",
      "Epoch 360/1000\n",
      "225/225 [==============================] - 1s 3ms/step - loss: 0.4585 - accuracy: 0.8205 - val_loss: 0.4331 - val_accuracy: 0.8369\n",
      "Epoch 361/1000\n",
      "225/225 [==============================] - 1s 3ms/step - loss: 0.4587 - accuracy: 0.8201 - val_loss: 0.4330 - val_accuracy: 0.8385\n",
      "Epoch 362/1000\n",
      "225/225 [==============================] - 1s 2ms/step - loss: 0.4576 - accuracy: 0.8211 - val_loss: 0.4332 - val_accuracy: 0.8390\n",
      "Epoch 363/1000\n",
      "225/225 [==============================] - 1s 3ms/step - loss: 0.4594 - accuracy: 0.8195 - val_loss: 0.4314 - val_accuracy: 0.8369\n",
      "Epoch 364/1000\n",
      "225/225 [==============================] - 1s 3ms/step - loss: 0.4583 - accuracy: 0.8198 - val_loss: 0.4322 - val_accuracy: 0.8358\n",
      "Epoch 365/1000\n",
      "225/225 [==============================] - 1s 2ms/step - loss: 0.4550 - accuracy: 0.8228 - val_loss: 0.4316 - val_accuracy: 0.8404\n",
      "Epoch 366/1000\n",
      "225/225 [==============================] - 1s 3ms/step - loss: 0.4575 - accuracy: 0.8207 - val_loss: 0.4344 - val_accuracy: 0.8396\n",
      "Epoch 367/1000\n",
      "225/225 [==============================] - 1s 3ms/step - loss: 0.4562 - accuracy: 0.8218 - val_loss: 0.4342 - val_accuracy: 0.8408\n",
      "Epoch 368/1000\n",
      "225/225 [==============================] - 1s 3ms/step - loss: 0.4557 - accuracy: 0.8208 - val_loss: 0.4337 - val_accuracy: 0.8397\n",
      "Epoch 369/1000\n",
      "225/225 [==============================] - 1s 3ms/step - loss: 0.4578 - accuracy: 0.8202 - val_loss: 0.4303 - val_accuracy: 0.8380\n",
      "Epoch 370/1000\n",
      "225/225 [==============================] - 1s 3ms/step - loss: 0.4567 - accuracy: 0.8210 - val_loss: 0.4305 - val_accuracy: 0.8392\n",
      "Epoch 371/1000\n",
      "225/225 [==============================] - 1s 2ms/step - loss: 0.4579 - accuracy: 0.8213 - val_loss: 0.4364 - val_accuracy: 0.8379\n",
      "Epoch 372/1000\n",
      "225/225 [==============================] - 1s 3ms/step - loss: 0.4588 - accuracy: 0.8198 - val_loss: 0.4325 - val_accuracy: 0.8358\n",
      "Epoch 373/1000\n",
      "225/225 [==============================] - 1s 3ms/step - loss: 0.4587 - accuracy: 0.8206 - val_loss: 0.4343 - val_accuracy: 0.8373\n",
      "Epoch 374/1000\n",
      "225/225 [==============================] - 1s 2ms/step - loss: 0.4574 - accuracy: 0.8212 - val_loss: 0.4302 - val_accuracy: 0.8384\n",
      "Epoch 375/1000\n",
      "225/225 [==============================] - 1s 3ms/step - loss: 0.4568 - accuracy: 0.8203 - val_loss: 0.4314 - val_accuracy: 0.8375\n",
      "Epoch 376/1000\n",
      "225/225 [==============================] - 1s 3ms/step - loss: 0.4588 - accuracy: 0.8200 - val_loss: 0.4316 - val_accuracy: 0.8384\n",
      "Epoch 377/1000\n",
      "225/225 [==============================] - 1s 3ms/step - loss: 0.4561 - accuracy: 0.8225 - val_loss: 0.4358 - val_accuracy: 0.8350\n",
      "Epoch 378/1000\n",
      "225/225 [==============================] - 1s 3ms/step - loss: 0.4581 - accuracy: 0.8209 - val_loss: 0.4311 - val_accuracy: 0.8390\n",
      "Epoch 379/1000\n",
      "225/225 [==============================] - 1s 2ms/step - loss: 0.4568 - accuracy: 0.8211 - val_loss: 0.4309 - val_accuracy: 0.8368\n",
      "Epoch 380/1000\n",
      "225/225 [==============================] - 1s 2ms/step - loss: 0.4587 - accuracy: 0.8199 - val_loss: 0.4328 - val_accuracy: 0.8373\n",
      "Epoch 381/1000\n",
      "225/225 [==============================] - 1s 2ms/step - loss: 0.4594 - accuracy: 0.8202 - val_loss: 0.4344 - val_accuracy: 0.8376\n",
      "Epoch 382/1000\n",
      "225/225 [==============================] - 1s 2ms/step - loss: 0.4576 - accuracy: 0.8214 - val_loss: 0.4345 - val_accuracy: 0.8360\n",
      "Epoch 383/1000\n",
      "225/225 [==============================] - 1s 2ms/step - loss: 0.4565 - accuracy: 0.8204 - val_loss: 0.4308 - val_accuracy: 0.8379\n",
      "Epoch 384/1000\n",
      "225/225 [==============================] - 1s 2ms/step - loss: 0.4558 - accuracy: 0.8220 - val_loss: 0.4300 - val_accuracy: 0.8405\n",
      "Epoch 385/1000\n",
      "225/225 [==============================] - 1s 2ms/step - loss: 0.4557 - accuracy: 0.8213 - val_loss: 0.4329 - val_accuracy: 0.8376\n",
      "Epoch 386/1000\n",
      "225/225 [==============================] - 1s 2ms/step - loss: 0.4563 - accuracy: 0.8207 - val_loss: 0.4341 - val_accuracy: 0.8373\n",
      "Epoch 387/1000\n",
      "225/225 [==============================] - 1s 2ms/step - loss: 0.4563 - accuracy: 0.8215 - val_loss: 0.4296 - val_accuracy: 0.8388\n",
      "Epoch 388/1000\n",
      "225/225 [==============================] - 1s 3ms/step - loss: 0.4564 - accuracy: 0.8214 - val_loss: 0.4320 - val_accuracy: 0.8384\n",
      "Epoch 389/1000\n",
      "225/225 [==============================] - 1s 3ms/step - loss: 0.4565 - accuracy: 0.8221 - val_loss: 0.4290 - val_accuracy: 0.8387\n",
      "Epoch 390/1000\n",
      "225/225 [==============================] - 1s 3ms/step - loss: 0.4567 - accuracy: 0.8225 - val_loss: 0.4285 - val_accuracy: 0.8409\n",
      "Epoch 391/1000\n",
      "225/225 [==============================] - 1s 3ms/step - loss: 0.4559 - accuracy: 0.8208 - val_loss: 0.4321 - val_accuracy: 0.8388\n",
      "Epoch 392/1000\n",
      "225/225 [==============================] - 1s 3ms/step - loss: 0.4554 - accuracy: 0.8219 - val_loss: 0.4312 - val_accuracy: 0.8371\n",
      "Epoch 393/1000\n",
      "225/225 [==============================] - 1s 2ms/step - loss: 0.4573 - accuracy: 0.8208 - val_loss: 0.4328 - val_accuracy: 0.8389\n",
      "Epoch 394/1000\n",
      "225/225 [==============================] - 1s 2ms/step - loss: 0.4576 - accuracy: 0.8205 - val_loss: 0.4289 - val_accuracy: 0.8401\n",
      "Epoch 395/1000\n",
      "225/225 [==============================] - 1s 2ms/step - loss: 0.4554 - accuracy: 0.8215 - val_loss: 0.4307 - val_accuracy: 0.8393\n",
      "Epoch 396/1000\n",
      "225/225 [==============================] - 1s 3ms/step - loss: 0.4567 - accuracy: 0.8214 - val_loss: 0.4285 - val_accuracy: 0.8387\n",
      "Epoch 397/1000\n",
      "225/225 [==============================] - 1s 2ms/step - loss: 0.4559 - accuracy: 0.8222 - val_loss: 0.4307 - val_accuracy: 0.8408\n",
      "Epoch 398/1000\n",
      "225/225 [==============================] - 1s 2ms/step - loss: 0.4526 - accuracy: 0.8221 - val_loss: 0.4318 - val_accuracy: 0.8388\n",
      "Epoch 399/1000\n",
      "225/225 [==============================] - 1s 2ms/step - loss: 0.4561 - accuracy: 0.8211 - val_loss: 0.4337 - val_accuracy: 0.8380\n",
      "Epoch 400/1000\n",
      "225/225 [==============================] - 1s 2ms/step - loss: 0.4558 - accuracy: 0.8217 - val_loss: 0.4302 - val_accuracy: 0.8407\n",
      "Epoch 401/1000\n",
      "225/225 [==============================] - 1s 2ms/step - loss: 0.4567 - accuracy: 0.8218 - val_loss: 0.4309 - val_accuracy: 0.8399\n",
      "Epoch 402/1000\n",
      "225/225 [==============================] - 1s 3ms/step - loss: 0.4584 - accuracy: 0.8209 - val_loss: 0.4313 - val_accuracy: 0.8387\n",
      "Epoch 403/1000\n",
      "225/225 [==============================] - 1s 2ms/step - loss: 0.4536 - accuracy: 0.8231 - val_loss: 0.4293 - val_accuracy: 0.8385\n",
      "Epoch 404/1000\n",
      "225/225 [==============================] - 1s 2ms/step - loss: 0.4540 - accuracy: 0.8229 - val_loss: 0.4303 - val_accuracy: 0.8398\n",
      "Epoch 405/1000\n",
      "225/225 [==============================] - 1s 2ms/step - loss: 0.4532 - accuracy: 0.8227 - val_loss: 0.4281 - val_accuracy: 0.8405\n",
      "Epoch 406/1000\n",
      "225/225 [==============================] - 1s 2ms/step - loss: 0.4556 - accuracy: 0.8223 - val_loss: 0.4302 - val_accuracy: 0.8391\n",
      "Epoch 407/1000\n",
      "225/225 [==============================] - 1s 2ms/step - loss: 0.4551 - accuracy: 0.8216 - val_loss: 0.4302 - val_accuracy: 0.8395\n",
      "Epoch 408/1000\n",
      "225/225 [==============================] - 1s 3ms/step - loss: 0.4553 - accuracy: 0.8228 - val_loss: 0.4294 - val_accuracy: 0.8397\n",
      "Epoch 409/1000\n",
      "225/225 [==============================] - 1s 2ms/step - loss: 0.4557 - accuracy: 0.8217 - val_loss: 0.4289 - val_accuracy: 0.8399\n",
      "Epoch 410/1000\n",
      "225/225 [==============================] - 1s 2ms/step - loss: 0.4550 - accuracy: 0.8219 - val_loss: 0.4263 - val_accuracy: 0.8411\n",
      "Epoch 411/1000\n",
      "225/225 [==============================] - 1s 2ms/step - loss: 0.4545 - accuracy: 0.8222 - val_loss: 0.4311 - val_accuracy: 0.8393\n",
      "Epoch 412/1000\n",
      "225/225 [==============================] - 1s 2ms/step - loss: 0.4544 - accuracy: 0.8223 - val_loss: 0.4276 - val_accuracy: 0.8387\n",
      "Epoch 413/1000\n",
      "225/225 [==============================] - 1s 2ms/step - loss: 0.4537 - accuracy: 0.8223 - val_loss: 0.4312 - val_accuracy: 0.8431\n",
      "Epoch 414/1000\n",
      "225/225 [==============================] - 1s 2ms/step - loss: 0.4544 - accuracy: 0.8228 - val_loss: 0.4255 - val_accuracy: 0.8402\n",
      "Epoch 415/1000\n",
      "225/225 [==============================] - 1s 3ms/step - loss: 0.4542 - accuracy: 0.8223 - val_loss: 0.4280 - val_accuracy: 0.8425\n",
      "Epoch 416/1000\n",
      "225/225 [==============================] - 1s 2ms/step - loss: 0.4520 - accuracy: 0.8227 - val_loss: 0.4274 - val_accuracy: 0.8409\n",
      "Epoch 417/1000\n",
      "225/225 [==============================] - 1s 2ms/step - loss: 0.4550 - accuracy: 0.8221 - val_loss: 0.4296 - val_accuracy: 0.8377\n",
      "Epoch 418/1000\n",
      "225/225 [==============================] - 1s 2ms/step - loss: 0.4541 - accuracy: 0.8220 - val_loss: 0.4293 - val_accuracy: 0.8401\n",
      "Epoch 419/1000\n",
      "225/225 [==============================] - 1s 2ms/step - loss: 0.4547 - accuracy: 0.8223 - val_loss: 0.4281 - val_accuracy: 0.8396\n",
      "Epoch 420/1000\n",
      "225/225 [==============================] - 1s 2ms/step - loss: 0.4537 - accuracy: 0.8237 - val_loss: 0.4297 - val_accuracy: 0.8381\n",
      "Epoch 421/1000\n",
      "225/225 [==============================] - 1s 2ms/step - loss: 0.4578 - accuracy: 0.8202 - val_loss: 0.4281 - val_accuracy: 0.8414\n",
      "Epoch 422/1000\n",
      "225/225 [==============================] - 1s 2ms/step - loss: 0.4516 - accuracy: 0.8237 - val_loss: 0.4292 - val_accuracy: 0.8416\n",
      "Epoch 423/1000\n",
      "225/225 [==============================] - 1s 2ms/step - loss: 0.4552 - accuracy: 0.8224 - val_loss: 0.4285 - val_accuracy: 0.8402\n",
      "Epoch 424/1000\n",
      "225/225 [==============================] - 1s 3ms/step - loss: 0.4533 - accuracy: 0.8220 - val_loss: 0.4282 - val_accuracy: 0.8413\n",
      "Epoch 425/1000\n",
      "225/225 [==============================] - 1s 3ms/step - loss: 0.4541 - accuracy: 0.8218 - val_loss: 0.4271 - val_accuracy: 0.8420\n",
      "Epoch 426/1000\n",
      "225/225 [==============================] - 1s 3ms/step - loss: 0.4551 - accuracy: 0.8222 - val_loss: 0.4270 - val_accuracy: 0.8415\n",
      "Epoch 427/1000\n",
      "225/225 [==============================] - 1s 3ms/step - loss: 0.4537 - accuracy: 0.8220 - val_loss: 0.4286 - val_accuracy: 0.8402\n",
      "Epoch 428/1000\n",
      "225/225 [==============================] - 1s 2ms/step - loss: 0.4553 - accuracy: 0.8223 - val_loss: 0.4275 - val_accuracy: 0.8434\n",
      "Epoch 429/1000\n",
      "225/225 [==============================] - 1s 3ms/step - loss: 0.4544 - accuracy: 0.8223 - val_loss: 0.4284 - val_accuracy: 0.8418\n",
      "Epoch 430/1000\n",
      "225/225 [==============================] - 1s 3ms/step - loss: 0.4545 - accuracy: 0.8217 - val_loss: 0.4294 - val_accuracy: 0.8387\n",
      "Epoch 431/1000\n",
      "225/225 [==============================] - 1s 3ms/step - loss: 0.4540 - accuracy: 0.8228 - val_loss: 0.4234 - val_accuracy: 0.8424\n",
      "Epoch 432/1000\n",
      "225/225 [==============================] - 1s 2ms/step - loss: 0.4534 - accuracy: 0.8233 - val_loss: 0.4247 - val_accuracy: 0.8433\n",
      "Epoch 433/1000\n",
      "225/225 [==============================] - 1s 2ms/step - loss: 0.4545 - accuracy: 0.8214 - val_loss: 0.4283 - val_accuracy: 0.8405\n",
      "Epoch 434/1000\n",
      "225/225 [==============================] - 1s 2ms/step - loss: 0.4524 - accuracy: 0.8232 - val_loss: 0.4274 - val_accuracy: 0.8417\n",
      "Epoch 435/1000\n",
      "225/225 [==============================] - 1s 2ms/step - loss: 0.4539 - accuracy: 0.8232 - val_loss: 0.4260 - val_accuracy: 0.8400\n",
      "Epoch 436/1000\n",
      "225/225 [==============================] - 1s 2ms/step - loss: 0.4543 - accuracy: 0.8218 - val_loss: 0.4237 - val_accuracy: 0.8419\n",
      "Epoch 437/1000\n",
      "225/225 [==============================] - 1s 2ms/step - loss: 0.4528 - accuracy: 0.8226 - val_loss: 0.4269 - val_accuracy: 0.8404\n",
      "Epoch 438/1000\n",
      "225/225 [==============================] - 1s 3ms/step - loss: 0.4532 - accuracy: 0.8225 - val_loss: 0.4266 - val_accuracy: 0.8427\n",
      "Epoch 439/1000\n",
      "225/225 [==============================] - 1s 3ms/step - loss: 0.4556 - accuracy: 0.8217 - val_loss: 0.4248 - val_accuracy: 0.8426\n",
      "Epoch 440/1000\n",
      "225/225 [==============================] - 1s 3ms/step - loss: 0.4512 - accuracy: 0.8242 - val_loss: 0.4243 - val_accuracy: 0.8420\n",
      "Epoch 441/1000\n",
      "225/225 [==============================] - 1s 2ms/step - loss: 0.4540 - accuracy: 0.8223 - val_loss: 0.4267 - val_accuracy: 0.8417\n",
      "Epoch 442/1000\n",
      "225/225 [==============================] - 1s 2ms/step - loss: 0.4530 - accuracy: 0.8231 - val_loss: 0.4254 - val_accuracy: 0.8408\n",
      "Epoch 443/1000\n",
      "225/225 [==============================] - 1s 2ms/step - loss: 0.4524 - accuracy: 0.8239 - val_loss: 0.4260 - val_accuracy: 0.8437\n",
      "Epoch 444/1000\n",
      "225/225 [==============================] - 1s 2ms/step - loss: 0.4532 - accuracy: 0.8234 - val_loss: 0.4273 - val_accuracy: 0.8413\n",
      "Epoch 445/1000\n",
      "225/225 [==============================] - 1s 2ms/step - loss: 0.4527 - accuracy: 0.8240 - val_loss: 0.4259 - val_accuracy: 0.8395\n",
      "Epoch 446/1000\n",
      "225/225 [==============================] - 1s 2ms/step - loss: 0.4515 - accuracy: 0.8234 - val_loss: 0.4255 - val_accuracy: 0.8416\n",
      "Epoch 447/1000\n",
      "225/225 [==============================] - 1s 2ms/step - loss: 0.4501 - accuracy: 0.8236 - val_loss: 0.4236 - val_accuracy: 0.8425\n",
      "Epoch 448/1000\n",
      "225/225 [==============================] - 1s 2ms/step - loss: 0.4531 - accuracy: 0.8224 - val_loss: 0.4238 - val_accuracy: 0.8431\n",
      "Epoch 449/1000\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "225/225 [==============================] - 1s 2ms/step - loss: 0.4525 - accuracy: 0.8239 - val_loss: 0.4291 - val_accuracy: 0.8393\n",
      "Epoch 450/1000\n",
      "225/225 [==============================] - 1s 2ms/step - loss: 0.4512 - accuracy: 0.8240 - val_loss: 0.4236 - val_accuracy: 0.8436\n",
      "Epoch 451/1000\n",
      "225/225 [==============================] - 1s 2ms/step - loss: 0.4526 - accuracy: 0.8229 - val_loss: 0.4256 - val_accuracy: 0.8414\n",
      "Epoch 452/1000\n",
      "225/225 [==============================] - 1s 2ms/step - loss: 0.4521 - accuracy: 0.8236 - val_loss: 0.4272 - val_accuracy: 0.8410\n",
      "Epoch 453/1000\n",
      "225/225 [==============================] - 1s 3ms/step - loss: 0.4528 - accuracy: 0.8230 - val_loss: 0.4258 - val_accuracy: 0.8422\n",
      "Epoch 454/1000\n",
      "225/225 [==============================] - 1s 2ms/step - loss: 0.4509 - accuracy: 0.8245 - val_loss: 0.4250 - val_accuracy: 0.8420\n",
      "Epoch 455/1000\n",
      "225/225 [==============================] - 1s 2ms/step - loss: 0.4521 - accuracy: 0.8231 - val_loss: 0.4296 - val_accuracy: 0.8396\n",
      "Epoch 456/1000\n",
      "225/225 [==============================] - 1s 2ms/step - loss: 0.4531 - accuracy: 0.8232 - val_loss: 0.4295 - val_accuracy: 0.8396\n",
      "Epoch 457/1000\n",
      "225/225 [==============================] - 1s 2ms/step - loss: 0.4524 - accuracy: 0.8234 - val_loss: 0.4267 - val_accuracy: 0.8403\n",
      "Epoch 458/1000\n",
      "225/225 [==============================] - 1s 2ms/step - loss: 0.4516 - accuracy: 0.8229 - val_loss: 0.4272 - val_accuracy: 0.8441\n",
      "Epoch 459/1000\n",
      "225/225 [==============================] - 1s 2ms/step - loss: 0.4519 - accuracy: 0.8229 - val_loss: 0.4287 - val_accuracy: 0.8402\n",
      "Epoch 460/1000\n",
      "225/225 [==============================] - 1s 2ms/step - loss: 0.4502 - accuracy: 0.8239 - val_loss: 0.4279 - val_accuracy: 0.8420\n",
      "Epoch 461/1000\n",
      "225/225 [==============================] - 1s 2ms/step - loss: 0.4524 - accuracy: 0.8236 - val_loss: 0.4294 - val_accuracy: 0.8391\n",
      "Epoch 462/1000\n",
      "225/225 [==============================] - 1s 2ms/step - loss: 0.4522 - accuracy: 0.8230 - val_loss: 0.4257 - val_accuracy: 0.8415\n",
      "Epoch 463/1000\n",
      "225/225 [==============================] - 1s 2ms/step - loss: 0.4503 - accuracy: 0.8236 - val_loss: 0.4267 - val_accuracy: 0.8433\n",
      "Epoch 464/1000\n",
      "225/225 [==============================] - 1s 2ms/step - loss: 0.4511 - accuracy: 0.8234 - val_loss: 0.4274 - val_accuracy: 0.8421\n",
      "Epoch 465/1000\n",
      "225/225 [==============================] - 1s 3ms/step - loss: 0.4524 - accuracy: 0.8231 - val_loss: 0.4260 - val_accuracy: 0.8421\n",
      "Epoch 466/1000\n",
      "225/225 [==============================] - 1s 2ms/step - loss: 0.4539 - accuracy: 0.8236 - val_loss: 0.4272 - val_accuracy: 0.8431\n",
      "Epoch 467/1000\n",
      "225/225 [==============================] - 1s 3ms/step - loss: 0.4537 - accuracy: 0.8222 - val_loss: 0.4278 - val_accuracy: 0.8416\n",
      "Epoch 468/1000\n",
      "225/225 [==============================] - 1s 3ms/step - loss: 0.4504 - accuracy: 0.8243 - val_loss: 0.4258 - val_accuracy: 0.8417\n",
      "Epoch 469/1000\n",
      "225/225 [==============================] - 1s 2ms/step - loss: 0.4517 - accuracy: 0.8225 - val_loss: 0.4268 - val_accuracy: 0.8413\n",
      "Epoch 470/1000\n",
      "225/225 [==============================] - 1s 2ms/step - loss: 0.4529 - accuracy: 0.8229 - val_loss: 0.4276 - val_accuracy: 0.8413\n",
      "Epoch 471/1000\n",
      "225/225 [==============================] - 1s 3ms/step - loss: 0.4513 - accuracy: 0.8240 - val_loss: 0.4259 - val_accuracy: 0.8408\n",
      "Epoch 472/1000\n",
      "225/225 [==============================] - 1s 2ms/step - loss: 0.4520 - accuracy: 0.8240 - val_loss: 0.4288 - val_accuracy: 0.8394\n",
      "Epoch 473/1000\n",
      "225/225 [==============================] - 1s 3ms/step - loss: 0.4511 - accuracy: 0.8233 - val_loss: 0.4267 - val_accuracy: 0.8401\n",
      "Epoch 474/1000\n",
      "225/225 [==============================] - 1s 3ms/step - loss: 0.4533 - accuracy: 0.8222 - val_loss: 0.4264 - val_accuracy: 0.8431\n",
      "Epoch 475/1000\n",
      "225/225 [==============================] - 1s 3ms/step - loss: 0.4501 - accuracy: 0.8249 - val_loss: 0.4274 - val_accuracy: 0.8414\n",
      "Epoch 476/1000\n",
      "225/225 [==============================] - 1s 2ms/step - loss: 0.4521 - accuracy: 0.8233 - val_loss: 0.4265 - val_accuracy: 0.8427\n",
      "Epoch 477/1000\n",
      "225/225 [==============================] - 1s 2ms/step - loss: 0.4508 - accuracy: 0.8224 - val_loss: 0.4256 - val_accuracy: 0.8421\n",
      "Epoch 478/1000\n",
      "225/225 [==============================] - 1s 2ms/step - loss: 0.4530 - accuracy: 0.8223 - val_loss: 0.4296 - val_accuracy: 0.8401\n",
      "Epoch 479/1000\n",
      "225/225 [==============================] - 1s 2ms/step - loss: 0.4517 - accuracy: 0.8229 - val_loss: 0.4266 - val_accuracy: 0.8409\n",
      "Epoch 480/1000\n",
      "225/225 [==============================] - 1s 2ms/step - loss: 0.4526 - accuracy: 0.8222 - val_loss: 0.4260 - val_accuracy: 0.8435\n",
      "Epoch 481/1000\n",
      "225/225 [==============================] - 1s 3ms/step - loss: 0.4515 - accuracy: 0.8237 - val_loss: 0.4255 - val_accuracy: 0.8414\n",
      "Epoch 482/1000\n",
      "225/225 [==============================] - 1s 2ms/step - loss: 0.4512 - accuracy: 0.8240 - val_loss: 0.4258 - val_accuracy: 0.8423\n",
      "Epoch 483/1000\n",
      "225/225 [==============================] - 1s 2ms/step - loss: 0.4503 - accuracy: 0.8233 - val_loss: 0.4255 - val_accuracy: 0.8405\n",
      "Epoch 484/1000\n",
      "225/225 [==============================] - 1s 2ms/step - loss: 0.4540 - accuracy: 0.8231 - val_loss: 0.4274 - val_accuracy: 0.8411\n",
      "Epoch 485/1000\n",
      "225/225 [==============================] - 1s 2ms/step - loss: 0.4497 - accuracy: 0.8250 - val_loss: 0.4246 - val_accuracy: 0.8432\n",
      "Epoch 486/1000\n",
      "225/225 [==============================] - 1s 2ms/step - loss: 0.4529 - accuracy: 0.8231 - val_loss: 0.4246 - val_accuracy: 0.8434\n",
      "Epoch 487/1000\n",
      "225/225 [==============================] - 1s 2ms/step - loss: 0.4501 - accuracy: 0.8231 - val_loss: 0.4254 - val_accuracy: 0.8416\n",
      "Epoch 488/1000\n",
      "225/225 [==============================] - 1s 2ms/step - loss: 0.4506 - accuracy: 0.8240 - val_loss: 0.4259 - val_accuracy: 0.8396\n",
      "Epoch 489/1000\n",
      "225/225 [==============================] - 1s 2ms/step - loss: 0.4490 - accuracy: 0.8249 - val_loss: 0.4253 - val_accuracy: 0.8417\n",
      "Epoch 490/1000\n",
      "225/225 [==============================] - 1s 2ms/step - loss: 0.4514 - accuracy: 0.8247 - val_loss: 0.4264 - val_accuracy: 0.8405\n",
      "Epoch 491/1000\n",
      "225/225 [==============================] - 1s 2ms/step - loss: 0.4494 - accuracy: 0.8227 - val_loss: 0.4264 - val_accuracy: 0.8427\n",
      "Epoch 492/1000\n",
      "225/225 [==============================] - 1s 2ms/step - loss: 0.4512 - accuracy: 0.8240 - val_loss: 0.4261 - val_accuracy: 0.8431\n",
      "Epoch 493/1000\n",
      "225/225 [==============================] - 1s 2ms/step - loss: 0.4511 - accuracy: 0.8240 - val_loss: 0.4253 - val_accuracy: 0.8431\n",
      "Epoch 494/1000\n",
      "225/225 [==============================] - 1s 2ms/step - loss: 0.4504 - accuracy: 0.8238 - val_loss: 0.4254 - val_accuracy: 0.8438\n",
      "Epoch 495/1000\n",
      "225/225 [==============================] - 1s 2ms/step - loss: 0.4520 - accuracy: 0.8236 - val_loss: 0.4265 - val_accuracy: 0.8427\n",
      "Epoch 496/1000\n",
      "225/225 [==============================] - 1s 2ms/step - loss: 0.4509 - accuracy: 0.8243 - val_loss: 0.4258 - val_accuracy: 0.8431\n",
      "Epoch 497/1000\n",
      "225/225 [==============================] - 1s 2ms/step - loss: 0.4493 - accuracy: 0.8241 - val_loss: 0.4242 - val_accuracy: 0.8419\n",
      "Epoch 498/1000\n",
      "225/225 [==============================] - 1s 2ms/step - loss: 0.4510 - accuracy: 0.8241 - val_loss: 0.4249 - val_accuracy: 0.8413\n",
      "Epoch 499/1000\n",
      "225/225 [==============================] - 1s 2ms/step - loss: 0.4515 - accuracy: 0.8219 - val_loss: 0.4245 - val_accuracy: 0.8451\n",
      "Epoch 500/1000\n",
      "225/225 [==============================] - 1s 2ms/step - loss: 0.4496 - accuracy: 0.8243 - val_loss: 0.4266 - val_accuracy: 0.8401\n",
      "Epoch 501/1000\n",
      "225/225 [==============================] - 1s 2ms/step - loss: 0.4496 - accuracy: 0.8255 - val_loss: 0.4222 - val_accuracy: 0.8444\n",
      "Epoch 502/1000\n",
      "225/225 [==============================] - 1s 2ms/step - loss: 0.4520 - accuracy: 0.8237 - val_loss: 0.4278 - val_accuracy: 0.8395\n",
      "Epoch 503/1000\n",
      "225/225 [==============================] - 1s 2ms/step - loss: 0.4499 - accuracy: 0.8250 - val_loss: 0.4254 - val_accuracy: 0.8449\n",
      "Epoch 504/1000\n",
      "225/225 [==============================] - 1s 2ms/step - loss: 0.4510 - accuracy: 0.8231 - val_loss: 0.4253 - val_accuracy: 0.8441\n",
      "Epoch 505/1000\n",
      "225/225 [==============================] - 1s 2ms/step - loss: 0.4475 - accuracy: 0.8251 - val_loss: 0.4251 - val_accuracy: 0.8406\n",
      "Epoch 506/1000\n",
      "225/225 [==============================] - 1s 2ms/step - loss: 0.4500 - accuracy: 0.8242 - val_loss: 0.4267 - val_accuracy: 0.8425\n",
      "Epoch 507/1000\n",
      "225/225 [==============================] - 1s 2ms/step - loss: 0.4532 - accuracy: 0.8230 - val_loss: 0.4226 - val_accuracy: 0.8445\n",
      "Epoch 508/1000\n",
      "225/225 [==============================] - 1s 2ms/step - loss: 0.4484 - accuracy: 0.8239 - val_loss: 0.4236 - val_accuracy: 0.8438\n",
      "Epoch 509/1000\n",
      "225/225 [==============================] - 1s 2ms/step - loss: 0.4488 - accuracy: 0.8247 - val_loss: 0.4243 - val_accuracy: 0.8445\n",
      "Epoch 510/1000\n",
      "225/225 [==============================] - 1s 3ms/step - loss: 0.4505 - accuracy: 0.8245 - val_loss: 0.4235 - val_accuracy: 0.8434\n",
      "Epoch 511/1000\n",
      "225/225 [==============================] - 1s 3ms/step - loss: 0.4471 - accuracy: 0.8242 - val_loss: 0.4235 - val_accuracy: 0.8457\n",
      "Epoch 512/1000\n",
      "225/225 [==============================] - 1s 2ms/step - loss: 0.4497 - accuracy: 0.8235 - val_loss: 0.4258 - val_accuracy: 0.8442\n",
      "Epoch 513/1000\n",
      "225/225 [==============================] - 1s 2ms/step - loss: 0.4517 - accuracy: 0.8235 - val_loss: 0.4250 - val_accuracy: 0.8459\n",
      "Epoch 514/1000\n",
      "225/225 [==============================] - 1s 3ms/step - loss: 0.4500 - accuracy: 0.8232 - val_loss: 0.4248 - val_accuracy: 0.8439\n",
      "Epoch 515/1000\n",
      "225/225 [==============================] - 1s 2ms/step - loss: 0.4487 - accuracy: 0.8244 - val_loss: 0.4234 - val_accuracy: 0.8448\n",
      "Epoch 516/1000\n",
      "225/225 [==============================] - 1s 2ms/step - loss: 0.4499 - accuracy: 0.8241 - val_loss: 0.4277 - val_accuracy: 0.8418\n",
      "Epoch 517/1000\n",
      "225/225 [==============================] - 1s 3ms/step - loss: 0.4508 - accuracy: 0.8234 - val_loss: 0.4241 - val_accuracy: 0.8452\n",
      "Epoch 518/1000\n",
      "225/225 [==============================] - 1s 3ms/step - loss: 0.4479 - accuracy: 0.8255 - val_loss: 0.4226 - val_accuracy: 0.8451\n",
      "Epoch 519/1000\n",
      "225/225 [==============================] - 1s 2ms/step - loss: 0.4507 - accuracy: 0.8234 - val_loss: 0.4253 - val_accuracy: 0.8418\n",
      "Epoch 520/1000\n",
      "225/225 [==============================] - 1s 2ms/step - loss: 0.4519 - accuracy: 0.8231 - val_loss: 0.4258 - val_accuracy: 0.8453\n",
      "Epoch 521/1000\n",
      "225/225 [==============================] - 1s 2ms/step - loss: 0.4509 - accuracy: 0.8229 - val_loss: 0.4237 - val_accuracy: 0.8432\n",
      "Epoch 522/1000\n",
      "225/225 [==============================] - 1s 3ms/step - loss: 0.4470 - accuracy: 0.8256 - val_loss: 0.4262 - val_accuracy: 0.8439\n",
      "Epoch 523/1000\n",
      "225/225 [==============================] - 1s 2ms/step - loss: 0.4520 - accuracy: 0.8234 - val_loss: 0.4251 - val_accuracy: 0.8442\n",
      "Epoch 524/1000\n",
      "225/225 [==============================] - 1s 2ms/step - loss: 0.4493 - accuracy: 0.8242 - val_loss: 0.4218 - val_accuracy: 0.8444\n",
      "Epoch 525/1000\n",
      "225/225 [==============================] - 1s 2ms/step - loss: 0.4483 - accuracy: 0.8250 - val_loss: 0.4261 - val_accuracy: 0.8420\n",
      "Epoch 526/1000\n",
      "225/225 [==============================] - 1s 3ms/step - loss: 0.4495 - accuracy: 0.8240 - val_loss: 0.4225 - val_accuracy: 0.8444\n",
      "Epoch 527/1000\n",
      "225/225 [==============================] - 1s 2ms/step - loss: 0.4496 - accuracy: 0.8239 - val_loss: 0.4234 - val_accuracy: 0.8446\n",
      "Epoch 528/1000\n",
      "225/225 [==============================] - 1s 2ms/step - loss: 0.4504 - accuracy: 0.8240 - val_loss: 0.4245 - val_accuracy: 0.8442\n",
      "Epoch 529/1000\n",
      "225/225 [==============================] - 1s 2ms/step - loss: 0.4487 - accuracy: 0.8245 - val_loss: 0.4217 - val_accuracy: 0.8435\n",
      "Epoch 530/1000\n",
      "225/225 [==============================] - 1s 2ms/step - loss: 0.4499 - accuracy: 0.8239 - val_loss: 0.4262 - val_accuracy: 0.8455\n",
      "Epoch 531/1000\n",
      "225/225 [==============================] - 1s 3ms/step - loss: 0.4495 - accuracy: 0.8256 - val_loss: 0.4252 - val_accuracy: 0.8424\n",
      "Epoch 532/1000\n",
      "225/225 [==============================] - 1s 2ms/step - loss: 0.4469 - accuracy: 0.8256 - val_loss: 0.4227 - val_accuracy: 0.8448\n",
      "Epoch 533/1000\n",
      "225/225 [==============================] - 1s 2ms/step - loss: 0.4494 - accuracy: 0.8247 - val_loss: 0.4265 - val_accuracy: 0.8442\n",
      "Epoch 534/1000\n",
      "225/225 [==============================] - 1s 2ms/step - loss: 0.4496 - accuracy: 0.8247 - val_loss: 0.4231 - val_accuracy: 0.8434\n",
      "Epoch 535/1000\n",
      "225/225 [==============================] - 1s 2ms/step - loss: 0.4509 - accuracy: 0.8238 - val_loss: 0.4238 - val_accuracy: 0.8443\n",
      "Epoch 536/1000\n",
      "225/225 [==============================] - 1s 2ms/step - loss: 0.4485 - accuracy: 0.8246 - val_loss: 0.4230 - val_accuracy: 0.8445\n",
      "Epoch 537/1000\n",
      "225/225 [==============================] - 1s 2ms/step - loss: 0.4500 - accuracy: 0.8253 - val_loss: 0.4240 - val_accuracy: 0.8442\n",
      "Epoch 538/1000\n",
      "225/225 [==============================] - 1s 2ms/step - loss: 0.4485 - accuracy: 0.8254 - val_loss: 0.4255 - val_accuracy: 0.8434\n",
      "Epoch 539/1000\n",
      "225/225 [==============================] - 1s 3ms/step - loss: 0.4501 - accuracy: 0.8250 - val_loss: 0.4233 - val_accuracy: 0.8432\n",
      "Epoch 540/1000\n",
      "225/225 [==============================] - 1s 3ms/step - loss: 0.4499 - accuracy: 0.8238 - val_loss: 0.4250 - val_accuracy: 0.8425\n",
      "Epoch 541/1000\n",
      "225/225 [==============================] - 1s 2ms/step - loss: 0.4495 - accuracy: 0.8249 - val_loss: 0.4233 - val_accuracy: 0.8447\n",
      "Epoch 542/1000\n",
      "225/225 [==============================] - 1s 2ms/step - loss: 0.4476 - accuracy: 0.8251 - val_loss: 0.4226 - val_accuracy: 0.8437\n",
      "Epoch 543/1000\n",
      "225/225 [==============================] - 1s 3ms/step - loss: 0.4490 - accuracy: 0.8253 - val_loss: 0.4221 - val_accuracy: 0.8458\n",
      "Epoch 544/1000\n",
      "225/225 [==============================] - 1s 2ms/step - loss: 0.4488 - accuracy: 0.8252 - val_loss: 0.4247 - val_accuracy: 0.8438\n",
      "Epoch 545/1000\n",
      "225/225 [==============================] - 1s 2ms/step - loss: 0.4463 - accuracy: 0.8261 - val_loss: 0.4241 - val_accuracy: 0.8438\n",
      "Epoch 546/1000\n",
      "225/225 [==============================] - 1s 2ms/step - loss: 0.4490 - accuracy: 0.8252 - val_loss: 0.4261 - val_accuracy: 0.8427\n",
      "Epoch 547/1000\n",
      "225/225 [==============================] - 1s 2ms/step - loss: 0.4498 - accuracy: 0.8237 - val_loss: 0.4255 - val_accuracy: 0.8428\n",
      "Epoch 548/1000\n",
      "225/225 [==============================] - 1s 2ms/step - loss: 0.4471 - accuracy: 0.8266 - val_loss: 0.4251 - val_accuracy: 0.8438\n",
      "Epoch 549/1000\n",
      "225/225 [==============================] - 1s 2ms/step - loss: 0.4479 - accuracy: 0.8253 - val_loss: 0.4262 - val_accuracy: 0.8449\n",
      "Epoch 550/1000\n",
      "225/225 [==============================] - 1s 2ms/step - loss: 0.4501 - accuracy: 0.8239 - val_loss: 0.4227 - val_accuracy: 0.8470\n",
      "Epoch 551/1000\n",
      "225/225 [==============================] - 1s 2ms/step - loss: 0.4476 - accuracy: 0.8259 - val_loss: 0.4237 - val_accuracy: 0.8427\n",
      "Epoch 552/1000\n",
      "225/225 [==============================] - 1s 2ms/step - loss: 0.4494 - accuracy: 0.8245 - val_loss: 0.4215 - val_accuracy: 0.8430\n",
      "Epoch 553/1000\n",
      "225/225 [==============================] - 1s 2ms/step - loss: 0.4492 - accuracy: 0.8244 - val_loss: 0.4257 - val_accuracy: 0.8430\n",
      "Epoch 554/1000\n",
      "225/225 [==============================] - 1s 3ms/step - loss: 0.4457 - accuracy: 0.8257 - val_loss: 0.4252 - val_accuracy: 0.8439\n",
      "Epoch 555/1000\n",
      "225/225 [==============================] - 1s 2ms/step - loss: 0.4484 - accuracy: 0.8252 - val_loss: 0.4232 - val_accuracy: 0.8432\n",
      "Epoch 556/1000\n",
      "225/225 [==============================] - 1s 2ms/step - loss: 0.4468 - accuracy: 0.8257 - val_loss: 0.4225 - val_accuracy: 0.8438\n",
      "Epoch 557/1000\n",
      "225/225 [==============================] - 1s 2ms/step - loss: 0.4481 - accuracy: 0.8253 - val_loss: 0.4235 - val_accuracy: 0.8422\n",
      "Epoch 558/1000\n",
      "225/225 [==============================] - 1s 2ms/step - loss: 0.4485 - accuracy: 0.8244 - val_loss: 0.4221 - val_accuracy: 0.8439\n",
      "Epoch 559/1000\n",
      "225/225 [==============================] - 1s 2ms/step - loss: 0.4482 - accuracy: 0.8245 - val_loss: 0.4231 - val_accuracy: 0.8434\n",
      "Epoch 560/1000\n",
      "225/225 [==============================] - 1s 2ms/step - loss: 0.4509 - accuracy: 0.8232 - val_loss: 0.4256 - val_accuracy: 0.8434\n",
      "Epoch 561/1000\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "225/225 [==============================] - 1s 2ms/step - loss: 0.4480 - accuracy: 0.8245 - val_loss: 0.4229 - val_accuracy: 0.8445\n",
      "Epoch 562/1000\n",
      "225/225 [==============================] - 1s 2ms/step - loss: 0.4473 - accuracy: 0.8250 - val_loss: 0.4214 - val_accuracy: 0.8448\n",
      "Epoch 563/1000\n",
      "225/225 [==============================] - 1s 2ms/step - loss: 0.4480 - accuracy: 0.8238 - val_loss: 0.4214 - val_accuracy: 0.8456\n",
      "Epoch 564/1000\n",
      "225/225 [==============================] - 1s 2ms/step - loss: 0.4464 - accuracy: 0.8254 - val_loss: 0.4230 - val_accuracy: 0.8431\n",
      "Epoch 565/1000\n",
      "225/225 [==============================] - 1s 2ms/step - loss: 0.4483 - accuracy: 0.8241 - val_loss: 0.4239 - val_accuracy: 0.8416\n",
      "Epoch 566/1000\n",
      "225/225 [==============================] - 1s 2ms/step - loss: 0.4493 - accuracy: 0.8246 - val_loss: 0.4235 - val_accuracy: 0.8429\n",
      "Epoch 567/1000\n",
      "225/225 [==============================] - 1s 3ms/step - loss: 0.4459 - accuracy: 0.8263 - val_loss: 0.4226 - val_accuracy: 0.8449\n",
      "Epoch 568/1000\n",
      "225/225 [==============================] - 1s 3ms/step - loss: 0.4477 - accuracy: 0.8252 - val_loss: 0.4261 - val_accuracy: 0.8445\n",
      "Epoch 569/1000\n",
      "225/225 [==============================] - 1s 2ms/step - loss: 0.4478 - accuracy: 0.8249 - val_loss: 0.4251 - val_accuracy: 0.8441\n",
      "Epoch 570/1000\n",
      "225/225 [==============================] - 1s 2ms/step - loss: 0.4472 - accuracy: 0.8260 - val_loss: 0.4214 - val_accuracy: 0.8453\n",
      "Epoch 571/1000\n",
      "225/225 [==============================] - 1s 2ms/step - loss: 0.4465 - accuracy: 0.8261 - val_loss: 0.4226 - val_accuracy: 0.8459\n",
      "Epoch 572/1000\n",
      "225/225 [==============================] - 1s 2ms/step - loss: 0.4481 - accuracy: 0.8245 - val_loss: 0.4249 - val_accuracy: 0.8427\n",
      "Epoch 573/1000\n",
      "225/225 [==============================] - 1s 2ms/step - loss: 0.4474 - accuracy: 0.8254 - val_loss: 0.4230 - val_accuracy: 0.8442\n",
      "Epoch 574/1000\n",
      "225/225 [==============================] - 1s 2ms/step - loss: 0.4463 - accuracy: 0.8258 - val_loss: 0.4238 - val_accuracy: 0.8431\n",
      "Epoch 575/1000\n",
      "225/225 [==============================] - 1s 2ms/step - loss: 0.4486 - accuracy: 0.8245 - val_loss: 0.4221 - val_accuracy: 0.8449\n",
      "Epoch 576/1000\n",
      "225/225 [==============================] - 1s 3ms/step - loss: 0.4473 - accuracy: 0.8251 - val_loss: 0.4238 - val_accuracy: 0.8434\n",
      "Epoch 577/1000\n",
      "225/225 [==============================] - 1s 2ms/step - loss: 0.4468 - accuracy: 0.8257 - val_loss: 0.4226 - val_accuracy: 0.8427\n",
      "Epoch 578/1000\n",
      "225/225 [==============================] - 1s 2ms/step - loss: 0.4454 - accuracy: 0.8263 - val_loss: 0.4226 - val_accuracy: 0.8463\n",
      "Epoch 579/1000\n",
      "225/225 [==============================] - 1s 2ms/step - loss: 0.4470 - accuracy: 0.8256 - val_loss: 0.4206 - val_accuracy: 0.8449\n",
      "Epoch 580/1000\n",
      "225/225 [==============================] - 1s 3ms/step - loss: 0.4484 - accuracy: 0.8253 - val_loss: 0.4237 - val_accuracy: 0.8448\n",
      "Epoch 581/1000\n",
      "225/225 [==============================] - 1s 2ms/step - loss: 0.4463 - accuracy: 0.8256 - val_loss: 0.4234 - val_accuracy: 0.8446\n",
      "Epoch 582/1000\n",
      "225/225 [==============================] - 1s 3ms/step - loss: 0.4469 - accuracy: 0.8250 - val_loss: 0.4236 - val_accuracy: 0.8434\n",
      "Epoch 583/1000\n",
      "225/225 [==============================] - 1s 2ms/step - loss: 0.4468 - accuracy: 0.8249 - val_loss: 0.4206 - val_accuracy: 0.8460\n",
      "Epoch 584/1000\n",
      "225/225 [==============================] - 1s 2ms/step - loss: 0.4468 - accuracy: 0.8256 - val_loss: 0.4207 - val_accuracy: 0.8464\n",
      "Epoch 585/1000\n",
      "225/225 [==============================] - 1s 2ms/step - loss: 0.4455 - accuracy: 0.8262 - val_loss: 0.4212 - val_accuracy: 0.8451\n",
      "Epoch 586/1000\n",
      "225/225 [==============================] - 1s 3ms/step - loss: 0.4481 - accuracy: 0.8252 - val_loss: 0.4223 - val_accuracy: 0.8431\n",
      "Epoch 587/1000\n",
      "225/225 [==============================] - 1s 3ms/step - loss: 0.4453 - accuracy: 0.8254 - val_loss: 0.4250 - val_accuracy: 0.8438\n",
      "Epoch 588/1000\n",
      "225/225 [==============================] - 1s 3ms/step - loss: 0.4465 - accuracy: 0.8247 - val_loss: 0.4235 - val_accuracy: 0.8453\n",
      "Epoch 589/1000\n",
      "225/225 [==============================] - 1s 2ms/step - loss: 0.4473 - accuracy: 0.8251 - val_loss: 0.4237 - val_accuracy: 0.8420\n",
      "Epoch 590/1000\n",
      "225/225 [==============================] - 1s 2ms/step - loss: 0.4484 - accuracy: 0.8252 - val_loss: 0.4221 - val_accuracy: 0.8413\n",
      "Epoch 591/1000\n",
      "225/225 [==============================] - 1s 2ms/step - loss: 0.4445 - accuracy: 0.8273 - val_loss: 0.4230 - val_accuracy: 0.8431\n",
      "Epoch 592/1000\n",
      "225/225 [==============================] - 1s 3ms/step - loss: 0.4471 - accuracy: 0.8262 - val_loss: 0.4248 - val_accuracy: 0.8416\n",
      "Epoch 593/1000\n",
      "225/225 [==============================] - 1s 2ms/step - loss: 0.4470 - accuracy: 0.8262 - val_loss: 0.4196 - val_accuracy: 0.8442\n",
      "Epoch 594/1000\n",
      "225/225 [==============================] - 1s 2ms/step - loss: 0.4459 - accuracy: 0.8252 - val_loss: 0.4194 - val_accuracy: 0.8469\n",
      "Epoch 595/1000\n",
      "225/225 [==============================] - 1s 2ms/step - loss: 0.4460 - accuracy: 0.8256 - val_loss: 0.4206 - val_accuracy: 0.8444\n",
      "Epoch 596/1000\n",
      "225/225 [==============================] - 1s 3ms/step - loss: 0.4477 - accuracy: 0.8262 - val_loss: 0.4234 - val_accuracy: 0.8423\n",
      "Epoch 597/1000\n",
      "225/225 [==============================] - 1s 3ms/step - loss: 0.4474 - accuracy: 0.8246 - val_loss: 0.4213 - val_accuracy: 0.8463\n",
      "Epoch 598/1000\n",
      "225/225 [==============================] - 1s 2ms/step - loss: 0.4469 - accuracy: 0.8249 - val_loss: 0.4219 - val_accuracy: 0.8428\n",
      "Epoch 599/1000\n",
      "225/225 [==============================] - 1s 2ms/step - loss: 0.4463 - accuracy: 0.8260 - val_loss: 0.4255 - val_accuracy: 0.8449\n",
      "Epoch 600/1000\n",
      "225/225 [==============================] - 1s 2ms/step - loss: 0.4481 - accuracy: 0.8250 - val_loss: 0.4232 - val_accuracy: 0.8458\n",
      "Epoch 601/1000\n",
      "225/225 [==============================] - 1s 2ms/step - loss: 0.4497 - accuracy: 0.8251 - val_loss: 0.4231 - val_accuracy: 0.8426\n",
      "Epoch 602/1000\n",
      "225/225 [==============================] - 1s 4ms/step - loss: 0.4445 - accuracy: 0.8267 - val_loss: 0.4211 - val_accuracy: 0.8463\n",
      "Epoch 603/1000\n",
      "225/225 [==============================] - 1s 3ms/step - loss: 0.4469 - accuracy: 0.8251 - val_loss: 0.4214 - val_accuracy: 0.8451\n",
      "Epoch 604/1000\n",
      "225/225 [==============================] - 1s 3ms/step - loss: 0.4474 - accuracy: 0.8256 - val_loss: 0.4238 - val_accuracy: 0.8437\n",
      "Epoch 605/1000\n",
      "225/225 [==============================] - 1s 2ms/step - loss: 0.4461 - accuracy: 0.8259 - val_loss: 0.4225 - val_accuracy: 0.8432\n",
      "Epoch 606/1000\n",
      "225/225 [==============================] - 1s 2ms/step - loss: 0.4464 - accuracy: 0.8257 - val_loss: 0.4259 - val_accuracy: 0.8438\n",
      "Epoch 607/1000\n",
      "225/225 [==============================] - 1s 2ms/step - loss: 0.4492 - accuracy: 0.8262 - val_loss: 0.4246 - val_accuracy: 0.8468\n",
      "Epoch 608/1000\n",
      "225/225 [==============================] - 1s 2ms/step - loss: 0.4478 - accuracy: 0.8247 - val_loss: 0.4240 - val_accuracy: 0.8438\n",
      "Epoch 609/1000\n",
      "225/225 [==============================] - 1s 2ms/step - loss: 0.4453 - accuracy: 0.8256 - val_loss: 0.4225 - val_accuracy: 0.8434\n",
      "Epoch 610/1000\n",
      "225/225 [==============================] - 1s 2ms/step - loss: 0.4431 - accuracy: 0.8276 - val_loss: 0.4221 - val_accuracy: 0.8455\n",
      "Epoch 611/1000\n",
      "225/225 [==============================] - 1s 2ms/step - loss: 0.4457 - accuracy: 0.8256 - val_loss: 0.4234 - val_accuracy: 0.8454\n",
      "Epoch 612/1000\n",
      "225/225 [==============================] - 1s 3ms/step - loss: 0.4449 - accuracy: 0.8259 - val_loss: 0.4196 - val_accuracy: 0.8448\n",
      "Epoch 613/1000\n",
      "225/225 [==============================] - 1s 3ms/step - loss: 0.4435 - accuracy: 0.8271 - val_loss: 0.4214 - val_accuracy: 0.8465\n",
      "Epoch 614/1000\n",
      "225/225 [==============================] - 1s 2ms/step - loss: 0.4444 - accuracy: 0.8268 - val_loss: 0.4246 - val_accuracy: 0.8449\n",
      "Epoch 615/1000\n",
      "225/225 [==============================] - 1s 2ms/step - loss: 0.4454 - accuracy: 0.8261 - val_loss: 0.4231 - val_accuracy: 0.8428\n",
      "Epoch 616/1000\n",
      "225/225 [==============================] - 1s 2ms/step - loss: 0.4489 - accuracy: 0.8238 - val_loss: 0.4216 - val_accuracy: 0.8460\n",
      "Epoch 617/1000\n",
      "225/225 [==============================] - 1s 3ms/step - loss: 0.4445 - accuracy: 0.8269 - val_loss: 0.4207 - val_accuracy: 0.8456\n",
      "Epoch 618/1000\n",
      "225/225 [==============================] - 1s 2ms/step - loss: 0.4478 - accuracy: 0.8253 - val_loss: 0.4246 - val_accuracy: 0.8456\n",
      "Epoch 619/1000\n",
      "225/225 [==============================] - 1s 2ms/step - loss: 0.4445 - accuracy: 0.8261 - val_loss: 0.4199 - val_accuracy: 0.8442\n",
      "Epoch 620/1000\n",
      "225/225 [==============================] - 1s 2ms/step - loss: 0.4449 - accuracy: 0.8257 - val_loss: 0.4209 - val_accuracy: 0.8467\n",
      "Epoch 621/1000\n",
      "225/225 [==============================] - 1s 2ms/step - loss: 0.4430 - accuracy: 0.8277 - val_loss: 0.4214 - val_accuracy: 0.8460\n",
      "Epoch 622/1000\n",
      "225/225 [==============================] - 1s 2ms/step - loss: 0.4461 - accuracy: 0.8252 - val_loss: 0.4250 - val_accuracy: 0.8439\n",
      "Epoch 623/1000\n",
      "225/225 [==============================] - 1s 2ms/step - loss: 0.4476 - accuracy: 0.8255 - val_loss: 0.4213 - val_accuracy: 0.8452\n",
      "Epoch 624/1000\n",
      "225/225 [==============================] - 1s 3ms/step - loss: 0.4475 - accuracy: 0.8249 - val_loss: 0.4220 - val_accuracy: 0.8450\n",
      "Epoch 625/1000\n",
      "225/225 [==============================] - 1s 3ms/step - loss: 0.4455 - accuracy: 0.8263 - val_loss: 0.4197 - val_accuracy: 0.8461\n",
      "Epoch 626/1000\n",
      "225/225 [==============================] - 1s 2ms/step - loss: 0.4451 - accuracy: 0.8260 - val_loss: 0.4218 - val_accuracy: 0.8459\n",
      "Epoch 627/1000\n",
      "225/225 [==============================] - 1s 3ms/step - loss: 0.4470 - accuracy: 0.8257 - val_loss: 0.4242 - val_accuracy: 0.8467\n",
      "Epoch 628/1000\n",
      "225/225 [==============================] - 1s 3ms/step - loss: 0.4445 - accuracy: 0.8255 - val_loss: 0.4210 - val_accuracy: 0.8441\n",
      "Epoch 629/1000\n",
      "225/225 [==============================] - 1s 3ms/step - loss: 0.4457 - accuracy: 0.8262 - val_loss: 0.4223 - val_accuracy: 0.8461\n",
      "Epoch 630/1000\n",
      "225/225 [==============================] - 1s 2ms/step - loss: 0.4446 - accuracy: 0.8263 - val_loss: 0.4210 - val_accuracy: 0.8450\n",
      "Epoch 631/1000\n",
      "225/225 [==============================] - 1s 3ms/step - loss: 0.4459 - accuracy: 0.8270 - val_loss: 0.4253 - val_accuracy: 0.8439\n",
      "Epoch 632/1000\n",
      "225/225 [==============================] - 1s 2ms/step - loss: 0.4448 - accuracy: 0.8268 - val_loss: 0.4216 - val_accuracy: 0.8460\n",
      "Epoch 633/1000\n",
      "225/225 [==============================] - 1s 2ms/step - loss: 0.4441 - accuracy: 0.8270 - val_loss: 0.4204 - val_accuracy: 0.8460\n",
      "Epoch 634/1000\n",
      "225/225 [==============================] - 1s 2ms/step - loss: 0.4470 - accuracy: 0.8252 - val_loss: 0.4226 - val_accuracy: 0.8447\n",
      "Epoch 635/1000\n",
      "225/225 [==============================] - 1s 2ms/step - loss: 0.4461 - accuracy: 0.8263 - val_loss: 0.4204 - val_accuracy: 0.8452\n",
      "Epoch 636/1000\n",
      "225/225 [==============================] - 1s 2ms/step - loss: 0.4449 - accuracy: 0.8259 - val_loss: 0.4218 - val_accuracy: 0.8455\n",
      "Epoch 637/1000\n",
      "225/225 [==============================] - 1s 2ms/step - loss: 0.4468 - accuracy: 0.8259 - val_loss: 0.4203 - val_accuracy: 0.8467\n",
      "Epoch 638/1000\n",
      "225/225 [==============================] - 1s 2ms/step - loss: 0.4440 - accuracy: 0.8272 - val_loss: 0.4213 - val_accuracy: 0.8464\n",
      "Epoch 639/1000\n",
      "225/225 [==============================] - 1s 2ms/step - loss: 0.4433 - accuracy: 0.8277 - val_loss: 0.4230 - val_accuracy: 0.8452\n",
      "Epoch 640/1000\n",
      "225/225 [==============================] - 1s 2ms/step - loss: 0.4456 - accuracy: 0.8254 - val_loss: 0.4200 - val_accuracy: 0.8459\n",
      "Epoch 641/1000\n",
      "225/225 [==============================] - 1s 3ms/step - loss: 0.4444 - accuracy: 0.8275 - val_loss: 0.4223 - val_accuracy: 0.8454\n",
      "Epoch 642/1000\n",
      "225/225 [==============================] - 1s 2ms/step - loss: 0.4425 - accuracy: 0.8272 - val_loss: 0.4218 - val_accuracy: 0.8437\n",
      "Epoch 643/1000\n",
      "225/225 [==============================] - 1s 2ms/step - loss: 0.4460 - accuracy: 0.8254 - val_loss: 0.4217 - val_accuracy: 0.8449\n",
      "Epoch 644/1000\n",
      "225/225 [==============================] - 1s 2ms/step - loss: 0.4441 - accuracy: 0.8270 - val_loss: 0.4190 - val_accuracy: 0.8456\n",
      "Epoch 645/1000\n",
      "225/225 [==============================] - 1s 2ms/step - loss: 0.4449 - accuracy: 0.8260 - val_loss: 0.4215 - val_accuracy: 0.8443\n",
      "Epoch 646/1000\n",
      "225/225 [==============================] - 1s 2ms/step - loss: 0.4476 - accuracy: 0.8243 - val_loss: 0.4227 - val_accuracy: 0.8462\n",
      "Epoch 647/1000\n",
      "225/225 [==============================] - 1s 2ms/step - loss: 0.4456 - accuracy: 0.8264 - val_loss: 0.4217 - val_accuracy: 0.8457\n",
      "Epoch 648/1000\n",
      "225/225 [==============================] - 1s 2ms/step - loss: 0.4455 - accuracy: 0.8262 - val_loss: 0.4188 - val_accuracy: 0.8467\n",
      "Epoch 649/1000\n",
      "225/225 [==============================] - 1s 3ms/step - loss: 0.4435 - accuracy: 0.8270 - val_loss: 0.4199 - val_accuracy: 0.8448\n",
      "Epoch 650/1000\n",
      "225/225 [==============================] - 1s 3ms/step - loss: 0.4463 - accuracy: 0.8252 - val_loss: 0.4205 - val_accuracy: 0.8449\n",
      "Epoch 651/1000\n",
      "225/225 [==============================] - 1s 2ms/step - loss: 0.4455 - accuracy: 0.8264 - val_loss: 0.4234 - val_accuracy: 0.8455\n",
      "Epoch 652/1000\n",
      "225/225 [==============================] - 1s 3ms/step - loss: 0.4472 - accuracy: 0.8260 - val_loss: 0.4183 - val_accuracy: 0.8452\n",
      "Epoch 653/1000\n",
      "225/225 [==============================] - 1s 3ms/step - loss: 0.4440 - accuracy: 0.8258 - val_loss: 0.4190 - val_accuracy: 0.8463\n",
      "Epoch 654/1000\n",
      "225/225 [==============================] - 1s 3ms/step - loss: 0.4436 - accuracy: 0.8275 - val_loss: 0.4210 - val_accuracy: 0.8458\n",
      "Epoch 655/1000\n",
      "225/225 [==============================] - 1s 2ms/step - loss: 0.4444 - accuracy: 0.8264 - val_loss: 0.4200 - val_accuracy: 0.8453\n",
      "Epoch 656/1000\n",
      "225/225 [==============================] - 1s 2ms/step - loss: 0.4460 - accuracy: 0.8260 - val_loss: 0.4212 - val_accuracy: 0.8442\n",
      "Epoch 657/1000\n",
      "225/225 [==============================] - 1s 2ms/step - loss: 0.4449 - accuracy: 0.8258 - val_loss: 0.4209 - val_accuracy: 0.8457\n",
      "Epoch 658/1000\n",
      "225/225 [==============================] - 1s 2ms/step - loss: 0.4458 - accuracy: 0.8271 - val_loss: 0.4182 - val_accuracy: 0.8462\n",
      "Epoch 659/1000\n",
      "225/225 [==============================] - 1s 3ms/step - loss: 0.4441 - accuracy: 0.8282 - val_loss: 0.4212 - val_accuracy: 0.8454\n",
      "Epoch 660/1000\n",
      "225/225 [==============================] - 1s 3ms/step - loss: 0.4473 - accuracy: 0.8249 - val_loss: 0.4239 - val_accuracy: 0.8460\n",
      "Epoch 661/1000\n",
      "225/225 [==============================] - 1s 3ms/step - loss: 0.4441 - accuracy: 0.8264 - val_loss: 0.4221 - val_accuracy: 0.8446\n",
      "Epoch 662/1000\n",
      "225/225 [==============================] - 1s 2ms/step - loss: 0.4435 - accuracy: 0.8278 - val_loss: 0.4222 - val_accuracy: 0.8458\n",
      "Epoch 663/1000\n",
      "225/225 [==============================] - 1s 2ms/step - loss: 0.4436 - accuracy: 0.8264 - val_loss: 0.4183 - val_accuracy: 0.8443\n",
      "Epoch 664/1000\n",
      "225/225 [==============================] - 1s 2ms/step - loss: 0.4442 - accuracy: 0.8273 - val_loss: 0.4202 - val_accuracy: 0.8465\n",
      "Epoch 665/1000\n",
      "225/225 [==============================] - 1s 2ms/step - loss: 0.4450 - accuracy: 0.8272 - val_loss: 0.4216 - val_accuracy: 0.8433\n",
      "Epoch 666/1000\n",
      "225/225 [==============================] - 1s 2ms/step - loss: 0.4448 - accuracy: 0.8271 - val_loss: 0.4194 - val_accuracy: 0.8478\n",
      "Epoch 667/1000\n",
      "225/225 [==============================] - 1s 2ms/step - loss: 0.4441 - accuracy: 0.8266 - val_loss: 0.4179 - val_accuracy: 0.8493\n",
      "Epoch 668/1000\n",
      "225/225 [==============================] - 1s 2ms/step - loss: 0.4443 - accuracy: 0.8267 - val_loss: 0.4207 - val_accuracy: 0.8415\n",
      "Epoch 669/1000\n",
      "225/225 [==============================] - 1s 2ms/step - loss: 0.4458 - accuracy: 0.8269 - val_loss: 0.4220 - val_accuracy: 0.8454\n",
      "Epoch 670/1000\n",
      "225/225 [==============================] - 1s 3ms/step - loss: 0.4447 - accuracy: 0.8252 - val_loss: 0.4227 - val_accuracy: 0.8464\n",
      "Epoch 671/1000\n",
      "225/225 [==============================] - 1s 2ms/step - loss: 0.4437 - accuracy: 0.8264 - val_loss: 0.4207 - val_accuracy: 0.8456\n",
      "Epoch 672/1000\n",
      "225/225 [==============================] - 1s 2ms/step - loss: 0.4439 - accuracy: 0.8274 - val_loss: 0.4216 - val_accuracy: 0.8467\n",
      "Epoch 673/1000\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "225/225 [==============================] - 1s 3ms/step - loss: 0.4441 - accuracy: 0.8264 - val_loss: 0.4189 - val_accuracy: 0.8451\n",
      "Epoch 674/1000\n",
      "225/225 [==============================] - 1s 3ms/step - loss: 0.4444 - accuracy: 0.8267 - val_loss: 0.4244 - val_accuracy: 0.8410\n",
      "Epoch 675/1000\n",
      "225/225 [==============================] - 1s 3ms/step - loss: 0.4423 - accuracy: 0.8279 - val_loss: 0.4184 - val_accuracy: 0.8433\n",
      "Epoch 676/1000\n",
      "225/225 [==============================] - 1s 3ms/step - loss: 0.4452 - accuracy: 0.8265 - val_loss: 0.4203 - val_accuracy: 0.8460\n",
      "Epoch 677/1000\n",
      "225/225 [==============================] - 1s 3ms/step - loss: 0.4446 - accuracy: 0.8269 - val_loss: 0.4203 - val_accuracy: 0.8452\n",
      "Epoch 678/1000\n",
      "225/225 [==============================] - 1s 2ms/step - loss: 0.4437 - accuracy: 0.8267 - val_loss: 0.4216 - val_accuracy: 0.8443\n",
      "Epoch 679/1000\n",
      "225/225 [==============================] - 1s 2ms/step - loss: 0.4448 - accuracy: 0.8266 - val_loss: 0.4197 - val_accuracy: 0.8471\n",
      "Epoch 680/1000\n",
      "225/225 [==============================] - 1s 2ms/step - loss: 0.4448 - accuracy: 0.8268 - val_loss: 0.4228 - val_accuracy: 0.8446\n",
      "Epoch 681/1000\n",
      "225/225 [==============================] - 1s 3ms/step - loss: 0.4425 - accuracy: 0.8278 - val_loss: 0.4212 - val_accuracy: 0.8456\n",
      "Epoch 682/1000\n",
      "225/225 [==============================] - 1s 2ms/step - loss: 0.4418 - accuracy: 0.8277 - val_loss: 0.4200 - val_accuracy: 0.8456\n",
      "Epoch 683/1000\n",
      "225/225 [==============================] - 1s 3ms/step - loss: 0.4450 - accuracy: 0.8264 - val_loss: 0.4201 - val_accuracy: 0.8446\n",
      "Epoch 684/1000\n",
      "225/225 [==============================] - 1s 2ms/step - loss: 0.4427 - accuracy: 0.8273 - val_loss: 0.4204 - val_accuracy: 0.8456\n",
      "Epoch 685/1000\n",
      "225/225 [==============================] - 1s 2ms/step - loss: 0.4443 - accuracy: 0.8261 - val_loss: 0.4199 - val_accuracy: 0.8460\n",
      "Epoch 686/1000\n",
      "225/225 [==============================] - 1s 2ms/step - loss: 0.4428 - accuracy: 0.8276 - val_loss: 0.4185 - val_accuracy: 0.8442\n",
      "Epoch 687/1000\n",
      "225/225 [==============================] - 1s 2ms/step - loss: 0.4426 - accuracy: 0.8265 - val_loss: 0.4160 - val_accuracy: 0.8471\n",
      "Epoch 688/1000\n",
      "225/225 [==============================] - 1s 2ms/step - loss: 0.4434 - accuracy: 0.8262 - val_loss: 0.4200 - val_accuracy: 0.8456\n",
      "Epoch 689/1000\n",
      "225/225 [==============================] - 1s 3ms/step - loss: 0.4442 - accuracy: 0.8261 - val_loss: 0.4222 - val_accuracy: 0.8469\n",
      "Epoch 690/1000\n",
      "225/225 [==============================] - 1s 2ms/step - loss: 0.4426 - accuracy: 0.8268 - val_loss: 0.4175 - val_accuracy: 0.8468\n",
      "Epoch 691/1000\n",
      "225/225 [==============================] - 1s 2ms/step - loss: 0.4423 - accuracy: 0.8280 - val_loss: 0.4193 - val_accuracy: 0.8454\n",
      "Epoch 692/1000\n",
      "225/225 [==============================] - 1s 2ms/step - loss: 0.4426 - accuracy: 0.8274 - val_loss: 0.4194 - val_accuracy: 0.8448\n",
      "Epoch 693/1000\n",
      "225/225 [==============================] - 1s 2ms/step - loss: 0.4413 - accuracy: 0.8277 - val_loss: 0.4214 - val_accuracy: 0.8461\n",
      "Epoch 694/1000\n",
      "225/225 [==============================] - 1s 2ms/step - loss: 0.4445 - accuracy: 0.8266 - val_loss: 0.4166 - val_accuracy: 0.8460\n",
      "Epoch 695/1000\n",
      "225/225 [==============================] - 1s 2ms/step - loss: 0.4418 - accuracy: 0.8279 - val_loss: 0.4185 - val_accuracy: 0.8452\n",
      "Epoch 696/1000\n",
      "225/225 [==============================] - 1s 2ms/step - loss: 0.4441 - accuracy: 0.8270 - val_loss: 0.4177 - val_accuracy: 0.8470\n",
      "Epoch 697/1000\n",
      "225/225 [==============================] - 1s 2ms/step - loss: 0.4428 - accuracy: 0.8269 - val_loss: 0.4190 - val_accuracy: 0.8467\n",
      "Epoch 698/1000\n",
      "225/225 [==============================] - 1s 2ms/step - loss: 0.4436 - accuracy: 0.8267 - val_loss: 0.4179 - val_accuracy: 0.8471\n",
      "Epoch 699/1000\n",
      "225/225 [==============================] - 1s 3ms/step - loss: 0.4432 - accuracy: 0.8285 - val_loss: 0.4197 - val_accuracy: 0.8440\n",
      "Epoch 700/1000\n",
      "225/225 [==============================] - 1s 3ms/step - loss: 0.4453 - accuracy: 0.8263 - val_loss: 0.4188 - val_accuracy: 0.8464\n",
      "Epoch 701/1000\n",
      "225/225 [==============================] - 1s 2ms/step - loss: 0.4424 - accuracy: 0.8272 - val_loss: 0.4193 - val_accuracy: 0.8453\n",
      "Epoch 702/1000\n",
      "225/225 [==============================] - 1s 2ms/step - loss: 0.4421 - accuracy: 0.8278 - val_loss: 0.4171 - val_accuracy: 0.8456\n",
      "Epoch 703/1000\n",
      "225/225 [==============================] - 1s 3ms/step - loss: 0.4429 - accuracy: 0.8279 - val_loss: 0.4177 - val_accuracy: 0.8461\n",
      "Epoch 704/1000\n",
      "225/225 [==============================] - 1s 2ms/step - loss: 0.4434 - accuracy: 0.8269 - val_loss: 0.4155 - val_accuracy: 0.8463\n",
      "Epoch 705/1000\n",
      "225/225 [==============================] - 1s 2ms/step - loss: 0.4461 - accuracy: 0.8276 - val_loss: 0.4186 - val_accuracy: 0.8457\n",
      "Epoch 706/1000\n",
      "225/225 [==============================] - 1s 2ms/step - loss: 0.4432 - accuracy: 0.8269 - val_loss: 0.4186 - val_accuracy: 0.8446\n",
      "Epoch 707/1000\n",
      "225/225 [==============================] - 1s 3ms/step - loss: 0.4421 - accuracy: 0.8277 - val_loss: 0.4182 - val_accuracy: 0.8458\n",
      "Epoch 708/1000\n",
      "225/225 [==============================] - 1s 2ms/step - loss: 0.4443 - accuracy: 0.8261 - val_loss: 0.4215 - val_accuracy: 0.8438\n",
      "Epoch 709/1000\n",
      "225/225 [==============================] - 1s 2ms/step - loss: 0.4424 - accuracy: 0.8274 - val_loss: 0.4187 - val_accuracy: 0.8456\n",
      "Epoch 710/1000\n",
      "225/225 [==============================] - 1s 3ms/step - loss: 0.4438 - accuracy: 0.8277 - val_loss: 0.4190 - val_accuracy: 0.8469\n",
      "Epoch 711/1000\n",
      "225/225 [==============================] - 1s 2ms/step - loss: 0.4421 - accuracy: 0.8275 - val_loss: 0.4211 - val_accuracy: 0.8463\n",
      "Epoch 712/1000\n",
      "225/225 [==============================] - 1s 2ms/step - loss: 0.4461 - accuracy: 0.8253 - val_loss: 0.4191 - val_accuracy: 0.8484\n",
      "Epoch 713/1000\n",
      "225/225 [==============================] - 1s 2ms/step - loss: 0.4435 - accuracy: 0.8272 - val_loss: 0.4198 - val_accuracy: 0.8460\n",
      "Epoch 714/1000\n",
      "225/225 [==============================] - 1s 2ms/step - loss: 0.4425 - accuracy: 0.8275 - val_loss: 0.4156 - val_accuracy: 0.8464\n",
      "Epoch 715/1000\n",
      "225/225 [==============================] - 1s 2ms/step - loss: 0.4419 - accuracy: 0.8277 - val_loss: 0.4167 - val_accuracy: 0.8469\n",
      "Epoch 716/1000\n",
      "225/225 [==============================] - 1s 2ms/step - loss: 0.4413 - accuracy: 0.8273 - val_loss: 0.4179 - val_accuracy: 0.8489\n",
      "Epoch 717/1000\n",
      "225/225 [==============================] - 1s 2ms/step - loss: 0.4447 - accuracy: 0.8284 - val_loss: 0.4198 - val_accuracy: 0.8460\n",
      "Epoch 718/1000\n",
      "225/225 [==============================] - 1s 2ms/step - loss: 0.4429 - accuracy: 0.8272 - val_loss: 0.4206 - val_accuracy: 0.8445\n",
      "Epoch 719/1000\n",
      "225/225 [==============================] - 1s 2ms/step - loss: 0.4431 - accuracy: 0.8278 - val_loss: 0.4184 - val_accuracy: 0.8453\n",
      "Epoch 720/1000\n",
      "225/225 [==============================] - 1s 2ms/step - loss: 0.4420 - accuracy: 0.8274 - val_loss: 0.4153 - val_accuracy: 0.8469\n",
      "Epoch 721/1000\n",
      "225/225 [==============================] - 1s 2ms/step - loss: 0.4407 - accuracy: 0.8287 - val_loss: 0.4169 - val_accuracy: 0.8464\n",
      "Epoch 722/1000\n",
      "225/225 [==============================] - 1s 2ms/step - loss: 0.4435 - accuracy: 0.8277 - val_loss: 0.4199 - val_accuracy: 0.8470\n",
      "Epoch 723/1000\n",
      "225/225 [==============================] - 1s 2ms/step - loss: 0.4428 - accuracy: 0.8273 - val_loss: 0.4199 - val_accuracy: 0.8461\n",
      "Epoch 724/1000\n",
      "225/225 [==============================] - 1s 2ms/step - loss: 0.4432 - accuracy: 0.8266 - val_loss: 0.4206 - val_accuracy: 0.8440\n",
      "Epoch 725/1000\n",
      "225/225 [==============================] - 1s 2ms/step - loss: 0.4436 - accuracy: 0.8273 - val_loss: 0.4192 - val_accuracy: 0.8463\n",
      "Epoch 726/1000\n",
      "225/225 [==============================] - 1s 2ms/step - loss: 0.4406 - accuracy: 0.8281 - val_loss: 0.4148 - val_accuracy: 0.8486\n",
      "Epoch 727/1000\n",
      "225/225 [==============================] - 1s 3ms/step - loss: 0.4426 - accuracy: 0.8277 - val_loss: 0.4163 - val_accuracy: 0.8482\n",
      "Epoch 728/1000\n",
      "225/225 [==============================] - 1s 2ms/step - loss: 0.4435 - accuracy: 0.8270 - val_loss: 0.4199 - val_accuracy: 0.8474\n",
      "Epoch 729/1000\n",
      "225/225 [==============================] - 1s 2ms/step - loss: 0.4426 - accuracy: 0.8274 - val_loss: 0.4187 - val_accuracy: 0.8471\n",
      "Epoch 730/1000\n",
      "225/225 [==============================] - 1s 2ms/step - loss: 0.4432 - accuracy: 0.8262 - val_loss: 0.4174 - val_accuracy: 0.8477\n",
      "Epoch 731/1000\n",
      "225/225 [==============================] - 1s 2ms/step - loss: 0.4422 - accuracy: 0.8274 - val_loss: 0.4175 - val_accuracy: 0.8471\n",
      "Epoch 732/1000\n",
      "225/225 [==============================] - 1s 2ms/step - loss: 0.4411 - accuracy: 0.8279 - val_loss: 0.4170 - val_accuracy: 0.8481\n",
      "Epoch 733/1000\n",
      "225/225 [==============================] - 1s 2ms/step - loss: 0.4431 - accuracy: 0.8284 - val_loss: 0.4177 - val_accuracy: 0.8466\n",
      "Epoch 734/1000\n",
      "225/225 [==============================] - 1s 3ms/step - loss: 0.4436 - accuracy: 0.8269 - val_loss: 0.4185 - val_accuracy: 0.8489\n",
      "Epoch 735/1000\n",
      "225/225 [==============================] - 1s 2ms/step - loss: 0.4442 - accuracy: 0.8258 - val_loss: 0.4182 - val_accuracy: 0.8462\n",
      "Epoch 736/1000\n",
      "225/225 [==============================] - 1s 2ms/step - loss: 0.4428 - accuracy: 0.8270 - val_loss: 0.4165 - val_accuracy: 0.8470\n",
      "Epoch 737/1000\n",
      "225/225 [==============================] - 1s 2ms/step - loss: 0.4415 - accuracy: 0.8276 - val_loss: 0.4178 - val_accuracy: 0.8471\n",
      "Epoch 738/1000\n",
      "225/225 [==============================] - 1s 2ms/step - loss: 0.4419 - accuracy: 0.8279 - val_loss: 0.4174 - val_accuracy: 0.8461\n",
      "Epoch 739/1000\n",
      "225/225 [==============================] - 1s 3ms/step - loss: 0.4425 - accuracy: 0.8283 - val_loss: 0.4161 - val_accuracy: 0.8479\n",
      "Epoch 740/1000\n",
      "225/225 [==============================] - 1s 3ms/step - loss: 0.4425 - accuracy: 0.8274 - val_loss: 0.4158 - val_accuracy: 0.8481\n",
      "Epoch 741/1000\n",
      "225/225 [==============================] - 1s 2ms/step - loss: 0.4411 - accuracy: 0.8274 - val_loss: 0.4170 - val_accuracy: 0.8457\n",
      "Epoch 742/1000\n",
      "225/225 [==============================] - 1s 2ms/step - loss: 0.4416 - accuracy: 0.8275 - val_loss: 0.4171 - val_accuracy: 0.8458\n",
      "Epoch 743/1000\n",
      "225/225 [==============================] - 1s 3ms/step - loss: 0.4411 - accuracy: 0.8281 - val_loss: 0.4170 - val_accuracy: 0.8468\n",
      "Epoch 744/1000\n",
      "225/225 [==============================] - 1s 2ms/step - loss: 0.4420 - accuracy: 0.8279 - val_loss: 0.4207 - val_accuracy: 0.8471\n",
      "Epoch 745/1000\n",
      "225/225 [==============================] - 1s 2ms/step - loss: 0.4432 - accuracy: 0.8268 - val_loss: 0.4158 - val_accuracy: 0.8467\n",
      "Epoch 746/1000\n",
      "225/225 [==============================] - 1s 2ms/step - loss: 0.4395 - accuracy: 0.8295 - val_loss: 0.4168 - val_accuracy: 0.8492\n",
      "Epoch 747/1000\n",
      "225/225 [==============================] - 1s 2ms/step - loss: 0.4429 - accuracy: 0.8277 - val_loss: 0.4174 - val_accuracy: 0.8500\n",
      "Epoch 748/1000\n",
      "225/225 [==============================] - 1s 2ms/step - loss: 0.4414 - accuracy: 0.8285 - val_loss: 0.4186 - val_accuracy: 0.8478\n",
      "Epoch 749/1000\n",
      "225/225 [==============================] - 1s 2ms/step - loss: 0.4408 - accuracy: 0.8272 - val_loss: 0.4184 - val_accuracy: 0.8452\n",
      "Epoch 750/1000\n",
      "225/225 [==============================] - 1s 2ms/step - loss: 0.4438 - accuracy: 0.8275 - val_loss: 0.4172 - val_accuracy: 0.8477\n",
      "Epoch 751/1000\n",
      "225/225 [==============================] - 1s 2ms/step - loss: 0.4415 - accuracy: 0.8277 - val_loss: 0.4162 - val_accuracy: 0.8484\n",
      "Epoch 752/1000\n",
      "225/225 [==============================] - 1s 2ms/step - loss: 0.4407 - accuracy: 0.8269 - val_loss: 0.4158 - val_accuracy: 0.8490\n",
      "Epoch 753/1000\n",
      "225/225 [==============================] - 1s 2ms/step - loss: 0.4434 - accuracy: 0.8265 - val_loss: 0.4161 - val_accuracy: 0.8494\n",
      "Epoch 754/1000\n",
      "225/225 [==============================] - 1s 2ms/step - loss: 0.4423 - accuracy: 0.8272 - val_loss: 0.4155 - val_accuracy: 0.8472\n",
      "Epoch 755/1000\n",
      "225/225 [==============================] - 1s 2ms/step - loss: 0.4417 - accuracy: 0.8276 - val_loss: 0.4194 - val_accuracy: 0.8474\n",
      "Epoch 756/1000\n",
      "225/225 [==============================] - 1s 2ms/step - loss: 0.4413 - accuracy: 0.8276 - val_loss: 0.4166 - val_accuracy: 0.8481\n",
      "Epoch 757/1000\n",
      "225/225 [==============================] - 1s 3ms/step - loss: 0.4415 - accuracy: 0.8276 - val_loss: 0.4169 - val_accuracy: 0.8471\n",
      "Epoch 758/1000\n",
      "225/225 [==============================] - 1s 3ms/step - loss: 0.4407 - accuracy: 0.8281 - val_loss: 0.4195 - val_accuracy: 0.8472\n",
      "Epoch 759/1000\n",
      "225/225 [==============================] - 1s 2ms/step - loss: 0.4407 - accuracy: 0.8277 - val_loss: 0.4180 - val_accuracy: 0.8462\n",
      "Epoch 760/1000\n",
      "225/225 [==============================] - 1s 2ms/step - loss: 0.4399 - accuracy: 0.8289 - val_loss: 0.4182 - val_accuracy: 0.8468\n",
      "Epoch 761/1000\n",
      "225/225 [==============================] - 1s 2ms/step - loss: 0.4401 - accuracy: 0.8291 - val_loss: 0.4174 - val_accuracy: 0.8463\n",
      "Epoch 762/1000\n",
      "225/225 [==============================] - 1s 2ms/step - loss: 0.4437 - accuracy: 0.8267 - val_loss: 0.4186 - val_accuracy: 0.8474\n",
      "Epoch 763/1000\n",
      "225/225 [==============================] - 1s 2ms/step - loss: 0.4413 - accuracy: 0.8289 - val_loss: 0.4188 - val_accuracy: 0.8472\n",
      "Epoch 764/1000\n",
      "225/225 [==============================] - 1s 2ms/step - loss: 0.4424 - accuracy: 0.8269 - val_loss: 0.4172 - val_accuracy: 0.8470\n",
      "Epoch 765/1000\n",
      "225/225 [==============================] - 1s 2ms/step - loss: 0.4421 - accuracy: 0.8274 - val_loss: 0.4149 - val_accuracy: 0.8480\n",
      "Epoch 766/1000\n",
      "225/225 [==============================] - 1s 2ms/step - loss: 0.4421 - accuracy: 0.8278 - val_loss: 0.4157 - val_accuracy: 0.8489\n",
      "Epoch 767/1000\n",
      "225/225 [==============================] - 1s 2ms/step - loss: 0.4410 - accuracy: 0.8275 - val_loss: 0.4199 - val_accuracy: 0.8470\n",
      "Epoch 768/1000\n",
      "225/225 [==============================] - 1s 3ms/step - loss: 0.4407 - accuracy: 0.8281 - val_loss: 0.4166 - val_accuracy: 0.8460\n",
      "Epoch 769/1000\n",
      "225/225 [==============================] - 1s 3ms/step - loss: 0.4423 - accuracy: 0.8274 - val_loss: 0.4166 - val_accuracy: 0.8477\n",
      "Epoch 770/1000\n",
      "225/225 [==============================] - 1s 2ms/step - loss: 0.4414 - accuracy: 0.8287 - val_loss: 0.4189 - val_accuracy: 0.8473\n",
      "Epoch 771/1000\n",
      "225/225 [==============================] - 1s 2ms/step - loss: 0.4403 - accuracy: 0.8285 - val_loss: 0.4171 - val_accuracy: 0.8484\n",
      "Epoch 772/1000\n",
      "225/225 [==============================] - 1s 2ms/step - loss: 0.4423 - accuracy: 0.8284 - val_loss: 0.4173 - val_accuracy: 0.8488\n",
      "Epoch 773/1000\n",
      "225/225 [==============================] - 1s 2ms/step - loss: 0.4398 - accuracy: 0.8289 - val_loss: 0.4167 - val_accuracy: 0.8479\n",
      "Epoch 774/1000\n",
      "225/225 [==============================] - 1s 2ms/step - loss: 0.4386 - accuracy: 0.8294 - val_loss: 0.4171 - val_accuracy: 0.8466\n",
      "Epoch 775/1000\n",
      "225/225 [==============================] - 1s 3ms/step - loss: 0.4426 - accuracy: 0.8275 - val_loss: 0.4193 - val_accuracy: 0.8465\n",
      "Epoch 776/1000\n",
      "225/225 [==============================] - 1s 2ms/step - loss: 0.4425 - accuracy: 0.8277 - val_loss: 0.4175 - val_accuracy: 0.8454\n",
      "Epoch 777/1000\n",
      "225/225 [==============================] - 1s 3ms/step - loss: 0.4401 - accuracy: 0.8297 - val_loss: 0.4152 - val_accuracy: 0.8479\n",
      "Epoch 778/1000\n",
      "225/225 [==============================] - 1s 2ms/step - loss: 0.4418 - accuracy: 0.8281 - val_loss: 0.4164 - val_accuracy: 0.8472\n",
      "Epoch 779/1000\n",
      "225/225 [==============================] - 1s 2ms/step - loss: 0.4410 - accuracy: 0.8271 - val_loss: 0.4191 - val_accuracy: 0.8483\n",
      "Epoch 780/1000\n",
      "225/225 [==============================] - 1s 2ms/step - loss: 0.4410 - accuracy: 0.8287 - val_loss: 0.4190 - val_accuracy: 0.8485\n",
      "Epoch 781/1000\n",
      "225/225 [==============================] - 1s 3ms/step - loss: 0.4432 - accuracy: 0.8272 - val_loss: 0.4189 - val_accuracy: 0.8446\n",
      "Epoch 782/1000\n",
      "225/225 [==============================] - 1s 2ms/step - loss: 0.4419 - accuracy: 0.8273 - val_loss: 0.4172 - val_accuracy: 0.8472\n",
      "Epoch 783/1000\n",
      "225/225 [==============================] - 1s 2ms/step - loss: 0.4415 - accuracy: 0.8283 - val_loss: 0.4185 - val_accuracy: 0.8470\n",
      "Epoch 784/1000\n",
      "225/225 [==============================] - 1s 2ms/step - loss: 0.4421 - accuracy: 0.8281 - val_loss: 0.4189 - val_accuracy: 0.8473\n",
      "Epoch 785/1000\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "225/225 [==============================] - 1s 2ms/step - loss: 0.4415 - accuracy: 0.8285 - val_loss: 0.4168 - val_accuracy: 0.8485\n",
      "Epoch 786/1000\n",
      "225/225 [==============================] - 1s 2ms/step - loss: 0.4426 - accuracy: 0.8284 - val_loss: 0.4159 - val_accuracy: 0.8503\n",
      "Epoch 787/1000\n",
      "225/225 [==============================] - 1s 3ms/step - loss: 0.4412 - accuracy: 0.8272 - val_loss: 0.4155 - val_accuracy: 0.8482\n",
      "Epoch 788/1000\n",
      "225/225 [==============================] - 1s 2ms/step - loss: 0.4408 - accuracy: 0.8281 - val_loss: 0.4168 - val_accuracy: 0.8478\n",
      "Epoch 789/1000\n",
      "225/225 [==============================] - 1s 2ms/step - loss: 0.4406 - accuracy: 0.8287 - val_loss: 0.4159 - val_accuracy: 0.8459\n",
      "Epoch 790/1000\n",
      "225/225 [==============================] - 1s 2ms/step - loss: 0.4422 - accuracy: 0.8276 - val_loss: 0.4171 - val_accuracy: 0.8462\n",
      "Epoch 791/1000\n",
      "225/225 [==============================] - 1s 2ms/step - loss: 0.4407 - accuracy: 0.8290 - val_loss: 0.4163 - val_accuracy: 0.8489\n",
      "Epoch 792/1000\n",
      "225/225 [==============================] - 1s 2ms/step - loss: 0.4417 - accuracy: 0.8276 - val_loss: 0.4158 - val_accuracy: 0.8474\n",
      "Epoch 793/1000\n",
      "225/225 [==============================] - 1s 2ms/step - loss: 0.4392 - accuracy: 0.8289 - val_loss: 0.4143 - val_accuracy: 0.8485\n",
      "Epoch 794/1000\n",
      "225/225 [==============================] - 1s 3ms/step - loss: 0.4413 - accuracy: 0.8289 - val_loss: 0.4169 - val_accuracy: 0.8496\n",
      "Epoch 795/1000\n",
      "225/225 [==============================] - 1s 2ms/step - loss: 0.4409 - accuracy: 0.8279 - val_loss: 0.4197 - val_accuracy: 0.8457\n",
      "Epoch 796/1000\n",
      "225/225 [==============================] - 1s 2ms/step - loss: 0.4411 - accuracy: 0.8276 - val_loss: 0.4174 - val_accuracy: 0.8496\n",
      "Epoch 797/1000\n",
      "225/225 [==============================] - 1s 3ms/step - loss: 0.4388 - accuracy: 0.8290 - val_loss: 0.4181 - val_accuracy: 0.8485\n",
      "Epoch 798/1000\n",
      "225/225 [==============================] - 1s 2ms/step - loss: 0.4388 - accuracy: 0.8293 - val_loss: 0.4172 - val_accuracy: 0.8479\n",
      "Epoch 799/1000\n",
      "225/225 [==============================] - 1s 2ms/step - loss: 0.4404 - accuracy: 0.8286 - val_loss: 0.4149 - val_accuracy: 0.8487\n",
      "Epoch 800/1000\n",
      "225/225 [==============================] - 1s 2ms/step - loss: 0.4407 - accuracy: 0.8287 - val_loss: 0.4138 - val_accuracy: 0.8481\n",
      "Epoch 801/1000\n",
      "225/225 [==============================] - 1s 2ms/step - loss: 0.4435 - accuracy: 0.8269 - val_loss: 0.4182 - val_accuracy: 0.8449\n",
      "Epoch 802/1000\n",
      "225/225 [==============================] - 1s 2ms/step - loss: 0.4419 - accuracy: 0.8275 - val_loss: 0.4158 - val_accuracy: 0.8486\n",
      "Epoch 803/1000\n",
      "225/225 [==============================] - 1s 2ms/step - loss: 0.4396 - accuracy: 0.8287 - val_loss: 0.4152 - val_accuracy: 0.8466\n",
      "Epoch 804/1000\n",
      "225/225 [==============================] - 1s 3ms/step - loss: 0.4394 - accuracy: 0.8294 - val_loss: 0.4190 - val_accuracy: 0.8470\n",
      "Epoch 805/1000\n",
      "225/225 [==============================] - 1s 2ms/step - loss: 0.4411 - accuracy: 0.8281 - val_loss: 0.4194 - val_accuracy: 0.8474\n",
      "Epoch 806/1000\n",
      "225/225 [==============================] - 1s 2ms/step - loss: 0.4385 - accuracy: 0.8279 - val_loss: 0.4160 - val_accuracy: 0.8465\n",
      "Epoch 807/1000\n",
      "225/225 [==============================] - 1s 3ms/step - loss: 0.4391 - accuracy: 0.8284 - val_loss: 0.4170 - val_accuracy: 0.8474\n",
      "Epoch 808/1000\n",
      "225/225 [==============================] - 1s 2ms/step - loss: 0.4385 - accuracy: 0.8288 - val_loss: 0.4145 - val_accuracy: 0.8477\n",
      "Epoch 809/1000\n",
      "225/225 [==============================] - 1s 2ms/step - loss: 0.4408 - accuracy: 0.8282 - val_loss: 0.4164 - val_accuracy: 0.8475\n",
      "Epoch 810/1000\n",
      "225/225 [==============================] - 1s 2ms/step - loss: 0.4407 - accuracy: 0.8292 - val_loss: 0.4169 - val_accuracy: 0.8487\n",
      "Epoch 811/1000\n",
      "225/225 [==============================] - 1s 2ms/step - loss: 0.4428 - accuracy: 0.8285 - val_loss: 0.4172 - val_accuracy: 0.8464\n",
      "Epoch 812/1000\n",
      "225/225 [==============================] - 1s 2ms/step - loss: 0.4415 - accuracy: 0.8270 - val_loss: 0.4189 - val_accuracy: 0.8459\n",
      "Epoch 813/1000\n",
      "225/225 [==============================] - 1s 2ms/step - loss: 0.4407 - accuracy: 0.8294 - val_loss: 0.4184 - val_accuracy: 0.8458\n",
      "Epoch 814/1000\n",
      "225/225 [==============================] - 1s 2ms/step - loss: 0.4405 - accuracy: 0.8271 - val_loss: 0.4196 - val_accuracy: 0.8456\n",
      "Epoch 815/1000\n",
      "225/225 [==============================] - 1s 2ms/step - loss: 0.4399 - accuracy: 0.8290 - val_loss: 0.4173 - val_accuracy: 0.8480\n",
      "Epoch 816/1000\n",
      "225/225 [==============================] - 1s 2ms/step - loss: 0.4384 - accuracy: 0.8297 - val_loss: 0.4162 - val_accuracy: 0.8486\n",
      "Epoch 817/1000\n",
      "225/225 [==============================] - 1s 2ms/step - loss: 0.4386 - accuracy: 0.8281 - val_loss: 0.4158 - val_accuracy: 0.8487\n",
      "Epoch 818/1000\n",
      "225/225 [==============================] - 1s 2ms/step - loss: 0.4417 - accuracy: 0.8283 - val_loss: 0.4174 - val_accuracy: 0.8483\n",
      "Epoch 819/1000\n",
      "225/225 [==============================] - 1s 2ms/step - loss: 0.4391 - accuracy: 0.8291 - val_loss: 0.4166 - val_accuracy: 0.8473\n",
      "Epoch 820/1000\n",
      "225/225 [==============================] - 1s 3ms/step - loss: 0.4395 - accuracy: 0.8289 - val_loss: 0.4186 - val_accuracy: 0.8466\n",
      "Epoch 821/1000\n",
      "225/225 [==============================] - 1s 2ms/step - loss: 0.4396 - accuracy: 0.8298 - val_loss: 0.4164 - val_accuracy: 0.8468\n",
      "Epoch 822/1000\n",
      "225/225 [==============================] - 1s 2ms/step - loss: 0.4398 - accuracy: 0.8295 - val_loss: 0.4156 - val_accuracy: 0.8473\n",
      "Epoch 823/1000\n",
      "225/225 [==============================] - 1s 2ms/step - loss: 0.4398 - accuracy: 0.8292 - val_loss: 0.4151 - val_accuracy: 0.8488\n",
      "Epoch 824/1000\n",
      "225/225 [==============================] - 1s 2ms/step - loss: 0.4400 - accuracy: 0.8289 - val_loss: 0.4166 - val_accuracy: 0.8499\n",
      "Epoch 825/1000\n",
      "225/225 [==============================] - 1s 2ms/step - loss: 0.4407 - accuracy: 0.8288 - val_loss: 0.4183 - val_accuracy: 0.8475\n",
      "Epoch 826/1000\n",
      "225/225 [==============================] - 1s 3ms/step - loss: 0.4397 - accuracy: 0.8290 - val_loss: 0.4172 - val_accuracy: 0.8474\n",
      "Epoch 827/1000\n",
      "225/225 [==============================] - 1s 3ms/step - loss: 0.4410 - accuracy: 0.8292 - val_loss: 0.4149 - val_accuracy: 0.8474\n",
      "Epoch 828/1000\n",
      "225/225 [==============================] - 1s 2ms/step - loss: 0.4391 - accuracy: 0.8297 - val_loss: 0.4191 - val_accuracy: 0.8477\n",
      "Epoch 829/1000\n",
      "225/225 [==============================] - 1s 2ms/step - loss: 0.4382 - accuracy: 0.8295 - val_loss: 0.4163 - val_accuracy: 0.8460\n",
      "Epoch 830/1000\n",
      "225/225 [==============================] - 1s 2ms/step - loss: 0.4418 - accuracy: 0.8275 - val_loss: 0.4175 - val_accuracy: 0.8468\n",
      "Epoch 831/1000\n",
      "225/225 [==============================] - 1s 2ms/step - loss: 0.4383 - accuracy: 0.8291 - val_loss: 0.4144 - val_accuracy: 0.8492\n",
      "Epoch 832/1000\n",
      "225/225 [==============================] - 1s 3ms/step - loss: 0.4383 - accuracy: 0.8293 - val_loss: 0.4151 - val_accuracy: 0.8497\n",
      "Epoch 833/1000\n",
      "225/225 [==============================] - 1s 2ms/step - loss: 0.4407 - accuracy: 0.8283 - val_loss: 0.4154 - val_accuracy: 0.8490\n",
      "Epoch 834/1000\n",
      "225/225 [==============================] - 1s 2ms/step - loss: 0.4392 - accuracy: 0.8294 - val_loss: 0.4132 - val_accuracy: 0.8478\n",
      "Epoch 835/1000\n",
      "225/225 [==============================] - 1s 2ms/step - loss: 0.4408 - accuracy: 0.8280 - val_loss: 0.4155 - val_accuracy: 0.8474\n",
      "Epoch 836/1000\n",
      "225/225 [==============================] - 1s 2ms/step - loss: 0.4394 - accuracy: 0.8285 - val_loss: 0.4170 - val_accuracy: 0.8479\n",
      "Epoch 837/1000\n",
      "225/225 [==============================] - 1s 3ms/step - loss: 0.4409 - accuracy: 0.8281 - val_loss: 0.4172 - val_accuracy: 0.8487\n",
      "Epoch 838/1000\n",
      "225/225 [==============================] - 1s 2ms/step - loss: 0.4394 - accuracy: 0.8288 - val_loss: 0.4166 - val_accuracy: 0.8475\n",
      "Epoch 839/1000\n",
      "225/225 [==============================] - 1s 3ms/step - loss: 0.4387 - accuracy: 0.8280 - val_loss: 0.4149 - val_accuracy: 0.8461\n",
      "Epoch 840/1000\n",
      "225/225 [==============================] - 1s 3ms/step - loss: 0.4378 - accuracy: 0.8301 - val_loss: 0.4146 - val_accuracy: 0.8489\n",
      "Epoch 841/1000\n",
      "225/225 [==============================] - 1s 2ms/step - loss: 0.4385 - accuracy: 0.8301 - val_loss: 0.4142 - val_accuracy: 0.8485\n",
      "Epoch 842/1000\n",
      "225/225 [==============================] - 1s 2ms/step - loss: 0.4423 - accuracy: 0.8278 - val_loss: 0.4194 - val_accuracy: 0.8465\n",
      "Epoch 843/1000\n",
      "225/225 [==============================] - 1s 2ms/step - loss: 0.4399 - accuracy: 0.8282 - val_loss: 0.4162 - val_accuracy: 0.8477\n",
      "Epoch 844/1000\n",
      "225/225 [==============================] - 1s 3ms/step - loss: 0.4405 - accuracy: 0.8289 - val_loss: 0.4152 - val_accuracy: 0.8480\n",
      "Epoch 845/1000\n",
      "225/225 [==============================] - 1s 3ms/step - loss: 0.4384 - accuracy: 0.8291 - val_loss: 0.4146 - val_accuracy: 0.8492\n",
      "Epoch 846/1000\n",
      "225/225 [==============================] - 1s 2ms/step - loss: 0.4393 - accuracy: 0.8291 - val_loss: 0.4131 - val_accuracy: 0.8507\n",
      "Epoch 847/1000\n",
      "225/225 [==============================] - 1s 2ms/step - loss: 0.4378 - accuracy: 0.8307 - val_loss: 0.4126 - val_accuracy: 0.8476\n",
      "Epoch 848/1000\n",
      "225/225 [==============================] - 1s 2ms/step - loss: 0.4382 - accuracy: 0.8296 - val_loss: 0.4134 - val_accuracy: 0.8507\n",
      "Epoch 849/1000\n",
      "225/225 [==============================] - 1s 2ms/step - loss: 0.4387 - accuracy: 0.8287 - val_loss: 0.4148 - val_accuracy: 0.8499\n",
      "Epoch 850/1000\n",
      "225/225 [==============================] - 1s 2ms/step - loss: 0.4407 - accuracy: 0.8279 - val_loss: 0.4149 - val_accuracy: 0.8472\n",
      "Epoch 851/1000\n",
      "225/225 [==============================] - 1s 2ms/step - loss: 0.4384 - accuracy: 0.8295 - val_loss: 0.4170 - val_accuracy: 0.8501\n",
      "Epoch 852/1000\n",
      "225/225 [==============================] - 1s 2ms/step - loss: 0.4391 - accuracy: 0.8291 - val_loss: 0.4148 - val_accuracy: 0.8481\n",
      "Epoch 853/1000\n",
      "225/225 [==============================] - 1s 2ms/step - loss: 0.4388 - accuracy: 0.8294 - val_loss: 0.4171 - val_accuracy: 0.8475\n",
      "Epoch 854/1000\n",
      "225/225 [==============================] - 1s 2ms/step - loss: 0.4411 - accuracy: 0.8283 - val_loss: 0.4184 - val_accuracy: 0.8469\n",
      "Epoch 855/1000\n",
      "225/225 [==============================] - 1s 3ms/step - loss: 0.4387 - accuracy: 0.8291 - val_loss: 0.4167 - val_accuracy: 0.8488\n",
      "Epoch 856/1000\n",
      "225/225 [==============================] - 1s 2ms/step - loss: 0.4387 - accuracy: 0.8300 - val_loss: 0.4151 - val_accuracy: 0.8500\n",
      "Epoch 857/1000\n",
      "225/225 [==============================] - 1s 2ms/step - loss: 0.4393 - accuracy: 0.8297 - val_loss: 0.4205 - val_accuracy: 0.8479\n",
      "Epoch 858/1000\n",
      "225/225 [==============================] - 1s 3ms/step - loss: 0.4376 - accuracy: 0.8296 - val_loss: 0.4165 - val_accuracy: 0.8492\n",
      "Epoch 859/1000\n",
      "225/225 [==============================] - 1s 3ms/step - loss: 0.4395 - accuracy: 0.8286 - val_loss: 0.4184 - val_accuracy: 0.8442\n",
      "Epoch 860/1000\n",
      "225/225 [==============================] - 1s 3ms/step - loss: 0.4406 - accuracy: 0.8285 - val_loss: 0.4185 - val_accuracy: 0.8466\n",
      "Epoch 861/1000\n",
      "225/225 [==============================] - 1s 2ms/step - loss: 0.4387 - accuracy: 0.8307 - val_loss: 0.4160 - val_accuracy: 0.8483\n",
      "Epoch 862/1000\n",
      "225/225 [==============================] - 1s 2ms/step - loss: 0.4403 - accuracy: 0.8282 - val_loss: 0.4187 - val_accuracy: 0.8463\n",
      "Epoch 863/1000\n",
      "225/225 [==============================] - 1s 2ms/step - loss: 0.4378 - accuracy: 0.8304 - val_loss: 0.4156 - val_accuracy: 0.8474\n",
      "Epoch 864/1000\n",
      "225/225 [==============================] - 1s 2ms/step - loss: 0.4390 - accuracy: 0.8287 - val_loss: 0.4153 - val_accuracy: 0.8500\n",
      "Epoch 865/1000\n",
      "225/225 [==============================] - 1s 3ms/step - loss: 0.4390 - accuracy: 0.8287 - val_loss: 0.4136 - val_accuracy: 0.8483\n",
      "Epoch 866/1000\n",
      "225/225 [==============================] - 1s 2ms/step - loss: 0.4354 - accuracy: 0.8308 - val_loss: 0.4138 - val_accuracy: 0.8485\n",
      "Epoch 867/1000\n",
      "225/225 [==============================] - 1s 2ms/step - loss: 0.4414 - accuracy: 0.8282 - val_loss: 0.4172 - val_accuracy: 0.8476\n",
      "Epoch 868/1000\n",
      "225/225 [==============================] - 1s 3ms/step - loss: 0.4383 - accuracy: 0.8293 - val_loss: 0.4143 - val_accuracy: 0.8486\n",
      "Epoch 869/1000\n",
      "225/225 [==============================] - 1s 2ms/step - loss: 0.4391 - accuracy: 0.8299 - val_loss: 0.4169 - val_accuracy: 0.8474\n",
      "Epoch 870/1000\n",
      "225/225 [==============================] - 1s 3ms/step - loss: 0.4368 - accuracy: 0.8303 - val_loss: 0.4168 - val_accuracy: 0.8478\n",
      "Epoch 871/1000\n",
      "225/225 [==============================] - 1s 2ms/step - loss: 0.4432 - accuracy: 0.8281 - val_loss: 0.4178 - val_accuracy: 0.8492\n",
      "Epoch 872/1000\n",
      "225/225 [==============================] - 1s 2ms/step - loss: 0.4374 - accuracy: 0.8299 - val_loss: 0.4178 - val_accuracy: 0.8470\n",
      "Epoch 873/1000\n",
      "225/225 [==============================] - 1s 2ms/step - loss: 0.4378 - accuracy: 0.8296 - val_loss: 0.4169 - val_accuracy: 0.8484\n",
      "Epoch 874/1000\n",
      "225/225 [==============================] - 1s 2ms/step - loss: 0.4394 - accuracy: 0.8296 - val_loss: 0.4155 - val_accuracy: 0.8485\n",
      "Epoch 875/1000\n",
      "225/225 [==============================] - 1s 2ms/step - loss: 0.4394 - accuracy: 0.8295 - val_loss: 0.4172 - val_accuracy: 0.8486\n",
      "Epoch 876/1000\n",
      "225/225 [==============================] - 1s 2ms/step - loss: 0.4402 - accuracy: 0.8285 - val_loss: 0.4194 - val_accuracy: 0.8463\n",
      "Epoch 877/1000\n",
      "225/225 [==============================] - 1s 3ms/step - loss: 0.4403 - accuracy: 0.8282 - val_loss: 0.4185 - val_accuracy: 0.8479\n",
      "Epoch 878/1000\n",
      "225/225 [==============================] - 1s 2ms/step - loss: 0.4405 - accuracy: 0.8299 - val_loss: 0.4172 - val_accuracy: 0.8478\n",
      "Epoch 879/1000\n",
      "225/225 [==============================] - 1s 2ms/step - loss: 0.4388 - accuracy: 0.8294 - val_loss: 0.4163 - val_accuracy: 0.8481\n",
      "Epoch 880/1000\n",
      "225/225 [==============================] - 1s 2ms/step - loss: 0.4358 - accuracy: 0.8314 - val_loss: 0.4140 - val_accuracy: 0.8493\n",
      "Epoch 881/1000\n",
      "225/225 [==============================] - 1s 2ms/step - loss: 0.4372 - accuracy: 0.8297 - val_loss: 0.4137 - val_accuracy: 0.8485\n",
      "Epoch 882/1000\n",
      "225/225 [==============================] - 1s 2ms/step - loss: 0.4387 - accuracy: 0.8297 - val_loss: 0.4131 - val_accuracy: 0.8481\n",
      "Epoch 883/1000\n",
      "225/225 [==============================] - 1s 3ms/step - loss: 0.4393 - accuracy: 0.8291 - val_loss: 0.4175 - val_accuracy: 0.8480\n",
      "Epoch 884/1000\n",
      "225/225 [==============================] - 1s 2ms/step - loss: 0.4386 - accuracy: 0.8284 - val_loss: 0.4148 - val_accuracy: 0.8493\n",
      "Epoch 885/1000\n",
      "225/225 [==============================] - 1s 2ms/step - loss: 0.4388 - accuracy: 0.8288 - val_loss: 0.4166 - val_accuracy: 0.8482\n",
      "Epoch 886/1000\n",
      "225/225 [==============================] - 1s 2ms/step - loss: 0.4407 - accuracy: 0.8293 - val_loss: 0.4128 - val_accuracy: 0.8492\n",
      "Epoch 887/1000\n",
      "225/225 [==============================] - 1s 2ms/step - loss: 0.4377 - accuracy: 0.8310 - val_loss: 0.4134 - val_accuracy: 0.8490\n",
      "Epoch 888/1000\n",
      "225/225 [==============================] - 1s 2ms/step - loss: 0.4378 - accuracy: 0.8295 - val_loss: 0.4185 - val_accuracy: 0.8471\n",
      "Epoch 889/1000\n",
      "225/225 [==============================] - 1s 2ms/step - loss: 0.4388 - accuracy: 0.8294 - val_loss: 0.4140 - val_accuracy: 0.8500\n",
      "Epoch 890/1000\n",
      "225/225 [==============================] - 1s 2ms/step - loss: 0.4384 - accuracy: 0.8287 - val_loss: 0.4169 - val_accuracy: 0.8477\n",
      "Epoch 891/1000\n",
      "225/225 [==============================] - 1s 2ms/step - loss: 0.4377 - accuracy: 0.8309 - val_loss: 0.4113 - val_accuracy: 0.8494\n",
      "Epoch 892/1000\n",
      "225/225 [==============================] - 1s 2ms/step - loss: 0.4413 - accuracy: 0.8280 - val_loss: 0.4152 - val_accuracy: 0.8491\n",
      "Epoch 893/1000\n",
      "225/225 [==============================] - 1s 2ms/step - loss: 0.4385 - accuracy: 0.8290 - val_loss: 0.4157 - val_accuracy: 0.8471\n",
      "Epoch 894/1000\n",
      "225/225 [==============================] - 1s 2ms/step - loss: 0.4361 - accuracy: 0.8304 - val_loss: 0.4144 - val_accuracy: 0.8497\n",
      "Epoch 895/1000\n",
      "225/225 [==============================] - 1s 2ms/step - loss: 0.4379 - accuracy: 0.8288 - val_loss: 0.4152 - val_accuracy: 0.8489\n",
      "Epoch 896/1000\n",
      "225/225 [==============================] - 1s 2ms/step - loss: 0.4378 - accuracy: 0.8306 - val_loss: 0.4142 - val_accuracy: 0.8488\n",
      "Epoch 897/1000\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "225/225 [==============================] - 1s 2ms/step - loss: 0.4383 - accuracy: 0.8282 - val_loss: 0.4132 - val_accuracy: 0.8484\n",
      "Epoch 898/1000\n",
      "225/225 [==============================] - 1s 2ms/step - loss: 0.4387 - accuracy: 0.8289 - val_loss: 0.4141 - val_accuracy: 0.8474\n",
      "Epoch 899/1000\n",
      "225/225 [==============================] - 1s 3ms/step - loss: 0.4389 - accuracy: 0.8291 - val_loss: 0.4160 - val_accuracy: 0.8492\n",
      "Epoch 900/1000\n",
      "225/225 [==============================] - 1s 3ms/step - loss: 0.4381 - accuracy: 0.8295 - val_loss: 0.4128 - val_accuracy: 0.8496\n",
      "Epoch 901/1000\n",
      "225/225 [==============================] - 1s 2ms/step - loss: 0.4371 - accuracy: 0.8308 - val_loss: 0.4151 - val_accuracy: 0.8492\n",
      "Epoch 902/1000\n",
      "225/225 [==============================] - 1s 2ms/step - loss: 0.4385 - accuracy: 0.8301 - val_loss: 0.4151 - val_accuracy: 0.8498\n",
      "Epoch 903/1000\n",
      "225/225 [==============================] - 1s 2ms/step - loss: 0.4387 - accuracy: 0.8298 - val_loss: 0.4146 - val_accuracy: 0.8481\n",
      "Epoch 904/1000\n",
      "225/225 [==============================] - 1s 3ms/step - loss: 0.4378 - accuracy: 0.8306 - val_loss: 0.4126 - val_accuracy: 0.8498\n",
      "Epoch 905/1000\n",
      "225/225 [==============================] - 1s 2ms/step - loss: 0.4377 - accuracy: 0.8297 - val_loss: 0.4148 - val_accuracy: 0.8492\n",
      "Epoch 906/1000\n",
      "225/225 [==============================] - 1s 2ms/step - loss: 0.4380 - accuracy: 0.8290 - val_loss: 0.4118 - val_accuracy: 0.8479\n",
      "Epoch 907/1000\n",
      "225/225 [==============================] - 1s 2ms/step - loss: 0.4388 - accuracy: 0.8296 - val_loss: 0.4127 - val_accuracy: 0.8482\n",
      "Epoch 908/1000\n",
      "225/225 [==============================] - 1s 2ms/step - loss: 0.4380 - accuracy: 0.8294 - val_loss: 0.4143 - val_accuracy: 0.8495\n",
      "Epoch 909/1000\n",
      "225/225 [==============================] - 1s 2ms/step - loss: 0.4369 - accuracy: 0.8313 - val_loss: 0.4178 - val_accuracy: 0.8472\n",
      "Epoch 910/1000\n",
      "225/225 [==============================] - 1s 2ms/step - loss: 0.4401 - accuracy: 0.8292 - val_loss: 0.4169 - val_accuracy: 0.8463\n",
      "Epoch 911/1000\n",
      "225/225 [==============================] - 1s 2ms/step - loss: 0.4387 - accuracy: 0.8296 - val_loss: 0.4146 - val_accuracy: 0.8490\n",
      "Epoch 912/1000\n",
      "225/225 [==============================] - 1s 3ms/step - loss: 0.4366 - accuracy: 0.8304 - val_loss: 0.4157 - val_accuracy: 0.8486\n",
      "Epoch 913/1000\n",
      "225/225 [==============================] - 1s 2ms/step - loss: 0.4389 - accuracy: 0.8286 - val_loss: 0.4168 - val_accuracy: 0.8488\n",
      "Epoch 914/1000\n",
      "225/225 [==============================] - 1s 3ms/step - loss: 0.4375 - accuracy: 0.8300 - val_loss: 0.4145 - val_accuracy: 0.8482\n",
      "Epoch 915/1000\n",
      "225/225 [==============================] - 1s 2ms/step - loss: 0.4382 - accuracy: 0.8306 - val_loss: 0.4131 - val_accuracy: 0.8480\n",
      "Epoch 916/1000\n",
      "225/225 [==============================] - 1s 2ms/step - loss: 0.4408 - accuracy: 0.8285 - val_loss: 0.4158 - val_accuracy: 0.8498\n",
      "Epoch 917/1000\n",
      "225/225 [==============================] - 1s 2ms/step - loss: 0.4390 - accuracy: 0.8286 - val_loss: 0.4148 - val_accuracy: 0.8471\n",
      "Epoch 918/1000\n",
      "225/225 [==============================] - 1s 2ms/step - loss: 0.4380 - accuracy: 0.8287 - val_loss: 0.4153 - val_accuracy: 0.8467\n",
      "Epoch 919/1000\n",
      "225/225 [==============================] - 1s 3ms/step - loss: 0.4387 - accuracy: 0.8288 - val_loss: 0.4154 - val_accuracy: 0.8492\n",
      "Epoch 920/1000\n",
      "225/225 [==============================] - 1s 2ms/step - loss: 0.4375 - accuracy: 0.8292 - val_loss: 0.4170 - val_accuracy: 0.8500\n",
      "Epoch 921/1000\n",
      "225/225 [==============================] - 1s 2ms/step - loss: 0.4378 - accuracy: 0.8305 - val_loss: 0.4157 - val_accuracy: 0.8492\n",
      "Epoch 922/1000\n",
      "225/225 [==============================] - 1s 2ms/step - loss: 0.4369 - accuracy: 0.8300 - val_loss: 0.4149 - val_accuracy: 0.8466\n",
      "Epoch 923/1000\n",
      "225/225 [==============================] - 1s 2ms/step - loss: 0.4397 - accuracy: 0.8286 - val_loss: 0.4181 - val_accuracy: 0.8467\n",
      "Epoch 924/1000\n",
      "225/225 [==============================] - 1s 2ms/step - loss: 0.4379 - accuracy: 0.8284 - val_loss: 0.4138 - val_accuracy: 0.8473\n",
      "Epoch 925/1000\n",
      "225/225 [==============================] - 1s 2ms/step - loss: 0.4391 - accuracy: 0.8286 - val_loss: 0.4158 - val_accuracy: 0.8473\n",
      "Epoch 926/1000\n",
      "225/225 [==============================] - 1s 2ms/step - loss: 0.4363 - accuracy: 0.8295 - val_loss: 0.4155 - val_accuracy: 0.8452\n",
      "Epoch 927/1000\n",
      "225/225 [==============================] - 1s 2ms/step - loss: 0.4364 - accuracy: 0.8304 - val_loss: 0.4143 - val_accuracy: 0.8473\n",
      "Epoch 928/1000\n",
      "225/225 [==============================] - 1s 2ms/step - loss: 0.4391 - accuracy: 0.8297 - val_loss: 0.4164 - val_accuracy: 0.8490\n",
      "Epoch 929/1000\n",
      "225/225 [==============================] - 1s 2ms/step - loss: 0.4393 - accuracy: 0.8295 - val_loss: 0.4151 - val_accuracy: 0.8490\n",
      "Epoch 930/1000\n",
      "225/225 [==============================] - 1s 2ms/step - loss: 0.4385 - accuracy: 0.8293 - val_loss: 0.4154 - val_accuracy: 0.8475\n",
      "Epoch 931/1000\n",
      "225/225 [==============================] - 1s 2ms/step - loss: 0.4376 - accuracy: 0.8303 - val_loss: 0.4154 - val_accuracy: 0.8469\n",
      "Epoch 932/1000\n",
      "225/225 [==============================] - 1s 2ms/step - loss: 0.4379 - accuracy: 0.8293 - val_loss: 0.4137 - val_accuracy: 0.8486\n",
      "Epoch 933/1000\n",
      "225/225 [==============================] - 1s 2ms/step - loss: 0.4370 - accuracy: 0.8299 - val_loss: 0.4146 - val_accuracy: 0.8497\n",
      "Epoch 934/1000\n",
      "225/225 [==============================] - 1s 2ms/step - loss: 0.4390 - accuracy: 0.8293 - val_loss: 0.4118 - val_accuracy: 0.8489\n",
      "Epoch 935/1000\n",
      "225/225 [==============================] - 1s 2ms/step - loss: 0.4382 - accuracy: 0.8289 - val_loss: 0.4148 - val_accuracy: 0.8469\n",
      "Epoch 936/1000\n",
      "225/225 [==============================] - 1s 2ms/step - loss: 0.4378 - accuracy: 0.8287 - val_loss: 0.4134 - val_accuracy: 0.8462\n",
      "Epoch 937/1000\n",
      "225/225 [==============================] - 1s 2ms/step - loss: 0.4369 - accuracy: 0.8300 - val_loss: 0.4165 - val_accuracy: 0.8490\n",
      "Epoch 938/1000\n",
      "225/225 [==============================] - 1s 2ms/step - loss: 0.4376 - accuracy: 0.8283 - val_loss: 0.4159 - val_accuracy: 0.8474\n",
      "Epoch 939/1000\n",
      "225/225 [==============================] - 1s 2ms/step - loss: 0.4354 - accuracy: 0.8308 - val_loss: 0.4142 - val_accuracy: 0.8477\n",
      "Epoch 940/1000\n",
      "225/225 [==============================] - 1s 2ms/step - loss: 0.4386 - accuracy: 0.8289 - val_loss: 0.4150 - val_accuracy: 0.8492\n",
      "Epoch 941/1000\n",
      "225/225 [==============================] - 1s 3ms/step - loss: 0.4363 - accuracy: 0.8312 - val_loss: 0.4165 - val_accuracy: 0.8485\n",
      "Epoch 942/1000\n",
      "225/225 [==============================] - 1s 3ms/step - loss: 0.4369 - accuracy: 0.8299 - val_loss: 0.4144 - val_accuracy: 0.8490\n",
      "Epoch 943/1000\n",
      "225/225 [==============================] - 1s 2ms/step - loss: 0.4370 - accuracy: 0.8294 - val_loss: 0.4140 - val_accuracy: 0.8503\n",
      "Epoch 944/1000\n",
      "225/225 [==============================] - 1s 2ms/step - loss: 0.4367 - accuracy: 0.8308 - val_loss: 0.4116 - val_accuracy: 0.8491\n",
      "Epoch 945/1000\n",
      "225/225 [==============================] - 1s 2ms/step - loss: 0.4386 - accuracy: 0.8297 - val_loss: 0.4148 - val_accuracy: 0.8485\n",
      "Epoch 946/1000\n",
      "225/225 [==============================] - 1s 2ms/step - loss: 0.4372 - accuracy: 0.8301 - val_loss: 0.4164 - val_accuracy: 0.8477\n",
      "Epoch 947/1000\n",
      "225/225 [==============================] - 1s 3ms/step - loss: 0.4372 - accuracy: 0.8298 - val_loss: 0.4126 - val_accuracy: 0.8495\n",
      "Epoch 948/1000\n",
      "225/225 [==============================] - 1s 2ms/step - loss: 0.4366 - accuracy: 0.8301 - val_loss: 0.4128 - val_accuracy: 0.8485\n",
      "Epoch 949/1000\n",
      "225/225 [==============================] - 1s 2ms/step - loss: 0.4384 - accuracy: 0.8299 - val_loss: 0.4128 - val_accuracy: 0.8519\n",
      "Epoch 950/1000\n",
      "225/225 [==============================] - 1s 2ms/step - loss: 0.4361 - accuracy: 0.8308 - val_loss: 0.4151 - val_accuracy: 0.8476\n",
      "Epoch 951/1000\n",
      "225/225 [==============================] - 1s 2ms/step - loss: 0.4363 - accuracy: 0.8310 - val_loss: 0.4159 - val_accuracy: 0.8477\n",
      "Epoch 952/1000\n",
      "225/225 [==============================] - 1s 2ms/step - loss: 0.4362 - accuracy: 0.8307 - val_loss: 0.4141 - val_accuracy: 0.8471\n",
      "Epoch 953/1000\n",
      "225/225 [==============================] - 1s 2ms/step - loss: 0.4369 - accuracy: 0.8297 - val_loss: 0.4143 - val_accuracy: 0.8500\n",
      "Epoch 954/1000\n",
      "225/225 [==============================] - 1s 2ms/step - loss: 0.4364 - accuracy: 0.8308 - val_loss: 0.4119 - val_accuracy: 0.8483\n",
      "Epoch 955/1000\n",
      "225/225 [==============================] - 1s 2ms/step - loss: 0.4360 - accuracy: 0.8307 - val_loss: 0.4136 - val_accuracy: 0.8489\n",
      "Epoch 956/1000\n",
      "225/225 [==============================] - 1s 2ms/step - loss: 0.4369 - accuracy: 0.8301 - val_loss: 0.4132 - val_accuracy: 0.8487\n",
      "Epoch 957/1000\n",
      "225/225 [==============================] - 1s 2ms/step - loss: 0.4366 - accuracy: 0.8295 - val_loss: 0.4138 - val_accuracy: 0.8482\n",
      "Epoch 958/1000\n",
      "225/225 [==============================] - 1s 2ms/step - loss: 0.4375 - accuracy: 0.8312 - val_loss: 0.4145 - val_accuracy: 0.8474\n",
      "Epoch 959/1000\n",
      "225/225 [==============================] - 1s 2ms/step - loss: 0.4386 - accuracy: 0.8291 - val_loss: 0.4163 - val_accuracy: 0.8479\n",
      "Epoch 960/1000\n",
      "225/225 [==============================] - 1s 2ms/step - loss: 0.4359 - accuracy: 0.8311 - val_loss: 0.4106 - val_accuracy: 0.8507\n",
      "Epoch 961/1000\n",
      "225/225 [==============================] - 1s 2ms/step - loss: 0.4377 - accuracy: 0.8307 - val_loss: 0.4150 - val_accuracy: 0.8469\n",
      "Epoch 962/1000\n",
      "225/225 [==============================] - 1s 2ms/step - loss: 0.4373 - accuracy: 0.8295 - val_loss: 0.4126 - val_accuracy: 0.8475\n",
      "Epoch 963/1000\n",
      "225/225 [==============================] - 1s 2ms/step - loss: 0.4359 - accuracy: 0.8306 - val_loss: 0.4122 - val_accuracy: 0.8501\n",
      "Epoch 964/1000\n",
      "225/225 [==============================] - 1s 2ms/step - loss: 0.4359 - accuracy: 0.8300 - val_loss: 0.4136 - val_accuracy: 0.8480\n",
      "Epoch 965/1000\n",
      "225/225 [==============================] - 1s 2ms/step - loss: 0.4348 - accuracy: 0.8308 - val_loss: 0.4124 - val_accuracy: 0.8491\n",
      "Epoch 966/1000\n",
      "225/225 [==============================] - 1s 2ms/step - loss: 0.4369 - accuracy: 0.8298 - val_loss: 0.4144 - val_accuracy: 0.8500\n",
      "Epoch 967/1000\n",
      "225/225 [==============================] - 1s 2ms/step - loss: 0.4349 - accuracy: 0.8306 - val_loss: 0.4158 - val_accuracy: 0.8473\n",
      "Epoch 968/1000\n",
      "225/225 [==============================] - 1s 2ms/step - loss: 0.4361 - accuracy: 0.8292 - val_loss: 0.4132 - val_accuracy: 0.8500\n",
      "Epoch 969/1000\n",
      "225/225 [==============================] - 1s 2ms/step - loss: 0.4360 - accuracy: 0.8305 - val_loss: 0.4164 - val_accuracy: 0.8465\n",
      "Epoch 970/1000\n",
      "225/225 [==============================] - 1s 2ms/step - loss: 0.4379 - accuracy: 0.8299 - val_loss: 0.4141 - val_accuracy: 0.8482\n",
      "Epoch 971/1000\n",
      "225/225 [==============================] - 1s 3ms/step - loss: 0.4376 - accuracy: 0.8299 - val_loss: 0.4135 - val_accuracy: 0.8499\n",
      "Epoch 972/1000\n",
      "225/225 [==============================] - 1s 2ms/step - loss: 0.4367 - accuracy: 0.8310 - val_loss: 0.4132 - val_accuracy: 0.8505\n",
      "Epoch 973/1000\n",
      "225/225 [==============================] - 1s 2ms/step - loss: 0.4376 - accuracy: 0.8290 - val_loss: 0.4156 - val_accuracy: 0.8492\n",
      "Epoch 974/1000\n",
      "225/225 [==============================] - 1s 3ms/step - loss: 0.4360 - accuracy: 0.8306 - val_loss: 0.4144 - val_accuracy: 0.8494\n",
      "Epoch 975/1000\n",
      "225/225 [==============================] - 1s 2ms/step - loss: 0.4364 - accuracy: 0.8310 - val_loss: 0.4154 - val_accuracy: 0.8495\n",
      "Epoch 976/1000\n",
      "225/225 [==============================] - 1s 2ms/step - loss: 0.4368 - accuracy: 0.8305 - val_loss: 0.4162 - val_accuracy: 0.8497\n",
      "Epoch 977/1000\n",
      "225/225 [==============================] - 1s 2ms/step - loss: 0.4364 - accuracy: 0.8300 - val_loss: 0.4157 - val_accuracy: 0.8486\n",
      "Epoch 978/1000\n",
      "225/225 [==============================] - 1s 3ms/step - loss: 0.4347 - accuracy: 0.8310 - val_loss: 0.4156 - val_accuracy: 0.8475\n",
      "Epoch 979/1000\n",
      "225/225 [==============================] - 1s 2ms/step - loss: 0.4372 - accuracy: 0.8305 - val_loss: 0.4140 - val_accuracy: 0.8512\n",
      "Epoch 980/1000\n",
      "225/225 [==============================] - 1s 2ms/step - loss: 0.4356 - accuracy: 0.8288 - val_loss: 0.4126 - val_accuracy: 0.8483\n",
      "Epoch 981/1000\n",
      "225/225 [==============================] - 1s 2ms/step - loss: 0.4354 - accuracy: 0.8314 - val_loss: 0.4094 - val_accuracy: 0.8517\n",
      "Epoch 982/1000\n",
      "225/225 [==============================] - 1s 3ms/step - loss: 0.4396 - accuracy: 0.8301 - val_loss: 0.4130 - val_accuracy: 0.8499\n",
      "Epoch 983/1000\n",
      "225/225 [==============================] - 1s 2ms/step - loss: 0.4348 - accuracy: 0.8306 - val_loss: 0.4168 - val_accuracy: 0.8498\n",
      "Epoch 984/1000\n",
      "225/225 [==============================] - 1s 2ms/step - loss: 0.4365 - accuracy: 0.8298 - val_loss: 0.4137 - val_accuracy: 0.8517\n",
      "Epoch 985/1000\n",
      "225/225 [==============================] - 1s 3ms/step - loss: 0.4334 - accuracy: 0.8318 - val_loss: 0.4135 - val_accuracy: 0.8479\n",
      "Epoch 986/1000\n",
      "225/225 [==============================] - 1s 2ms/step - loss: 0.4365 - accuracy: 0.8315 - val_loss: 0.4157 - val_accuracy: 0.8473\n",
      "Epoch 987/1000\n",
      "225/225 [==============================] - 1s 3ms/step - loss: 0.4363 - accuracy: 0.8305 - val_loss: 0.4123 - val_accuracy: 0.8483\n",
      "Epoch 988/1000\n",
      "225/225 [==============================] - 1s 2ms/step - loss: 0.4378 - accuracy: 0.8293 - val_loss: 0.4137 - val_accuracy: 0.8484\n",
      "Epoch 989/1000\n",
      "225/225 [==============================] - 1s 2ms/step - loss: 0.4390 - accuracy: 0.8297 - val_loss: 0.4125 - val_accuracy: 0.8480\n",
      "Epoch 990/1000\n",
      "225/225 [==============================] - 1s 2ms/step - loss: 0.4350 - accuracy: 0.8314 - val_loss: 0.4119 - val_accuracy: 0.8486\n",
      "Epoch 991/1000\n",
      "225/225 [==============================] - 1s 2ms/step - loss: 0.4385 - accuracy: 0.8299 - val_loss: 0.4114 - val_accuracy: 0.8492\n",
      "Epoch 992/1000\n",
      "225/225 [==============================] - 1s 2ms/step - loss: 0.4360 - accuracy: 0.8308 - val_loss: 0.4139 - val_accuracy: 0.8508\n",
      "Epoch 993/1000\n",
      "225/225 [==============================] - 1s 3ms/step - loss: 0.4350 - accuracy: 0.8311 - val_loss: 0.4134 - val_accuracy: 0.8470\n",
      "Epoch 994/1000\n",
      "225/225 [==============================] - 1s 2ms/step - loss: 0.4354 - accuracy: 0.8311 - val_loss: 0.4145 - val_accuracy: 0.8485\n",
      "Epoch 995/1000\n",
      "225/225 [==============================] - 1s 2ms/step - loss: 0.4349 - accuracy: 0.8303 - val_loss: 0.4154 - val_accuracy: 0.8496\n",
      "Epoch 996/1000\n",
      "225/225 [==============================] - 1s 2ms/step - loss: 0.4364 - accuracy: 0.8298 - val_loss: 0.4136 - val_accuracy: 0.8487\n",
      "Epoch 997/1000\n",
      "225/225 [==============================] - 1s 2ms/step - loss: 0.4360 - accuracy: 0.8311 - val_loss: 0.4124 - val_accuracy: 0.8489\n",
      "Epoch 998/1000\n",
      "225/225 [==============================] - 1s 2ms/step - loss: 0.4349 - accuracy: 0.8307 - val_loss: 0.4126 - val_accuracy: 0.8493\n",
      "Epoch 999/1000\n",
      "225/225 [==============================] - 1s 3ms/step - loss: 0.4374 - accuracy: 0.8304 - val_loss: 0.4121 - val_accuracy: 0.8494\n",
      "Epoch 1000/1000\n",
      "225/225 [==============================] - 1s 3ms/step - loss: 0.4374 - accuracy: 0.8299 - val_loss: 0.4139 - val_accuracy: 0.8483\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "<keras.src.callbacks.History at 0x14473d2a0>"
      ]
     },
     "execution_count": 215,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "model=Sequential()\n",
    "model.add(Dense(128, input_dim=X_train.shape[1], activation=\"relu\"))\n",
    "model.add(Dropout(0.2))\n",
    "model.add(Dense(128, activation=\"relu\"))\n",
    "model.add(BatchNormalization())\n",
    "model.add(Dense(64, activation=\"relu\"))\n",
    "model.add(Dropout(0.2))\n",
    "model.add(Dense(64, activation=\"relu\"))\n",
    "model.add(BatchNormalization())\n",
    "model.add(Dense(32, activation=\"relu\"))\n",
    "model.add(Dropout(0.2))\n",
    "model.add(Dense(16, activation=\"relu\"))\n",
    "\n",
    "model.add(Dense(3, activation=\"softmax\"))\n",
    "\n",
    "optimizer = tf.keras.optimizers.legacy.Nadam(learning_rate=0.001)\n",
    "model.compile(loss='categorical_crossentropy', optimizer=optimizer, metrics=['accuracy'])\n",
    "\n",
    "es=EarlyStopping(monitor=\"val_loss\",patience=90,mode=\"auto\",verbose=1)\n",
    "\n",
    "model.fit(X_train, y_train,epochs=1000,batch_size=512,validation_split=0.1,verbose=1,callbacks=[es])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 216,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "997/997 [==============================] - 0s 293us/step\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0       0.86      0.93      0.89     10867\n",
      "           1       0.84      0.90      0.87     10432\n",
      "           2       0.84      0.70      0.76     10591\n",
      "\n",
      "    accuracy                           0.85     31890\n",
      "   macro avg       0.85      0.85      0.84     31890\n",
      "weighted avg       0.85      0.85      0.84     31890\n",
      "\n"
     ]
    }
   ],
   "source": [
    "y_pred = model.predict(X_test)\n",
    "y_pred_classes = np.argmax(y_pred, axis=1)\n",
    "y_true = np.argmax(y_test, axis=1)\n",
    "print(classification_report(y_true, y_pred_classes))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 217,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "3987/3987 [==============================] - 1s 294us/step\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0       0.89      0.96      0.92     42282\n",
      "           1       0.86      0.93      0.90     42717\n",
      "           2       0.88      0.74      0.81     42558\n",
      "\n",
      "    accuracy                           0.88    127557\n",
      "   macro avg       0.88      0.88      0.87    127557\n",
      "weighted avg       0.88      0.88      0.87    127557\n",
      "\n"
     ]
    }
   ],
   "source": [
    "y_t_pred = model.predict(X_train)\n",
    "y_t_pred_classes = np.argmax(y_t_pred, axis=1)\n",
    "y_t_true = np.argmax(y_train, axis=1)\n",
    "print(classification_report(y_t_true, y_t_pred_classes))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 218,
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 1/1000\n",
      "225/225 [==============================] - 1s 3ms/step - loss: 0.8212 - accuracy: 0.6637 - val_loss: 0.7093 - val_accuracy: 0.7237\n",
      "Epoch 2/1000\n",
      "225/225 [==============================] - 1s 3ms/step - loss: 0.7155 - accuracy: 0.7200 - val_loss: 0.6704 - val_accuracy: 0.7364\n",
      "Epoch 3/1000\n",
      "225/225 [==============================] - 1s 3ms/step - loss: 0.6927 - accuracy: 0.7291 - val_loss: 0.6586 - val_accuracy: 0.7422\n",
      "Epoch 4/1000\n",
      "225/225 [==============================] - 1s 3ms/step - loss: 0.6815 - accuracy: 0.7335 - val_loss: 0.6514 - val_accuracy: 0.7448\n",
      "Epoch 5/1000\n",
      "225/225 [==============================] - 1s 3ms/step - loss: 0.6737 - accuracy: 0.7365 - val_loss: 0.6458 - val_accuracy: 0.7457\n",
      "Epoch 6/1000\n",
      "225/225 [==============================] - 1s 3ms/step - loss: 0.6670 - accuracy: 0.7385 - val_loss: 0.6419 - val_accuracy: 0.7448\n",
      "Epoch 7/1000\n",
      "225/225 [==============================] - 1s 3ms/step - loss: 0.6612 - accuracy: 0.7405 - val_loss: 0.6388 - val_accuracy: 0.7500\n",
      "Epoch 8/1000\n",
      "225/225 [==============================] - 1s 3ms/step - loss: 0.6560 - accuracy: 0.7422 - val_loss: 0.6311 - val_accuracy: 0.7505\n",
      "Epoch 9/1000\n",
      "225/225 [==============================] - 1s 3ms/step - loss: 0.6510 - accuracy: 0.7444 - val_loss: 0.6294 - val_accuracy: 0.7510\n",
      "Epoch 10/1000\n",
      "225/225 [==============================] - 1s 3ms/step - loss: 0.6461 - accuracy: 0.7452 - val_loss: 0.6264 - val_accuracy: 0.7520\n",
      "Epoch 11/1000\n",
      "225/225 [==============================] - 1s 3ms/step - loss: 0.6425 - accuracy: 0.7471 - val_loss: 0.6205 - val_accuracy: 0.7547\n",
      "Epoch 12/1000\n",
      "225/225 [==============================] - 1s 3ms/step - loss: 0.6379 - accuracy: 0.7484 - val_loss: 0.6157 - val_accuracy: 0.7544\n",
      "Epoch 13/1000\n",
      "225/225 [==============================] - 1s 3ms/step - loss: 0.6335 - accuracy: 0.7495 - val_loss: 0.6136 - val_accuracy: 0.7584\n",
      "Epoch 14/1000\n",
      "225/225 [==============================] - 1s 3ms/step - loss: 0.6296 - accuracy: 0.7500 - val_loss: 0.6114 - val_accuracy: 0.7567\n",
      "Epoch 15/1000\n",
      "225/225 [==============================] - 1s 3ms/step - loss: 0.6264 - accuracy: 0.7521 - val_loss: 0.6041 - val_accuracy: 0.7610\n",
      "Epoch 16/1000\n",
      "225/225 [==============================] - 1s 3ms/step - loss: 0.6227 - accuracy: 0.7531 - val_loss: 0.6009 - val_accuracy: 0.7618\n",
      "Epoch 17/1000\n",
      "225/225 [==============================] - 1s 3ms/step - loss: 0.6177 - accuracy: 0.7547 - val_loss: 0.5946 - val_accuracy: 0.7636\n",
      "Epoch 18/1000\n",
      "225/225 [==============================] - 1s 3ms/step - loss: 0.6140 - accuracy: 0.7578 - val_loss: 0.5924 - val_accuracy: 0.7652\n",
      "Epoch 19/1000\n",
      "225/225 [==============================] - 1s 3ms/step - loss: 0.6115 - accuracy: 0.7576 - val_loss: 0.5880 - val_accuracy: 0.7668\n",
      "Epoch 20/1000\n",
      "225/225 [==============================] - 1s 3ms/step - loss: 0.6075 - accuracy: 0.7601 - val_loss: 0.5814 - val_accuracy: 0.7705\n",
      "Epoch 21/1000\n",
      "225/225 [==============================] - 1s 3ms/step - loss: 0.6047 - accuracy: 0.7607 - val_loss: 0.5810 - val_accuracy: 0.7676\n",
      "Epoch 22/1000\n",
      "225/225 [==============================] - 1s 3ms/step - loss: 0.6004 - accuracy: 0.7614 - val_loss: 0.5795 - val_accuracy: 0.7691\n",
      "Epoch 23/1000\n",
      "225/225 [==============================] - 1s 3ms/step - loss: 0.5977 - accuracy: 0.7628 - val_loss: 0.5716 - val_accuracy: 0.7766\n",
      "Epoch 24/1000\n",
      "225/225 [==============================] - 1s 3ms/step - loss: 0.5942 - accuracy: 0.7657 - val_loss: 0.5659 - val_accuracy: 0.7757\n",
      "Epoch 25/1000\n",
      "225/225 [==============================] - 1s 3ms/step - loss: 0.5916 - accuracy: 0.7655 - val_loss: 0.5668 - val_accuracy: 0.7763\n",
      "Epoch 26/1000\n",
      "225/225 [==============================] - 1s 3ms/step - loss: 0.5880 - accuracy: 0.7670 - val_loss: 0.5687 - val_accuracy: 0.7765\n",
      "Epoch 27/1000\n",
      "225/225 [==============================] - 1s 3ms/step - loss: 0.5853 - accuracy: 0.7680 - val_loss: 0.5605 - val_accuracy: 0.7767\n",
      "Epoch 28/1000\n",
      "225/225 [==============================] - 1s 3ms/step - loss: 0.5829 - accuracy: 0.7686 - val_loss: 0.5557 - val_accuracy: 0.7786\n",
      "Epoch 29/1000\n",
      "225/225 [==============================] - 1s 3ms/step - loss: 0.5815 - accuracy: 0.7687 - val_loss: 0.5509 - val_accuracy: 0.7822\n",
      "Epoch 30/1000\n",
      "225/225 [==============================] - 1s 3ms/step - loss: 0.5786 - accuracy: 0.7698 - val_loss: 0.5534 - val_accuracy: 0.7792\n",
      "Epoch 31/1000\n",
      "225/225 [==============================] - 1s 3ms/step - loss: 0.5780 - accuracy: 0.7704 - val_loss: 0.5556 - val_accuracy: 0.7785\n",
      "Epoch 32/1000\n",
      "225/225 [==============================] - 1s 3ms/step - loss: 0.5758 - accuracy: 0.7714 - val_loss: 0.5492 - val_accuracy: 0.7803\n",
      "Epoch 33/1000\n",
      "225/225 [==============================] - 1s 3ms/step - loss: 0.5717 - accuracy: 0.7722 - val_loss: 0.5443 - val_accuracy: 0.7843\n",
      "Epoch 34/1000\n",
      "225/225 [==============================] - 1s 3ms/step - loss: 0.5708 - accuracy: 0.7726 - val_loss: 0.5426 - val_accuracy: 0.7835\n",
      "Epoch 35/1000\n",
      "225/225 [==============================] - 1s 3ms/step - loss: 0.5690 - accuracy: 0.7737 - val_loss: 0.5387 - val_accuracy: 0.7878\n",
      "Epoch 36/1000\n",
      "225/225 [==============================] - 1s 3ms/step - loss: 0.5680 - accuracy: 0.7750 - val_loss: 0.5385 - val_accuracy: 0.7867\n",
      "Epoch 37/1000\n",
      "225/225 [==============================] - 1s 3ms/step - loss: 0.5652 - accuracy: 0.7762 - val_loss: 0.5355 - val_accuracy: 0.7866\n",
      "Epoch 38/1000\n",
      "225/225 [==============================] - 1s 3ms/step - loss: 0.5614 - accuracy: 0.7774 - val_loss: 0.5308 - val_accuracy: 0.7904\n",
      "Epoch 39/1000\n",
      "225/225 [==============================] - 1s 3ms/step - loss: 0.5623 - accuracy: 0.7767 - val_loss: 0.5290 - val_accuracy: 0.7901\n",
      "Epoch 40/1000\n",
      "225/225 [==============================] - 1s 3ms/step - loss: 0.5598 - accuracy: 0.7787 - val_loss: 0.5307 - val_accuracy: 0.7909\n",
      "Epoch 41/1000\n",
      "225/225 [==============================] - 1s 3ms/step - loss: 0.5576 - accuracy: 0.7792 - val_loss: 0.5288 - val_accuracy: 0.7934\n",
      "Epoch 42/1000\n",
      "225/225 [==============================] - 1s 3ms/step - loss: 0.5556 - accuracy: 0.7790 - val_loss: 0.5246 - val_accuracy: 0.7948\n",
      "Epoch 43/1000\n",
      "225/225 [==============================] - 1s 3ms/step - loss: 0.5542 - accuracy: 0.7803 - val_loss: 0.5222 - val_accuracy: 0.7942\n",
      "Epoch 44/1000\n",
      "225/225 [==============================] - 1s 3ms/step - loss: 0.5542 - accuracy: 0.7803 - val_loss: 0.5230 - val_accuracy: 0.7919\n",
      "Epoch 45/1000\n",
      "225/225 [==============================] - 1s 3ms/step - loss: 0.5521 - accuracy: 0.7807 - val_loss: 0.5198 - val_accuracy: 0.7964\n",
      "Epoch 46/1000\n",
      "225/225 [==============================] - 1s 3ms/step - loss: 0.5516 - accuracy: 0.7804 - val_loss: 0.5160 - val_accuracy: 0.7969\n",
      "Epoch 47/1000\n",
      "225/225 [==============================] - 1s 3ms/step - loss: 0.5486 - accuracy: 0.7834 - val_loss: 0.5190 - val_accuracy: 0.7937\n",
      "Epoch 48/1000\n",
      "225/225 [==============================] - 1s 3ms/step - loss: 0.5481 - accuracy: 0.7822 - val_loss: 0.5160 - val_accuracy: 0.7967\n",
      "Epoch 49/1000\n",
      "225/225 [==============================] - 1s 3ms/step - loss: 0.5498 - accuracy: 0.7826 - val_loss: 0.5126 - val_accuracy: 0.7963\n",
      "Epoch 50/1000\n",
      "225/225 [==============================] - 1s 3ms/step - loss: 0.5473 - accuracy: 0.7821 - val_loss: 0.5118 - val_accuracy: 0.7987\n",
      "Epoch 51/1000\n",
      "225/225 [==============================] - 1s 3ms/step - loss: 0.5459 - accuracy: 0.7846 - val_loss: 0.5091 - val_accuracy: 0.7985\n",
      "Epoch 52/1000\n",
      "225/225 [==============================] - 1s 3ms/step - loss: 0.5449 - accuracy: 0.7842 - val_loss: 0.5104 - val_accuracy: 0.8000\n",
      "Epoch 53/1000\n",
      "225/225 [==============================] - 1s 4ms/step - loss: 0.5445 - accuracy: 0.7835 - val_loss: 0.5061 - val_accuracy: 0.7995\n",
      "Epoch 54/1000\n",
      "225/225 [==============================] - 1s 3ms/step - loss: 0.5410 - accuracy: 0.7853 - val_loss: 0.5025 - val_accuracy: 0.8027\n",
      "Epoch 55/1000\n",
      "225/225 [==============================] - 1s 3ms/step - loss: 0.5412 - accuracy: 0.7855 - val_loss: 0.5038 - val_accuracy: 0.8023\n",
      "Epoch 56/1000\n",
      "225/225 [==============================] - 1s 3ms/step - loss: 0.5384 - accuracy: 0.7855 - val_loss: 0.5034 - val_accuracy: 0.8046\n",
      "Epoch 57/1000\n",
      "225/225 [==============================] - 1s 3ms/step - loss: 0.5370 - accuracy: 0.7868 - val_loss: 0.4980 - val_accuracy: 0.8064\n",
      "Epoch 58/1000\n",
      "225/225 [==============================] - 1s 4ms/step - loss: 0.5353 - accuracy: 0.7886 - val_loss: 0.5036 - val_accuracy: 0.8053\n",
      "Epoch 59/1000\n",
      "225/225 [==============================] - 1s 3ms/step - loss: 0.5367 - accuracy: 0.7876 - val_loss: 0.4978 - val_accuracy: 0.8068\n",
      "Epoch 60/1000\n",
      "225/225 [==============================] - 1s 3ms/step - loss: 0.5366 - accuracy: 0.7889 - val_loss: 0.4982 - val_accuracy: 0.8088\n",
      "Epoch 61/1000\n",
      "225/225 [==============================] - 1s 3ms/step - loss: 0.5349 - accuracy: 0.7881 - val_loss: 0.5001 - val_accuracy: 0.8077\n",
      "Epoch 62/1000\n",
      "225/225 [==============================] - 1s 3ms/step - loss: 0.5346 - accuracy: 0.7889 - val_loss: 0.4988 - val_accuracy: 0.8057\n",
      "Epoch 63/1000\n",
      "225/225 [==============================] - 1s 3ms/step - loss: 0.5328 - accuracy: 0.7893 - val_loss: 0.4974 - val_accuracy: 0.8069\n",
      "Epoch 64/1000\n",
      "225/225 [==============================] - 1s 3ms/step - loss: 0.5334 - accuracy: 0.7893 - val_loss: 0.4969 - val_accuracy: 0.8047\n",
      "Epoch 65/1000\n",
      "225/225 [==============================] - 1s 3ms/step - loss: 0.5314 - accuracy: 0.7894 - val_loss: 0.4949 - val_accuracy: 0.8082\n",
      "Epoch 66/1000\n",
      "225/225 [==============================] - 1s 3ms/step - loss: 0.5296 - accuracy: 0.7914 - val_loss: 0.4941 - val_accuracy: 0.8087\n",
      "Epoch 67/1000\n",
      "225/225 [==============================] - 1s 3ms/step - loss: 0.5278 - accuracy: 0.7905 - val_loss: 0.4950 - val_accuracy: 0.8083\n",
      "Epoch 68/1000\n",
      "225/225 [==============================] - 1s 3ms/step - loss: 0.5308 - accuracy: 0.7901 - val_loss: 0.4913 - val_accuracy: 0.8076\n",
      "Epoch 69/1000\n",
      "225/225 [==============================] - 1s 3ms/step - loss: 0.5276 - accuracy: 0.7914 - val_loss: 0.4938 - val_accuracy: 0.8082\n",
      "Epoch 70/1000\n",
      "225/225 [==============================] - 1s 3ms/step - loss: 0.5275 - accuracy: 0.7911 - val_loss: 0.4898 - val_accuracy: 0.8108\n",
      "Epoch 71/1000\n",
      "225/225 [==============================] - 1s 3ms/step - loss: 0.5256 - accuracy: 0.7927 - val_loss: 0.4886 - val_accuracy: 0.8103\n",
      "Epoch 72/1000\n",
      "225/225 [==============================] - 1s 3ms/step - loss: 0.5266 - accuracy: 0.7918 - val_loss: 0.4885 - val_accuracy: 0.8105\n",
      "Epoch 73/1000\n",
      "225/225 [==============================] - 1s 3ms/step - loss: 0.5243 - accuracy: 0.7931 - val_loss: 0.4851 - val_accuracy: 0.8110\n",
      "Epoch 74/1000\n",
      "225/225 [==============================] - 1s 3ms/step - loss: 0.5243 - accuracy: 0.7923 - val_loss: 0.4875 - val_accuracy: 0.8097\n",
      "Epoch 75/1000\n",
      "225/225 [==============================] - 1s 3ms/step - loss: 0.5238 - accuracy: 0.7928 - val_loss: 0.4834 - val_accuracy: 0.8134\n",
      "Epoch 76/1000\n",
      "225/225 [==============================] - 1s 3ms/step - loss: 0.5230 - accuracy: 0.7934 - val_loss: 0.4829 - val_accuracy: 0.8121\n",
      "Epoch 77/1000\n",
      "225/225 [==============================] - 1s 3ms/step - loss: 0.5235 - accuracy: 0.7928 - val_loss: 0.4848 - val_accuracy: 0.8110\n",
      "Epoch 78/1000\n",
      "225/225 [==============================] - 1s 3ms/step - loss: 0.5225 - accuracy: 0.7926 - val_loss: 0.4821 - val_accuracy: 0.8124\n",
      "Epoch 79/1000\n",
      "225/225 [==============================] - 1s 3ms/step - loss: 0.5210 - accuracy: 0.7944 - val_loss: 0.4838 - val_accuracy: 0.8125\n",
      "Epoch 80/1000\n",
      "225/225 [==============================] - 1s 3ms/step - loss: 0.5202 - accuracy: 0.7958 - val_loss: 0.4834 - val_accuracy: 0.8105\n",
      "Epoch 81/1000\n",
      "225/225 [==============================] - 1s 3ms/step - loss: 0.5197 - accuracy: 0.7957 - val_loss: 0.4809 - val_accuracy: 0.8137\n",
      "Epoch 82/1000\n",
      "225/225 [==============================] - 1s 3ms/step - loss: 0.5203 - accuracy: 0.7947 - val_loss: 0.4774 - val_accuracy: 0.8137\n",
      "Epoch 83/1000\n",
      "225/225 [==============================] - 1s 3ms/step - loss: 0.5185 - accuracy: 0.7949 - val_loss: 0.4796 - val_accuracy: 0.8116\n",
      "Epoch 84/1000\n",
      "225/225 [==============================] - 1s 3ms/step - loss: 0.5174 - accuracy: 0.7961 - val_loss: 0.4826 - val_accuracy: 0.8144\n",
      "Epoch 85/1000\n",
      "225/225 [==============================] - 1s 3ms/step - loss: 0.5179 - accuracy: 0.7950 - val_loss: 0.4789 - val_accuracy: 0.8120\n",
      "Epoch 86/1000\n",
      "225/225 [==============================] - 1s 3ms/step - loss: 0.5163 - accuracy: 0.7966 - val_loss: 0.4800 - val_accuracy: 0.8133\n",
      "Epoch 87/1000\n",
      "225/225 [==============================] - 1s 3ms/step - loss: 0.5144 - accuracy: 0.7971 - val_loss: 0.4780 - val_accuracy: 0.8170\n",
      "Epoch 88/1000\n",
      "225/225 [==============================] - 1s 3ms/step - loss: 0.5151 - accuracy: 0.7963 - val_loss: 0.4781 - val_accuracy: 0.8141\n",
      "Epoch 89/1000\n",
      "225/225 [==============================] - 1s 3ms/step - loss: 0.5158 - accuracy: 0.7970 - val_loss: 0.4767 - val_accuracy: 0.8180\n",
      "Epoch 90/1000\n",
      "225/225 [==============================] - 1s 3ms/step - loss: 0.5129 - accuracy: 0.7976 - val_loss: 0.4781 - val_accuracy: 0.8149\n",
      "Epoch 91/1000\n",
      "225/225 [==============================] - 1s 3ms/step - loss: 0.5138 - accuracy: 0.7960 - val_loss: 0.4732 - val_accuracy: 0.8155\n",
      "Epoch 92/1000\n",
      "225/225 [==============================] - 1s 3ms/step - loss: 0.5136 - accuracy: 0.7973 - val_loss: 0.4745 - val_accuracy: 0.8155\n",
      "Epoch 93/1000\n",
      "225/225 [==============================] - 1s 3ms/step - loss: 0.5141 - accuracy: 0.7960 - val_loss: 0.4761 - val_accuracy: 0.8146\n",
      "Epoch 94/1000\n",
      "225/225 [==============================] - 1s 3ms/step - loss: 0.5108 - accuracy: 0.7987 - val_loss: 0.4756 - val_accuracy: 0.8161\n",
      "Epoch 95/1000\n",
      "225/225 [==============================] - 1s 3ms/step - loss: 0.5104 - accuracy: 0.7988 - val_loss: 0.4747 - val_accuracy: 0.8140\n",
      "Epoch 96/1000\n",
      "225/225 [==============================] - 1s 3ms/step - loss: 0.5122 - accuracy: 0.7977 - val_loss: 0.4747 - val_accuracy: 0.8176\n",
      "Epoch 97/1000\n",
      "225/225 [==============================] - 1s 3ms/step - loss: 0.5119 - accuracy: 0.7987 - val_loss: 0.4728 - val_accuracy: 0.8164\n",
      "Epoch 98/1000\n",
      "225/225 [==============================] - 1s 3ms/step - loss: 0.5092 - accuracy: 0.7997 - val_loss: 0.4702 - val_accuracy: 0.8198\n",
      "Epoch 99/1000\n",
      "225/225 [==============================] - 1s 3ms/step - loss: 0.5095 - accuracy: 0.7984 - val_loss: 0.4704 - val_accuracy: 0.8216\n",
      "Epoch 100/1000\n",
      "225/225 [==============================] - 1s 3ms/step - loss: 0.5098 - accuracy: 0.7989 - val_loss: 0.4707 - val_accuracy: 0.8185\n",
      "Epoch 101/1000\n",
      "225/225 [==============================] - 1s 3ms/step - loss: 0.5099 - accuracy: 0.8003 - val_loss: 0.4736 - val_accuracy: 0.8147\n",
      "Epoch 102/1000\n",
      "225/225 [==============================] - 1s 3ms/step - loss: 0.5107 - accuracy: 0.7991 - val_loss: 0.4684 - val_accuracy: 0.8191\n",
      "Epoch 103/1000\n",
      "225/225 [==============================] - 1s 3ms/step - loss: 0.5071 - accuracy: 0.8008 - val_loss: 0.4687 - val_accuracy: 0.8180\n",
      "Epoch 104/1000\n",
      "225/225 [==============================] - 1s 3ms/step - loss: 0.5074 - accuracy: 0.8003 - val_loss: 0.4676 - val_accuracy: 0.8203\n",
      "Epoch 105/1000\n",
      "225/225 [==============================] - 1s 3ms/step - loss: 0.5059 - accuracy: 0.7999 - val_loss: 0.4703 - val_accuracy: 0.8176\n",
      "Epoch 106/1000\n",
      "225/225 [==============================] - 1s 3ms/step - loss: 0.5071 - accuracy: 0.8008 - val_loss: 0.4721 - val_accuracy: 0.8157\n",
      "Epoch 107/1000\n",
      "225/225 [==============================] - 1s 3ms/step - loss: 0.5068 - accuracy: 0.8009 - val_loss: 0.4702 - val_accuracy: 0.8167\n",
      "Epoch 108/1000\n",
      "225/225 [==============================] - 1s 3ms/step - loss: 0.5033 - accuracy: 0.8020 - val_loss: 0.4641 - val_accuracy: 0.8201\n",
      "Epoch 109/1000\n",
      "225/225 [==============================] - 1s 3ms/step - loss: 0.5057 - accuracy: 0.8008 - val_loss: 0.4633 - val_accuracy: 0.8214\n",
      "Epoch 110/1000\n",
      "225/225 [==============================] - 1s 3ms/step - loss: 0.5058 - accuracy: 0.8017 - val_loss: 0.4649 - val_accuracy: 0.8231\n",
      "Epoch 111/1000\n",
      "225/225 [==============================] - 1s 3ms/step - loss: 0.5048 - accuracy: 0.8017 - val_loss: 0.4640 - val_accuracy: 0.8242\n",
      "Epoch 112/1000\n",
      "225/225 [==============================] - 1s 3ms/step - loss: 0.5022 - accuracy: 0.8018 - val_loss: 0.4638 - val_accuracy: 0.8200\n",
      "Epoch 113/1000\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "225/225 [==============================] - 1s 3ms/step - loss: 0.5053 - accuracy: 0.8012 - val_loss: 0.4643 - val_accuracy: 0.8237\n",
      "Epoch 114/1000\n",
      "225/225 [==============================] - 1s 3ms/step - loss: 0.5033 - accuracy: 0.8006 - val_loss: 0.4602 - val_accuracy: 0.8238\n",
      "Epoch 115/1000\n",
      "225/225 [==============================] - 1s 3ms/step - loss: 0.5042 - accuracy: 0.8024 - val_loss: 0.4612 - val_accuracy: 0.8241\n",
      "Epoch 116/1000\n",
      "225/225 [==============================] - 1s 3ms/step - loss: 0.5037 - accuracy: 0.8017 - val_loss: 0.4623 - val_accuracy: 0.8209\n",
      "Epoch 117/1000\n",
      "225/225 [==============================] - 1s 3ms/step - loss: 0.5018 - accuracy: 0.8026 - val_loss: 0.4624 - val_accuracy: 0.8226\n",
      "Epoch 118/1000\n",
      "225/225 [==============================] - 1s 3ms/step - loss: 0.5016 - accuracy: 0.8036 - val_loss: 0.4612 - val_accuracy: 0.8238\n",
      "Epoch 119/1000\n",
      "225/225 [==============================] - 1s 3ms/step - loss: 0.5017 - accuracy: 0.8015 - val_loss: 0.4601 - val_accuracy: 0.8231\n",
      "Epoch 120/1000\n",
      "225/225 [==============================] - 1s 3ms/step - loss: 0.5004 - accuracy: 0.8033 - val_loss: 0.4630 - val_accuracy: 0.8231\n",
      "Epoch 121/1000\n",
      "225/225 [==============================] - 1s 3ms/step - loss: 0.5002 - accuracy: 0.8020 - val_loss: 0.4645 - val_accuracy: 0.8221\n",
      "Epoch 122/1000\n",
      "225/225 [==============================] - 1s 3ms/step - loss: 0.4991 - accuracy: 0.8041 - val_loss: 0.4597 - val_accuracy: 0.8260\n",
      "Epoch 123/1000\n",
      "225/225 [==============================] - 1s 3ms/step - loss: 0.5016 - accuracy: 0.8031 - val_loss: 0.4624 - val_accuracy: 0.8229\n",
      "Epoch 124/1000\n",
      "225/225 [==============================] - 1s 3ms/step - loss: 0.5015 - accuracy: 0.8029 - val_loss: 0.4617 - val_accuracy: 0.8208\n",
      "Epoch 125/1000\n",
      "225/225 [==============================] - 1s 3ms/step - loss: 0.4986 - accuracy: 0.8040 - val_loss: 0.4594 - val_accuracy: 0.8252\n",
      "Epoch 126/1000\n",
      "225/225 [==============================] - 1s 3ms/step - loss: 0.4991 - accuracy: 0.8052 - val_loss: 0.4569 - val_accuracy: 0.8246\n",
      "Epoch 127/1000\n",
      "225/225 [==============================] - 1s 3ms/step - loss: 0.4985 - accuracy: 0.8048 - val_loss: 0.4624 - val_accuracy: 0.8209\n",
      "Epoch 128/1000\n",
      "225/225 [==============================] - 1s 3ms/step - loss: 0.4998 - accuracy: 0.8048 - val_loss: 0.4594 - val_accuracy: 0.8231\n",
      "Epoch 129/1000\n",
      "225/225 [==============================] - 1s 3ms/step - loss: 0.4992 - accuracy: 0.8037 - val_loss: 0.4560 - val_accuracy: 0.8255\n",
      "Epoch 130/1000\n",
      "225/225 [==============================] - 1s 3ms/step - loss: 0.4988 - accuracy: 0.8047 - val_loss: 0.4600 - val_accuracy: 0.8238\n",
      "Epoch 131/1000\n",
      "225/225 [==============================] - 1s 3ms/step - loss: 0.4982 - accuracy: 0.8043 - val_loss: 0.4587 - val_accuracy: 0.8253\n",
      "Epoch 132/1000\n",
      "225/225 [==============================] - 1s 3ms/step - loss: 0.4961 - accuracy: 0.8051 - val_loss: 0.4575 - val_accuracy: 0.8251\n",
      "Epoch 133/1000\n",
      "225/225 [==============================] - 1s 3ms/step - loss: 0.4960 - accuracy: 0.8058 - val_loss: 0.4587 - val_accuracy: 0.8227\n",
      "Epoch 134/1000\n",
      "225/225 [==============================] - 1s 3ms/step - loss: 0.4979 - accuracy: 0.8048 - val_loss: 0.4606 - val_accuracy: 0.8225\n",
      "Epoch 135/1000\n",
      "225/225 [==============================] - 1s 3ms/step - loss: 0.4973 - accuracy: 0.8054 - val_loss: 0.4551 - val_accuracy: 0.8255\n",
      "Epoch 136/1000\n",
      "225/225 [==============================] - 1s 3ms/step - loss: 0.4999 - accuracy: 0.8044 - val_loss: 0.4582 - val_accuracy: 0.8253\n",
      "Epoch 137/1000\n",
      "225/225 [==============================] - 1s 3ms/step - loss: 0.4946 - accuracy: 0.8059 - val_loss: 0.4626 - val_accuracy: 0.8235\n",
      "Epoch 138/1000\n",
      "225/225 [==============================] - 1s 3ms/step - loss: 0.4964 - accuracy: 0.8055 - val_loss: 0.4567 - val_accuracy: 0.8267\n",
      "Epoch 139/1000\n",
      "225/225 [==============================] - 1s 3ms/step - loss: 0.4964 - accuracy: 0.8048 - val_loss: 0.4547 - val_accuracy: 0.8277\n",
      "Epoch 140/1000\n",
      "225/225 [==============================] - 1s 3ms/step - loss: 0.4965 - accuracy: 0.8054 - val_loss: 0.4551 - val_accuracy: 0.8252\n",
      "Epoch 141/1000\n",
      "225/225 [==============================] - 1s 3ms/step - loss: 0.4950 - accuracy: 0.8061 - val_loss: 0.4579 - val_accuracy: 0.8222\n",
      "Epoch 142/1000\n",
      "225/225 [==============================] - 1s 3ms/step - loss: 0.4964 - accuracy: 0.8049 - val_loss: 0.4546 - val_accuracy: 0.8243\n",
      "Epoch 143/1000\n",
      "225/225 [==============================] - 1s 3ms/step - loss: 0.4941 - accuracy: 0.8060 - val_loss: 0.4541 - val_accuracy: 0.8238\n",
      "Epoch 144/1000\n",
      "225/225 [==============================] - 1s 3ms/step - loss: 0.4937 - accuracy: 0.8067 - val_loss: 0.4504 - val_accuracy: 0.8291\n",
      "Epoch 145/1000\n",
      "225/225 [==============================] - 1s 3ms/step - loss: 0.4936 - accuracy: 0.8068 - val_loss: 0.4529 - val_accuracy: 0.8274\n",
      "Epoch 146/1000\n",
      "225/225 [==============================] - 1s 3ms/step - loss: 0.4917 - accuracy: 0.8071 - val_loss: 0.4524 - val_accuracy: 0.8283\n",
      "Epoch 147/1000\n",
      "225/225 [==============================] - 1s 3ms/step - loss: 0.4928 - accuracy: 0.8057 - val_loss: 0.4549 - val_accuracy: 0.8221\n",
      "Epoch 148/1000\n",
      "225/225 [==============================] - 1s 3ms/step - loss: 0.4931 - accuracy: 0.8069 - val_loss: 0.4507 - val_accuracy: 0.8289\n",
      "Epoch 149/1000\n",
      "225/225 [==============================] - 1s 3ms/step - loss: 0.4936 - accuracy: 0.8054 - val_loss: 0.4517 - val_accuracy: 0.8300\n",
      "Epoch 150/1000\n",
      "225/225 [==============================] - 1s 3ms/step - loss: 0.4950 - accuracy: 0.8057 - val_loss: 0.4505 - val_accuracy: 0.8281\n",
      "Epoch 151/1000\n",
      "225/225 [==============================] - 1s 3ms/step - loss: 0.4908 - accuracy: 0.8067 - val_loss: 0.4539 - val_accuracy: 0.8286\n",
      "Epoch 152/1000\n",
      "225/225 [==============================] - 1s 3ms/step - loss: 0.4915 - accuracy: 0.8072 - val_loss: 0.4520 - val_accuracy: 0.8293\n",
      "Epoch 153/1000\n",
      "225/225 [==============================] - 1s 3ms/step - loss: 0.4923 - accuracy: 0.8078 - val_loss: 0.4528 - val_accuracy: 0.8251\n",
      "Epoch 154/1000\n",
      "225/225 [==============================] - 1s 3ms/step - loss: 0.4911 - accuracy: 0.8070 - val_loss: 0.4516 - val_accuracy: 0.8258\n",
      "Epoch 155/1000\n",
      "225/225 [==============================] - 1s 3ms/step - loss: 0.4906 - accuracy: 0.8081 - val_loss: 0.4470 - val_accuracy: 0.8293\n",
      "Epoch 156/1000\n",
      "225/225 [==============================] - 1s 3ms/step - loss: 0.4905 - accuracy: 0.8071 - val_loss: 0.4489 - val_accuracy: 0.8271\n",
      "Epoch 157/1000\n",
      "225/225 [==============================] - 1s 3ms/step - loss: 0.4922 - accuracy: 0.8072 - val_loss: 0.4509 - val_accuracy: 0.8280\n",
      "Epoch 158/1000\n",
      "225/225 [==============================] - 1s 3ms/step - loss: 0.4918 - accuracy: 0.8083 - val_loss: 0.4501 - val_accuracy: 0.8271\n",
      "Epoch 159/1000\n",
      "225/225 [==============================] - 1s 3ms/step - loss: 0.4900 - accuracy: 0.8076 - val_loss: 0.4483 - val_accuracy: 0.8320\n",
      "Epoch 160/1000\n",
      "225/225 [==============================] - 1s 4ms/step - loss: 0.4906 - accuracy: 0.8071 - val_loss: 0.4491 - val_accuracy: 0.8309\n",
      "Epoch 161/1000\n",
      "225/225 [==============================] - 1s 3ms/step - loss: 0.4889 - accuracy: 0.8082 - val_loss: 0.4463 - val_accuracy: 0.8312\n",
      "Epoch 162/1000\n",
      "225/225 [==============================] - 1s 3ms/step - loss: 0.4913 - accuracy: 0.8065 - val_loss: 0.4467 - val_accuracy: 0.8286\n",
      "Epoch 163/1000\n",
      "225/225 [==============================] - 1s 3ms/step - loss: 0.4886 - accuracy: 0.8092 - val_loss: 0.4492 - val_accuracy: 0.8296\n",
      "Epoch 164/1000\n",
      "225/225 [==============================] - 1s 4ms/step - loss: 0.4913 - accuracy: 0.8074 - val_loss: 0.4499 - val_accuracy: 0.8290\n",
      "Epoch 165/1000\n",
      "225/225 [==============================] - 1s 3ms/step - loss: 0.4896 - accuracy: 0.8081 - val_loss: 0.4474 - val_accuracy: 0.8304\n",
      "Epoch 166/1000\n",
      "225/225 [==============================] - 1s 3ms/step - loss: 0.4875 - accuracy: 0.8090 - val_loss: 0.4510 - val_accuracy: 0.8286\n",
      "Epoch 167/1000\n",
      "225/225 [==============================] - 1s 3ms/step - loss: 0.4888 - accuracy: 0.8079 - val_loss: 0.4507 - val_accuracy: 0.8265\n",
      "Epoch 168/1000\n",
      "225/225 [==============================] - 1s 3ms/step - loss: 0.4909 - accuracy: 0.8083 - val_loss: 0.4454 - val_accuracy: 0.8292\n",
      "Epoch 169/1000\n",
      "225/225 [==============================] - 1s 3ms/step - loss: 0.4889 - accuracy: 0.8074 - val_loss: 0.4438 - val_accuracy: 0.8317\n",
      "Epoch 170/1000\n",
      "225/225 [==============================] - 1s 3ms/step - loss: 0.4876 - accuracy: 0.8088 - val_loss: 0.4477 - val_accuracy: 0.8296\n",
      "Epoch 171/1000\n",
      "225/225 [==============================] - 1s 3ms/step - loss: 0.4868 - accuracy: 0.8111 - val_loss: 0.4455 - val_accuracy: 0.8306\n",
      "Epoch 172/1000\n",
      "225/225 [==============================] - 1s 3ms/step - loss: 0.4873 - accuracy: 0.8094 - val_loss: 0.4507 - val_accuracy: 0.8267\n",
      "Epoch 173/1000\n",
      "225/225 [==============================] - 1s 3ms/step - loss: 0.4899 - accuracy: 0.8070 - val_loss: 0.4458 - val_accuracy: 0.8301\n",
      "Epoch 174/1000\n",
      "225/225 [==============================] - 1s 3ms/step - loss: 0.4874 - accuracy: 0.8091 - val_loss: 0.4427 - val_accuracy: 0.8318\n",
      "Epoch 175/1000\n",
      "225/225 [==============================] - 1s 3ms/step - loss: 0.4882 - accuracy: 0.8085 - val_loss: 0.4522 - val_accuracy: 0.8262\n",
      "Epoch 176/1000\n",
      "225/225 [==============================] - 1s 3ms/step - loss: 0.4865 - accuracy: 0.8099 - val_loss: 0.4442 - val_accuracy: 0.8321\n",
      "Epoch 177/1000\n",
      "225/225 [==============================] - 1s 3ms/step - loss: 0.4864 - accuracy: 0.8101 - val_loss: 0.4497 - val_accuracy: 0.8277\n",
      "Epoch 178/1000\n",
      "225/225 [==============================] - 1s 3ms/step - loss: 0.4857 - accuracy: 0.8097 - val_loss: 0.4486 - val_accuracy: 0.8318\n",
      "Epoch 179/1000\n",
      "225/225 [==============================] - 1s 3ms/step - loss: 0.4881 - accuracy: 0.8091 - val_loss: 0.4484 - val_accuracy: 0.8315\n",
      "Epoch 180/1000\n",
      "225/225 [==============================] - 1s 3ms/step - loss: 0.4853 - accuracy: 0.8093 - val_loss: 0.4441 - val_accuracy: 0.8333\n",
      "Epoch 181/1000\n",
      "225/225 [==============================] - 1s 3ms/step - loss: 0.4878 - accuracy: 0.8087 - val_loss: 0.4458 - val_accuracy: 0.8305\n",
      "Epoch 182/1000\n",
      "225/225 [==============================] - 1s 3ms/step - loss: 0.4849 - accuracy: 0.8091 - val_loss: 0.4451 - val_accuracy: 0.8287\n",
      "Epoch 183/1000\n",
      "225/225 [==============================] - 1s 3ms/step - loss: 0.4853 - accuracy: 0.8097 - val_loss: 0.4451 - val_accuracy: 0.8346\n",
      "Epoch 184/1000\n",
      "225/225 [==============================] - 1s 3ms/step - loss: 0.4835 - accuracy: 0.8101 - val_loss: 0.4419 - val_accuracy: 0.8333\n",
      "Epoch 185/1000\n",
      "225/225 [==============================] - 1s 4ms/step - loss: 0.4842 - accuracy: 0.8098 - val_loss: 0.4411 - val_accuracy: 0.8350\n",
      "Epoch 186/1000\n",
      "225/225 [==============================] - 1s 3ms/step - loss: 0.4842 - accuracy: 0.8112 - val_loss: 0.4451 - val_accuracy: 0.8288\n",
      "Epoch 187/1000\n",
      "225/225 [==============================] - 1s 3ms/step - loss: 0.4824 - accuracy: 0.8113 - val_loss: 0.4425 - val_accuracy: 0.8326\n",
      "Epoch 188/1000\n",
      "225/225 [==============================] - 1s 3ms/step - loss: 0.4854 - accuracy: 0.8099 - val_loss: 0.4433 - val_accuracy: 0.8325\n",
      "Epoch 189/1000\n",
      "225/225 [==============================] - 1s 3ms/step - loss: 0.4840 - accuracy: 0.8101 - val_loss: 0.4401 - val_accuracy: 0.8347\n",
      "Epoch 190/1000\n",
      "225/225 [==============================] - 1s 3ms/step - loss: 0.4824 - accuracy: 0.8119 - val_loss: 0.4433 - val_accuracy: 0.8324\n",
      "Epoch 191/1000\n",
      "225/225 [==============================] - 1s 3ms/step - loss: 0.4842 - accuracy: 0.8096 - val_loss: 0.4434 - val_accuracy: 0.8314\n",
      "Epoch 192/1000\n",
      "225/225 [==============================] - 1s 3ms/step - loss: 0.4863 - accuracy: 0.8093 - val_loss: 0.4398 - val_accuracy: 0.8340\n",
      "Epoch 193/1000\n",
      "225/225 [==============================] - 1s 3ms/step - loss: 0.4812 - accuracy: 0.8116 - val_loss: 0.4419 - val_accuracy: 0.8321\n",
      "Epoch 194/1000\n",
      "225/225 [==============================] - 1s 3ms/step - loss: 0.4828 - accuracy: 0.8110 - val_loss: 0.4392 - val_accuracy: 0.8325\n",
      "Epoch 195/1000\n",
      "225/225 [==============================] - 1s 3ms/step - loss: 0.4816 - accuracy: 0.8125 - val_loss: 0.4437 - val_accuracy: 0.8320\n",
      "Epoch 196/1000\n",
      "225/225 [==============================] - 1s 3ms/step - loss: 0.4830 - accuracy: 0.8106 - val_loss: 0.4427 - val_accuracy: 0.8314\n",
      "Epoch 197/1000\n",
      "225/225 [==============================] - 1s 3ms/step - loss: 0.4847 - accuracy: 0.8097 - val_loss: 0.4429 - val_accuracy: 0.8315\n",
      "Epoch 198/1000\n",
      "225/225 [==============================] - 1s 3ms/step - loss: 0.4807 - accuracy: 0.8120 - val_loss: 0.4399 - val_accuracy: 0.8349\n",
      "Epoch 199/1000\n",
      "225/225 [==============================] - 1s 3ms/step - loss: 0.4812 - accuracy: 0.8123 - val_loss: 0.4411 - val_accuracy: 0.8350\n",
      "Epoch 200/1000\n",
      "225/225 [==============================] - 1s 3ms/step - loss: 0.4834 - accuracy: 0.8107 - val_loss: 0.4440 - val_accuracy: 0.8315\n",
      "Epoch 201/1000\n",
      "225/225 [==============================] - 1s 3ms/step - loss: 0.4789 - accuracy: 0.8124 - val_loss: 0.4362 - val_accuracy: 0.8333\n",
      "Epoch 202/1000\n",
      "225/225 [==============================] - 1s 3ms/step - loss: 0.4809 - accuracy: 0.8122 - val_loss: 0.4407 - val_accuracy: 0.8333\n",
      "Epoch 203/1000\n",
      "225/225 [==============================] - 1s 3ms/step - loss: 0.4820 - accuracy: 0.8110 - val_loss: 0.4438 - val_accuracy: 0.8325\n",
      "Epoch 204/1000\n",
      "225/225 [==============================] - 1s 3ms/step - loss: 0.4786 - accuracy: 0.8129 - val_loss: 0.4428 - val_accuracy: 0.8342\n",
      "Epoch 205/1000\n",
      "225/225 [==============================] - 1s 3ms/step - loss: 0.4814 - accuracy: 0.8118 - val_loss: 0.4415 - val_accuracy: 0.8324\n",
      "Epoch 206/1000\n",
      "225/225 [==============================] - 1s 3ms/step - loss: 0.4821 - accuracy: 0.8124 - val_loss: 0.4440 - val_accuracy: 0.8336\n",
      "Epoch 207/1000\n",
      "225/225 [==============================] - 1s 3ms/step - loss: 0.4808 - accuracy: 0.8128 - val_loss: 0.4436 - val_accuracy: 0.8333\n",
      "Epoch 208/1000\n",
      "225/225 [==============================] - 1s 3ms/step - loss: 0.4810 - accuracy: 0.8121 - val_loss: 0.4427 - val_accuracy: 0.8325\n",
      "Epoch 209/1000\n",
      "225/225 [==============================] - 1s 3ms/step - loss: 0.4809 - accuracy: 0.8114 - val_loss: 0.4368 - val_accuracy: 0.8355\n",
      "Epoch 210/1000\n",
      "225/225 [==============================] - 1s 3ms/step - loss: 0.4803 - accuracy: 0.8121 - val_loss: 0.4394 - val_accuracy: 0.8350\n",
      "Epoch 211/1000\n",
      "225/225 [==============================] - 1s 3ms/step - loss: 0.4815 - accuracy: 0.8120 - val_loss: 0.4390 - val_accuracy: 0.8344\n",
      "Epoch 212/1000\n",
      "225/225 [==============================] - 1s 3ms/step - loss: 0.4786 - accuracy: 0.8120 - val_loss: 0.4433 - val_accuracy: 0.8304\n",
      "Epoch 213/1000\n",
      "225/225 [==============================] - 1s 3ms/step - loss: 0.4790 - accuracy: 0.8127 - val_loss: 0.4404 - val_accuracy: 0.8337\n",
      "Epoch 214/1000\n",
      "225/225 [==============================] - 1s 3ms/step - loss: 0.4808 - accuracy: 0.8116 - val_loss: 0.4405 - val_accuracy: 0.8328\n",
      "Epoch 215/1000\n",
      "225/225 [==============================] - 1s 3ms/step - loss: 0.4797 - accuracy: 0.8118 - val_loss: 0.4385 - val_accuracy: 0.8353\n",
      "Epoch 216/1000\n",
      "225/225 [==============================] - 1s 3ms/step - loss: 0.4790 - accuracy: 0.8125 - val_loss: 0.4391 - val_accuracy: 0.8338\n",
      "Epoch 217/1000\n",
      "225/225 [==============================] - 1s 3ms/step - loss: 0.4790 - accuracy: 0.8135 - val_loss: 0.4401 - val_accuracy: 0.8354\n",
      "Epoch 218/1000\n",
      "225/225 [==============================] - 1s 3ms/step - loss: 0.4803 - accuracy: 0.8124 - val_loss: 0.4367 - val_accuracy: 0.8377\n",
      "Epoch 219/1000\n",
      "225/225 [==============================] - 1s 3ms/step - loss: 0.4811 - accuracy: 0.8111 - val_loss: 0.4374 - val_accuracy: 0.8349\n",
      "Epoch 220/1000\n",
      "225/225 [==============================] - 1s 3ms/step - loss: 0.4785 - accuracy: 0.8126 - val_loss: 0.4420 - val_accuracy: 0.8343\n",
      "Epoch 221/1000\n",
      "225/225 [==============================] - 1s 3ms/step - loss: 0.4796 - accuracy: 0.8129 - val_loss: 0.4372 - val_accuracy: 0.8354\n",
      "Epoch 222/1000\n",
      "225/225 [==============================] - 1s 3ms/step - loss: 0.4772 - accuracy: 0.8119 - val_loss: 0.4380 - val_accuracy: 0.8317\n",
      "Epoch 223/1000\n",
      "225/225 [==============================] - 1s 3ms/step - loss: 0.4774 - accuracy: 0.8127 - val_loss: 0.4407 - val_accuracy: 0.8325\n",
      "Epoch 224/1000\n",
      "225/225 [==============================] - 1s 3ms/step - loss: 0.4781 - accuracy: 0.8134 - val_loss: 0.4359 - val_accuracy: 0.8344\n",
      "Epoch 225/1000\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "225/225 [==============================] - 1s 3ms/step - loss: 0.4779 - accuracy: 0.8137 - val_loss: 0.4380 - val_accuracy: 0.8340\n",
      "Epoch 226/1000\n",
      "225/225 [==============================] - 1s 3ms/step - loss: 0.4784 - accuracy: 0.8138 - val_loss: 0.4369 - val_accuracy: 0.8353\n",
      "Epoch 227/1000\n",
      "225/225 [==============================] - 1s 3ms/step - loss: 0.4755 - accuracy: 0.8135 - val_loss: 0.4404 - val_accuracy: 0.8323\n",
      "Epoch 228/1000\n",
      "225/225 [==============================] - 1s 3ms/step - loss: 0.4806 - accuracy: 0.8122 - val_loss: 0.4352 - val_accuracy: 0.8359\n",
      "Epoch 229/1000\n",
      "225/225 [==============================] - 1s 3ms/step - loss: 0.4789 - accuracy: 0.8123 - val_loss: 0.4410 - val_accuracy: 0.8318\n",
      "Epoch 230/1000\n",
      "225/225 [==============================] - 1s 3ms/step - loss: 0.4770 - accuracy: 0.8130 - val_loss: 0.4345 - val_accuracy: 0.8379\n",
      "Epoch 231/1000\n",
      "225/225 [==============================] - 1s 3ms/step - loss: 0.4776 - accuracy: 0.8136 - val_loss: 0.4383 - val_accuracy: 0.8351\n",
      "Epoch 232/1000\n",
      "225/225 [==============================] - 1s 3ms/step - loss: 0.4771 - accuracy: 0.8140 - val_loss: 0.4360 - val_accuracy: 0.8377\n",
      "Epoch 233/1000\n",
      "225/225 [==============================] - 1s 3ms/step - loss: 0.4762 - accuracy: 0.8132 - val_loss: 0.4373 - val_accuracy: 0.8371\n",
      "Epoch 234/1000\n",
      "225/225 [==============================] - 1s 3ms/step - loss: 0.4764 - accuracy: 0.8134 - val_loss: 0.4384 - val_accuracy: 0.8372\n",
      "Epoch 235/1000\n",
      "225/225 [==============================] - 1s 3ms/step - loss: 0.4782 - accuracy: 0.8126 - val_loss: 0.4366 - val_accuracy: 0.8372\n",
      "Epoch 236/1000\n",
      "225/225 [==============================] - 1s 3ms/step - loss: 0.4766 - accuracy: 0.8142 - val_loss: 0.4351 - val_accuracy: 0.8368\n",
      "Epoch 237/1000\n",
      "225/225 [==============================] - 1s 3ms/step - loss: 0.4766 - accuracy: 0.8139 - val_loss: 0.4331 - val_accuracy: 0.8368\n",
      "Epoch 238/1000\n",
      "225/225 [==============================] - 1s 3ms/step - loss: 0.4764 - accuracy: 0.8137 - val_loss: 0.4348 - val_accuracy: 0.8383\n",
      "Epoch 239/1000\n",
      "225/225 [==============================] - 1s 3ms/step - loss: 0.4766 - accuracy: 0.8142 - val_loss: 0.4375 - val_accuracy: 0.8334\n",
      "Epoch 240/1000\n",
      "225/225 [==============================] - 1s 3ms/step - loss: 0.4751 - accuracy: 0.8141 - val_loss: 0.4350 - val_accuracy: 0.8352\n",
      "Epoch 241/1000\n",
      "225/225 [==============================] - 1s 3ms/step - loss: 0.4748 - accuracy: 0.8142 - val_loss: 0.4357 - val_accuracy: 0.8377\n",
      "Epoch 242/1000\n",
      "225/225 [==============================] - 1s 3ms/step - loss: 0.4757 - accuracy: 0.8150 - val_loss: 0.4405 - val_accuracy: 0.8336\n",
      "Epoch 243/1000\n",
      "225/225 [==============================] - 1s 3ms/step - loss: 0.4732 - accuracy: 0.8151 - val_loss: 0.4343 - val_accuracy: 0.8334\n",
      "Epoch 244/1000\n",
      "225/225 [==============================] - 1s 3ms/step - loss: 0.4770 - accuracy: 0.8134 - val_loss: 0.4334 - val_accuracy: 0.8365\n",
      "Epoch 245/1000\n",
      "225/225 [==============================] - 1s 3ms/step - loss: 0.4744 - accuracy: 0.8146 - val_loss: 0.4381 - val_accuracy: 0.8344\n",
      "Epoch 246/1000\n",
      "225/225 [==============================] - 1s 3ms/step - loss: 0.4751 - accuracy: 0.8145 - val_loss: 0.4337 - val_accuracy: 0.8386\n",
      "Epoch 247/1000\n",
      "225/225 [==============================] - 1s 3ms/step - loss: 0.4760 - accuracy: 0.8137 - val_loss: 0.4345 - val_accuracy: 0.8387\n",
      "Epoch 248/1000\n",
      "225/225 [==============================] - 1s 3ms/step - loss: 0.4758 - accuracy: 0.8134 - val_loss: 0.4348 - val_accuracy: 0.8355\n",
      "Epoch 249/1000\n",
      "225/225 [==============================] - 1s 3ms/step - loss: 0.4765 - accuracy: 0.8132 - val_loss: 0.4400 - val_accuracy: 0.8330\n",
      "Epoch 250/1000\n",
      "225/225 [==============================] - 1s 3ms/step - loss: 0.4750 - accuracy: 0.8142 - val_loss: 0.4361 - val_accuracy: 0.8369\n",
      "Epoch 251/1000\n",
      "225/225 [==============================] - 1s 3ms/step - loss: 0.4755 - accuracy: 0.8141 - val_loss: 0.4349 - val_accuracy: 0.8373\n",
      "Epoch 252/1000\n",
      "225/225 [==============================] - 1s 3ms/step - loss: 0.4743 - accuracy: 0.8143 - val_loss: 0.4352 - val_accuracy: 0.8360\n",
      "Epoch 253/1000\n",
      "225/225 [==============================] - 1s 3ms/step - loss: 0.4745 - accuracy: 0.8154 - val_loss: 0.4345 - val_accuracy: 0.8378\n",
      "Epoch 254/1000\n",
      "225/225 [==============================] - 1s 3ms/step - loss: 0.4739 - accuracy: 0.8145 - val_loss: 0.4389 - val_accuracy: 0.8336\n",
      "Epoch 255/1000\n",
      "225/225 [==============================] - 1s 3ms/step - loss: 0.4731 - accuracy: 0.8145 - val_loss: 0.4355 - val_accuracy: 0.8379\n",
      "Epoch 256/1000\n",
      "225/225 [==============================] - 1s 3ms/step - loss: 0.4739 - accuracy: 0.8145 - val_loss: 0.4359 - val_accuracy: 0.8376\n",
      "Epoch 257/1000\n",
      "225/225 [==============================] - 1s 3ms/step - loss: 0.4748 - accuracy: 0.8144 - val_loss: 0.4306 - val_accuracy: 0.8358\n",
      "Epoch 258/1000\n",
      "225/225 [==============================] - 1s 3ms/step - loss: 0.4751 - accuracy: 0.8142 - val_loss: 0.4324 - val_accuracy: 0.8354\n",
      "Epoch 259/1000\n",
      "225/225 [==============================] - 1s 3ms/step - loss: 0.4747 - accuracy: 0.8144 - val_loss: 0.4366 - val_accuracy: 0.8391\n",
      "Epoch 260/1000\n",
      "225/225 [==============================] - 1s 3ms/step - loss: 0.4728 - accuracy: 0.8148 - val_loss: 0.4320 - val_accuracy: 0.8410\n",
      "Epoch 261/1000\n",
      "225/225 [==============================] - 1s 3ms/step - loss: 0.4757 - accuracy: 0.8141 - val_loss: 0.4297 - val_accuracy: 0.8384\n",
      "Epoch 262/1000\n",
      "225/225 [==============================] - 1s 3ms/step - loss: 0.4721 - accuracy: 0.8163 - val_loss: 0.4311 - val_accuracy: 0.8386\n",
      "Epoch 263/1000\n",
      "225/225 [==============================] - 1s 3ms/step - loss: 0.4719 - accuracy: 0.8154 - val_loss: 0.4300 - val_accuracy: 0.8387\n",
      "Epoch 264/1000\n",
      "225/225 [==============================] - 1s 4ms/step - loss: 0.4732 - accuracy: 0.8156 - val_loss: 0.4319 - val_accuracy: 0.8393\n",
      "Epoch 265/1000\n",
      "225/225 [==============================] - 1s 3ms/step - loss: 0.4746 - accuracy: 0.8146 - val_loss: 0.4334 - val_accuracy: 0.8384\n",
      "Epoch 266/1000\n",
      "225/225 [==============================] - 1s 3ms/step - loss: 0.4743 - accuracy: 0.8146 - val_loss: 0.4285 - val_accuracy: 0.8409\n",
      "Epoch 267/1000\n",
      "225/225 [==============================] - 1s 3ms/step - loss: 0.4732 - accuracy: 0.8148 - val_loss: 0.4327 - val_accuracy: 0.8374\n",
      "Epoch 268/1000\n",
      "225/225 [==============================] - 1s 3ms/step - loss: 0.4730 - accuracy: 0.8162 - val_loss: 0.4281 - val_accuracy: 0.8400\n",
      "Epoch 269/1000\n",
      "225/225 [==============================] - 1s 3ms/step - loss: 0.4722 - accuracy: 0.8156 - val_loss: 0.4284 - val_accuracy: 0.8401\n",
      "Epoch 270/1000\n",
      "225/225 [==============================] - 1s 3ms/step - loss: 0.4735 - accuracy: 0.8154 - val_loss: 0.4328 - val_accuracy: 0.8364\n",
      "Epoch 271/1000\n",
      "225/225 [==============================] - 1s 3ms/step - loss: 0.4707 - accuracy: 0.8165 - val_loss: 0.4302 - val_accuracy: 0.8387\n",
      "Epoch 272/1000\n",
      "225/225 [==============================] - 1s 3ms/step - loss: 0.4738 - accuracy: 0.8149 - val_loss: 0.4334 - val_accuracy: 0.8360\n",
      "Epoch 273/1000\n",
      "225/225 [==============================] - 1s 3ms/step - loss: 0.4729 - accuracy: 0.8156 - val_loss: 0.4330 - val_accuracy: 0.8410\n",
      "Epoch 274/1000\n",
      "225/225 [==============================] - 1s 3ms/step - loss: 0.4731 - accuracy: 0.8164 - val_loss: 0.4337 - val_accuracy: 0.8372\n",
      "Epoch 275/1000\n",
      "225/225 [==============================] - 1s 3ms/step - loss: 0.4698 - accuracy: 0.8166 - val_loss: 0.4301 - val_accuracy: 0.8387\n",
      "Epoch 276/1000\n",
      "225/225 [==============================] - 1s 3ms/step - loss: 0.4699 - accuracy: 0.8164 - val_loss: 0.4358 - val_accuracy: 0.8381\n",
      "Epoch 277/1000\n",
      "225/225 [==============================] - 1s 3ms/step - loss: 0.4727 - accuracy: 0.8152 - val_loss: 0.4300 - val_accuracy: 0.8397\n",
      "Epoch 278/1000\n",
      "225/225 [==============================] - 1s 3ms/step - loss: 0.4717 - accuracy: 0.8164 - val_loss: 0.4326 - val_accuracy: 0.8371\n",
      "Epoch 279/1000\n",
      "225/225 [==============================] - 1s 3ms/step - loss: 0.4718 - accuracy: 0.8167 - val_loss: 0.4349 - val_accuracy: 0.8378\n",
      "Epoch 280/1000\n",
      "225/225 [==============================] - 1s 3ms/step - loss: 0.4731 - accuracy: 0.8167 - val_loss: 0.4303 - val_accuracy: 0.8394\n",
      "Epoch 281/1000\n",
      "225/225 [==============================] - 1s 3ms/step - loss: 0.4723 - accuracy: 0.8166 - val_loss: 0.4304 - val_accuracy: 0.8399\n",
      "Epoch 282/1000\n",
      "225/225 [==============================] - 1s 3ms/step - loss: 0.4693 - accuracy: 0.8176 - val_loss: 0.4276 - val_accuracy: 0.8380\n",
      "Epoch 283/1000\n",
      "225/225 [==============================] - 1s 3ms/step - loss: 0.4717 - accuracy: 0.8140 - val_loss: 0.4277 - val_accuracy: 0.8385\n",
      "Epoch 284/1000\n",
      "225/225 [==============================] - 1s 3ms/step - loss: 0.4728 - accuracy: 0.8163 - val_loss: 0.4334 - val_accuracy: 0.8402\n",
      "Epoch 285/1000\n",
      "225/225 [==============================] - 1s 3ms/step - loss: 0.4714 - accuracy: 0.8163 - val_loss: 0.4326 - val_accuracy: 0.8374\n",
      "Epoch 286/1000\n",
      "225/225 [==============================] - 1s 3ms/step - loss: 0.4729 - accuracy: 0.8153 - val_loss: 0.4318 - val_accuracy: 0.8387\n",
      "Epoch 287/1000\n",
      "225/225 [==============================] - 1s 3ms/step - loss: 0.4709 - accuracy: 0.8164 - val_loss: 0.4328 - val_accuracy: 0.8384\n",
      "Epoch 288/1000\n",
      "225/225 [==============================] - 1s 3ms/step - loss: 0.4698 - accuracy: 0.8176 - val_loss: 0.4356 - val_accuracy: 0.8381\n",
      "Epoch 289/1000\n",
      "225/225 [==============================] - 1s 3ms/step - loss: 0.4704 - accuracy: 0.8161 - val_loss: 0.4327 - val_accuracy: 0.8388\n",
      "Epoch 290/1000\n",
      "225/225 [==============================] - 1s 3ms/step - loss: 0.4711 - accuracy: 0.8169 - val_loss: 0.4296 - val_accuracy: 0.8397\n",
      "Epoch 291/1000\n",
      "225/225 [==============================] - 1s 3ms/step - loss: 0.4708 - accuracy: 0.8163 - val_loss: 0.4297 - val_accuracy: 0.8384\n",
      "Epoch 292/1000\n",
      "225/225 [==============================] - 1s 3ms/step - loss: 0.4690 - accuracy: 0.8173 - val_loss: 0.4304 - val_accuracy: 0.8397\n",
      "Epoch 293/1000\n",
      "225/225 [==============================] - 1s 3ms/step - loss: 0.4692 - accuracy: 0.8176 - val_loss: 0.4351 - val_accuracy: 0.8363\n",
      "Epoch 294/1000\n",
      "225/225 [==============================] - 1s 3ms/step - loss: 0.4699 - accuracy: 0.8165 - val_loss: 0.4317 - val_accuracy: 0.8393\n",
      "Epoch 295/1000\n",
      "225/225 [==============================] - 1s 3ms/step - loss: 0.4713 - accuracy: 0.8159 - val_loss: 0.4356 - val_accuracy: 0.8385\n",
      "Epoch 296/1000\n",
      "225/225 [==============================] - 1s 3ms/step - loss: 0.4707 - accuracy: 0.8166 - val_loss: 0.4303 - val_accuracy: 0.8416\n",
      "Epoch 297/1000\n",
      "225/225 [==============================] - 1s 3ms/step - loss: 0.4718 - accuracy: 0.8169 - val_loss: 0.4286 - val_accuracy: 0.8419\n",
      "Epoch 298/1000\n",
      "225/225 [==============================] - 1s 3ms/step - loss: 0.4699 - accuracy: 0.8166 - val_loss: 0.4299 - val_accuracy: 0.8406\n",
      "Epoch 299/1000\n",
      "225/225 [==============================] - 1s 3ms/step - loss: 0.4712 - accuracy: 0.8165 - val_loss: 0.4300 - val_accuracy: 0.8368\n",
      "Epoch 300/1000\n",
      "225/225 [==============================] - 1s 3ms/step - loss: 0.4697 - accuracy: 0.8159 - val_loss: 0.4266 - val_accuracy: 0.8430\n",
      "Epoch 301/1000\n",
      "225/225 [==============================] - 1s 3ms/step - loss: 0.4693 - accuracy: 0.8162 - val_loss: 0.4290 - val_accuracy: 0.8394\n",
      "Epoch 302/1000\n",
      "225/225 [==============================] - 1s 3ms/step - loss: 0.4701 - accuracy: 0.8171 - val_loss: 0.4278 - val_accuracy: 0.8413\n",
      "Epoch 303/1000\n",
      "225/225 [==============================] - 1s 3ms/step - loss: 0.4686 - accuracy: 0.8166 - val_loss: 0.4285 - val_accuracy: 0.8408\n",
      "Epoch 304/1000\n",
      "225/225 [==============================] - 1s 3ms/step - loss: 0.4686 - accuracy: 0.8177 - val_loss: 0.4274 - val_accuracy: 0.8424\n",
      "Epoch 305/1000\n",
      "225/225 [==============================] - 1s 3ms/step - loss: 0.4691 - accuracy: 0.8169 - val_loss: 0.4288 - val_accuracy: 0.8372\n",
      "Epoch 306/1000\n",
      "225/225 [==============================] - 1s 3ms/step - loss: 0.4699 - accuracy: 0.8166 - val_loss: 0.4280 - val_accuracy: 0.8412\n",
      "Epoch 307/1000\n",
      "225/225 [==============================] - 1s 3ms/step - loss: 0.4687 - accuracy: 0.8174 - val_loss: 0.4323 - val_accuracy: 0.8373\n",
      "Epoch 308/1000\n",
      "225/225 [==============================] - 1s 3ms/step - loss: 0.4685 - accuracy: 0.8175 - val_loss: 0.4292 - val_accuracy: 0.8414\n",
      "Epoch 309/1000\n",
      "225/225 [==============================] - 1s 3ms/step - loss: 0.4703 - accuracy: 0.8160 - val_loss: 0.4320 - val_accuracy: 0.8367\n",
      "Epoch 310/1000\n",
      "225/225 [==============================] - 1s 3ms/step - loss: 0.4693 - accuracy: 0.8172 - val_loss: 0.4313 - val_accuracy: 0.8414\n",
      "Epoch 311/1000\n",
      "225/225 [==============================] - 1s 3ms/step - loss: 0.4679 - accuracy: 0.8176 - val_loss: 0.4305 - val_accuracy: 0.8390\n",
      "Epoch 312/1000\n",
      "225/225 [==============================] - 1s 3ms/step - loss: 0.4685 - accuracy: 0.8175 - val_loss: 0.4274 - val_accuracy: 0.8420\n",
      "Epoch 313/1000\n",
      "225/225 [==============================] - 1s 3ms/step - loss: 0.4680 - accuracy: 0.8178 - val_loss: 0.4283 - val_accuracy: 0.8405\n",
      "Epoch 314/1000\n",
      "225/225 [==============================] - 1s 3ms/step - loss: 0.4699 - accuracy: 0.8167 - val_loss: 0.4284 - val_accuracy: 0.8424\n",
      "Epoch 315/1000\n",
      "225/225 [==============================] - 1s 3ms/step - loss: 0.4692 - accuracy: 0.8174 - val_loss: 0.4333 - val_accuracy: 0.8411\n",
      "Epoch 316/1000\n",
      "225/225 [==============================] - 1s 3ms/step - loss: 0.4695 - accuracy: 0.8167 - val_loss: 0.4329 - val_accuracy: 0.8373\n",
      "Epoch 317/1000\n",
      "225/225 [==============================] - 1s 3ms/step - loss: 0.4670 - accuracy: 0.8185 - val_loss: 0.4289 - val_accuracy: 0.8411\n",
      "Epoch 318/1000\n",
      "225/225 [==============================] - 1s 3ms/step - loss: 0.4660 - accuracy: 0.8187 - val_loss: 0.4262 - val_accuracy: 0.8434\n",
      "Epoch 319/1000\n",
      "225/225 [==============================] - 1s 3ms/step - loss: 0.4674 - accuracy: 0.8178 - val_loss: 0.4277 - val_accuracy: 0.8407\n",
      "Epoch 320/1000\n",
      "225/225 [==============================] - 1s 3ms/step - loss: 0.4662 - accuracy: 0.8172 - val_loss: 0.4311 - val_accuracy: 0.8391\n",
      "Epoch 321/1000\n",
      "225/225 [==============================] - 1s 3ms/step - loss: 0.4679 - accuracy: 0.8183 - val_loss: 0.4317 - val_accuracy: 0.8380\n",
      "Epoch 322/1000\n",
      "225/225 [==============================] - 1s 3ms/step - loss: 0.4660 - accuracy: 0.8183 - val_loss: 0.4307 - val_accuracy: 0.8397\n",
      "Epoch 323/1000\n",
      "225/225 [==============================] - 1s 3ms/step - loss: 0.4670 - accuracy: 0.8174 - val_loss: 0.4274 - val_accuracy: 0.8405\n",
      "Epoch 324/1000\n",
      "225/225 [==============================] - 1s 3ms/step - loss: 0.4664 - accuracy: 0.8176 - val_loss: 0.4287 - val_accuracy: 0.8405\n",
      "Epoch 325/1000\n",
      "225/225 [==============================] - 1s 3ms/step - loss: 0.4695 - accuracy: 0.8166 - val_loss: 0.4279 - val_accuracy: 0.8390\n",
      "Epoch 326/1000\n",
      "225/225 [==============================] - 1s 3ms/step - loss: 0.4669 - accuracy: 0.8171 - val_loss: 0.4280 - val_accuracy: 0.8420\n",
      "Epoch 327/1000\n",
      "225/225 [==============================] - 1s 3ms/step - loss: 0.4663 - accuracy: 0.8183 - val_loss: 0.4285 - val_accuracy: 0.8407\n",
      "Epoch 328/1000\n",
      "225/225 [==============================] - 1s 3ms/step - loss: 0.4675 - accuracy: 0.8171 - val_loss: 0.4255 - val_accuracy: 0.8432\n",
      "Epoch 329/1000\n",
      "225/225 [==============================] - 1s 3ms/step - loss: 0.4671 - accuracy: 0.8176 - val_loss: 0.4260 - val_accuracy: 0.8404\n",
      "Epoch 330/1000\n",
      "225/225 [==============================] - 1s 3ms/step - loss: 0.4675 - accuracy: 0.8175 - val_loss: 0.4290 - val_accuracy: 0.8410\n",
      "Epoch 331/1000\n",
      "225/225 [==============================] - 1s 3ms/step - loss: 0.4660 - accuracy: 0.8185 - val_loss: 0.4260 - val_accuracy: 0.8410\n",
      "Epoch 332/1000\n",
      "225/225 [==============================] - 1s 3ms/step - loss: 0.4654 - accuracy: 0.8176 - val_loss: 0.4295 - val_accuracy: 0.8375\n",
      "Epoch 333/1000\n",
      "225/225 [==============================] - 1s 3ms/step - loss: 0.4676 - accuracy: 0.8173 - val_loss: 0.4243 - val_accuracy: 0.8402\n",
      "Epoch 334/1000\n",
      "225/225 [==============================] - 1s 3ms/step - loss: 0.4671 - accuracy: 0.8193 - val_loss: 0.4257 - val_accuracy: 0.8423\n",
      "Epoch 335/1000\n",
      "225/225 [==============================] - 1s 3ms/step - loss: 0.4697 - accuracy: 0.8165 - val_loss: 0.4291 - val_accuracy: 0.8376\n",
      "Epoch 336/1000\n",
      "225/225 [==============================] - 1s 3ms/step - loss: 0.4675 - accuracy: 0.8182 - val_loss: 0.4249 - val_accuracy: 0.8431\n",
      "Epoch 337/1000\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "225/225 [==============================] - 1s 3ms/step - loss: 0.4672 - accuracy: 0.8176 - val_loss: 0.4284 - val_accuracy: 0.8399\n",
      "Epoch 338/1000\n",
      "225/225 [==============================] - 1s 3ms/step - loss: 0.4646 - accuracy: 0.8190 - val_loss: 0.4236 - val_accuracy: 0.8405\n",
      "Epoch 339/1000\n",
      "225/225 [==============================] - 1s 3ms/step - loss: 0.4677 - accuracy: 0.8168 - val_loss: 0.4291 - val_accuracy: 0.8386\n",
      "Epoch 340/1000\n",
      "225/225 [==============================] - 1s 3ms/step - loss: 0.4658 - accuracy: 0.8186 - val_loss: 0.4284 - val_accuracy: 0.8394\n",
      "Epoch 341/1000\n",
      "225/225 [==============================] - 1s 3ms/step - loss: 0.4637 - accuracy: 0.8199 - val_loss: 0.4242 - val_accuracy: 0.8400\n",
      "Epoch 342/1000\n",
      "225/225 [==============================] - 1s 3ms/step - loss: 0.4663 - accuracy: 0.8182 - val_loss: 0.4262 - val_accuracy: 0.8419\n",
      "Epoch 343/1000\n",
      "225/225 [==============================] - 1s 3ms/step - loss: 0.4648 - accuracy: 0.8190 - val_loss: 0.4278 - val_accuracy: 0.8414\n",
      "Epoch 344/1000\n",
      "225/225 [==============================] - 1s 3ms/step - loss: 0.4642 - accuracy: 0.8181 - val_loss: 0.4250 - val_accuracy: 0.8414\n",
      "Epoch 345/1000\n",
      "225/225 [==============================] - 1s 3ms/step - loss: 0.4667 - accuracy: 0.8181 - val_loss: 0.4265 - val_accuracy: 0.8421\n",
      "Epoch 346/1000\n",
      "225/225 [==============================] - 1s 3ms/step - loss: 0.4680 - accuracy: 0.8178 - val_loss: 0.4254 - val_accuracy: 0.8408\n",
      "Epoch 347/1000\n",
      "225/225 [==============================] - 1s 3ms/step - loss: 0.4655 - accuracy: 0.8187 - val_loss: 0.4237 - val_accuracy: 0.8416\n",
      "Epoch 348/1000\n",
      "225/225 [==============================] - 1s 3ms/step - loss: 0.4665 - accuracy: 0.8174 - val_loss: 0.4260 - val_accuracy: 0.8406\n",
      "Epoch 349/1000\n",
      "225/225 [==============================] - 1s 3ms/step - loss: 0.4649 - accuracy: 0.8187 - val_loss: 0.4282 - val_accuracy: 0.8383\n",
      "Epoch 350/1000\n",
      "225/225 [==============================] - 1s 3ms/step - loss: 0.4653 - accuracy: 0.8186 - val_loss: 0.4243 - val_accuracy: 0.8420\n",
      "Epoch 351/1000\n",
      "225/225 [==============================] - 1s 3ms/step - loss: 0.4641 - accuracy: 0.8195 - val_loss: 0.4271 - val_accuracy: 0.8423\n",
      "Epoch 352/1000\n",
      "225/225 [==============================] - 1s 3ms/step - loss: 0.4674 - accuracy: 0.8184 - val_loss: 0.4254 - val_accuracy: 0.8427\n",
      "Epoch 353/1000\n",
      "225/225 [==============================] - 1s 3ms/step - loss: 0.4653 - accuracy: 0.8193 - val_loss: 0.4273 - val_accuracy: 0.8396\n",
      "Epoch 354/1000\n",
      "225/225 [==============================] - 1s 3ms/step - loss: 0.4642 - accuracy: 0.8188 - val_loss: 0.4248 - val_accuracy: 0.8401\n",
      "Epoch 355/1000\n",
      "225/225 [==============================] - 1s 3ms/step - loss: 0.4632 - accuracy: 0.8181 - val_loss: 0.4299 - val_accuracy: 0.8355\n",
      "Epoch 356/1000\n",
      "225/225 [==============================] - 1s 3ms/step - loss: 0.4669 - accuracy: 0.8176 - val_loss: 0.4279 - val_accuracy: 0.8397\n",
      "Epoch 357/1000\n",
      "225/225 [==============================] - 1s 3ms/step - loss: 0.4657 - accuracy: 0.8183 - val_loss: 0.4259 - val_accuracy: 0.8432\n",
      "Epoch 358/1000\n",
      "225/225 [==============================] - 1s 3ms/step - loss: 0.4639 - accuracy: 0.8196 - val_loss: 0.4279 - val_accuracy: 0.8390\n",
      "Epoch 359/1000\n",
      "225/225 [==============================] - 1s 3ms/step - loss: 0.4642 - accuracy: 0.8175 - val_loss: 0.4252 - val_accuracy: 0.8406\n",
      "Epoch 360/1000\n",
      "225/225 [==============================] - 1s 3ms/step - loss: 0.4653 - accuracy: 0.8191 - val_loss: 0.4223 - val_accuracy: 0.8447\n",
      "Epoch 361/1000\n",
      "225/225 [==============================] - 1s 3ms/step - loss: 0.4642 - accuracy: 0.8182 - val_loss: 0.4269 - val_accuracy: 0.8411\n",
      "Epoch 362/1000\n",
      "225/225 [==============================] - 1s 3ms/step - loss: 0.4629 - accuracy: 0.8194 - val_loss: 0.4252 - val_accuracy: 0.8431\n",
      "Epoch 363/1000\n",
      "225/225 [==============================] - 1s 3ms/step - loss: 0.4658 - accuracy: 0.8187 - val_loss: 0.4300 - val_accuracy: 0.8382\n",
      "Epoch 364/1000\n",
      "225/225 [==============================] - 1s 3ms/step - loss: 0.4648 - accuracy: 0.8196 - val_loss: 0.4253 - val_accuracy: 0.8413\n",
      "Epoch 365/1000\n",
      "225/225 [==============================] - 1s 3ms/step - loss: 0.4655 - accuracy: 0.8186 - val_loss: 0.4262 - val_accuracy: 0.8413\n",
      "Epoch 366/1000\n",
      "225/225 [==============================] - 1s 3ms/step - loss: 0.4650 - accuracy: 0.8186 - val_loss: 0.4241 - val_accuracy: 0.8408\n",
      "Epoch 367/1000\n",
      "225/225 [==============================] - 1s 3ms/step - loss: 0.4632 - accuracy: 0.8191 - val_loss: 0.4263 - val_accuracy: 0.8412\n",
      "Epoch 368/1000\n",
      "225/225 [==============================] - 1s 3ms/step - loss: 0.4646 - accuracy: 0.8185 - val_loss: 0.4317 - val_accuracy: 0.8353\n",
      "Epoch 369/1000\n",
      "225/225 [==============================] - 1s 3ms/step - loss: 0.4634 - accuracy: 0.8193 - val_loss: 0.4241 - val_accuracy: 0.8432\n",
      "Epoch 370/1000\n",
      "225/225 [==============================] - 1s 3ms/step - loss: 0.4649 - accuracy: 0.8181 - val_loss: 0.4251 - val_accuracy: 0.8432\n",
      "Epoch 371/1000\n",
      "225/225 [==============================] - 1s 3ms/step - loss: 0.4657 - accuracy: 0.8178 - val_loss: 0.4258 - val_accuracy: 0.8416\n",
      "Epoch 372/1000\n",
      "225/225 [==============================] - 1s 3ms/step - loss: 0.4640 - accuracy: 0.8184 - val_loss: 0.4248 - val_accuracy: 0.8405\n",
      "Epoch 373/1000\n",
      "225/225 [==============================] - 1s 3ms/step - loss: 0.4630 - accuracy: 0.8196 - val_loss: 0.4216 - val_accuracy: 0.8443\n",
      "Epoch 374/1000\n",
      "225/225 [==============================] - 1s 3ms/step - loss: 0.4625 - accuracy: 0.8190 - val_loss: 0.4249 - val_accuracy: 0.8410\n",
      "Epoch 375/1000\n",
      "225/225 [==============================] - 1s 3ms/step - loss: 0.4652 - accuracy: 0.8179 - val_loss: 0.4274 - val_accuracy: 0.8413\n",
      "Epoch 376/1000\n",
      "225/225 [==============================] - 1s 3ms/step - loss: 0.4640 - accuracy: 0.8187 - val_loss: 0.4207 - val_accuracy: 0.8444\n",
      "Epoch 377/1000\n",
      "225/225 [==============================] - 1s 3ms/step - loss: 0.4625 - accuracy: 0.8197 - val_loss: 0.4224 - val_accuracy: 0.8401\n",
      "Epoch 378/1000\n",
      "225/225 [==============================] - 1s 3ms/step - loss: 0.4647 - accuracy: 0.8194 - val_loss: 0.4240 - val_accuracy: 0.8423\n",
      "Epoch 379/1000\n",
      "225/225 [==============================] - 1s 3ms/step - loss: 0.4618 - accuracy: 0.8203 - val_loss: 0.4232 - val_accuracy: 0.8438\n",
      "Epoch 380/1000\n",
      "225/225 [==============================] - 1s 3ms/step - loss: 0.4633 - accuracy: 0.8191 - val_loss: 0.4257 - val_accuracy: 0.8407\n",
      "Epoch 381/1000\n",
      "225/225 [==============================] - 1s 3ms/step - loss: 0.4624 - accuracy: 0.8202 - val_loss: 0.4295 - val_accuracy: 0.8383\n",
      "Epoch 382/1000\n",
      "225/225 [==============================] - 1s 3ms/step - loss: 0.4647 - accuracy: 0.8189 - val_loss: 0.4263 - val_accuracy: 0.8415\n",
      "Epoch 383/1000\n",
      "225/225 [==============================] - 1s 3ms/step - loss: 0.4623 - accuracy: 0.8196 - val_loss: 0.4245 - val_accuracy: 0.8413\n",
      "Epoch 384/1000\n",
      "225/225 [==============================] - 1s 3ms/step - loss: 0.4632 - accuracy: 0.8196 - val_loss: 0.4239 - val_accuracy: 0.8419\n",
      "Epoch 385/1000\n",
      "225/225 [==============================] - 1s 3ms/step - loss: 0.4639 - accuracy: 0.8198 - val_loss: 0.4249 - val_accuracy: 0.8434\n",
      "Epoch 386/1000\n",
      "225/225 [==============================] - 1s 3ms/step - loss: 0.4643 - accuracy: 0.8189 - val_loss: 0.4240 - val_accuracy: 0.8414\n",
      "Epoch 387/1000\n",
      "225/225 [==============================] - 1s 3ms/step - loss: 0.4626 - accuracy: 0.8206 - val_loss: 0.4231 - val_accuracy: 0.8418\n",
      "Epoch 388/1000\n",
      "225/225 [==============================] - 1s 3ms/step - loss: 0.4639 - accuracy: 0.8185 - val_loss: 0.4253 - val_accuracy: 0.8414\n",
      "Epoch 389/1000\n",
      "225/225 [==============================] - 1s 3ms/step - loss: 0.4630 - accuracy: 0.8193 - val_loss: 0.4257 - val_accuracy: 0.8423\n",
      "Epoch 390/1000\n",
      "225/225 [==============================] - 1s 3ms/step - loss: 0.4632 - accuracy: 0.8186 - val_loss: 0.4270 - val_accuracy: 0.8413\n",
      "Epoch 391/1000\n",
      "225/225 [==============================] - 1s 3ms/step - loss: 0.4631 - accuracy: 0.8203 - val_loss: 0.4233 - val_accuracy: 0.8431\n",
      "Epoch 392/1000\n",
      "225/225 [==============================] - 1s 3ms/step - loss: 0.4631 - accuracy: 0.8192 - val_loss: 0.4245 - val_accuracy: 0.8435\n",
      "Epoch 393/1000\n",
      "225/225 [==============================] - 1s 3ms/step - loss: 0.4644 - accuracy: 0.8192 - val_loss: 0.4268 - val_accuracy: 0.8419\n",
      "Epoch 394/1000\n",
      "225/225 [==============================] - 1s 3ms/step - loss: 0.4627 - accuracy: 0.8200 - val_loss: 0.4197 - val_accuracy: 0.8428\n",
      "Epoch 395/1000\n",
      "225/225 [==============================] - 1s 3ms/step - loss: 0.4611 - accuracy: 0.8196 - val_loss: 0.4216 - val_accuracy: 0.8424\n",
      "Epoch 396/1000\n",
      "225/225 [==============================] - 1s 3ms/step - loss: 0.4629 - accuracy: 0.8205 - val_loss: 0.4223 - val_accuracy: 0.8435\n",
      "Epoch 397/1000\n",
      "225/225 [==============================] - 1s 3ms/step - loss: 0.4622 - accuracy: 0.8201 - val_loss: 0.4260 - val_accuracy: 0.8409\n",
      "Epoch 398/1000\n",
      "225/225 [==============================] - 1s 3ms/step - loss: 0.4598 - accuracy: 0.8200 - val_loss: 0.4218 - val_accuracy: 0.8431\n",
      "Epoch 399/1000\n",
      "225/225 [==============================] - 1s 3ms/step - loss: 0.4625 - accuracy: 0.8199 - val_loss: 0.4230 - val_accuracy: 0.8436\n",
      "Epoch 400/1000\n",
      "225/225 [==============================] - 1s 3ms/step - loss: 0.4608 - accuracy: 0.8201 - val_loss: 0.4192 - val_accuracy: 0.8451\n",
      "Epoch 401/1000\n",
      "225/225 [==============================] - 1s 3ms/step - loss: 0.4608 - accuracy: 0.8209 - val_loss: 0.4213 - val_accuracy: 0.8436\n",
      "Epoch 402/1000\n",
      "225/225 [==============================] - 1s 3ms/step - loss: 0.4630 - accuracy: 0.8191 - val_loss: 0.4228 - val_accuracy: 0.8417\n",
      "Epoch 403/1000\n",
      "225/225 [==============================] - 1s 3ms/step - loss: 0.4632 - accuracy: 0.8197 - val_loss: 0.4230 - val_accuracy: 0.8431\n",
      "Epoch 404/1000\n",
      "225/225 [==============================] - 1s 3ms/step - loss: 0.4600 - accuracy: 0.8201 - val_loss: 0.4232 - val_accuracy: 0.8409\n",
      "Epoch 405/1000\n",
      "225/225 [==============================] - 1s 3ms/step - loss: 0.4611 - accuracy: 0.8208 - val_loss: 0.4225 - val_accuracy: 0.8396\n",
      "Epoch 406/1000\n",
      "225/225 [==============================] - 1s 3ms/step - loss: 0.4642 - accuracy: 0.8194 - val_loss: 0.4274 - val_accuracy: 0.8389\n",
      "Epoch 407/1000\n",
      "225/225 [==============================] - 1s 3ms/step - loss: 0.4603 - accuracy: 0.8206 - val_loss: 0.4243 - val_accuracy: 0.8420\n",
      "Epoch 408/1000\n",
      "225/225 [==============================] - 1s 3ms/step - loss: 0.4623 - accuracy: 0.8197 - val_loss: 0.4219 - val_accuracy: 0.8458\n",
      "Epoch 409/1000\n",
      "225/225 [==============================] - 1s 3ms/step - loss: 0.4619 - accuracy: 0.8193 - val_loss: 0.4230 - val_accuracy: 0.8419\n",
      "Epoch 410/1000\n",
      "225/225 [==============================] - 1s 3ms/step - loss: 0.4616 - accuracy: 0.8218 - val_loss: 0.4250 - val_accuracy: 0.8413\n",
      "Epoch 411/1000\n",
      "225/225 [==============================] - 1s 3ms/step - loss: 0.4620 - accuracy: 0.8200 - val_loss: 0.4227 - val_accuracy: 0.8434\n",
      "Epoch 412/1000\n",
      "225/225 [==============================] - 1s 3ms/step - loss: 0.4616 - accuracy: 0.8197 - val_loss: 0.4220 - val_accuracy: 0.8427\n",
      "Epoch 413/1000\n",
      "225/225 [==============================] - 1s 3ms/step - loss: 0.4610 - accuracy: 0.8211 - val_loss: 0.4261 - val_accuracy: 0.8380\n",
      "Epoch 414/1000\n",
      "225/225 [==============================] - 1s 3ms/step - loss: 0.4624 - accuracy: 0.8210 - val_loss: 0.4230 - val_accuracy: 0.8440\n",
      "Epoch 415/1000\n",
      "225/225 [==============================] - 1s 3ms/step - loss: 0.4585 - accuracy: 0.8215 - val_loss: 0.4193 - val_accuracy: 0.8457\n",
      "Epoch 416/1000\n",
      "225/225 [==============================] - 1s 3ms/step - loss: 0.4608 - accuracy: 0.8198 - val_loss: 0.4226 - val_accuracy: 0.8438\n",
      "Epoch 417/1000\n",
      "225/225 [==============================] - 1s 3ms/step - loss: 0.4614 - accuracy: 0.8202 - val_loss: 0.4217 - val_accuracy: 0.8423\n",
      "Epoch 418/1000\n",
      "225/225 [==============================] - 1s 3ms/step - loss: 0.4601 - accuracy: 0.8210 - val_loss: 0.4227 - val_accuracy: 0.8429\n",
      "Epoch 419/1000\n",
      "225/225 [==============================] - 1s 3ms/step - loss: 0.4577 - accuracy: 0.8225 - val_loss: 0.4211 - val_accuracy: 0.8422\n",
      "Epoch 420/1000\n",
      "225/225 [==============================] - 1s 3ms/step - loss: 0.4609 - accuracy: 0.8210 - val_loss: 0.4225 - val_accuracy: 0.8418\n",
      "Epoch 421/1000\n",
      "225/225 [==============================] - 1s 3ms/step - loss: 0.4616 - accuracy: 0.8205 - val_loss: 0.4218 - val_accuracy: 0.8424\n",
      "Epoch 422/1000\n",
      "225/225 [==============================] - 1s 3ms/step - loss: 0.4607 - accuracy: 0.8206 - val_loss: 0.4213 - val_accuracy: 0.8434\n",
      "Epoch 423/1000\n",
      "225/225 [==============================] - 1s 3ms/step - loss: 0.4609 - accuracy: 0.8205 - val_loss: 0.4233 - val_accuracy: 0.8444\n",
      "Epoch 424/1000\n",
      "225/225 [==============================] - 1s 3ms/step - loss: 0.4608 - accuracy: 0.8208 - val_loss: 0.4256 - val_accuracy: 0.8403\n",
      "Epoch 425/1000\n",
      "225/225 [==============================] - 1s 3ms/step - loss: 0.4611 - accuracy: 0.8208 - val_loss: 0.4221 - val_accuracy: 0.8439\n",
      "Epoch 426/1000\n",
      "225/225 [==============================] - 1s 3ms/step - loss: 0.4604 - accuracy: 0.8212 - val_loss: 0.4245 - val_accuracy: 0.8418\n",
      "Epoch 427/1000\n",
      "225/225 [==============================] - 1s 3ms/step - loss: 0.4607 - accuracy: 0.8201 - val_loss: 0.4222 - val_accuracy: 0.8435\n",
      "Epoch 428/1000\n",
      "225/225 [==============================] - 1s 3ms/step - loss: 0.4610 - accuracy: 0.8206 - val_loss: 0.4240 - val_accuracy: 0.8427\n",
      "Epoch 429/1000\n",
      "225/225 [==============================] - 1s 3ms/step - loss: 0.4611 - accuracy: 0.8206 - val_loss: 0.4238 - val_accuracy: 0.8438\n",
      "Epoch 430/1000\n",
      "225/225 [==============================] - 1s 3ms/step - loss: 0.4609 - accuracy: 0.8209 - val_loss: 0.4220 - val_accuracy: 0.8463\n",
      "Epoch 431/1000\n",
      "225/225 [==============================] - 1s 3ms/step - loss: 0.4610 - accuracy: 0.8208 - val_loss: 0.4241 - val_accuracy: 0.8442\n",
      "Epoch 432/1000\n",
      "225/225 [==============================] - 1s 3ms/step - loss: 0.4610 - accuracy: 0.8204 - val_loss: 0.4215 - val_accuracy: 0.8438\n",
      "Epoch 433/1000\n",
      "225/225 [==============================] - 1s 3ms/step - loss: 0.4597 - accuracy: 0.8215 - val_loss: 0.4208 - val_accuracy: 0.8434\n",
      "Epoch 434/1000\n",
      "225/225 [==============================] - 1s 3ms/step - loss: 0.4599 - accuracy: 0.8210 - val_loss: 0.4227 - val_accuracy: 0.8426\n",
      "Epoch 435/1000\n",
      "225/225 [==============================] - 1s 3ms/step - loss: 0.4612 - accuracy: 0.8212 - val_loss: 0.4201 - val_accuracy: 0.8434\n",
      "Epoch 436/1000\n",
      "225/225 [==============================] - 1s 3ms/step - loss: 0.4618 - accuracy: 0.8206 - val_loss: 0.4253 - val_accuracy: 0.8413\n",
      "Epoch 437/1000\n",
      "225/225 [==============================] - 1s 3ms/step - loss: 0.4579 - accuracy: 0.8211 - val_loss: 0.4226 - val_accuracy: 0.8431\n",
      "Epoch 438/1000\n",
      "225/225 [==============================] - 1s 3ms/step - loss: 0.4602 - accuracy: 0.8205 - val_loss: 0.4225 - val_accuracy: 0.8420\n",
      "Epoch 439/1000\n",
      "225/225 [==============================] - 1s 3ms/step - loss: 0.4608 - accuracy: 0.8206 - val_loss: 0.4244 - val_accuracy: 0.8441\n",
      "Epoch 440/1000\n",
      "225/225 [==============================] - 1s 3ms/step - loss: 0.4585 - accuracy: 0.8209 - val_loss: 0.4266 - val_accuracy: 0.8406\n",
      "Epoch 441/1000\n",
      "225/225 [==============================] - 1s 3ms/step - loss: 0.4598 - accuracy: 0.8203 - val_loss: 0.4202 - val_accuracy: 0.8425\n",
      "Epoch 442/1000\n",
      "225/225 [==============================] - 1s 3ms/step - loss: 0.4600 - accuracy: 0.8200 - val_loss: 0.4223 - val_accuracy: 0.8438\n",
      "Epoch 443/1000\n",
      "225/225 [==============================] - 1s 3ms/step - loss: 0.4585 - accuracy: 0.8213 - val_loss: 0.4225 - val_accuracy: 0.8430\n",
      "Epoch 444/1000\n",
      "225/225 [==============================] - 1s 3ms/step - loss: 0.4598 - accuracy: 0.8207 - val_loss: 0.4225 - val_accuracy: 0.8445\n",
      "Epoch 445/1000\n",
      "225/225 [==============================] - 1s 3ms/step - loss: 0.4589 - accuracy: 0.8214 - val_loss: 0.4221 - val_accuracy: 0.8435\n",
      "Epoch 446/1000\n",
      "225/225 [==============================] - 1s 3ms/step - loss: 0.4587 - accuracy: 0.8216 - val_loss: 0.4204 - val_accuracy: 0.8416\n",
      "Epoch 447/1000\n",
      "225/225 [==============================] - 1s 3ms/step - loss: 0.4590 - accuracy: 0.8214 - val_loss: 0.4232 - val_accuracy: 0.8415\n",
      "Epoch 448/1000\n",
      "225/225 [==============================] - 1s 3ms/step - loss: 0.4587 - accuracy: 0.8220 - val_loss: 0.4204 - val_accuracy: 0.8438\n",
      "Epoch 449/1000\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "225/225 [==============================] - 1s 3ms/step - loss: 0.4583 - accuracy: 0.8212 - val_loss: 0.4235 - val_accuracy: 0.8422\n",
      "Epoch 450/1000\n",
      "225/225 [==============================] - 1s 3ms/step - loss: 0.4573 - accuracy: 0.8216 - val_loss: 0.4224 - val_accuracy: 0.8444\n",
      "Epoch 451/1000\n",
      "225/225 [==============================] - 1s 3ms/step - loss: 0.4577 - accuracy: 0.8218 - val_loss: 0.4226 - val_accuracy: 0.8436\n",
      "Epoch 452/1000\n",
      "225/225 [==============================] - 1s 3ms/step - loss: 0.4588 - accuracy: 0.8207 - val_loss: 0.4194 - val_accuracy: 0.8436\n",
      "Epoch 453/1000\n",
      "225/225 [==============================] - 1s 3ms/step - loss: 0.4603 - accuracy: 0.8202 - val_loss: 0.4243 - val_accuracy: 0.8392\n",
      "Epoch 454/1000\n",
      "225/225 [==============================] - 1s 3ms/step - loss: 0.4605 - accuracy: 0.8194 - val_loss: 0.4215 - val_accuracy: 0.8420\n",
      "Epoch 455/1000\n",
      "225/225 [==============================] - 1s 3ms/step - loss: 0.4584 - accuracy: 0.8211 - val_loss: 0.4210 - val_accuracy: 0.8431\n",
      "Epoch 456/1000\n",
      "225/225 [==============================] - 1s 3ms/step - loss: 0.4606 - accuracy: 0.8209 - val_loss: 0.4237 - val_accuracy: 0.8427\n",
      "Epoch 457/1000\n",
      "225/225 [==============================] - 1s 3ms/step - loss: 0.4587 - accuracy: 0.8226 - val_loss: 0.4218 - val_accuracy: 0.8427\n",
      "Epoch 458/1000\n",
      "225/225 [==============================] - 1s 3ms/step - loss: 0.4607 - accuracy: 0.8206 - val_loss: 0.4226 - val_accuracy: 0.8423\n",
      "Epoch 459/1000\n",
      "225/225 [==============================] - 1s 3ms/step - loss: 0.4569 - accuracy: 0.8219 - val_loss: 0.4227 - val_accuracy: 0.8406\n",
      "Epoch 460/1000\n",
      "225/225 [==============================] - 1s 3ms/step - loss: 0.4582 - accuracy: 0.8210 - val_loss: 0.4228 - val_accuracy: 0.8428\n",
      "Epoch 461/1000\n",
      "225/225 [==============================] - 1s 3ms/step - loss: 0.4586 - accuracy: 0.8222 - val_loss: 0.4223 - val_accuracy: 0.8441\n",
      "Epoch 462/1000\n",
      "225/225 [==============================] - 1s 3ms/step - loss: 0.4603 - accuracy: 0.8208 - val_loss: 0.4207 - val_accuracy: 0.8436\n",
      "Epoch 463/1000\n",
      "225/225 [==============================] - 1s 3ms/step - loss: 0.4577 - accuracy: 0.8225 - val_loss: 0.4232 - val_accuracy: 0.8422\n",
      "Epoch 464/1000\n",
      "225/225 [==============================] - 1s 3ms/step - loss: 0.4581 - accuracy: 0.8217 - val_loss: 0.4224 - val_accuracy: 0.8461\n",
      "Epoch 465/1000\n",
      "225/225 [==============================] - 1s 3ms/step - loss: 0.4587 - accuracy: 0.8206 - val_loss: 0.4227 - val_accuracy: 0.8433\n",
      "Epoch 466/1000\n",
      "225/225 [==============================] - 1s 3ms/step - loss: 0.4596 - accuracy: 0.8208 - val_loss: 0.4214 - val_accuracy: 0.8404\n",
      "Epoch 467/1000\n",
      "225/225 [==============================] - 1s 3ms/step - loss: 0.4574 - accuracy: 0.8211 - val_loss: 0.4201 - val_accuracy: 0.8434\n",
      "Epoch 468/1000\n",
      "225/225 [==============================] - 1s 3ms/step - loss: 0.4598 - accuracy: 0.8210 - val_loss: 0.4207 - val_accuracy: 0.8436\n",
      "Epoch 469/1000\n",
      "225/225 [==============================] - 1s 3ms/step - loss: 0.4587 - accuracy: 0.8214 - val_loss: 0.4246 - val_accuracy: 0.8406\n",
      "Epoch 470/1000\n",
      "225/225 [==============================] - 1s 4ms/step - loss: 0.4598 - accuracy: 0.8209 - val_loss: 0.4209 - val_accuracy: 0.8436\n",
      "Epoch 471/1000\n",
      "225/225 [==============================] - 1s 3ms/step - loss: 0.4553 - accuracy: 0.8232 - val_loss: 0.4222 - val_accuracy: 0.8405\n",
      "Epoch 472/1000\n",
      "225/225 [==============================] - 1s 3ms/step - loss: 0.4617 - accuracy: 0.8215 - val_loss: 0.4236 - val_accuracy: 0.8438\n",
      "Epoch 473/1000\n",
      "225/225 [==============================] - 1s 3ms/step - loss: 0.4599 - accuracy: 0.8208 - val_loss: 0.4209 - val_accuracy: 0.8431\n",
      "Epoch 474/1000\n",
      "225/225 [==============================] - 1s 3ms/step - loss: 0.4574 - accuracy: 0.8215 - val_loss: 0.4181 - val_accuracy: 0.8450\n",
      "Epoch 475/1000\n",
      "225/225 [==============================] - 1s 3ms/step - loss: 0.4586 - accuracy: 0.8218 - val_loss: 0.4218 - val_accuracy: 0.8429\n",
      "Epoch 476/1000\n",
      "225/225 [==============================] - 1s 3ms/step - loss: 0.4583 - accuracy: 0.8223 - val_loss: 0.4212 - val_accuracy: 0.8436\n",
      "Epoch 477/1000\n",
      "225/225 [==============================] - 1s 3ms/step - loss: 0.4594 - accuracy: 0.8218 - val_loss: 0.4205 - val_accuracy: 0.8455\n",
      "Epoch 478/1000\n",
      "225/225 [==============================] - 1s 3ms/step - loss: 0.4595 - accuracy: 0.8213 - val_loss: 0.4243 - val_accuracy: 0.8425\n",
      "Epoch 479/1000\n",
      "225/225 [==============================] - 1s 3ms/step - loss: 0.4589 - accuracy: 0.8210 - val_loss: 0.4231 - val_accuracy: 0.8419\n",
      "Epoch 480/1000\n",
      "225/225 [==============================] - 1s 3ms/step - loss: 0.4577 - accuracy: 0.8218 - val_loss: 0.4214 - val_accuracy: 0.8436\n",
      "Epoch 481/1000\n",
      "225/225 [==============================] - 1s 3ms/step - loss: 0.4576 - accuracy: 0.8219 - val_loss: 0.4197 - val_accuracy: 0.8437\n",
      "Epoch 482/1000\n",
      "225/225 [==============================] - 1s 3ms/step - loss: 0.4561 - accuracy: 0.8225 - val_loss: 0.4209 - val_accuracy: 0.8442\n",
      "Epoch 483/1000\n",
      "225/225 [==============================] - 1s 3ms/step - loss: 0.4582 - accuracy: 0.8221 - val_loss: 0.4220 - val_accuracy: 0.8416\n",
      "Epoch 484/1000\n",
      "225/225 [==============================] - 1s 3ms/step - loss: 0.4562 - accuracy: 0.8229 - val_loss: 0.4221 - val_accuracy: 0.8423\n",
      "Epoch 485/1000\n",
      "225/225 [==============================] - 1s 3ms/step - loss: 0.4556 - accuracy: 0.8231 - val_loss: 0.4204 - val_accuracy: 0.8418\n",
      "Epoch 486/1000\n",
      "225/225 [==============================] - 1s 3ms/step - loss: 0.4572 - accuracy: 0.8218 - val_loss: 0.4237 - val_accuracy: 0.8405\n",
      "Epoch 487/1000\n",
      "225/225 [==============================] - 1s 3ms/step - loss: 0.4582 - accuracy: 0.8210 - val_loss: 0.4216 - val_accuracy: 0.8438\n",
      "Epoch 488/1000\n",
      "225/225 [==============================] - 1s 3ms/step - loss: 0.4583 - accuracy: 0.8219 - val_loss: 0.4218 - val_accuracy: 0.8436\n",
      "Epoch 489/1000\n",
      "225/225 [==============================] - 1s 3ms/step - loss: 0.4568 - accuracy: 0.8215 - val_loss: 0.4219 - val_accuracy: 0.8461\n",
      "Epoch 490/1000\n",
      "225/225 [==============================] - 1s 3ms/step - loss: 0.4560 - accuracy: 0.8228 - val_loss: 0.4232 - val_accuracy: 0.8433\n",
      "Epoch 491/1000\n",
      "225/225 [==============================] - 1s 3ms/step - loss: 0.4595 - accuracy: 0.8214 - val_loss: 0.4201 - val_accuracy: 0.8452\n",
      "Epoch 492/1000\n",
      "225/225 [==============================] - 1s 3ms/step - loss: 0.4577 - accuracy: 0.8210 - val_loss: 0.4227 - val_accuracy: 0.8425\n",
      "Epoch 493/1000\n",
      "225/225 [==============================] - 1s 3ms/step - loss: 0.4570 - accuracy: 0.8218 - val_loss: 0.4198 - val_accuracy: 0.8448\n",
      "Epoch 494/1000\n",
      "225/225 [==============================] - 1s 3ms/step - loss: 0.4565 - accuracy: 0.8223 - val_loss: 0.4212 - val_accuracy: 0.8440\n",
      "Epoch 495/1000\n",
      "225/225 [==============================] - 1s 3ms/step - loss: 0.4551 - accuracy: 0.8232 - val_loss: 0.4217 - val_accuracy: 0.8417\n",
      "Epoch 496/1000\n",
      "225/225 [==============================] - 1s 3ms/step - loss: 0.4561 - accuracy: 0.8219 - val_loss: 0.4215 - val_accuracy: 0.8428\n",
      "Epoch 497/1000\n",
      "225/225 [==============================] - 1s 3ms/step - loss: 0.4550 - accuracy: 0.8234 - val_loss: 0.4201 - val_accuracy: 0.8426\n",
      "Epoch 498/1000\n",
      "225/225 [==============================] - 1s 3ms/step - loss: 0.4552 - accuracy: 0.8221 - val_loss: 0.4242 - val_accuracy: 0.8444\n",
      "Epoch 499/1000\n",
      "225/225 [==============================] - 1s 3ms/step - loss: 0.4553 - accuracy: 0.8232 - val_loss: 0.4227 - val_accuracy: 0.8423\n",
      "Epoch 500/1000\n",
      "225/225 [==============================] - 1s 3ms/step - loss: 0.4573 - accuracy: 0.8224 - val_loss: 0.4226 - val_accuracy: 0.8439\n",
      "Epoch 501/1000\n",
      "225/225 [==============================] - 1s 3ms/step - loss: 0.4581 - accuracy: 0.8214 - val_loss: 0.4209 - val_accuracy: 0.8424\n",
      "Epoch 502/1000\n",
      "225/225 [==============================] - 1s 3ms/step - loss: 0.4557 - accuracy: 0.8228 - val_loss: 0.4203 - val_accuracy: 0.8442\n",
      "Epoch 503/1000\n",
      "225/225 [==============================] - 1s 3ms/step - loss: 0.4575 - accuracy: 0.8224 - val_loss: 0.4229 - val_accuracy: 0.8423\n",
      "Epoch 504/1000\n",
      "225/225 [==============================] - 1s 3ms/step - loss: 0.4544 - accuracy: 0.8231 - val_loss: 0.4201 - val_accuracy: 0.8431\n",
      "Epoch 505/1000\n",
      "225/225 [==============================] - 1s 3ms/step - loss: 0.4571 - accuracy: 0.8223 - val_loss: 0.4230 - val_accuracy: 0.8435\n",
      "Epoch 506/1000\n",
      "225/225 [==============================] - 1s 3ms/step - loss: 0.4566 - accuracy: 0.8218 - val_loss: 0.4182 - val_accuracy: 0.8423\n",
      "Epoch 507/1000\n",
      "225/225 [==============================] - 1s 3ms/step - loss: 0.4544 - accuracy: 0.8238 - val_loss: 0.4195 - val_accuracy: 0.8426\n",
      "Epoch 508/1000\n",
      "225/225 [==============================] - 1s 3ms/step - loss: 0.4565 - accuracy: 0.8222 - val_loss: 0.4215 - val_accuracy: 0.8417\n",
      "Epoch 509/1000\n",
      "225/225 [==============================] - 1s 3ms/step - loss: 0.4563 - accuracy: 0.8228 - val_loss: 0.4207 - val_accuracy: 0.8445\n",
      "Epoch 510/1000\n",
      "225/225 [==============================] - 1s 3ms/step - loss: 0.4545 - accuracy: 0.8230 - val_loss: 0.4191 - val_accuracy: 0.8445\n",
      "Epoch 511/1000\n",
      "225/225 [==============================] - 1s 4ms/step - loss: 0.4559 - accuracy: 0.8232 - val_loss: 0.4195 - val_accuracy: 0.8447\n",
      "Epoch 512/1000\n",
      "225/225 [==============================] - 1s 3ms/step - loss: 0.4555 - accuracy: 0.8225 - val_loss: 0.4209 - val_accuracy: 0.8431\n",
      "Epoch 513/1000\n",
      "225/225 [==============================] - 1s 3ms/step - loss: 0.4549 - accuracy: 0.8234 - val_loss: 0.4188 - val_accuracy: 0.8444\n",
      "Epoch 514/1000\n",
      "225/225 [==============================] - 1s 3ms/step - loss: 0.4550 - accuracy: 0.8240 - val_loss: 0.4184 - val_accuracy: 0.8440\n",
      "Epoch 515/1000\n",
      "225/225 [==============================] - 1s 3ms/step - loss: 0.4541 - accuracy: 0.8240 - val_loss: 0.4179 - val_accuracy: 0.8465\n",
      "Epoch 516/1000\n",
      "225/225 [==============================] - 1s 3ms/step - loss: 0.4545 - accuracy: 0.8224 - val_loss: 0.4175 - val_accuracy: 0.8467\n",
      "Epoch 517/1000\n",
      "225/225 [==============================] - 1s 3ms/step - loss: 0.4556 - accuracy: 0.8241 - val_loss: 0.4201 - val_accuracy: 0.8416\n",
      "Epoch 518/1000\n",
      "225/225 [==============================] - 1s 3ms/step - loss: 0.4556 - accuracy: 0.8227 - val_loss: 0.4196 - val_accuracy: 0.8441\n",
      "Epoch 519/1000\n",
      "225/225 [==============================] - 1s 4ms/step - loss: 0.4568 - accuracy: 0.8211 - val_loss: 0.4239 - val_accuracy: 0.8423\n",
      "Epoch 520/1000\n",
      "225/225 [==============================] - 1s 3ms/step - loss: 0.4562 - accuracy: 0.8223 - val_loss: 0.4226 - val_accuracy: 0.8426\n",
      "Epoch 521/1000\n",
      "225/225 [==============================] - 1s 3ms/step - loss: 0.4543 - accuracy: 0.8237 - val_loss: 0.4223 - val_accuracy: 0.8415\n",
      "Epoch 522/1000\n",
      "225/225 [==============================] - 1s 3ms/step - loss: 0.4541 - accuracy: 0.8226 - val_loss: 0.4214 - val_accuracy: 0.8423\n",
      "Epoch 523/1000\n",
      "225/225 [==============================] - 1s 3ms/step - loss: 0.4542 - accuracy: 0.8234 - val_loss: 0.4209 - val_accuracy: 0.8434\n",
      "Epoch 524/1000\n",
      "225/225 [==============================] - 1s 4ms/step - loss: 0.4550 - accuracy: 0.8227 - val_loss: 0.4206 - val_accuracy: 0.8457\n",
      "Epoch 525/1000\n",
      "225/225 [==============================] - 1s 3ms/step - loss: 0.4543 - accuracy: 0.8237 - val_loss: 0.4211 - val_accuracy: 0.8455\n",
      "Epoch 526/1000\n",
      "225/225 [==============================] - 1s 3ms/step - loss: 0.4557 - accuracy: 0.8221 - val_loss: 0.4189 - val_accuracy: 0.8435\n",
      "Epoch 527/1000\n",
      "225/225 [==============================] - 1s 3ms/step - loss: 0.4549 - accuracy: 0.8235 - val_loss: 0.4198 - val_accuracy: 0.8449\n",
      "Epoch 528/1000\n",
      "225/225 [==============================] - 1s 3ms/step - loss: 0.4572 - accuracy: 0.8226 - val_loss: 0.4182 - val_accuracy: 0.8442\n",
      "Epoch 529/1000\n",
      "225/225 [==============================] - 1s 3ms/step - loss: 0.4547 - accuracy: 0.8232 - val_loss: 0.4172 - val_accuracy: 0.8442\n",
      "Epoch 530/1000\n",
      "225/225 [==============================] - 1s 3ms/step - loss: 0.4545 - accuracy: 0.8219 - val_loss: 0.4186 - val_accuracy: 0.8456\n",
      "Epoch 531/1000\n",
      "225/225 [==============================] - 1s 3ms/step - loss: 0.4530 - accuracy: 0.8241 - val_loss: 0.4226 - val_accuracy: 0.8449\n",
      "Epoch 532/1000\n",
      "225/225 [==============================] - 1s 3ms/step - loss: 0.4548 - accuracy: 0.8236 - val_loss: 0.4175 - val_accuracy: 0.8441\n",
      "Epoch 533/1000\n",
      "225/225 [==============================] - 1s 3ms/step - loss: 0.4557 - accuracy: 0.8220 - val_loss: 0.4188 - val_accuracy: 0.8471\n",
      "Epoch 534/1000\n",
      "225/225 [==============================] - 1s 3ms/step - loss: 0.4561 - accuracy: 0.8225 - val_loss: 0.4186 - val_accuracy: 0.8453\n",
      "Epoch 535/1000\n",
      "225/225 [==============================] - 1s 3ms/step - loss: 0.4569 - accuracy: 0.8221 - val_loss: 0.4206 - val_accuracy: 0.8447\n",
      "Epoch 536/1000\n",
      "225/225 [==============================] - 1s 3ms/step - loss: 0.4551 - accuracy: 0.8235 - val_loss: 0.4218 - val_accuracy: 0.8431\n",
      "Epoch 537/1000\n",
      "225/225 [==============================] - 1s 3ms/step - loss: 0.4544 - accuracy: 0.8235 - val_loss: 0.4203 - val_accuracy: 0.8449\n",
      "Epoch 538/1000\n",
      "225/225 [==============================] - 1s 3ms/step - loss: 0.4552 - accuracy: 0.8226 - val_loss: 0.4207 - val_accuracy: 0.8434\n",
      "Epoch 539/1000\n",
      "225/225 [==============================] - 1s 3ms/step - loss: 0.4527 - accuracy: 0.8243 - val_loss: 0.4181 - val_accuracy: 0.8444\n",
      "Epoch 540/1000\n",
      "225/225 [==============================] - 1s 3ms/step - loss: 0.4560 - accuracy: 0.8226 - val_loss: 0.4210 - val_accuracy: 0.8456\n",
      "Epoch 541/1000\n",
      "225/225 [==============================] - 1s 4ms/step - loss: 0.4566 - accuracy: 0.8226 - val_loss: 0.4179 - val_accuracy: 0.8449\n",
      "Epoch 542/1000\n",
      "225/225 [==============================] - 1s 3ms/step - loss: 0.4525 - accuracy: 0.8240 - val_loss: 0.4206 - val_accuracy: 0.8426\n",
      "Epoch 543/1000\n",
      "225/225 [==============================] - 1s 3ms/step - loss: 0.4552 - accuracy: 0.8224 - val_loss: 0.4166 - val_accuracy: 0.8460\n",
      "Epoch 544/1000\n",
      "225/225 [==============================] - 1s 3ms/step - loss: 0.4535 - accuracy: 0.8235 - val_loss: 0.4183 - val_accuracy: 0.8436\n",
      "Epoch 545/1000\n",
      "225/225 [==============================] - 1s 3ms/step - loss: 0.4557 - accuracy: 0.8221 - val_loss: 0.4223 - val_accuracy: 0.8411\n",
      "Epoch 546/1000\n",
      "225/225 [==============================] - 1s 3ms/step - loss: 0.4555 - accuracy: 0.8239 - val_loss: 0.4202 - val_accuracy: 0.8463\n",
      "Epoch 547/1000\n",
      "225/225 [==============================] - 1s 3ms/step - loss: 0.4538 - accuracy: 0.8231 - val_loss: 0.4172 - val_accuracy: 0.8467\n",
      "Epoch 548/1000\n",
      "225/225 [==============================] - 1s 3ms/step - loss: 0.4562 - accuracy: 0.8224 - val_loss: 0.4217 - val_accuracy: 0.8441\n",
      "Epoch 549/1000\n",
      "225/225 [==============================] - 1s 3ms/step - loss: 0.4535 - accuracy: 0.8229 - val_loss: 0.4159 - val_accuracy: 0.8434\n",
      "Epoch 550/1000\n",
      "225/225 [==============================] - 1s 3ms/step - loss: 0.4536 - accuracy: 0.8218 - val_loss: 0.4184 - val_accuracy: 0.8444\n",
      "Epoch 551/1000\n",
      "225/225 [==============================] - 1s 3ms/step - loss: 0.4557 - accuracy: 0.8229 - val_loss: 0.4200 - val_accuracy: 0.8442\n",
      "Epoch 552/1000\n",
      "225/225 [==============================] - 1s 3ms/step - loss: 0.4548 - accuracy: 0.8233 - val_loss: 0.4185 - val_accuracy: 0.8452\n",
      "Epoch 553/1000\n",
      "225/225 [==============================] - 1s 3ms/step - loss: 0.4540 - accuracy: 0.8232 - val_loss: 0.4180 - val_accuracy: 0.8476\n",
      "Epoch 554/1000\n",
      "225/225 [==============================] - 1s 3ms/step - loss: 0.4545 - accuracy: 0.8229 - val_loss: 0.4168 - val_accuracy: 0.8449\n",
      "Epoch 555/1000\n",
      "225/225 [==============================] - 1s 3ms/step - loss: 0.4530 - accuracy: 0.8246 - val_loss: 0.4178 - val_accuracy: 0.8462\n",
      "Epoch 556/1000\n",
      "225/225 [==============================] - 1s 3ms/step - loss: 0.4534 - accuracy: 0.8240 - val_loss: 0.4193 - val_accuracy: 0.8438\n",
      "Epoch 557/1000\n",
      "225/225 [==============================] - 1s 3ms/step - loss: 0.4525 - accuracy: 0.8246 - val_loss: 0.4158 - val_accuracy: 0.8449\n",
      "Epoch 558/1000\n",
      "225/225 [==============================] - 1s 3ms/step - loss: 0.4543 - accuracy: 0.8243 - val_loss: 0.4188 - val_accuracy: 0.8448\n",
      "Epoch 559/1000\n",
      "225/225 [==============================] - 1s 3ms/step - loss: 0.4531 - accuracy: 0.8231 - val_loss: 0.4178 - val_accuracy: 0.8430\n",
      "Epoch 560/1000\n",
      "225/225 [==============================] - 1s 3ms/step - loss: 0.4525 - accuracy: 0.8250 - val_loss: 0.4176 - val_accuracy: 0.8442\n",
      "Epoch 561/1000\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "225/225 [==============================] - 1s 3ms/step - loss: 0.4514 - accuracy: 0.8250 - val_loss: 0.4187 - val_accuracy: 0.8447\n",
      "Epoch 562/1000\n",
      "225/225 [==============================] - 1s 3ms/step - loss: 0.4544 - accuracy: 0.8225 - val_loss: 0.4183 - val_accuracy: 0.8440\n",
      "Epoch 563/1000\n",
      "225/225 [==============================] - 1s 3ms/step - loss: 0.4526 - accuracy: 0.8237 - val_loss: 0.4164 - val_accuracy: 0.8439\n",
      "Epoch 564/1000\n",
      "225/225 [==============================] - 1s 3ms/step - loss: 0.4542 - accuracy: 0.8227 - val_loss: 0.4185 - val_accuracy: 0.8452\n",
      "Epoch 565/1000\n",
      "225/225 [==============================] - 1s 3ms/step - loss: 0.4506 - accuracy: 0.8248 - val_loss: 0.4202 - val_accuracy: 0.8451\n",
      "Epoch 566/1000\n",
      "225/225 [==============================] - 1s 3ms/step - loss: 0.4529 - accuracy: 0.8240 - val_loss: 0.4207 - val_accuracy: 0.8438\n",
      "Epoch 567/1000\n",
      "225/225 [==============================] - 1s 3ms/step - loss: 0.4534 - accuracy: 0.8233 - val_loss: 0.4185 - val_accuracy: 0.8458\n",
      "Epoch 568/1000\n",
      "225/225 [==============================] - 1s 3ms/step - loss: 0.4539 - accuracy: 0.8236 - val_loss: 0.4178 - val_accuracy: 0.8439\n",
      "Epoch 569/1000\n",
      "225/225 [==============================] - 1s 3ms/step - loss: 0.4528 - accuracy: 0.8240 - val_loss: 0.4175 - val_accuracy: 0.8443\n",
      "Epoch 570/1000\n",
      "225/225 [==============================] - 1s 3ms/step - loss: 0.4501 - accuracy: 0.8248 - val_loss: 0.4148 - val_accuracy: 0.8461\n",
      "Epoch 571/1000\n",
      "225/225 [==============================] - 1s 3ms/step - loss: 0.4524 - accuracy: 0.8249 - val_loss: 0.4136 - val_accuracy: 0.8461\n",
      "Epoch 572/1000\n",
      "225/225 [==============================] - 1s 4ms/step - loss: 0.4557 - accuracy: 0.8225 - val_loss: 0.4169 - val_accuracy: 0.8431\n",
      "Epoch 573/1000\n",
      "225/225 [==============================] - 1s 3ms/step - loss: 0.4516 - accuracy: 0.8238 - val_loss: 0.4196 - val_accuracy: 0.8445\n",
      "Epoch 574/1000\n",
      "225/225 [==============================] - 1s 3ms/step - loss: 0.4532 - accuracy: 0.8221 - val_loss: 0.4180 - val_accuracy: 0.8437\n",
      "Epoch 575/1000\n",
      "225/225 [==============================] - 1s 3ms/step - loss: 0.4524 - accuracy: 0.8232 - val_loss: 0.4152 - val_accuracy: 0.8457\n",
      "Epoch 576/1000\n",
      "225/225 [==============================] - 1s 3ms/step - loss: 0.4544 - accuracy: 0.8230 - val_loss: 0.4149 - val_accuracy: 0.8479\n",
      "Epoch 577/1000\n",
      "225/225 [==============================] - 1s 3ms/step - loss: 0.4532 - accuracy: 0.8237 - val_loss: 0.4157 - val_accuracy: 0.8423\n",
      "Epoch 578/1000\n",
      "225/225 [==============================] - 1s 3ms/step - loss: 0.4564 - accuracy: 0.8230 - val_loss: 0.4161 - val_accuracy: 0.8458\n",
      "Epoch 579/1000\n",
      "225/225 [==============================] - 1s 3ms/step - loss: 0.4542 - accuracy: 0.8233 - val_loss: 0.4137 - val_accuracy: 0.8468\n",
      "Epoch 580/1000\n",
      "225/225 [==============================] - 1s 3ms/step - loss: 0.4539 - accuracy: 0.8233 - val_loss: 0.4157 - val_accuracy: 0.8474\n",
      "Epoch 581/1000\n",
      "225/225 [==============================] - 1s 3ms/step - loss: 0.4531 - accuracy: 0.8240 - val_loss: 0.4156 - val_accuracy: 0.8465\n",
      "Epoch 582/1000\n",
      "225/225 [==============================] - 1s 3ms/step - loss: 0.4529 - accuracy: 0.8244 - val_loss: 0.4191 - val_accuracy: 0.8450\n",
      "Epoch 583/1000\n",
      "225/225 [==============================] - 1s 3ms/step - loss: 0.4530 - accuracy: 0.8237 - val_loss: 0.4190 - val_accuracy: 0.8442\n",
      "Epoch 584/1000\n",
      "225/225 [==============================] - 1s 3ms/step - loss: 0.4533 - accuracy: 0.8236 - val_loss: 0.4168 - val_accuracy: 0.8473\n",
      "Epoch 585/1000\n",
      "225/225 [==============================] - 1s 3ms/step - loss: 0.4527 - accuracy: 0.8235 - val_loss: 0.4200 - val_accuracy: 0.8445\n",
      "Epoch 586/1000\n",
      "225/225 [==============================] - 1s 3ms/step - loss: 0.4562 - accuracy: 0.8222 - val_loss: 0.4164 - val_accuracy: 0.8439\n",
      "Epoch 587/1000\n",
      "225/225 [==============================] - 1s 3ms/step - loss: 0.4512 - accuracy: 0.8246 - val_loss: 0.4190 - val_accuracy: 0.8467\n",
      "Epoch 588/1000\n",
      "225/225 [==============================] - 1s 3ms/step - loss: 0.4513 - accuracy: 0.8229 - val_loss: 0.4164 - val_accuracy: 0.8456\n",
      "Epoch 589/1000\n",
      "225/225 [==============================] - 1s 3ms/step - loss: 0.4501 - accuracy: 0.8253 - val_loss: 0.4167 - val_accuracy: 0.8478\n",
      "Epoch 590/1000\n",
      "225/225 [==============================] - 1s 3ms/step - loss: 0.4511 - accuracy: 0.8239 - val_loss: 0.4160 - val_accuracy: 0.8442\n",
      "Epoch 591/1000\n",
      "225/225 [==============================] - 1s 3ms/step - loss: 0.4528 - accuracy: 0.8235 - val_loss: 0.4200 - val_accuracy: 0.8438\n",
      "Epoch 592/1000\n",
      "225/225 [==============================] - 1s 3ms/step - loss: 0.4534 - accuracy: 0.8232 - val_loss: 0.4158 - val_accuracy: 0.8459\n",
      "Epoch 593/1000\n",
      "225/225 [==============================] - 1s 3ms/step - loss: 0.4522 - accuracy: 0.8240 - val_loss: 0.4187 - val_accuracy: 0.8434\n",
      "Epoch 594/1000\n",
      "225/225 [==============================] - 1s 3ms/step - loss: 0.4499 - accuracy: 0.8252 - val_loss: 0.4135 - val_accuracy: 0.8457\n",
      "Epoch 595/1000\n",
      "225/225 [==============================] - 1s 3ms/step - loss: 0.4529 - accuracy: 0.8239 - val_loss: 0.4155 - val_accuracy: 0.8437\n",
      "Epoch 596/1000\n",
      "225/225 [==============================] - 1s 3ms/step - loss: 0.4518 - accuracy: 0.8250 - val_loss: 0.4138 - val_accuracy: 0.8454\n",
      "Epoch 597/1000\n",
      "225/225 [==============================] - 1s 3ms/step - loss: 0.4540 - accuracy: 0.8224 - val_loss: 0.4167 - val_accuracy: 0.8467\n",
      "Epoch 598/1000\n",
      "225/225 [==============================] - 1s 3ms/step - loss: 0.4529 - accuracy: 0.8241 - val_loss: 0.4169 - val_accuracy: 0.8449\n",
      "Epoch 599/1000\n",
      "225/225 [==============================] - 1s 3ms/step - loss: 0.4539 - accuracy: 0.8244 - val_loss: 0.4138 - val_accuracy: 0.8485\n",
      "Epoch 600/1000\n",
      "225/225 [==============================] - 1s 3ms/step - loss: 0.4499 - accuracy: 0.8254 - val_loss: 0.4136 - val_accuracy: 0.8483\n",
      "Epoch 601/1000\n",
      "225/225 [==============================] - 1s 3ms/step - loss: 0.4526 - accuracy: 0.8240 - val_loss: 0.4165 - val_accuracy: 0.8452\n",
      "Epoch 602/1000\n",
      "225/225 [==============================] - 1s 3ms/step - loss: 0.4535 - accuracy: 0.8241 - val_loss: 0.4187 - val_accuracy: 0.8446\n",
      "Epoch 603/1000\n",
      "225/225 [==============================] - 1s 3ms/step - loss: 0.4513 - accuracy: 0.8248 - val_loss: 0.4133 - val_accuracy: 0.8449\n",
      "Epoch 604/1000\n",
      "225/225 [==============================] - 1s 3ms/step - loss: 0.4527 - accuracy: 0.8239 - val_loss: 0.4215 - val_accuracy: 0.8433\n",
      "Epoch 605/1000\n",
      "225/225 [==============================] - 1s 3ms/step - loss: 0.4537 - accuracy: 0.8233 - val_loss: 0.4180 - val_accuracy: 0.8457\n",
      "Epoch 606/1000\n",
      "225/225 [==============================] - 1s 3ms/step - loss: 0.4520 - accuracy: 0.8240 - val_loss: 0.4165 - val_accuracy: 0.8449\n",
      "Epoch 607/1000\n",
      "225/225 [==============================] - 1s 3ms/step - loss: 0.4512 - accuracy: 0.8251 - val_loss: 0.4139 - val_accuracy: 0.8485\n",
      "Epoch 608/1000\n",
      "225/225 [==============================] - 1s 3ms/step - loss: 0.4532 - accuracy: 0.8231 - val_loss: 0.4191 - val_accuracy: 0.8465\n",
      "Epoch 609/1000\n",
      "225/225 [==============================] - 1s 3ms/step - loss: 0.4523 - accuracy: 0.8239 - val_loss: 0.4160 - val_accuracy: 0.8449\n",
      "Epoch 610/1000\n",
      "225/225 [==============================] - 1s 3ms/step - loss: 0.4513 - accuracy: 0.8248 - val_loss: 0.4162 - val_accuracy: 0.8476\n",
      "Epoch 611/1000\n",
      "225/225 [==============================] - 1s 3ms/step - loss: 0.4519 - accuracy: 0.8243 - val_loss: 0.4150 - val_accuracy: 0.8460\n",
      "Epoch 612/1000\n",
      "225/225 [==============================] - 1s 3ms/step - loss: 0.4493 - accuracy: 0.8260 - val_loss: 0.4175 - val_accuracy: 0.8449\n",
      "Epoch 613/1000\n",
      "225/225 [==============================] - 1s 3ms/step - loss: 0.4504 - accuracy: 0.8247 - val_loss: 0.4155 - val_accuracy: 0.8462\n",
      "Epoch 614/1000\n",
      "225/225 [==============================] - 1s 3ms/step - loss: 0.4503 - accuracy: 0.8253 - val_loss: 0.4142 - val_accuracy: 0.8480\n",
      "Epoch 615/1000\n",
      "225/225 [==============================] - 1s 3ms/step - loss: 0.4523 - accuracy: 0.8240 - val_loss: 0.4202 - val_accuracy: 0.8439\n",
      "Epoch 616/1000\n",
      "225/225 [==============================] - 1s 3ms/step - loss: 0.4506 - accuracy: 0.8246 - val_loss: 0.4164 - val_accuracy: 0.8463\n",
      "Epoch 617/1000\n",
      "225/225 [==============================] - 1s 3ms/step - loss: 0.4523 - accuracy: 0.8246 - val_loss: 0.4161 - val_accuracy: 0.8459\n",
      "Epoch 618/1000\n",
      "225/225 [==============================] - 1s 3ms/step - loss: 0.4526 - accuracy: 0.8236 - val_loss: 0.4170 - val_accuracy: 0.8474\n",
      "Epoch 619/1000\n",
      "225/225 [==============================] - 1s 3ms/step - loss: 0.4516 - accuracy: 0.8246 - val_loss: 0.4131 - val_accuracy: 0.8478\n",
      "Epoch 620/1000\n",
      "225/225 [==============================] - 1s 3ms/step - loss: 0.4508 - accuracy: 0.8248 - val_loss: 0.4148 - val_accuracy: 0.8472\n",
      "Epoch 621/1000\n",
      "225/225 [==============================] - 1s 3ms/step - loss: 0.4502 - accuracy: 0.8247 - val_loss: 0.4145 - val_accuracy: 0.8478\n",
      "Epoch 622/1000\n",
      "225/225 [==============================] - 1s 3ms/step - loss: 0.4529 - accuracy: 0.8237 - val_loss: 0.4160 - val_accuracy: 0.8481\n",
      "Epoch 623/1000\n",
      "225/225 [==============================] - 1s 3ms/step - loss: 0.4522 - accuracy: 0.8238 - val_loss: 0.4158 - val_accuracy: 0.8453\n",
      "Epoch 624/1000\n",
      "225/225 [==============================] - 1s 3ms/step - loss: 0.4524 - accuracy: 0.8237 - val_loss: 0.4167 - val_accuracy: 0.8467\n",
      "Epoch 625/1000\n",
      "225/225 [==============================] - 1s 3ms/step - loss: 0.4489 - accuracy: 0.8261 - val_loss: 0.4144 - val_accuracy: 0.8462\n",
      "Epoch 626/1000\n",
      "225/225 [==============================] - 1s 3ms/step - loss: 0.4500 - accuracy: 0.8254 - val_loss: 0.4215 - val_accuracy: 0.8411\n",
      "Epoch 627/1000\n",
      "225/225 [==============================] - 1s 3ms/step - loss: 0.4491 - accuracy: 0.8258 - val_loss: 0.4151 - val_accuracy: 0.8452\n",
      "Epoch 628/1000\n",
      "225/225 [==============================] - 1s 3ms/step - loss: 0.4525 - accuracy: 0.8244 - val_loss: 0.4172 - val_accuracy: 0.8451\n",
      "Epoch 629/1000\n",
      "225/225 [==============================] - 1s 3ms/step - loss: 0.4501 - accuracy: 0.8248 - val_loss: 0.4180 - val_accuracy: 0.8426\n",
      "Epoch 630/1000\n",
      "225/225 [==============================] - 1s 3ms/step - loss: 0.4518 - accuracy: 0.8236 - val_loss: 0.4175 - val_accuracy: 0.8451\n",
      "Epoch 631/1000\n",
      "225/225 [==============================] - 1s 3ms/step - loss: 0.4517 - accuracy: 0.8243 - val_loss: 0.4177 - val_accuracy: 0.8431\n",
      "Epoch 632/1000\n",
      "225/225 [==============================] - 1s 3ms/step - loss: 0.4497 - accuracy: 0.8253 - val_loss: 0.4148 - val_accuracy: 0.8454\n",
      "Epoch 633/1000\n",
      "225/225 [==============================] - 1s 3ms/step - loss: 0.4509 - accuracy: 0.8247 - val_loss: 0.4170 - val_accuracy: 0.8456\n",
      "Epoch 634/1000\n",
      "225/225 [==============================] - 1s 3ms/step - loss: 0.4524 - accuracy: 0.8232 - val_loss: 0.4176 - val_accuracy: 0.8450\n",
      "Epoch 635/1000\n",
      "225/225 [==============================] - 1s 3ms/step - loss: 0.4513 - accuracy: 0.8243 - val_loss: 0.4147 - val_accuracy: 0.8459\n",
      "Epoch 636/1000\n",
      "225/225 [==============================] - 1s 3ms/step - loss: 0.4528 - accuracy: 0.8245 - val_loss: 0.4164 - val_accuracy: 0.8445\n",
      "Epoch 637/1000\n",
      "225/225 [==============================] - 1s 3ms/step - loss: 0.4500 - accuracy: 0.8255 - val_loss: 0.4167 - val_accuracy: 0.8430\n",
      "Epoch 638/1000\n",
      "225/225 [==============================] - 1s 3ms/step - loss: 0.4535 - accuracy: 0.8239 - val_loss: 0.4164 - val_accuracy: 0.8446\n",
      "Epoch 639/1000\n",
      "225/225 [==============================] - 1s 3ms/step - loss: 0.4498 - accuracy: 0.8258 - val_loss: 0.4150 - val_accuracy: 0.8449\n",
      "Epoch 640/1000\n",
      "225/225 [==============================] - 1s 3ms/step - loss: 0.4509 - accuracy: 0.8253 - val_loss: 0.4151 - val_accuracy: 0.8449\n",
      "Epoch 641/1000\n",
      "225/225 [==============================] - 1s 3ms/step - loss: 0.4524 - accuracy: 0.8237 - val_loss: 0.4178 - val_accuracy: 0.8454\n",
      "Epoch 642/1000\n",
      "225/225 [==============================] - 1s 3ms/step - loss: 0.4515 - accuracy: 0.8255 - val_loss: 0.4156 - val_accuracy: 0.8453\n",
      "Epoch 643/1000\n",
      "225/225 [==============================] - 1s 3ms/step - loss: 0.4521 - accuracy: 0.8247 - val_loss: 0.4181 - val_accuracy: 0.8456\n",
      "Epoch 644/1000\n",
      "225/225 [==============================] - 1s 3ms/step - loss: 0.4510 - accuracy: 0.8245 - val_loss: 0.4187 - val_accuracy: 0.8453\n",
      "Epoch 645/1000\n",
      "225/225 [==============================] - 1s 3ms/step - loss: 0.4503 - accuracy: 0.8246 - val_loss: 0.4136 - val_accuracy: 0.8505\n",
      "Epoch 646/1000\n",
      "225/225 [==============================] - 1s 3ms/step - loss: 0.4503 - accuracy: 0.8245 - val_loss: 0.4175 - val_accuracy: 0.8446\n",
      "Epoch 647/1000\n",
      "225/225 [==============================] - 1s 3ms/step - loss: 0.4507 - accuracy: 0.8249 - val_loss: 0.4148 - val_accuracy: 0.8474\n",
      "Epoch 648/1000\n",
      "225/225 [==============================] - 1s 3ms/step - loss: 0.4496 - accuracy: 0.8260 - val_loss: 0.4132 - val_accuracy: 0.8464\n",
      "Epoch 649/1000\n",
      "225/225 [==============================] - 1s 3ms/step - loss: 0.4499 - accuracy: 0.8258 - val_loss: 0.4150 - val_accuracy: 0.8477\n",
      "Epoch 650/1000\n",
      "225/225 [==============================] - 1s 3ms/step - loss: 0.4501 - accuracy: 0.8252 - val_loss: 0.4146 - val_accuracy: 0.8460\n",
      "Epoch 651/1000\n",
      "225/225 [==============================] - 1s 3ms/step - loss: 0.4480 - accuracy: 0.8256 - val_loss: 0.4157 - val_accuracy: 0.8445\n",
      "Epoch 652/1000\n",
      "225/225 [==============================] - 1s 3ms/step - loss: 0.4515 - accuracy: 0.8237 - val_loss: 0.4171 - val_accuracy: 0.8460\n",
      "Epoch 653/1000\n",
      "225/225 [==============================] - 1s 3ms/step - loss: 0.4526 - accuracy: 0.8239 - val_loss: 0.4136 - val_accuracy: 0.8478\n",
      "Epoch 654/1000\n",
      "225/225 [==============================] - 1s 3ms/step - loss: 0.4504 - accuracy: 0.8241 - val_loss: 0.4140 - val_accuracy: 0.8451\n",
      "Epoch 655/1000\n",
      "225/225 [==============================] - 1s 3ms/step - loss: 0.4505 - accuracy: 0.8246 - val_loss: 0.4161 - val_accuracy: 0.8464\n",
      "Epoch 656/1000\n",
      "225/225 [==============================] - 1s 3ms/step - loss: 0.4513 - accuracy: 0.8249 - val_loss: 0.4169 - val_accuracy: 0.8472\n",
      "Epoch 657/1000\n",
      "225/225 [==============================] - 1s 3ms/step - loss: 0.4512 - accuracy: 0.8250 - val_loss: 0.4148 - val_accuracy: 0.8452\n",
      "Epoch 658/1000\n",
      "225/225 [==============================] - 1s 3ms/step - loss: 0.4519 - accuracy: 0.8243 - val_loss: 0.4167 - val_accuracy: 0.8434\n",
      "Epoch 659/1000\n",
      "225/225 [==============================] - 1s 3ms/step - loss: 0.4514 - accuracy: 0.8249 - val_loss: 0.4181 - val_accuracy: 0.8463\n",
      "Epoch 660/1000\n",
      "225/225 [==============================] - 1s 3ms/step - loss: 0.4483 - accuracy: 0.8257 - val_loss: 0.4147 - val_accuracy: 0.8450\n",
      "Epoch 661/1000\n",
      "225/225 [==============================] - 1s 3ms/step - loss: 0.4502 - accuracy: 0.8252 - val_loss: 0.4170 - val_accuracy: 0.8475\n",
      "Epoch 662/1000\n",
      "225/225 [==============================] - 1s 3ms/step - loss: 0.4522 - accuracy: 0.8242 - val_loss: 0.4147 - val_accuracy: 0.8469\n",
      "Epoch 663/1000\n",
      "225/225 [==============================] - 1s 3ms/step - loss: 0.4498 - accuracy: 0.8250 - val_loss: 0.4143 - val_accuracy: 0.8458\n",
      "Epoch 664/1000\n",
      "225/225 [==============================] - 1s 3ms/step - loss: 0.4499 - accuracy: 0.8258 - val_loss: 0.4142 - val_accuracy: 0.8476\n",
      "Epoch 665/1000\n",
      "225/225 [==============================] - 1s 3ms/step - loss: 0.4503 - accuracy: 0.8252 - val_loss: 0.4172 - val_accuracy: 0.8453\n",
      "Epoch 666/1000\n",
      "225/225 [==============================] - 1s 3ms/step - loss: 0.4500 - accuracy: 0.8248 - val_loss: 0.4141 - val_accuracy: 0.8468\n",
      "Epoch 667/1000\n",
      "225/225 [==============================] - 1s 3ms/step - loss: 0.4500 - accuracy: 0.8248 - val_loss: 0.4157 - val_accuracy: 0.8450\n",
      "Epoch 668/1000\n",
      "225/225 [==============================] - 1s 3ms/step - loss: 0.4482 - accuracy: 0.8261 - val_loss: 0.4173 - val_accuracy: 0.8449\n",
      "Epoch 669/1000\n",
      "225/225 [==============================] - 1s 3ms/step - loss: 0.4503 - accuracy: 0.8250 - val_loss: 0.4153 - val_accuracy: 0.8455\n",
      "Epoch 670/1000\n",
      "225/225 [==============================] - 1s 3ms/step - loss: 0.4524 - accuracy: 0.8242 - val_loss: 0.4161 - val_accuracy: 0.8463\n",
      "Epoch 671/1000\n",
      "225/225 [==============================] - 1s 3ms/step - loss: 0.4494 - accuracy: 0.8251 - val_loss: 0.4162 - val_accuracy: 0.8456\n",
      "Epoch 672/1000\n",
      "225/225 [==============================] - 1s 3ms/step - loss: 0.4508 - accuracy: 0.8246 - val_loss: 0.4157 - val_accuracy: 0.8470\n",
      "Epoch 673/1000\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "225/225 [==============================] - 1s 3ms/step - loss: 0.4483 - accuracy: 0.8257 - val_loss: 0.4156 - val_accuracy: 0.8482\n",
      "Epoch 674/1000\n",
      "225/225 [==============================] - 1s 3ms/step - loss: 0.4516 - accuracy: 0.8243 - val_loss: 0.4175 - val_accuracy: 0.8461\n",
      "Epoch 675/1000\n",
      "225/225 [==============================] - 1s 3ms/step - loss: 0.4492 - accuracy: 0.8247 - val_loss: 0.4139 - val_accuracy: 0.8481\n",
      "Epoch 676/1000\n",
      "225/225 [==============================] - 1s 3ms/step - loss: 0.4504 - accuracy: 0.8255 - val_loss: 0.4161 - val_accuracy: 0.8433\n",
      "Epoch 677/1000\n",
      "225/225 [==============================] - 1s 3ms/step - loss: 0.4490 - accuracy: 0.8247 - val_loss: 0.4126 - val_accuracy: 0.8460\n",
      "Epoch 678/1000\n",
      "225/225 [==============================] - 1s 3ms/step - loss: 0.4485 - accuracy: 0.8263 - val_loss: 0.4161 - val_accuracy: 0.8471\n",
      "Epoch 679/1000\n",
      "225/225 [==============================] - 1s 3ms/step - loss: 0.4488 - accuracy: 0.8248 - val_loss: 0.4150 - val_accuracy: 0.8485\n",
      "Epoch 680/1000\n",
      "225/225 [==============================] - 1s 3ms/step - loss: 0.4497 - accuracy: 0.8253 - val_loss: 0.4171 - val_accuracy: 0.8487\n",
      "Epoch 681/1000\n",
      "225/225 [==============================] - 1s 3ms/step - loss: 0.4504 - accuracy: 0.8251 - val_loss: 0.4164 - val_accuracy: 0.8435\n",
      "Epoch 682/1000\n",
      "225/225 [==============================] - 1s 3ms/step - loss: 0.4495 - accuracy: 0.8257 - val_loss: 0.4135 - val_accuracy: 0.8471\n",
      "Epoch 683/1000\n",
      "225/225 [==============================] - 1s 3ms/step - loss: 0.4514 - accuracy: 0.8245 - val_loss: 0.4157 - val_accuracy: 0.8460\n",
      "Epoch 684/1000\n",
      "225/225 [==============================] - 1s 3ms/step - loss: 0.4511 - accuracy: 0.8250 - val_loss: 0.4126 - val_accuracy: 0.8482\n",
      "Epoch 685/1000\n",
      "225/225 [==============================] - 1s 3ms/step - loss: 0.4495 - accuracy: 0.8257 - val_loss: 0.4141 - val_accuracy: 0.8459\n",
      "Epoch 686/1000\n",
      "225/225 [==============================] - 1s 3ms/step - loss: 0.4503 - accuracy: 0.8250 - val_loss: 0.4134 - val_accuracy: 0.8471\n",
      "Epoch 687/1000\n",
      "225/225 [==============================] - 1s 3ms/step - loss: 0.4480 - accuracy: 0.8261 - val_loss: 0.4141 - val_accuracy: 0.8443\n",
      "Epoch 688/1000\n",
      "225/225 [==============================] - 1s 3ms/step - loss: 0.4493 - accuracy: 0.8252 - val_loss: 0.4156 - val_accuracy: 0.8466\n",
      "Epoch 689/1000\n",
      "225/225 [==============================] - 1s 3ms/step - loss: 0.4487 - accuracy: 0.8249 - val_loss: 0.4162 - val_accuracy: 0.8463\n",
      "Epoch 690/1000\n",
      "225/225 [==============================] - 1s 3ms/step - loss: 0.4501 - accuracy: 0.8251 - val_loss: 0.4166 - val_accuracy: 0.8467\n",
      "Epoch 691/1000\n",
      "225/225 [==============================] - 1s 3ms/step - loss: 0.4499 - accuracy: 0.8251 - val_loss: 0.4149 - val_accuracy: 0.8478\n",
      "Epoch 692/1000\n",
      "225/225 [==============================] - 1s 3ms/step - loss: 0.4482 - accuracy: 0.8256 - val_loss: 0.4146 - val_accuracy: 0.8459\n",
      "Epoch 693/1000\n",
      "225/225 [==============================] - 1s 3ms/step - loss: 0.4486 - accuracy: 0.8250 - val_loss: 0.4171 - val_accuracy: 0.8485\n",
      "Epoch 694/1000\n",
      "225/225 [==============================] - 1s 3ms/step - loss: 0.4489 - accuracy: 0.8261 - val_loss: 0.4120 - val_accuracy: 0.8481\n",
      "Epoch 695/1000\n",
      "225/225 [==============================] - 1s 3ms/step - loss: 0.4503 - accuracy: 0.8242 - val_loss: 0.4172 - val_accuracy: 0.8462\n",
      "Epoch 696/1000\n",
      "225/225 [==============================] - 1s 3ms/step - loss: 0.4480 - accuracy: 0.8261 - val_loss: 0.4144 - val_accuracy: 0.8461\n",
      "Epoch 697/1000\n",
      "225/225 [==============================] - 1s 3ms/step - loss: 0.4476 - accuracy: 0.8264 - val_loss: 0.4117 - val_accuracy: 0.8491\n",
      "Epoch 698/1000\n",
      "225/225 [==============================] - 1s 3ms/step - loss: 0.4494 - accuracy: 0.8244 - val_loss: 0.4115 - val_accuracy: 0.8478\n",
      "Epoch 699/1000\n",
      "225/225 [==============================] - 1s 3ms/step - loss: 0.4463 - accuracy: 0.8262 - val_loss: 0.4154 - val_accuracy: 0.8448\n",
      "Epoch 700/1000\n",
      "225/225 [==============================] - 1s 3ms/step - loss: 0.4476 - accuracy: 0.8253 - val_loss: 0.4178 - val_accuracy: 0.8440\n",
      "Epoch 701/1000\n",
      "225/225 [==============================] - 1s 3ms/step - loss: 0.4495 - accuracy: 0.8267 - val_loss: 0.4167 - val_accuracy: 0.8465\n",
      "Epoch 702/1000\n",
      "225/225 [==============================] - 1s 3ms/step - loss: 0.4479 - accuracy: 0.8257 - val_loss: 0.4165 - val_accuracy: 0.8463\n",
      "Epoch 703/1000\n",
      "225/225 [==============================] - 1s 3ms/step - loss: 0.4517 - accuracy: 0.8241 - val_loss: 0.4185 - val_accuracy: 0.8475\n",
      "Epoch 704/1000\n",
      "225/225 [==============================] - 1s 3ms/step - loss: 0.4488 - accuracy: 0.8256 - val_loss: 0.4185 - val_accuracy: 0.8450\n",
      "Epoch 705/1000\n",
      "225/225 [==============================] - 1s 3ms/step - loss: 0.4482 - accuracy: 0.8251 - val_loss: 0.4154 - val_accuracy: 0.8442\n",
      "Epoch 706/1000\n",
      "225/225 [==============================] - 1s 3ms/step - loss: 0.4468 - accuracy: 0.8271 - val_loss: 0.4144 - val_accuracy: 0.8498\n",
      "Epoch 707/1000\n",
      "225/225 [==============================] - 1s 3ms/step - loss: 0.4502 - accuracy: 0.8257 - val_loss: 0.4159 - val_accuracy: 0.8474\n",
      "Epoch 708/1000\n",
      "225/225 [==============================] - 1s 3ms/step - loss: 0.4465 - accuracy: 0.8257 - val_loss: 0.4142 - val_accuracy: 0.8480\n",
      "Epoch 709/1000\n",
      "225/225 [==============================] - 1s 3ms/step - loss: 0.4487 - accuracy: 0.8265 - val_loss: 0.4129 - val_accuracy: 0.8468\n",
      "Epoch 710/1000\n",
      "225/225 [==============================] - 1s 3ms/step - loss: 0.4505 - accuracy: 0.8245 - val_loss: 0.4162 - val_accuracy: 0.8460\n",
      "Epoch 711/1000\n",
      "225/225 [==============================] - 1s 3ms/step - loss: 0.4480 - accuracy: 0.8258 - val_loss: 0.4150 - val_accuracy: 0.8462\n",
      "Epoch 712/1000\n",
      "225/225 [==============================] - 1s 3ms/step - loss: 0.4495 - accuracy: 0.8251 - val_loss: 0.4139 - val_accuracy: 0.8463\n",
      "Epoch 713/1000\n",
      "225/225 [==============================] - 1s 3ms/step - loss: 0.4479 - accuracy: 0.8269 - val_loss: 0.4143 - val_accuracy: 0.8467\n",
      "Epoch 714/1000\n",
      "225/225 [==============================] - 1s 3ms/step - loss: 0.4479 - accuracy: 0.8270 - val_loss: 0.4178 - val_accuracy: 0.8436\n",
      "Epoch 715/1000\n",
      "225/225 [==============================] - 1s 3ms/step - loss: 0.4487 - accuracy: 0.8254 - val_loss: 0.4144 - val_accuracy: 0.8460\n",
      "Epoch 716/1000\n",
      "225/225 [==============================] - 1s 3ms/step - loss: 0.4476 - accuracy: 0.8262 - val_loss: 0.4156 - val_accuracy: 0.8478\n",
      "Epoch 717/1000\n",
      "225/225 [==============================] - 1s 3ms/step - loss: 0.4485 - accuracy: 0.8253 - val_loss: 0.4189 - val_accuracy: 0.8447\n",
      "Epoch 718/1000\n",
      "225/225 [==============================] - 1s 3ms/step - loss: 0.4477 - accuracy: 0.8258 - val_loss: 0.4170 - val_accuracy: 0.8463\n",
      "Epoch 719/1000\n",
      "225/225 [==============================] - 1s 3ms/step - loss: 0.4487 - accuracy: 0.8246 - val_loss: 0.4158 - val_accuracy: 0.8453\n",
      "Epoch 720/1000\n",
      "225/225 [==============================] - 1s 3ms/step - loss: 0.4483 - accuracy: 0.8256 - val_loss: 0.4127 - val_accuracy: 0.8474\n",
      "Epoch 721/1000\n",
      "225/225 [==============================] - 1s 3ms/step - loss: 0.4477 - accuracy: 0.8259 - val_loss: 0.4146 - val_accuracy: 0.8475\n",
      "Epoch 722/1000\n",
      "225/225 [==============================] - 1s 3ms/step - loss: 0.4493 - accuracy: 0.8242 - val_loss: 0.4144 - val_accuracy: 0.8488\n",
      "Epoch 723/1000\n",
      "225/225 [==============================] - 1s 3ms/step - loss: 0.4477 - accuracy: 0.8271 - val_loss: 0.4166 - val_accuracy: 0.8479\n",
      "Epoch 724/1000\n",
      "225/225 [==============================] - 1s 3ms/step - loss: 0.4500 - accuracy: 0.8248 - val_loss: 0.4155 - val_accuracy: 0.8458\n",
      "Epoch 725/1000\n",
      "225/225 [==============================] - 1s 3ms/step - loss: 0.4491 - accuracy: 0.8245 - val_loss: 0.4122 - val_accuracy: 0.8474\n",
      "Epoch 726/1000\n",
      "225/225 [==============================] - 1s 3ms/step - loss: 0.4478 - accuracy: 0.8258 - val_loss: 0.4121 - val_accuracy: 0.8477\n",
      "Epoch 727/1000\n",
      "225/225 [==============================] - 1s 3ms/step - loss: 0.4485 - accuracy: 0.8267 - val_loss: 0.4148 - val_accuracy: 0.8481\n",
      "Epoch 728/1000\n",
      "225/225 [==============================] - 1s 3ms/step - loss: 0.4452 - accuracy: 0.8271 - val_loss: 0.4146 - val_accuracy: 0.8446\n",
      "Epoch 729/1000\n",
      "225/225 [==============================] - 1s 3ms/step - loss: 0.4487 - accuracy: 0.8259 - val_loss: 0.4135 - val_accuracy: 0.8452\n",
      "Epoch 730/1000\n",
      "225/225 [==============================] - 1s 3ms/step - loss: 0.4476 - accuracy: 0.8253 - val_loss: 0.4120 - val_accuracy: 0.8486\n",
      "Epoch 731/1000\n",
      "225/225 [==============================] - 1s 3ms/step - loss: 0.4478 - accuracy: 0.8267 - val_loss: 0.4171 - val_accuracy: 0.8450\n",
      "Epoch 732/1000\n",
      "225/225 [==============================] - 1s 4ms/step - loss: 0.4474 - accuracy: 0.8259 - val_loss: 0.4146 - val_accuracy: 0.8442\n",
      "Epoch 733/1000\n",
      "225/225 [==============================] - 1s 3ms/step - loss: 0.4485 - accuracy: 0.8255 - val_loss: 0.4119 - val_accuracy: 0.8482\n",
      "Epoch 734/1000\n",
      "225/225 [==============================] - 1s 3ms/step - loss: 0.4475 - accuracy: 0.8266 - val_loss: 0.4190 - val_accuracy: 0.8412\n",
      "Epoch 735/1000\n",
      "225/225 [==============================] - 1s 3ms/step - loss: 0.4482 - accuracy: 0.8254 - val_loss: 0.4155 - val_accuracy: 0.8456\n",
      "Epoch 736/1000\n",
      "225/225 [==============================] - 1s 3ms/step - loss: 0.4446 - accuracy: 0.8271 - val_loss: 0.4162 - val_accuracy: 0.8463\n",
      "Epoch 737/1000\n",
      "225/225 [==============================] - 1s 3ms/step - loss: 0.4477 - accuracy: 0.8260 - val_loss: 0.4122 - val_accuracy: 0.8489\n",
      "Epoch 738/1000\n",
      "225/225 [==============================] - 1s 3ms/step - loss: 0.4488 - accuracy: 0.8257 - val_loss: 0.4124 - val_accuracy: 0.8499\n",
      "Epoch 739/1000\n",
      "225/225 [==============================] - 1s 3ms/step - loss: 0.4461 - accuracy: 0.8266 - val_loss: 0.4157 - val_accuracy: 0.8464\n",
      "Epoch 740/1000\n",
      "225/225 [==============================] - 1s 3ms/step - loss: 0.4480 - accuracy: 0.8258 - val_loss: 0.4143 - val_accuracy: 0.8460\n",
      "Epoch 741/1000\n",
      "225/225 [==============================] - 1s 3ms/step - loss: 0.4486 - accuracy: 0.8259 - val_loss: 0.4156 - val_accuracy: 0.8442\n",
      "Epoch 742/1000\n",
      "225/225 [==============================] - 1s 3ms/step - loss: 0.4467 - accuracy: 0.8272 - val_loss: 0.4151 - val_accuracy: 0.8485\n",
      "Epoch 743/1000\n",
      "225/225 [==============================] - 1s 3ms/step - loss: 0.4475 - accuracy: 0.8265 - val_loss: 0.4158 - val_accuracy: 0.8438\n",
      "Epoch 744/1000\n",
      "225/225 [==============================] - 1s 3ms/step - loss: 0.4469 - accuracy: 0.8261 - val_loss: 0.4141 - val_accuracy: 0.8470\n",
      "Epoch 745/1000\n",
      "225/225 [==============================] - 1s 3ms/step - loss: 0.4477 - accuracy: 0.8269 - val_loss: 0.4147 - val_accuracy: 0.8463\n",
      "Epoch 746/1000\n",
      "225/225 [==============================] - 1s 5ms/step - loss: 0.4472 - accuracy: 0.8255 - val_loss: 0.4142 - val_accuracy: 0.8472\n",
      "Epoch 747/1000\n",
      "225/225 [==============================] - 1s 3ms/step - loss: 0.4477 - accuracy: 0.8261 - val_loss: 0.4148 - val_accuracy: 0.8443\n",
      "Epoch 748/1000\n",
      "225/225 [==============================] - 1s 3ms/step - loss: 0.4486 - accuracy: 0.8261 - val_loss: 0.4144 - val_accuracy: 0.8462\n",
      "Epoch 749/1000\n",
      "225/225 [==============================] - 1s 3ms/step - loss: 0.4497 - accuracy: 0.8249 - val_loss: 0.4152 - val_accuracy: 0.8481\n",
      "Epoch 750/1000\n",
      "225/225 [==============================] - 1s 3ms/step - loss: 0.4459 - accuracy: 0.8267 - val_loss: 0.4122 - val_accuracy: 0.8481\n",
      "Epoch 751/1000\n",
      "225/225 [==============================] - 1s 3ms/step - loss: 0.4497 - accuracy: 0.8244 - val_loss: 0.4154 - val_accuracy: 0.8470\n",
      "Epoch 752/1000\n",
      "225/225 [==============================] - 1s 3ms/step - loss: 0.4474 - accuracy: 0.8263 - val_loss: 0.4167 - val_accuracy: 0.8487\n",
      "Epoch 753/1000\n",
      "225/225 [==============================] - 1s 3ms/step - loss: 0.4444 - accuracy: 0.8280 - val_loss: 0.4128 - val_accuracy: 0.8461\n",
      "Epoch 754/1000\n",
      "225/225 [==============================] - 1s 3ms/step - loss: 0.4455 - accuracy: 0.8276 - val_loss: 0.4165 - val_accuracy: 0.8467\n",
      "Epoch 755/1000\n",
      "225/225 [==============================] - 1s 3ms/step - loss: 0.4430 - accuracy: 0.8286 - val_loss: 0.4130 - val_accuracy: 0.8471\n",
      "Epoch 756/1000\n",
      "225/225 [==============================] - 1s 3ms/step - loss: 0.4483 - accuracy: 0.8259 - val_loss: 0.4182 - val_accuracy: 0.8452\n",
      "Epoch 757/1000\n",
      "225/225 [==============================] - 1s 3ms/step - loss: 0.4477 - accuracy: 0.8269 - val_loss: 0.4145 - val_accuracy: 0.8481\n",
      "Epoch 758/1000\n",
      "225/225 [==============================] - 1s 3ms/step - loss: 0.4463 - accuracy: 0.8275 - val_loss: 0.4153 - val_accuracy: 0.8489\n",
      "Epoch 759/1000\n",
      "225/225 [==============================] - 1s 3ms/step - loss: 0.4468 - accuracy: 0.8262 - val_loss: 0.4130 - val_accuracy: 0.8469\n",
      "Epoch 760/1000\n",
      "225/225 [==============================] - 1s 3ms/step - loss: 0.4491 - accuracy: 0.8253 - val_loss: 0.4130 - val_accuracy: 0.8480\n",
      "Epoch 761/1000\n",
      "225/225 [==============================] - 1s 3ms/step - loss: 0.4466 - accuracy: 0.8281 - val_loss: 0.4140 - val_accuracy: 0.8489\n",
      "Epoch 762/1000\n",
      "225/225 [==============================] - 1s 3ms/step - loss: 0.4490 - accuracy: 0.8256 - val_loss: 0.4138 - val_accuracy: 0.8450\n",
      "Epoch 763/1000\n",
      "225/225 [==============================] - 1s 3ms/step - loss: 0.4480 - accuracy: 0.8263 - val_loss: 0.4152 - val_accuracy: 0.8474\n",
      "Epoch 764/1000\n",
      "225/225 [==============================] - 1s 3ms/step - loss: 0.4466 - accuracy: 0.8268 - val_loss: 0.4152 - val_accuracy: 0.8481\n",
      "Epoch 765/1000\n",
      "225/225 [==============================] - 1s 3ms/step - loss: 0.4476 - accuracy: 0.8267 - val_loss: 0.4154 - val_accuracy: 0.8474\n",
      "Epoch 766/1000\n",
      "225/225 [==============================] - 1s 3ms/step - loss: 0.4503 - accuracy: 0.8246 - val_loss: 0.4162 - val_accuracy: 0.8461\n",
      "Epoch 767/1000\n",
      "225/225 [==============================] - 1s 3ms/step - loss: 0.4463 - accuracy: 0.8264 - val_loss: 0.4109 - val_accuracy: 0.8504\n",
      "Epoch 768/1000\n",
      "225/225 [==============================] - 1s 3ms/step - loss: 0.4481 - accuracy: 0.8252 - val_loss: 0.4125 - val_accuracy: 0.8479\n",
      "Epoch 769/1000\n",
      "225/225 [==============================] - 1s 3ms/step - loss: 0.4450 - accuracy: 0.8278 - val_loss: 0.4126 - val_accuracy: 0.8471\n",
      "Epoch 770/1000\n",
      "225/225 [==============================] - 1s 3ms/step - loss: 0.4456 - accuracy: 0.8283 - val_loss: 0.4156 - val_accuracy: 0.8462\n",
      "Epoch 771/1000\n",
      "225/225 [==============================] - 1s 3ms/step - loss: 0.4466 - accuracy: 0.8257 - val_loss: 0.4141 - val_accuracy: 0.8474\n",
      "Epoch 772/1000\n",
      "225/225 [==============================] - 1s 3ms/step - loss: 0.4451 - accuracy: 0.8265 - val_loss: 0.4116 - val_accuracy: 0.8467\n",
      "Epoch 773/1000\n",
      "225/225 [==============================] - 1s 3ms/step - loss: 0.4459 - accuracy: 0.8272 - val_loss: 0.4141 - val_accuracy: 0.8483\n",
      "Epoch 774/1000\n",
      "225/225 [==============================] - 1s 3ms/step - loss: 0.4498 - accuracy: 0.8246 - val_loss: 0.4144 - val_accuracy: 0.8489\n",
      "Epoch 775/1000\n",
      "225/225 [==============================] - 1s 3ms/step - loss: 0.4468 - accuracy: 0.8279 - val_loss: 0.4140 - val_accuracy: 0.8471\n",
      "Epoch 776/1000\n",
      "225/225 [==============================] - 1s 3ms/step - loss: 0.4464 - accuracy: 0.8267 - val_loss: 0.4124 - val_accuracy: 0.8487\n",
      "Epoch 777/1000\n",
      "225/225 [==============================] - 1s 3ms/step - loss: 0.4461 - accuracy: 0.8269 - val_loss: 0.4143 - val_accuracy: 0.8477\n",
      "Epoch 778/1000\n",
      "225/225 [==============================] - 1s 3ms/step - loss: 0.4478 - accuracy: 0.8261 - val_loss: 0.4144 - val_accuracy: 0.8474\n",
      "Epoch 779/1000\n",
      "225/225 [==============================] - 1s 3ms/step - loss: 0.4467 - accuracy: 0.8261 - val_loss: 0.4117 - val_accuracy: 0.8474\n",
      "Epoch 780/1000\n",
      "225/225 [==============================] - 1s 3ms/step - loss: 0.4463 - accuracy: 0.8267 - val_loss: 0.4113 - val_accuracy: 0.8485\n",
      "Epoch 781/1000\n",
      "225/225 [==============================] - 1s 3ms/step - loss: 0.4449 - accuracy: 0.8277 - val_loss: 0.4140 - val_accuracy: 0.8468\n",
      "Epoch 782/1000\n",
      "225/225 [==============================] - 1s 4ms/step - loss: 0.4471 - accuracy: 0.8260 - val_loss: 0.4138 - val_accuracy: 0.8498\n",
      "Epoch 783/1000\n",
      "225/225 [==============================] - 1s 3ms/step - loss: 0.4481 - accuracy: 0.8254 - val_loss: 0.4140 - val_accuracy: 0.8471\n",
      "Epoch 784/1000\n",
      "225/225 [==============================] - 1s 3ms/step - loss: 0.4473 - accuracy: 0.8270 - val_loss: 0.4133 - val_accuracy: 0.8490\n",
      "Epoch 785/1000\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "225/225 [==============================] - 1s 3ms/step - loss: 0.4459 - accuracy: 0.8267 - val_loss: 0.4151 - val_accuracy: 0.8474\n",
      "Epoch 786/1000\n",
      "225/225 [==============================] - 1s 3ms/step - loss: 0.4467 - accuracy: 0.8265 - val_loss: 0.4124 - val_accuracy: 0.8466\n",
      "Epoch 787/1000\n",
      "225/225 [==============================] - 1s 3ms/step - loss: 0.4465 - accuracy: 0.8263 - val_loss: 0.4099 - val_accuracy: 0.8487\n",
      "Epoch 788/1000\n",
      "225/225 [==============================] - 1s 3ms/step - loss: 0.4459 - accuracy: 0.8271 - val_loss: 0.4136 - val_accuracy: 0.8476\n",
      "Epoch 789/1000\n",
      "225/225 [==============================] - 1s 3ms/step - loss: 0.4461 - accuracy: 0.8270 - val_loss: 0.4123 - val_accuracy: 0.8491\n",
      "Epoch 790/1000\n",
      "225/225 [==============================] - 1s 3ms/step - loss: 0.4461 - accuracy: 0.8271 - val_loss: 0.4120 - val_accuracy: 0.8496\n",
      "Epoch 791/1000\n",
      "225/225 [==============================] - 1s 3ms/step - loss: 0.4465 - accuracy: 0.8274 - val_loss: 0.4118 - val_accuracy: 0.8492\n",
      "Epoch 792/1000\n",
      "225/225 [==============================] - 1s 3ms/step - loss: 0.4455 - accuracy: 0.8267 - val_loss: 0.4133 - val_accuracy: 0.8487\n",
      "Epoch 793/1000\n",
      "225/225 [==============================] - 1s 3ms/step - loss: 0.4445 - accuracy: 0.8281 - val_loss: 0.4102 - val_accuracy: 0.8479\n",
      "Epoch 794/1000\n",
      "225/225 [==============================] - 1s 3ms/step - loss: 0.4466 - accuracy: 0.8256 - val_loss: 0.4129 - val_accuracy: 0.8487\n",
      "Epoch 795/1000\n",
      "225/225 [==============================] - 1s 3ms/step - loss: 0.4468 - accuracy: 0.8268 - val_loss: 0.4149 - val_accuracy: 0.8489\n",
      "Epoch 796/1000\n",
      "225/225 [==============================] - 1s 3ms/step - loss: 0.4444 - accuracy: 0.8275 - val_loss: 0.4128 - val_accuracy: 0.8485\n",
      "Epoch 797/1000\n",
      "225/225 [==============================] - 1s 3ms/step - loss: 0.4455 - accuracy: 0.8273 - val_loss: 0.4131 - val_accuracy: 0.8496\n",
      "Epoch 798/1000\n",
      "225/225 [==============================] - 1s 3ms/step - loss: 0.4465 - accuracy: 0.8266 - val_loss: 0.4115 - val_accuracy: 0.8495\n",
      "Epoch 799/1000\n",
      "225/225 [==============================] - 1s 3ms/step - loss: 0.4466 - accuracy: 0.8270 - val_loss: 0.4111 - val_accuracy: 0.8484\n",
      "Epoch 800/1000\n",
      "225/225 [==============================] - 1s 3ms/step - loss: 0.4471 - accuracy: 0.8263 - val_loss: 0.4147 - val_accuracy: 0.8463\n",
      "Epoch 801/1000\n",
      "225/225 [==============================] - 1s 3ms/step - loss: 0.4473 - accuracy: 0.8273 - val_loss: 0.4134 - val_accuracy: 0.8480\n",
      "Epoch 802/1000\n",
      "225/225 [==============================] - 1s 3ms/step - loss: 0.4450 - accuracy: 0.8270 - val_loss: 0.4134 - val_accuracy: 0.8467\n",
      "Epoch 803/1000\n",
      "225/225 [==============================] - 1s 3ms/step - loss: 0.4460 - accuracy: 0.8269 - val_loss: 0.4098 - val_accuracy: 0.8497\n",
      "Epoch 804/1000\n",
      "225/225 [==============================] - 1s 3ms/step - loss: 0.4449 - accuracy: 0.8273 - val_loss: 0.4088 - val_accuracy: 0.8494\n",
      "Epoch 805/1000\n",
      "225/225 [==============================] - 1s 3ms/step - loss: 0.4455 - accuracy: 0.8273 - val_loss: 0.4088 - val_accuracy: 0.8487\n",
      "Epoch 806/1000\n",
      "225/225 [==============================] - 1s 3ms/step - loss: 0.4463 - accuracy: 0.8255 - val_loss: 0.4116 - val_accuracy: 0.8480\n",
      "Epoch 807/1000\n",
      "225/225 [==============================] - 1s 3ms/step - loss: 0.4455 - accuracy: 0.8274 - val_loss: 0.4109 - val_accuracy: 0.8495\n",
      "Epoch 808/1000\n",
      "225/225 [==============================] - 1s 3ms/step - loss: 0.4449 - accuracy: 0.8272 - val_loss: 0.4106 - val_accuracy: 0.8484\n",
      "Epoch 809/1000\n",
      "225/225 [==============================] - 1s 3ms/step - loss: 0.4459 - accuracy: 0.8267 - val_loss: 0.4117 - val_accuracy: 0.8516\n",
      "Epoch 810/1000\n",
      "225/225 [==============================] - 1s 3ms/step - loss: 0.4466 - accuracy: 0.8263 - val_loss: 0.4136 - val_accuracy: 0.8484\n",
      "Epoch 811/1000\n",
      "225/225 [==============================] - 1s 3ms/step - loss: 0.4456 - accuracy: 0.8277 - val_loss: 0.4123 - val_accuracy: 0.8492\n",
      "Epoch 812/1000\n",
      "225/225 [==============================] - 1s 3ms/step - loss: 0.4460 - accuracy: 0.8274 - val_loss: 0.4126 - val_accuracy: 0.8493\n",
      "Epoch 813/1000\n",
      "225/225 [==============================] - 1s 3ms/step - loss: 0.4436 - accuracy: 0.8280 - val_loss: 0.4113 - val_accuracy: 0.8485\n",
      "Epoch 814/1000\n",
      "225/225 [==============================] - 1s 3ms/step - loss: 0.4440 - accuracy: 0.8275 - val_loss: 0.4105 - val_accuracy: 0.8493\n",
      "Epoch 815/1000\n",
      "225/225 [==============================] - 1s 3ms/step - loss: 0.4475 - accuracy: 0.8266 - val_loss: 0.4127 - val_accuracy: 0.8487\n",
      "Epoch 816/1000\n",
      "225/225 [==============================] - 1s 3ms/step - loss: 0.4439 - accuracy: 0.8278 - val_loss: 0.4150 - val_accuracy: 0.8458\n",
      "Epoch 817/1000\n",
      "225/225 [==============================] - 1s 3ms/step - loss: 0.4468 - accuracy: 0.8261 - val_loss: 0.4114 - val_accuracy: 0.8496\n",
      "Epoch 818/1000\n",
      "225/225 [==============================] - 1s 3ms/step - loss: 0.4477 - accuracy: 0.8268 - val_loss: 0.4112 - val_accuracy: 0.8483\n",
      "Epoch 819/1000\n",
      "225/225 [==============================] - 1s 3ms/step - loss: 0.4454 - accuracy: 0.8270 - val_loss: 0.4137 - val_accuracy: 0.8473\n",
      "Epoch 820/1000\n",
      "225/225 [==============================] - 1s 3ms/step - loss: 0.4451 - accuracy: 0.8272 - val_loss: 0.4124 - val_accuracy: 0.8479\n",
      "Epoch 821/1000\n",
      "225/225 [==============================] - 1s 3ms/step - loss: 0.4435 - accuracy: 0.8276 - val_loss: 0.4118 - val_accuracy: 0.8497\n",
      "Epoch 822/1000\n",
      "225/225 [==============================] - 1s 3ms/step - loss: 0.4472 - accuracy: 0.8268 - val_loss: 0.4128 - val_accuracy: 0.8481\n",
      "Epoch 823/1000\n",
      "225/225 [==============================] - 1s 3ms/step - loss: 0.4461 - accuracy: 0.8276 - val_loss: 0.4143 - val_accuracy: 0.8481\n",
      "Epoch 824/1000\n",
      "225/225 [==============================] - 1s 3ms/step - loss: 0.4480 - accuracy: 0.8267 - val_loss: 0.4122 - val_accuracy: 0.8521\n",
      "Epoch 825/1000\n",
      "225/225 [==============================] - 1s 3ms/step - loss: 0.4468 - accuracy: 0.8270 - val_loss: 0.4117 - val_accuracy: 0.8463\n",
      "Epoch 826/1000\n",
      "225/225 [==============================] - 1s 3ms/step - loss: 0.4446 - accuracy: 0.8278 - val_loss: 0.4099 - val_accuracy: 0.8494\n",
      "Epoch 827/1000\n",
      "225/225 [==============================] - 1s 3ms/step - loss: 0.4450 - accuracy: 0.8279 - val_loss: 0.4116 - val_accuracy: 0.8492\n",
      "Epoch 828/1000\n",
      "225/225 [==============================] - 1s 3ms/step - loss: 0.4452 - accuracy: 0.8271 - val_loss: 0.4126 - val_accuracy: 0.8500\n",
      "Epoch 829/1000\n",
      "225/225 [==============================] - 1s 3ms/step - loss: 0.4458 - accuracy: 0.8269 - val_loss: 0.4105 - val_accuracy: 0.8475\n",
      "Epoch 830/1000\n",
      "225/225 [==============================] - 1s 3ms/step - loss: 0.4473 - accuracy: 0.8256 - val_loss: 0.4130 - val_accuracy: 0.8467\n",
      "Epoch 831/1000\n",
      "225/225 [==============================] - 1s 3ms/step - loss: 0.4443 - accuracy: 0.8280 - val_loss: 0.4144 - val_accuracy: 0.8452\n",
      "Epoch 832/1000\n",
      "225/225 [==============================] - 1s 3ms/step - loss: 0.4447 - accuracy: 0.8272 - val_loss: 0.4101 - val_accuracy: 0.8481\n",
      "Epoch 833/1000\n",
      "225/225 [==============================] - 1s 3ms/step - loss: 0.4463 - accuracy: 0.8262 - val_loss: 0.4120 - val_accuracy: 0.8475\n",
      "Epoch 834/1000\n",
      "225/225 [==============================] - 1s 3ms/step - loss: 0.4456 - accuracy: 0.8262 - val_loss: 0.4109 - val_accuracy: 0.8485\n",
      "Epoch 835/1000\n",
      "225/225 [==============================] - 1s 3ms/step - loss: 0.4448 - accuracy: 0.8280 - val_loss: 0.4140 - val_accuracy: 0.8472\n",
      "Epoch 836/1000\n",
      "225/225 [==============================] - 1s 3ms/step - loss: 0.4473 - accuracy: 0.8262 - val_loss: 0.4136 - val_accuracy: 0.8471\n",
      "Epoch 837/1000\n",
      "225/225 [==============================] - 1s 3ms/step - loss: 0.4441 - accuracy: 0.8280 - val_loss: 0.4112 - val_accuracy: 0.8488\n",
      "Epoch 838/1000\n",
      "225/225 [==============================] - 1s 3ms/step - loss: 0.4441 - accuracy: 0.8281 - val_loss: 0.4108 - val_accuracy: 0.8477\n",
      "Epoch 839/1000\n",
      "225/225 [==============================] - 1s 3ms/step - loss: 0.4437 - accuracy: 0.8280 - val_loss: 0.4109 - val_accuracy: 0.8487\n",
      "Epoch 840/1000\n",
      "225/225 [==============================] - 1s 3ms/step - loss: 0.4431 - accuracy: 0.8278 - val_loss: 0.4081 - val_accuracy: 0.8500\n",
      "Epoch 841/1000\n",
      "225/225 [==============================] - 1s 3ms/step - loss: 0.4471 - accuracy: 0.8264 - val_loss: 0.4097 - val_accuracy: 0.8489\n",
      "Epoch 842/1000\n",
      "225/225 [==============================] - 1s 3ms/step - loss: 0.4452 - accuracy: 0.8276 - val_loss: 0.4094 - val_accuracy: 0.8496\n",
      "Epoch 843/1000\n",
      "225/225 [==============================] - 1s 3ms/step - loss: 0.4467 - accuracy: 0.8271 - val_loss: 0.4127 - val_accuracy: 0.8498\n",
      "Epoch 844/1000\n",
      "225/225 [==============================] - 1s 3ms/step - loss: 0.4462 - accuracy: 0.8268 - val_loss: 0.4132 - val_accuracy: 0.8492\n",
      "Epoch 845/1000\n",
      "225/225 [==============================] - 1s 3ms/step - loss: 0.4455 - accuracy: 0.8271 - val_loss: 0.4135 - val_accuracy: 0.8469\n",
      "Epoch 846/1000\n",
      "225/225 [==============================] - 1s 3ms/step - loss: 0.4456 - accuracy: 0.8265 - val_loss: 0.4106 - val_accuracy: 0.8498\n",
      "Epoch 847/1000\n",
      "225/225 [==============================] - 1s 3ms/step - loss: 0.4444 - accuracy: 0.8279 - val_loss: 0.4122 - val_accuracy: 0.8501\n",
      "Epoch 848/1000\n",
      "225/225 [==============================] - 1s 3ms/step - loss: 0.4453 - accuracy: 0.8275 - val_loss: 0.4107 - val_accuracy: 0.8514\n",
      "Epoch 849/1000\n",
      "225/225 [==============================] - 1s 3ms/step - loss: 0.4440 - accuracy: 0.8283 - val_loss: 0.4133 - val_accuracy: 0.8488\n",
      "Epoch 850/1000\n",
      "225/225 [==============================] - 1s 3ms/step - loss: 0.4430 - accuracy: 0.8279 - val_loss: 0.4120 - val_accuracy: 0.8485\n",
      "Epoch 851/1000\n",
      "225/225 [==============================] - 1s 3ms/step - loss: 0.4449 - accuracy: 0.8260 - val_loss: 0.4148 - val_accuracy: 0.8478\n",
      "Epoch 852/1000\n",
      "225/225 [==============================] - 1s 3ms/step - loss: 0.4427 - accuracy: 0.8276 - val_loss: 0.4089 - val_accuracy: 0.8508\n",
      "Epoch 853/1000\n",
      "225/225 [==============================] - 1s 3ms/step - loss: 0.4442 - accuracy: 0.8287 - val_loss: 0.4097 - val_accuracy: 0.8503\n",
      "Epoch 854/1000\n",
      "225/225 [==============================] - 1s 3ms/step - loss: 0.4438 - accuracy: 0.8278 - val_loss: 0.4098 - val_accuracy: 0.8497\n",
      "Epoch 855/1000\n",
      "225/225 [==============================] - 1s 3ms/step - loss: 0.4428 - accuracy: 0.8277 - val_loss: 0.4147 - val_accuracy: 0.8495\n",
      "Epoch 856/1000\n",
      "225/225 [==============================] - 1s 3ms/step - loss: 0.4460 - accuracy: 0.8269 - val_loss: 0.4128 - val_accuracy: 0.8471\n",
      "Epoch 857/1000\n",
      "225/225 [==============================] - 1s 3ms/step - loss: 0.4454 - accuracy: 0.8277 - val_loss: 0.4114 - val_accuracy: 0.8481\n",
      "Epoch 858/1000\n",
      "225/225 [==============================] - 1s 3ms/step - loss: 0.4444 - accuracy: 0.8279 - val_loss: 0.4127 - val_accuracy: 0.8487\n",
      "Epoch 859/1000\n",
      "225/225 [==============================] - 1s 3ms/step - loss: 0.4439 - accuracy: 0.8276 - val_loss: 0.4149 - val_accuracy: 0.8480\n",
      "Epoch 860/1000\n",
      "225/225 [==============================] - 1s 3ms/step - loss: 0.4453 - accuracy: 0.8275 - val_loss: 0.4107 - val_accuracy: 0.8485\n",
      "Epoch 861/1000\n",
      "225/225 [==============================] - 1s 3ms/step - loss: 0.4442 - accuracy: 0.8269 - val_loss: 0.4134 - val_accuracy: 0.8468\n",
      "Epoch 862/1000\n",
      "225/225 [==============================] - 1s 3ms/step - loss: 0.4447 - accuracy: 0.8274 - val_loss: 0.4139 - val_accuracy: 0.8474\n",
      "Epoch 863/1000\n",
      "225/225 [==============================] - 1s 3ms/step - loss: 0.4447 - accuracy: 0.8270 - val_loss: 0.4133 - val_accuracy: 0.8489\n",
      "Epoch 864/1000\n",
      "225/225 [==============================] - 1s 3ms/step - loss: 0.4436 - accuracy: 0.8291 - val_loss: 0.4104 - val_accuracy: 0.8485\n",
      "Epoch 865/1000\n",
      "225/225 [==============================] - 1s 3ms/step - loss: 0.4435 - accuracy: 0.8277 - val_loss: 0.4118 - val_accuracy: 0.8484\n",
      "Epoch 866/1000\n",
      "225/225 [==============================] - 1s 3ms/step - loss: 0.4426 - accuracy: 0.8280 - val_loss: 0.4141 - val_accuracy: 0.8494\n",
      "Epoch 867/1000\n",
      "225/225 [==============================] - 1s 3ms/step - loss: 0.4436 - accuracy: 0.8261 - val_loss: 0.4140 - val_accuracy: 0.8465\n",
      "Epoch 868/1000\n",
      "225/225 [==============================] - 1s 3ms/step - loss: 0.4436 - accuracy: 0.8274 - val_loss: 0.4134 - val_accuracy: 0.8487\n",
      "Epoch 869/1000\n",
      "225/225 [==============================] - 1s 3ms/step - loss: 0.4439 - accuracy: 0.8273 - val_loss: 0.4110 - val_accuracy: 0.8516\n",
      "Epoch 870/1000\n",
      "225/225 [==============================] - 1s 3ms/step - loss: 0.4449 - accuracy: 0.8270 - val_loss: 0.4111 - val_accuracy: 0.8491\n",
      "Epoch 871/1000\n",
      "225/225 [==============================] - 1s 3ms/step - loss: 0.4434 - accuracy: 0.8277 - val_loss: 0.4151 - val_accuracy: 0.8511\n",
      "Epoch 872/1000\n",
      "225/225 [==============================] - 1s 3ms/step - loss: 0.4447 - accuracy: 0.8283 - val_loss: 0.4116 - val_accuracy: 0.8486\n",
      "Epoch 873/1000\n",
      "225/225 [==============================] - 1s 3ms/step - loss: 0.4450 - accuracy: 0.8273 - val_loss: 0.4122 - val_accuracy: 0.8478\n",
      "Epoch 874/1000\n",
      "225/225 [==============================] - 1s 3ms/step - loss: 0.4447 - accuracy: 0.8274 - val_loss: 0.4114 - val_accuracy: 0.8496\n",
      "Epoch 875/1000\n",
      "225/225 [==============================] - 1s 3ms/step - loss: 0.4435 - accuracy: 0.8277 - val_loss: 0.4103 - val_accuracy: 0.8513\n",
      "Epoch 876/1000\n",
      "225/225 [==============================] - 1s 3ms/step - loss: 0.4465 - accuracy: 0.8269 - val_loss: 0.4100 - val_accuracy: 0.8489\n",
      "Epoch 877/1000\n",
      "225/225 [==============================] - 1s 3ms/step - loss: 0.4458 - accuracy: 0.8274 - val_loss: 0.4141 - val_accuracy: 0.8506\n",
      "Epoch 878/1000\n",
      "225/225 [==============================] - 1s 3ms/step - loss: 0.4455 - accuracy: 0.8272 - val_loss: 0.4108 - val_accuracy: 0.8470\n",
      "Epoch 879/1000\n",
      "225/225 [==============================] - 1s 3ms/step - loss: 0.4433 - accuracy: 0.8266 - val_loss: 0.4108 - val_accuracy: 0.8485\n",
      "Epoch 880/1000\n",
      "225/225 [==============================] - 1s 3ms/step - loss: 0.4431 - accuracy: 0.8280 - val_loss: 0.4100 - val_accuracy: 0.8489\n",
      "Epoch 881/1000\n",
      "225/225 [==============================] - 1s 3ms/step - loss: 0.4431 - accuracy: 0.8282 - val_loss: 0.4113 - val_accuracy: 0.8465\n",
      "Epoch 882/1000\n",
      "225/225 [==============================] - 1s 3ms/step - loss: 0.4456 - accuracy: 0.8266 - val_loss: 0.4130 - val_accuracy: 0.8457\n",
      "Epoch 883/1000\n",
      "225/225 [==============================] - 1s 3ms/step - loss: 0.4446 - accuracy: 0.8268 - val_loss: 0.4108 - val_accuracy: 0.8478\n",
      "Epoch 884/1000\n",
      "225/225 [==============================] - 1s 3ms/step - loss: 0.4445 - accuracy: 0.8266 - val_loss: 0.4120 - val_accuracy: 0.8479\n",
      "Epoch 885/1000\n",
      "225/225 [==============================] - 1s 3ms/step - loss: 0.4431 - accuracy: 0.8293 - val_loss: 0.4120 - val_accuracy: 0.8483\n",
      "Epoch 886/1000\n",
      "225/225 [==============================] - 1s 3ms/step - loss: 0.4452 - accuracy: 0.8273 - val_loss: 0.4142 - val_accuracy: 0.8459\n",
      "Epoch 887/1000\n",
      "225/225 [==============================] - 1s 3ms/step - loss: 0.4431 - accuracy: 0.8265 - val_loss: 0.4130 - val_accuracy: 0.8484\n",
      "Epoch 888/1000\n",
      "225/225 [==============================] - 1s 3ms/step - loss: 0.4451 - accuracy: 0.8273 - val_loss: 0.4133 - val_accuracy: 0.8471\n",
      "Epoch 889/1000\n",
      "225/225 [==============================] - 1s 3ms/step - loss: 0.4450 - accuracy: 0.8280 - val_loss: 0.4128 - val_accuracy: 0.8493\n",
      "Epoch 890/1000\n",
      "225/225 [==============================] - 1s 3ms/step - loss: 0.4433 - accuracy: 0.8279 - val_loss: 0.4125 - val_accuracy: 0.8485\n",
      "Epoch 891/1000\n",
      "225/225 [==============================] - 1s 3ms/step - loss: 0.4434 - accuracy: 0.8266 - val_loss: 0.4100 - val_accuracy: 0.8490\n",
      "Epoch 892/1000\n",
      "225/225 [==============================] - 1s 3ms/step - loss: 0.4446 - accuracy: 0.8275 - val_loss: 0.4123 - val_accuracy: 0.8485\n",
      "Epoch 893/1000\n",
      "225/225 [==============================] - 1s 3ms/step - loss: 0.4446 - accuracy: 0.8280 - val_loss: 0.4124 - val_accuracy: 0.8447\n",
      "Epoch 894/1000\n",
      "225/225 [==============================] - 1s 3ms/step - loss: 0.4454 - accuracy: 0.8277 - val_loss: 0.4135 - val_accuracy: 0.8503\n",
      "Epoch 895/1000\n",
      "225/225 [==============================] - 1s 3ms/step - loss: 0.4442 - accuracy: 0.8265 - val_loss: 0.4108 - val_accuracy: 0.8502\n",
      "Epoch 896/1000\n",
      "225/225 [==============================] - 1s 3ms/step - loss: 0.4430 - accuracy: 0.8278 - val_loss: 0.4119 - val_accuracy: 0.8485\n",
      "Epoch 897/1000\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "225/225 [==============================] - 1s 3ms/step - loss: 0.4459 - accuracy: 0.8262 - val_loss: 0.4091 - val_accuracy: 0.8489\n",
      "Epoch 898/1000\n",
      "225/225 [==============================] - 1s 3ms/step - loss: 0.4434 - accuracy: 0.8279 - val_loss: 0.4111 - val_accuracy: 0.8475\n",
      "Epoch 899/1000\n",
      "225/225 [==============================] - 1s 3ms/step - loss: 0.4458 - accuracy: 0.8273 - val_loss: 0.4119 - val_accuracy: 0.8496\n",
      "Epoch 900/1000\n",
      "225/225 [==============================] - 1s 3ms/step - loss: 0.4428 - accuracy: 0.8278 - val_loss: 0.4106 - val_accuracy: 0.8486\n",
      "Epoch 901/1000\n",
      "225/225 [==============================] - 1s 3ms/step - loss: 0.4453 - accuracy: 0.8263 - val_loss: 0.4103 - val_accuracy: 0.8506\n",
      "Epoch 902/1000\n",
      "225/225 [==============================] - 1s 3ms/step - loss: 0.4435 - accuracy: 0.8284 - val_loss: 0.4088 - val_accuracy: 0.8477\n",
      "Epoch 903/1000\n",
      "225/225 [==============================] - 1s 3ms/step - loss: 0.4457 - accuracy: 0.8270 - val_loss: 0.4153 - val_accuracy: 0.8442\n",
      "Epoch 904/1000\n",
      "225/225 [==============================] - 1s 3ms/step - loss: 0.4465 - accuracy: 0.8273 - val_loss: 0.4140 - val_accuracy: 0.8482\n",
      "Epoch 905/1000\n",
      "225/225 [==============================] - 1s 3ms/step - loss: 0.4444 - accuracy: 0.8288 - val_loss: 0.4111 - val_accuracy: 0.8495\n",
      "Epoch 906/1000\n",
      "225/225 [==============================] - 1s 3ms/step - loss: 0.4445 - accuracy: 0.8268 - val_loss: 0.4109 - val_accuracy: 0.8488\n",
      "Epoch 907/1000\n",
      "225/225 [==============================] - 1s 3ms/step - loss: 0.4419 - accuracy: 0.8294 - val_loss: 0.4086 - val_accuracy: 0.8511\n",
      "Epoch 908/1000\n",
      "225/225 [==============================] - 1s 3ms/step - loss: 0.4446 - accuracy: 0.8265 - val_loss: 0.4119 - val_accuracy: 0.8499\n",
      "Epoch 909/1000\n",
      "225/225 [==============================] - 1s 3ms/step - loss: 0.4420 - accuracy: 0.8278 - val_loss: 0.4122 - val_accuracy: 0.8500\n",
      "Epoch 910/1000\n",
      "225/225 [==============================] - 1s 3ms/step - loss: 0.4455 - accuracy: 0.8266 - val_loss: 0.4127 - val_accuracy: 0.8503\n",
      "Epoch 911/1000\n",
      "225/225 [==============================] - 1s 3ms/step - loss: 0.4433 - accuracy: 0.8275 - val_loss: 0.4117 - val_accuracy: 0.8496\n",
      "Epoch 912/1000\n",
      "225/225 [==============================] - 1s 3ms/step - loss: 0.4436 - accuracy: 0.8275 - val_loss: 0.4092 - val_accuracy: 0.8497\n",
      "Epoch 913/1000\n",
      "225/225 [==============================] - 1s 3ms/step - loss: 0.4456 - accuracy: 0.8270 - val_loss: 0.4113 - val_accuracy: 0.8487\n",
      "Epoch 914/1000\n",
      "225/225 [==============================] - 1s 3ms/step - loss: 0.4436 - accuracy: 0.8292 - val_loss: 0.4116 - val_accuracy: 0.8480\n",
      "Epoch 915/1000\n",
      "225/225 [==============================] - 1s 3ms/step - loss: 0.4440 - accuracy: 0.8275 - val_loss: 0.4122 - val_accuracy: 0.8474\n",
      "Epoch 916/1000\n",
      "225/225 [==============================] - 1s 3ms/step - loss: 0.4410 - accuracy: 0.8288 - val_loss: 0.4099 - val_accuracy: 0.8487\n",
      "Epoch 917/1000\n",
      "225/225 [==============================] - 1s 3ms/step - loss: 0.4432 - accuracy: 0.8283 - val_loss: 0.4101 - val_accuracy: 0.8481\n",
      "Epoch 918/1000\n",
      "225/225 [==============================] - 1s 3ms/step - loss: 0.4446 - accuracy: 0.8272 - val_loss: 0.4120 - val_accuracy: 0.8492\n",
      "Epoch 919/1000\n",
      "225/225 [==============================] - 1s 3ms/step - loss: 0.4416 - accuracy: 0.8283 - val_loss: 0.4092 - val_accuracy: 0.8497\n",
      "Epoch 920/1000\n",
      "225/225 [==============================] - 1s 3ms/step - loss: 0.4418 - accuracy: 0.8295 - val_loss: 0.4109 - val_accuracy: 0.8516\n",
      "Epoch 921/1000\n",
      "225/225 [==============================] - 1s 3ms/step - loss: 0.4427 - accuracy: 0.8288 - val_loss: 0.4114 - val_accuracy: 0.8501\n",
      "Epoch 922/1000\n",
      "225/225 [==============================] - 1s 3ms/step - loss: 0.4436 - accuracy: 0.8272 - val_loss: 0.4107 - val_accuracy: 0.8488\n",
      "Epoch 923/1000\n",
      "225/225 [==============================] - 1s 3ms/step - loss: 0.4442 - accuracy: 0.8277 - val_loss: 0.4112 - val_accuracy: 0.8499\n",
      "Epoch 924/1000\n",
      "225/225 [==============================] - 1s 3ms/step - loss: 0.4422 - accuracy: 0.8283 - val_loss: 0.4142 - val_accuracy: 0.8443\n",
      "Epoch 925/1000\n",
      "225/225 [==============================] - 1s 3ms/step - loss: 0.4438 - accuracy: 0.8285 - val_loss: 0.4106 - val_accuracy: 0.8500\n",
      "Epoch 926/1000\n",
      "225/225 [==============================] - 1s 3ms/step - loss: 0.4423 - accuracy: 0.8282 - val_loss: 0.4108 - val_accuracy: 0.8487\n",
      "Epoch 927/1000\n",
      "225/225 [==============================] - 1s 3ms/step - loss: 0.4451 - accuracy: 0.8274 - val_loss: 0.4085 - val_accuracy: 0.8502\n",
      "Epoch 928/1000\n",
      "225/225 [==============================] - 1s 3ms/step - loss: 0.4432 - accuracy: 0.8287 - val_loss: 0.4093 - val_accuracy: 0.8500\n",
      "Epoch 929/1000\n",
      "225/225 [==============================] - 1s 3ms/step - loss: 0.4418 - accuracy: 0.8281 - val_loss: 0.4110 - val_accuracy: 0.8491\n",
      "Epoch 930/1000\n",
      "225/225 [==============================] - 1s 3ms/step - loss: 0.4458 - accuracy: 0.8267 - val_loss: 0.4092 - val_accuracy: 0.8490\n",
      "Epoch 930: early stopping\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "<keras.src.callbacks.History at 0x2b4ff7400>"
      ]
     },
     "execution_count": 218,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "model=Sequential()\n",
    "model.add(Dense(128, input_dim=X_train.shape[1], activation=\"relu\"))\n",
    "model.add(Dropout(0.2))\n",
    "model.add(BatchNormalization())\n",
    "model.add(Dense(128, activation=\"relu\"))\n",
    "model.add(BatchNormalization())\n",
    "model.add(Dense(64, activation=\"relu\"))\n",
    "model.add(Dropout(0.2))\n",
    "model.add(Dense(64, activation=\"relu\"))\n",
    "model.add(BatchNormalization())\n",
    "model.add(Dense(32, activation=\"relu\"))\n",
    "model.add(Dropout(0.2))\n",
    "model.add(Dense(16, activation=\"relu\"))\n",
    "model.add(BatchNormalization())\n",
    "model.add(Dense(3, activation=\"softmax\"))\n",
    "\n",
    "optimizer = tf.keras.optimizers.legacy.Nadam(learning_rate=0.001)\n",
    "model.compile(loss='categorical_crossentropy', optimizer=optimizer, metrics=['accuracy'])\n",
    "\n",
    "es=EarlyStopping(monitor=\"val_loss\",patience=90,mode=\"auto\",verbose=1)\n",
    "\n",
    "model.fit(X_train, y_train,epochs=1000,batch_size=512,validation_split=0.1,verbose=1,callbacks=[es])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 219,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "997/997 [==============================] - 0s 306us/step\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0       0.85      0.93      0.89     10867\n",
      "           1       0.84      0.91      0.87     10432\n",
      "           2       0.84      0.69      0.76     10591\n",
      "\n",
      "    accuracy                           0.85     31890\n",
      "   macro avg       0.85      0.85      0.84     31890\n",
      "weighted avg       0.85      0.85      0.84     31890\n",
      "\n"
     ]
    }
   ],
   "source": [
    "y_pred = model.predict(X_test)\n",
    "y_pred_classes = np.argmax(y_pred, axis=1)\n",
    "y_true = np.argmax(y_test, axis=1)\n",
    "print(classification_report(y_true, y_pred_classes))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 220,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "3987/3987 [==============================] - 1s 302us/step\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0       0.88      0.96      0.92     42282\n",
      "           1       0.86      0.94      0.90     42717\n",
      "           2       0.89      0.73      0.80     42558\n",
      "\n",
      "    accuracy                           0.88    127557\n",
      "   macro avg       0.88      0.88      0.87    127557\n",
      "weighted avg       0.88      0.88      0.87    127557\n",
      "\n"
     ]
    }
   ],
   "source": [
    "y_t_pred = model.predict(X_train)\n",
    "y_t_pred_classes = np.argmax(y_t_pred, axis=1)\n",
    "y_t_true = np.argmax(y_train, axis=1)\n",
    "print(classification_report(y_t_true, y_t_pred_classes))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "model=Sequential()\n",
    "model.add(Dense(128, input_dim=X_train.shape[1], activation=\"relu\"))\n",
    "model.add(Dropout(0.6))\n",
    "model.add(Dense(128, activation=\"relu\"))\n",
    "model.add(BatchNormalization())\n",
    "model.add(Dense(64, activation=\"relu\"))\n",
    "model.add(Dropout(0.2))\n",
    "model.add(Dense(64, activation=\"relu\"))\n",
    "model.add(BatchNormalization())\n",
    "model.add(Dense(32, activation=\"relu\"))\n",
    "model.add(Dropout(0.2))\n",
    "model.add(Dense(16, activation=\"relu\"))\n",
    "\n",
    "model.add(Dense(3, activation=\"softmax\"))\n",
    "\n",
    "optimizer = tf.keras.optimizers.legacy.Nadam(learning_rate=0.001)\n",
    "model.compile(loss='categorical_crossentropy', optimizer=optimizer, metrics=['accuracy'])\n",
    "\n",
    "es=EarlyStopping(monitor=\"val_loss\",patience=90,mode=\"auto\",verbose=1)\n",
    "\n",
    "model.fit(X_train, y_train,epochs=1000,batch_size=512,validation_split=0.1,verbose=1,callbacks=[es])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "accelerator": "GPU",
  "colab": {
   "authorship_tag": "ABX9TyPqP6yzn6SH+3EVuKsV1nzz",
   "gpuType": "T4",
   "mount_file_id": "1pYkekeORHFFXXH4wMOShnbYPz70vMnI1",
   "provenance": []
  },
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.7"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 1
}
